{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cWACPRL869I4"
   },
   "outputs": [],
   "source": [
    "# C0797202 JAY PANCHAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from memory_profiler) (5.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (1.23.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (0.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JSAnimation in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (20.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.36.0)\n",
      "Requirement already satisfied: six in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->matplotlib) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[accept-rom-license,atari] in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.0.7)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (1.23.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (2.1.0)\n",
      "Requirement already satisfied: ale-py~=0.7.5 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.7.5)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.24.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2020.11.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jay\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n",
      "UsageError: Line magic function `%%file` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install memory_profiler\n",
    "%load_ext memory_profiler\n",
    "%pip install gym\n",
    "%pip install JSAnimation\n",
    "%pip install matplotlib\n",
    "%pip install -U gym >= 0.21.0\n",
    "%pip install -U gym[atari,accept-rom-license]\n",
    "\n",
    "%%file training.py\n",
    "\n",
    "%%python -m memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wotUOa_e6edP"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "from matplotlib import animation\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R66_INeZ9nYX"
   },
   "source": [
    "## Initiating Ping Pong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtT2GyK_6edc",
    "outputId": "6ef17a84-3563-4157-caf3-2c50438190ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\envs\\registration.py:593: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "# Importing gym library and creating environment\n",
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRE6WmXQJ1Z0",
    "outputId": "41a4b484-4f7e-4fd6-fc69-e626adec0523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trwRXI-h6eeI",
    "outputId": "42368b9e-2477-41ef-fb42-30ced75282c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\Jay\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished without success, accumulated reward = -17.0\n"
     ]
    }
   ],
   "source": [
    "# Run a demo of the environment\n",
    "observation = env.reset()\n",
    "cumulated_reward = 0\n",
    "\n",
    "frames = []\n",
    "for t in range(1000):\n",
    "#     print(observation)\n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    # very stupid agent, just makes a random action within the allowd action space\n",
    "    action = env.action_space.sample()\n",
    "#     print(\"Action: {}\".format(t+1))    \n",
    "    observation, reward, done, info = env.step(action)\n",
    "#     print(reward)\n",
    "    cumulated_reward += reward\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
    "        break\n",
    "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3zZTecVWLLes"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
    "\n",
    "def prepro(I):\n",
    "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "  I = I[35:195] # crop\n",
    "  I = I[::2,::2,0] # downsample by factor of 2\n",
    "  I[I == 144] = 0 # erase background (background type 1)\n",
    "  I[I == 109] = 0 # erase background (background type 2)\n",
    "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "  return I.astype(np.float).ravel()\n",
    "\n",
    "def policy_forward(x):\n",
    "  h = np.dot(model['W1'], x)\n",
    "  h[h<0] = 0 # ReLU nonlinearity\n",
    "  logp = np.dot(model['W2'], h)\n",
    "  p = sigmoid(logp)\n",
    "  return p, h # return probability of taking action 2, and hidden state\n",
    "\n",
    "def model_step(model, observation, prev_x):\n",
    "  # preprocess the observation, set input to network to be difference image\n",
    "  cur_x = prepro(observation)\n",
    "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "  prev_x = cur_x\n",
    "  \n",
    "  # forward the policy network and sample an action from the returned probability\n",
    "  aprob, _ = policy_forward(x)\n",
    "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
    "  \n",
    "  return action, prev_x\n",
    "\n",
    "def play_game(env, model):\n",
    "  observation = env.reset()\n",
    "\n",
    "  frames = []\n",
    "  cumulated_reward = 0\n",
    "\n",
    "  prev_x = None # used in computing the difference frame\n",
    "\n",
    "  for t in range(1000):\n",
    "      frames.append(env.render(mode = 'rgb_array'))\n",
    "      action, prev_x = model_step(model, observation, prev_x)\n",
    "      observation, reward, done, info = env.step(action)\n",
    "      cumulated_reward += reward\n",
    "      if done:\n",
    "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
    "          break\n",
    "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
    "  display_frames_as_gif(frames)\n",
    "  env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gWvZQ7AQLQt"
   },
   "source": [
    "# Logic behind the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eqFm7hqcItWl"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Init the model\n",
    "\n",
    "# number of neurons\n",
    "H = 200 \n",
    "\n",
    "# input dimensionality: 80x80 grid\n",
    "D = 80 * 80 \n",
    "\n",
    "model = {}\n",
    "def update_neurons(neurons = 200):\n",
    "    H = neurons\n",
    "    \n",
    "    # \"Xavier\" initialization\n",
    "    \n",
    "    model['W1'] = np.random.randn(H,D) / np.sqrt(D)\n",
    "    model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "update_neurons(H)\n",
    "\n",
    "# import pickle\n",
    "#  model = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TwjiwKisQM19"
   },
   "outputs": [],
   "source": [
    "\n",
    "# hyperparameters\n",
    "batch_size = 10 # every how many episodes to do a param update?\n",
    "\n",
    "# learning_rate = 1e-4\n",
    "learning_rate = 1e-4\n",
    " \n",
    "# discount factor for reward\n",
    "gamma = 0.99 \n",
    "\n",
    "# decay factor for RMSProp leaky sum of grad^2\n",
    "decay_rate = 0.99 \n",
    "  \n",
    "# update buffers that add up gradients over a batch\n",
    "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } \n",
    "\n",
    "# rmsprop memory\n",
    "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } \n",
    "\n",
    "def discount_rewards(r):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "def policy_backward(epx, eph, epdlogp):\n",
    "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
    "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "  dh = np.outer(epdlogp, model['W2'])\n",
    "  dh[eph <= 0] = 0 # backpro prelu\n",
    "  dW1 = np.dot(dh.T, epx)\n",
    "  return {'W1':dW1, 'W2':dW2}\n",
    "\n",
    "\n",
    "def train_model(env, model, total_episodes = 100):\n",
    "  hist = []\n",
    "  hist_2 = []\n",
    "  observation = env.reset()\n",
    "\n",
    "  prev_x = None # used in computing the difference frame\n",
    "  xs,hs,dlogps,drs = [],[],[],[]\n",
    "  running_reward = None\n",
    "  reward_sum = 0\n",
    "  episode_number = 0\n",
    "\n",
    "  from datetime import datetime\n",
    "\n",
    "  now = datetime.now()\n",
    "\n",
    "  print(f'Start time: {now}')\n",
    "\n",
    "  last_export_time = now\n",
    "\n",
    "  while True:\n",
    "    # preprocess the observation, set input to network to be difference image\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # forward the policy network and sample an action from the returned probability\n",
    "    aprob, h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
    "\n",
    "    # record various intermediates (needed later for backprop)\n",
    "    xs.append(x) # observation\n",
    "    hs.append(h) # hidden state\n",
    "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
    "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
    "\n",
    "    # step the environment and get new measurements\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "    if done: # an episode finished\n",
    "      episode_number += 1\n",
    "\n",
    "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "      epx = np.vstack(xs)\n",
    "      eph = np.vstack(hs)\n",
    "      epdlogp = np.vstack(dlogps)\n",
    "      epr = np.vstack(drs)\n",
    "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
    "\n",
    "      # compute the discounted reward backwards through time\n",
    "      discounted_epr = discount_rewards(epr)\n",
    "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "      discounted_epr -= np.mean(discounted_epr)\n",
    "      discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
    "      grad = policy_backward(epx, eph, epdlogp)\n",
    "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
    "\n",
    "      # perform rmsprop parameter update every batch_size episodes\n",
    "      if episode_number % batch_size == 0:\n",
    "        for k,v in model.items():\n",
    "          g = grad_buffer[k] # gradient\n",
    "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
    "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
    "\n",
    "      # boring book-keeping\n",
    "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "      hist.append((episode_number, reward_sum, running_reward,datetime.now()))\n",
    "      hist_2.append((episode_number, running_reward))\n",
    "      \n",
    "      if ((datetime.now() - last_export_time).total_seconds() > 30):\n",
    "        file_name = 'hist1_'+ str(total_episodes) + '.csv'\n",
    "        np.savetxt(file_name, hist, delimiter =\",\", fmt ='% s')\n",
    "        last_export_time = datetime.now()\n",
    "        \n",
    "      print (f'resetting env. episode {episode_number}, reward total was {reward_sum}. running mean: {running_reward}, timestamp: {datetime.now()}')\n",
    "            \n",
    "      reward_sum = 0\n",
    "      observation = env.reset() # reset env\n",
    "      prev_x = None\n",
    "      if running_reward > -11.95:\n",
    "        sys.exit()\n",
    "      if episode_number == total_episodes:\n",
    "        return hist, hist_2\n",
    "\n",
    "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
    "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6Ka_5Vl9Orm",
    "outputId": "75de5744-f8e4-4aea-c00f-2cb2977a38cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2022-08-19 19:14:00.890484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay\\AppData\\Local\\Temp\\ipykernel_16876\\1818632268.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return I.astype(np.float).ravel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode 1, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-19 19:14:03.138693\n",
      "resetting env. episode 2, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-19 19:14:05.835722\n",
      "resetting env. episode 3, reward total was -20.0. running mean: -20.99, timestamp: 2022-08-19 19:14:08.528490\n",
      "resetting env. episode 4, reward total was -20.0. running mean: -20.980099999999997, timestamp: 2022-08-19 19:14:11.516505\n",
      "resetting env. episode 5, reward total was -20.0. running mean: -20.970298999999997, timestamp: 2022-08-19 19:14:14.359908\n",
      "resetting env. episode 6, reward total was -21.0. running mean: -20.970596009999998, timestamp: 2022-08-19 19:14:16.479265\n",
      "resetting env. episode 7, reward total was -21.0. running mean: -20.9708900499, timestamp: 2022-08-19 19:14:18.597393\n",
      "resetting env. episode 8, reward total was -18.0. running mean: -20.941181149401, timestamp: 2022-08-19 19:14:21.897046\n",
      "resetting env. episode 9, reward total was -21.0. running mean: -20.94176933790699, timestamp: 2022-08-19 19:14:24.593851\n",
      "resetting env. episode 10, reward total was -20.0. running mean: -20.93235164452792, timestamp: 2022-08-19 19:14:27.251732\n",
      "resetting env. episode 11, reward total was -20.0. running mean: -20.92302812808264, timestamp: 2022-08-19 19:14:29.933564\n",
      "resetting env. episode 12, reward total was -21.0. running mean: -20.92379784680181, timestamp: 2022-08-19 19:14:31.788606\n",
      "resetting env. episode 13, reward total was -21.0. running mean: -20.924559868333795, timestamp: 2022-08-19 19:14:33.980746\n",
      "resetting env. episode 14, reward total was -20.0. running mean: -20.915314269650455, timestamp: 2022-08-19 19:14:36.527940\n",
      "resetting env. episode 15, reward total was -19.0. running mean: -20.896161126953952, timestamp: 2022-08-19 19:14:38.985517\n",
      "resetting env. episode 16, reward total was -21.0. running mean: -20.897199515684413, timestamp: 2022-08-19 19:14:41.454993\n",
      "resetting env. episode 17, reward total was -21.0. running mean: -20.89822752052757, timestamp: 2022-08-19 19:14:44.167180\n",
      "resetting env. episode 18, reward total was -21.0. running mean: -20.899245245322295, timestamp: 2022-08-19 19:14:46.883780\n",
      "resetting env. episode 19, reward total was -21.0. running mean: -20.900252792869072, timestamp: 2022-08-19 19:14:49.366670\n",
      "resetting env. episode 20, reward total was -20.0. running mean: -20.89125026494038, timestamp: 2022-08-19 19:14:51.873968\n",
      "resetting env. episode 21, reward total was -21.0. running mean: -20.892337762290975, timestamp: 2022-08-19 19:14:54.173427\n",
      "resetting env. episode 22, reward total was -21.0. running mean: -20.893414384668066, timestamp: 2022-08-19 19:14:56.069610\n",
      "resetting env. episode 23, reward total was -20.0. running mean: -20.884480240821386, timestamp: 2022-08-19 19:14:59.010207\n",
      "resetting env. episode 24, reward total was -21.0. running mean: -20.88563543841317, timestamp: 2022-08-19 19:15:01.521853\n",
      "resetting env. episode 25, reward total was -21.0. running mean: -20.88677908402904, timestamp: 2022-08-19 19:15:03.549346\n",
      "resetting env. episode 26, reward total was -19.0. running mean: -20.86791129318875, timestamp: 2022-08-19 19:15:05.997918\n",
      "resetting env. episode 27, reward total was -20.0. running mean: -20.859232180256864, timestamp: 2022-08-19 19:15:08.249433\n",
      "resetting env. episode 28, reward total was -21.0. running mean: -20.860639858454295, timestamp: 2022-08-19 19:15:10.531035\n",
      "resetting env. episode 29, reward total was -21.0. running mean: -20.862033459869753, timestamp: 2022-08-19 19:15:12.546591\n",
      "resetting env. episode 30, reward total was -20.0. running mean: -20.853413125271054, timestamp: 2022-08-19 19:15:15.302874\n",
      "resetting env. episode 31, reward total was -21.0. running mean: -20.854878994018343, timestamp: 2022-08-19 19:15:17.426900\n",
      "resetting env. episode 32, reward total was -20.0. running mean: -20.846330204078157, timestamp: 2022-08-19 19:15:20.423585\n",
      "resetting env. episode 33, reward total was -21.0. running mean: -20.847866902037378, timestamp: 2022-08-19 19:15:22.995883\n",
      "resetting env. episode 34, reward total was -21.0. running mean: -20.849388233017006, timestamp: 2022-08-19 19:15:25.921131\n",
      "resetting env. episode 35, reward total was -19.0. running mean: -20.830894350686837, timestamp: 2022-08-19 19:15:28.483350\n",
      "resetting env. episode 36, reward total was -21.0. running mean: -20.83258540717997, timestamp: 2022-08-19 19:15:30.187820\n",
      "resetting env. episode 37, reward total was -21.0. running mean: -20.834259553108172, timestamp: 2022-08-19 19:15:32.734460\n",
      "resetting env. episode 38, reward total was -21.0. running mean: -20.83591695757709, timestamp: 2022-08-19 19:15:35.258324\n",
      "resetting env. episode 39, reward total was -21.0. running mean: -20.83755778800132, timestamp: 2022-08-19 19:15:37.756658\n",
      "resetting env. episode 40, reward total was -21.0. running mean: -20.839182210121308, timestamp: 2022-08-19 19:15:40.216925\n",
      "resetting env. episode 41, reward total was -20.0. running mean: -20.830790388020095, timestamp: 2022-08-19 19:15:42.784049\n",
      "resetting env. episode 42, reward total was -21.0. running mean: -20.832482484139895, timestamp: 2022-08-19 19:15:45.187901\n",
      "resetting env. episode 43, reward total was -20.0. running mean: -20.824157659298496, timestamp: 2022-08-19 19:15:47.972867\n",
      "resetting env. episode 44, reward total was -20.0. running mean: -20.81591608270551, timestamp: 2022-08-19 19:15:50.369544\n",
      "resetting env. episode 45, reward total was -21.0. running mean: -20.817756921878456, timestamp: 2022-08-19 19:15:52.361098\n",
      "resetting env. episode 46, reward total was -20.0. running mean: -20.80957935265967, timestamp: 2022-08-19 19:15:55.116709\n",
      "resetting env. episode 47, reward total was -21.0. running mean: -20.811483559133077, timestamp: 2022-08-19 19:15:56.996706\n",
      "resetting env. episode 48, reward total was -20.0. running mean: -20.803368723541745, timestamp: 2022-08-19 19:15:59.363379\n",
      "resetting env. episode 49, reward total was -19.0. running mean: -20.78533503630633, timestamp: 2022-08-19 19:16:02.460101\n",
      "resetting env. episode 50, reward total was -21.0. running mean: -20.787481685943266, timestamp: 2022-08-19 19:16:04.811783\n",
      "resetting env. episode 51, reward total was -21.0. running mean: -20.789606869083833, timestamp: 2022-08-19 19:16:06.961442\n",
      "resetting env. episode 52, reward total was -20.0. running mean: -20.781710800392993, timestamp: 2022-08-19 19:16:09.589485\n",
      "resetting env. episode 53, reward total was -21.0. running mean: -20.783893692389064, timestamp: 2022-08-19 19:16:12.247957\n",
      "resetting env. episode 54, reward total was -21.0. running mean: -20.786054755465173, timestamp: 2022-08-19 19:16:14.812771\n",
      "resetting env. episode 55, reward total was -21.0. running mean: -20.78819420791052, timestamp: 2022-08-19 19:16:17.258297\n",
      "resetting env. episode 56, reward total was -20.0. running mean: -20.780312265831416, timestamp: 2022-08-19 19:16:19.615912\n",
      "resetting env. episode 57, reward total was -21.0. running mean: -20.7825091431731, timestamp: 2022-08-19 19:16:22.323199\n",
      "resetting env. episode 58, reward total was -20.0. running mean: -20.77468405174137, timestamp: 2022-08-19 19:16:24.693919\n",
      "resetting env. episode 59, reward total was -21.0. running mean: -20.77693721122396, timestamp: 2022-08-19 19:16:27.219171\n",
      "resetting env. episode 60, reward total was -21.0. running mean: -20.77916783911172, timestamp: 2022-08-19 19:16:29.829137\n",
      "resetting env. episode 61, reward total was -21.0. running mean: -20.781376160720605, timestamp: 2022-08-19 19:16:32.388012\n",
      "resetting env. episode 62, reward total was -20.0. running mean: -20.7735623991134, timestamp: 2022-08-19 19:16:34.582675\n",
      "resetting env. episode 63, reward total was -20.0. running mean: -20.765826775122264, timestamp: 2022-08-19 19:16:37.308389\n",
      "resetting env. episode 64, reward total was -21.0. running mean: -20.76816850737104, timestamp: 2022-08-19 19:16:39.445679\n",
      "resetting env. episode 65, reward total was -21.0. running mean: -20.770486822297332, timestamp: 2022-08-19 19:16:42.432720\n",
      "resetting env. episode 66, reward total was -20.0. running mean: -20.76278195407436, timestamp: 2022-08-19 19:16:45.354236\n",
      "resetting env. episode 67, reward total was -21.0. running mean: -20.765154134533617, timestamp: 2022-08-19 19:16:47.214267\n",
      "resetting env. episode 68, reward total was -19.0. running mean: -20.747502593188283, timestamp: 2022-08-19 19:16:50.194382\n",
      "resetting env. episode 69, reward total was -21.0. running mean: -20.7500275672564, timestamp: 2022-08-19 19:16:52.493123\n",
      "resetting env. episode 70, reward total was -19.0. running mean: -20.732527291583835, timestamp: 2022-08-19 19:16:55.068242\n",
      "resetting env. episode 71, reward total was -21.0. running mean: -20.735202018667998, timestamp: 2022-08-19 19:16:57.621018\n",
      "resetting env. episode 72, reward total was -20.0. running mean: -20.727849998481318, timestamp: 2022-08-19 19:17:00.137264\n",
      "resetting env. episode 73, reward total was -21.0. running mean: -20.730571498496506, timestamp: 2022-08-19 19:17:02.132805\n",
      "resetting env. episode 74, reward total was -20.0. running mean: -20.72326578351154, timestamp: 2022-08-19 19:17:04.228768\n",
      "resetting env. episode 75, reward total was -21.0. running mean: -20.726033125676423, timestamp: 2022-08-19 19:17:06.082999\n",
      "resetting env. episode 76, reward total was -21.0. running mean: -20.72877279441966, timestamp: 2022-08-19 19:17:08.237889\n",
      "resetting env. episode 77, reward total was -20.0. running mean: -20.72148506647546, timestamp: 2022-08-19 19:17:10.486298\n",
      "resetting env. episode 78, reward total was -20.0. running mean: -20.714270215810703, timestamp: 2022-08-19 19:17:12.969227\n",
      "resetting env. episode 79, reward total was -20.0. running mean: -20.707127513652594, timestamp: 2022-08-19 19:17:15.332430\n",
      "resetting env. episode 80, reward total was -20.0. running mean: -20.700056238516066, timestamp: 2022-08-19 19:17:17.924887\n",
      "resetting env. episode 81, reward total was -19.0. running mean: -20.683055676130905, timestamp: 2022-08-19 19:17:20.668556\n",
      "resetting env. episode 82, reward total was -21.0. running mean: -20.686225119369595, timestamp: 2022-08-19 19:17:23.251466\n",
      "resetting env. episode 83, reward total was -19.0. running mean: -20.669362868175902, timestamp: 2022-08-19 19:17:26.249455\n",
      "resetting env. episode 84, reward total was -21.0. running mean: -20.672669239494144, timestamp: 2022-08-19 19:17:28.871448\n",
      "resetting env. episode 85, reward total was -20.0. running mean: -20.665942547099203, timestamp: 2022-08-19 19:17:32.144702\n",
      "resetting env. episode 86, reward total was -21.0. running mean: -20.66928312162821, timestamp: 2022-08-19 19:17:34.717853\n",
      "resetting env. episode 87, reward total was -21.0. running mean: -20.67259029041193, timestamp: 2022-08-19 19:17:37.455536\n",
      "resetting env. episode 88, reward total was -20.0. running mean: -20.66586438750781, timestamp: 2022-08-19 19:17:40.197184\n",
      "resetting env. episode 89, reward total was -21.0. running mean: -20.669205743632734, timestamp: 2022-08-19 19:17:42.602237\n",
      "resetting env. episode 90, reward total was -21.0. running mean: -20.672513686196407, timestamp: 2022-08-19 19:17:45.051690\n",
      "resetting env. episode 91, reward total was -21.0. running mean: -20.67578854933444, timestamp: 2022-08-19 19:17:47.929008\n",
      "resetting env. episode 92, reward total was -21.0. running mean: -20.679030663841097, timestamp: 2022-08-19 19:17:49.996481\n",
      "resetting env. episode 93, reward total was -21.0. running mean: -20.682240357202687, timestamp: 2022-08-19 19:17:52.362158\n",
      "resetting env. episode 94, reward total was -21.0. running mean: -20.68541795363066, timestamp: 2022-08-19 19:17:55.014071\n",
      "resetting env. episode 95, reward total was -21.0. running mean: -20.688563774094355, timestamp: 2022-08-19 19:17:57.877115\n",
      "resetting env. episode 96, reward total was -20.0. running mean: -20.681678136353412, timestamp: 2022-08-19 19:18:00.597352\n",
      "resetting env. episode 97, reward total was -21.0. running mean: -20.684861354989877, timestamp: 2022-08-19 19:18:02.803454\n",
      "resetting env. episode 98, reward total was -21.0. running mean: -20.68801274143998, timestamp: 2022-08-19 19:18:05.497254\n",
      "resetting env. episode 99, reward total was -21.0. running mean: -20.69113261402558, timestamp: 2022-08-19 19:18:08.473298\n",
      "resetting env. episode 100, reward total was -21.0. running mean: -20.694221287885323, timestamp: 2022-08-19 19:18:11.179068\n",
      "resetting env. episode 101, reward total was -20.0. running mean: -20.68727907500647, timestamp: 2022-08-19 19:18:13.984877\n",
      "resetting env. episode 102, reward total was -21.0. running mean: -20.690406284256404, timestamp: 2022-08-19 19:18:16.503179\n",
      "resetting env. episode 103, reward total was -21.0. running mean: -20.69350222141384, timestamp: 2022-08-19 19:18:19.175999\n",
      "resetting env. episode 104, reward total was -19.0. running mean: -20.676567199199702, timestamp: 2022-08-19 19:18:21.855831\n",
      "resetting env. episode 105, reward total was -20.0. running mean: -20.669801527207703, timestamp: 2022-08-19 19:18:25.074185\n",
      "resetting env. episode 106, reward total was -19.0. running mean: -20.653103511935626, timestamp: 2022-08-19 19:18:28.535932\n",
      "resetting env. episode 107, reward total was -21.0. running mean: -20.65657247681627, timestamp: 2022-08-19 19:18:31.493575\n",
      "resetting env. episode 108, reward total was -18.0. running mean: -20.630006752048107, timestamp: 2022-08-19 19:18:35.468860\n",
      "resetting env. episode 109, reward total was -21.0. running mean: -20.633706684527628, timestamp: 2022-08-19 19:18:37.821571\n",
      "resetting env. episode 110, reward total was -20.0. running mean: -20.62736961768235, timestamp: 2022-08-19 19:18:40.742761\n",
      "resetting env. episode 111, reward total was -19.0. running mean: -20.61109592150553, timestamp: 2022-08-19 19:18:44.172669\n",
      "resetting env. episode 112, reward total was -21.0. running mean: -20.614984962290475, timestamp: 2022-08-19 19:18:46.366541\n",
      "resetting env. episode 113, reward total was -21.0. running mean: -20.618835112667572, timestamp: 2022-08-19 19:18:48.654426\n",
      "resetting env. episode 114, reward total was -21.0. running mean: -20.622646761540896, timestamp: 2022-08-19 19:18:51.580602\n",
      "resetting env. episode 115, reward total was -20.0. running mean: -20.616420293925486, timestamp: 2022-08-19 19:18:54.685304\n",
      "resetting env. episode 116, reward total was -21.0. running mean: -20.62025609098623, timestamp: 2022-08-19 19:18:57.361154\n",
      "resetting env. episode 117, reward total was -21.0. running mean: -20.62405353007637, timestamp: 2022-08-19 19:19:00.322150\n",
      "resetting env. episode 118, reward total was -21.0. running mean: -20.627812994775606, timestamp: 2022-08-19 19:19:02.966081\n",
      "resetting env. episode 119, reward total was -21.0. running mean: -20.631534864827852, timestamp: 2022-08-19 19:19:05.926172\n",
      "resetting env. episode 120, reward total was -21.0. running mean: -20.635219516179575, timestamp: 2022-08-19 19:19:08.314786\n",
      "resetting env. episode 121, reward total was -19.0. running mean: -20.61886732101778, timestamp: 2022-08-19 19:19:11.542083\n",
      "resetting env. episode 122, reward total was -19.0. running mean: -20.602678647807604, timestamp: 2022-08-19 19:19:14.657695\n",
      "resetting env. episode 123, reward total was -19.0. running mean: -20.58665186132953, timestamp: 2022-08-19 19:19:18.349827\n",
      "resetting env. episode 124, reward total was -21.0. running mean: -20.590785342716234, timestamp: 2022-08-19 19:19:20.882064\n",
      "resetting env. episode 125, reward total was -21.0. running mean: -20.594877489289072, timestamp: 2022-08-19 19:19:23.523997\n",
      "resetting env. episode 126, reward total was -21.0. running mean: -20.59892871439618, timestamp: 2022-08-19 19:19:25.740075\n",
      "resetting env. episode 127, reward total was -21.0. running mean: -20.60293942725222, timestamp: 2022-08-19 19:19:27.938199\n",
      "resetting env. episode 128, reward total was -21.0. running mean: -20.606910032979698, timestamp: 2022-08-19 19:19:31.123684\n",
      "resetting env. episode 129, reward total was -21.0. running mean: -20.610840932649904, timestamp: 2022-08-19 19:19:33.617019\n",
      "resetting env. episode 130, reward total was -21.0. running mean: -20.614732523323404, timestamp: 2022-08-19 19:19:36.141272\n",
      "resetting env. episode 131, reward total was -21.0. running mean: -20.61858519809017, timestamp: 2022-08-19 19:19:39.015587\n",
      "resetting env. episode 132, reward total was -19.0. running mean: -20.60239934610927, timestamp: 2022-08-19 19:19:41.980662\n",
      "resetting env. episode 133, reward total was -21.0. running mean: -20.60637535264818, timestamp: 2022-08-19 19:19:44.336367\n",
      "resetting env. episode 134, reward total was -21.0. running mean: -20.610311599121697, timestamp: 2022-08-19 19:19:46.635220\n",
      "resetting env. episode 135, reward total was -21.0. running mean: -20.614208483130483, timestamp: 2022-08-19 19:19:49.124568\n",
      "resetting env. episode 136, reward total was -21.0. running mean: -20.618066398299177, timestamp: 2022-08-19 19:19:51.788445\n",
      "resetting env. episode 137, reward total was -19.0. running mean: -20.601885734316188, timestamp: 2022-08-19 19:19:54.978919\n",
      "resetting env. episode 138, reward total was -20.0. running mean: -20.595866876973023, timestamp: 2022-08-19 19:19:57.390471\n",
      "resetting env. episode 139, reward total was -21.0. running mean: -20.599908208203292, timestamp: 2022-08-19 19:19:59.898766\n",
      "resetting env. episode 140, reward total was -21.0. running mean: -20.60390912612126, timestamp: 2022-08-19 19:20:02.277465\n",
      "resetting env. episode 141, reward total was -21.0. running mean: -20.607870034860046, timestamp: 2022-08-19 19:20:05.461116\n",
      "resetting env. episode 142, reward total was -21.0. running mean: -20.611791334511445, timestamp: 2022-08-19 19:20:07.690158\n",
      "resetting env. episode 143, reward total was -21.0. running mean: -20.61567342116633, timestamp: 2022-08-19 19:20:10.188479\n",
      "resetting env. episode 144, reward total was -20.0. running mean: -20.609516686954667, timestamp: 2022-08-19 19:20:12.812465\n",
      "resetting env. episode 145, reward total was -21.0. running mean: -20.613421520085122, timestamp: 2022-08-19 19:20:15.055470\n",
      "resetting env. episode 146, reward total was -21.0. running mean: -20.61728730488427, timestamp: 2022-08-19 19:20:17.322681\n",
      "resetting env. episode 147, reward total was -20.0. running mean: -20.61111443183543, timestamp: 2022-08-19 19:20:19.705310\n",
      "resetting env. episode 148, reward total was -21.0. running mean: -20.615003287517077, timestamp: 2022-08-19 19:20:22.040103\n",
      "resetting env. episode 149, reward total was -20.0. running mean: -20.608853254641904, timestamp: 2022-08-19 19:20:24.784732\n",
      "resetting env. episode 150, reward total was -21.0. running mean: -20.612764722095484, timestamp: 2022-08-19 19:20:27.219227\n",
      "resetting env. episode 151, reward total was -21.0. running mean: -20.61663707487453, timestamp: 2022-08-19 19:20:29.615723\n",
      "resetting env. episode 152, reward total was -20.0. running mean: -20.61047070412578, timestamp: 2022-08-19 19:20:32.664788\n",
      "resetting env. episode 153, reward total was -20.0. running mean: -20.60436599708452, timestamp: 2022-08-19 19:20:35.868337\n",
      "resetting env. episode 154, reward total was -21.0. running mean: -20.608322337113677, timestamp: 2022-08-19 19:20:38.582083\n",
      "resetting env. episode 155, reward total was -18.0. running mean: -20.58223911374254, timestamp: 2022-08-19 19:20:41.839056\n",
      "resetting env. episode 156, reward total was -21.0. running mean: -20.586416722605115, timestamp: 2022-08-19 19:20:44.329377\n",
      "resetting env. episode 157, reward total was -21.0. running mean: -20.590552555379066, timestamp: 2022-08-19 19:20:46.994254\n",
      "resetting env. episode 158, reward total was -21.0. running mean: -20.594647029825275, timestamp: 2022-08-19 19:20:49.535946\n",
      "resetting env. episode 159, reward total was -20.0. running mean: -20.58870055952702, timestamp: 2022-08-19 19:20:52.321552\n",
      "resetting env. episode 160, reward total was -21.0. running mean: -20.59281355393175, timestamp: 2022-08-19 19:20:54.590435\n",
      "resetting env. episode 161, reward total was -21.0. running mean: -20.596885418392436, timestamp: 2022-08-19 19:20:56.789540\n",
      "resetting env. episode 162, reward total was -21.0. running mean: -20.60091656420851, timestamp: 2022-08-19 19:20:59.622958\n",
      "resetting env. episode 163, reward total was -21.0. running mean: -20.604907398566425, timestamp: 2022-08-19 19:21:01.993620\n",
      "resetting env. episode 164, reward total was -21.0. running mean: -20.608858324580762, timestamp: 2022-08-19 19:21:04.507805\n",
      "resetting env. episode 165, reward total was -20.0. running mean: -20.602769741334953, timestamp: 2022-08-19 19:21:07.552433\n",
      "resetting env. episode 166, reward total was -20.0. running mean: -20.5967420439216, timestamp: 2022-08-19 19:21:10.748888\n",
      "resetting env. episode 167, reward total was -21.0. running mean: -20.600774623482387, timestamp: 2022-08-19 19:21:13.737901\n",
      "resetting env. episode 168, reward total was -21.0. running mean: -20.604766877247563, timestamp: 2022-08-19 19:21:16.099586\n",
      "resetting env. episode 169, reward total was -20.0. running mean: -20.598719208475085, timestamp: 2022-08-19 19:21:19.014792\n",
      "resetting env. episode 170, reward total was -21.0. running mean: -20.602732016390334, timestamp: 2022-08-19 19:21:21.618864\n",
      "resetting env. episode 171, reward total was -21.0. running mean: -20.60670469622643, timestamp: 2022-08-19 19:21:23.996485\n",
      "resetting env. episode 172, reward total was -21.0. running mean: -20.610637649264167, timestamp: 2022-08-19 19:21:26.479846\n",
      "resetting env. episode 173, reward total was -21.0. running mean: -20.614531272771526, timestamp: 2022-08-19 19:21:28.950243\n",
      "resetting env. episode 174, reward total was -20.0. running mean: -20.608385960043808, timestamp: 2022-08-19 19:21:31.660998\n",
      "resetting env. episode 175, reward total was -21.0. running mean: -20.612302100443372, timestamp: 2022-08-19 19:21:33.859124\n",
      "resetting env. episode 176, reward total was -21.0. running mean: -20.61617907943894, timestamp: 2022-08-19 19:21:36.687562\n",
      "resetting env. episode 177, reward total was -20.0. running mean: -20.61001728864455, timestamp: 2022-08-19 19:21:39.406297\n",
      "resetting env. episode 178, reward total was -18.0. running mean: -20.583917115758105, timestamp: 2022-08-19 19:21:42.528947\n",
      "resetting env. episode 179, reward total was -21.0. running mean: -20.588077944600524, timestamp: 2022-08-19 19:21:45.038239\n",
      "resetting env. episode 180, reward total was -21.0. running mean: -20.59219716515452, timestamp: 2022-08-19 19:21:47.854712\n",
      "resetting env. episode 181, reward total was -21.0. running mean: -20.596275193502976, timestamp: 2022-08-19 19:21:50.807821\n",
      "resetting env. episode 182, reward total was -20.0. running mean: -20.590312441567946, timestamp: 2022-08-19 19:21:53.369968\n",
      "resetting env. episode 183, reward total was -21.0. running mean: -20.594409317152266, timestamp: 2022-08-19 19:21:55.938105\n",
      "resetting env. episode 184, reward total was -20.0. running mean: -20.58846522398074, timestamp: 2022-08-19 19:21:59.960353\n",
      "resetting env. episode 185, reward total was -20.0. running mean: -20.582580571740934, timestamp: 2022-08-19 19:22:02.856613\n",
      "resetting env. episode 186, reward total was -21.0. running mean: -20.586754766023525, timestamp: 2022-08-19 19:22:05.490574\n",
      "resetting env. episode 187, reward total was -21.0. running mean: -20.59088721836329, timestamp: 2022-08-19 19:22:08.327986\n",
      "resetting env. episode 188, reward total was -20.0. running mean: -20.584978346179653, timestamp: 2022-08-19 19:22:11.535416\n",
      "resetting env. episode 189, reward total was -20.0. running mean: -20.579128562717855, timestamp: 2022-08-19 19:22:14.252735\n",
      "resetting env. episode 190, reward total was -21.0. running mean: -20.583337277090678, timestamp: 2022-08-19 19:22:17.475118\n",
      "resetting env. episode 191, reward total was -21.0. running mean: -20.58750390431977, timestamp: 2022-08-19 19:22:19.773978\n",
      "resetting env. episode 192, reward total was -19.0. running mean: -20.571628865276573, timestamp: 2022-08-19 19:22:23.342435\n",
      "resetting env. episode 193, reward total was -21.0. running mean: -20.575912576623807, timestamp: 2022-08-19 19:22:25.823802\n",
      "resetting env. episode 194, reward total was -20.0. running mean: -20.570153450857568, timestamp: 2022-08-19 19:22:28.723053\n",
      "resetting env. episode 195, reward total was -20.0. running mean: -20.56445191634899, timestamp: 2022-08-19 19:22:31.828752\n",
      "resetting env. episode 196, reward total was -20.0. running mean: -20.5588073971855, timestamp: 2022-08-19 19:22:34.668162\n",
      "resetting env. episode 197, reward total was -19.0. running mean: -20.543219323213645, timestamp: 2022-08-19 19:22:37.529869\n",
      "resetting env. episode 198, reward total was -21.0. running mean: -20.547787129981508, timestamp: 2022-08-19 19:22:41.455877\n",
      "resetting env. episode 199, reward total was -21.0. running mean: -20.552309258681692, timestamp: 2022-08-19 19:22:44.116765\n",
      "resetting env. episode 200, reward total was -21.0. running mean: -20.556786166094877, timestamp: 2022-08-19 19:22:46.387696\n",
      "resetting env. episode 201, reward total was -21.0. running mean: -20.56121830443393, timestamp: 2022-08-19 19:22:49.354554\n",
      "resetting env. episode 202, reward total was -21.0. running mean: -20.56560612138959, timestamp: 2022-08-19 19:22:51.596199\n",
      "resetting env. episode 203, reward total was -21.0. running mean: -20.569950060175692, timestamp: 2022-08-19 19:22:53.927967\n",
      "resetting env. episode 204, reward total was -21.0. running mean: -20.574250559573937, timestamp: 2022-08-19 19:22:56.594836\n",
      "resetting env. episode 205, reward total was -21.0. running mean: -20.578508053978197, timestamp: 2022-08-19 19:23:00.100466\n",
      "resetting env. episode 206, reward total was -21.0. running mean: -20.582722973438415, timestamp: 2022-08-19 19:23:02.461250\n",
      "resetting env. episode 207, reward total was -21.0. running mean: -20.58689574370403, timestamp: 2022-08-19 19:23:05.003482\n",
      "resetting env. episode 208, reward total was -20.0. running mean: -20.58102678626699, timestamp: 2022-08-19 19:23:08.070786\n",
      "resetting env. episode 209, reward total was -21.0. running mean: -20.58521651840432, timestamp: 2022-08-19 19:23:10.468915\n",
      "resetting env. episode 210, reward total was -21.0. running mean: -20.589364353220276, timestamp: 2022-08-19 19:23:13.439970\n",
      "resetting env. episode 211, reward total was -21.0. running mean: -20.593470709688074, timestamp: 2022-08-19 19:23:16.102868\n",
      "resetting env. episode 212, reward total was -21.0. running mean: -20.597536002591195, timestamp: 2022-08-19 19:23:18.943429\n",
      "resetting env. episode 213, reward total was -19.0. running mean: -20.581560642565282, timestamp: 2022-08-19 19:23:22.120935\n",
      "resetting env. episode 214, reward total was -19.0. running mean: -20.56574503613963, timestamp: 2022-08-19 19:23:25.419119\n",
      "resetting env. episode 215, reward total was -21.0. running mean: -20.570087585778236, timestamp: 2022-08-19 19:23:28.448021\n",
      "resetting env. episode 216, reward total was -19.0. running mean: -20.554386709920454, timestamp: 2022-08-19 19:23:31.341289\n",
      "resetting env. episode 217, reward total was -21.0. running mean: -20.55884284282125, timestamp: 2022-08-19 19:23:33.847588\n",
      "resetting env. episode 218, reward total was -19.0. running mean: -20.543254414393036, timestamp: 2022-08-19 19:23:36.699561\n",
      "resetting env. episode 219, reward total was -20.0. running mean: -20.537821870249104, timestamp: 2022-08-19 19:23:39.453416\n",
      "resetting env. episode 220, reward total was -20.0. running mean: -20.53244365154661, timestamp: 2022-08-19 19:23:42.391578\n",
      "resetting env. episode 221, reward total was -19.0. running mean: -20.517119215031148, timestamp: 2022-08-19 19:23:45.216717\n",
      "resetting env. episode 222, reward total was -20.0. running mean: -20.511948022880834, timestamp: 2022-08-19 19:23:47.690106\n",
      "resetting env. episode 223, reward total was -21.0. running mean: -20.516828542652025, timestamp: 2022-08-19 19:23:50.663160\n",
      "resetting env. episode 224, reward total was -21.0. running mean: -20.521660257225506, timestamp: 2022-08-19 19:23:53.039807\n",
      "resetting env. episode 225, reward total was -21.0. running mean: -20.526443654653253, timestamp: 2022-08-19 19:23:56.439718\n",
      "resetting env. episode 226, reward total was -21.0. running mean: -20.531179218106722, timestamp: 2022-08-19 19:23:58.499239\n",
      "resetting env. episode 227, reward total was -20.0. running mean: -20.525867425925654, timestamp: 2022-08-19 19:24:01.844131\n",
      "resetting env. episode 228, reward total was -19.0. running mean: -20.5106087516664, timestamp: 2022-08-19 19:24:05.773193\n",
      "resetting env. episode 229, reward total was -21.0. running mean: -20.515502664149736, timestamp: 2022-08-19 19:24:08.457019\n",
      "resetting env. episode 230, reward total was -21.0. running mean: -20.520347637508237, timestamp: 2022-08-19 19:24:10.970281\n",
      "resetting env. episode 231, reward total was -21.0. running mean: -20.525144161133156, timestamp: 2022-08-19 19:24:13.696108\n",
      "resetting env. episode 232, reward total was -21.0. running mean: -20.529892719521825, timestamp: 2022-08-19 19:24:15.753725\n",
      "resetting env. episode 233, reward total was -21.0. running mean: -20.534593792326607, timestamp: 2022-08-19 19:24:17.959827\n",
      "resetting env. episode 234, reward total was -21.0. running mean: -20.539247854403342, timestamp: 2022-08-19 19:24:20.455156\n",
      "resetting env. episode 235, reward total was -20.0. running mean: -20.533855375859307, timestamp: 2022-08-19 19:24:22.879332\n",
      "resetting env. episode 236, reward total was -21.0. running mean: -20.538516822100714, timestamp: 2022-08-19 19:24:25.352735\n",
      "resetting env. episode 237, reward total was -21.0. running mean: -20.54313165387971, timestamp: 2022-08-19 19:24:27.702496\n",
      "resetting env. episode 238, reward total was -21.0. running mean: -20.547700337340913, timestamp: 2022-08-19 19:24:29.582468\n",
      "resetting env. episode 239, reward total was -21.0. running mean: -20.552223333967504, timestamp: 2022-08-19 19:24:32.947475\n",
      "resetting env. episode 240, reward total was -20.0. running mean: -20.54670110062783, timestamp: 2022-08-19 19:24:35.978423\n",
      "resetting env. episode 241, reward total was -20.0. running mean: -20.54123408962155, timestamp: 2022-08-19 19:24:39.134398\n",
      "resetting env. episode 242, reward total was -20.0. running mean: -20.535821748725333, timestamp: 2022-08-19 19:24:41.717449\n",
      "resetting env. episode 243, reward total was -21.0. running mean: -20.54046353123808, timestamp: 2022-08-19 19:24:44.067167\n",
      "resetting env. episode 244, reward total was -18.0. running mean: -20.515058895925698, timestamp: 2022-08-19 19:24:47.856040\n",
      "resetting env. episode 245, reward total was -21.0. running mean: -20.519908306966443, timestamp: 2022-08-19 19:24:50.415204\n",
      "resetting env. episode 246, reward total was -20.0. running mean: -20.514709223896777, timestamp: 2022-08-19 19:24:54.313381\n",
      "resetting env. episode 247, reward total was -21.0. running mean: -20.51956213165781, timestamp: 2022-08-19 19:24:56.592011\n",
      "resetting env. episode 248, reward total was -21.0. running mean: -20.524366510341235, timestamp: 2022-08-19 19:24:58.897111\n",
      "resetting env. episode 249, reward total was -20.0. running mean: -20.51912284523782, timestamp: 2022-08-19 19:25:01.104209\n",
      "resetting env. episode 250, reward total was -20.0. running mean: -20.51393161678544, timestamp: 2022-08-19 19:25:03.523914\n",
      "resetting env. episode 251, reward total was -21.0. running mean: -20.518792300617587, timestamp: 2022-08-19 19:25:05.758183\n",
      "resetting env. episode 252, reward total was -21.0. running mean: -20.523604377611413, timestamp: 2022-08-19 19:25:08.091133\n",
      "resetting env. episode 253, reward total was -21.0. running mean: -20.5283683338353, timestamp: 2022-08-19 19:25:11.190002\n",
      "resetting env. episode 254, reward total was -21.0. running mean: -20.533084650496946, timestamp: 2022-08-19 19:25:14.705604\n",
      "resetting env. episode 255, reward total was -21.0. running mean: -20.537753803991976, timestamp: 2022-08-19 19:25:17.170015\n",
      "resetting env. episode 256, reward total was -21.0. running mean: -20.542376265952058, timestamp: 2022-08-19 19:25:19.810956\n",
      "resetting env. episode 257, reward total was -20.0. running mean: -20.536952503292536, timestamp: 2022-08-19 19:25:22.615407\n",
      "resetting env. episode 258, reward total was -19.0. running mean: -20.521582978259612, timestamp: 2022-08-19 19:25:25.881610\n",
      "resetting env. episode 259, reward total was -21.0. running mean: -20.526367148477018, timestamp: 2022-08-19 19:25:27.656541\n",
      "resetting env. episode 260, reward total was -21.0. running mean: -20.53110347699225, timestamp: 2022-08-19 19:25:29.453505\n",
      "resetting env. episode 261, reward total was -20.0. running mean: -20.525792442222325, timestamp: 2022-08-19 19:25:31.667317\n",
      "resetting env. episode 262, reward total was -21.0. running mean: -20.530534517800103, timestamp: 2022-08-19 19:25:33.987978\n",
      "resetting env. episode 263, reward total was -21.0. running mean: -20.535229172622103, timestamp: 2022-08-19 19:25:37.579011\n",
      "resetting env. episode 264, reward total was -21.0. running mean: -20.539876880895882, timestamp: 2022-08-19 19:25:40.241893\n",
      "resetting env. episode 265, reward total was -20.0. running mean: -20.534478112086923, timestamp: 2022-08-19 19:25:42.658433\n",
      "resetting env. episode 266, reward total was -21.0. running mean: -20.539133330966056, timestamp: 2022-08-19 19:25:45.022015\n",
      "resetting env. episode 267, reward total was -20.0. running mean: -20.533741997656396, timestamp: 2022-08-19 19:25:47.653755\n",
      "resetting env. episode 268, reward total was -20.0. running mean: -20.52840457767983, timestamp: 2022-08-19 19:25:51.566861\n",
      "resetting env. episode 269, reward total was -21.0. running mean: -20.53312053190303, timestamp: 2022-08-19 19:25:54.341453\n",
      "resetting env. episode 270, reward total was -21.0. running mean: -20.537789326584, timestamp: 2022-08-19 19:25:56.683183\n",
      "resetting env. episode 271, reward total was -21.0. running mean: -20.54241143331816, timestamp: 2022-08-19 19:25:58.663270\n",
      "resetting env. episode 272, reward total was -21.0. running mean: -20.546987318984982, timestamp: 2022-08-19 19:26:00.930369\n",
      "resetting env. episode 273, reward total was -21.0. running mean: -20.551517445795135, timestamp: 2022-08-19 19:26:03.989326\n",
      "resetting env. episode 274, reward total was -21.0. running mean: -20.556002271337185, timestamp: 2022-08-19 19:26:07.390749\n",
      "resetting env. episode 275, reward total was -21.0. running mean: -20.560442248623815, timestamp: 2022-08-19 19:26:09.452410\n",
      "resetting env. episode 276, reward total was -21.0. running mean: -20.564837826137577, timestamp: 2022-08-19 19:26:11.869989\n",
      "resetting env. episode 277, reward total was -21.0. running mean: -20.5691894478762, timestamp: 2022-08-19 19:26:14.646490\n",
      "resetting env. episode 278, reward total was -20.0. running mean: -20.56349755339744, timestamp: 2022-08-19 19:26:16.977433\n",
      "resetting env. episode 279, reward total was -20.0. running mean: -20.557862577863464, timestamp: 2022-08-19 19:26:19.377478\n",
      "resetting env. episode 280, reward total was -21.0. running mean: -20.56228395208483, timestamp: 2022-08-19 19:26:21.870147\n",
      "resetting env. episode 281, reward total was -21.0. running mean: -20.56666111256398, timestamp: 2022-08-19 19:26:24.349505\n",
      "resetting env. episode 282, reward total was -20.0. running mean: -20.56099450143834, timestamp: 2022-08-19 19:26:27.140655\n",
      "resetting env. episode 283, reward total was -19.0. running mean: -20.545384556423958, timestamp: 2022-08-19 19:26:29.727488\n",
      "resetting env. episode 284, reward total was -21.0. running mean: -20.54993071085972, timestamp: 2022-08-19 19:26:33.083615\n",
      "resetting env. episode 285, reward total was -21.0. running mean: -20.554431403751124, timestamp: 2022-08-19 19:26:35.537798\n",
      "resetting env. episode 286, reward total was -20.0. running mean: -20.548887089713613, timestamp: 2022-08-19 19:26:38.657201\n",
      "resetting env. episode 287, reward total was -18.0. running mean: -20.523398218816478, timestamp: 2022-08-19 19:26:41.616260\n",
      "resetting env. episode 288, reward total was -21.0. running mean: -20.528164236628314, timestamp: 2022-08-19 19:26:44.692171\n",
      "resetting env. episode 289, reward total was -16.0. running mean: -20.48288259426203, timestamp: 2022-08-19 19:26:48.548343\n",
      "resetting env. episode 290, reward total was -21.0. running mean: -20.48805376831941, timestamp: 2022-08-19 19:26:51.384434\n",
      "resetting env. episode 291, reward total was -18.0. running mean: -20.463173230636215, timestamp: 2022-08-19 19:26:55.356114\n",
      "resetting env. episode 292, reward total was -20.0. running mean: -20.45854149832985, timestamp: 2022-08-19 19:26:58.616371\n",
      "resetting env. episode 293, reward total was -20.0. running mean: -20.45395608334655, timestamp: 2022-08-19 19:27:02.763289\n",
      "resetting env. episode 294, reward total was -21.0. running mean: -20.459416522513084, timestamp: 2022-08-19 19:27:06.071470\n",
      "resetting env. episode 295, reward total was -21.0. running mean: -20.464822357287954, timestamp: 2022-08-19 19:27:09.144259\n",
      "resetting env. episode 296, reward total was -20.0. running mean: -20.460174133715075, timestamp: 2022-08-19 19:27:12.171135\n",
      "resetting env. episode 297, reward total was -21.0. running mean: -20.465572392377926, timestamp: 2022-08-19 19:27:14.538806\n",
      "resetting env. episode 298, reward total was -21.0. running mean: -20.470916668454148, timestamp: 2022-08-19 19:27:17.415131\n",
      "resetting env. episode 299, reward total was -20.0. running mean: -20.466207501769606, timestamp: 2022-08-19 19:27:20.805059\n",
      "resetting env. episode 300, reward total was -20.0. running mean: -20.461545426751908, timestamp: 2022-08-19 19:27:25.108587\n",
      "resetting env. episode 301, reward total was -21.0. running mean: -20.46692997248439, timestamp: 2022-08-19 19:27:27.646475\n",
      "resetting env. episode 302, reward total was -21.0. running mean: -20.472260672759546, timestamp: 2022-08-19 19:27:30.480896\n",
      "resetting env. episode 303, reward total was -18.0. running mean: -20.44753806603195, timestamp: 2022-08-19 19:27:34.086260\n",
      "resetting env. episode 304, reward total was -21.0. running mean: -20.45306268537163, timestamp: 2022-08-19 19:27:36.405061\n",
      "resetting env. episode 305, reward total was -19.0. running mean: -20.438532058517914, timestamp: 2022-08-19 19:27:40.212884\n",
      "resetting env. episode 306, reward total was -19.0. running mean: -20.424146737932737, timestamp: 2022-08-19 19:27:43.347390\n",
      "resetting env. episode 307, reward total was -19.0. running mean: -20.409905270553413, timestamp: 2022-08-19 19:27:47.117299\n",
      "resetting env. episode 308, reward total was -21.0. running mean: -20.41580621784788, timestamp: 2022-08-19 19:27:49.708596\n",
      "resetting env. episode 309, reward total was -21.0. running mean: -20.421648155669402, timestamp: 2022-08-19 19:27:52.438302\n",
      "resetting env. episode 310, reward total was -21.0. running mean: -20.427431674112707, timestamp: 2022-08-19 19:27:55.357497\n",
      "resetting env. episode 311, reward total was -20.0. running mean: -20.42315735737158, timestamp: 2022-08-19 19:27:58.577177\n",
      "resetting env. episode 312, reward total was -21.0. running mean: -20.428925783797865, timestamp: 2022-08-19 19:28:01.867415\n",
      "resetting env. episode 313, reward total was -21.0. running mean: -20.43463652595989, timestamp: 2022-08-19 19:28:04.625043\n",
      "resetting env. episode 314, reward total was -20.0. running mean: -20.430290160700288, timestamp: 2022-08-19 19:28:09.013279\n",
      "resetting env. episode 315, reward total was -19.0. running mean: -20.415987259093285, timestamp: 2022-08-19 19:28:12.090057\n",
      "resetting env. episode 316, reward total was -19.0. running mean: -20.401827386502354, timestamp: 2022-08-19 19:28:15.449092\n",
      "resetting env. episode 317, reward total was -21.0. running mean: -20.40780911263733, timestamp: 2022-08-19 19:28:18.273527\n",
      "resetting env. episode 318, reward total was -20.0. running mean: -20.403731021510957, timestamp: 2022-08-19 19:28:21.959674\n",
      "resetting env. episode 319, reward total was -20.0. running mean: -20.399693711295846, timestamp: 2022-08-19 19:28:25.192034\n",
      "resetting env. episode 320, reward total was -20.0. running mean: -20.395696774182888, timestamp: 2022-08-19 19:28:28.295741\n",
      "resetting env. episode 321, reward total was -20.0. running mean: -20.39173980644106, timestamp: 2022-08-19 19:28:31.198691\n",
      "resetting env. episode 322, reward total was -21.0. running mean: -20.397822408376648, timestamp: 2022-08-19 19:28:34.162769\n",
      "resetting env. episode 323, reward total was -21.0. running mean: -20.403844184292883, timestamp: 2022-08-19 19:28:37.807029\n",
      "resetting env. episode 324, reward total was -17.0. running mean: -20.369805742449955, timestamp: 2022-08-19 19:28:41.393367\n",
      "resetting env. episode 325, reward total was -20.0. running mean: -20.366107685025455, timestamp: 2022-08-19 19:28:44.377393\n",
      "resetting env. episode 326, reward total was -19.0. running mean: -20.3524466081752, timestamp: 2022-08-19 19:28:48.568198\n",
      "resetting env. episode 327, reward total was -18.0. running mean: -20.328922142093447, timestamp: 2022-08-19 19:28:51.976081\n",
      "resetting env. episode 328, reward total was -21.0. running mean: -20.335632920672513, timestamp: 2022-08-19 19:28:56.431176\n",
      "resetting env. episode 329, reward total was -21.0. running mean: -20.342276591465787, timestamp: 2022-08-19 19:28:59.283553\n",
      "resetting env. episode 330, reward total was -21.0. running mean: -20.348853825551128, timestamp: 2022-08-19 19:29:02.979697\n",
      "resetting env. episode 331, reward total was -19.0. running mean: -20.335365287295616, timestamp: 2022-08-19 19:29:06.284311\n",
      "resetting env. episode 332, reward total was -21.0. running mean: -20.34201163442266, timestamp: 2022-08-19 19:29:09.959072\n",
      "resetting env. episode 333, reward total was -21.0. running mean: -20.348591518078436, timestamp: 2022-08-19 19:29:12.500277\n",
      "resetting env. episode 334, reward total was -21.0. running mean: -20.355105602897652, timestamp: 2022-08-19 19:29:15.403136\n",
      "resetting env. episode 335, reward total was -20.0. running mean: -20.351554546868673, timestamp: 2022-08-19 19:29:18.303630\n",
      "resetting env. episode 336, reward total was -21.0. running mean: -20.358039001399987, timestamp: 2022-08-19 19:29:21.012396\n",
      "resetting env. episode 337, reward total was -20.0. running mean: -20.354458611385986, timestamp: 2022-08-19 19:29:24.248769\n",
      "resetting env. episode 338, reward total was -21.0. running mean: -20.360914025272127, timestamp: 2022-08-19 19:29:27.260703\n",
      "resetting env. episode 339, reward total was -21.0. running mean: -20.367304885019408, timestamp: 2022-08-19 19:29:30.034274\n",
      "resetting env. episode 340, reward total was -19.0. running mean: -20.353631836169214, timestamp: 2022-08-19 19:29:32.935553\n",
      "resetting env. episode 341, reward total was -20.0. running mean: -20.35009551780752, timestamp: 2022-08-19 19:29:36.203780\n",
      "resetting env. episode 342, reward total was -20.0. running mean: -20.346594562629445, timestamp: 2022-08-19 19:29:39.599705\n",
      "resetting env. episode 343, reward total was -20.0. running mean: -20.34312861700315, timestamp: 2022-08-19 19:29:42.829069\n",
      "resetting env. episode 344, reward total was -20.0. running mean: -20.33969733083312, timestamp: 2022-08-19 19:29:45.826080\n",
      "resetting env. episode 345, reward total was -19.0. running mean: -20.32630035752479, timestamp: 2022-08-19 19:29:50.210342\n",
      "resetting env. episode 346, reward total was -20.0. running mean: -20.32303735394954, timestamp: 2022-08-19 19:29:53.212915\n",
      "resetting env. episode 347, reward total was -21.0. running mean: -20.329806980410048, timestamp: 2022-08-19 19:29:55.880483\n",
      "resetting env. episode 348, reward total was -20.0. running mean: -20.326508910605945, timestamp: 2022-08-19 19:29:59.274413\n",
      "resetting env. episode 349, reward total was -20.0. running mean: -20.323243821499883, timestamp: 2022-08-19 19:30:02.434961\n",
      "resetting env. episode 350, reward total was -18.0. running mean: -20.300011383284883, timestamp: 2022-08-19 19:30:06.227860\n",
      "resetting env. episode 351, reward total was -20.0. running mean: -20.29701126945203, timestamp: 2022-08-19 19:30:10.349986\n",
      "resetting env. episode 352, reward total was -21.0. running mean: -20.304041156757513, timestamp: 2022-08-19 19:30:13.043750\n",
      "resetting env. episode 353, reward total was -21.0. running mean: -20.31100074518994, timestamp: 2022-08-19 19:30:15.747539\n",
      "resetting env. episode 354, reward total was -21.0. running mean: -20.31789073773804, timestamp: 2022-08-19 19:30:18.422375\n",
      "resetting env. episode 355, reward total was -21.0. running mean: -20.32471183036066, timestamp: 2022-08-19 19:30:21.350564\n",
      "resetting env. episode 356, reward total was -20.0. running mean: -20.32146471205705, timestamp: 2022-08-19 19:30:24.587894\n",
      "resetting env. episode 357, reward total was -20.0. running mean: -20.31825006493648, timestamp: 2022-08-19 19:30:28.481486\n",
      "resetting env. episode 358, reward total was -20.0. running mean: -20.315067564287112, timestamp: 2022-08-19 19:30:32.093840\n",
      "resetting env. episode 359, reward total was -20.0. running mean: -20.31191688864424, timestamp: 2022-08-19 19:30:36.081171\n",
      "resetting env. episode 360, reward total was -20.0. running mean: -20.3087977197578, timestamp: 2022-08-19 19:30:39.100104\n",
      "resetting env. episode 361, reward total was -21.0. running mean: -20.31570974256022, timestamp: 2022-08-19 19:30:41.389971\n",
      "resetting env. episode 362, reward total was -19.0. running mean: -20.302552645134618, timestamp: 2022-08-19 19:30:44.761955\n",
      "resetting env. episode 363, reward total was -21.0. running mean: -20.309527118683274, timestamp: 2022-08-19 19:30:47.567812\n",
      "resetting env. episode 364, reward total was -21.0. running mean: -20.316431847496442, timestamp: 2022-08-19 19:30:51.376612\n",
      "resetting env. episode 365, reward total was -21.0. running mean: -20.32326752902148, timestamp: 2022-08-19 19:30:54.513227\n",
      "resetting env. episode 366, reward total was -20.0. running mean: -20.32003485373126, timestamp: 2022-08-19 19:30:57.760558\n",
      "resetting env. episode 367, reward total was -20.0. running mean: -20.31683450519395, timestamp: 2022-08-19 19:31:00.857270\n",
      "resetting env. episode 368, reward total was -20.0. running mean: -20.31366616014201, timestamp: 2022-08-19 19:31:03.675787\n",
      "resetting env. episode 369, reward total was -20.0. running mean: -20.31052949854059, timestamp: 2022-08-19 19:31:06.518137\n",
      "resetting env. episode 370, reward total was -21.0. running mean: -20.317424203555184, timestamp: 2022-08-19 19:31:09.911069\n",
      "resetting env. episode 371, reward total was -21.0. running mean: -20.324249961519634, timestamp: 2022-08-19 19:31:12.645762\n",
      "resetting env. episode 372, reward total was -20.0. running mean: -20.321007461904436, timestamp: 2022-08-19 19:31:16.285033\n",
      "resetting env. episode 373, reward total was -21.0. running mean: -20.327797387285393, timestamp: 2022-08-19 19:31:19.623108\n",
      "resetting env. episode 374, reward total was -18.0. running mean: -20.30451941341254, timestamp: 2022-08-19 19:31:23.741129\n",
      "resetting env. episode 375, reward total was -21.0. running mean: -20.311474219278413, timestamp: 2022-08-19 19:31:27.093161\n",
      "resetting env. episode 376, reward total was -20.0. running mean: -20.308359477085627, timestamp: 2022-08-19 19:31:30.577825\n",
      "resetting env. episode 377, reward total was -21.0. running mean: -20.315275882314772, timestamp: 2022-08-19 19:31:33.177876\n",
      "resetting env. episode 378, reward total was -21.0. running mean: -20.322123123491625, timestamp: 2022-08-19 19:31:35.772940\n",
      "resetting env. episode 379, reward total was -21.0. running mean: -20.32890189225671, timestamp: 2022-08-19 19:31:38.616342\n",
      "resetting env. episode 380, reward total was -21.0. running mean: -20.335612873334142, timestamp: 2022-08-19 19:31:42.260634\n",
      "resetting env. episode 381, reward total was -21.0. running mean: -20.342256744600803, timestamp: 2022-08-19 19:31:44.749384\n",
      "resetting env. episode 382, reward total was -21.0. running mean: -20.348834177154796, timestamp: 2022-08-19 19:31:48.256041\n",
      "resetting env. episode 383, reward total was -20.0. running mean: -20.345345835383245, timestamp: 2022-08-19 19:31:51.826577\n",
      "resetting env. episode 384, reward total was -20.0. running mean: -20.341892377029414, timestamp: 2022-08-19 19:31:56.492435\n",
      "resetting env. episode 385, reward total was -21.0. running mean: -20.34847345325912, timestamp: 2022-08-19 19:31:59.661965\n",
      "resetting env. episode 386, reward total was -19.0. running mean: -20.33498871872653, timestamp: 2022-08-19 19:32:03.744053\n",
      "resetting env. episode 387, reward total was -19.0. running mean: -20.321638831539268, timestamp: 2022-08-19 19:32:07.524944\n",
      "resetting env. episode 388, reward total was -21.0. running mean: -20.328422443223875, timestamp: 2022-08-19 19:32:10.232707\n",
      "resetting env. episode 389, reward total was -19.0. running mean: -20.31513821879164, timestamp: 2022-08-19 19:32:14.503293\n",
      "resetting env. episode 390, reward total was -21.0. running mean: -20.321986836603724, timestamp: 2022-08-19 19:32:18.165503\n",
      "resetting env. episode 391, reward total was -21.0. running mean: -20.328766968237687, timestamp: 2022-08-19 19:32:21.463001\n",
      "resetting env. episode 392, reward total was -20.0. running mean: -20.325479298555308, timestamp: 2022-08-19 19:32:25.199988\n",
      "resetting env. episode 393, reward total was -21.0. running mean: -20.332224505569755, timestamp: 2022-08-19 19:32:27.877827\n",
      "resetting env. episode 394, reward total was -20.0. running mean: -20.328902260514056, timestamp: 2022-08-19 19:32:30.567640\n",
      "resetting env. episode 395, reward total was -21.0. running mean: -20.335613237908916, timestamp: 2022-08-19 19:32:33.709240\n",
      "resetting env. episode 396, reward total was -16.0. running mean: -20.292257105529828, timestamp: 2022-08-19 19:32:37.767563\n",
      "resetting env. episode 397, reward total was -21.0. running mean: -20.29933453447453, timestamp: 2022-08-19 19:32:40.202055\n",
      "resetting env. episode 398, reward total was -21.0. running mean: -20.306341189129785, timestamp: 2022-08-19 19:32:43.755555\n",
      "resetting env. episode 399, reward total was -21.0. running mean: -20.31327777723849, timestamp: 2022-08-19 19:32:46.393506\n",
      "resetting env. episode 400, reward total was -21.0. running mean: -20.320144999466105, timestamp: 2022-08-19 19:32:48.962637\n",
      "resetting env. episode 401, reward total was -21.0. running mean: -20.326943549471444, timestamp: 2022-08-19 19:32:52.030438\n",
      "resetting env. episode 402, reward total was -20.0. running mean: -20.32367411397673, timestamp: 2022-08-19 19:32:54.940661\n",
      "resetting env. episode 403, reward total was -21.0. running mean: -20.33043737283696, timestamp: 2022-08-19 19:32:58.099223\n",
      "resetting env. episode 404, reward total was -21.0. running mean: -20.337132999108594, timestamp: 2022-08-19 19:33:00.969541\n",
      "resetting env. episode 405, reward total was -21.0. running mean: -20.34376166911751, timestamp: 2022-08-19 19:33:03.672077\n",
      "resetting env. episode 406, reward total was -21.0. running mean: -20.350324052426334, timestamp: 2022-08-19 19:33:06.622192\n",
      "resetting env. episode 407, reward total was -21.0. running mean: -20.35682081190207, timestamp: 2022-08-19 19:33:10.184672\n",
      "resetting env. episode 408, reward total was -20.0. running mean: -20.35325260378305, timestamp: 2022-08-19 19:33:13.776067\n",
      "resetting env. episode 409, reward total was -21.0. running mean: -20.359720077745223, timestamp: 2022-08-19 19:33:16.933624\n",
      "resetting env. episode 410, reward total was -21.0. running mean: -20.366122876967772, timestamp: 2022-08-19 19:33:20.001484\n",
      "resetting env. episode 411, reward total was -21.0. running mean: -20.372461648198094, timestamp: 2022-08-19 19:33:22.963452\n",
      "resetting env. episode 412, reward total was -19.0. running mean: -20.358737031716114, timestamp: 2022-08-19 19:33:27.242377\n",
      "resetting env. episode 413, reward total was -20.0. running mean: -20.35514966139895, timestamp: 2022-08-19 19:33:30.025907\n",
      "resetting env. episode 414, reward total was -20.0. running mean: -20.35159816478496, timestamp: 2022-08-19 19:33:33.324125\n",
      "resetting env. episode 415, reward total was -21.0. running mean: -20.35808218313711, timestamp: 2022-08-19 19:33:35.824452\n",
      "resetting env. episode 416, reward total was -21.0. running mean: -20.36450136130574, timestamp: 2022-08-19 19:33:39.187454\n",
      "resetting env. episode 417, reward total was -19.0. running mean: -20.350856347692684, timestamp: 2022-08-19 19:33:42.077733\n",
      "resetting env. episode 418, reward total was -21.0. running mean: -20.357347784215758, timestamp: 2022-08-19 19:33:44.610969\n",
      "resetting env. episode 419, reward total was -19.0. running mean: -20.3437743063736, timestamp: 2022-08-19 19:33:48.351960\n",
      "resetting env. episode 420, reward total was -20.0. running mean: -20.34033656330986, timestamp: 2022-08-19 19:33:51.631218\n",
      "resetting env. episode 421, reward total was -21.0. running mean: -20.346933197676762, timestamp: 2022-08-19 19:33:53.957457\n",
      "resetting env. episode 422, reward total was -20.0. running mean: -20.343463865699995, timestamp: 2022-08-19 19:33:57.410241\n",
      "resetting env. episode 423, reward total was -21.0. running mean: -20.350029227042995, timestamp: 2022-08-19 19:34:00.123955\n",
      "resetting env. episode 424, reward total was -21.0. running mean: -20.356528934772566, timestamp: 2022-08-19 19:34:02.625270\n",
      "resetting env. episode 425, reward total was -18.0. running mean: -20.33296364542484, timestamp: 2022-08-19 19:34:06.771131\n",
      "resetting env. episode 426, reward total was -19.0. running mean: -20.319634008970592, timestamp: 2022-08-19 19:34:09.864691\n",
      "resetting env. episode 427, reward total was -19.0. running mean: -20.306437668880886, timestamp: 2022-08-19 19:34:13.084255\n",
      "resetting env. episode 428, reward total was -20.0. running mean: -20.303373292192077, timestamp: 2022-08-19 19:34:15.692250\n",
      "resetting env. episode 429, reward total was -21.0. running mean: -20.310339559270158, timestamp: 2022-08-19 19:34:18.147595\n",
      "resetting env. episode 430, reward total was -21.0. running mean: -20.317236163677457, timestamp: 2022-08-19 19:34:21.441795\n",
      "resetting env. episode 431, reward total was -21.0. running mean: -20.324063802040683, timestamp: 2022-08-19 19:34:24.353006\n",
      "resetting env. episode 432, reward total was -21.0. running mean: -20.330823164020277, timestamp: 2022-08-19 19:34:27.064760\n",
      "resetting env. episode 433, reward total was -21.0. running mean: -20.337514932380074, timestamp: 2022-08-19 19:34:29.530185\n",
      "resetting env. episode 434, reward total was -18.0. running mean: -20.314139783056273, timestamp: 2022-08-19 19:34:33.272389\n",
      "resetting env. episode 435, reward total was -20.0. running mean: -20.31099838522571, timestamp: 2022-08-19 19:34:36.253422\n",
      "resetting env. episode 436, reward total was -21.0. running mean: -20.31788840137345, timestamp: 2022-08-19 19:34:38.930296\n",
      "resetting env. episode 437, reward total was -21.0. running mean: -20.324709517359718, timestamp: 2022-08-19 19:34:42.169609\n",
      "resetting env. episode 438, reward total was -20.0. running mean: -20.32146242218612, timestamp: 2022-08-19 19:34:45.134682\n",
      "resetting env. episode 439, reward total was -21.0. running mean: -20.32824779796426, timestamp: 2022-08-19 19:34:47.992046\n",
      "resetting env. episode 440, reward total was -21.0. running mean: -20.33496531998462, timestamp: 2022-08-19 19:34:51.519973\n",
      "resetting env. episode 441, reward total was -21.0. running mean: -20.341615666784772, timestamp: 2022-08-19 19:34:55.157279\n",
      "resetting env. episode 442, reward total was -19.0. running mean: -20.328199510116924, timestamp: 2022-08-19 19:34:58.383122\n",
      "resetting env. episode 443, reward total was -21.0. running mean: -20.334917515015757, timestamp: 2022-08-19 19:35:00.918342\n",
      "resetting env. episode 444, reward total was -21.0. running mean: -20.3415683398656, timestamp: 2022-08-19 19:35:03.974172\n",
      "resetting env. episode 445, reward total was -21.0. running mean: -20.348152656466944, timestamp: 2022-08-19 19:35:06.860458\n",
      "resetting env. episode 446, reward total was -21.0. running mean: -20.354671129902275, timestamp: 2022-08-19 19:35:10.286310\n",
      "resetting env. episode 447, reward total was -20.0. running mean: -20.351124418603252, timestamp: 2022-08-19 19:35:13.471821\n",
      "resetting env. episode 448, reward total was -21.0. running mean: -20.35761317441722, timestamp: 2022-08-19 19:35:16.002022\n",
      "resetting env. episode 449, reward total was -20.0. running mean: -20.35403704267305, timestamp: 2022-08-19 19:35:19.370023\n",
      "resetting env. episode 450, reward total was -20.0. running mean: -20.35049667224632, timestamp: 2022-08-19 19:35:22.235777\n",
      "resetting env. episode 451, reward total was -20.0. running mean: -20.346991705523855, timestamp: 2022-08-19 19:35:25.013686\n",
      "resetting env. episode 452, reward total was -20.0. running mean: -20.343521788468617, timestamp: 2022-08-19 19:35:28.292919\n",
      "resetting env. episode 453, reward total was -21.0. running mean: -20.350086570583933, timestamp: 2022-08-19 19:35:30.776281\n",
      "resetting env. episode 454, reward total was -21.0. running mean: -20.356585704878093, timestamp: 2022-08-19 19:35:33.661800\n",
      "resetting env. episode 455, reward total was -19.0. running mean: -20.343019847829314, timestamp: 2022-08-19 19:35:37.214318\n",
      "resetting env. episode 456, reward total was -21.0. running mean: -20.34958964935102, timestamp: 2022-08-19 19:35:40.358900\n",
      "resetting env. episode 457, reward total was -21.0. running mean: -20.35609375285751, timestamp: 2022-08-19 19:35:44.203318\n",
      "resetting env. episode 458, reward total was -20.0. running mean: -20.352532815328935, timestamp: 2022-08-19 19:35:47.259513\n",
      "resetting env. episode 459, reward total was -21.0. running mean: -20.359007487175646, timestamp: 2022-08-19 19:35:49.875515\n",
      "resetting env. episode 460, reward total was -21.0. running mean: -20.36541741230389, timestamp: 2022-08-19 19:35:53.671366\n",
      "resetting env. episode 461, reward total was -21.0. running mean: -20.371763238180854, timestamp: 2022-08-19 19:35:56.532718\n",
      "resetting env. episode 462, reward total was -20.0. running mean: -20.368045605799043, timestamp: 2022-08-19 19:35:59.292340\n",
      "resetting env. episode 463, reward total was -19.0. running mean: -20.354365149741053, timestamp: 2022-08-19 19:36:02.658480\n",
      "resetting env. episode 464, reward total was -19.0. running mean: -20.340821498243642, timestamp: 2022-08-19 19:36:05.786132\n",
      "resetting env. episode 465, reward total was -20.0. running mean: -20.337413283261206, timestamp: 2022-08-19 19:36:09.408442\n",
      "resetting env. episode 466, reward total was -20.0. running mean: -20.334039150428595, timestamp: 2022-08-19 19:36:12.004501\n",
      "resetting env. episode 467, reward total was -20.0. running mean: -20.330698758924306, timestamp: 2022-08-19 19:36:15.057363\n",
      "resetting env. episode 468, reward total was -21.0. running mean: -20.337391771335064, timestamp: 2022-08-19 19:36:17.815965\n",
      "resetting env. episode 469, reward total was -18.0. running mean: -20.314017853621714, timestamp: 2022-08-19 19:36:21.083229\n",
      "resetting env. episode 470, reward total was -20.0. running mean: -20.310877675085496, timestamp: 2022-08-19 19:36:24.419342\n",
      "resetting env. episode 471, reward total was -20.0. running mean: -20.30776889833464, timestamp: 2022-08-19 19:36:27.429746\n",
      "resetting env. episode 472, reward total was -21.0. running mean: -20.314691209351295, timestamp: 2022-08-19 19:36:30.041762\n",
      "resetting env. episode 473, reward total was -21.0. running mean: -20.321544297257784, timestamp: 2022-08-19 19:36:33.013821\n",
      "resetting env. episode 474, reward total was -21.0. running mean: -20.328328854285207, timestamp: 2022-08-19 19:36:35.897112\n",
      "resetting env. episode 475, reward total was -20.0. running mean: -20.325045565742354, timestamp: 2022-08-19 19:36:38.873157\n",
      "resetting env. episode 476, reward total was -19.0. running mean: -20.31179511008493, timestamp: 2022-08-19 19:36:41.669683\n",
      "resetting env. episode 477, reward total was -21.0. running mean: -20.31867715898408, timestamp: 2022-08-19 19:36:44.434255\n",
      "resetting env. episode 478, reward total was -19.0. running mean: -20.30549038739424, timestamp: 2022-08-19 19:36:48.331836\n",
      "resetting env. episode 479, reward total was -21.0. running mean: -20.3124354835203, timestamp: 2022-08-19 19:36:51.117392\n",
      "resetting env. episode 480, reward total was -21.0. running mean: -20.319311128685097, timestamp: 2022-08-19 19:36:53.682535\n",
      "resetting env. episode 481, reward total was -20.0. running mean: -20.316118017398246, timestamp: 2022-08-19 19:36:56.465378\n",
      "resetting env. episode 482, reward total was -21.0. running mean: -20.322956837224265, timestamp: 2022-08-19 19:36:59.117292\n",
      "resetting env. episode 483, reward total was -20.0. running mean: -20.31972726885202, timestamp: 2022-08-19 19:37:02.069650\n",
      "resetting env. episode 484, reward total was -21.0. running mean: -20.3265299961635, timestamp: 2022-08-19 19:37:05.748817\n",
      "resetting env. episode 485, reward total was -18.0. running mean: -20.303264696201865, timestamp: 2022-08-19 19:37:09.684296\n",
      "resetting env. episode 486, reward total was -21.0. running mean: -20.310232049239847, timestamp: 2022-08-19 19:37:13.898034\n",
      "resetting env. episode 487, reward total was -20.0. running mean: -20.307129728747448, timestamp: 2022-08-19 19:37:16.658656\n",
      "resetting env. episode 488, reward total was -20.0. running mean: -20.30405843145997, timestamp: 2022-08-19 19:37:20.336438\n",
      "resetting env. episode 489, reward total was -21.0. running mean: -20.311017847145372, timestamp: 2022-08-19 19:37:24.088408\n",
      "resetting env. episode 490, reward total was -20.0. running mean: -20.307907668673916, timestamp: 2022-08-19 19:37:27.237996\n",
      "resetting env. episode 491, reward total was -21.0. running mean: -20.31482859198718, timestamp: 2022-08-19 19:37:30.835528\n",
      "resetting env. episode 492, reward total was -21.0. running mean: -20.321680306067307, timestamp: 2022-08-19 19:37:33.176271\n",
      "resetting env. episode 493, reward total was -20.0. running mean: -20.318463503006633, timestamp: 2022-08-19 19:37:36.221133\n",
      "resetting env. episode 494, reward total was -21.0. running mean: -20.325278867976568, timestamp: 2022-08-19 19:37:39.056506\n",
      "resetting env. episode 495, reward total was -21.0. running mean: -20.332026079296803, timestamp: 2022-08-19 19:37:41.542857\n",
      "resetting env. episode 496, reward total was -19.0. running mean: -20.318705818503837, timestamp: 2022-08-19 19:37:45.213112\n",
      "resetting env. episode 497, reward total was -20.0. running mean: -20.3155187603188, timestamp: 2022-08-19 19:37:48.658901\n",
      "resetting env. episode 498, reward total was -20.0. running mean: -20.31236357271561, timestamp: 2022-08-19 19:37:51.693789\n",
      "resetting env. episode 499, reward total was -20.0. running mean: -20.309239936988455, timestamp: 2022-08-19 19:37:55.060243\n",
      "resetting env. episode 500, reward total was -21.0. running mean: -20.31614753761857, timestamp: 2022-08-19 19:37:57.980429\n",
      "resetting env. episode 501, reward total was -20.0. running mean: -20.312986062242384, timestamp: 2022-08-19 19:38:01.180363\n",
      "resetting env. episode 502, reward total was -20.0. running mean: -20.309856201619958, timestamp: 2022-08-19 19:38:04.255141\n",
      "resetting env. episode 503, reward total was -21.0. running mean: -20.316757639603757, timestamp: 2022-08-19 19:38:06.751470\n",
      "resetting env. episode 504, reward total was -21.0. running mean: -20.32359006320772, timestamp: 2022-08-19 19:38:09.242810\n",
      "resetting env. episode 505, reward total was -19.0. running mean: -20.310354162575646, timestamp: 2022-08-19 19:38:13.405696\n",
      "resetting env. episode 506, reward total was -21.0. running mean: -20.31725062094989, timestamp: 2022-08-19 19:38:16.117435\n",
      "resetting env. episode 507, reward total was -21.0. running mean: -20.32407811474039, timestamp: 2022-08-19 19:38:18.931918\n",
      "resetting env. episode 508, reward total was -20.0. running mean: -20.320837333592987, timestamp: 2022-08-19 19:38:22.880359\n",
      "resetting env. episode 509, reward total was -21.0. running mean: -20.32762896025706, timestamp: 2022-08-19 19:38:25.329812\n",
      "resetting env. episode 510, reward total was -21.0. running mean: -20.33435267065449, timestamp: 2022-08-19 19:38:28.524326\n",
      "resetting env. episode 511, reward total was -21.0. running mean: -20.341009143947947, timestamp: 2022-08-19 19:38:31.408690\n",
      "resetting env. episode 512, reward total was -21.0. running mean: -20.347599052508468, timestamp: 2022-08-19 19:38:34.389704\n",
      "resetting env. episode 513, reward total was -21.0. running mean: -20.354123061983383, timestamp: 2022-08-19 19:38:38.137797\n",
      "resetting env. episode 514, reward total was -21.0. running mean: -20.36058183136355, timestamp: 2022-08-19 19:38:40.554329\n",
      "resetting env. episode 515, reward total was -21.0. running mean: -20.366976013049914, timestamp: 2022-08-19 19:38:44.626442\n",
      "resetting env. episode 516, reward total was -21.0. running mean: -20.373306252919416, timestamp: 2022-08-19 19:38:47.182610\n",
      "resetting env. episode 517, reward total was -20.0. running mean: -20.36957319039022, timestamp: 2022-08-19 19:38:50.194557\n",
      "resetting env. episode 518, reward total was -20.0. running mean: -20.365877458486317, timestamp: 2022-08-19 19:38:53.735564\n",
      "resetting env. episode 519, reward total was -21.0. running mean: -20.372218683901455, timestamp: 2022-08-19 19:38:56.449251\n",
      "resetting env. episode 520, reward total was -21.0. running mean: -20.37849649706244, timestamp: 2022-08-19 19:38:58.874769\n",
      "resetting env. episode 521, reward total was -20.0. running mean: -20.374711532091816, timestamp: 2022-08-19 19:39:02.165896\n",
      "resetting env. episode 522, reward total was -21.0. running mean: -20.380964416770897, timestamp: 2022-08-19 19:39:04.621331\n",
      "resetting env. episode 523, reward total was -21.0. running mean: -20.38715477260319, timestamp: 2022-08-19 19:39:07.771914\n",
      "resetting env. episode 524, reward total was -20.0. running mean: -20.383283224877157, timestamp: 2022-08-19 19:39:10.945428\n",
      "resetting env. episode 525, reward total was -21.0. running mean: -20.389450392628387, timestamp: 2022-08-19 19:39:14.118946\n",
      "resetting env. episode 526, reward total was -21.0. running mean: -20.395555888702102, timestamp: 2022-08-19 19:39:16.915487\n",
      "resetting env. episode 527, reward total was -19.0. running mean: -20.381600329815083, timestamp: 2022-08-19 19:39:19.848630\n",
      "resetting env. episode 528, reward total was -21.0. running mean: -20.387784326516933, timestamp: 2022-08-19 19:39:22.939367\n",
      "resetting env. episode 529, reward total was -20.0. running mean: -20.383906483251764, timestamp: 2022-08-19 19:39:25.811415\n",
      "resetting env. episode 530, reward total was -18.0. running mean: -20.360067418419245, timestamp: 2022-08-19 19:39:29.630206\n",
      "resetting env. episode 531, reward total was -20.0. running mean: -20.356466744235053, timestamp: 2022-08-19 19:39:32.765488\n",
      "resetting env. episode 532, reward total was -20.0. running mean: -20.352902076792702, timestamp: 2022-08-19 19:39:35.816315\n",
      "resetting env. episode 533, reward total was -20.0. running mean: -20.349373056024774, timestamp: 2022-08-19 19:39:38.587906\n",
      "resetting env. episode 534, reward total was -20.0. running mean: -20.345879325464526, timestamp: 2022-08-19 19:39:42.105913\n",
      "resetting env. episode 535, reward total was -20.0. running mean: -20.34242053220988, timestamp: 2022-08-19 19:39:45.291396\n",
      "resetting env. episode 536, reward total was -21.0. running mean: -20.34899632688778, timestamp: 2022-08-19 19:39:49.162047\n",
      "resetting env. episode 537, reward total was -21.0. running mean: -20.3555063636189, timestamp: 2022-08-19 19:39:52.433303\n",
      "resetting env. episode 538, reward total was -20.0. running mean: -20.351951299982712, timestamp: 2022-08-19 19:39:55.559946\n",
      "resetting env. episode 539, reward total was -21.0. running mean: -20.358431786982887, timestamp: 2022-08-19 19:39:58.062259\n",
      "resetting env. episode 540, reward total was -19.0. running mean: -20.34484746911306, timestamp: 2022-08-19 19:40:01.589839\n",
      "resetting env. episode 541, reward total was -21.0. running mean: -20.351398994421928, timestamp: 2022-08-19 19:40:04.442204\n",
      "resetting env. episode 542, reward total was -21.0. running mean: -20.35788500447771, timestamp: 2022-08-19 19:40:07.055219\n",
      "resetting env. episode 543, reward total was -19.0. running mean: -20.344306154432932, timestamp: 2022-08-19 19:40:10.477650\n",
      "resetting env. episode 544, reward total was -18.0. running mean: -20.3208630928886, timestamp: 2022-08-19 19:40:13.992258\n",
      "resetting env. episode 545, reward total was -20.0. running mean: -20.317654461959712, timestamp: 2022-08-19 19:40:17.227611\n",
      "resetting env. episode 546, reward total was -21.0. running mean: -20.324477917340115, timestamp: 2022-08-19 19:40:20.400128\n",
      "resetting env. episode 547, reward total was -19.0. running mean: -20.311233138166713, timestamp: 2022-08-19 19:40:23.570654\n",
      "resetting env. episode 548, reward total was -20.0. running mean: -20.308120806785045, timestamp: 2022-08-19 19:40:27.409395\n",
      "resetting env. episode 549, reward total was -20.0. running mean: -20.305039598717194, timestamp: 2022-08-19 19:40:30.783374\n",
      "resetting env. episode 550, reward total was -19.0. running mean: -20.291989202730022, timestamp: 2022-08-19 19:40:34.232185\n",
      "resetting env. episode 551, reward total was -20.0. running mean: -20.289069310702722, timestamp: 2022-08-19 19:40:37.523288\n",
      "resetting env. episode 552, reward total was -20.0. running mean: -20.286178617595695, timestamp: 2022-08-19 19:40:40.799511\n",
      "resetting env. episode 553, reward total was -21.0. running mean: -20.293316831419737, timestamp: 2022-08-19 19:40:44.466715\n",
      "resetting env. episode 554, reward total was -21.0. running mean: -20.300383663105542, timestamp: 2022-08-19 19:40:47.251261\n",
      "resetting env. episode 555, reward total was -21.0. running mean: -20.307379826474488, timestamp: 2022-08-19 19:40:50.237279\n",
      "resetting env. episode 556, reward total was -21.0. running mean: -20.314306028209742, timestamp: 2022-08-19 19:40:52.732610\n",
      "resetting env. episode 557, reward total was -20.0. running mean: -20.311162967927643, timestamp: 2022-08-19 19:40:56.323015\n",
      "resetting env. episode 558, reward total was -21.0. running mean: -20.318051338248367, timestamp: 2022-08-19 19:40:58.872228\n",
      "resetting env. episode 559, reward total was -21.0. running mean: -20.324870824865883, timestamp: 2022-08-19 19:41:01.702663\n",
      "resetting env. episode 560, reward total was -17.0. running mean: -20.291622116617226, timestamp: 2022-08-19 19:41:05.995781\n",
      "resetting env. episode 561, reward total was -18.0. running mean: -20.268705895451053, timestamp: 2022-08-19 19:41:09.667689\n",
      "resetting env. episode 562, reward total was -21.0. running mean: -20.276018836496544, timestamp: 2022-08-19 19:41:12.818390\n",
      "resetting env. episode 563, reward total was -20.0. running mean: -20.273258648131577, timestamp: 2022-08-19 19:41:16.170396\n",
      "resetting env. episode 564, reward total was -21.0. running mean: -20.280526061650264, timestamp: 2022-08-19 19:41:18.788405\n",
      "resetting env. episode 565, reward total was -21.0. running mean: -20.28772080103376, timestamp: 2022-08-19 19:41:22.190304\n",
      "resetting env. episode 566, reward total was -21.0. running mean: -20.294843593023423, timestamp: 2022-08-19 19:41:24.846438\n",
      "resetting env. episode 567, reward total was -21.0. running mean: -20.30189515709319, timestamp: 2022-08-19 19:41:27.877309\n",
      "resetting env. episode 568, reward total was -20.0. running mean: -20.298876205522255, timestamp: 2022-08-19 19:41:30.758608\n",
      "resetting env. episode 569, reward total was -20.0. running mean: -20.29588744346703, timestamp: 2022-08-19 19:41:34.397882\n",
      "resetting env. episode 570, reward total was -21.0. running mean: -20.30292856903236, timestamp: 2022-08-19 19:41:37.794801\n",
      "resetting env. episode 571, reward total was -19.0. running mean: -20.289899283342038, timestamp: 2022-08-19 19:41:41.021036\n",
      "resetting env. episode 572, reward total was -21.0. running mean: -20.297000290508617, timestamp: 2022-08-19 19:41:43.620089\n",
      "resetting env. episode 573, reward total was -21.0. running mean: -20.30403028760353, timestamp: 2022-08-19 19:41:46.666958\n",
      "resetting env. episode 574, reward total was -21.0. running mean: -20.310989984727495, timestamp: 2022-08-19 19:41:50.675235\n",
      "resetting env. episode 575, reward total was -19.0. running mean: -20.297880084880223, timestamp: 2022-08-19 19:41:54.072154\n",
      "resetting env. episode 576, reward total was -20.0. running mean: -20.29490128403142, timestamp: 2022-08-19 19:41:56.903583\n",
      "resetting env. episode 577, reward total was -20.0. running mean: -20.291952271191104, timestamp: 2022-08-19 19:41:59.858354\n",
      "resetting env. episode 578, reward total was -19.0. running mean: -20.279032748479192, timestamp: 2022-08-19 19:42:03.260260\n",
      "resetting env. episode 579, reward total was -21.0. running mean: -20.2862424209944, timestamp: 2022-08-19 19:42:05.921145\n",
      "resetting env. episode 580, reward total was -20.0. running mean: -20.283379996784458, timestamp: 2022-08-19 19:42:09.899514\n",
      "resetting env. episode 581, reward total was -21.0. running mean: -20.290546196816614, timestamp: 2022-08-19 19:42:13.191184\n",
      "resetting env. episode 582, reward total was -21.0. running mean: -20.297640734848446, timestamp: 2022-08-19 19:42:15.602735\n",
      "resetting env. episode 583, reward total was -21.0. running mean: -20.304664327499964, timestamp: 2022-08-19 19:42:18.115025\n",
      "resetting env. episode 584, reward total was -20.0. running mean: -20.301617684224965, timestamp: 2022-08-19 19:42:20.735016\n",
      "resetting env. episode 585, reward total was -21.0. running mean: -20.308601507382715, timestamp: 2022-08-19 19:42:23.891605\n",
      "resetting env. episode 586, reward total was -21.0. running mean: -20.31551549230889, timestamp: 2022-08-19 19:42:27.351113\n",
      "resetting env. episode 587, reward total was -21.0. running mean: -20.322360337385803, timestamp: 2022-08-19 19:42:31.095056\n",
      "resetting env. episode 588, reward total was -21.0. running mean: -20.329136734011946, timestamp: 2022-08-19 19:42:33.776876\n",
      "resetting env. episode 589, reward total was -21.0. running mean: -20.335845366671826, timestamp: 2022-08-19 19:42:37.081045\n",
      "resetting env. episode 590, reward total was -20.0. running mean: -20.332486913005106, timestamp: 2022-08-19 19:42:40.609604\n",
      "resetting env. episode 591, reward total was -20.0. running mean: -20.329162043875055, timestamp: 2022-08-19 19:42:44.175294\n",
      "resetting env. episode 592, reward total was -20.0. running mean: -20.325870423436303, timestamp: 2022-08-19 19:42:46.863110\n",
      "resetting env. episode 593, reward total was -20.0. running mean: -20.322611719201937, timestamp: 2022-08-19 19:42:49.587828\n",
      "resetting env. episode 594, reward total was -20.0. running mean: -20.319385602009916, timestamp: 2022-08-19 19:42:52.906967\n",
      "resetting env. episode 595, reward total was -19.0. running mean: -20.306191745989818, timestamp: 2022-08-19 19:42:55.733430\n",
      "resetting env. episode 596, reward total was -20.0. running mean: -20.30312982852992, timestamp: 2022-08-19 19:42:58.252695\n",
      "resetting env. episode 597, reward total was -20.0. running mean: -20.300098530244618, timestamp: 2022-08-19 19:43:01.228713\n",
      "resetting env. episode 598, reward total was -20.0. running mean: -20.297097544942172, timestamp: 2022-08-19 19:43:03.742990\n",
      "resetting env. episode 599, reward total was -21.0. running mean: -20.30412656949275, timestamp: 2022-08-19 19:43:06.941445\n",
      "resetting env. episode 600, reward total was -21.0. running mean: -20.311085303797825, timestamp: 2022-08-19 19:43:10.749268\n",
      "resetting env. episode 601, reward total was -21.0. running mean: -20.31797445075985, timestamp: 2022-08-19 19:43:13.485964\n",
      "resetting env. episode 602, reward total was -21.0. running mean: -20.324794706252252, timestamp: 2022-08-19 19:43:16.685410\n",
      "resetting env. episode 603, reward total was -21.0. running mean: -20.33154675918973, timestamp: 2022-08-19 19:43:19.209290\n",
      "resetting env. episode 604, reward total was -21.0. running mean: -20.338231291597836, timestamp: 2022-08-19 19:43:21.515125\n",
      "resetting env. episode 605, reward total was -21.0. running mean: -20.34484897868186, timestamp: 2022-08-19 19:43:24.381462\n",
      "resetting env. episode 606, reward total was -20.0. running mean: -20.34140048889504, timestamp: 2022-08-19 19:43:28.572307\n",
      "resetting env. episode 607, reward total was -21.0. running mean: -20.34798648400609, timestamp: 2022-08-19 19:43:31.619177\n",
      "resetting env. episode 608, reward total was -20.0. running mean: -20.344506619166026, timestamp: 2022-08-19 19:43:34.635100\n",
      "resetting env. episode 609, reward total was -21.0. running mean: -20.351061552974368, timestamp: 2022-08-19 19:43:37.767229\n",
      "resetting env. episode 610, reward total was -16.0. running mean: -20.307550937444624, timestamp: 2022-08-19 19:43:42.026842\n",
      "resetting env. episode 611, reward total was -21.0. running mean: -20.31447542807018, timestamp: 2022-08-19 19:43:45.261206\n",
      "resetting env. episode 612, reward total was -21.0. running mean: -20.321330673789475, timestamp: 2022-08-19 19:43:48.207425\n",
      "resetting env. episode 613, reward total was -21.0. running mean: -20.328117367051583, timestamp: 2022-08-19 19:43:50.997614\n",
      "resetting env. episode 614, reward total was -21.0. running mean: -20.33483619338107, timestamp: 2022-08-19 19:43:53.619107\n",
      "resetting env. episode 615, reward total was -20.0. running mean: -20.33148783144726, timestamp: 2022-08-19 19:43:56.449545\n",
      "resetting env. episode 616, reward total was -21.0. running mean: -20.338172953132787, timestamp: 2022-08-19 19:43:59.550254\n",
      "resetting env. episode 617, reward total was -19.0. running mean: -20.32479122360146, timestamp: 2022-08-19 19:44:02.804562\n",
      "resetting env. episode 618, reward total was -20.0. running mean: -20.321543311365442, timestamp: 2022-08-19 19:44:06.666231\n",
      "resetting env. episode 619, reward total was -20.0. running mean: -20.318327878251786, timestamp: 2022-08-19 19:44:09.359038\n",
      "resetting env. episode 620, reward total was -20.0. running mean: -20.315144599469267, timestamp: 2022-08-19 19:44:12.107489\n",
      "resetting env. episode 621, reward total was -19.0. running mean: -20.301993153474577, timestamp: 2022-08-19 19:44:15.297410\n",
      "resetting env. episode 622, reward total was -21.0. running mean: -20.30897322193983, timestamp: 2022-08-19 19:44:18.693362\n",
      "resetting env. episode 623, reward total was -21.0. running mean: -20.31588348972043, timestamp: 2022-08-19 19:44:21.524762\n",
      "resetting env. episode 624, reward total was -20.0. running mean: -20.312724654823224, timestamp: 2022-08-19 19:44:24.150741\n",
      "resetting env. episode 625, reward total was -21.0. running mean: -20.319597408274994, timestamp: 2022-08-19 19:44:27.258437\n",
      "resetting env. episode 626, reward total was -21.0. running mean: -20.326401434192245, timestamp: 2022-08-19 19:44:30.262412\n",
      "resetting env. episode 627, reward total was -20.0. running mean: -20.323137419850323, timestamp: 2022-08-19 19:44:33.336188\n",
      "resetting env. episode 628, reward total was -21.0. running mean: -20.32990604565182, timestamp: 2022-08-19 19:44:36.823876\n",
      "resetting env. episode 629, reward total was -18.0. running mean: -20.3066069851953, timestamp: 2022-08-19 19:44:39.882694\n",
      "resetting env. episode 630, reward total was -20.0. running mean: -20.303540915343348, timestamp: 2022-08-19 19:44:42.815878\n",
      "resetting env. episode 631, reward total was -20.0. running mean: -20.300505506189914, timestamp: 2022-08-19 19:44:46.278784\n",
      "resetting env. episode 632, reward total was -21.0. running mean: -20.307500451128014, timestamp: 2022-08-19 19:44:49.562002\n",
      "resetting env. episode 633, reward total was -19.0. running mean: -20.294425446616735, timestamp: 2022-08-19 19:44:53.836821\n",
      "resetting env. episode 634, reward total was -21.0. running mean: -20.30148119215057, timestamp: 2022-08-19 19:44:56.648305\n",
      "resetting env. episode 635, reward total was -20.0. running mean: -20.298466380229062, timestamp: 2022-08-19 19:44:59.478740\n",
      "resetting env. episode 636, reward total was -17.0. running mean: -20.265481716426773, timestamp: 2022-08-19 19:45:02.557512\n",
      "resetting env. episode 637, reward total was -19.0. running mean: -20.252826899262505, timestamp: 2022-08-19 19:45:06.099043\n",
      "resetting env. episode 638, reward total was -21.0. running mean: -20.26029863026988, timestamp: 2022-08-19 19:45:08.576424\n",
      "resetting env. episode 639, reward total was -20.0. running mean: -20.25769564396718, timestamp: 2022-08-19 19:45:11.078744\n",
      "resetting env. episode 640, reward total was -19.0. running mean: -20.24511868752751, timestamp: 2022-08-19 19:45:14.856856\n",
      "resetting env. episode 641, reward total was -21.0. running mean: -20.252667500652233, timestamp: 2022-08-19 19:45:17.167671\n",
      "resetting env. episode 642, reward total was -20.0. running mean: -20.25014082564571, timestamp: 2022-08-19 19:45:20.374098\n",
      "resetting env. episode 643, reward total was -21.0. running mean: -20.257639417389253, timestamp: 2022-08-19 19:45:23.988437\n",
      "resetting env. episode 644, reward total was -21.0. running mean: -20.26506302321536, timestamp: 2022-08-19 19:45:27.057236\n",
      "resetting env. episode 645, reward total was -21.0. running mean: -20.27241239298321, timestamp: 2022-08-19 19:45:29.580491\n",
      "resetting env. episode 646, reward total was -20.0. running mean: -20.269688269053376, timestamp: 2022-08-19 19:45:32.809859\n",
      "resetting env. episode 647, reward total was -21.0. running mean: -20.27699138636284, timestamp: 2022-08-19 19:45:35.645278\n",
      "resetting env. episode 648, reward total was -20.0. running mean: -20.27422147249921, timestamp: 2022-08-19 19:45:38.660222\n",
      "resetting env. episode 649, reward total was -19.0. running mean: -20.26147925777422, timestamp: 2022-08-19 19:45:42.633598\n",
      "resetting env. episode 650, reward total was -21.0. running mean: -20.26886446519648, timestamp: 2022-08-19 19:45:45.103997\n",
      "resetting env. episode 651, reward total was -21.0. running mean: -20.276175820544516, timestamp: 2022-08-19 19:45:48.219735\n",
      "resetting env. episode 652, reward total was -21.0. running mean: -20.283414062339073, timestamp: 2022-08-19 19:45:51.302433\n",
      "resetting env. episode 653, reward total was -20.0. running mean: -20.28057992171568, timestamp: 2022-08-19 19:45:53.972296\n",
      "resetting env. episode 654, reward total was -21.0. running mean: -20.287774122498526, timestamp: 2022-08-19 19:45:57.163762\n",
      "resetting env. episode 655, reward total was -21.0. running mean: -20.294896381273542, timestamp: 2022-08-19 19:46:00.122854\n",
      "resetting env. episode 656, reward total was -19.0. running mean: -20.281947417460806, timestamp: 2022-08-19 19:46:03.505810\n",
      "resetting env. episode 657, reward total was -20.0. running mean: -20.2791279432862, timestamp: 2022-08-19 19:46:06.959950\n",
      "resetting env. episode 658, reward total was -21.0. running mean: -20.286336663853337, timestamp: 2022-08-19 19:46:10.489518\n",
      "resetting env. episode 659, reward total was -21.0. running mean: -20.293473297214803, timestamp: 2022-08-19 19:46:13.420380\n",
      "resetting env. episode 660, reward total was -20.0. running mean: -20.290538564242652, timestamp: 2022-08-19 19:46:18.099861\n",
      "resetting env. episode 661, reward total was -21.0. running mean: -20.297633178600226, timestamp: 2022-08-19 19:46:21.174913\n",
      "resetting env. episode 662, reward total was -21.0. running mean: -20.304656846814225, timestamp: 2022-08-19 19:46:23.546506\n",
      "resetting env. episode 663, reward total was -21.0. running mean: -20.311610278346084, timestamp: 2022-08-19 19:46:27.042163\n",
      "resetting env. episode 664, reward total was -21.0. running mean: -20.318494175562623, timestamp: 2022-08-19 19:46:29.971343\n",
      "resetting env. episode 665, reward total was -21.0. running mean: -20.325309233806998, timestamp: 2022-08-19 19:46:32.314116\n",
      "resetting env. episode 666, reward total was -21.0. running mean: -20.33205614146893, timestamp: 2022-08-19 19:46:35.265194\n",
      "resetting env. episode 667, reward total was -19.0. running mean: -20.31873558005424, timestamp: 2022-08-19 19:46:39.017168\n",
      "resetting env. episode 668, reward total was -21.0. running mean: -20.325548224253698, timestamp: 2022-08-19 19:46:42.248531\n",
      "resetting env. episode 669, reward total was -21.0. running mean: -20.332292742011163, timestamp: 2022-08-19 19:46:45.310344\n",
      "resetting env. episode 670, reward total was -21.0. running mean: -20.338969814591053, timestamp: 2022-08-19 19:46:48.017112\n",
      "resetting env. episode 671, reward total was -21.0. running mean: -20.34558011644514, timestamp: 2022-08-19 19:46:50.944283\n",
      "resetting env. episode 672, reward total was -21.0. running mean: -20.35212431528069, timestamp: 2022-08-19 19:46:53.524388\n",
      "resetting env. episode 673, reward total was -21.0. running mean: -20.358603072127885, timestamp: 2022-08-19 19:46:55.989809\n",
      "resetting env. episode 674, reward total was -21.0. running mean: -20.365017041406606, timestamp: 2022-08-19 19:46:59.080057\n",
      "resetting env. episode 675, reward total was -21.0. running mean: -20.371366870992542, timestamp: 2022-08-19 19:47:02.049120\n",
      "resetting env. episode 676, reward total was -21.0. running mean: -20.377653202282616, timestamp: 2022-08-19 19:47:04.559410\n",
      "resetting env. episode 677, reward total was -20.0. running mean: -20.37387667025979, timestamp: 2022-08-19 19:47:07.998090\n",
      "resetting env. episode 678, reward total was -21.0. running mean: -20.38013790355719, timestamp: 2022-08-19 19:47:11.231448\n",
      "resetting env. episode 679, reward total was -19.0. running mean: -20.36633652452162, timestamp: 2022-08-19 19:47:15.245718\n",
      "resetting env. episode 680, reward total was -21.0. running mean: -20.372673159276406, timestamp: 2022-08-19 19:47:18.077151\n",
      "resetting env. episode 681, reward total was -21.0. running mean: -20.378946427683644, timestamp: 2022-08-19 19:47:21.078139\n",
      "resetting env. episode 682, reward total was -20.0. running mean: -20.375156963406805, timestamp: 2022-08-19 19:47:23.629305\n",
      "resetting env. episode 683, reward total was -21.0. running mean: -20.381405393772738, timestamp: 2022-08-19 19:47:26.212400\n",
      "resetting env. episode 684, reward total was -21.0. running mean: -20.387591339835012, timestamp: 2022-08-19 19:47:29.483691\n",
      "resetting env. episode 685, reward total was -21.0. running mean: -20.393715426436664, timestamp: 2022-08-19 19:47:33.382290\n",
      "resetting env. episode 686, reward total was -21.0. running mean: -20.3997782721723, timestamp: 2022-08-19 19:47:35.941957\n",
      "resetting env. episode 687, reward total was -19.0. running mean: -20.38578048945058, timestamp: 2022-08-19 19:47:39.653039\n",
      "resetting env. episode 688, reward total was -20.0. running mean: -20.38192268455607, timestamp: 2022-08-19 19:47:42.818577\n",
      "resetting env. episode 689, reward total was -20.0. running mean: -20.37810345771051, timestamp: 2022-08-19 19:47:45.627904\n",
      "resetting env. episode 690, reward total was -19.0. running mean: -20.364322423133405, timestamp: 2022-08-19 19:47:49.526482\n",
      "resetting env. episode 691, reward total was -21.0. running mean: -20.37067919890207, timestamp: 2022-08-19 19:47:52.113125\n",
      "resetting env. episode 692, reward total was -19.0. running mean: -20.35697240691305, timestamp: 2022-08-19 19:47:55.255725\n",
      "resetting env. episode 693, reward total was -21.0. running mean: -20.363402682843923, timestamp: 2022-08-19 19:47:58.339481\n",
      "resetting env. episode 694, reward total was -21.0. running mean: -20.369768656015484, timestamp: 2022-08-19 19:48:01.325117\n",
      "resetting env. episode 695, reward total was -20.0. running mean: -20.36607096945533, timestamp: 2022-08-19 19:48:04.025892\n",
      "resetting env. episode 696, reward total was -20.0. running mean: -20.362410259760775, timestamp: 2022-08-19 19:48:06.830395\n",
      "resetting env. episode 697, reward total was -21.0. running mean: -20.368786157163168, timestamp: 2022-08-19 19:48:09.642877\n",
      "resetting env. episode 698, reward total was -20.0. running mean: -20.365098295591537, timestamp: 2022-08-19 19:48:12.981952\n",
      "resetting env. episode 699, reward total was -21.0. running mean: -20.37144731263562, timestamp: 2022-08-19 19:48:15.192084\n",
      "resetting env. episode 700, reward total was -21.0. running mean: -20.377732839509264, timestamp: 2022-08-19 19:48:18.602927\n",
      "resetting env. episode 701, reward total was -20.0. running mean: -20.373955511114172, timestamp: 2022-08-19 19:48:22.715295\n",
      "resetting env. episode 702, reward total was -20.0. running mean: -20.37021595600303, timestamp: 2022-08-19 19:48:25.536504\n",
      "resetting env. episode 703, reward total was -21.0. running mean: -20.376513796443, timestamp: 2022-08-19 19:48:27.848325\n",
      "resetting env. episode 704, reward total was -21.0. running mean: -20.38274865847857, timestamp: 2022-08-19 19:48:30.290794\n",
      "resetting env. episode 705, reward total was -20.0. running mean: -20.378921171893783, timestamp: 2022-08-19 19:48:33.265731\n",
      "resetting env. episode 706, reward total was -20.0. running mean: -20.375131960174844, timestamp: 2022-08-19 19:48:37.130398\n",
      "resetting env. episode 707, reward total was -20.0. running mean: -20.371380640573094, timestamp: 2022-08-19 19:48:40.794605\n",
      "resetting env. episode 708, reward total was -20.0. running mean: -20.367666834167363, timestamp: 2022-08-19 19:48:43.519114\n",
      "resetting env. episode 709, reward total was -20.0. running mean: -20.363990165825687, timestamp: 2022-08-19 19:48:47.638024\n",
      "resetting env. episode 710, reward total was -19.0. running mean: -20.35035026416743, timestamp: 2022-08-19 19:48:51.100760\n",
      "resetting env. episode 711, reward total was -21.0. running mean: -20.35684676152576, timestamp: 2022-08-19 19:48:53.495360\n",
      "resetting env. episode 712, reward total was -21.0. running mean: -20.3632782939105, timestamp: 2022-08-19 19:48:56.097405\n",
      "resetting env. episode 713, reward total was -21.0. running mean: -20.369645510971395, timestamp: 2022-08-19 19:48:59.275908\n",
      "resetting env. episode 714, reward total was -20.0. running mean: -20.36594905586168, timestamp: 2022-08-19 19:49:02.300822\n",
      "resetting env. episode 715, reward total was -21.0. running mean: -20.372289565303063, timestamp: 2022-08-19 19:49:05.341694\n",
      "resetting env. episode 716, reward total was -20.0. running mean: -20.368566669650033, timestamp: 2022-08-19 19:49:08.537154\n",
      "resetting env. episode 717, reward total was -21.0. running mean: -20.374881002953533, timestamp: 2022-08-19 19:49:11.319715\n",
      "resetting env. episode 718, reward total was -21.0. running mean: -20.381132192924, timestamp: 2022-08-19 19:49:13.650488\n",
      "resetting env. episode 719, reward total was -21.0. running mean: -20.38732087099476, timestamp: 2022-08-19 19:49:15.944361\n",
      "resetting env. episode 720, reward total was -19.0. running mean: -20.373447662284814, timestamp: 2022-08-19 19:49:19.423057\n",
      "resetting env. episode 721, reward total was -19.0. running mean: -20.359713185661967, timestamp: 2022-08-19 19:49:22.826791\n",
      "resetting env. episode 722, reward total was -20.0. running mean: -20.356116053805348, timestamp: 2022-08-19 19:49:26.181912\n",
      "resetting env. episode 723, reward total was -21.0. running mean: -20.362554893267294, timestamp: 2022-08-19 19:49:29.882413\n",
      "resetting env. episode 724, reward total was -19.0. running mean: -20.34892934433462, timestamp: 2022-08-19 19:49:33.227471\n",
      "resetting env. episode 725, reward total was -21.0. running mean: -20.355440050891275, timestamp: 2022-08-19 19:49:36.526653\n",
      "resetting env. episode 726, reward total was -21.0. running mean: -20.361885650382362, timestamp: 2022-08-19 19:49:38.781627\n",
      "resetting env. episode 727, reward total was -21.0. running mean: -20.36826679387854, timestamp: 2022-08-19 19:49:41.231081\n",
      "resetting env. episode 728, reward total was -21.0. running mean: -20.374584125939755, timestamp: 2022-08-19 19:49:43.702472\n",
      "resetting env. episode 729, reward total was -19.0. running mean: -20.36083828468036, timestamp: 2022-08-19 19:49:46.561830\n",
      "resetting env. episode 730, reward total was -20.0. running mean: -20.357229901833556, timestamp: 2022-08-19 19:49:49.381327\n",
      "resetting env. episode 731, reward total was -21.0. running mean: -20.36365760281522, timestamp: 2022-08-19 19:49:52.525619\n",
      "resetting env. episode 732, reward total was -21.0. running mean: -20.370021026787068, timestamp: 2022-08-19 19:49:55.109474\n",
      "resetting env. episode 733, reward total was -20.0. running mean: -20.366320816519195, timestamp: 2022-08-19 19:49:57.894096\n",
      "resetting env. episode 734, reward total was -20.0. running mean: -20.362657608354002, timestamp: 2022-08-19 19:50:00.791288\n",
      "resetting env. episode 735, reward total was -19.0. running mean: -20.349031032270464, timestamp: 2022-08-19 19:50:04.514347\n",
      "resetting env. episode 736, reward total was -21.0. running mean: -20.355540721947758, timestamp: 2022-08-19 19:50:07.315973\n",
      "resetting env. episode 737, reward total was -21.0. running mean: -20.36198531472828, timestamp: 2022-08-19 19:50:10.068908\n",
      "resetting env. episode 738, reward total was -21.0. running mean: -20.368365461580996, timestamp: 2022-08-19 19:50:13.063903\n",
      "resetting env. episode 739, reward total was -21.0. running mean: -20.37468180696519, timestamp: 2022-08-19 19:50:16.394999\n",
      "resetting env. episode 740, reward total was -19.0. running mean: -20.360934988895536, timestamp: 2022-08-19 19:50:20.634700\n",
      "resetting env. episode 741, reward total was -19.0. running mean: -20.34732563900658, timestamp: 2022-08-19 19:50:23.911681\n",
      "resetting env. episode 742, reward total was -21.0. running mean: -20.353852382616516, timestamp: 2022-08-19 19:50:26.357182\n",
      "resetting env. episode 743, reward total was -21.0. running mean: -20.360313858790352, timestamp: 2022-08-19 19:50:28.755826\n",
      "resetting env. episode 744, reward total was -21.0. running mean: -20.366710720202448, timestamp: 2022-08-19 19:50:31.376821\n",
      "resetting env. episode 745, reward total was -21.0. running mean: -20.373043613000423, timestamp: 2022-08-19 19:50:33.959900\n",
      "resetting env. episode 746, reward total was -20.0. running mean: -20.369313176870417, timestamp: 2022-08-19 19:50:36.927024\n",
      "resetting env. episode 747, reward total was -20.0. running mean: -20.36562004510171, timestamp: 2022-08-19 19:50:39.923016\n",
      "resetting env. episode 748, reward total was -21.0. running mean: -20.371963844650693, timestamp: 2022-08-19 19:50:42.623829\n",
      "resetting env. episode 749, reward total was -20.0. running mean: -20.368244206204185, timestamp: 2022-08-19 19:50:47.145586\n",
      "resetting env. episode 750, reward total was -21.0. running mean: -20.374561764142143, timestamp: 2022-08-19 19:50:51.266278\n",
      "resetting env. episode 751, reward total was -21.0. running mean: -20.380816146500724, timestamp: 2022-08-19 19:50:54.667188\n",
      "resetting env. episode 752, reward total was -20.0. running mean: -20.377007985035714, timestamp: 2022-08-19 19:50:57.642052\n",
      "resetting env. episode 753, reward total was -19.0. running mean: -20.363237905185358, timestamp: 2022-08-19 19:51:01.312242\n",
      "resetting env. episode 754, reward total was -20.0. running mean: -20.359605526133503, timestamp: 2022-08-19 19:51:04.195534\n",
      "resetting env. episode 755, reward total was -21.0. running mean: -20.366009470872168, timestamp: 2022-08-19 19:51:06.871173\n",
      "resetting env. episode 756, reward total was -21.0. running mean: -20.37234937616345, timestamp: 2022-08-19 19:51:09.661727\n",
      "resetting env. episode 757, reward total was -19.0. running mean: -20.358625882401814, timestamp: 2022-08-19 19:51:12.966324\n",
      "resetting env. episode 758, reward total was -20.0. running mean: -20.355039623577795, timestamp: 2022-08-19 19:51:16.437047\n",
      "resetting env. episode 759, reward total was -19.0. running mean: -20.34148922734202, timestamp: 2022-08-19 19:51:20.044169\n",
      "resetting env. episode 760, reward total was -20.0. running mean: -20.338074335068598, timestamp: 2022-08-19 19:51:23.608675\n",
      "resetting env. episode 761, reward total was -21.0. running mean: -20.344693591717913, timestamp: 2022-08-19 19:51:26.442361\n",
      "resetting env. episode 762, reward total was -21.0. running mean: -20.351246655800736, timestamp: 2022-08-19 19:51:29.323528\n",
      "resetting env. episode 763, reward total was -20.0. running mean: -20.34773418924273, timestamp: 2022-08-19 19:51:32.622736\n",
      "resetting env. episode 764, reward total was -21.0. running mean: -20.354256847350303, timestamp: 2022-08-19 19:51:35.361386\n",
      "resetting env. episode 765, reward total was -21.0. running mean: -20.360714278876802, timestamp: 2022-08-19 19:51:38.439159\n",
      "resetting env. episode 766, reward total was -21.0. running mean: -20.367107136088034, timestamp: 2022-08-19 19:51:41.371530\n",
      "resetting env. episode 767, reward total was -17.0. running mean: -20.333436064727156, timestamp: 2022-08-19 19:51:45.131083\n",
      "resetting env. episode 768, reward total was -20.0. running mean: -20.330101704079883, timestamp: 2022-08-19 19:51:48.050281\n",
      "resetting env. episode 769, reward total was -21.0. running mean: -20.336800687039084, timestamp: 2022-08-19 19:51:50.733110\n",
      "resetting env. episode 770, reward total was -21.0. running mean: -20.343432680168693, timestamp: 2022-08-19 19:51:53.575525\n",
      "resetting env. episode 771, reward total was -20.0. running mean: -20.339998353367005, timestamp: 2022-08-19 19:51:58.091715\n",
      "resetting env. episode 772, reward total was -18.0. running mean: -20.316598369833333, timestamp: 2022-08-19 19:52:01.737968\n",
      "resetting env. episode 773, reward total was -19.0. running mean: -20.303432386135, timestamp: 2022-08-19 19:52:06.008690\n",
      "resetting env. episode 774, reward total was -20.0. running mean: -20.30039806227365, timestamp: 2022-08-19 19:52:08.727430\n",
      "resetting env. episode 775, reward total was -19.0. running mean: -20.287394081650916, timestamp: 2022-08-19 19:52:11.704462\n",
      "resetting env. episode 776, reward total was -21.0. running mean: -20.294520140834408, timestamp: 2022-08-19 19:52:14.128177\n",
      "resetting env. episode 777, reward total was -19.0. running mean: -20.281574939426065, timestamp: 2022-08-19 19:52:17.371505\n",
      "resetting env. episode 778, reward total was -20.0. running mean: -20.278759190031803, timestamp: 2022-08-19 19:52:20.508120\n",
      "resetting env. episode 779, reward total was -20.0. running mean: -20.275971598131484, timestamp: 2022-08-19 19:52:23.186961\n",
      "resetting env. episode 780, reward total was -21.0. running mean: -20.28321188215017, timestamp: 2022-08-19 19:52:25.586545\n",
      "resetting env. episode 781, reward total was -21.0. running mean: -20.29037976332867, timestamp: 2022-08-19 19:52:28.335348\n",
      "resetting env. episode 782, reward total was -20.0. running mean: -20.287475965695382, timestamp: 2022-08-19 19:52:31.217646\n",
      "resetting env. episode 783, reward total was -21.0. running mean: -20.29460120603843, timestamp: 2022-08-19 19:52:33.800739\n",
      "resetting env. episode 784, reward total was -20.0. running mean: -20.291655193978045, timestamp: 2022-08-19 19:52:36.925387\n",
      "resetting env. episode 785, reward total was -21.0. running mean: -20.298738642038266, timestamp: 2022-08-19 19:52:40.304358\n",
      "resetting env. episode 786, reward total was -21.0. running mean: -20.305751255617885, timestamp: 2022-08-19 19:52:43.599562\n",
      "resetting env. episode 787, reward total was -21.0. running mean: -20.312693743061708, timestamp: 2022-08-19 19:52:46.319277\n",
      "resetting env. episode 788, reward total was -21.0. running mean: -20.31956680563109, timestamp: 2022-08-19 19:52:48.665026\n",
      "resetting env. episode 789, reward total was -21.0. running mean: -20.32637113757478, timestamp: 2022-08-19 19:52:51.548721\n",
      "resetting env. episode 790, reward total was -20.0. running mean: -20.323107426199034, timestamp: 2022-08-19 19:52:54.801055\n",
      "resetting env. episode 791, reward total was -21.0. running mean: -20.329876351937045, timestamp: 2022-08-19 19:52:57.704081\n",
      "resetting env. episode 792, reward total was -20.0. running mean: -20.326577588417674, timestamp: 2022-08-19 19:53:00.330063\n",
      "resetting env. episode 793, reward total was -20.0. running mean: -20.323311812533497, timestamp: 2022-08-19 19:53:03.319073\n",
      "resetting env. episode 794, reward total was -18.0. running mean: -20.30007869440816, timestamp: 2022-08-19 19:53:06.781833\n",
      "resetting env. episode 795, reward total was -20.0. running mean: -20.29707790746408, timestamp: 2022-08-19 19:53:10.103864\n",
      "resetting env. episode 796, reward total was -20.0. running mean: -20.294107128389438, timestamp: 2022-08-19 19:53:13.098860\n",
      "resetting env. episode 797, reward total was -21.0. running mean: -20.301166057105544, timestamp: 2022-08-19 19:53:16.467852\n",
      "resetting env. episode 798, reward total was -20.0. running mean: -20.29815439653449, timestamp: 2022-08-19 19:53:20.433705\n",
      "resetting env. episode 799, reward total was -20.0. running mean: -20.29517285256914, timestamp: 2022-08-19 19:53:23.421717\n",
      "resetting env. episode 800, reward total was -19.0. running mean: -20.282221124043453, timestamp: 2022-08-19 19:53:26.984227\n",
      "resetting env. episode 801, reward total was -20.0. running mean: -20.279398912803018, timestamp: 2022-08-19 19:53:30.640379\n",
      "resetting env. episode 802, reward total was -20.0. running mean: -20.276604923674988, timestamp: 2022-08-19 19:53:33.484774\n",
      "resetting env. episode 803, reward total was -21.0. running mean: -20.28383887443824, timestamp: 2022-08-19 19:53:36.595460\n",
      "resetting env. episode 804, reward total was -21.0. running mean: -20.291000485693857, timestamp: 2022-08-19 19:53:39.964455\n",
      "resetting env. episode 805, reward total was -21.0. running mean: -20.29809048083692, timestamp: 2022-08-19 19:53:42.865673\n",
      "resetting env. episode 806, reward total was -20.0. running mean: -20.295109576028548, timestamp: 2022-08-19 19:53:46.010667\n",
      "resetting env. episode 807, reward total was -19.0. running mean: -20.28215848026826, timestamp: 2022-08-19 19:53:49.954122\n",
      "resetting env. episode 808, reward total was -19.0. running mean: -20.26933689546558, timestamp: 2022-08-19 19:53:52.816151\n",
      "resetting env. episode 809, reward total was -21.0. running mean: -20.276643526510927, timestamp: 2022-08-19 19:53:55.333423\n",
      "resetting env. episode 810, reward total was -20.0. running mean: -20.27387709124582, timestamp: 2022-08-19 19:53:58.211729\n",
      "resetting env. episode 811, reward total was -21.0. running mean: -20.281138320333362, timestamp: 2022-08-19 19:54:01.084298\n",
      "resetting env. episode 812, reward total was -21.0. running mean: -20.28832693713003, timestamp: 2022-08-19 19:54:03.982096\n",
      "resetting env. episode 813, reward total was -20.0. running mean: -20.285443667758727, timestamp: 2022-08-19 19:54:07.564986\n",
      "resetting env. episode 814, reward total was -21.0. running mean: -20.29258923108114, timestamp: 2022-08-19 19:54:09.798018\n",
      "resetting env. episode 815, reward total was -20.0. running mean: -20.28966333877033, timestamp: 2022-08-19 19:54:12.245455\n",
      "resetting env. episode 816, reward total was -18.0. running mean: -20.266766705382626, timestamp: 2022-08-19 19:54:15.885237\n",
      "resetting env. episode 817, reward total was -20.0. running mean: -20.264099038328798, timestamp: 2022-08-19 19:54:18.597215\n",
      "resetting env. episode 818, reward total was -21.0. running mean: -20.27145804794551, timestamp: 2022-08-19 19:54:22.560621\n",
      "resetting env. episode 819, reward total was -20.0. running mean: -20.268743467466056, timestamp: 2022-08-19 19:54:27.541324\n",
      "resetting env. episode 820, reward total was -21.0. running mean: -20.276056032791395, timestamp: 2022-08-19 19:54:29.865759\n",
      "resetting env. episode 821, reward total was -21.0. running mean: -20.283295472463482, timestamp: 2022-08-19 19:54:32.495014\n",
      "resetting env. episode 822, reward total was -19.0. running mean: -20.27046251773885, timestamp: 2022-08-19 19:54:35.230128\n",
      "resetting env. episode 823, reward total was -21.0. running mean: -20.27775789256146, timestamp: 2022-08-19 19:54:37.757373\n",
      "resetting env. episode 824, reward total was -19.0. running mean: -20.264980313635846, timestamp: 2022-08-19 19:54:41.233081\n",
      "resetting env. episode 825, reward total was -19.0. running mean: -20.252330510499487, timestamp: 2022-08-19 19:54:45.067553\n",
      "resetting env. episode 826, reward total was -21.0. running mean: -20.25980720539449, timestamp: 2022-08-19 19:54:49.430887\n",
      "resetting env. episode 827, reward total was -21.0. running mean: -20.267209133340547, timestamp: 2022-08-19 19:54:51.685557\n",
      "resetting env. episode 828, reward total was -20.0. running mean: -20.26453704200714, timestamp: 2022-08-19 19:54:55.272967\n",
      "resetting env. episode 829, reward total was -21.0. running mean: -20.27189167158707, timestamp: 2022-08-19 19:54:57.723502\n",
      "resetting env. episode 830, reward total was -19.0. running mean: -20.2591727548712, timestamp: 2022-08-19 19:55:00.302036\n",
      "resetting env. episode 831, reward total was -20.0. running mean: -20.25658102732249, timestamp: 2022-08-19 19:55:03.106407\n",
      "resetting env. episode 832, reward total was -19.0. running mean: -20.244015217049267, timestamp: 2022-08-19 19:55:06.486497\n",
      "resetting env. episode 833, reward total was -21.0. running mean: -20.251575064878775, timestamp: 2022-08-19 19:55:08.844493\n",
      "resetting env. episode 834, reward total was -20.0. running mean: -20.249059314229985, timestamp: 2022-08-19 19:55:12.595998\n",
      "resetting env. episode 835, reward total was -21.0. running mean: -20.256568721087685, timestamp: 2022-08-19 19:55:14.519480\n",
      "resetting env. episode 836, reward total was -20.0. running mean: -20.254003033876806, timestamp: 2022-08-19 19:55:16.811562\n",
      "resetting env. episode 837, reward total was -21.0. running mean: -20.26146300353804, timestamp: 2022-08-19 19:55:20.130413\n",
      "resetting env. episode 838, reward total was -21.0. running mean: -20.26884837350266, timestamp: 2022-08-19 19:55:22.629451\n",
      "resetting env. episode 839, reward total was -20.0. running mean: -20.266159889767632, timestamp: 2022-08-19 19:55:25.821762\n",
      "resetting env. episode 840, reward total was -19.0. running mean: -20.253498290869956, timestamp: 2022-08-19 19:55:28.836867\n",
      "resetting env. episode 841, reward total was -19.0. running mean: -20.24096330796126, timestamp: 2022-08-19 19:55:31.933026\n",
      "resetting env. episode 842, reward total was -20.0. running mean: -20.238553674881647, timestamp: 2022-08-19 19:55:35.149618\n",
      "resetting env. episode 843, reward total was -21.0. running mean: -20.24616813813283, timestamp: 2022-08-19 19:55:38.286769\n",
      "resetting env. episode 844, reward total was -21.0. running mean: -20.2537064567515, timestamp: 2022-08-19 19:55:40.639482\n",
      "resetting env. episode 845, reward total was -21.0. running mean: -20.261169392183987, timestamp: 2022-08-19 19:55:42.389178\n",
      "resetting env. episode 846, reward total was -21.0. running mean: -20.26855769826215, timestamp: 2022-08-19 19:55:44.967875\n",
      "resetting env. episode 847, reward total was -21.0. running mean: -20.27587212127953, timestamp: 2022-08-19 19:55:47.552203\n",
      "resetting env. episode 848, reward total was -20.0. running mean: -20.273113400066734, timestamp: 2022-08-19 19:55:50.529013\n",
      "resetting env. episode 849, reward total was -21.0. running mean: -20.280382266066066, timestamp: 2022-08-19 19:55:53.673060\n",
      "resetting env. episode 850, reward total was -21.0. running mean: -20.287578443405405, timestamp: 2022-08-19 19:55:56.383798\n",
      "resetting env. episode 851, reward total was -21.0. running mean: -20.294702658971353, timestamp: 2022-08-19 19:55:59.210069\n",
      "resetting env. episode 852, reward total was -20.0. running mean: -20.291755632381637, timestamp: 2022-08-19 19:56:01.601508\n",
      "resetting env. episode 853, reward total was -20.0. running mean: -20.28883807605782, timestamp: 2022-08-19 19:56:04.279627\n",
      "resetting env. episode 854, reward total was -20.0. running mean: -20.28594969529724, timestamp: 2022-08-19 19:56:06.822715\n",
      "resetting env. episode 855, reward total was -21.0. running mean: -20.29309019834427, timestamp: 2022-08-19 19:56:09.278623\n",
      "resetting env. episode 856, reward total was -20.0. running mean: -20.290159296360827, timestamp: 2022-08-19 19:56:11.556189\n",
      "resetting env. episode 857, reward total was -21.0. running mean: -20.297257703397218, timestamp: 2022-08-19 19:56:14.022448\n",
      "resetting env. episode 858, reward total was -20.0. running mean: -20.294285126363246, timestamp: 2022-08-19 19:56:16.698665\n",
      "resetting env. episode 859, reward total was -21.0. running mean: -20.301342275099614, timestamp: 2022-08-19 19:56:19.473676\n",
      "resetting env. episode 860, reward total was -21.0. running mean: -20.30832885234862, timestamp: 2022-08-19 19:56:21.820875\n",
      "resetting env. episode 861, reward total was -21.0. running mean: -20.315245563825133, timestamp: 2022-08-19 19:56:24.277558\n",
      "resetting env. episode 862, reward total was -21.0. running mean: -20.322093108186884, timestamp: 2022-08-19 19:56:27.049655\n",
      "resetting env. episode 863, reward total was -21.0. running mean: -20.328872177105016, timestamp: 2022-08-19 19:56:29.752953\n",
      "resetting env. episode 864, reward total was -19.0. running mean: -20.315583455333968, timestamp: 2022-08-19 19:56:32.745280\n",
      "resetting env. episode 865, reward total was -21.0. running mean: -20.32242762078063, timestamp: 2022-08-19 19:56:35.775878\n",
      "resetting env. episode 866, reward total was -20.0. running mean: -20.319203344572824, timestamp: 2022-08-19 19:56:38.289915\n",
      "resetting env. episode 867, reward total was -19.0. running mean: -20.306011311127097, timestamp: 2022-08-19 19:56:41.021875\n",
      "resetting env. episode 868, reward total was -20.0. running mean: -20.302951198015826, timestamp: 2022-08-19 19:56:44.294491\n",
      "resetting env. episode 869, reward total was -21.0. running mean: -20.30992168603567, timestamp: 2022-08-19 19:56:46.930047\n",
      "resetting env. episode 870, reward total was -20.0. running mean: -20.306822469175312, timestamp: 2022-08-19 19:56:49.802521\n",
      "resetting env. episode 871, reward total was -21.0. running mean: -20.313754244483558, timestamp: 2022-08-19 19:56:52.552447\n",
      "resetting env. episode 872, reward total was -18.0. running mean: -20.290616702038722, timestamp: 2022-08-19 19:56:55.382817\n",
      "resetting env. episode 873, reward total was -21.0. running mean: -20.297710535018336, timestamp: 2022-08-19 19:56:58.030457\n",
      "resetting env. episode 874, reward total was -21.0. running mean: -20.304733429668154, timestamp: 2022-08-19 19:57:00.156812\n",
      "resetting env. episode 875, reward total was -21.0. running mean: -20.311686095371474, timestamp: 2022-08-19 19:57:02.572348\n",
      "resetting env. episode 876, reward total was -19.0. running mean: -20.298569234417762, timestamp: 2022-08-19 19:57:05.606600\n",
      "resetting env. episode 877, reward total was -21.0. running mean: -20.305583542073585, timestamp: 2022-08-19 19:57:08.092477\n",
      "resetting env. episode 878, reward total was -21.0. running mean: -20.31252770665285, timestamp: 2022-08-19 19:57:11.032460\n",
      "resetting env. episode 879, reward total was -20.0. running mean: -20.30940242958632, timestamp: 2022-08-19 19:57:13.321604\n",
      "resetting env. episode 880, reward total was -18.0. running mean: -20.286308405290455, timestamp: 2022-08-19 19:57:16.935246\n",
      "resetting env. episode 881, reward total was -20.0. running mean: -20.28344532123755, timestamp: 2022-08-19 19:57:19.474299\n",
      "resetting env. episode 882, reward total was -20.0. running mean: -20.280610868025175, timestamp: 2022-08-19 19:57:21.729150\n",
      "resetting env. episode 883, reward total was -21.0. running mean: -20.287804759344922, timestamp: 2022-08-19 19:57:24.756065\n",
      "resetting env. episode 884, reward total was -19.0. running mean: -20.274926711751473, timestamp: 2022-08-19 19:57:27.855890\n",
      "resetting env. episode 885, reward total was -20.0. running mean: -20.272177444633957, timestamp: 2022-08-19 19:57:30.690823\n",
      "resetting env. episode 886, reward total was -21.0. running mean: -20.27945567018762, timestamp: 2022-08-19 19:57:33.724682\n",
      "resetting env. episode 887, reward total was -21.0. running mean: -20.286661113485746, timestamp: 2022-08-19 19:57:35.704836\n",
      "resetting env. episode 888, reward total was -21.0. running mean: -20.293794502350888, timestamp: 2022-08-19 19:57:38.016796\n",
      "resetting env. episode 889, reward total was -21.0. running mean: -20.30085655732738, timestamp: 2022-08-19 19:57:40.019064\n",
      "resetting env. episode 890, reward total was -21.0. running mean: -20.307847991754105, timestamp: 2022-08-19 19:57:42.934346\n",
      "resetting env. episode 891, reward total was -21.0. running mean: -20.314769511836566, timestamp: 2022-08-19 19:57:44.966682\n",
      "resetting env. episode 892, reward total was -20.0. running mean: -20.3116218167182, timestamp: 2022-08-19 19:57:47.349195\n",
      "resetting env. episode 893, reward total was -18.0. running mean: -20.28850559855102, timestamp: 2022-08-19 19:57:50.800768\n",
      "resetting env. episode 894, reward total was -21.0. running mean: -20.29562054256551, timestamp: 2022-08-19 19:57:53.022864\n",
      "resetting env. episode 895, reward total was -21.0. running mean: -20.302664337139856, timestamp: 2022-08-19 19:57:55.607703\n",
      "resetting env. episode 896, reward total was -20.0. running mean: -20.299637693768457, timestamp: 2022-08-19 19:57:58.096027\n",
      "resetting env. episode 897, reward total was -20.0. running mean: -20.296641316830772, timestamp: 2022-08-19 19:58:00.178457\n",
      "resetting env. episode 898, reward total was -21.0. running mean: -20.303674903662465, timestamp: 2022-08-19 19:58:02.943268\n",
      "resetting env. episode 899, reward total was -21.0. running mean: -20.310638154625842, timestamp: 2022-08-19 19:58:04.978801\n",
      "resetting env. episode 900, reward total was -20.0. running mean: -20.30753177307958, timestamp: 2022-08-19 19:58:07.416280\n",
      "resetting env. episode 901, reward total was -21.0. running mean: -20.314456455348786, timestamp: 2022-08-19 19:58:09.590697\n",
      "resetting env. episode 902, reward total was -21.0. running mean: -20.3213118907953, timestamp: 2022-08-19 19:58:12.360319\n",
      "resetting env. episode 903, reward total was -21.0. running mean: -20.328098771887348, timestamp: 2022-08-19 19:58:15.233744\n",
      "resetting env. episode 904, reward total was -19.0. running mean: -20.314817784168476, timestamp: 2022-08-19 19:58:17.823818\n",
      "resetting env. episode 905, reward total was -21.0. running mean: -20.321669606326793, timestamp: 2022-08-19 19:58:20.319593\n",
      "resetting env. episode 906, reward total was -21.0. running mean: -20.328452910263525, timestamp: 2022-08-19 19:58:22.482783\n",
      "resetting env. episode 907, reward total was -21.0. running mean: -20.33516838116089, timestamp: 2022-08-19 19:58:25.234660\n",
      "resetting env. episode 908, reward total was -21.0. running mean: -20.341816697349284, timestamp: 2022-08-19 19:58:27.700019\n",
      "resetting env. episode 909, reward total was -20.0. running mean: -20.33839853037579, timestamp: 2022-08-19 19:58:30.461744\n",
      "resetting env. episode 910, reward total was -19.0. running mean: -20.325014545072033, timestamp: 2022-08-19 19:58:33.901652\n",
      "resetting env. episode 911, reward total was -21.0. running mean: -20.331764399621314, timestamp: 2022-08-19 19:58:36.579972\n",
      "resetting env. episode 912, reward total was -21.0. running mean: -20.3384467556251, timestamp: 2022-08-19 19:58:38.693403\n",
      "resetting env. episode 913, reward total was -20.0. running mean: -20.335062288068848, timestamp: 2022-08-19 19:58:41.640525\n",
      "resetting env. episode 914, reward total was -21.0. running mean: -20.34171166518816, timestamp: 2022-08-19 19:58:43.899976\n",
      "resetting env. episode 915, reward total was -21.0. running mean: -20.34829454853628, timestamp: 2022-08-19 19:58:46.317042\n",
      "resetting env. episode 916, reward total was -21.0. running mean: -20.35481160305092, timestamp: 2022-08-19 19:58:48.379902\n",
      "resetting env. episode 917, reward total was -21.0. running mean: -20.36126348702041, timestamp: 2022-08-19 19:58:50.899791\n",
      "resetting env. episode 918, reward total was -20.0. running mean: -20.357650852150204, timestamp: 2022-08-19 19:58:53.726058\n",
      "resetting env. episode 919, reward total was -20.0. running mean: -20.3540743436287, timestamp: 2022-08-19 19:58:56.429498\n",
      "resetting env. episode 920, reward total was -21.0. running mean: -20.36053360019241, timestamp: 2022-08-19 19:58:58.644553\n",
      "resetting env. episode 921, reward total was -19.0. running mean: -20.34692826419049, timestamp: 2022-08-19 19:59:01.109542\n",
      "resetting env. episode 922, reward total was -21.0. running mean: -20.353458981548584, timestamp: 2022-08-19 19:59:03.575906\n",
      "resetting env. episode 923, reward total was -21.0. running mean: -20.3599243917331, timestamp: 2022-08-19 19:59:05.887368\n",
      "resetting env. episode 924, reward total was -21.0. running mean: -20.36632514781577, timestamp: 2022-08-19 19:59:08.383421\n",
      "resetting env. episode 925, reward total was -21.0. running mean: -20.37266189633761, timestamp: 2022-08-19 19:59:11.013335\n",
      "resetting env. episode 926, reward total was -21.0. running mean: -20.378935277374236, timestamp: 2022-08-19 19:59:13.505495\n",
      "resetting env. episode 927, reward total was -20.0. running mean: -20.375145924600492, timestamp: 2022-08-19 19:59:16.299901\n",
      "resetting env. episode 928, reward total was -21.0. running mean: -20.38139446535449, timestamp: 2022-08-19 19:59:18.883467\n",
      "resetting env. episode 929, reward total was -21.0. running mean: -20.387580520700944, timestamp: 2022-08-19 19:59:21.026540\n",
      "resetting env. episode 930, reward total was -21.0. running mean: -20.393704715493936, timestamp: 2022-08-19 19:59:23.279774\n",
      "resetting env. episode 931, reward total was -21.0. running mean: -20.399767668338995, timestamp: 2022-08-19 19:59:25.740652\n",
      "resetting env. episode 932, reward total was -21.0. running mean: -20.405769991655607, timestamp: 2022-08-19 19:59:28.617305\n",
      "resetting env. episode 933, reward total was -20.0. running mean: -20.40171229173905, timestamp: 2022-08-19 19:59:32.049730\n",
      "resetting env. episode 934, reward total was -21.0. running mean: -20.407695168821657, timestamp: 2022-08-19 19:59:34.066148\n",
      "resetting env. episode 935, reward total was -20.0. running mean: -20.40361821713344, timestamp: 2022-08-19 19:59:36.595303\n",
      "resetting env. episode 936, reward total was -21.0. running mean: -20.409582034962106, timestamp: 2022-08-19 19:59:39.837169\n",
      "resetting env. episode 937, reward total was -20.0. running mean: -20.405486214612484, timestamp: 2022-08-19 19:59:42.688854\n",
      "resetting env. episode 938, reward total was -21.0. running mean: -20.41143135246636, timestamp: 2022-08-19 19:59:45.165134\n",
      "resetting env. episode 939, reward total was -20.0. running mean: -20.407317038941695, timestamp: 2022-08-19 19:59:48.874576\n",
      "resetting env. episode 940, reward total was -20.0. running mean: -20.403243868552277, timestamp: 2022-08-19 19:59:51.525833\n",
      "resetting env. episode 941, reward total was -20.0. running mean: -20.399211429866753, timestamp: 2022-08-19 19:59:54.061163\n",
      "resetting env. episode 942, reward total was -21.0. running mean: -20.405219315568086, timestamp: 2022-08-19 19:59:56.407750\n",
      "resetting env. episode 943, reward total was -21.0. running mean: -20.411167122412404, timestamp: 2022-08-19 19:59:59.027510\n",
      "resetting env. episode 944, reward total was -21.0. running mean: -20.417055451188283, timestamp: 2022-08-19 20:00:01.374602\n",
      "resetting env. episode 945, reward total was -21.0. running mean: -20.4228848966764, timestamp: 2022-08-19 20:00:03.864108\n",
      "resetting env. episode 946, reward total was -20.0. running mean: -20.418656047709636, timestamp: 2022-08-19 20:00:06.752259\n",
      "resetting env. episode 947, reward total was -20.0. running mean: -20.414469487232537, timestamp: 2022-08-19 20:00:09.364621\n",
      "resetting env. episode 948, reward total was -20.0. running mean: -20.41032479236021, timestamp: 2022-08-19 20:00:12.094275\n",
      "resetting env. episode 949, reward total was -20.0. running mean: -20.406221544436608, timestamp: 2022-08-19 20:00:15.510446\n",
      "resetting env. episode 950, reward total was -21.0. running mean: -20.412159328992242, timestamp: 2022-08-19 20:00:18.312282\n",
      "resetting env. episode 951, reward total was -20.0. running mean: -20.40803773570232, timestamp: 2022-08-19 20:00:20.926761\n",
      "resetting env. episode 952, reward total was -21.0. running mean: -20.413957358345296, timestamp: 2022-08-19 20:00:24.402401\n",
      "resetting env. episode 953, reward total was -20.0. running mean: -20.40981778476184, timestamp: 2022-08-19 20:00:26.794397\n",
      "resetting env. episode 954, reward total was -18.0. running mean: -20.385719606914222, timestamp: 2022-08-19 20:00:29.879997\n",
      "resetting env. episode 955, reward total was -18.0. running mean: -20.36186241084508, timestamp: 2022-08-19 20:00:33.162001\n",
      "resetting env. episode 956, reward total was -20.0. running mean: -20.35824378673663, timestamp: 2022-08-19 20:00:35.478123\n",
      "resetting env. episode 957, reward total was -21.0. running mean: -20.364661348869262, timestamp: 2022-08-19 20:00:38.749592\n",
      "resetting env. episode 958, reward total was -20.0. running mean: -20.361014735380568, timestamp: 2022-08-19 20:00:42.506552\n",
      "resetting env. episode 959, reward total was -20.0. running mean: -20.35740458802676, timestamp: 2022-08-19 20:00:45.695028\n",
      "resetting env. episode 960, reward total was -19.0. running mean: -20.343830542146495, timestamp: 2022-08-19 20:00:49.230243\n",
      "resetting env. episode 961, reward total was -21.0. running mean: -20.350392236725032, timestamp: 2022-08-19 20:00:51.680719\n",
      "resetting env. episode 962, reward total was -21.0. running mean: -20.356888314357782, timestamp: 2022-08-19 20:00:54.024453\n",
      "resetting env. episode 963, reward total was -21.0. running mean: -20.363319431214205, timestamp: 2022-08-19 20:00:56.683346\n",
      "resetting env. episode 964, reward total was -20.0. running mean: -20.35968623690206, timestamp: 2022-08-19 20:00:59.463000\n",
      "resetting env. episode 965, reward total was -21.0. running mean: -20.36608937453304, timestamp: 2022-08-19 20:01:01.955337\n",
      "resetting env. episode 966, reward total was -21.0. running mean: -20.37242848078771, timestamp: 2022-08-19 20:01:04.443688\n",
      "resetting env. episode 967, reward total was -20.0. running mean: -20.368704195979834, timestamp: 2022-08-19 20:01:08.047058\n",
      "resetting env. episode 968, reward total was -19.0. running mean: -20.355017154020036, timestamp: 2022-08-19 20:01:11.590583\n",
      "resetting env. episode 969, reward total was -21.0. running mean: -20.361466982479836, timestamp: 2022-08-19 20:01:14.399078\n",
      "resetting env. episode 970, reward total was -20.0. running mean: -20.357852312655037, timestamp: 2022-08-19 20:01:17.733163\n",
      "resetting env. episode 971, reward total was -18.0. running mean: -20.334273789528485, timestamp: 2022-08-19 20:01:22.111743\n",
      "resetting env. episode 972, reward total was -21.0. running mean: -20.340931051633202, timestamp: 2022-08-19 20:01:24.471436\n",
      "resetting env. episode 973, reward total was -19.0. running mean: -20.327521741116872, timestamp: 2022-08-19 20:01:27.496520\n",
      "resetting env. episode 974, reward total was -21.0. running mean: -20.334246523705705, timestamp: 2022-08-19 20:01:30.981208\n",
      "resetting env. episode 975, reward total was -21.0. running mean: -20.34090405846865, timestamp: 2022-08-19 20:01:34.159188\n",
      "resetting env. episode 976, reward total was -21.0. running mean: -20.34749501788396, timestamp: 2022-08-19 20:01:36.924191\n",
      "resetting env. episode 977, reward total was -19.0. running mean: -20.334020067705122, timestamp: 2022-08-19 20:01:41.789460\n",
      "resetting env. episode 978, reward total was -21.0. running mean: -20.340679867028072, timestamp: 2022-08-19 20:01:44.622268\n",
      "resetting env. episode 979, reward total was -21.0. running mean: -20.347273068357794, timestamp: 2022-08-19 20:01:47.016737\n",
      "resetting env. episode 980, reward total was -21.0. running mean: -20.353800337674215, timestamp: 2022-08-19 20:01:50.792319\n",
      "resetting env. episode 981, reward total was -19.0. running mean: -20.340262334297474, timestamp: 2022-08-19 20:01:53.871945\n",
      "resetting env. episode 982, reward total was -20.0. running mean: -20.3368597109545, timestamp: 2022-08-19 20:01:57.147590\n",
      "resetting env. episode 983, reward total was -21.0. running mean: -20.343491113844955, timestamp: 2022-08-19 20:01:59.764129\n",
      "resetting env. episode 984, reward total was -21.0. running mean: -20.350056202706504, timestamp: 2022-08-19 20:02:02.606386\n",
      "resetting env. episode 985, reward total was -21.0. running mean: -20.35655564067944, timestamp: 2022-08-19 20:02:05.733430\n",
      "resetting env. episode 986, reward total was -21.0. running mean: -20.362990084272646, timestamp: 2022-08-19 20:02:09.138448\n",
      "resetting env. episode 987, reward total was -20.0. running mean: -20.359360183429917, timestamp: 2022-08-19 20:02:13.074922\n",
      "resetting env. episode 988, reward total was -20.0. running mean: -20.355766581595617, timestamp: 2022-08-19 20:02:16.288347\n",
      "resetting env. episode 989, reward total was -21.0. running mean: -20.36220891577966, timestamp: 2022-08-19 20:02:19.602101\n",
      "resetting env. episode 990, reward total was -21.0. running mean: -20.368586826621865, timestamp: 2022-08-19 20:02:22.529489\n",
      "resetting env. episode 991, reward total was -19.0. running mean: -20.354900958355646, timestamp: 2022-08-19 20:02:25.837234\n",
      "resetting env. episode 992, reward total was -20.0. running mean: -20.351351948772088, timestamp: 2022-08-19 20:02:29.887417\n",
      "resetting env. episode 993, reward total was -20.0. running mean: -20.347838429284366, timestamp: 2022-08-19 20:02:34.172953\n",
      "resetting env. episode 994, reward total was -20.0. running mean: -20.34436004499152, timestamp: 2022-08-19 20:02:40.352434\n",
      "resetting env. episode 995, reward total was -21.0. running mean: -20.350916444541607, timestamp: 2022-08-19 20:02:43.587783\n",
      "resetting env. episode 996, reward total was -21.0. running mean: -20.35740728009619, timestamp: 2022-08-19 20:02:47.706790\n",
      "resetting env. episode 997, reward total was -21.0. running mean: -20.36383320729523, timestamp: 2022-08-19 20:02:50.229034\n",
      "resetting env. episode 998, reward total was -20.0. running mean: -20.360194875222277, timestamp: 2022-08-19 20:02:53.430401\n",
      "resetting env. episode 999, reward total was -20.0. running mean: -20.356592926470054, timestamp: 2022-08-19 20:02:56.822332\n",
      "resetting env. episode 1000, reward total was -20.0. running mean: -20.35302699720535, timestamp: 2022-08-19 20:03:00.659655\n",
      "resetting env. episode 1001, reward total was -20.0. running mean: -20.349496727233298, timestamp: 2022-08-19 20:03:04.565228\n",
      "resetting env. episode 1002, reward total was -20.0. running mean: -20.346001759960963, timestamp: 2022-08-19 20:03:08.063865\n",
      "resetting env. episode 1003, reward total was -21.0. running mean: -20.352541742361353, timestamp: 2022-08-19 20:03:10.758660\n",
      "resetting env. episode 1004, reward total was -20.0. running mean: -20.34901632493774, timestamp: 2022-08-19 20:03:14.102083\n",
      "resetting env. episode 1005, reward total was -21.0. running mean: -20.355526161688363, timestamp: 2022-08-19 20:03:19.013879\n",
      "resetting env. episode 1006, reward total was -19.0. running mean: -20.34197090007148, timestamp: 2022-08-19 20:03:22.728937\n",
      "resetting env. episode 1007, reward total was -20.0. running mean: -20.338551191070763, timestamp: 2022-08-19 20:03:25.945338\n",
      "resetting env. episode 1008, reward total was -21.0. running mean: -20.345165679160058, timestamp: 2022-08-19 20:03:28.270125\n",
      "resetting env. episode 1009, reward total was -21.0. running mean: -20.35171402236846, timestamp: 2022-08-19 20:03:31.216250\n",
      "resetting env. episode 1010, reward total was -21.0. running mean: -20.358196882144775, timestamp: 2022-08-19 20:03:35.011112\n",
      "resetting env. episode 1011, reward total was -20.0. running mean: -20.354614913323324, timestamp: 2022-08-19 20:03:37.975025\n",
      "resetting env. episode 1012, reward total was -21.0. running mean: -20.36106876419009, timestamp: 2022-08-19 20:03:41.150618\n",
      "resetting env. episode 1013, reward total was -19.0. running mean: -20.34745807654819, timestamp: 2022-08-19 20:03:44.910911\n",
      "resetting env. episode 1014, reward total was -21.0. running mean: -20.353983495782707, timestamp: 2022-08-19 20:03:48.828435\n",
      "resetting env. episode 1015, reward total was -20.0. running mean: -20.35044366082488, timestamp: 2022-08-19 20:03:52.757928\n",
      "resetting env. episode 1016, reward total was -19.0. running mean: -20.336939224216632, timestamp: 2022-08-19 20:03:55.823155\n",
      "resetting env. episode 1017, reward total was -20.0. running mean: -20.333569831974465, timestamp: 2022-08-19 20:03:58.935862\n",
      "resetting env. episode 1018, reward total was -18.0. running mean: -20.31023413365472, timestamp: 2022-08-19 20:04:02.893500\n",
      "resetting env. episode 1019, reward total was -18.0. running mean: -20.287131792318174, timestamp: 2022-08-19 20:04:07.157563\n",
      "resetting env. episode 1020, reward total was -21.0. running mean: -20.294260474394992, timestamp: 2022-08-19 20:04:10.614423\n",
      "resetting env. episode 1021, reward total was -20.0. running mean: -20.291317869651042, timestamp: 2022-08-19 20:04:14.374008\n",
      "resetting env. episode 1022, reward total was -21.0. running mean: -20.29840469095453, timestamp: 2022-08-19 20:04:16.885279\n",
      "resetting env. episode 1023, reward total was -20.0. running mean: -20.295420644044984, timestamp: 2022-08-19 20:04:20.157463\n",
      "resetting env. episode 1024, reward total was -20.0. running mean: -20.292466437604535, timestamp: 2022-08-19 20:04:22.844974\n",
      "resetting env. episode 1025, reward total was -21.0. running mean: -20.29954177322849, timestamp: 2022-08-19 20:04:25.426072\n",
      "resetting env. episode 1026, reward total was -19.0. running mean: -20.286546355496206, timestamp: 2022-08-19 20:04:28.435426\n",
      "resetting env. episode 1027, reward total was -21.0. running mean: -20.293680891941246, timestamp: 2022-08-19 20:04:31.451454\n",
      "resetting env. episode 1028, reward total was -21.0. running mean: -20.300744083021833, timestamp: 2022-08-19 20:04:35.143598\n",
      "resetting env. episode 1029, reward total was -20.0. running mean: -20.297736642191612, timestamp: 2022-08-19 20:04:38.277207\n",
      "resetting env. episode 1030, reward total was -21.0. running mean: -20.304759275769698, timestamp: 2022-08-19 20:04:41.998270\n",
      "resetting env. episode 1031, reward total was -21.0. running mean: -20.311711683012, timestamp: 2022-08-19 20:04:45.195715\n",
      "resetting env. episode 1032, reward total was -21.0. running mean: -20.31859456618188, timestamp: 2022-08-19 20:04:48.385196\n",
      "resetting env. episode 1033, reward total was -21.0. running mean: -20.32540862052006, timestamp: 2022-08-19 20:04:51.144812\n",
      "resetting env. episode 1034, reward total was -21.0. running mean: -20.33215453431486, timestamp: 2022-08-19 20:04:55.072316\n",
      "resetting env. episode 1035, reward total was -21.0. running mean: -20.338832988971713, timestamp: 2022-08-19 20:04:58.508165\n",
      "resetting env. episode 1036, reward total was -19.0. running mean: -20.325444659082, timestamp: 2022-08-19 20:05:01.801336\n",
      "resetting env. episode 1037, reward total was -21.0. running mean: -20.33219021249118, timestamp: 2022-08-19 20:05:05.061611\n",
      "resetting env. episode 1038, reward total was -21.0. running mean: -20.33886831036627, timestamp: 2022-08-19 20:05:08.974169\n",
      "resetting env. episode 1039, reward total was -20.0. running mean: -20.335479627262604, timestamp: 2022-08-19 20:05:13.048297\n",
      "resetting env. episode 1040, reward total was -21.0. running mean: -20.342124830989977, timestamp: 2022-08-19 20:05:16.449328\n",
      "resetting env. episode 1041, reward total was -21.0. running mean: -20.348703582680077, timestamp: 2022-08-19 20:05:20.369853\n",
      "resetting env. episode 1042, reward total was -21.0. running mean: -20.355216546853278, timestamp: 2022-08-19 20:05:23.758790\n",
      "resetting env. episode 1043, reward total was -21.0. running mean: -20.361664381384745, timestamp: 2022-08-19 20:05:28.366788\n",
      "resetting env. episode 1044, reward total was -19.0. running mean: -20.348047737570898, timestamp: 2022-08-19 20:05:33.991745\n",
      "resetting env. episode 1045, reward total was -21.0. running mean: -20.35456726019519, timestamp: 2022-08-19 20:05:36.795249\n",
      "resetting env. episode 1046, reward total was -21.0. running mean: -20.36102158759324, timestamp: 2022-08-19 20:05:40.371697\n",
      "resetting env. episode 1047, reward total was -21.0. running mean: -20.367411371717306, timestamp: 2022-08-19 20:05:43.684835\n",
      "resetting env. episode 1048, reward total was -21.0. running mean: -20.373737258000133, timestamp: 2022-08-19 20:05:46.652122\n",
      "resetting env. episode 1049, reward total was -19.0. running mean: -20.359999885420134, timestamp: 2022-08-19 20:05:50.711268\n",
      "resetting env. episode 1050, reward total was -20.0. running mean: -20.35639988656593, timestamp: 2022-08-19 20:05:53.615567\n",
      "resetting env. episode 1051, reward total was -20.0. running mean: -20.35283588770027, timestamp: 2022-08-19 20:05:57.386428\n",
      "resetting env. episode 1052, reward total was -19.0. running mean: -20.33930752882327, timestamp: 2022-08-19 20:06:02.393044\n",
      "resetting env. episode 1053, reward total was -21.0. running mean: -20.345914453535038, timestamp: 2022-08-19 20:06:06.655717\n",
      "resetting env. episode 1054, reward total was -20.0. running mean: -20.342455308999686, timestamp: 2022-08-19 20:06:09.778370\n",
      "resetting env. episode 1055, reward total was -19.0. running mean: -20.329030755909688, timestamp: 2022-08-19 20:06:12.594840\n",
      "resetting env. episode 1056, reward total was -20.0. running mean: -20.32574044835059, timestamp: 2022-08-19 20:06:15.894024\n",
      "resetting env. episode 1057, reward total was -19.0. running mean: -20.312483043867086, timestamp: 2022-08-19 20:06:19.730770\n",
      "resetting env. episode 1058, reward total was -21.0. running mean: -20.319358213428416, timestamp: 2022-08-19 20:06:24.827137\n",
      "resetting env. episode 1059, reward total was -21.0. running mean: -20.326164631294134, timestamp: 2022-08-19 20:06:30.577768\n",
      "resetting env. episode 1060, reward total was -21.0. running mean: -20.332902984981192, timestamp: 2022-08-19 20:06:38.611294\n",
      "resetting env. episode 1061, reward total was -20.0. running mean: -20.32957395513138, timestamp: 2022-08-19 20:06:47.212972\n",
      "resetting env. episode 1062, reward total was -21.0. running mean: -20.336278215580066, timestamp: 2022-08-19 20:06:53.332563\n",
      "resetting env. episode 1063, reward total was -20.0. running mean: -20.332915433424265, timestamp: 2022-08-19 20:06:57.566243\n",
      "resetting env. episode 1064, reward total was -21.0. running mean: -20.339586279090025, timestamp: 2022-08-19 20:07:02.107106\n",
      "resetting env. episode 1065, reward total was -20.0. running mean: -20.336190416299125, timestamp: 2022-08-19 20:07:06.026056\n",
      "resetting env. episode 1066, reward total was -20.0. running mean: -20.332828512136132, timestamp: 2022-08-19 20:07:10.116157\n",
      "resetting env. episode 1067, reward total was -20.0. running mean: -20.32950022701477, timestamp: 2022-08-19 20:07:14.311908\n",
      "resetting env. episode 1068, reward total was -20.0. running mean: -20.32620522474462, timestamp: 2022-08-19 20:07:18.693662\n",
      "resetting env. episode 1069, reward total was -21.0. running mean: -20.332943172497174, timestamp: 2022-08-19 20:07:21.225865\n",
      "resetting env. episode 1070, reward total was -20.0. running mean: -20.329613740772203, timestamp: 2022-08-19 20:07:24.938854\n",
      "resetting env. episode 1071, reward total was -21.0. running mean: -20.33631760336448, timestamp: 2022-08-19 20:07:28.243036\n",
      "resetting env. episode 1072, reward total was -19.0. running mean: -20.32295442733084, timestamp: 2022-08-19 20:07:32.130634\n",
      "resetting env. episode 1073, reward total was -21.0. running mean: -20.32972488305753, timestamp: 2022-08-19 20:07:36.696336\n",
      "resetting env. episode 1074, reward total was -20.0. running mean: -20.326427634226953, timestamp: 2022-08-19 20:07:39.622394\n",
      "resetting env. episode 1075, reward total was -21.0. running mean: -20.333163357884683, timestamp: 2022-08-19 20:07:42.321771\n",
      "resetting env. episode 1076, reward total was -20.0. running mean: -20.329831724305834, timestamp: 2022-08-19 20:07:45.289837\n",
      "resetting env. episode 1077, reward total was -19.0. running mean: -20.316533407062778, timestamp: 2022-08-19 20:07:48.521587\n",
      "resetting env. episode 1078, reward total was -19.0. running mean: -20.30336807299215, timestamp: 2022-08-19 20:07:53.279987\n",
      "resetting env. episode 1079, reward total was -21.0. running mean: -20.31033439226223, timestamp: 2022-08-19 20:07:56.212395\n",
      "resetting env. episode 1080, reward total was -21.0. running mean: -20.317231048339607, timestamp: 2022-08-19 20:07:59.371228\n",
      "resetting env. episode 1081, reward total was -21.0. running mean: -20.324058737856213, timestamp: 2022-08-19 20:08:02.200304\n",
      "resetting env. episode 1082, reward total was -18.0. running mean: -20.30081815047765, timestamp: 2022-08-19 20:08:07.183001\n",
      "resetting env. episode 1083, reward total was -21.0. running mean: -20.307809968972872, timestamp: 2022-08-19 20:08:13.044319\n",
      "resetting env. episode 1084, reward total was -21.0. running mean: -20.314731869283143, timestamp: 2022-08-19 20:08:19.301593\n",
      "resetting env. episode 1085, reward total was -20.0. running mean: -20.31158455059031, timestamp: 2022-08-19 20:08:24.585470\n",
      "resetting env. episode 1086, reward total was -20.0. running mean: -20.308468705084408, timestamp: 2022-08-19 20:08:30.271272\n",
      "resetting env. episode 1087, reward total was -20.0. running mean: -20.305384018033564, timestamp: 2022-08-19 20:08:37.468034\n",
      "resetting env. episode 1088, reward total was -21.0. running mean: -20.31233017785323, timestamp: 2022-08-19 20:08:40.737187\n",
      "resetting env. episode 1089, reward total was -20.0. running mean: -20.309206876074697, timestamp: 2022-08-19 20:08:45.780706\n",
      "resetting env. episode 1090, reward total was -21.0. running mean: -20.31611480731395, timestamp: 2022-08-19 20:08:49.263396\n",
      "resetting env. episode 1091, reward total was -19.0. running mean: -20.302953659240814, timestamp: 2022-08-19 20:08:52.597340\n",
      "resetting env. episode 1092, reward total was -18.0. running mean: -20.279924122648406, timestamp: 2022-08-19 20:08:58.080350\n",
      "resetting env. episode 1093, reward total was -21.0. running mean: -20.287124881421924, timestamp: 2022-08-19 20:09:00.438905\n",
      "resetting env. episode 1094, reward total was -21.0. running mean: -20.294253632607706, timestamp: 2022-08-19 20:09:03.276323\n",
      "resetting env. episode 1095, reward total was -21.0. running mean: -20.30131109628163, timestamp: 2022-08-19 20:09:07.825164\n",
      "resetting env. episode 1096, reward total was -18.0. running mean: -20.27829798531881, timestamp: 2022-08-19 20:09:11.268957\n",
      "resetting env. episode 1097, reward total was -21.0. running mean: -20.285515005465623, timestamp: 2022-08-19 20:09:14.296862\n",
      "resetting env. episode 1098, reward total was -19.0. running mean: -20.272659855410968, timestamp: 2022-08-19 20:09:19.065309\n",
      "resetting env. episode 1099, reward total was -19.0. running mean: -20.259933256856858, timestamp: 2022-08-19 20:09:25.472183\n",
      "resetting env. episode 1100, reward total was -21.0. running mean: -20.26733392428829, timestamp: 2022-08-19 20:09:29.047624\n",
      "resetting env. episode 1101, reward total was -21.0. running mean: -20.27466058504541, timestamp: 2022-08-19 20:09:32.397672\n",
      "resetting env. episode 1102, reward total was -20.0. running mean: -20.271913979194956, timestamp: 2022-08-19 20:09:37.097196\n",
      "resetting env. episode 1103, reward total was -21.0. running mean: -20.279194839403008, timestamp: 2022-08-19 20:09:41.464535\n",
      "resetting env. episode 1104, reward total was -21.0. running mean: -20.28640289100898, timestamp: 2022-08-19 20:09:45.701200\n",
      "resetting env. episode 1105, reward total was -21.0. running mean: -20.29353886209889, timestamp: 2022-08-19 20:09:50.531293\n",
      "resetting env. episode 1106, reward total was -19.0. running mean: -20.280603473477903, timestamp: 2022-08-19 20:09:53.790610\n",
      "resetting env. episode 1107, reward total was -19.0. running mean: -20.267797438743127, timestamp: 2022-08-19 20:09:59.486214\n",
      "resetting env. episode 1108, reward total was -20.0. running mean: -20.265119464355696, timestamp: 2022-08-19 20:10:04.819955\n",
      "resetting env. episode 1109, reward total was -21.0. running mean: -20.27246826971214, timestamp: 2022-08-19 20:10:07.098653\n",
      "resetting env. episode 1110, reward total was -21.0. running mean: -20.27974358701502, timestamp: 2022-08-19 20:10:09.768520\n",
      "resetting env. episode 1111, reward total was -20.0. running mean: -20.27694615114487, timestamp: 2022-08-19 20:10:13.010152\n",
      "resetting env. episode 1112, reward total was -21.0. running mean: -20.284176689633423, timestamp: 2022-08-19 20:10:15.818643\n",
      "resetting env. episode 1113, reward total was -21.0. running mean: -20.29133492273709, timestamp: 2022-08-19 20:10:18.473049\n",
      "resetting env. episode 1114, reward total was -20.0. running mean: -20.28842157350972, timestamp: 2022-08-19 20:10:21.857999\n",
      "resetting env. episode 1115, reward total was -20.0. running mean: -20.285537357774622, timestamp: 2022-08-19 20:10:25.797470\n",
      "resetting env. episode 1116, reward total was -20.0. running mean: -20.282681984196874, timestamp: 2022-08-19 20:10:28.821229\n",
      "resetting env. episode 1117, reward total was -20.0. running mean: -20.279855164354903, timestamp: 2022-08-19 20:10:31.912212\n",
      "resetting env. episode 1118, reward total was -21.0. running mean: -20.287056612711353, timestamp: 2022-08-19 20:10:37.237968\n",
      "resetting env. episode 1119, reward total was -20.0. running mean: -20.28418604658424, timestamp: 2022-08-19 20:10:40.635116\n",
      "resetting env. episode 1120, reward total was -21.0. running mean: -20.291344186118398, timestamp: 2022-08-19 20:10:43.001805\n",
      "resetting env. episode 1121, reward total was -21.0. running mean: -20.298430744257214, timestamp: 2022-08-19 20:10:46.525535\n",
      "resetting env. episode 1122, reward total was -21.0. running mean: -20.30544643681464, timestamp: 2022-08-19 20:10:50.197717\n",
      "resetting env. episode 1123, reward total was -21.0. running mean: -20.312391972446495, timestamp: 2022-08-19 20:10:53.134866\n",
      "resetting env. episode 1124, reward total was -21.0. running mean: -20.31926805272203, timestamp: 2022-08-19 20:10:56.852070\n",
      "resetting env. episode 1125, reward total was -21.0. running mean: -20.32607537219481, timestamp: 2022-08-19 20:10:59.800191\n",
      "resetting env. episode 1126, reward total was -20.0. running mean: -20.32281461847286, timestamp: 2022-08-19 20:11:02.844053\n",
      "resetting env. episode 1127, reward total was -21.0. running mean: -20.329586472288135, timestamp: 2022-08-19 20:11:06.171163\n",
      "resetting env. episode 1128, reward total was -18.0. running mean: -20.306290607565252, timestamp: 2022-08-19 20:11:10.212357\n",
      "resetting env. episode 1129, reward total was -20.0. running mean: -20.3032277014896, timestamp: 2022-08-19 20:11:15.805159\n",
      "resetting env. episode 1130, reward total was -21.0. running mean: -20.310195424474706, timestamp: 2022-08-19 20:11:22.019181\n",
      "resetting env. episode 1131, reward total was -20.0. running mean: -20.307093470229958, timestamp: 2022-08-19 20:11:24.896368\n",
      "resetting env. episode 1132, reward total was -20.0. running mean: -20.304022535527658, timestamp: 2022-08-19 20:11:29.927912\n",
      "resetting env. episode 1133, reward total was -21.0. running mean: -20.31098231017238, timestamp: 2022-08-19 20:11:32.753356\n",
      "resetting env. episode 1134, reward total was -19.0. running mean: -20.29787248707066, timestamp: 2022-08-19 20:11:36.752664\n",
      "resetting env. episode 1135, reward total was -20.0. running mean: -20.29489376219995, timestamp: 2022-08-19 20:11:40.606362\n",
      "resetting env. episode 1136, reward total was -21.0. running mean: -20.30194482457795, timestamp: 2022-08-19 20:11:44.232671\n",
      "resetting env. episode 1137, reward total was -20.0. running mean: -20.29892537633217, timestamp: 2022-08-19 20:11:47.812103\n",
      "resetting env. episode 1138, reward total was -20.0. running mean: -20.29593612256885, timestamp: 2022-08-19 20:11:51.705699\n",
      "resetting env. episode 1139, reward total was -21.0. running mean: -20.302976761343164, timestamp: 2022-08-19 20:11:55.868573\n",
      "resetting env. episode 1140, reward total was -21.0. running mean: -20.30994699372973, timestamp: 2022-08-19 20:11:59.001201\n",
      "resetting env. episode 1141, reward total was -20.0. running mean: -20.306847523792435, timestamp: 2022-08-19 20:12:02.792062\n",
      "resetting env. episode 1142, reward total was -20.0. running mean: -20.30377904855451, timestamp: 2022-08-19 20:12:07.130464\n",
      "resetting env. episode 1143, reward total was -21.0. running mean: -20.310741258068965, timestamp: 2022-08-19 20:12:12.430298\n",
      "resetting env. episode 1144, reward total was -19.0. running mean: -20.297633845488278, timestamp: 2022-08-19 20:12:15.609799\n",
      "resetting env. episode 1145, reward total was -20.0. running mean: -20.294657507033396, timestamp: 2022-08-19 20:12:19.226135\n",
      "resetting env. episode 1146, reward total was -21.0. running mean: -20.30171093196306, timestamp: 2022-08-19 20:12:22.596135\n",
      "resetting env. episode 1147, reward total was -20.0. running mean: -20.29869382264343, timestamp: 2022-08-19 20:12:26.243375\n",
      "resetting env. episode 1148, reward total was -21.0. running mean: -20.305706884416995, timestamp: 2022-08-19 20:12:29.493689\n",
      "resetting env. episode 1149, reward total was -18.0. running mean: -20.282649815572825, timestamp: 2022-08-19 20:12:35.235339\n",
      "resetting env. episode 1150, reward total was -20.0. running mean: -20.279823317417094, timestamp: 2022-08-19 20:12:39.431126\n",
      "resetting env. episode 1151, reward total was -21.0. running mean: -20.287025084242924, timestamp: 2022-08-19 20:12:42.197730\n",
      "resetting env. episode 1152, reward total was -20.0. running mean: -20.284154833400493, timestamp: 2022-08-19 20:12:45.281739\n",
      "resetting env. episode 1153, reward total was -19.0. running mean: -20.27131328506649, timestamp: 2022-08-19 20:12:48.386170\n",
      "resetting env. episode 1154, reward total was -21.0. running mean: -20.278600152215827, timestamp: 2022-08-19 20:12:51.759511\n",
      "resetting env. episode 1155, reward total was -21.0. running mean: -20.285814150693668, timestamp: 2022-08-19 20:12:55.004927\n",
      "resetting env. episode 1156, reward total was -21.0. running mean: -20.29295600918673, timestamp: 2022-08-19 20:12:57.806439\n",
      "resetting env. episode 1157, reward total was -20.0. running mean: -20.290026449094864, timestamp: 2022-08-19 20:13:00.557087\n",
      "resetting env. episode 1158, reward total was -20.0. running mean: -20.287126184603913, timestamp: 2022-08-19 20:13:03.315715\n",
      "resetting env. episode 1159, reward total was -21.0. running mean: -20.294254922757876, timestamp: 2022-08-19 20:13:06.075336\n",
      "resetting env. episode 1160, reward total was -21.0. running mean: -20.301312373530298, timestamp: 2022-08-19 20:13:09.273502\n",
      "resetting env. episode 1161, reward total was -20.0. running mean: -20.298299249794994, timestamp: 2022-08-19 20:13:13.630465\n",
      "resetting env. episode 1162, reward total was -20.0. running mean: -20.295316257297042, timestamp: 2022-08-19 20:13:17.196633\n",
      "resetting env. episode 1163, reward total was -20.0. running mean: -20.29236309472407, timestamp: 2022-08-19 20:13:21.126576\n",
      "resetting env. episode 1164, reward total was -21.0. running mean: -20.29943946377683, timestamp: 2022-08-19 20:13:23.826360\n",
      "resetting env. episode 1165, reward total was -20.0. running mean: -20.29644506913906, timestamp: 2022-08-19 20:13:26.743564\n",
      "resetting env. episode 1166, reward total was -21.0. running mean: -20.303480618447672, timestamp: 2022-08-19 20:13:29.432821\n",
      "resetting env. episode 1167, reward total was -19.0. running mean: -20.290445812263197, timestamp: 2022-08-19 20:13:33.214793\n",
      "resetting env. episode 1168, reward total was -21.0. running mean: -20.297541354140566, timestamp: 2022-08-19 20:13:36.168899\n",
      "resetting env. episode 1169, reward total was -21.0. running mean: -20.30456594059916, timestamp: 2022-08-19 20:13:40.052259\n",
      "resetting env. episode 1170, reward total was -21.0. running mean: -20.31152028119317, timestamp: 2022-08-19 20:13:45.556725\n",
      "resetting env. episode 1171, reward total was -21.0. running mean: -20.31840507838124, timestamp: 2022-08-19 20:13:49.053377\n",
      "resetting env. episode 1172, reward total was -20.0. running mean: -20.315221027597428, timestamp: 2022-08-19 20:13:52.420380\n",
      "resetting env. episode 1173, reward total was -21.0. running mean: -20.322068817321455, timestamp: 2022-08-19 20:13:57.482774\n",
      "resetting env. episode 1174, reward total was -21.0. running mean: -20.32884812914824, timestamp: 2022-08-19 20:14:00.192532\n",
      "resetting env. episode 1175, reward total was -21.0. running mean: -20.33555964785676, timestamp: 2022-08-19 20:14:02.703884\n",
      "resetting env. episode 1176, reward total was -21.0. running mean: -20.342204051378193, timestamp: 2022-08-19 20:14:06.852726\n",
      "resetting env. episode 1177, reward total was -20.0. running mean: -20.33878201086441, timestamp: 2022-08-19 20:14:10.562816\n",
      "resetting env. episode 1178, reward total was -21.0. running mean: -20.345394190755766, timestamp: 2022-08-19 20:14:13.245640\n",
      "resetting env. episode 1179, reward total was -20.0. running mean: -20.341940248848207, timestamp: 2022-08-19 20:14:16.923836\n",
      "resetting env. episode 1180, reward total was -21.0. running mean: -20.348520846359726, timestamp: 2022-08-19 20:14:19.682078\n",
      "resetting env. episode 1181, reward total was -19.0. running mean: -20.33503563789613, timestamp: 2022-08-19 20:14:22.799092\n",
      "resetting env. episode 1182, reward total was -21.0. running mean: -20.34168528151717, timestamp: 2022-08-19 20:14:25.541188\n",
      "resetting env. episode 1183, reward total was -20.0. running mean: -20.338268428701998, timestamp: 2022-08-19 20:14:28.243043\n",
      "resetting env. episode 1184, reward total was -21.0. running mean: -20.344885744414977, timestamp: 2022-08-19 20:14:31.166446\n",
      "resetting env. episode 1185, reward total was -21.0. running mean: -20.351436886970827, timestamp: 2022-08-19 20:14:34.126891\n",
      "resetting env. episode 1186, reward total was -21.0. running mean: -20.35792251810112, timestamp: 2022-08-19 20:14:37.378198\n",
      "resetting env. episode 1187, reward total was -21.0. running mean: -20.364343292920108, timestamp: 2022-08-19 20:14:39.554381\n",
      "resetting env. episode 1188, reward total was -19.0. running mean: -20.350699859990907, timestamp: 2022-08-19 20:14:43.298400\n",
      "resetting env. episode 1189, reward total was -21.0. running mean: -20.357192861391, timestamp: 2022-08-19 20:14:46.132776\n",
      "resetting env. episode 1190, reward total was -19.0. running mean: -20.34362093277709, timestamp: 2022-08-19 20:14:49.284569\n",
      "resetting env. episode 1191, reward total was -20.0. running mean: -20.340184723449315, timestamp: 2022-08-19 20:14:52.228811\n",
      "resetting env. episode 1192, reward total was -20.0. running mean: -20.336782876214823, timestamp: 2022-08-19 20:14:55.875050\n",
      "resetting env. episode 1193, reward total was -21.0. running mean: -20.343415047452677, timestamp: 2022-08-19 20:14:59.418139\n",
      "resetting env. episode 1194, reward total was -21.0. running mean: -20.34998089697815, timestamp: 2022-08-19 20:15:02.270380\n",
      "resetting env. episode 1195, reward total was -21.0. running mean: -20.35648108800837, timestamp: 2022-08-19 20:15:05.458422\n",
      "resetting env. episode 1196, reward total was -21.0. running mean: -20.362916277128285, timestamp: 2022-08-19 20:15:08.991834\n",
      "resetting env. episode 1197, reward total was -20.0. running mean: -20.359287114357002, timestamp: 2022-08-19 20:15:11.863157\n",
      "resetting env. episode 1198, reward total was -19.0. running mean: -20.345694243213433, timestamp: 2022-08-19 20:15:15.483048\n",
      "resetting env. episode 1199, reward total was -21.0. running mean: -20.3522373007813, timestamp: 2022-08-19 20:15:18.202534\n",
      "resetting env. episode 1200, reward total was -20.0. running mean: -20.348714927773486, timestamp: 2022-08-19 20:15:21.009820\n",
      "resetting env. episode 1201, reward total was -20.0. running mean: -20.34522777849575, timestamp: 2022-08-19 20:15:24.307433\n",
      "resetting env. episode 1202, reward total was -21.0. running mean: -20.351775500710794, timestamp: 2022-08-19 20:15:27.044100\n",
      "resetting env. episode 1203, reward total was -21.0. running mean: -20.358257745703686, timestamp: 2022-08-19 20:15:29.500527\n",
      "resetting env. episode 1204, reward total was -20.0. running mean: -20.354675168246647, timestamp: 2022-08-19 20:15:32.443660\n",
      "resetting env. episode 1205, reward total was -21.0. running mean: -20.36112841656418, timestamp: 2022-08-19 20:15:34.939001\n",
      "resetting env. episode 1206, reward total was -19.0. running mean: -20.34751713239854, timestamp: 2022-08-19 20:15:38.228019\n",
      "resetting env. episode 1207, reward total was -21.0. running mean: -20.354041961074554, timestamp: 2022-08-19 20:15:41.715504\n",
      "resetting env. episode 1208, reward total was -20.0. running mean: -20.350501541463807, timestamp: 2022-08-19 20:15:44.740491\n",
      "resetting env. episode 1209, reward total was -20.0. running mean: -20.346996526049168, timestamp: 2022-08-19 20:15:47.676606\n",
      "resetting env. episode 1210, reward total was -20.0. running mean: -20.343526560788675, timestamp: 2022-08-19 20:15:51.290294\n",
      "resetting env. episode 1211, reward total was -20.0. running mean: -20.340091295180788, timestamp: 2022-08-19 20:15:55.178957\n",
      "resetting env. episode 1212, reward total was -21.0. running mean: -20.34669038222898, timestamp: 2022-08-19 20:15:58.056424\n",
      "resetting env. episode 1213, reward total was -21.0. running mean: -20.353223478406694, timestamp: 2022-08-19 20:16:01.250509\n",
      "resetting env. episode 1214, reward total was -18.0. running mean: -20.329691243622626, timestamp: 2022-08-19 20:16:05.190983\n",
      "resetting env. episode 1215, reward total was -19.0. running mean: -20.3163943311864, timestamp: 2022-08-19 20:16:08.343793\n",
      "resetting env. episode 1216, reward total was -21.0. running mean: -20.32323038787454, timestamp: 2022-08-19 20:16:11.216749\n",
      "resetting env. episode 1217, reward total was -21.0. running mean: -20.329998083995793, timestamp: 2022-08-19 20:16:14.235646\n",
      "resetting env. episode 1218, reward total was -21.0. running mean: -20.336698103155836, timestamp: 2022-08-19 20:16:17.267511\n",
      "resetting env. episode 1219, reward total was -20.0. running mean: -20.333331122124278, timestamp: 2022-08-19 20:16:21.013276\n",
      "resetting env. episode 1220, reward total was -19.0. running mean: -20.319997810903036, timestamp: 2022-08-19 20:16:24.563814\n",
      "resetting env. episode 1221, reward total was -21.0. running mean: -20.326797832794007, timestamp: 2022-08-19 20:16:27.303020\n",
      "resetting env. episode 1222, reward total was -20.0. running mean: -20.323529854466067, timestamp: 2022-08-19 20:16:30.097551\n",
      "resetting env. episode 1223, reward total was -21.0. running mean: -20.330294555921405, timestamp: 2022-08-19 20:16:33.081858\n",
      "resetting env. episode 1224, reward total was -19.0. running mean: -20.31699161036219, timestamp: 2022-08-19 20:16:36.092675\n",
      "resetting env. episode 1225, reward total was -21.0. running mean: -20.32382169425857, timestamp: 2022-08-19 20:16:38.616104\n",
      "resetting env. episode 1226, reward total was -19.0. running mean: -20.310583477315983, timestamp: 2022-08-19 20:16:41.639376\n",
      "resetting env. episode 1227, reward total was -20.0. running mean: -20.30747764254282, timestamp: 2022-08-19 20:16:45.301913\n",
      "resetting env. episode 1228, reward total was -19.0. running mean: -20.294402866117395, timestamp: 2022-08-19 20:16:48.869971\n",
      "resetting env. episode 1229, reward total was -21.0. running mean: -20.30145883745622, timestamp: 2022-08-19 20:16:53.035482\n",
      "resetting env. episode 1230, reward total was -17.0. running mean: -20.26844424908166, timestamp: 2022-08-19 20:16:57.659696\n",
      "resetting env. episode 1231, reward total was -19.0. running mean: -20.255759806590845, timestamp: 2022-08-19 20:17:01.201227\n",
      "resetting env. episode 1232, reward total was -21.0. running mean: -20.263202208524937, timestamp: 2022-08-19 20:17:03.899019\n",
      "resetting env. episode 1233, reward total was -19.0. running mean: -20.25057018643969, timestamp: 2022-08-19 20:17:07.249181\n",
      "resetting env. episode 1234, reward total was -19.0. running mean: -20.238064484575293, timestamp: 2022-08-19 20:17:10.399765\n",
      "resetting env. episode 1235, reward total was -21.0. running mean: -20.24568383972954, timestamp: 2022-08-19 20:17:12.696622\n",
      "resetting env. episode 1236, reward total was -21.0. running mean: -20.253227001332245, timestamp: 2022-08-19 20:17:15.543016\n",
      "resetting env. episode 1237, reward total was -20.0. running mean: -20.250694731318923, timestamp: 2022-08-19 20:17:18.576533\n",
      "resetting env. episode 1238, reward total was -20.0. running mean: -20.248187784005733, timestamp: 2022-08-19 20:17:21.321925\n",
      "resetting env. episode 1239, reward total was -20.0. running mean: -20.245705906165675, timestamp: 2022-08-19 20:17:24.336108\n",
      "resetting env. episode 1240, reward total was -20.0. running mean: -20.243248847104017, timestamp: 2022-08-19 20:17:27.398913\n",
      "resetting env. episode 1241, reward total was -21.0. running mean: -20.250816358632978, timestamp: 2022-08-19 20:17:30.752375\n",
      "resetting env. episode 1242, reward total was -19.0. running mean: -20.23830819504665, timestamp: 2022-08-19 20:17:34.682993\n",
      "resetting env. episode 1243, reward total was -19.0. running mean: -20.225925113096185, timestamp: 2022-08-19 20:17:38.548763\n",
      "resetting env. episode 1244, reward total was -21.0. running mean: -20.233665861965225, timestamp: 2022-08-19 20:17:42.062883\n",
      "resetting env. episode 1245, reward total was -20.0. running mean: -20.23132920334557, timestamp: 2022-08-19 20:17:44.969087\n",
      "resetting env. episode 1246, reward total was -21.0. running mean: -20.239015911312116, timestamp: 2022-08-19 20:17:47.818486\n",
      "resetting env. episode 1247, reward total was -21.0. running mean: -20.246625752198995, timestamp: 2022-08-19 20:17:50.504268\n",
      "resetting env. episode 1248, reward total was -20.0. running mean: -20.244159494677003, timestamp: 2022-08-19 20:17:53.244607\n",
      "resetting env. episode 1249, reward total was -21.0. running mean: -20.251717899730235, timestamp: 2022-08-19 20:17:56.567993\n",
      "resetting env. episode 1250, reward total was -19.0. running mean: -20.239200720732935, timestamp: 2022-08-19 20:17:59.811028\n",
      "resetting env. episode 1251, reward total was -20.0. running mean: -20.236808713525605, timestamp: 2022-08-19 20:18:03.758762\n",
      "resetting env. episode 1252, reward total was -19.0. running mean: -20.22444062639035, timestamp: 2022-08-19 20:18:06.801441\n",
      "resetting env. episode 1253, reward total was -20.0. running mean: -20.222196220126445, timestamp: 2022-08-19 20:18:10.363772\n",
      "resetting env. episode 1254, reward total was -20.0. running mean: -20.21997425792518, timestamp: 2022-08-19 20:18:13.508363\n",
      "resetting env. episode 1255, reward total was -21.0. running mean: -20.227774515345928, timestamp: 2022-08-19 20:18:17.364801\n",
      "resetting env. episode 1256, reward total was -21.0. running mean: -20.23549677019247, timestamp: 2022-08-19 20:18:20.242180\n",
      "resetting env. episode 1257, reward total was -19.0. running mean: -20.223141802490545, timestamp: 2022-08-19 20:18:23.529481\n",
      "resetting env. episode 1258, reward total was -21.0. running mean: -20.23091038446564, timestamp: 2022-08-19 20:18:25.804971\n",
      "resetting env. episode 1259, reward total was -21.0. running mean: -20.238601280620987, timestamp: 2022-08-19 20:18:28.870102\n",
      "resetting env. episode 1260, reward total was -21.0. running mean: -20.246215267814776, timestamp: 2022-08-19 20:18:31.968421\n",
      "resetting env. episode 1261, reward total was -18.0. running mean: -20.223753115136628, timestamp: 2022-08-19 20:18:35.796635\n",
      "resetting env. episode 1262, reward total was -20.0. running mean: -20.221515583985262, timestamp: 2022-08-19 20:18:38.491542\n",
      "resetting env. episode 1263, reward total was -21.0. running mean: -20.22930042814541, timestamp: 2022-08-19 20:18:41.128325\n",
      "resetting env. episode 1264, reward total was -20.0. running mean: -20.227007423863956, timestamp: 2022-08-19 20:18:43.744958\n",
      "resetting env. episode 1265, reward total was -21.0. running mean: -20.234737349625316, timestamp: 2022-08-19 20:18:46.795399\n",
      "resetting env. episode 1266, reward total was -20.0. running mean: -20.232389976129063, timestamp: 2022-08-19 20:18:50.740325\n",
      "resetting env. episode 1267, reward total was -21.0. running mean: -20.240066076367775, timestamp: 2022-08-19 20:18:53.517714\n",
      "resetting env. episode 1268, reward total was -20.0. running mean: -20.237665415604095, timestamp: 2022-08-19 20:18:56.630289\n",
      "resetting env. episode 1269, reward total was -19.0. running mean: -20.225288761448056, timestamp: 2022-08-19 20:18:59.962288\n",
      "resetting env. episode 1270, reward total was -21.0. running mean: -20.233035873833575, timestamp: 2022-08-19 20:19:03.340308\n",
      "resetting env. episode 1271, reward total was -20.0. running mean: -20.230705515095238, timestamp: 2022-08-19 20:19:06.918888\n",
      "resetting env. episode 1272, reward total was -20.0. running mean: -20.228398459944284, timestamp: 2022-08-19 20:19:10.089042\n",
      "resetting env. episode 1273, reward total was -21.0. running mean: -20.23611447534484, timestamp: 2022-08-19 20:19:13.033166\n",
      "resetting env. episode 1274, reward total was -20.0. running mean: -20.23375333059139, timestamp: 2022-08-19 20:19:16.446855\n",
      "resetting env. episode 1275, reward total was -21.0. running mean: -20.241415797285477, timestamp: 2022-08-19 20:19:19.064855\n",
      "resetting env. episode 1276, reward total was -20.0. running mean: -20.239001639312622, timestamp: 2022-08-19 20:19:22.167838\n",
      "resetting env. episode 1277, reward total was -20.0. running mean: -20.236611622919494, timestamp: 2022-08-19 20:19:25.521814\n",
      "resetting env. episode 1278, reward total was -21.0. running mean: -20.244245506690298, timestamp: 2022-08-19 20:19:28.502006\n",
      "resetting env. episode 1279, reward total was -20.0. running mean: -20.241803051623393, timestamp: 2022-08-19 20:19:31.123943\n",
      "resetting env. episode 1280, reward total was -20.0. running mean: -20.239385021107157, timestamp: 2022-08-19 20:19:34.436299\n",
      "resetting env. episode 1281, reward total was -20.0. running mean: -20.236991170896086, timestamp: 2022-08-19 20:19:38.526358\n",
      "resetting env. episode 1282, reward total was -21.0. running mean: -20.244621259187127, timestamp: 2022-08-19 20:19:41.225112\n",
      "resetting env. episode 1283, reward total was -21.0. running mean: -20.252175046595255, timestamp: 2022-08-19 20:19:43.830184\n",
      "resetting env. episode 1284, reward total was -21.0. running mean: -20.259653296129304, timestamp: 2022-08-19 20:19:46.317531\n",
      "resetting env. episode 1285, reward total was -20.0. running mean: -20.25705676316801, timestamp: 2022-08-19 20:19:49.707720\n",
      "resetting env. episode 1286, reward total was -21.0. running mean: -20.26448619553633, timestamp: 2022-08-19 20:19:52.217159\n",
      "resetting env. episode 1287, reward total was -21.0. running mean: -20.271841333580966, timestamp: 2022-08-19 20:19:54.899972\n",
      "resetting env. episode 1288, reward total was -21.0. running mean: -20.279122920245158, timestamp: 2022-08-19 20:19:57.335151\n",
      "resetting env. episode 1289, reward total was -21.0. running mean: -20.286331691042708, timestamp: 2022-08-19 20:20:00.921563\n",
      "resetting env. episode 1290, reward total was -19.0. running mean: -20.273468374132282, timestamp: 2022-08-19 20:20:05.194023\n",
      "resetting env. episode 1291, reward total was -21.0. running mean: -20.28073369039096, timestamp: 2022-08-19 20:20:08.331448\n",
      "resetting env. episode 1292, reward total was -21.0. running mean: -20.28792635348705, timestamp: 2022-08-19 20:20:11.021291\n",
      "resetting env. episode 1293, reward total was -21.0. running mean: -20.29504708995218, timestamp: 2022-08-19 20:20:13.670189\n",
      "resetting env. episode 1294, reward total was -19.0. running mean: -20.28209661905266, timestamp: 2022-08-19 20:20:17.021328\n",
      "resetting env. episode 1295, reward total was -21.0. running mean: -20.289275652862134, timestamp: 2022-08-19 20:20:20.231595\n",
      "resetting env. episode 1296, reward total was -20.0. running mean: -20.28638289633351, timestamp: 2022-08-19 20:20:24.213973\n",
      "resetting env. episode 1297, reward total was -20.0. running mean: -20.283519067370175, timestamp: 2022-08-19 20:20:27.790983\n",
      "resetting env. episode 1298, reward total was -21.0. running mean: -20.290683876696473, timestamp: 2022-08-19 20:20:30.903676\n",
      "resetting env. episode 1299, reward total was -21.0. running mean: -20.29777703792951, timestamp: 2022-08-19 20:20:33.962343\n",
      "resetting env. episode 1300, reward total was -20.0. running mean: -20.294799267550214, timestamp: 2022-08-19 20:20:37.227454\n",
      "resetting env. episode 1301, reward total was -21.0. running mean: -20.301851274874714, timestamp: 2022-08-19 20:20:40.229453\n",
      "resetting env. episode 1302, reward total was -21.0. running mean: -20.308832762125967, timestamp: 2022-08-19 20:20:42.677582\n",
      "resetting env. episode 1303, reward total was -21.0. running mean: -20.31574443450471, timestamp: 2022-08-19 20:20:45.688717\n",
      "resetting env. episode 1304, reward total was -19.0. running mean: -20.30258699015966, timestamp: 2022-08-19 20:20:48.870527\n",
      "resetting env. episode 1305, reward total was -21.0. running mean: -20.309561120258063, timestamp: 2022-08-19 20:20:51.671008\n",
      "resetting env. episode 1306, reward total was -19.0. running mean: -20.296465509055484, timestamp: 2022-08-19 20:20:55.424638\n",
      "resetting env. episode 1307, reward total was -20.0. running mean: -20.29350085396493, timestamp: 2022-08-19 20:20:58.168344\n",
      "resetting env. episode 1308, reward total was -21.0. running mean: -20.30056584542528, timestamp: 2022-08-19 20:21:00.912001\n",
      "resetting env. episode 1309, reward total was -21.0. running mean: -20.307560186971028, timestamp: 2022-08-19 20:21:04.420395\n",
      "resetting env. episode 1310, reward total was -20.0. running mean: -20.304484585101317, timestamp: 2022-08-19 20:21:08.616604\n",
      "resetting env. episode 1311, reward total was -21.0. running mean: -20.311439739250304, timestamp: 2022-08-19 20:21:11.150988\n",
      "resetting env. episode 1312, reward total was -21.0. running mean: -20.3183253418578, timestamp: 2022-08-19 20:21:13.371052\n",
      "resetting env. episode 1313, reward total was -20.0. running mean: -20.31514208843922, timestamp: 2022-08-19 20:21:16.738253\n",
      "resetting env. episode 1314, reward total was -20.0. running mean: -20.311990667554827, timestamp: 2022-08-19 20:21:19.699337\n",
      "resetting env. episode 1315, reward total was -19.0. running mean: -20.29887076087928, timestamp: 2022-08-19 20:21:22.670449\n",
      "resetting env. episode 1316, reward total was -21.0. running mean: -20.305882053270487, timestamp: 2022-08-19 20:21:25.412097\n",
      "resetting env. episode 1317, reward total was -21.0. running mean: -20.312823232737784, timestamp: 2022-08-19 20:21:28.451543\n",
      "resetting env. episode 1318, reward total was -21.0. running mean: -20.31969500041041, timestamp: 2022-08-19 20:21:31.621141\n",
      "resetting env. episode 1319, reward total was -20.0. running mean: -20.316498050406302, timestamp: 2022-08-19 20:21:34.657995\n",
      "resetting env. episode 1320, reward total was -21.0. running mean: -20.32333306990224, timestamp: 2022-08-19 20:21:37.916314\n",
      "resetting env. episode 1321, reward total was -21.0. running mean: -20.33009973920322, timestamp: 2022-08-19 20:21:40.422568\n",
      "resetting env. episode 1322, reward total was -20.0. running mean: -20.32679874181119, timestamp: 2022-08-19 20:21:43.720286\n",
      "resetting env. episode 1323, reward total was -20.0. running mean: -20.323530754393076, timestamp: 2022-08-19 20:21:46.356570\n",
      "resetting env. episode 1324, reward total was -20.0. running mean: -20.320295446849144, timestamp: 2022-08-19 20:21:49.072570\n",
      "resetting env. episode 1325, reward total was -21.0. running mean: -20.327092492380654, timestamp: 2022-08-19 20:21:51.782321\n",
      "resetting env. episode 1326, reward total was -21.0. running mean: -20.333821567456848, timestamp: 2022-08-19 20:21:54.404435\n",
      "resetting env. episode 1327, reward total was -21.0. running mean: -20.34048335178228, timestamp: 2022-08-19 20:21:56.839248\n",
      "resetting env. episode 1328, reward total was -21.0. running mean: -20.347078518264457, timestamp: 2022-08-19 20:21:59.418678\n",
      "resetting env. episode 1329, reward total was -21.0. running mean: -20.353607733081812, timestamp: 2022-08-19 20:22:02.250162\n",
      "resetting env. episode 1330, reward total was -16.0. running mean: -20.310071655750995, timestamp: 2022-08-19 20:22:06.401012\n",
      "resetting env. episode 1331, reward total was -21.0. running mean: -20.316970939193485, timestamp: 2022-08-19 20:22:09.636352\n",
      "resetting env. episode 1332, reward total was -21.0. running mean: -20.32380122980155, timestamp: 2022-08-19 20:22:12.441849\n",
      "resetting env. episode 1333, reward total was -21.0. running mean: -20.330563217503535, timestamp: 2022-08-19 20:22:15.542936\n",
      "resetting env. episode 1334, reward total was -21.0. running mean: -20.3372575853285, timestamp: 2022-08-19 20:22:18.341002\n",
      "resetting env. episode 1335, reward total was -20.0. running mean: -20.333885009475214, timestamp: 2022-08-19 20:22:21.266026\n",
      "resetting env. episode 1336, reward total was -20.0. running mean: -20.33054615938046, timestamp: 2022-08-19 20:22:24.553050\n",
      "resetting env. episode 1337, reward total was -20.0. running mean: -20.327240697786657, timestamp: 2022-08-19 20:22:27.940451\n",
      "resetting env. episode 1338, reward total was -19.0. running mean: -20.31396829080879, timestamp: 2022-08-19 20:22:31.167824\n",
      "resetting env. episode 1339, reward total was -21.0. running mean: -20.320828607900705, timestamp: 2022-08-19 20:22:34.508892\n",
      "resetting env. episode 1340, reward total was -20.0. running mean: -20.317620321821696, timestamp: 2022-08-19 20:22:38.093064\n",
      "resetting env. episode 1341, reward total was -21.0. running mean: -20.32444411860348, timestamp: 2022-08-19 20:22:41.002279\n",
      "resetting env. episode 1342, reward total was -21.0. running mean: -20.331199677417448, timestamp: 2022-08-19 20:22:44.384336\n",
      "resetting env. episode 1343, reward total was -21.0. running mean: -20.337887680643274, timestamp: 2022-08-19 20:22:47.229027\n",
      "resetting env. episode 1344, reward total was -21.0. running mean: -20.344508803836842, timestamp: 2022-08-19 20:22:50.446427\n",
      "resetting env. episode 1345, reward total was -20.0. running mean: -20.341063715798473, timestamp: 2022-08-19 20:22:53.784505\n",
      "resetting env. episode 1346, reward total was -19.0. running mean: -20.327653078640488, timestamp: 2022-08-19 20:22:57.163371\n",
      "resetting env. episode 1347, reward total was -20.0. running mean: -20.324376547854083, timestamp: 2022-08-19 20:23:00.734590\n",
      "resetting env. episode 1348, reward total was -20.0. running mean: -20.321132782375543, timestamp: 2022-08-19 20:23:04.033586\n",
      "resetting env. episode 1349, reward total was -20.0. running mean: -20.317921454551787, timestamp: 2022-08-19 20:23:07.634962\n",
      "resetting env. episode 1350, reward total was -20.0. running mean: -20.314742240006268, timestamp: 2022-08-19 20:23:11.201796\n",
      "resetting env. episode 1351, reward total was -20.0. running mean: -20.311594817606206, timestamp: 2022-08-19 20:23:14.398693\n",
      "resetting env. episode 1352, reward total was -21.0. running mean: -20.318478869430145, timestamp: 2022-08-19 20:23:17.742871\n",
      "resetting env. episode 1353, reward total was -18.0. running mean: -20.295294080735843, timestamp: 2022-08-19 20:23:21.094914\n",
      "resetting env. episode 1354, reward total was -21.0. running mean: -20.302341139928487, timestamp: 2022-08-19 20:23:23.388781\n",
      "resetting env. episode 1355, reward total was -21.0. running mean: -20.3093177285292, timestamp: 2022-08-19 20:23:26.035167\n",
      "resetting env. episode 1356, reward total was -21.0. running mean: -20.31622455124391, timestamp: 2022-08-19 20:23:28.719991\n",
      "resetting env. episode 1357, reward total was -20.0. running mean: -20.31306230573147, timestamp: 2022-08-19 20:23:31.279158\n",
      "resetting env. episode 1358, reward total was -21.0. running mean: -20.319931682674156, timestamp: 2022-08-19 20:23:34.703991\n",
      "resetting env. episode 1359, reward total was -19.0. running mean: -20.306732365847417, timestamp: 2022-08-19 20:23:38.079560\n",
      "resetting env. episode 1360, reward total was -21.0. running mean: -20.313665042188944, timestamp: 2022-08-19 20:23:40.783653\n",
      "resetting env. episode 1361, reward total was -20.0. running mean: -20.310528391767054, timestamp: 2022-08-19 20:23:43.765497\n",
      "resetting env. episode 1362, reward total was -20.0. running mean: -20.30742310784938, timestamp: 2022-08-19 20:23:46.856848\n",
      "resetting env. episode 1363, reward total was -20.0. running mean: -20.304348876770888, timestamp: 2022-08-19 20:23:50.353480\n",
      "resetting env. episode 1364, reward total was -21.0. running mean: -20.31130538800318, timestamp: 2022-08-19 20:23:52.849801\n",
      "resetting env. episode 1365, reward total was -20.0. running mean: -20.30819233412315, timestamp: 2022-08-19 20:23:55.783967\n",
      "resetting env. episode 1366, reward total was -21.0. running mean: -20.31511041078192, timestamp: 2022-08-19 20:23:59.145883\n",
      "resetting env. episode 1367, reward total was -21.0. running mean: -20.3219593066741, timestamp: 2022-08-19 20:24:02.002242\n",
      "resetting env. episode 1368, reward total was -20.0. running mean: -20.318739713607357, timestamp: 2022-08-19 20:24:06.259377\n",
      "resetting env. episode 1369, reward total was -21.0. running mean: -20.325552316471285, timestamp: 2022-08-19 20:24:09.996329\n",
      "resetting env. episode 1370, reward total was -20.0. running mean: -20.32229679330657, timestamp: 2022-08-19 20:24:13.884529\n",
      "resetting env. episode 1371, reward total was -20.0. running mean: -20.319073825373504, timestamp: 2022-08-19 20:24:18.468739\n",
      "resetting env. episode 1372, reward total was -21.0. running mean: -20.32588308711977, timestamp: 2022-08-19 20:24:22.097025\n",
      "resetting env. episode 1373, reward total was -21.0. running mean: -20.33262425624857, timestamp: 2022-08-19 20:24:25.858622\n",
      "resetting env. episode 1374, reward total was -21.0. running mean: -20.339298013686086, timestamp: 2022-08-19 20:24:29.125889\n",
      "resetting env. episode 1375, reward total was -21.0. running mean: -20.345905033549226, timestamp: 2022-08-19 20:24:34.055708\n",
      "resetting env. episode 1376, reward total was -21.0. running mean: -20.352445983213734, timestamp: 2022-08-19 20:24:38.281420\n",
      "resetting env. episode 1377, reward total was -20.0. running mean: -20.348921523381595, timestamp: 2022-08-19 20:24:42.001465\n",
      "resetting env. episode 1378, reward total was -21.0. running mean: -20.35543230814778, timestamp: 2022-08-19 20:24:45.574910\n",
      "resetting env. episode 1379, reward total was -21.0. running mean: -20.361877985066304, timestamp: 2022-08-19 20:24:49.046213\n",
      "resetting env. episode 1380, reward total was -19.0. running mean: -20.34825920521564, timestamp: 2022-08-19 20:24:52.510945\n",
      "resetting env. episode 1381, reward total was -20.0. running mean: -20.344776613163482, timestamp: 2022-08-19 20:24:56.637278\n",
      "resetting env. episode 1382, reward total was -18.0. running mean: -20.321328847031847, timestamp: 2022-08-19 20:25:02.697768\n",
      "resetting env. episode 1383, reward total was -17.0. running mean: -20.28811555856153, timestamp: 2022-08-19 20:25:13.057078\n",
      "resetting env. episode 1384, reward total was -20.0. running mean: -20.285234402975913, timestamp: 2022-08-19 20:25:19.909308\n",
      "resetting env. episode 1385, reward total was -19.0. running mean: -20.272382058946157, timestamp: 2022-08-19 20:25:24.574833\n",
      "resetting env. episode 1386, reward total was -20.0. running mean: -20.269658238356694, timestamp: 2022-08-19 20:25:27.818762\n",
      "resetting env. episode 1387, reward total was -21.0. running mean: -20.27696165597313, timestamp: 2022-08-19 20:25:30.734953\n",
      "resetting env. episode 1388, reward total was -21.0. running mean: -20.284192039413398, timestamp: 2022-08-19 20:25:33.418936\n",
      "resetting env. episode 1389, reward total was -20.0. running mean: -20.28135011901926, timestamp: 2022-08-19 20:25:36.358622\n",
      "resetting env. episode 1390, reward total was -19.0. running mean: -20.26853661782907, timestamp: 2022-08-19 20:25:40.471613\n",
      "resetting env. episode 1391, reward total was -19.0. running mean: -20.255851251650782, timestamp: 2022-08-19 20:25:45.559015\n",
      "resetting env. episode 1392, reward total was -21.0. running mean: -20.263292739134275, timestamp: 2022-08-19 20:25:48.577943\n",
      "resetting env. episode 1393, reward total was -21.0. running mean: -20.270659811742934, timestamp: 2022-08-19 20:25:52.643112\n",
      "resetting env. episode 1394, reward total was -20.0. running mean: -20.267953213625503, timestamp: 2022-08-19 20:25:56.869807\n",
      "resetting env. episode 1395, reward total was -21.0. running mean: -20.27527368148925, timestamp: 2022-08-19 20:26:00.832189\n",
      "resetting env. episode 1396, reward total was -21.0. running mean: -20.282520944674356, timestamp: 2022-08-19 20:26:04.799623\n",
      "resetting env. episode 1397, reward total was -20.0. running mean: -20.279695735227612, timestamp: 2022-08-19 20:26:09.250710\n",
      "resetting env. episode 1398, reward total was -21.0. running mean: -20.286898777875336, timestamp: 2022-08-19 20:26:13.064494\n",
      "resetting env. episode 1399, reward total was -20.0. running mean: -20.284029790096582, timestamp: 2022-08-19 20:26:16.650729\n",
      "resetting env. episode 1400, reward total was -21.0. running mean: -20.291189492195617, timestamp: 2022-08-19 20:26:21.931356\n",
      "resetting env. episode 1401, reward total was -21.0. running mean: -20.29827759727366, timestamp: 2022-08-19 20:26:25.544493\n",
      "resetting env. episode 1402, reward total was -19.0. running mean: -20.285294821300926, timestamp: 2022-08-19 20:26:29.133889\n",
      "resetting env. episode 1403, reward total was -21.0. running mean: -20.292441873087917, timestamp: 2022-08-19 20:26:31.669111\n",
      "resetting env. episode 1404, reward total was -20.0. running mean: -20.289517454357036, timestamp: 2022-08-19 20:26:35.236578\n",
      "resetting env. episode 1405, reward total was -21.0. running mean: -20.296622279813466, timestamp: 2022-08-19 20:26:38.648335\n",
      "resetting env. episode 1406, reward total was -20.0. running mean: -20.29365605701533, timestamp: 2022-08-19 20:26:41.948099\n",
      "resetting env. episode 1407, reward total was -21.0. running mean: -20.300719496445176, timestamp: 2022-08-19 20:26:47.387395\n",
      "resetting env. episode 1408, reward total was -21.0. running mean: -20.307712301480723, timestamp: 2022-08-19 20:26:53.840166\n",
      "resetting env. episode 1409, reward total was -20.0. running mean: -20.304635178465915, timestamp: 2022-08-19 20:27:00.380403\n",
      "resetting env. episode 1410, reward total was -20.0. running mean: -20.301588826681254, timestamp: 2022-08-19 20:27:06.299765\n",
      "resetting env. episode 1411, reward total was -21.0. running mean: -20.308572938414443, timestamp: 2022-08-19 20:27:11.825013\n",
      "resetting env. episode 1412, reward total was -21.0. running mean: -20.315487209030298, timestamp: 2022-08-19 20:27:18.133132\n",
      "resetting env. episode 1413, reward total was -21.0. running mean: -20.322332336939997, timestamp: 2022-08-19 20:27:22.404714\n",
      "resetting env. episode 1414, reward total was -21.0. running mean: -20.329109013570598, timestamp: 2022-08-19 20:27:27.794305\n",
      "resetting env. episode 1415, reward total was -20.0. running mean: -20.32581792343489, timestamp: 2022-08-19 20:27:31.302938\n",
      "resetting env. episode 1416, reward total was -21.0. running mean: -20.33255974420054, timestamp: 2022-08-19 20:27:35.498713\n",
      "resetting env. episode 1417, reward total was -21.0. running mean: -20.339234146758535, timestamp: 2022-08-19 20:27:38.551626\n",
      "resetting env. episode 1418, reward total was -21.0. running mean: -20.345841805290952, timestamp: 2022-08-19 20:27:41.346127\n",
      "resetting env. episode 1419, reward total was -20.0. running mean: -20.34238338723804, timestamp: 2022-08-19 20:27:45.347173\n",
      "resetting env. episode 1420, reward total was -20.0. running mean: -20.338959553365658, timestamp: 2022-08-19 20:27:49.324538\n",
      "resetting env. episode 1421, reward total was -18.0. running mean: -20.315569957832, timestamp: 2022-08-19 20:27:52.831097\n",
      "resetting env. episode 1422, reward total was -21.0. running mean: -20.32241425825368, timestamp: 2022-08-19 20:27:56.030535\n",
      "resetting env. episode 1423, reward total was -21.0. running mean: -20.329190115671143, timestamp: 2022-08-19 20:27:59.114292\n",
      "resetting env. episode 1424, reward total was -19.0. running mean: -20.315898214514434, timestamp: 2022-08-19 20:28:02.835867\n",
      "resetting env. episode 1425, reward total was -21.0. running mean: -20.32273923236929, timestamp: 2022-08-19 20:28:05.575552\n",
      "resetting env. episode 1426, reward total was -19.0. running mean: -20.309511840045598, timestamp: 2022-08-19 20:28:08.720344\n",
      "resetting env. episode 1427, reward total was -21.0. running mean: -20.316416721645144, timestamp: 2022-08-19 20:28:11.719332\n",
      "resetting env. episode 1428, reward total was -20.0. running mean: -20.31325255442869, timestamp: 2022-08-19 20:28:15.651030\n",
      "resetting env. episode 1429, reward total was -20.0. running mean: -20.310120028884402, timestamp: 2022-08-19 20:28:19.478978\n",
      "resetting env. episode 1430, reward total was -21.0. running mean: -20.317018828595558, timestamp: 2022-08-19 20:28:22.879883\n",
      "resetting env. episode 1431, reward total was -21.0. running mean: -20.323848640309603, timestamp: 2022-08-19 20:28:25.995557\n",
      "resetting env. episode 1432, reward total was -20.0. running mean: -20.320610153906507, timestamp: 2022-08-19 20:28:28.980578\n",
      "resetting env. episode 1433, reward total was -21.0. running mean: -20.32740405236744, timestamp: 2022-08-19 20:28:32.715221\n",
      "resetting env. episode 1434, reward total was -18.0. running mean: -20.304130011843768, timestamp: 2022-08-19 20:28:36.396324\n",
      "resetting env. episode 1435, reward total was -20.0. running mean: -20.301088711725328, timestamp: 2022-08-19 20:28:40.392629\n",
      "resetting env. episode 1436, reward total was -21.0. running mean: -20.308077824608073, timestamp: 2022-08-19 20:28:43.965112\n",
      "resetting env. episode 1437, reward total was -20.0. running mean: -20.30499704636199, timestamp: 2022-08-19 20:28:48.052304\n",
      "resetting env. episode 1438, reward total was -21.0. running mean: -20.31194707589837, timestamp: 2022-08-19 20:28:52.347822\n",
      "resetting env. episode 1439, reward total was -20.0. running mean: -20.308827605139385, timestamp: 2022-08-19 20:28:56.325867\n",
      "resetting env. episode 1440, reward total was -21.0. running mean: -20.315739329087993, timestamp: 2022-08-19 20:28:59.428575\n",
      "resetting env. episode 1441, reward total was -21.0. running mean: -20.322581935797114, timestamp: 2022-08-19 20:29:03.490920\n",
      "resetting env. episode 1442, reward total was -18.0. running mean: -20.299356116439142, timestamp: 2022-08-19 20:29:08.131514\n",
      "resetting env. episode 1443, reward total was -20.0. running mean: -20.29636255527475, timestamp: 2022-08-19 20:29:13.065632\n",
      "resetting env. episode 1444, reward total was -21.0. running mean: -20.303398929722004, timestamp: 2022-08-19 20:29:16.177313\n",
      "resetting env. episode 1445, reward total was -21.0. running mean: -20.310364940424783, timestamp: 2022-08-19 20:29:20.279354\n",
      "resetting env. episode 1446, reward total was -19.0. running mean: -20.297261291020536, timestamp: 2022-08-19 20:29:24.884148\n",
      "resetting env. episode 1447, reward total was -18.0. running mean: -20.27428867811033, timestamp: 2022-08-19 20:29:29.789021\n",
      "resetting env. episode 1448, reward total was -21.0. running mean: -20.28154579132923, timestamp: 2022-08-19 20:29:33.830221\n",
      "resetting env. episode 1449, reward total was -21.0. running mean: -20.288730333415938, timestamp: 2022-08-19 20:29:36.749444\n",
      "resetting env. episode 1450, reward total was -20.0. running mean: -20.28584303008178, timestamp: 2022-08-19 20:29:39.890035\n",
      "resetting env. episode 1451, reward total was -18.0. running mean: -20.26298459978096, timestamp: 2022-08-19 20:29:46.821494\n",
      "resetting env. episode 1452, reward total was -20.0. running mean: -20.26035475378315, timestamp: 2022-08-19 20:29:50.986394\n",
      "resetting env. episode 1453, reward total was -21.0. running mean: -20.267751206245322, timestamp: 2022-08-19 20:29:55.294002\n",
      "resetting env. episode 1454, reward total was -21.0. running mean: -20.27507369418287, timestamp: 2022-08-19 20:29:58.388887\n",
      "resetting env. episode 1455, reward total was -21.0. running mean: -20.28232295724104, timestamp: 2022-08-19 20:30:01.016695\n",
      "resetting env. episode 1456, reward total was -20.0. running mean: -20.27949972766863, timestamp: 2022-08-19 20:30:04.602229\n",
      "resetting env. episode 1457, reward total was -21.0. running mean: -20.286704730391943, timestamp: 2022-08-19 20:30:07.627554\n",
      "resetting env. episode 1458, reward total was -21.0. running mean: -20.293837683088025, timestamp: 2022-08-19 20:30:11.163103\n",
      "resetting env. episode 1459, reward total was -21.0. running mean: -20.300899306257147, timestamp: 2022-08-19 20:30:14.470264\n",
      "resetting env. episode 1460, reward total was -19.0. running mean: -20.287890313194577, timestamp: 2022-08-19 20:30:17.664476\n",
      "resetting env. episode 1461, reward total was -21.0. running mean: -20.29501141006263, timestamp: 2022-08-19 20:30:21.185299\n",
      "resetting env. episode 1462, reward total was -19.0. running mean: -20.282061295962006, timestamp: 2022-08-19 20:30:25.440890\n",
      "resetting env. episode 1463, reward total was -20.0. running mean: -20.279240683002385, timestamp: 2022-08-19 20:30:29.232249\n",
      "resetting env. episode 1464, reward total was -21.0. running mean: -20.28644827617236, timestamp: 2022-08-19 20:30:33.157171\n",
      "resetting env. episode 1465, reward total was -20.0. running mean: -20.28358379341064, timestamp: 2022-08-19 20:30:36.588882\n",
      "resetting env. episode 1466, reward total was -21.0. running mean: -20.290747955476533, timestamp: 2022-08-19 20:30:39.557976\n",
      "resetting env. episode 1467, reward total was -20.0. running mean: -20.287840475921765, timestamp: 2022-08-19 20:30:43.656416\n",
      "resetting env. episode 1468, reward total was -20.0. running mean: -20.284962071162546, timestamp: 2022-08-19 20:30:47.028405\n",
      "resetting env. episode 1469, reward total was -21.0. running mean: -20.292112450450922, timestamp: 2022-08-19 20:30:50.056340\n",
      "resetting env. episode 1470, reward total was -21.0. running mean: -20.299191325946413, timestamp: 2022-08-19 20:30:53.216920\n",
      "resetting env. episode 1471, reward total was -21.0. running mean: -20.30619941268695, timestamp: 2022-08-19 20:30:56.968311\n",
      "resetting env. episode 1472, reward total was -20.0. running mean: -20.30313741856008, timestamp: 2022-08-19 20:31:02.106580\n",
      "resetting env. episode 1473, reward total was -21.0. running mean: -20.31010604437448, timestamp: 2022-08-19 20:31:06.002168\n",
      "resetting env. episode 1474, reward total was -21.0. running mean: -20.317004983930733, timestamp: 2022-08-19 20:31:09.800067\n",
      "resetting env. episode 1475, reward total was -21.0. running mean: -20.323834934091426, timestamp: 2022-08-19 20:31:13.766630\n",
      "resetting env. episode 1476, reward total was -20.0. running mean: -20.32059658475051, timestamp: 2022-08-19 20:31:16.916211\n",
      "resetting env. episode 1477, reward total was -21.0. running mean: -20.327390618903006, timestamp: 2022-08-19 20:31:19.630394\n",
      "resetting env. episode 1478, reward total was -20.0. running mean: -20.324116712713977, timestamp: 2022-08-19 20:31:22.245523\n",
      "resetting env. episode 1479, reward total was -20.0. running mean: -20.320875545586837, timestamp: 2022-08-19 20:31:24.952097\n",
      "resetting env. episode 1480, reward total was -21.0. running mean: -20.32766679013097, timestamp: 2022-08-19 20:31:27.192150\n",
      "resetting env. episode 1481, reward total was -20.0. running mean: -20.32439012222966, timestamp: 2022-08-19 20:31:29.599628\n",
      "resetting env. episode 1482, reward total was -21.0. running mean: -20.331146221007362, timestamp: 2022-08-19 20:31:31.900704\n",
      "resetting env. episode 1483, reward total was -21.0. running mean: -20.33783475879729, timestamp: 2022-08-19 20:31:34.480808\n",
      "resetting env. episode 1484, reward total was -21.0. running mean: -20.34445641120932, timestamp: 2022-08-19 20:31:37.550520\n",
      "resetting env. episode 1485, reward total was -21.0. running mean: -20.351011847097226, timestamp: 2022-08-19 20:31:40.808813\n",
      "resetting env. episode 1486, reward total was -20.0. running mean: -20.347501728626252, timestamp: 2022-08-19 20:31:44.528778\n",
      "resetting env. episode 1487, reward total was -19.0. running mean: -20.33402671133999, timestamp: 2022-08-19 20:31:49.323006\n",
      "resetting env. episode 1488, reward total was -21.0. running mean: -20.34068644422659, timestamp: 2022-08-19 20:31:53.511162\n",
      "resetting env. episode 1489, reward total was -18.0. running mean: -20.317279579784326, timestamp: 2022-08-19 20:31:58.978612\n",
      "resetting env. episode 1490, reward total was -20.0. running mean: -20.31410678398648, timestamp: 2022-08-19 20:32:03.434700\n",
      "resetting env. episode 1491, reward total was -21.0. running mean: -20.320965716146617, timestamp: 2022-08-19 20:32:06.615317\n",
      "resetting env. episode 1492, reward total was -21.0. running mean: -20.327756058985152, timestamp: 2022-08-19 20:32:10.811106\n",
      "resetting env. episode 1493, reward total was -20.0. running mean: -20.3244784983953, timestamp: 2022-08-19 20:32:14.905171\n",
      "resetting env. episode 1494, reward total was -21.0. running mean: -20.331233713411347, timestamp: 2022-08-19 20:32:19.138339\n",
      "resetting env. episode 1495, reward total was -21.0. running mean: -20.337921376277233, timestamp: 2022-08-19 20:32:24.017320\n",
      "resetting env. episode 1496, reward total was -21.0. running mean: -20.34454216251446, timestamp: 2022-08-19 20:32:29.085761\n",
      "resetting env. episode 1497, reward total was -20.0. running mean: -20.341096740889316, timestamp: 2022-08-19 20:32:34.894137\n",
      "resetting env. episode 1498, reward total was -19.0. running mean: -20.327685773480425, timestamp: 2022-08-19 20:32:39.758136\n",
      "resetting env. episode 1499, reward total was -20.0. running mean: -20.32440891574562, timestamp: 2022-08-19 20:32:42.796016\n",
      "resetting env. episode 1500, reward total was -20.0. running mean: -20.321164826588163, timestamp: 2022-08-19 20:32:47.086587\n",
      "resetting env. episode 1501, reward total was -20.0. running mean: -20.31795317832228, timestamp: 2022-08-19 20:32:50.677948\n",
      "resetting env. episode 1502, reward total was -20.0. running mean: -20.314773646539056, timestamp: 2022-08-19 20:32:53.637036\n",
      "resetting env. episode 1503, reward total was -19.0. running mean: -20.301625910073668, timestamp: 2022-08-19 20:32:58.248712\n",
      "resetting env. episode 1504, reward total was -20.0. running mean: -20.29860965097293, timestamp: 2022-08-19 20:33:02.051559\n",
      "resetting env. episode 1505, reward total was -21.0. running mean: -20.305623554463203, timestamp: 2022-08-19 20:33:05.881877\n",
      "resetting env. episode 1506, reward total was -20.0. running mean: -20.30256731891857, timestamp: 2022-08-19 20:33:10.892482\n",
      "resetting env. episode 1507, reward total was -21.0. running mean: -20.309541645729386, timestamp: 2022-08-19 20:33:16.019777\n",
      "resetting env. episode 1508, reward total was -21.0. running mean: -20.316446229272092, timestamp: 2022-08-19 20:33:21.019411\n",
      "resetting env. episode 1509, reward total was -19.0. running mean: -20.30328176697937, timestamp: 2022-08-19 20:33:24.128108\n",
      "resetting env. episode 1510, reward total was -19.0. running mean: -20.29024894930958, timestamp: 2022-08-19 20:33:27.132071\n",
      "resetting env. episode 1511, reward total was -21.0. running mean: -20.297346459816485, timestamp: 2022-08-19 20:33:30.160280\n",
      "resetting env. episode 1512, reward total was -20.0. running mean: -20.294372995218318, timestamp: 2022-08-19 20:33:32.663001\n",
      "resetting env. episode 1513, reward total was -21.0. running mean: -20.301429265266137, timestamp: 2022-08-19 20:33:35.069086\n",
      "resetting env. episode 1514, reward total was -20.0. running mean: -20.298414972613475, timestamp: 2022-08-19 20:33:37.939979\n",
      "resetting env. episode 1515, reward total was -20.0. running mean: -20.29543082288734, timestamp: 2022-08-19 20:33:40.361175\n",
      "resetting env. episode 1516, reward total was -21.0. running mean: -20.30247651465847, timestamp: 2022-08-19 20:33:43.191545\n",
      "resetting env. episode 1517, reward total was -20.0. running mean: -20.299451749511885, timestamp: 2022-08-19 20:33:45.842418\n",
      "resetting env. episode 1518, reward total was -20.0. running mean: -20.296457232016767, timestamp: 2022-08-19 20:33:48.371369\n",
      "resetting env. episode 1519, reward total was -21.0. running mean: -20.303492659696598, timestamp: 2022-08-19 20:33:51.905590\n",
      "resetting env. episode 1520, reward total was -19.0. running mean: -20.290457733099633, timestamp: 2022-08-19 20:33:56.400575\n",
      "resetting env. episode 1521, reward total was -17.0. running mean: -20.257553155768637, timestamp: 2022-08-19 20:34:01.305279\n",
      "resetting env. episode 1522, reward total was -18.0. running mean: -20.23497762421095, timestamp: 2022-08-19 20:34:05.227888\n",
      "resetting env. episode 1523, reward total was -20.0. running mean: -20.23262784796884, timestamp: 2022-08-19 20:34:08.409386\n",
      "resetting env. episode 1524, reward total was -18.0. running mean: -20.21030156948915, timestamp: 2022-08-19 20:34:12.970193\n",
      "resetting env. episode 1525, reward total was -21.0. running mean: -20.21819855379426, timestamp: 2022-08-19 20:34:15.703408\n",
      "resetting env. episode 1526, reward total was -21.0. running mean: -20.226016568256316, timestamp: 2022-08-19 20:34:18.734591\n",
      "resetting env. episode 1527, reward total was -21.0. running mean: -20.233756402573754, timestamp: 2022-08-19 20:34:21.219331\n",
      "resetting env. episode 1528, reward total was -18.0. running mean: -20.211418838548017, timestamp: 2022-08-19 20:34:24.718358\n",
      "resetting env. episode 1529, reward total was -19.0. running mean: -20.19930465016254, timestamp: 2022-08-19 20:34:28.132359\n",
      "resetting env. episode 1530, reward total was -21.0. running mean: -20.207311603660912, timestamp: 2022-08-19 20:34:30.236234\n",
      "resetting env. episode 1531, reward total was -21.0. running mean: -20.215238487624305, timestamp: 2022-08-19 20:34:33.085359\n",
      "resetting env. episode 1532, reward total was -20.0. running mean: -20.21308610274806, timestamp: 2022-08-19 20:34:36.113859\n",
      "resetting env. episode 1533, reward total was -21.0. running mean: -20.22095524172058, timestamp: 2022-08-19 20:34:39.209792\n",
      "resetting env. episode 1534, reward total was -21.0. running mean: -20.228745689303377, timestamp: 2022-08-19 20:34:41.768528\n",
      "resetting env. episode 1535, reward total was -21.0. running mean: -20.236458232410342, timestamp: 2022-08-19 20:34:44.193427\n",
      "resetting env. episode 1536, reward total was -21.0. running mean: -20.24409365008624, timestamp: 2022-08-19 20:34:46.546803\n",
      "resetting env. episode 1537, reward total was -21.0. running mean: -20.251652713585376, timestamp: 2022-08-19 20:34:49.723230\n",
      "resetting env. episode 1538, reward total was -21.0. running mean: -20.259136186449524, timestamp: 2022-08-19 20:34:52.370126\n",
      "resetting env. episode 1539, reward total was -21.0. running mean: -20.26654482458503, timestamp: 2022-08-19 20:34:55.039802\n",
      "resetting env. episode 1540, reward total was -20.0. running mean: -20.26387937633918, timestamp: 2022-08-19 20:34:58.422760\n",
      "resetting env. episode 1541, reward total was -20.0. running mean: -20.261240582575788, timestamp: 2022-08-19 20:35:01.644552\n",
      "resetting env. episode 1542, reward total was -20.0. running mean: -20.25862817675003, timestamp: 2022-08-19 20:35:05.438658\n",
      "resetting env. episode 1543, reward total was -19.0. running mean: -20.24604189498253, timestamp: 2022-08-19 20:35:11.332252\n",
      "resetting env. episode 1544, reward total was -20.0. running mean: -20.243581476032702, timestamp: 2022-08-19 20:35:15.368461\n",
      "resetting env. episode 1545, reward total was -21.0. running mean: -20.251145661272375, timestamp: 2022-08-19 20:35:18.766377\n",
      "resetting env. episode 1546, reward total was -21.0. running mean: -20.258634204659653, timestamp: 2022-08-19 20:35:21.615804\n",
      "resetting env. episode 1547, reward total was -19.0. running mean: -20.246047862613057, timestamp: 2022-08-19 20:35:26.366132\n",
      "resetting env. episode 1548, reward total was -21.0. running mean: -20.25358738398693, timestamp: 2022-08-19 20:35:29.862970\n",
      "resetting env. episode 1549, reward total was -19.0. running mean: -20.24105151014706, timestamp: 2022-08-19 20:35:33.155461\n",
      "resetting env. episode 1550, reward total was -19.0. running mean: -20.22864099504559, timestamp: 2022-08-19 20:35:37.171242\n",
      "resetting env. episode 1551, reward total was -20.0. running mean: -20.226354585095134, timestamp: 2022-08-19 20:35:42.075260\n",
      "resetting env. episode 1552, reward total was -21.0. running mean: -20.234091039244184, timestamp: 2022-08-19 20:35:46.346869\n",
      "resetting env. episode 1553, reward total was -21.0. running mean: -20.24175012885174, timestamp: 2022-08-19 20:35:51.140027\n",
      "resetting env. episode 1554, reward total was -21.0. running mean: -20.249332627563223, timestamp: 2022-08-19 20:35:55.207157\n",
      "resetting env. episode 1555, reward total was -19.0. running mean: -20.236839301287592, timestamp: 2022-08-19 20:36:00.535912\n",
      "resetting env. episode 1556, reward total was -21.0. running mean: -20.244470908274717, timestamp: 2022-08-19 20:36:04.645388\n",
      "resetting env. episode 1557, reward total was -21.0. running mean: -20.25202619919197, timestamp: 2022-08-19 20:36:07.530214\n",
      "resetting env. episode 1558, reward total was -20.0. running mean: -20.24950593720005, timestamp: 2022-08-19 20:36:11.652200\n",
      "resetting env. episode 1559, reward total was -21.0. running mean: -20.257010877828048, timestamp: 2022-08-19 20:36:15.177777\n",
      "resetting env. episode 1560, reward total was -18.0. running mean: -20.234440769049765, timestamp: 2022-08-19 20:36:19.143456\n",
      "resetting env. episode 1561, reward total was -21.0. running mean: -20.24209636135927, timestamp: 2022-08-19 20:36:22.361166\n",
      "resetting env. episode 1562, reward total was -20.0. running mean: -20.239675397745675, timestamp: 2022-08-19 20:36:25.694258\n",
      "resetting env. episode 1563, reward total was -20.0. running mean: -20.237278643768217, timestamp: 2022-08-19 20:36:28.558603\n",
      "resetting env. episode 1564, reward total was -18.0. running mean: -20.214905857330535, timestamp: 2022-08-19 20:36:32.219861\n",
      "resetting env. episode 1565, reward total was -21.0. running mean: -20.22275679875723, timestamp: 2022-08-19 20:36:35.255748\n",
      "resetting env. episode 1566, reward total was -21.0. running mean: -20.23052923076966, timestamp: 2022-08-19 20:36:38.053269\n",
      "resetting env. episode 1567, reward total was -21.0. running mean: -20.238223938461964, timestamp: 2022-08-19 20:36:41.194540\n",
      "resetting env. episode 1568, reward total was -21.0. running mean: -20.245841699077346, timestamp: 2022-08-19 20:36:44.225943\n",
      "resetting env. episode 1569, reward total was -20.0. running mean: -20.243383282086572, timestamp: 2022-08-19 20:36:48.624188\n",
      "resetting env. episode 1570, reward total was -21.0. running mean: -20.250949449265708, timestamp: 2022-08-19 20:36:53.686655\n",
      "resetting env. episode 1571, reward total was -20.0. running mean: -20.24843995477305, timestamp: 2022-08-19 20:36:57.763757\n",
      "resetting env. episode 1572, reward total was -21.0. running mean: -20.25595555522532, timestamp: 2022-08-19 20:37:02.145845\n",
      "resetting env. episode 1573, reward total was -18.0. running mean: -20.233395999673068, timestamp: 2022-08-19 20:37:06.198347\n",
      "resetting env. episode 1574, reward total was -21.0. running mean: -20.241062039676336, timestamp: 2022-08-19 20:37:10.856897\n",
      "resetting env. episode 1575, reward total was -21.0. running mean: -20.248651419279575, timestamp: 2022-08-19 20:37:16.423031\n",
      "resetting env. episode 1576, reward total was -18.0. running mean: -20.22616490508678, timestamp: 2022-08-19 20:37:20.296674\n",
      "resetting env. episode 1577, reward total was -19.0. running mean: -20.213903256035913, timestamp: 2022-08-19 20:37:23.507307\n",
      "resetting env. episode 1578, reward total was -21.0. running mean: -20.221764223475553, timestamp: 2022-08-19 20:37:26.640868\n",
      "resetting env. episode 1579, reward total was -21.0. running mean: -20.229546581240797, timestamp: 2022-08-19 20:37:32.679744\n",
      "resetting env. episode 1580, reward total was -21.0. running mean: -20.23725111542839, timestamp: 2022-08-19 20:37:37.503833\n",
      "resetting env. episode 1581, reward total was -21.0. running mean: -20.244878604274106, timestamp: 2022-08-19 20:37:44.496146\n",
      "resetting env. episode 1582, reward total was -20.0. running mean: -20.242429818231365, timestamp: 2022-08-19 20:37:52.036983\n",
      "resetting env. episode 1583, reward total was -20.0. running mean: -20.24000552004905, timestamp: 2022-08-19 20:37:56.791281\n",
      "resetting env. episode 1584, reward total was -21.0. running mean: -20.247605464848558, timestamp: 2022-08-19 20:38:00.724788\n",
      "resetting env. episode 1585, reward total was -20.0. running mean: -20.24512941020007, timestamp: 2022-08-19 20:38:04.861731\n",
      "resetting env. episode 1586, reward total was -20.0. running mean: -20.24267811609807, timestamp: 2022-08-19 20:38:11.224251\n",
      "resetting env. episode 1587, reward total was -21.0. running mean: -20.25025133493709, timestamp: 2022-08-19 20:38:18.044022\n",
      "resetting env. episode 1588, reward total was -20.0. running mean: -20.247748821587717, timestamp: 2022-08-19 20:38:24.654365\n",
      "resetting env. episode 1589, reward total was -21.0. running mean: -20.25527133337184, timestamp: 2022-08-19 20:38:30.249396\n",
      "resetting env. episode 1590, reward total was -21.0. running mean: -20.26271862003812, timestamp: 2022-08-19 20:38:33.970477\n",
      "resetting env. episode 1591, reward total was -19.0. running mean: -20.250091433837742, timestamp: 2022-08-19 20:38:39.184085\n",
      "resetting env. episode 1592, reward total was -20.0. running mean: -20.247590519499365, timestamp: 2022-08-19 20:38:42.438386\n",
      "resetting env. episode 1593, reward total was -21.0. running mean: -20.25511461430437, timestamp: 2022-08-19 20:38:47.393179\n",
      "resetting env. episode 1594, reward total was -20.0. running mean: -20.252563468161327, timestamp: 2022-08-19 20:38:51.602893\n",
      "resetting env. episode 1595, reward total was -20.0. running mean: -20.250037833479713, timestamp: 2022-08-19 20:38:56.322281\n",
      "resetting env. episode 1596, reward total was -21.0. running mean: -20.257537455144917, timestamp: 2022-08-19 20:38:59.450923\n",
      "resetting env. episode 1597, reward total was -21.0. running mean: -20.264962080593467, timestamp: 2022-08-19 20:39:02.713197\n",
      "resetting env. episode 1598, reward total was -21.0. running mean: -20.272312459787532, timestamp: 2022-08-19 20:39:06.656803\n",
      "resetting env. episode 1599, reward total was -21.0. running mean: -20.27958933518966, timestamp: 2022-08-19 20:39:10.263159\n",
      "resetting env. episode 1600, reward total was -20.0. running mean: -20.27679344183776, timestamp: 2022-08-19 20:39:13.707773\n",
      "resetting env. episode 1601, reward total was -21.0. running mean: -20.284025507419383, timestamp: 2022-08-19 20:39:16.267920\n",
      "resetting env. episode 1602, reward total was -20.0. running mean: -20.28118525234519, timestamp: 2022-08-19 20:39:19.227042\n",
      "resetting env. episode 1603, reward total was -18.0. running mean: -20.258373399821735, timestamp: 2022-08-19 20:39:22.958035\n",
      "resetting env. episode 1604, reward total was -18.0. running mean: -20.235789665823518, timestamp: 2022-08-19 20:39:27.164831\n",
      "resetting env. episode 1605, reward total was -20.0. running mean: -20.233431769165282, timestamp: 2022-08-19 20:39:30.348314\n",
      "resetting env. episode 1606, reward total was -21.0. running mean: -20.241097451473628, timestamp: 2022-08-19 20:39:33.459001\n",
      "resetting env. episode 1607, reward total was -20.0. running mean: -20.23868647695889, timestamp: 2022-08-19 20:39:36.746217\n",
      "resetting env. episode 1608, reward total was -19.0. running mean: -20.2262996121893, timestamp: 2022-08-19 20:39:41.214269\n",
      "resetting env. episode 1609, reward total was -21.0. running mean: -20.23403661606741, timestamp: 2022-08-19 20:39:44.629308\n",
      "resetting env. episode 1610, reward total was -20.0. running mean: -20.231696249906737, timestamp: 2022-08-19 20:39:50.309125\n",
      "resetting env. episode 1611, reward total was -21.0. running mean: -20.23937928740767, timestamp: 2022-08-19 20:39:55.041475\n",
      "resetting env. episode 1612, reward total was -20.0. running mean: -20.23698549453359, timestamp: 2022-08-19 20:39:59.166612\n",
      "resetting env. episode 1613, reward total was -17.0. running mean: -20.20461563958826, timestamp: 2022-08-19 20:40:04.064388\n",
      "resetting env. episode 1614, reward total was -21.0. running mean: -20.212569483192375, timestamp: 2022-08-19 20:40:08.331984\n",
      "resetting env. episode 1615, reward total was -21.0. running mean: -20.220443788360452, timestamp: 2022-08-19 20:40:11.919395\n",
      "resetting env. episode 1616, reward total was -21.0. running mean: -20.228239350476848, timestamp: 2022-08-19 20:40:14.653271\n",
      "resetting env. episode 1617, reward total was -21.0. running mean: -20.23595695697208, timestamp: 2022-08-19 20:40:17.820832\n",
      "resetting env. episode 1618, reward total was -21.0. running mean: -20.243597387402357, timestamp: 2022-08-19 20:40:21.221716\n",
      "resetting env. episode 1619, reward total was -20.0. running mean: -20.24116141352833, timestamp: 2022-08-19 20:40:24.091063\n",
      "resetting env. episode 1620, reward total was -21.0. running mean: -20.24874979939305, timestamp: 2022-08-19 20:40:26.839732\n",
      "resetting env. episode 1621, reward total was -21.0. running mean: -20.25626230139912, timestamp: 2022-08-19 20:40:30.230635\n",
      "resetting env. episode 1622, reward total was -18.0. running mean: -20.233699678385126, timestamp: 2022-08-19 20:40:34.248166\n",
      "resetting env. episode 1623, reward total was -20.0. running mean: -20.231362681601272, timestamp: 2022-08-19 20:40:37.638103\n",
      "resetting env. episode 1624, reward total was -20.0. running mean: -20.229049054785257, timestamp: 2022-08-19 20:40:41.791106\n",
      "resetting env. episode 1625, reward total was -20.0. running mean: -20.226758564237404, timestamp: 2022-08-19 20:40:45.942009\n",
      "resetting env. episode 1626, reward total was -21.0. running mean: -20.23449097859503, timestamp: 2022-08-19 20:40:49.147314\n",
      "resetting env. episode 1627, reward total was -20.0. running mean: -20.23214606880908, timestamp: 2022-08-19 20:40:52.474423\n",
      "resetting env. episode 1628, reward total was -21.0. running mean: -20.23982460812099, timestamp: 2022-08-19 20:40:56.037906\n",
      "resetting env. episode 1629, reward total was -20.0. running mean: -20.23742636203978, timestamp: 2022-08-19 20:41:00.724369\n",
      "resetting env. episode 1630, reward total was -20.0. running mean: -20.23505209841938, timestamp: 2022-08-19 20:41:06.009825\n",
      "resetting env. episode 1631, reward total was -21.0. running mean: -20.242701577435188, timestamp: 2022-08-19 20:41:09.513431\n",
      "resetting env. episode 1632, reward total was -20.0. running mean: -20.240274561660836, timestamp: 2022-08-19 20:41:13.333222\n",
      "resetting env. episode 1633, reward total was -20.0. running mean: -20.237871816044226, timestamp: 2022-08-19 20:41:17.045305\n",
      "resetting env. episode 1634, reward total was -20.0. running mean: -20.235493097883783, timestamp: 2022-08-19 20:41:21.349665\n",
      "resetting env. episode 1635, reward total was -21.0. running mean: -20.243138166904945, timestamp: 2022-08-19 20:41:24.664806\n",
      "resetting env. episode 1636, reward total was -21.0. running mean: -20.250706785235895, timestamp: 2022-08-19 20:41:28.699030\n",
      "resetting env. episode 1637, reward total was -20.0. running mean: -20.248199717383535, timestamp: 2022-08-19 20:41:35.031128\n",
      "resetting env. episode 1638, reward total was -19.0. running mean: -20.235717720209703, timestamp: 2022-08-19 20:41:43.016285\n",
      "resetting env. episode 1639, reward total was -19.0. running mean: -20.223360543007608, timestamp: 2022-08-19 20:41:47.978096\n",
      "resetting env. episode 1640, reward total was -20.0. running mean: -20.22112693757753, timestamp: 2022-08-19 20:41:51.874903\n",
      "resetting env. episode 1641, reward total was -20.0. running mean: -20.218915668201753, timestamp: 2022-08-19 20:41:56.464352\n",
      "resetting env. episode 1642, reward total was -21.0. running mean: -20.226726511519736, timestamp: 2022-08-19 20:42:00.534253\n",
      "resetting env. episode 1643, reward total was -20.0. running mean: -20.22445924640454, timestamp: 2022-08-19 20:42:04.980719\n",
      "resetting env. episode 1644, reward total was -20.0. running mean: -20.222214653940494, timestamp: 2022-08-19 20:42:09.246778\n",
      "resetting env. episode 1645, reward total was -20.0. running mean: -20.219992507401088, timestamp: 2022-08-19 20:42:13.644007\n",
      "resetting env. episode 1646, reward total was -19.0. running mean: -20.207792582327077, timestamp: 2022-08-19 20:42:20.520624\n",
      "resetting env. episode 1647, reward total was -20.0. running mean: -20.205714656503805, timestamp: 2022-08-19 20:42:29.972361\n",
      "resetting env. episode 1648, reward total was -21.0. running mean: -20.213657509938766, timestamp: 2022-08-19 20:42:33.243220\n",
      "resetting env. episode 1649, reward total was -21.0. running mean: -20.22152093483938, timestamp: 2022-08-19 20:42:35.939616\n",
      "resetting env. episode 1650, reward total was -21.0. running mean: -20.229305725490985, timestamp: 2022-08-19 20:42:38.473063\n",
      "resetting env. episode 1651, reward total was -19.0. running mean: -20.217012668236077, timestamp: 2022-08-19 20:42:42.626477\n",
      "resetting env. episode 1652, reward total was -20.0. running mean: -20.214842541553715, timestamp: 2022-08-19 20:42:45.914687\n",
      "resetting env. episode 1653, reward total was -21.0. running mean: -20.22269411613818, timestamp: 2022-08-19 20:42:48.885172\n",
      "resetting env. episode 1654, reward total was -21.0. running mean: -20.2304671749768, timestamp: 2022-08-19 20:42:51.226796\n",
      "resetting env. episode 1655, reward total was -21.0. running mean: -20.23816250322703, timestamp: 2022-08-19 20:42:54.055903\n",
      "resetting env. episode 1656, reward total was -20.0. running mean: -20.23578087819476, timestamp: 2022-08-19 20:42:57.395347\n",
      "resetting env. episode 1657, reward total was -21.0. running mean: -20.243423069412813, timestamp: 2022-08-19 20:43:00.004372\n",
      "resetting env. episode 1658, reward total was -19.0. running mean: -20.230988838718687, timestamp: 2022-08-19 20:43:02.808333\n",
      "resetting env. episode 1659, reward total was -20.0. running mean: -20.2286789503315, timestamp: 2022-08-19 20:43:06.281704\n",
      "resetting env. episode 1660, reward total was -20.0. running mean: -20.226392160828183, timestamp: 2022-08-19 20:43:09.276952\n",
      "resetting env. episode 1661, reward total was -21.0. running mean: -20.234128239219903, timestamp: 2022-08-19 20:43:12.390629\n",
      "resetting env. episode 1662, reward total was -21.0. running mean: -20.241786956827703, timestamp: 2022-08-19 20:43:15.678838\n",
      "resetting env. episode 1663, reward total was -19.0. running mean: -20.22936908725943, timestamp: 2022-08-19 20:43:19.467668\n",
      "resetting env. episode 1664, reward total was -21.0. running mean: -20.237075396386835, timestamp: 2022-08-19 20:43:22.156122\n",
      "resetting env. episode 1665, reward total was -21.0. running mean: -20.244704642422967, timestamp: 2022-08-19 20:43:24.829947\n",
      "resetting env. episode 1666, reward total was -21.0. running mean: -20.25225759599874, timestamp: 2022-08-19 20:43:27.533667\n",
      "resetting env. episode 1667, reward total was -21.0. running mean: -20.25973502003875, timestamp: 2022-08-19 20:43:31.084173\n",
      "resetting env. episode 1668, reward total was -21.0. running mean: -20.267137669838363, timestamp: 2022-08-19 20:43:33.686217\n",
      "resetting env. episode 1669, reward total was -20.0. running mean: -20.26446629313998, timestamp: 2022-08-19 20:43:37.111063\n",
      "resetting env. episode 1670, reward total was -19.0. running mean: -20.25182163020858, timestamp: 2022-08-19 20:43:40.527849\n",
      "resetting env. episode 1671, reward total was -21.0. running mean: -20.259303413906494, timestamp: 2022-08-19 20:43:44.601027\n",
      "resetting env. episode 1672, reward total was -19.0. running mean: -20.246710379767432, timestamp: 2022-08-19 20:43:47.724117\n",
      "resetting env. episode 1673, reward total was -20.0. running mean: -20.244243275969758, timestamp: 2022-08-19 20:43:50.554259\n",
      "resetting env. episode 1674, reward total was -21.0. running mean: -20.251800843210063, timestamp: 2022-08-19 20:43:53.824815\n",
      "resetting env. episode 1675, reward total was -20.0. running mean: -20.24928283477796, timestamp: 2022-08-19 20:43:56.698664\n",
      "resetting env. episode 1676, reward total was -21.0. running mean: -20.256790006430183, timestamp: 2022-08-19 20:44:00.061365\n",
      "resetting env. episode 1677, reward total was -20.0. running mean: -20.25422210636588, timestamp: 2022-08-19 20:44:04.201621\n",
      "resetting env. episode 1678, reward total was -21.0. running mean: -20.26167988530222, timestamp: 2022-08-19 20:44:06.659845\n",
      "resetting env. episode 1679, reward total was -17.0. running mean: -20.2290630864492, timestamp: 2022-08-19 20:44:10.484447\n",
      "resetting env. episode 1680, reward total was -21.0. running mean: -20.23677245558471, timestamp: 2022-08-19 20:44:13.864405\n",
      "resetting env. episode 1681, reward total was -21.0. running mean: -20.24440473102886, timestamp: 2022-08-19 20:44:16.579642\n",
      "resetting env. episode 1682, reward total was -20.0. running mean: -20.241960683718574, timestamp: 2022-08-19 20:44:19.312332\n",
      "resetting env. episode 1683, reward total was -21.0. running mean: -20.24954107688139, timestamp: 2022-08-19 20:44:22.708724\n",
      "resetting env. episode 1684, reward total was -21.0. running mean: -20.257045666112575, timestamp: 2022-08-19 20:44:25.398654\n",
      "resetting env. episode 1685, reward total was -20.0. running mean: -20.25447520945145, timestamp: 2022-08-19 20:44:29.068858\n",
      "resetting env. episode 1686, reward total was -20.0. running mean: -20.251930457356934, timestamp: 2022-08-19 20:44:32.626034\n",
      "resetting env. episode 1687, reward total was -19.0. running mean: -20.239411152783365, timestamp: 2022-08-19 20:44:36.000092\n",
      "resetting env. episode 1688, reward total was -20.0. running mean: -20.23701704125553, timestamp: 2022-08-19 20:44:39.176652\n",
      "resetting env. episode 1689, reward total was -19.0. running mean: -20.224646870842975, timestamp: 2022-08-19 20:44:42.138746\n",
      "resetting env. episode 1690, reward total was -19.0. running mean: -20.212400402134545, timestamp: 2022-08-19 20:44:45.383069\n",
      "resetting env. episode 1691, reward total was -19.0. running mean: -20.2002763981132, timestamp: 2022-08-19 20:44:49.324636\n",
      "resetting env. episode 1692, reward total was -21.0. running mean: -20.20827363413207, timestamp: 2022-08-19 20:44:51.997762\n",
      "resetting env. episode 1693, reward total was -21.0. running mean: -20.21619089779075, timestamp: 2022-08-19 20:44:55.005705\n",
      "resetting env. episode 1694, reward total was -20.0. running mean: -20.214028988812842, timestamp: 2022-08-19 20:44:58.926271\n",
      "resetting env. episode 1695, reward total was -19.0. running mean: -20.201888698924716, timestamp: 2022-08-19 20:45:01.939363\n",
      "resetting env. episode 1696, reward total was -20.0. running mean: -20.199869811935468, timestamp: 2022-08-19 20:45:04.725655\n",
      "resetting env. episode 1697, reward total was -20.0. running mean: -20.197871113816113, timestamp: 2022-08-19 20:45:08.370269\n",
      "resetting env. episode 1698, reward total was -21.0. running mean: -20.205892402677954, timestamp: 2022-08-19 20:45:10.706530\n",
      "resetting env. episode 1699, reward total was -20.0. running mean: -20.203833478651173, timestamp: 2022-08-19 20:45:13.661660\n",
      "resetting env. episode 1700, reward total was -20.0. running mean: -20.20179514386466, timestamp: 2022-08-19 20:45:16.543371\n",
      "resetting env. episode 1701, reward total was -20.0. running mean: -20.199777192426012, timestamp: 2022-08-19 20:45:20.559514\n",
      "resetting env. episode 1702, reward total was -19.0. running mean: -20.18777942050175, timestamp: 2022-08-19 20:45:23.430448\n",
      "resetting env. episode 1703, reward total was -21.0. running mean: -20.195901626296735, timestamp: 2022-08-19 20:45:26.399510\n",
      "resetting env. episode 1704, reward total was -21.0. running mean: -20.203942610033767, timestamp: 2022-08-19 20:45:29.270288\n",
      "resetting env. episode 1705, reward total was -18.0. running mean: -20.18190318393343, timestamp: 2022-08-19 20:45:33.952261\n",
      "resetting env. episode 1706, reward total was -21.0. running mean: -20.190084152094094, timestamp: 2022-08-19 20:45:37.935765\n",
      "resetting env. episode 1707, reward total was -21.0. running mean: -20.198183310573153, timestamp: 2022-08-19 20:45:41.292768\n",
      "resetting env. episode 1708, reward total was -21.0. running mean: -20.206201477467424, timestamp: 2022-08-19 20:45:43.439030\n",
      "resetting env. episode 1709, reward total was -19.0. running mean: -20.19413946269275, timestamp: 2022-08-19 20:45:47.410047\n",
      "resetting env. episode 1710, reward total was -20.0. running mean: -20.19219806806582, timestamp: 2022-08-19 20:45:50.412990\n",
      "resetting env. episode 1711, reward total was -21.0. running mean: -20.200276087385163, timestamp: 2022-08-19 20:45:53.121287\n",
      "resetting env. episode 1712, reward total was -21.0. running mean: -20.20827332651131, timestamp: 2022-08-19 20:45:56.404829\n",
      "resetting env. episode 1713, reward total was -20.0. running mean: -20.2061905932462, timestamp: 2022-08-19 20:45:59.117560\n",
      "resetting env. episode 1714, reward total was -20.0. running mean: -20.204128687313734, timestamp: 2022-08-19 20:46:01.714618\n",
      "resetting env. episode 1715, reward total was -21.0. running mean: -20.2120874004406, timestamp: 2022-08-19 20:46:04.579987\n",
      "resetting env. episode 1716, reward total was -18.0. running mean: -20.18996652643619, timestamp: 2022-08-19 20:46:08.320042\n",
      "resetting env. episode 1717, reward total was -21.0. running mean: -20.198066861171828, timestamp: 2022-08-19 20:46:11.637713\n",
      "resetting env. episode 1718, reward total was -20.0. running mean: -20.19608619256011, timestamp: 2022-08-19 20:46:14.853706\n",
      "resetting env. episode 1719, reward total was -21.0. running mean: -20.204125330634508, timestamp: 2022-08-19 20:46:17.551201\n",
      "resetting env. episode 1720, reward total was -17.0. running mean: -20.172084077328165, timestamp: 2022-08-19 20:46:21.309152\n",
      "resetting env. episode 1721, reward total was -20.0. running mean: -20.170363236554884, timestamp: 2022-08-19 20:46:25.160969\n",
      "resetting env. episode 1722, reward total was -21.0. running mean: -20.178659604189335, timestamp: 2022-08-19 20:46:28.045312\n",
      "resetting env. episode 1723, reward total was -19.0. running mean: -20.16687300814744, timestamp: 2022-08-19 20:46:31.409893\n",
      "resetting env. episode 1724, reward total was -21.0. running mean: -20.175204278065966, timestamp: 2022-08-19 20:46:35.593352\n",
      "resetting env. episode 1725, reward total was -20.0. running mean: -20.173452235285303, timestamp: 2022-08-19 20:46:38.659659\n",
      "resetting env. episode 1726, reward total was -21.0. running mean: -20.18171771293245, timestamp: 2022-08-19 20:46:41.417292\n",
      "resetting env. episode 1727, reward total was -21.0. running mean: -20.189900535803126, timestamp: 2022-08-19 20:46:44.246726\n",
      "resetting env. episode 1728, reward total was -21.0. running mean: -20.198001530445094, timestamp: 2022-08-19 20:46:47.276626\n",
      "resetting env. episode 1729, reward total was -20.0. running mean: -20.196021515140643, timestamp: 2022-08-19 20:46:50.393298\n",
      "resetting env. episode 1730, reward total was -21.0. running mean: -20.204061299989238, timestamp: 2022-08-19 20:46:52.638305\n",
      "resetting env. episode 1731, reward total was -21.0. running mean: -20.212020686989348, timestamp: 2022-08-19 20:46:55.603083\n",
      "resetting env. episode 1732, reward total was -20.0. running mean: -20.209900480119455, timestamp: 2022-08-19 20:46:58.684845\n",
      "resetting env. episode 1733, reward total was -19.0. running mean: -20.19780147531826, timestamp: 2022-08-19 20:47:02.433823\n",
      "resetting env. episode 1734, reward total was -21.0. running mean: -20.205823460565078, timestamp: 2022-08-19 20:47:05.287197\n",
      "resetting env. episode 1735, reward total was -21.0. running mean: -20.213765225959428, timestamp: 2022-08-19 20:47:10.253860\n",
      "resetting env. episode 1736, reward total was -20.0. running mean: -20.211627573699833, timestamp: 2022-08-19 20:47:13.640830\n",
      "resetting env. episode 1737, reward total was -21.0. running mean: -20.219511297962836, timestamp: 2022-08-19 20:47:18.520801\n",
      "resetting env. episode 1738, reward total was -21.0. running mean: -20.22731618498321, timestamp: 2022-08-19 20:47:21.969746\n",
      "resetting env. episode 1739, reward total was -19.0. running mean: -20.21504302313338, timestamp: 2022-08-19 20:47:25.585612\n",
      "resetting env. episode 1740, reward total was -21.0. running mean: -20.222892592902046, timestamp: 2022-08-19 20:47:28.663383\n",
      "resetting env. episode 1741, reward total was -18.0. running mean: -20.200663666973025, timestamp: 2022-08-19 20:47:32.842222\n",
      "resetting env. episode 1742, reward total was -19.0. running mean: -20.188657030303297, timestamp: 2022-08-19 20:47:38.143347\n",
      "resetting env. episode 1743, reward total was -21.0. running mean: -20.196770460000266, timestamp: 2022-08-19 20:47:45.227413\n",
      "resetting env. episode 1744, reward total was -21.0. running mean: -20.204802755400266, timestamp: 2022-08-19 20:47:51.328115\n",
      "resetting env. episode 1745, reward total was -20.0. running mean: -20.202754727846262, timestamp: 2022-08-19 20:47:57.120550\n",
      "resetting env. episode 1746, reward total was -20.0. running mean: -20.2007271805678, timestamp: 2022-08-19 20:48:01.954629\n",
      "resetting env. episode 1747, reward total was -19.0. running mean: -20.188719908762124, timestamp: 2022-08-19 20:48:06.660053\n",
      "resetting env. episode 1748, reward total was -21.0. running mean: -20.196832709674503, timestamp: 2022-08-19 20:48:10.417028\n",
      "resetting env. episode 1749, reward total was -21.0. running mean: -20.204864382577757, timestamp: 2022-08-19 20:48:13.782015\n",
      "resetting env. episode 1750, reward total was -20.0. running mean: -20.20281573875198, timestamp: 2022-08-19 20:48:17.268692\n",
      "resetting env. episode 1751, reward total was -21.0. running mean: -20.21078758136446, timestamp: 2022-08-19 20:48:22.580504\n",
      "resetting env. episode 1752, reward total was -21.0. running mean: -20.218679705550816, timestamp: 2022-08-19 20:48:28.865443\n",
      "resetting env. episode 1753, reward total was -20.0. running mean: -20.216492908495308, timestamp: 2022-08-19 20:48:32.986418\n",
      "resetting env. episode 1754, reward total was -21.0. running mean: -20.224327979410354, timestamp: 2022-08-19 20:48:38.116566\n",
      "resetting env. episode 1755, reward total was -21.0. running mean: -20.23208469961625, timestamp: 2022-08-19 20:48:42.534741\n",
      "resetting env. episode 1756, reward total was -21.0. running mean: -20.23976385262009, timestamp: 2022-08-19 20:48:45.987527\n",
      "resetting env. episode 1757, reward total was -20.0. running mean: -20.23736621409389, timestamp: 2022-08-19 20:48:49.158695\n",
      "resetting env. episode 1758, reward total was -19.0. running mean: -20.22499255195295, timestamp: 2022-08-19 20:48:53.921068\n",
      "resetting env. episode 1759, reward total was -21.0. running mean: -20.23274262643342, timestamp: 2022-08-19 20:48:57.093092\n",
      "resetting env. episode 1760, reward total was -20.0. running mean: -20.230415200169087, timestamp: 2022-08-19 20:49:00.678119\n",
      "resetting env. episode 1761, reward total was -21.0. running mean: -20.238111048167397, timestamp: 2022-08-19 20:49:05.100356\n",
      "resetting env. episode 1762, reward total was -20.0. running mean: -20.235729937685722, timestamp: 2022-08-19 20:49:12.419789\n",
      "resetting env. episode 1763, reward total was -20.0. running mean: -20.233372638308865, timestamp: 2022-08-19 20:49:15.881541\n",
      "resetting env. episode 1764, reward total was -21.0. running mean: -20.241038911925777, timestamp: 2022-08-19 20:49:20.037424\n",
      "resetting env. episode 1765, reward total was -21.0. running mean: -20.24862852280652, timestamp: 2022-08-19 20:49:24.703093\n",
      "resetting env. episode 1766, reward total was -20.0. running mean: -20.246142237578454, timestamp: 2022-08-19 20:49:30.395437\n",
      "resetting env. episode 1767, reward total was -21.0. running mean: -20.25368081520267, timestamp: 2022-08-19 20:49:35.691553\n",
      "resetting env. episode 1768, reward total was -19.0. running mean: -20.241144007050647, timestamp: 2022-08-19 20:49:40.672039\n",
      "resetting env. episode 1769, reward total was -20.0. running mean: -20.23873256698014, timestamp: 2022-08-19 20:49:45.464161\n",
      "resetting env. episode 1770, reward total was -20.0. running mean: -20.23634524131034, timestamp: 2022-08-19 20:49:49.744844\n",
      "resetting env. episode 1771, reward total was -20.0. running mean: -20.233981788897236, timestamp: 2022-08-19 20:49:54.740473\n",
      "resetting env. episode 1772, reward total was -21.0. running mean: -20.241641971008264, timestamp: 2022-08-19 20:49:59.308875\n",
      "resetting env. episode 1773, reward total was -21.0. running mean: -20.24922555129818, timestamp: 2022-08-19 20:50:03.340694\n",
      "resetting env. episode 1774, reward total was -20.0. running mean: -20.246733295785198, timestamp: 2022-08-19 20:50:07.307609\n",
      "resetting env. episode 1775, reward total was -19.0. running mean: -20.234265962827347, timestamp: 2022-08-19 20:50:12.238399\n",
      "resetting env. episode 1776, reward total was -21.0. running mean: -20.241923303199073, timestamp: 2022-08-19 20:50:15.582531\n",
      "resetting env. episode 1777, reward total was -20.0. running mean: -20.239504070167083, timestamp: 2022-08-19 20:50:19.590142\n",
      "resetting env. episode 1778, reward total was -20.0. running mean: -20.23710902946541, timestamp: 2022-08-19 20:50:22.967838\n",
      "resetting env. episode 1779, reward total was -21.0. running mean: -20.244737939170758, timestamp: 2022-08-19 20:50:27.210117\n",
      "resetting env. episode 1780, reward total was -19.0. running mean: -20.232290559779052, timestamp: 2022-08-19 20:50:30.968364\n",
      "resetting env. episode 1781, reward total was -19.0. running mean: -20.219967654181264, timestamp: 2022-08-19 20:50:35.252192\n",
      "resetting env. episode 1782, reward total was -20.0. running mean: -20.21776797763945, timestamp: 2022-08-19 20:50:38.523319\n",
      "resetting env. episode 1783, reward total was -20.0. running mean: -20.215590297863056, timestamp: 2022-08-19 20:50:42.936066\n",
      "resetting env. episode 1784, reward total was -19.0. running mean: -20.203434394884425, timestamp: 2022-08-19 20:50:48.306869\n",
      "resetting env. episode 1785, reward total was -20.0. running mean: -20.20140005093558, timestamp: 2022-08-19 20:50:52.436290\n",
      "resetting env. episode 1786, reward total was -18.0. running mean: -20.179386050426224, timestamp: 2022-08-19 20:50:57.108016\n",
      "resetting env. episode 1787, reward total was -20.0. running mean: -20.17759218992196, timestamp: 2022-08-19 20:51:01.079610\n",
      "resetting env. episode 1788, reward total was -20.0. running mean: -20.17581626802274, timestamp: 2022-08-19 20:51:05.614560\n",
      "resetting env. episode 1789, reward total was -21.0. running mean: -20.184058105342512, timestamp: 2022-08-19 20:51:08.626125\n",
      "resetting env. episode 1790, reward total was -21.0. running mean: -20.192217524289088, timestamp: 2022-08-19 20:51:13.174403\n",
      "resetting env. episode 1791, reward total was -20.0. running mean: -20.190295349046195, timestamp: 2022-08-19 20:51:17.059299\n",
      "resetting env. episode 1792, reward total was -21.0. running mean: -20.198392395555736, timestamp: 2022-08-19 20:51:20.289745\n",
      "resetting env. episode 1793, reward total was -19.0. running mean: -20.18640847160018, timestamp: 2022-08-19 20:51:24.430382\n",
      "resetting env. episode 1794, reward total was -21.0. running mean: -20.19454438688418, timestamp: 2022-08-19 20:51:29.397566\n",
      "resetting env. episode 1795, reward total was -21.0. running mean: -20.20259894301534, timestamp: 2022-08-19 20:51:32.809971\n",
      "resetting env. episode 1796, reward total was -18.0. running mean: -20.180572953585184, timestamp: 2022-08-19 20:51:38.809078\n",
      "resetting env. episode 1797, reward total was -18.0. running mean: -20.15876722404933, timestamp: 2022-08-19 20:51:44.685338\n",
      "resetting env. episode 1798, reward total was -21.0. running mean: -20.16717955180884, timestamp: 2022-08-19 20:51:49.473210\n",
      "resetting env. episode 1799, reward total was -21.0. running mean: -20.175507756290752, timestamp: 2022-08-19 20:51:53.643223\n",
      "resetting env. episode 1800, reward total was -21.0. running mean: -20.183752678727846, timestamp: 2022-08-19 20:51:58.089788\n",
      "resetting env. episode 1801, reward total was -20.0. running mean: -20.181915151940565, timestamp: 2022-08-19 20:52:01.955859\n",
      "resetting env. episode 1802, reward total was -19.0. running mean: -20.17009600042116, timestamp: 2022-08-19 20:52:05.907685\n",
      "resetting env. episode 1803, reward total was -20.0. running mean: -20.16839504041695, timestamp: 2022-08-19 20:52:09.571105\n",
      "resetting env. episode 1804, reward total was -21.0. running mean: -20.17671109001278, timestamp: 2022-08-19 20:52:13.055076\n",
      "resetting env. episode 1805, reward total was -20.0. running mean: -20.17494397911265, timestamp: 2022-08-19 20:52:17.754234\n",
      "resetting env. episode 1806, reward total was -19.0. running mean: -20.163194539321527, timestamp: 2022-08-19 20:52:23.408932\n",
      "resetting env. episode 1807, reward total was -20.0. running mean: -20.16156259392831, timestamp: 2022-08-19 20:52:26.905213\n",
      "resetting env. episode 1808, reward total was -20.0. running mean: -20.159946967989026, timestamp: 2022-08-19 20:52:30.934912\n",
      "resetting env. episode 1809, reward total was -20.0. running mean: -20.158347498309134, timestamp: 2022-08-19 20:52:36.375625\n",
      "resetting env. episode 1810, reward total was -20.0. running mean: -20.15676402332604, timestamp: 2022-08-19 20:52:41.876463\n",
      "resetting env. episode 1811, reward total was -21.0. running mean: -20.16519638309278, timestamp: 2022-08-19 20:52:46.242769\n",
      "resetting env. episode 1812, reward total was -20.0. running mean: -20.16354441926185, timestamp: 2022-08-19 20:52:51.252678\n",
      "resetting env. episode 1813, reward total was -17.0. running mean: -20.131908975069233, timestamp: 2022-08-19 20:52:56.516576\n",
      "resetting env. episode 1814, reward total was -21.0. running mean: -20.14058988531854, timestamp: 2022-08-19 20:53:00.337663\n",
      "resetting env. episode 1815, reward total was -21.0. running mean: -20.149183986465356, timestamp: 2022-08-19 20:53:04.862100\n",
      "resetting env. episode 1816, reward total was -21.0. running mean: -20.157692146600702, timestamp: 2022-08-19 20:53:08.270272\n",
      "resetting env. episode 1817, reward total was -21.0. running mean: -20.166115225134696, timestamp: 2022-08-19 20:53:11.287339\n",
      "resetting env. episode 1818, reward total was -21.0. running mean: -20.17445407288335, timestamp: 2022-08-19 20:53:16.085918\n",
      "resetting env. episode 1819, reward total was -18.0. running mean: -20.152709532154518, timestamp: 2022-08-19 20:53:20.872776\n",
      "resetting env. episode 1820, reward total was -21.0. running mean: -20.161182436832974, timestamp: 2022-08-19 20:53:24.979223\n",
      "resetting env. episode 1821, reward total was -19.0. running mean: -20.149570612464643, timestamp: 2022-08-19 20:53:29.560346\n",
      "resetting env. episode 1822, reward total was -21.0. running mean: -20.158074906339998, timestamp: 2022-08-19 20:53:33.189242\n",
      "resetting env. episode 1823, reward total was -21.0. running mean: -20.1664941572766, timestamp: 2022-08-19 20:53:37.137575\n",
      "resetting env. episode 1824, reward total was -20.0. running mean: -20.164829215703833, timestamp: 2022-08-19 20:53:41.123303\n",
      "resetting env. episode 1825, reward total was -21.0. running mean: -20.173180923546795, timestamp: 2022-08-19 20:53:44.117229\n",
      "resetting env. episode 1826, reward total was -21.0. running mean: -20.181449114311327, timestamp: 2022-08-19 20:53:47.724042\n",
      "resetting env. episode 1827, reward total was -21.0. running mean: -20.189634623168214, timestamp: 2022-08-19 20:53:51.036000\n",
      "resetting env. episode 1828, reward total was -21.0. running mean: -20.197738276936533, timestamp: 2022-08-19 20:53:54.758253\n",
      "resetting env. episode 1829, reward total was -20.0. running mean: -20.19576089416717, timestamp: 2022-08-19 20:53:58.195896\n",
      "resetting env. episode 1830, reward total was -19.0. running mean: -20.183803285225498, timestamp: 2022-08-19 20:54:02.616879\n",
      "resetting env. episode 1831, reward total was -21.0. running mean: -20.191965252373244, timestamp: 2022-08-19 20:54:06.631315\n",
      "resetting env. episode 1832, reward total was -20.0. running mean: -20.190045599849512, timestamp: 2022-08-19 20:54:11.927699\n",
      "resetting env. episode 1833, reward total was -20.0. running mean: -20.188145143851017, timestamp: 2022-08-19 20:54:16.122251\n",
      "resetting env. episode 1834, reward total was -21.0. running mean: -20.196263692412508, timestamp: 2022-08-19 20:54:19.285256\n",
      "resetting env. episode 1835, reward total was -21.0. running mean: -20.204301055488383, timestamp: 2022-08-19 20:54:23.081922\n",
      "resetting env. episode 1836, reward total was -19.0. running mean: -20.1922580449335, timestamp: 2022-08-19 20:54:28.620234\n",
      "resetting env. episode 1837, reward total was -21.0. running mean: -20.200335464484166, timestamp: 2022-08-19 20:54:32.935265\n",
      "resetting env. episode 1838, reward total was -21.0. running mean: -20.208332109839326, timestamp: 2022-08-19 20:54:36.812593\n",
      "resetting env. episode 1839, reward total was -20.0. running mean: -20.206248788740933, timestamp: 2022-08-19 20:54:40.723340\n",
      "resetting env. episode 1840, reward total was -20.0. running mean: -20.20418630085352, timestamp: 2022-08-19 20:54:46.238133\n",
      "resetting env. episode 1841, reward total was -20.0. running mean: -20.202144437844986, timestamp: 2022-08-19 20:54:50.328922\n",
      "resetting env. episode 1842, reward total was -21.0. running mean: -20.210122993466538, timestamp: 2022-08-19 20:54:54.918863\n",
      "resetting env. episode 1843, reward total was -21.0. running mean: -20.218021763531873, timestamp: 2022-08-19 20:54:59.793781\n",
      "resetting env. episode 1844, reward total was -21.0. running mean: -20.225841545896554, timestamp: 2022-08-19 20:55:04.233035\n",
      "resetting env. episode 1845, reward total was -20.0. running mean: -20.223583130437586, timestamp: 2022-08-19 20:55:07.656480\n",
      "resetting env. episode 1846, reward total was -21.0. running mean: -20.231347299133212, timestamp: 2022-08-19 20:55:10.864375\n",
      "resetting env. episode 1847, reward total was -19.0. running mean: -20.21903382614188, timestamp: 2022-08-19 20:55:14.813519\n",
      "resetting env. episode 1848, reward total was -21.0. running mean: -20.226843487880462, timestamp: 2022-08-19 20:55:20.114038\n",
      "resetting env. episode 1849, reward total was -21.0. running mean: -20.23457505300166, timestamp: 2022-08-19 20:55:24.413202\n",
      "resetting env. episode 1850, reward total was -19.0. running mean: -20.222229302471643, timestamp: 2022-08-19 20:55:29.487450\n",
      "resetting env. episode 1851, reward total was -20.0. running mean: -20.220007009446924, timestamp: 2022-08-19 20:55:34.050206\n",
      "resetting env. episode 1852, reward total was -21.0. running mean: -20.227806939352455, timestamp: 2022-08-19 20:55:38.205271\n",
      "resetting env. episode 1853, reward total was -21.0. running mean: -20.23552886995893, timestamp: 2022-08-19 20:55:41.811217\n",
      "resetting env. episode 1854, reward total was -21.0. running mean: -20.24317358125934, timestamp: 2022-08-19 20:55:45.585716\n",
      "resetting env. episode 1855, reward total was -20.0. running mean: -20.24074184544675, timestamp: 2022-08-19 20:55:50.270780\n",
      "resetting env. episode 1856, reward total was -21.0. running mean: -20.248334426992283, timestamp: 2022-08-19 20:55:53.758263\n",
      "resetting env. episode 1857, reward total was -20.0. running mean: -20.24585108272236, timestamp: 2022-08-19 20:55:58.097722\n",
      "resetting env. episode 1858, reward total was -19.0. running mean: -20.233392571895138, timestamp: 2022-08-19 20:56:03.058379\n",
      "resetting env. episode 1859, reward total was -20.0. running mean: -20.231058646176187, timestamp: 2022-08-19 20:56:06.603507\n",
      "resetting env. episode 1860, reward total was -21.0. running mean: -20.238748059714425, timestamp: 2022-08-19 20:56:10.511821\n",
      "resetting env. episode 1861, reward total was -21.0. running mean: -20.24636057911728, timestamp: 2022-08-19 20:56:14.099205\n",
      "resetting env. episode 1862, reward total was -20.0. running mean: -20.243896973326105, timestamp: 2022-08-19 20:56:18.284072\n",
      "resetting env. episode 1863, reward total was -21.0. running mean: -20.251458003592845, timestamp: 2022-08-19 20:56:22.958733\n",
      "resetting env. episode 1864, reward total was -21.0. running mean: -20.258943423556918, timestamp: 2022-08-19 20:56:25.910641\n",
      "resetting env. episode 1865, reward total was -21.0. running mean: -20.26635398932135, timestamp: 2022-08-19 20:56:30.813319\n",
      "resetting env. episode 1866, reward total was -21.0. running mean: -20.273690449428138, timestamp: 2022-08-19 20:56:34.482094\n",
      "resetting env. episode 1867, reward total was -19.0. running mean: -20.26095354493386, timestamp: 2022-08-19 20:56:40.230819\n",
      "resetting env. episode 1868, reward total was -21.0. running mean: -20.268344009484522, timestamp: 2022-08-19 20:56:43.664918\n",
      "resetting env. episode 1869, reward total was -20.0. running mean: -20.265660569389677, timestamp: 2022-08-19 20:56:46.957793\n",
      "resetting env. episode 1870, reward total was -19.0. running mean: -20.253003963695782, timestamp: 2022-08-19 20:56:51.711669\n",
      "resetting env. episode 1871, reward total was -21.0. running mean: -20.260473924058825, timestamp: 2022-08-19 20:56:57.387559\n",
      "resetting env. episode 1872, reward total was -21.0. running mean: -20.267869184818238, timestamp: 2022-08-19 20:57:00.408731\n",
      "resetting env. episode 1873, reward total was -21.0. running mean: -20.275190492970058, timestamp: 2022-08-19 20:57:04.884415\n",
      "resetting env. episode 1874, reward total was -18.0. running mean: -20.252438588040356, timestamp: 2022-08-19 20:57:09.954634\n",
      "resetting env. episode 1875, reward total was -21.0. running mean: -20.25991420215995, timestamp: 2022-08-19 20:57:13.459045\n",
      "resetting env. episode 1876, reward total was -20.0. running mean: -20.25731506013835, timestamp: 2022-08-19 20:57:18.379547\n",
      "resetting env. episode 1877, reward total was -20.0. running mean: -20.254741909536964, timestamp: 2022-08-19 20:57:24.843207\n",
      "resetting env. episode 1878, reward total was -19.0. running mean: -20.242194490441594, timestamp: 2022-08-19 20:57:31.498732\n",
      "resetting env. episode 1879, reward total was -21.0. running mean: -20.24977254553718, timestamp: 2022-08-19 20:57:35.531055\n",
      "resetting env. episode 1880, reward total was -20.0. running mean: -20.247274820081806, timestamp: 2022-08-19 20:57:41.572369\n",
      "resetting env. episode 1881, reward total was -20.0. running mean: -20.244802071880986, timestamp: 2022-08-19 20:57:45.497576\n",
      "resetting env. episode 1882, reward total was -21.0. running mean: -20.25235405116218, timestamp: 2022-08-19 20:57:49.516485\n",
      "resetting env. episode 1883, reward total was -20.0. running mean: -20.249830510650558, timestamp: 2022-08-19 20:57:55.283473\n",
      "resetting env. episode 1884, reward total was -21.0. running mean: -20.257332205544053, timestamp: 2022-08-19 20:57:59.916085\n",
      "resetting env. episode 1885, reward total was -20.0. running mean: -20.254758883488613, timestamp: 2022-08-19 20:58:05.890003\n",
      "resetting env. episode 1886, reward total was -21.0. running mean: -20.262211294653728, timestamp: 2022-08-19 20:58:10.410755\n",
      "resetting env. episode 1887, reward total was -21.0. running mean: -20.26958918170719, timestamp: 2022-08-19 20:58:17.499453\n",
      "resetting env. episode 1888, reward total was -21.0. running mean: -20.27689328989012, timestamp: 2022-08-19 20:58:23.867824\n",
      "resetting env. episode 1889, reward total was -19.0. running mean: -20.264124356991218, timestamp: 2022-08-19 20:58:29.627117\n",
      "resetting env. episode 1890, reward total was -20.0. running mean: -20.261483113421306, timestamp: 2022-08-19 20:58:34.254632\n",
      "resetting env. episode 1891, reward total was -20.0. running mean: -20.258868282287093, timestamp: 2022-08-19 20:58:38.564997\n",
      "resetting env. episode 1892, reward total was -18.0. running mean: -20.236279599464222, timestamp: 2022-08-19 20:58:43.947957\n",
      "resetting env. episode 1893, reward total was -20.0. running mean: -20.23391680346958, timestamp: 2022-08-19 20:58:48.105305\n",
      "resetting env. episode 1894, reward total was -20.0. running mean: -20.23157763543488, timestamp: 2022-08-19 20:58:52.611888\n",
      "resetting env. episode 1895, reward total was -20.0. running mean: -20.22926185908053, timestamp: 2022-08-19 20:58:56.566697\n",
      "resetting env. episode 1896, reward total was -19.0. running mean: -20.216969240489725, timestamp: 2022-08-19 20:59:02.155680\n",
      "resetting env. episode 1897, reward total was -18.0. running mean: -20.194799548084827, timestamp: 2022-08-19 20:59:07.262394\n",
      "resetting env. episode 1898, reward total was -20.0. running mean: -20.19285155260398, timestamp: 2022-08-19 20:59:12.663840\n",
      "resetting env. episode 1899, reward total was -20.0. running mean: -20.19092303707794, timestamp: 2022-08-19 20:59:19.388705\n",
      "resetting env. episode 1900, reward total was -20.0. running mean: -20.18901380670716, timestamp: 2022-08-19 20:59:24.949625\n",
      "resetting env. episode 1901, reward total was -21.0. running mean: -20.19712366864009, timestamp: 2022-08-19 20:59:29.911496\n",
      "resetting env. episode 1902, reward total was -20.0. running mean: -20.195152431953687, timestamp: 2022-08-19 20:59:37.084653\n",
      "resetting env. episode 1903, reward total was -20.0. running mean: -20.19320090763415, timestamp: 2022-08-19 20:59:47.647930\n",
      "resetting env. episode 1904, reward total was -21.0. running mean: -20.20126889855781, timestamp: 2022-08-19 20:59:54.412548\n",
      "resetting env. episode 1905, reward total was -21.0. running mean: -20.20925620957223, timestamp: 2022-08-19 21:00:01.220290\n",
      "resetting env. episode 1906, reward total was -20.0. running mean: -20.20716364747651, timestamp: 2022-08-19 21:00:06.095478\n",
      "resetting env. episode 1907, reward total was -20.0. running mean: -20.205092011001742, timestamp: 2022-08-19 21:00:09.706242\n",
      "resetting env. episode 1908, reward total was -19.0. running mean: -20.193041090891725, timestamp: 2022-08-19 21:00:13.059762\n",
      "resetting env. episode 1909, reward total was -20.0. running mean: -20.191110679982806, timestamp: 2022-08-19 21:00:16.112834\n",
      "resetting env. episode 1910, reward total was -21.0. running mean: -20.19919957318298, timestamp: 2022-08-19 21:00:19.516721\n",
      "resetting env. episode 1911, reward total was -20.0. running mean: -20.19720757745115, timestamp: 2022-08-19 21:00:23.650940\n",
      "resetting env. episode 1912, reward total was -20.0. running mean: -20.195235501676635, timestamp: 2022-08-19 21:00:26.334178\n",
      "resetting env. episode 1913, reward total was -20.0. running mean: -20.19328314665987, timestamp: 2022-08-19 21:00:29.711916\n",
      "resetting env. episode 1914, reward total was -21.0. running mean: -20.20135031519327, timestamp: 2022-08-19 21:00:32.633617\n",
      "resetting env. episode 1915, reward total was -20.0. running mean: -20.199336812041338, timestamp: 2022-08-19 21:00:36.551875\n",
      "resetting env. episode 1916, reward total was -20.0. running mean: -20.197343443920925, timestamp: 2022-08-19 21:00:40.086950\n",
      "resetting env. episode 1917, reward total was -20.0. running mean: -20.195370009481714, timestamp: 2022-08-19 21:00:43.498356\n",
      "resetting env. episode 1918, reward total was -20.0. running mean: -20.193416309386894, timestamp: 2022-08-19 21:00:47.227241\n",
      "resetting env. episode 1919, reward total was -19.0. running mean: -20.181482146293025, timestamp: 2022-08-19 21:00:51.998726\n",
      "resetting env. episode 1920, reward total was -21.0. running mean: -20.189667324830094, timestamp: 2022-08-19 21:00:56.691899\n",
      "resetting env. episode 1921, reward total was -21.0. running mean: -20.197770651581795, timestamp: 2022-08-19 21:00:59.755239\n",
      "resetting env. episode 1922, reward total was -21.0. running mean: -20.205792945065976, timestamp: 2022-08-19 21:01:03.749308\n",
      "resetting env. episode 1923, reward total was -20.0. running mean: -20.203735015615315, timestamp: 2022-08-19 21:01:07.141294\n",
      "resetting env. episode 1924, reward total was -19.0. running mean: -20.191697665459163, timestamp: 2022-08-19 21:01:10.478888\n",
      "resetting env. episode 1925, reward total was -21.0. running mean: -20.199780688804573, timestamp: 2022-08-19 21:01:13.521002\n",
      "resetting env. episode 1926, reward total was -21.0. running mean: -20.20778288191653, timestamp: 2022-08-19 21:01:20.758557\n",
      "resetting env. episode 1927, reward total was -19.0. running mean: -20.195705053097363, timestamp: 2022-08-19 21:01:26.865264\n",
      "resetting env. episode 1928, reward total was -18.0. running mean: -20.173748002566388, timestamp: 2022-08-19 21:01:33.943023\n",
      "resetting env. episode 1929, reward total was -18.0. running mean: -20.152010522540724, timestamp: 2022-08-19 21:01:40.264630\n",
      "resetting env. episode 1930, reward total was -21.0. running mean: -20.160490417315316, timestamp: 2022-08-19 21:01:45.545503\n",
      "resetting env. episode 1931, reward total was -20.0. running mean: -20.158885513142163, timestamp: 2022-08-19 21:01:51.098397\n",
      "resetting env. episode 1932, reward total was -21.0. running mean: -20.16729665801074, timestamp: 2022-08-19 21:01:55.622101\n",
      "resetting env. episode 1933, reward total was -21.0. running mean: -20.175623691430633, timestamp: 2022-08-19 21:01:59.415610\n",
      "resetting env. episode 1934, reward total was -19.0. running mean: -20.16386745451633, timestamp: 2022-08-19 21:02:03.482566\n",
      "resetting env. episode 1935, reward total was -21.0. running mean: -20.172228779971167, timestamp: 2022-08-19 21:02:07.880203\n",
      "resetting env. episode 1936, reward total was -20.0. running mean: -20.170506492171455, timestamp: 2022-08-19 21:02:11.665595\n",
      "resetting env. episode 1937, reward total was -17.0. running mean: -20.138801427249742, timestamp: 2022-08-19 21:02:15.432187\n",
      "resetting env. episode 1938, reward total was -20.0. running mean: -20.137413412977242, timestamp: 2022-08-19 21:02:20.141147\n",
      "resetting env. episode 1939, reward total was -20.0. running mean: -20.13603927884747, timestamp: 2022-08-19 21:02:26.308978\n",
      "resetting env. episode 1940, reward total was -21.0. running mean: -20.144678886058994, timestamp: 2022-08-19 21:02:30.040451\n",
      "resetting env. episode 1941, reward total was -18.0. running mean: -20.123232097198404, timestamp: 2022-08-19 21:02:37.866654\n",
      "resetting env. episode 1942, reward total was -19.0. running mean: -20.11199977622642, timestamp: 2022-08-19 21:02:44.095199\n",
      "resetting env. episode 1943, reward total was -21.0. running mean: -20.120879778464154, timestamp: 2022-08-19 21:02:47.077112\n",
      "resetting env. episode 1944, reward total was -21.0. running mean: -20.129670980679514, timestamp: 2022-08-19 21:02:50.844977\n",
      "resetting env. episode 1945, reward total was -18.0. running mean: -20.10837427087272, timestamp: 2022-08-19 21:02:55.829668\n",
      "resetting env. episode 1946, reward total was -21.0. running mean: -20.11729052816399, timestamp: 2022-08-19 21:02:59.022715\n",
      "resetting env. episode 1947, reward total was -20.0. running mean: -20.11611762288235, timestamp: 2022-08-19 21:03:03.808750\n",
      "resetting env. episode 1948, reward total was -21.0. running mean: -20.124956446653528, timestamp: 2022-08-19 21:03:07.870207\n",
      "resetting env. episode 1949, reward total was -21.0. running mean: -20.133706882186992, timestamp: 2022-08-19 21:03:14.944351\n",
      "resetting env. episode 1950, reward total was -18.0. running mean: -20.11236981336512, timestamp: 2022-08-19 21:03:21.308455\n",
      "resetting env. episode 1951, reward total was -21.0. running mean: -20.121246115231468, timestamp: 2022-08-19 21:03:25.318996\n",
      "resetting env. episode 1952, reward total was -21.0. running mean: -20.130033654079153, timestamp: 2022-08-19 21:03:28.736832\n",
      "resetting env. episode 1953, reward total was -21.0. running mean: -20.13873331753836, timestamp: 2022-08-19 21:03:32.538770\n",
      "resetting env. episode 1954, reward total was -21.0. running mean: -20.14734598436298, timestamp: 2022-08-19 21:03:36.680343\n",
      "resetting env. episode 1955, reward total was -19.0. running mean: -20.13587252451935, timestamp: 2022-08-19 21:03:41.698930\n",
      "resetting env. episode 1956, reward total was -21.0. running mean: -20.144513799274158, timestamp: 2022-08-19 21:03:47.260227\n",
      "resetting env. episode 1957, reward total was -18.0. running mean: -20.123068661281415, timestamp: 2022-08-19 21:03:53.551495\n",
      "resetting env. episode 1958, reward total was -21.0. running mean: -20.131837974668603, timestamp: 2022-08-19 21:03:57.564752\n",
      "resetting env. episode 1959, reward total was -21.0. running mean: -20.140519594921916, timestamp: 2022-08-19 21:04:04.115341\n",
      "resetting env. episode 1960, reward total was -20.0. running mean: -20.139114398972694, timestamp: 2022-08-19 21:04:10.167460\n",
      "resetting env. episode 1961, reward total was -21.0. running mean: -20.147723254982967, timestamp: 2022-08-19 21:04:14.628999\n",
      "resetting env. episode 1962, reward total was -20.0. running mean: -20.146246022433136, timestamp: 2022-08-19 21:04:19.903334\n",
      "resetting env. episode 1963, reward total was -20.0. running mean: -20.144783562208804, timestamp: 2022-08-19 21:04:25.708255\n",
      "resetting env. episode 1964, reward total was -20.0. running mean: -20.143335726586717, timestamp: 2022-08-19 21:04:32.131536\n",
      "resetting env. episode 1965, reward total was -20.0. running mean: -20.14190236932085, timestamp: 2022-08-19 21:04:38.726164\n",
      "resetting env. episode 1966, reward total was -19.0. running mean: -20.130483345627642, timestamp: 2022-08-19 21:04:47.937247\n",
      "resetting env. episode 1967, reward total was -20.0. running mean: -20.129178512171364, timestamp: 2022-08-19 21:04:53.436730\n",
      "resetting env. episode 1968, reward total was -19.0. running mean: -20.11788672704965, timestamp: 2022-08-19 21:04:57.154972\n",
      "resetting env. episode 1969, reward total was -20.0. running mean: -20.116707859779154, timestamp: 2022-08-19 21:05:01.108455\n",
      "resetting env. episode 1970, reward total was -21.0. running mean: -20.125540781181364, timestamp: 2022-08-19 21:05:04.190654\n",
      "resetting env. episode 1971, reward total was -19.0. running mean: -20.11428537336955, timestamp: 2022-08-19 21:05:08.163881\n",
      "resetting env. episode 1972, reward total was -21.0. running mean: -20.123142519635856, timestamp: 2022-08-19 21:05:10.969741\n",
      "resetting env. episode 1973, reward total was -21.0. running mean: -20.1319110944395, timestamp: 2022-08-19 21:05:14.875050\n",
      "resetting env. episode 1974, reward total was -20.0. running mean: -20.1305919834951, timestamp: 2022-08-19 21:05:19.266988\n",
      "resetting env. episode 1975, reward total was -19.0. running mean: -20.11928606366015, timestamp: 2022-08-19 21:05:23.243499\n",
      "resetting env. episode 1976, reward total was -21.0. running mean: -20.12809320302355, timestamp: 2022-08-19 21:05:26.835885\n",
      "resetting env. episode 1977, reward total was -20.0. running mean: -20.126812270993312, timestamp: 2022-08-19 21:05:31.443631\n",
      "resetting env. episode 1978, reward total was -19.0. running mean: -20.11554414828338, timestamp: 2022-08-19 21:05:36.645874\n",
      "resetting env. episode 1979, reward total was -19.0. running mean: -20.10438870680055, timestamp: 2022-08-19 21:05:42.899401\n",
      "resetting env. episode 1980, reward total was -20.0. running mean: -20.10334481973254, timestamp: 2022-08-19 21:05:48.148123\n",
      "resetting env. episode 1981, reward total was -20.0. running mean: -20.102311371535215, timestamp: 2022-08-19 21:05:53.794004\n",
      "resetting env. episode 1982, reward total was -21.0. running mean: -20.111288257819865, timestamp: 2022-08-19 21:05:58.601198\n",
      "resetting env. episode 1983, reward total was -20.0. running mean: -20.110175375241667, timestamp: 2022-08-19 21:06:02.146410\n",
      "resetting env. episode 1984, reward total was -21.0. running mean: -20.11907362148925, timestamp: 2022-08-19 21:06:05.672749\n",
      "resetting env. episode 1985, reward total was -21.0. running mean: -20.127882885274357, timestamp: 2022-08-19 21:06:09.826691\n",
      "resetting env. episode 1986, reward total was -18.0. running mean: -20.106604056421613, timestamp: 2022-08-19 21:06:13.764187\n",
      "resetting env. episode 1987, reward total was -21.0. running mean: -20.115538015857396, timestamp: 2022-08-19 21:06:17.026183\n",
      "resetting env. episode 1988, reward total was -21.0. running mean: -20.124382635698822, timestamp: 2022-08-19 21:06:20.112948\n",
      "resetting env. episode 1989, reward total was -20.0. running mean: -20.12313880934183, timestamp: 2022-08-19 21:06:24.774238\n",
      "resetting env. episode 1990, reward total was -21.0. running mean: -20.131907421248414, timestamp: 2022-08-19 21:06:28.814294\n",
      "resetting env. episode 1991, reward total was -21.0. running mean: -20.14058834703593, timestamp: 2022-08-19 21:06:32.523321\n",
      "resetting env. episode 1992, reward total was -19.0. running mean: -20.12918246356557, timestamp: 2022-08-19 21:06:36.390288\n",
      "resetting env. episode 1993, reward total was -19.0. running mean: -20.117890638929914, timestamp: 2022-08-19 21:06:40.346708\n",
      "resetting env. episode 1994, reward total was -21.0. running mean: -20.126711732540617, timestamp: 2022-08-19 21:06:44.004944\n",
      "resetting env. episode 1995, reward total was -20.0. running mean: -20.12544461521521, timestamp: 2022-08-19 21:06:47.806629\n",
      "resetting env. episode 1996, reward total was -20.0. running mean: -20.124190169063056, timestamp: 2022-08-19 21:06:52.710450\n",
      "resetting env. episode 1997, reward total was -21.0. running mean: -20.132948267372427, timestamp: 2022-08-19 21:06:56.272443\n",
      "resetting env. episode 1998, reward total was -20.0. running mean: -20.131618784698702, timestamp: 2022-08-19 21:06:59.839412\n",
      "resetting env. episode 1999, reward total was -21.0. running mean: -20.140302596851715, timestamp: 2022-08-19 21:07:03.678463\n",
      "resetting env. episode 2000, reward total was -20.0. running mean: -20.138899570883197, timestamp: 2022-08-19 21:07:07.795666\n",
      "resetting env. episode 2001, reward total was -21.0. running mean: -20.147510575174365, timestamp: 2022-08-19 21:07:11.066124\n",
      "resetting env. episode 2002, reward total was -20.0. running mean: -20.14603546942262, timestamp: 2022-08-19 21:07:14.471426\n",
      "resetting env. episode 2003, reward total was -20.0. running mean: -20.144575114728394, timestamp: 2022-08-19 21:07:17.710458\n",
      "resetting env. episode 2004, reward total was -20.0. running mean: -20.14312936358111, timestamp: 2022-08-19 21:07:21.559461\n",
      "resetting env. episode 2005, reward total was -20.0. running mean: -20.1416980699453, timestamp: 2022-08-19 21:07:24.744850\n",
      "resetting env. episode 2006, reward total was -21.0. running mean: -20.150281089245848, timestamp: 2022-08-19 21:07:28.638082\n",
      "resetting env. episode 2007, reward total was -20.0. running mean: -20.148778278353387, timestamp: 2022-08-19 21:07:32.247702\n",
      "resetting env. episode 2008, reward total was -19.0. running mean: -20.137290495569854, timestamp: 2022-08-19 21:07:36.972317\n",
      "resetting env. episode 2009, reward total was -21.0. running mean: -20.145917590614157, timestamp: 2022-08-19 21:07:41.395141\n",
      "resetting env. episode 2010, reward total was -21.0. running mean: -20.154458414708017, timestamp: 2022-08-19 21:07:46.733755\n",
      "resetting env. episode 2011, reward total was -21.0. running mean: -20.16291383056094, timestamp: 2022-08-19 21:07:53.497043\n",
      "resetting env. episode 2012, reward total was -21.0. running mean: -20.17128469225533, timestamp: 2022-08-19 21:07:59.372121\n",
      "resetting env. episode 2013, reward total was -20.0. running mean: -20.169571845332776, timestamp: 2022-08-19 21:08:04.740557\n",
      "resetting env. episode 2014, reward total was -21.0. running mean: -20.177876126879447, timestamp: 2022-08-19 21:08:09.563998\n",
      "resetting env. episode 2015, reward total was -20.0. running mean: -20.17609736561065, timestamp: 2022-08-19 21:08:14.573110\n",
      "resetting env. episode 2016, reward total was -21.0. running mean: -20.184336391954545, timestamp: 2022-08-19 21:08:19.121143\n",
      "resetting env. episode 2017, reward total was -20.0. running mean: -20.182493028034997, timestamp: 2022-08-19 21:08:23.832129\n",
      "resetting env. episode 2018, reward total was -21.0. running mean: -20.19066809775465, timestamp: 2022-08-19 21:08:28.854964\n",
      "resetting env. episode 2019, reward total was -18.0. running mean: -20.1687614167771, timestamp: 2022-08-19 21:08:34.713716\n",
      "resetting env. episode 2020, reward total was -20.0. running mean: -20.16707380260933, timestamp: 2022-08-19 21:08:39.233352\n",
      "resetting env. episode 2021, reward total was -21.0. running mean: -20.17540306458324, timestamp: 2022-08-19 21:08:42.327453\n",
      "resetting env. episode 2022, reward total was -21.0. running mean: -20.183649033937407, timestamp: 2022-08-19 21:08:46.922340\n",
      "resetting env. episode 2023, reward total was -19.0. running mean: -20.171812543598033, timestamp: 2022-08-19 21:08:51.828710\n",
      "resetting env. episode 2024, reward total was -20.0. running mean: -20.17009441816205, timestamp: 2022-08-19 21:08:55.504550\n",
      "resetting env. episode 2025, reward total was -20.0. running mean: -20.16839347398043, timestamp: 2022-08-19 21:08:59.808040\n",
      "resetting env. episode 2026, reward total was -21.0. running mean: -20.176709539240626, timestamp: 2022-08-19 21:09:04.147237\n",
      "resetting env. episode 2027, reward total was -21.0. running mean: -20.18494244384822, timestamp: 2022-08-19 21:09:08.197614\n",
      "resetting env. episode 2028, reward total was -20.0. running mean: -20.18309301940974, timestamp: 2022-08-19 21:09:11.839893\n",
      "resetting env. episode 2029, reward total was -20.0. running mean: -20.18126208921564, timestamp: 2022-08-19 21:09:18.074583\n",
      "resetting env. episode 2030, reward total was -21.0. running mean: -20.189449468323485, timestamp: 2022-08-19 21:09:21.457300\n",
      "resetting env. episode 2031, reward total was -21.0. running mean: -20.19755497364025, timestamp: 2022-08-19 21:09:25.130615\n",
      "resetting env. episode 2032, reward total was -17.0. running mean: -20.16557942390385, timestamp: 2022-08-19 21:09:30.517137\n",
      "resetting env. episode 2033, reward total was -21.0. running mean: -20.173923629664813, timestamp: 2022-08-19 21:09:34.809450\n",
      "resetting env. episode 2034, reward total was -20.0. running mean: -20.172184393368163, timestamp: 2022-08-19 21:09:39.317486\n",
      "resetting env. episode 2035, reward total was -21.0. running mean: -20.18046254943448, timestamp: 2022-08-19 21:09:42.698698\n",
      "resetting env. episode 2036, reward total was -19.0. running mean: -20.16865792394014, timestamp: 2022-08-19 21:09:48.754813\n",
      "resetting env. episode 2037, reward total was -20.0. running mean: -20.166971344700737, timestamp: 2022-08-19 21:09:53.793363\n",
      "resetting env. episode 2038, reward total was -21.0. running mean: -20.17530163125373, timestamp: 2022-08-19 21:09:58.534646\n",
      "resetting env. episode 2039, reward total was -21.0. running mean: -20.183548614941195, timestamp: 2022-08-19 21:10:02.255211\n",
      "resetting env. episode 2040, reward total was -21.0. running mean: -20.191713128791783, timestamp: 2022-08-19 21:10:06.864373\n",
      "resetting env. episode 2041, reward total was -20.0. running mean: -20.189795997503865, timestamp: 2022-08-19 21:10:11.308220\n",
      "resetting env. episode 2042, reward total was -18.0. running mean: -20.167898037528825, timestamp: 2022-08-19 21:10:16.984566\n",
      "resetting env. episode 2043, reward total was -20.0. running mean: -20.166219057153537, timestamp: 2022-08-19 21:10:22.808668\n",
      "resetting env. episode 2044, reward total was -21.0. running mean: -20.174556866582, timestamp: 2022-08-19 21:10:26.785914\n",
      "resetting env. episode 2045, reward total was -21.0. running mean: -20.18281129791618, timestamp: 2022-08-19 21:10:31.426997\n",
      "resetting env. episode 2046, reward total was -21.0. running mean: -20.19098318493702, timestamp: 2022-08-19 21:10:35.129870\n",
      "resetting env. episode 2047, reward total was -21.0. running mean: -20.199073353087652, timestamp: 2022-08-19 21:10:39.622175\n",
      "resetting env. episode 2048, reward total was -19.0. running mean: -20.187082619556776, timestamp: 2022-08-19 21:10:44.393409\n",
      "resetting env. episode 2049, reward total was -20.0. running mean: -20.18521179336121, timestamp: 2022-08-19 21:10:48.721115\n",
      "resetting env. episode 2050, reward total was -19.0. running mean: -20.173359675427598, timestamp: 2022-08-19 21:10:56.072087\n",
      "resetting env. episode 2051, reward total was -21.0. running mean: -20.18162607867332, timestamp: 2022-08-19 21:11:00.344580\n",
      "resetting env. episode 2052, reward total was -21.0. running mean: -20.18980981788659, timestamp: 2022-08-19 21:11:05.685083\n",
      "resetting env. episode 2053, reward total was -19.0. running mean: -20.177911719707726, timestamp: 2022-08-19 21:11:13.127486\n",
      "resetting env. episode 2054, reward total was -21.0. running mean: -20.18613260251065, timestamp: 2022-08-19 21:11:18.567777\n",
      "resetting env. episode 2055, reward total was -21.0. running mean: -20.194271276485544, timestamp: 2022-08-19 21:11:23.985914\n",
      "resetting env. episode 2056, reward total was -20.0. running mean: -20.19232856372069, timestamp: 2022-08-19 21:11:28.667001\n",
      "resetting env. episode 2057, reward total was -21.0. running mean: -20.200405278083483, timestamp: 2022-08-19 21:11:33.793425\n",
      "resetting env. episode 2058, reward total was -20.0. running mean: -20.198401225302646, timestamp: 2022-08-19 21:11:38.034278\n",
      "resetting env. episode 2059, reward total was -20.0. running mean: -20.196417213049617, timestamp: 2022-08-19 21:11:41.772414\n",
      "resetting env. episode 2060, reward total was -20.0. running mean: -20.19445304091912, timestamp: 2022-08-19 21:11:47.731419\n",
      "resetting env. episode 2061, reward total was -20.0. running mean: -20.192508510509928, timestamp: 2022-08-19 21:11:52.254364\n",
      "resetting env. episode 2062, reward total was -18.0. running mean: -20.17058342540483, timestamp: 2022-08-19 21:11:56.785301\n",
      "resetting env. episode 2063, reward total was -20.0. running mean: -20.16887759115078, timestamp: 2022-08-19 21:12:01.061993\n",
      "resetting env. episode 2064, reward total was -20.0. running mean: -20.16718881523927, timestamp: 2022-08-19 21:12:05.353356\n",
      "resetting env. episode 2065, reward total was -20.0. running mean: -20.165516927086877, timestamp: 2022-08-19 21:12:09.392626\n",
      "resetting env. episode 2066, reward total was -21.0. running mean: -20.17386175781601, timestamp: 2022-08-19 21:12:13.658689\n",
      "resetting env. episode 2067, reward total was -21.0. running mean: -20.18212314023785, timestamp: 2022-08-19 21:12:18.880053\n",
      "resetting env. episode 2068, reward total was -19.0. running mean: -20.170301908835473, timestamp: 2022-08-19 21:12:23.541854\n",
      "resetting env. episode 2069, reward total was -21.0. running mean: -20.178598889747118, timestamp: 2022-08-19 21:12:27.605233\n",
      "resetting env. episode 2070, reward total was -21.0. running mean: -20.18681290084965, timestamp: 2022-08-19 21:12:31.674931\n",
      "resetting env. episode 2071, reward total was -19.0. running mean: -20.174944771841155, timestamp: 2022-08-19 21:12:36.623501\n",
      "resetting env. episode 2072, reward total was -20.0. running mean: -20.17319532412274, timestamp: 2022-08-19 21:12:40.536975\n",
      "resetting env. episode 2073, reward total was -21.0. running mean: -20.181463370881513, timestamp: 2022-08-19 21:12:45.024361\n",
      "resetting env. episode 2074, reward total was -20.0. running mean: -20.1796487371727, timestamp: 2022-08-19 21:12:49.018904\n",
      "resetting env. episode 2075, reward total was -21.0. running mean: -20.187852249800972, timestamp: 2022-08-19 21:12:51.632672\n",
      "resetting env. episode 2076, reward total was -19.0. running mean: -20.175973727302964, timestamp: 2022-08-19 21:12:54.559778\n",
      "resetting env. episode 2077, reward total was -18.0. running mean: -20.154213990029934, timestamp: 2022-08-19 21:12:58.922592\n",
      "resetting env. episode 2078, reward total was -19.0. running mean: -20.142671850129634, timestamp: 2022-08-19 21:13:02.560027\n",
      "resetting env. episode 2079, reward total was -21.0. running mean: -20.15124513162834, timestamp: 2022-08-19 21:13:05.080749\n",
      "resetting env. episode 2080, reward total was -20.0. running mean: -20.149732680312056, timestamp: 2022-08-19 21:13:08.253214\n",
      "resetting env. episode 2081, reward total was -20.0. running mean: -20.148235353508934, timestamp: 2022-08-19 21:13:11.528496\n",
      "resetting env. episode 2082, reward total was -21.0. running mean: -20.156752999973847, timestamp: 2022-08-19 21:13:14.600227\n",
      "resetting env. episode 2083, reward total was -20.0. running mean: -20.155185469974107, timestamp: 2022-08-19 21:13:17.230749\n",
      "resetting env. episode 2084, reward total was -19.0. running mean: -20.143633615274368, timestamp: 2022-08-19 21:13:20.410312\n",
      "resetting env. episode 2085, reward total was -20.0. running mean: -20.142197279121625, timestamp: 2022-08-19 21:13:24.142757\n",
      "resetting env. episode 2086, reward total was -21.0. running mean: -20.15077530633041, timestamp: 2022-08-19 21:13:27.480781\n",
      "resetting env. episode 2087, reward total was -21.0. running mean: -20.159267553267107, timestamp: 2022-08-19 21:13:31.377830\n",
      "resetting env. episode 2088, reward total was -21.0. running mean: -20.167674877734438, timestamp: 2022-08-19 21:13:37.809833\n",
      "resetting env. episode 2089, reward total was -21.0. running mean: -20.175998128957094, timestamp: 2022-08-19 21:13:42.054092\n",
      "resetting env. episode 2090, reward total was -21.0. running mean: -20.184238147667525, timestamp: 2022-08-19 21:13:45.777397\n",
      "resetting env. episode 2091, reward total was -19.0. running mean: -20.17239576619085, timestamp: 2022-08-19 21:13:49.332712\n",
      "resetting env. episode 2092, reward total was -21.0. running mean: -20.180671808528942, timestamp: 2022-08-19 21:13:52.401737\n",
      "resetting env. episode 2093, reward total was -21.0. running mean: -20.188865090443652, timestamp: 2022-08-19 21:13:55.804403\n",
      "resetting env. episode 2094, reward total was -21.0. running mean: -20.196976439539217, timestamp: 2022-08-19 21:13:58.303397\n",
      "resetting env. episode 2095, reward total was -19.0. running mean: -20.185006675143825, timestamp: 2022-08-19 21:14:01.851596\n",
      "resetting env. episode 2096, reward total was -21.0. running mean: -20.19315660839239, timestamp: 2022-08-19 21:14:05.430374\n",
      "resetting env. episode 2097, reward total was -21.0. running mean: -20.201225042308465, timestamp: 2022-08-19 21:14:07.712629\n",
      "resetting env. episode 2098, reward total was -21.0. running mean: -20.20921279188538, timestamp: 2022-08-19 21:14:11.188346\n",
      "resetting env. episode 2099, reward total was -17.0. running mean: -20.17712066396653, timestamp: 2022-08-19 21:14:14.564503\n",
      "resetting env. episode 2100, reward total was -21.0. running mean: -20.185349457326865, timestamp: 2022-08-19 21:14:17.924319\n",
      "resetting env. episode 2101, reward total was -20.0. running mean: -20.183495962753597, timestamp: 2022-08-19 21:14:20.515752\n",
      "resetting env. episode 2102, reward total was -19.0. running mean: -20.17166100312606, timestamp: 2022-08-19 21:14:23.936489\n",
      "resetting env. episode 2103, reward total was -21.0. running mean: -20.1799443930948, timestamp: 2022-08-19 21:14:26.618537\n",
      "resetting env. episode 2104, reward total was -21.0. running mean: -20.188144949163853, timestamp: 2022-08-19 21:14:29.103244\n",
      "resetting env. episode 2105, reward total was -21.0. running mean: -20.196263499672217, timestamp: 2022-08-19 21:14:31.992830\n",
      "resetting env. episode 2106, reward total was -20.0. running mean: -20.194300864675494, timestamp: 2022-08-19 21:14:35.454921\n",
      "resetting env. episode 2107, reward total was -21.0. running mean: -20.20235785602874, timestamp: 2022-08-19 21:14:37.606681\n",
      "resetting env. episode 2108, reward total was -21.0. running mean: -20.210334277468455, timestamp: 2022-08-19 21:14:40.496150\n",
      "resetting env. episode 2109, reward total was -18.0. running mean: -20.18823093469377, timestamp: 2022-08-19 21:14:44.112775\n",
      "resetting env. episode 2110, reward total was -21.0. running mean: -20.196348625346833, timestamp: 2022-08-19 21:14:46.940528\n",
      "resetting env. episode 2111, reward total was -21.0. running mean: -20.204385139093365, timestamp: 2022-08-19 21:14:50.755100\n",
      "resetting env. episode 2112, reward total was -21.0. running mean: -20.212341287702433, timestamp: 2022-08-19 21:14:53.358579\n",
      "resetting env. episode 2113, reward total was -21.0. running mean: -20.22021787482541, timestamp: 2022-08-19 21:14:55.976685\n",
      "resetting env. episode 2114, reward total was -21.0. running mean: -20.228015696077154, timestamp: 2022-08-19 21:14:58.655562\n",
      "resetting env. episode 2115, reward total was -20.0. running mean: -20.225735539116382, timestamp: 2022-08-19 21:15:02.334565\n",
      "resetting env. episode 2116, reward total was -21.0. running mean: -20.233478183725218, timestamp: 2022-08-19 21:15:05.526850\n",
      "resetting env. episode 2117, reward total was -19.0. running mean: -20.221143401887968, timestamp: 2022-08-19 21:15:08.868760\n",
      "resetting env. episode 2118, reward total was -19.0. running mean: -20.208931967869088, timestamp: 2022-08-19 21:15:12.433334\n",
      "resetting env. episode 2119, reward total was -21.0. running mean: -20.216842648190397, timestamp: 2022-08-19 21:15:15.434812\n",
      "resetting env. episode 2120, reward total was -21.0. running mean: -20.224674221708494, timestamp: 2022-08-19 21:15:18.351990\n",
      "resetting env. episode 2121, reward total was -21.0. running mean: -20.23242747949141, timestamp: 2022-08-19 21:15:22.314742\n",
      "resetting env. episode 2122, reward total was -21.0. running mean: -20.240103204696496, timestamp: 2022-08-19 21:15:24.954533\n",
      "resetting env. episode 2123, reward total was -21.0. running mean: -20.247702172649532, timestamp: 2022-08-19 21:15:27.710072\n",
      "resetting env. episode 2124, reward total was -19.0. running mean: -20.23522515092304, timestamp: 2022-08-19 21:15:30.798066\n",
      "resetting env. episode 2125, reward total was -17.0. running mean: -20.202872899413812, timestamp: 2022-08-19 21:15:35.491750\n",
      "resetting env. episode 2126, reward total was -21.0. running mean: -20.210844170419673, timestamp: 2022-08-19 21:15:38.634994\n",
      "resetting env. episode 2127, reward total was -21.0. running mean: -20.218735728715476, timestamp: 2022-08-19 21:15:41.654194\n",
      "resetting env. episode 2128, reward total was -19.0. running mean: -20.206548371428322, timestamp: 2022-08-19 21:15:45.647526\n",
      "resetting env. episode 2129, reward total was -20.0. running mean: -20.20448288771404, timestamp: 2022-08-19 21:15:50.528021\n",
      "resetting env. episode 2130, reward total was -21.0. running mean: -20.2124380588369, timestamp: 2022-08-19 21:15:55.602802\n",
      "resetting env. episode 2131, reward total was -21.0. running mean: -20.22031367824853, timestamp: 2022-08-19 21:15:59.100137\n",
      "resetting env. episode 2132, reward total was -19.0. running mean: -20.208110541466045, timestamp: 2022-08-19 21:16:03.683138\n",
      "resetting env. episode 2133, reward total was -21.0. running mean: -20.216029436051386, timestamp: 2022-08-19 21:16:06.882632\n",
      "resetting env. episode 2134, reward total was -20.0. running mean: -20.21386914169087, timestamp: 2022-08-19 21:16:11.264970\n",
      "resetting env. episode 2135, reward total was -19.0. running mean: -20.201730450273963, timestamp: 2022-08-19 21:16:15.761640\n",
      "resetting env. episode 2136, reward total was -20.0. running mean: -20.199713145771224, timestamp: 2022-08-19 21:16:19.652557\n",
      "resetting env. episode 2137, reward total was -20.0. running mean: -20.19771601431351, timestamp: 2022-08-19 21:16:24.492389\n",
      "resetting env. episode 2138, reward total was -20.0. running mean: -20.195738854170376, timestamp: 2022-08-19 21:16:28.146620\n",
      "resetting env. episode 2139, reward total was -21.0. running mean: -20.203781465628673, timestamp: 2022-08-19 21:16:31.140620\n",
      "resetting env. episode 2140, reward total was -20.0. running mean: -20.201743650972386, timestamp: 2022-08-19 21:16:34.566486\n",
      "resetting env. episode 2141, reward total was -16.0. running mean: -20.159726214462662, timestamp: 2022-08-19 21:16:39.673269\n",
      "resetting env. episode 2142, reward total was -21.0. running mean: -20.168128952318035, timestamp: 2022-08-19 21:16:43.088359\n",
      "resetting env. episode 2143, reward total was -20.0. running mean: -20.166447662794855, timestamp: 2022-08-19 21:16:46.300772\n",
      "resetting env. episode 2144, reward total was -19.0. running mean: -20.154783186166906, timestamp: 2022-08-19 21:16:50.640756\n",
      "resetting env. episode 2145, reward total was -21.0. running mean: -20.163235354305236, timestamp: 2022-08-19 21:16:54.320067\n",
      "resetting env. episode 2146, reward total was -21.0. running mean: -20.171603000762186, timestamp: 2022-08-19 21:16:57.287159\n",
      "resetting env. episode 2147, reward total was -19.0. running mean: -20.159886970754567, timestamp: 2022-08-19 21:17:00.550415\n",
      "resetting env. episode 2148, reward total was -20.0. running mean: -20.15828810104702, timestamp: 2022-08-19 21:17:03.779780\n",
      "resetting env. episode 2149, reward total was -20.0. running mean: -20.15670522003655, timestamp: 2022-08-19 21:17:07.452967\n",
      "resetting env. episode 2150, reward total was -20.0. running mean: -20.15513816783618, timestamp: 2022-08-19 21:17:11.331093\n",
      "resetting env. episode 2151, reward total was -21.0. running mean: -20.163586786157822, timestamp: 2022-08-19 21:17:14.090051\n",
      "resetting env. episode 2152, reward total was -21.0. running mean: -20.171950918296243, timestamp: 2022-08-19 21:17:16.768891\n",
      "resetting env. episode 2153, reward total was -21.0. running mean: -20.180231409113283, timestamp: 2022-08-19 21:17:20.529840\n",
      "resetting env. episode 2154, reward total was -21.0. running mean: -20.18842909502215, timestamp: 2022-08-19 21:17:24.977947\n",
      "resetting env. episode 2155, reward total was -19.0. running mean: -20.17654480407193, timestamp: 2022-08-19 21:17:27.924201\n",
      "resetting env. episode 2156, reward total was -21.0. running mean: -20.18477935603121, timestamp: 2022-08-19 21:17:30.326535\n",
      "resetting env. episode 2157, reward total was -21.0. running mean: -20.1929315624709, timestamp: 2022-08-19 21:17:33.243763\n",
      "resetting env. episode 2158, reward total was -21.0. running mean: -20.20100224684619, timestamp: 2022-08-19 21:17:36.234885\n",
      "resetting env. episode 2159, reward total was -21.0. running mean: -20.20899222437773, timestamp: 2022-08-19 21:17:39.459266\n",
      "resetting env. episode 2160, reward total was -21.0. running mean: -20.216902302133953, timestamp: 2022-08-19 21:17:42.389693\n",
      "resetting env. episode 2161, reward total was -20.0. running mean: -20.21473327911261, timestamp: 2022-08-19 21:17:44.907472\n",
      "resetting env. episode 2162, reward total was -21.0. running mean: -20.222585946321484, timestamp: 2022-08-19 21:17:48.186672\n",
      "resetting env. episode 2163, reward total was -21.0. running mean: -20.23036008685827, timestamp: 2022-08-19 21:17:52.097219\n",
      "resetting env. episode 2164, reward total was -21.0. running mean: -20.238056485989688, timestamp: 2022-08-19 21:17:55.179724\n",
      "resetting env. episode 2165, reward total was -20.0. running mean: -20.23567592112979, timestamp: 2022-08-19 21:17:58.336339\n",
      "resetting env. episode 2166, reward total was -20.0. running mean: -20.23331916191849, timestamp: 2022-08-19 21:18:02.721233\n",
      "resetting env. episode 2167, reward total was -20.0. running mean: -20.230985970299304, timestamp: 2022-08-19 21:18:05.028095\n",
      "resetting env. episode 2168, reward total was -21.0. running mean: -20.238676110596312, timestamp: 2022-08-19 21:18:08.460891\n",
      "resetting env. episode 2169, reward total was -21.0. running mean: -20.24628934949035, timestamp: 2022-08-19 21:18:11.400033\n",
      "resetting env. episode 2170, reward total was -19.0. running mean: -20.233826455995448, timestamp: 2022-08-19 21:18:17.125729\n",
      "resetting env. episode 2171, reward total was -21.0. running mean: -20.241488191435494, timestamp: 2022-08-19 21:18:21.915415\n",
      "resetting env. episode 2172, reward total was -19.0. running mean: -20.22907330952114, timestamp: 2022-08-19 21:18:26.015466\n",
      "resetting env. episode 2173, reward total was -21.0. running mean: -20.23678257642593, timestamp: 2022-08-19 21:18:29.520097\n",
      "resetting env. episode 2174, reward total was -21.0. running mean: -20.244414750661672, timestamp: 2022-08-19 21:18:32.422178\n",
      "resetting env. episode 2175, reward total was -21.0. running mean: -20.251970603155055, timestamp: 2022-08-19 21:18:35.460792\n",
      "resetting env. episode 2176, reward total was -20.0. running mean: -20.249450897123502, timestamp: 2022-08-19 21:18:38.703595\n",
      "resetting env. episode 2177, reward total was -21.0. running mean: -20.25695638815227, timestamp: 2022-08-19 21:18:42.166030\n",
      "resetting env. episode 2178, reward total was -21.0. running mean: -20.264386824270748, timestamp: 2022-08-19 21:18:44.554625\n",
      "resetting env. episode 2179, reward total was -19.0. running mean: -20.251742956028043, timestamp: 2022-08-19 21:18:47.760598\n",
      "resetting env. episode 2180, reward total was -19.0. running mean: -20.239225526467763, timestamp: 2022-08-19 21:18:51.136213\n",
      "resetting env. episode 2181, reward total was -21.0. running mean: -20.246833271203087, timestamp: 2022-08-19 21:18:53.321818\n",
      "resetting env. episode 2182, reward total was -18.0. running mean: -20.224364938491057, timestamp: 2022-08-19 21:18:56.326756\n",
      "resetting env. episode 2183, reward total was -20.0. running mean: -20.222121289106145, timestamp: 2022-08-19 21:18:59.080996\n",
      "resetting env. episode 2184, reward total was -20.0. running mean: -20.219900076215083, timestamp: 2022-08-19 21:19:02.486859\n",
      "resetting env. episode 2185, reward total was -18.0. running mean: -20.197701075452933, timestamp: 2022-08-19 21:19:05.742166\n",
      "resetting env. episode 2186, reward total was -21.0. running mean: -20.205724064698405, timestamp: 2022-08-19 21:19:08.679345\n",
      "resetting env. episode 2187, reward total was -21.0. running mean: -20.213666824051423, timestamp: 2022-08-19 21:19:11.180621\n",
      "resetting env. episode 2188, reward total was -21.0. running mean: -20.22153015581091, timestamp: 2022-08-19 21:19:14.452873\n",
      "resetting env. episode 2189, reward total was -21.0. running mean: -20.229314854252802, timestamp: 2022-08-19 21:19:16.773669\n",
      "resetting env. episode 2190, reward total was -21.0. running mean: -20.237021705710276, timestamp: 2022-08-19 21:19:19.513377\n",
      "resetting env. episode 2191, reward total was -21.0. running mean: -20.244651488653176, timestamp: 2022-08-19 21:19:21.858748\n",
      "resetting env. episode 2192, reward total was -21.0. running mean: -20.252204973766645, timestamp: 2022-08-19 21:19:24.424889\n",
      "resetting env. episode 2193, reward total was -20.0. running mean: -20.249682924028978, timestamp: 2022-08-19 21:19:28.403877\n",
      "resetting env. episode 2194, reward total was -20.0. running mean: -20.247186094788688, timestamp: 2022-08-19 21:19:31.525882\n",
      "resetting env. episode 2195, reward total was -19.0. running mean: -20.2347142338408, timestamp: 2022-08-19 21:19:35.821405\n",
      "resetting env. episode 2196, reward total was -20.0. running mean: -20.232367091502393, timestamp: 2022-08-19 21:19:38.959038\n",
      "resetting env. episode 2197, reward total was -19.0. running mean: -20.22004342058737, timestamp: 2022-08-19 21:19:41.448795\n",
      "resetting env. episode 2198, reward total was -21.0. running mean: -20.227842986381496, timestamp: 2022-08-19 21:19:44.981754\n",
      "resetting env. episode 2199, reward total was -21.0. running mean: -20.235564556517684, timestamp: 2022-08-19 21:19:47.235683\n",
      "resetting env. episode 2200, reward total was -20.0. running mean: -20.233208910952506, timestamp: 2022-08-19 21:19:49.944387\n",
      "resetting env. episode 2201, reward total was -20.0. running mean: -20.23087682184298, timestamp: 2022-08-19 21:19:52.508367\n",
      "resetting env. episode 2202, reward total was -19.0. running mean: -20.21856805362455, timestamp: 2022-08-19 21:19:56.339263\n",
      "resetting env. episode 2203, reward total was -20.0. running mean: -20.216382373088305, timestamp: 2022-08-19 21:19:59.668063\n",
      "resetting env. episode 2204, reward total was -19.0. running mean: -20.20421854935742, timestamp: 2022-08-19 21:20:02.572024\n",
      "resetting env. episode 2205, reward total was -21.0. running mean: -20.212176363863847, timestamp: 2022-08-19 21:20:05.338701\n",
      "resetting env. episode 2206, reward total was -20.0. running mean: -20.210054600225206, timestamp: 2022-08-19 21:20:08.457412\n",
      "resetting env. episode 2207, reward total was -19.0. running mean: -20.197954054222954, timestamp: 2022-08-19 21:20:11.828402\n",
      "resetting env. episode 2208, reward total was -19.0. running mean: -20.185974513680726, timestamp: 2022-08-19 21:20:15.501083\n",
      "resetting env. episode 2209, reward total was -21.0. running mean: -20.19411476854392, timestamp: 2022-08-19 21:20:18.623640\n",
      "resetting env. episode 2210, reward total was -21.0. running mean: -20.20217362085848, timestamp: 2022-08-19 21:20:23.325071\n",
      "resetting env. episode 2211, reward total was -21.0. running mean: -20.210151884649896, timestamp: 2022-08-19 21:20:26.110700\n",
      "resetting env. episode 2212, reward total was -21.0. running mean: -20.218050365803396, timestamp: 2022-08-19 21:20:28.702226\n",
      "resetting env. episode 2213, reward total was -21.0. running mean: -20.225869862145363, timestamp: 2022-08-19 21:20:31.332200\n",
      "resetting env. episode 2214, reward total was -19.0. running mean: -20.21361116352391, timestamp: 2022-08-19 21:20:35.610156\n",
      "resetting env. episode 2215, reward total was -20.0. running mean: -20.21147505188867, timestamp: 2022-08-19 21:20:38.659901\n",
      "resetting env. episode 2216, reward total was -21.0. running mean: -20.219360301369782, timestamp: 2022-08-19 21:20:41.212971\n",
      "resetting env. episode 2217, reward total was -21.0. running mean: -20.227166698356086, timestamp: 2022-08-19 21:20:44.576660\n",
      "resetting env. episode 2218, reward total was -21.0. running mean: -20.234895031372528, timestamp: 2022-08-19 21:20:47.341179\n",
      "resetting env. episode 2219, reward total was -21.0. running mean: -20.2425460810588, timestamp: 2022-08-19 21:20:50.533310\n",
      "resetting env. episode 2220, reward total was -20.0. running mean: -20.240120620248213, timestamp: 2022-08-19 21:20:54.436366\n",
      "resetting env. episode 2221, reward total was -18.0. running mean: -20.21771941404573, timestamp: 2022-08-19 21:20:57.992488\n",
      "resetting env. episode 2222, reward total was -21.0. running mean: -20.225542219905275, timestamp: 2022-08-19 21:21:00.931419\n",
      "resetting env. episode 2223, reward total was -21.0. running mean: -20.233286797706224, timestamp: 2022-08-19 21:21:04.960651\n",
      "resetting env. episode 2224, reward total was -20.0. running mean: -20.23095392972916, timestamp: 2022-08-19 21:21:08.355034\n",
      "resetting env. episode 2225, reward total was -21.0. running mean: -20.23864439043187, timestamp: 2022-08-19 21:21:10.859017\n",
      "resetting env. episode 2226, reward total was -20.0. running mean: -20.236257946527548, timestamp: 2022-08-19 21:21:16.185781\n",
      "resetting env. episode 2227, reward total was -20.0. running mean: -20.23389536706227, timestamp: 2022-08-19 21:21:21.264205\n",
      "resetting env. episode 2228, reward total was -18.0. running mean: -20.211556413391648, timestamp: 2022-08-19 21:21:28.160769\n",
      "resetting env. episode 2229, reward total was -20.0. running mean: -20.20944084925773, timestamp: 2022-08-19 21:21:33.245179\n",
      "resetting env. episode 2230, reward total was -21.0. running mean: -20.217346440765155, timestamp: 2022-08-19 21:21:36.778490\n",
      "resetting env. episode 2231, reward total was -20.0. running mean: -20.215172976357504, timestamp: 2022-08-19 21:21:39.404987\n",
      "resetting env. episode 2232, reward total was -19.0. running mean: -20.20302124659393, timestamp: 2022-08-19 21:21:42.361084\n",
      "resetting env. episode 2233, reward total was -20.0. running mean: -20.20099103412799, timestamp: 2022-08-19 21:21:44.764749\n",
      "resetting env. episode 2234, reward total was -20.0. running mean: -20.19898112378671, timestamp: 2022-08-19 21:21:48.250089\n",
      "resetting env. episode 2235, reward total was -21.0. running mean: -20.206991312548844, timestamp: 2022-08-19 21:21:51.215561\n",
      "resetting env. episode 2236, reward total was -21.0. running mean: -20.214921399423357, timestamp: 2022-08-19 21:21:54.172485\n",
      "resetting env. episode 2237, reward total was -21.0. running mean: -20.222772185429125, timestamp: 2022-08-19 21:21:57.241442\n",
      "resetting env. episode 2238, reward total was -19.0. running mean: -20.210544463574834, timestamp: 2022-08-19 21:22:00.515157\n",
      "resetting env. episode 2239, reward total was -20.0. running mean: -20.208439018939085, timestamp: 2022-08-19 21:22:03.266359\n",
      "resetting env. episode 2240, reward total was -21.0. running mean: -20.216354628749695, timestamp: 2022-08-19 21:22:06.014947\n",
      "resetting env. episode 2241, reward total was -21.0. running mean: -20.224191082462198, timestamp: 2022-08-19 21:22:08.325352\n",
      "resetting env. episode 2242, reward total was -20.0. running mean: -20.221949171637576, timestamp: 2022-08-19 21:22:12.522137\n",
      "resetting env. episode 2243, reward total was -20.0. running mean: -20.219729679921198, timestamp: 2022-08-19 21:22:17.625490\n",
      "resetting env. episode 2244, reward total was -21.0. running mean: -20.227532383121986, timestamp: 2022-08-19 21:22:20.463903\n",
      "resetting env. episode 2245, reward total was -20.0. running mean: -20.225257059290765, timestamp: 2022-08-19 21:22:23.748126\n",
      "resetting env. episode 2246, reward total was -19.0. running mean: -20.21300448869786, timestamp: 2022-08-19 21:22:27.588358\n",
      "resetting env. episode 2247, reward total was -21.0. running mean: -20.22087444381088, timestamp: 2022-08-19 21:22:30.541443\n",
      "resetting env. episode 2248, reward total was -20.0. running mean: -20.21866569937277, timestamp: 2022-08-19 21:22:34.862450\n",
      "resetting env. episode 2249, reward total was -21.0. running mean: -20.226479042379044, timestamp: 2022-08-19 21:22:38.571526\n",
      "resetting env. episode 2250, reward total was -19.0. running mean: -20.214214251955255, timestamp: 2022-08-19 21:22:44.006996\n",
      "resetting env. episode 2251, reward total was -19.0. running mean: -20.202072109435704, timestamp: 2022-08-19 21:22:49.264944\n",
      "resetting env. episode 2252, reward total was -21.0. running mean: -20.21005138834135, timestamp: 2022-08-19 21:22:53.362988\n",
      "resetting env. episode 2253, reward total was -21.0. running mean: -20.217950874457937, timestamp: 2022-08-19 21:22:57.129405\n",
      "resetting env. episode 2254, reward total was -20.0. running mean: -20.21577136571336, timestamp: 2022-08-19 21:23:00.847433\n",
      "resetting env. episode 2255, reward total was -20.0. running mean: -20.213613652056225, timestamp: 2022-08-19 21:23:04.329502\n",
      "resetting env. episode 2256, reward total was -21.0. running mean: -20.221477515535664, timestamp: 2022-08-19 21:23:07.729414\n",
      "resetting env. episode 2257, reward total was -20.0. running mean: -20.219262740380305, timestamp: 2022-08-19 21:23:12.210435\n",
      "resetting env. episode 2258, reward total was -21.0. running mean: -20.227070112976502, timestamp: 2022-08-19 21:23:15.645259\n",
      "resetting env. episode 2259, reward total was -21.0. running mean: -20.234799411846737, timestamp: 2022-08-19 21:23:18.788852\n",
      "resetting env. episode 2260, reward total was -21.0. running mean: -20.24245141772827, timestamp: 2022-08-19 21:23:22.256582\n",
      "resetting env. episode 2261, reward total was -16.0. running mean: -20.200026903550985, timestamp: 2022-08-19 21:23:26.405798\n",
      "resetting env. episode 2262, reward total was -21.0. running mean: -20.208026634515477, timestamp: 2022-08-19 21:23:30.363298\n",
      "resetting env. episode 2263, reward total was -20.0. running mean: -20.20594636817032, timestamp: 2022-08-19 21:23:33.628415\n",
      "resetting env. episode 2264, reward total was -20.0. running mean: -20.203886904488616, timestamp: 2022-08-19 21:23:36.848168\n",
      "resetting env. episode 2265, reward total was -20.0. running mean: -20.201848035443728, timestamp: 2022-08-19 21:23:39.562911\n",
      "resetting env. episode 2266, reward total was -21.0. running mean: -20.209829555089293, timestamp: 2022-08-19 21:23:42.951862\n",
      "resetting env. episode 2267, reward total was -19.0. running mean: -20.1977312595384, timestamp: 2022-08-19 21:23:46.000704\n",
      "resetting env. episode 2268, reward total was -20.0. running mean: -20.195753946943015, timestamp: 2022-08-19 21:23:48.850093\n",
      "resetting env. episode 2269, reward total was -20.0. running mean: -20.193796407473585, timestamp: 2022-08-19 21:23:51.856052\n",
      "resetting env. episode 2270, reward total was -21.0. running mean: -20.201858443398848, timestamp: 2022-08-19 21:23:54.731399\n",
      "resetting env. episode 2271, reward total was -21.0. running mean: -20.20983985896486, timestamp: 2022-08-19 21:23:57.544782\n",
      "resetting env. episode 2272, reward total was -21.0. running mean: -20.217741460375212, timestamp: 2022-08-19 21:24:00.025002\n",
      "resetting env. episode 2273, reward total was -20.0. running mean: -20.21556404577146, timestamp: 2022-08-19 21:24:03.499713\n",
      "resetting env. episode 2274, reward total was -21.0. running mean: -20.223408405313744, timestamp: 2022-08-19 21:24:06.000028\n",
      "resetting env. episode 2275, reward total was -20.0. running mean: -20.221174321260605, timestamp: 2022-08-19 21:24:08.863375\n",
      "resetting env. episode 2276, reward total was -19.0. running mean: -20.208962578048002, timestamp: 2022-08-19 21:24:11.703803\n",
      "resetting env. episode 2277, reward total was -21.0. running mean: -20.216872952267522, timestamp: 2022-08-19 21:24:14.785537\n",
      "resetting env. episode 2278, reward total was -21.0. running mean: -20.224704222744847, timestamp: 2022-08-19 21:24:18.318024\n",
      "resetting env. episode 2279, reward total was -21.0. running mean: -20.2324571805174, timestamp: 2022-08-19 21:24:22.467933\n",
      "resetting env. episode 2280, reward total was -20.0. running mean: -20.230132608712225, timestamp: 2022-08-19 21:24:26.130143\n",
      "resetting env. episode 2281, reward total was -19.0. running mean: -20.217831282625102, timestamp: 2022-08-19 21:24:29.597878\n",
      "resetting env. episode 2282, reward total was -21.0. running mean: -20.22565296979885, timestamp: 2022-08-19 21:24:32.836216\n",
      "resetting env. episode 2283, reward total was -19.0. running mean: -20.213396440100865, timestamp: 2022-08-19 21:24:36.933265\n",
      "resetting env. episode 2284, reward total was -21.0. running mean: -20.221262475699856, timestamp: 2022-08-19 21:24:40.897038\n",
      "resetting env. episode 2285, reward total was -21.0. running mean: -20.229049850942857, timestamp: 2022-08-19 21:24:44.299392\n",
      "resetting env. episode 2286, reward total was -21.0. running mean: -20.23675935243343, timestamp: 2022-08-19 21:24:47.293398\n",
      "resetting env. episode 2287, reward total was -19.0. running mean: -20.224391758909096, timestamp: 2022-08-19 21:24:50.083072\n",
      "resetting env. episode 2288, reward total was -21.0. running mean: -20.232147841320007, timestamp: 2022-08-19 21:24:53.333544\n",
      "resetting env. episode 2289, reward total was -18.0. running mean: -20.209826362906806, timestamp: 2022-08-19 21:24:56.684109\n",
      "resetting env. episode 2290, reward total was -21.0. running mean: -20.21772809927774, timestamp: 2022-08-19 21:24:59.063830\n",
      "resetting env. episode 2291, reward total was -21.0. running mean: -20.22555081828496, timestamp: 2022-08-19 21:25:01.120512\n",
      "resetting env. episode 2292, reward total was -20.0. running mean: -20.22329531010211, timestamp: 2022-08-19 21:25:04.194137\n",
      "resetting env. episode 2293, reward total was -21.0. running mean: -20.23106235700109, timestamp: 2022-08-19 21:25:06.958940\n",
      "resetting env. episode 2294, reward total was -21.0. running mean: -20.23875173343108, timestamp: 2022-08-19 21:25:09.722919\n",
      "resetting env. episode 2295, reward total was -17.0. running mean: -20.20636421609677, timestamp: 2022-08-19 21:25:13.838380\n",
      "resetting env. episode 2296, reward total was -20.0. running mean: -20.2043005739358, timestamp: 2022-08-19 21:25:16.919336\n",
      "resetting env. episode 2297, reward total was -21.0. running mean: -20.212257568196442, timestamp: 2022-08-19 21:25:19.256137\n",
      "resetting env. episode 2298, reward total was -20.0. running mean: -20.210134992514476, timestamp: 2022-08-19 21:25:22.338178\n",
      "resetting env. episode 2299, reward total was -19.0. running mean: -20.198033642589333, timestamp: 2022-08-19 21:25:25.589962\n",
      "resetting env. episode 2300, reward total was -19.0. running mean: -20.18605330616344, timestamp: 2022-08-19 21:25:28.999372\n",
      "resetting env. episode 2301, reward total was -21.0. running mean: -20.194192773101808, timestamp: 2022-08-19 21:25:31.589070\n",
      "resetting env. episode 2302, reward total was -20.0. running mean: -20.19225084537079, timestamp: 2022-08-19 21:25:33.965279\n",
      "resetting env. episode 2303, reward total was -21.0. running mean: -20.20032833691708, timestamp: 2022-08-19 21:25:37.161460\n",
      "resetting env. episode 2304, reward total was -19.0. running mean: -20.188325053547914, timestamp: 2022-08-19 21:25:41.653052\n",
      "resetting env. episode 2305, reward total was -19.0. running mean: -20.176441803012434, timestamp: 2022-08-19 21:25:45.822674\n",
      "resetting env. episode 2306, reward total was -18.0. running mean: -20.15467738498231, timestamp: 2022-08-19 21:25:49.771127\n",
      "resetting env. episode 2307, reward total was -21.0. running mean: -20.163130611132488, timestamp: 2022-08-19 21:25:56.707634\n",
      "resetting env. episode 2308, reward total was -21.0. running mean: -20.171499305021165, timestamp: 2022-08-19 21:26:01.024083\n",
      "resetting env. episode 2309, reward total was -20.0. running mean: -20.16978431197095, timestamp: 2022-08-19 21:26:04.619472\n",
      "resetting env. episode 2310, reward total was -21.0. running mean: -20.17808646885124, timestamp: 2022-08-19 21:26:08.595869\n",
      "resetting env. episode 2311, reward total was -20.0. running mean: -20.176305604162728, timestamp: 2022-08-19 21:26:11.640302\n",
      "resetting env. episode 2312, reward total was -19.0. running mean: -20.1645425481211, timestamp: 2022-08-19 21:26:16.252902\n",
      "resetting env. episode 2313, reward total was -21.0. running mean: -20.172897122639892, timestamp: 2022-08-19 21:26:19.334558\n",
      "resetting env. episode 2314, reward total was -20.0. running mean: -20.171168151413493, timestamp: 2022-08-19 21:26:21.871272\n",
      "resetting env. episode 2315, reward total was -21.0. running mean: -20.17945646989936, timestamp: 2022-08-19 21:26:25.029777\n",
      "resetting env. episode 2316, reward total was -21.0. running mean: -20.18766190520037, timestamp: 2022-08-19 21:26:28.543386\n",
      "resetting env. episode 2317, reward total was -20.0. running mean: -20.185785286148363, timestamp: 2022-08-19 21:26:31.645165\n",
      "resetting env. episode 2318, reward total was -20.0. running mean: -20.18392743328688, timestamp: 2022-08-19 21:26:37.647530\n",
      "resetting env. episode 2319, reward total was -21.0. running mean: -20.19208815895401, timestamp: 2022-08-19 21:26:41.715655\n",
      "resetting env. episode 2320, reward total was -20.0. running mean: -20.19016727736447, timestamp: 2022-08-19 21:26:45.739925\n",
      "resetting env. episode 2321, reward total was -21.0. running mean: -20.198265604590826, timestamp: 2022-08-19 21:26:48.335409\n",
      "resetting env. episode 2322, reward total was -20.0. running mean: -20.196282948544916, timestamp: 2022-08-19 21:26:52.239972\n",
      "resetting env. episode 2323, reward total was -18.0. running mean: -20.174320119059466, timestamp: 2022-08-19 21:26:56.123547\n",
      "resetting env. episode 2324, reward total was -18.0. running mean: -20.15257691786887, timestamp: 2022-08-19 21:26:59.152436\n",
      "resetting env. episode 2325, reward total was -21.0. running mean: -20.161051148690184, timestamp: 2022-08-19 21:27:02.859785\n",
      "resetting env. episode 2326, reward total was -20.0. running mean: -20.159440637203282, timestamp: 2022-08-19 21:27:07.565208\n",
      "resetting env. episode 2327, reward total was -18.0. running mean: -20.137846230831247, timestamp: 2022-08-19 21:27:11.341114\n",
      "resetting env. episode 2328, reward total was -20.0. running mean: -20.136467768522934, timestamp: 2022-08-19 21:27:16.650919\n",
      "resetting env. episode 2329, reward total was -19.0. running mean: -20.125103090837705, timestamp: 2022-08-19 21:27:21.330412\n",
      "resetting env. episode 2330, reward total was -20.0. running mean: -20.123852059929327, timestamp: 2022-08-19 21:27:24.875673\n",
      "resetting env. episode 2331, reward total was -20.0. running mean: -20.122613539330032, timestamp: 2022-08-19 21:27:28.926872\n",
      "resetting env. episode 2332, reward total was -20.0. running mean: -20.12138740393673, timestamp: 2022-08-19 21:27:32.040528\n",
      "resetting env. episode 2333, reward total was -21.0. running mean: -20.130173529897363, timestamp: 2022-08-19 21:27:36.034834\n",
      "resetting env. episode 2334, reward total was -20.0. running mean: -20.12887179459839, timestamp: 2022-08-19 21:27:39.295403\n",
      "resetting env. episode 2335, reward total was -19.0. running mean: -20.117583076652405, timestamp: 2022-08-19 21:27:42.771568\n",
      "resetting env. episode 2336, reward total was -21.0. running mean: -20.126407245885883, timestamp: 2022-08-19 21:27:45.679696\n",
      "resetting env. episode 2337, reward total was -20.0. running mean: -20.125143173427023, timestamp: 2022-08-19 21:27:48.466190\n",
      "resetting env. episode 2338, reward total was -21.0. running mean: -20.133891741692754, timestamp: 2022-08-19 21:27:51.281011\n",
      "resetting env. episode 2339, reward total was -19.0. running mean: -20.12255282427583, timestamp: 2022-08-19 21:27:54.556474\n",
      "resetting env. episode 2340, reward total was -21.0. running mean: -20.13132729603307, timestamp: 2022-08-19 21:27:57.742450\n",
      "resetting env. episode 2341, reward total was -20.0. running mean: -20.13001402307274, timestamp: 2022-08-19 21:28:00.607222\n",
      "resetting env. episode 2342, reward total was -20.0. running mean: -20.12871388284201, timestamp: 2022-08-19 21:28:04.637200\n",
      "resetting env. episode 2343, reward total was -19.0. running mean: -20.117426744013592, timestamp: 2022-08-19 21:28:07.586000\n",
      "resetting env. episode 2344, reward total was -21.0. running mean: -20.126252476573455, timestamp: 2022-08-19 21:28:10.829673\n",
      "resetting env. episode 2345, reward total was -19.0. running mean: -20.114989951807722, timestamp: 2022-08-19 21:28:14.269712\n",
      "resetting env. episode 2346, reward total was -20.0. running mean: -20.113840052289643, timestamp: 2022-08-19 21:28:17.676960\n",
      "resetting env. episode 2347, reward total was -18.0. running mean: -20.092701651766745, timestamp: 2022-08-19 21:28:20.674520\n",
      "resetting env. episode 2348, reward total was -21.0. running mean: -20.10177463524908, timestamp: 2022-08-19 21:28:23.480081\n",
      "resetting env. episode 2349, reward total was -18.0. running mean: -20.080756888896587, timestamp: 2022-08-19 21:28:26.926581\n",
      "resetting env. episode 2350, reward total was -21.0. running mean: -20.089949320007623, timestamp: 2022-08-19 21:28:31.489832\n",
      "resetting env. episode 2351, reward total was -20.0. running mean: -20.089049826807546, timestamp: 2022-08-19 21:28:35.380191\n",
      "resetting env. episode 2352, reward total was -20.0. running mean: -20.08815932853947, timestamp: 2022-08-19 21:28:38.261440\n",
      "resetting env. episode 2353, reward total was -19.0. running mean: -20.077277735254075, timestamp: 2022-08-19 21:28:41.821285\n",
      "resetting env. episode 2354, reward total was -18.0. running mean: -20.056504957901534, timestamp: 2022-08-19 21:28:45.228011\n",
      "resetting env. episode 2355, reward total was -20.0. running mean: -20.055939908322518, timestamp: 2022-08-19 21:28:48.374863\n",
      "resetting env. episode 2356, reward total was -21.0. running mean: -20.065380509239294, timestamp: 2022-08-19 21:28:51.291739\n",
      "resetting env. episode 2357, reward total was -20.0. running mean: -20.0647267041469, timestamp: 2022-08-19 21:28:54.576518\n",
      "resetting env. episode 2358, reward total was -21.0. running mean: -20.074079437105432, timestamp: 2022-08-19 21:28:57.296930\n",
      "resetting env. episode 2359, reward total was -19.0. running mean: -20.06333864273438, timestamp: 2022-08-19 21:29:00.731608\n",
      "resetting env. episode 2360, reward total was -21.0. running mean: -20.072705256307035, timestamp: 2022-08-19 21:29:03.224977\n",
      "resetting env. episode 2361, reward total was -21.0. running mean: -20.081978203743965, timestamp: 2022-08-19 21:29:05.666202\n",
      "resetting env. episode 2362, reward total was -20.0. running mean: -20.081158421706526, timestamp: 2022-08-19 21:29:07.942874\n",
      "resetting env. episode 2363, reward total was -20.0. running mean: -20.08034683748946, timestamp: 2022-08-19 21:29:11.754487\n",
      "resetting env. episode 2364, reward total was -19.0. running mean: -20.06954336911457, timestamp: 2022-08-19 21:29:14.735693\n",
      "resetting env. episode 2365, reward total was -19.0. running mean: -20.058847935423426, timestamp: 2022-08-19 21:29:18.443651\n",
      "resetting env. episode 2366, reward total was -21.0. running mean: -20.068259456069192, timestamp: 2022-08-19 21:29:20.830178\n",
      "resetting env. episode 2367, reward total was -21.0. running mean: -20.0775768615085, timestamp: 2022-08-19 21:29:23.407637\n",
      "resetting env. episode 2368, reward total was -20.0. running mean: -20.076801092893415, timestamp: 2022-08-19 21:29:26.157297\n",
      "resetting env. episode 2369, reward total was -20.0. running mean: -20.07603308196448, timestamp: 2022-08-19 21:29:28.823583\n",
      "resetting env. episode 2370, reward total was -19.0. running mean: -20.065272751144835, timestamp: 2022-08-19 21:29:31.849987\n",
      "resetting env. episode 2371, reward total was -17.0. running mean: -20.034620023633387, timestamp: 2022-08-19 21:29:34.978521\n",
      "resetting env. episode 2372, reward total was -21.0. running mean: -20.044273823397052, timestamp: 2022-08-19 21:29:38.055357\n",
      "resetting env. episode 2373, reward total was -20.0. running mean: -20.04383108516308, timestamp: 2022-08-19 21:29:40.704463\n",
      "resetting env. episode 2374, reward total was -20.0. running mean: -20.04339277431145, timestamp: 2022-08-19 21:29:43.377730\n",
      "resetting env. episode 2375, reward total was -21.0. running mean: -20.052958846568334, timestamp: 2022-08-19 21:29:46.381408\n",
      "resetting env. episode 2376, reward total was -20.0. running mean: -20.05242925810265, timestamp: 2022-08-19 21:29:48.803512\n",
      "resetting env. episode 2377, reward total was -21.0. running mean: -20.061904965521624, timestamp: 2022-08-19 21:29:51.715003\n",
      "resetting env. episode 2378, reward total was -21.0. running mean: -20.071285915866408, timestamp: 2022-08-19 21:29:56.053380\n",
      "resetting env. episode 2379, reward total was -18.0. running mean: -20.050573056707744, timestamp: 2022-08-19 21:29:59.652605\n",
      "resetting env. episode 2380, reward total was -19.0. running mean: -20.04006732614067, timestamp: 2022-08-19 21:30:03.108045\n",
      "resetting env. episode 2381, reward total was -18.0. running mean: -20.019666652879263, timestamp: 2022-08-19 21:30:06.239755\n",
      "resetting env. episode 2382, reward total was -21.0. running mean: -20.02946998635047, timestamp: 2022-08-19 21:30:08.564847\n",
      "resetting env. episode 2383, reward total was -20.0. running mean: -20.029175286486964, timestamp: 2022-08-19 21:30:11.399230\n",
      "resetting env. episode 2384, reward total was -21.0. running mean: -20.038883533622094, timestamp: 2022-08-19 21:30:14.349270\n",
      "resetting env. episode 2385, reward total was -19.0. running mean: -20.028494698285876, timestamp: 2022-08-19 21:30:16.729073\n",
      "resetting env. episode 2386, reward total was -20.0. running mean: -20.028209751303017, timestamp: 2022-08-19 21:30:19.665224\n",
      "resetting env. episode 2387, reward total was -20.0. running mean: -20.027927653789984, timestamp: 2022-08-19 21:30:22.488411\n",
      "resetting env. episode 2388, reward total was -20.0. running mean: -20.027648377252085, timestamp: 2022-08-19 21:30:25.038829\n",
      "resetting env. episode 2389, reward total was -20.0. running mean: -20.027371893479565, timestamp: 2022-08-19 21:30:27.577272\n",
      "resetting env. episode 2390, reward total was -20.0. running mean: -20.02709817454477, timestamp: 2022-08-19 21:30:31.641618\n",
      "resetting env. episode 2391, reward total was -20.0. running mean: -20.02682719279932, timestamp: 2022-08-19 21:30:34.524013\n",
      "resetting env. episode 2392, reward total was -20.0. running mean: -20.026558920871327, timestamp: 2022-08-19 21:30:37.063163\n",
      "resetting env. episode 2393, reward total was -20.0. running mean: -20.026293331662615, timestamp: 2022-08-19 21:30:39.941525\n",
      "resetting env. episode 2394, reward total was -20.0. running mean: -20.026030398345988, timestamp: 2022-08-19 21:30:43.615810\n",
      "resetting env. episode 2395, reward total was -20.0. running mean: -20.025770094362528, timestamp: 2022-08-19 21:30:45.772047\n",
      "resetting env. episode 2396, reward total was -20.0. running mean: -20.025512393418904, timestamp: 2022-08-19 21:30:49.502999\n",
      "resetting env. episode 2397, reward total was -21.0. running mean: -20.035257269484717, timestamp: 2022-08-19 21:30:52.359435\n",
      "resetting env. episode 2398, reward total was -21.0. running mean: -20.04490469678987, timestamp: 2022-08-19 21:30:56.009692\n",
      "resetting env. episode 2399, reward total was -21.0. running mean: -20.05445564982197, timestamp: 2022-08-19 21:30:59.149544\n",
      "resetting env. episode 2400, reward total was -21.0. running mean: -20.063911093323753, timestamp: 2022-08-19 21:31:02.903185\n",
      "resetting env. episode 2401, reward total was -19.0. running mean: -20.053271982390516, timestamp: 2022-08-19 21:31:07.247295\n",
      "resetting env. episode 2402, reward total was -21.0. running mean: -20.062739262566613, timestamp: 2022-08-19 21:31:09.582029\n",
      "resetting env. episode 2403, reward total was -21.0. running mean: -20.072111869940947, timestamp: 2022-08-19 21:31:12.206097\n",
      "resetting env. episode 2404, reward total was -21.0. running mean: -20.08139075124154, timestamp: 2022-08-19 21:31:16.070143\n",
      "resetting env. episode 2405, reward total was -21.0. running mean: -20.090576843729124, timestamp: 2022-08-19 21:31:18.427062\n",
      "resetting env. episode 2406, reward total was -20.0. running mean: -20.089671075291832, timestamp: 2022-08-19 21:31:23.056689\n",
      "resetting env. episode 2407, reward total was -20.0. running mean: -20.088774364538914, timestamp: 2022-08-19 21:31:26.630132\n",
      "resetting env. episode 2408, reward total was -21.0. running mean: -20.097886620893526, timestamp: 2022-08-19 21:31:29.520889\n",
      "resetting env. episode 2409, reward total was -19.0. running mean: -20.086907754684592, timestamp: 2022-08-19 21:31:32.849251\n",
      "resetting env. episode 2410, reward total was -21.0. running mean: -20.09603867713775, timestamp: 2022-08-19 21:31:36.167580\n",
      "resetting env. episode 2411, reward total was -20.0. running mean: -20.09507829036637, timestamp: 2022-08-19 21:31:39.677999\n",
      "resetting env. episode 2412, reward total was -21.0. running mean: -20.104127507462707, timestamp: 2022-08-19 21:31:42.797847\n",
      "resetting env. episode 2413, reward total was -19.0. running mean: -20.09308623238808, timestamp: 2022-08-19 21:31:46.801271\n",
      "resetting env. episode 2414, reward total was -20.0. running mean: -20.0921553700642, timestamp: 2022-08-19 21:31:50.939243\n",
      "resetting env. episode 2415, reward total was -21.0. running mean: -20.10123381636356, timestamp: 2022-08-19 21:31:54.228426\n",
      "resetting env. episode 2416, reward total was -20.0. running mean: -20.100221478199924, timestamp: 2022-08-19 21:31:58.255663\n",
      "resetting env. episode 2417, reward total was -20.0. running mean: -20.099219263417922, timestamp: 2022-08-19 21:32:02.283892\n",
      "resetting env. episode 2418, reward total was -20.0. running mean: -20.098227070783743, timestamp: 2022-08-19 21:32:07.141908\n",
      "resetting env. episode 2419, reward total was -20.0. running mean: -20.097244800075906, timestamp: 2022-08-19 21:32:10.530845\n",
      "resetting env. episode 2420, reward total was -20.0. running mean: -20.096272352075147, timestamp: 2022-08-19 21:32:13.747272\n",
      "resetting env. episode 2421, reward total was -18.0. running mean: -20.075309628554393, timestamp: 2022-08-19 21:32:18.060716\n",
      "resetting env. episode 2422, reward total was -20.0. running mean: -20.074556532268847, timestamp: 2022-08-19 21:32:21.804679\n",
      "resetting env. episode 2423, reward total was -20.0. running mean: -20.07381096694616, timestamp: 2022-08-19 21:32:25.594920\n",
      "resetting env. episode 2424, reward total was -21.0. running mean: -20.083072857276697, timestamp: 2022-08-19 21:32:28.747519\n",
      "resetting env. episode 2425, reward total was -21.0. running mean: -20.09224212870393, timestamp: 2022-08-19 21:32:31.146603\n",
      "resetting env. episode 2426, reward total was -20.0. running mean: -20.09131970741689, timestamp: 2022-08-19 21:32:34.982199\n",
      "resetting env. episode 2427, reward total was -21.0. running mean: -20.100406510342722, timestamp: 2022-08-19 21:32:37.560215\n",
      "resetting env. episode 2428, reward total was -18.0. running mean: -20.079402445239296, timestamp: 2022-08-19 21:32:41.828596\n",
      "resetting env. episode 2429, reward total was -19.0. running mean: -20.068608420786905, timestamp: 2022-08-19 21:32:45.154416\n",
      "resetting env. episode 2430, reward total was -21.0. running mean: -20.077922336579036, timestamp: 2022-08-19 21:32:48.510301\n",
      "resetting env. episode 2431, reward total was -21.0. running mean: -20.087143113213248, timestamp: 2022-08-19 21:32:52.684579\n",
      "resetting env. episode 2432, reward total was -20.0. running mean: -20.086271682081115, timestamp: 2022-08-19 21:32:56.854779\n",
      "resetting env. episode 2433, reward total was -20.0. running mean: -20.085408965260303, timestamp: 2022-08-19 21:33:00.384480\n",
      "resetting env. episode 2434, reward total was -21.0. running mean: -20.0945548756077, timestamp: 2022-08-19 21:33:03.191976\n",
      "resetting env. episode 2435, reward total was -20.0. running mean: -20.09360932685162, timestamp: 2022-08-19 21:33:07.057220\n",
      "resetting env. episode 2436, reward total was -21.0. running mean: -20.102673233583104, timestamp: 2022-08-19 21:33:11.002763\n",
      "resetting env. episode 2437, reward total was -20.0. running mean: -20.101646501247274, timestamp: 2022-08-19 21:33:13.915655\n",
      "resetting env. episode 2438, reward total was -19.0. running mean: -20.090630036234803, timestamp: 2022-08-19 21:33:17.380062\n",
      "resetting env. episode 2439, reward total was -21.0. running mean: -20.099723735872455, timestamp: 2022-08-19 21:33:20.371076\n",
      "resetting env. episode 2440, reward total was -21.0. running mean: -20.108726498513732, timestamp: 2022-08-19 21:33:23.248533\n",
      "resetting env. episode 2441, reward total was -19.0. running mean: -20.097639233528596, timestamp: 2022-08-19 21:33:26.615571\n",
      "resetting env. episode 2442, reward total was -20.0. running mean: -20.09666284119331, timestamp: 2022-08-19 21:33:29.557804\n",
      "resetting env. episode 2443, reward total was -21.0. running mean: -20.10569621278138, timestamp: 2022-08-19 21:33:32.706137\n",
      "resetting env. episode 2444, reward total was -21.0. running mean: -20.114639250653564, timestamp: 2022-08-19 21:33:35.209928\n",
      "resetting env. episode 2445, reward total was -20.0. running mean: -20.113492858147026, timestamp: 2022-08-19 21:33:38.806742\n",
      "resetting env. episode 2446, reward total was -19.0. running mean: -20.102357929565557, timestamp: 2022-08-19 21:33:41.843695\n",
      "resetting env. episode 2447, reward total was -18.0. running mean: -20.081334350269902, timestamp: 2022-08-19 21:33:47.240042\n",
      "resetting env. episode 2448, reward total was -18.0. running mean: -20.060521006767203, timestamp: 2022-08-19 21:33:51.835758\n",
      "resetting env. episode 2449, reward total was -20.0. running mean: -20.05991579669953, timestamp: 2022-08-19 21:33:55.237114\n",
      "resetting env. episode 2450, reward total was -21.0. running mean: -20.069316638732538, timestamp: 2022-08-19 21:33:58.299929\n",
      "resetting env. episode 2451, reward total was -21.0. running mean: -20.078623472345214, timestamp: 2022-08-19 21:34:01.179218\n",
      "resetting env. episode 2452, reward total was -20.0. running mean: -20.07783723762176, timestamp: 2022-08-19 21:34:05.128398\n",
      "resetting env. episode 2453, reward total was -21.0. running mean: -20.087058865245545, timestamp: 2022-08-19 21:34:08.408166\n",
      "resetting env. episode 2454, reward total was -21.0. running mean: -20.09618827659309, timestamp: 2022-08-19 21:34:11.892418\n",
      "resetting env. episode 2455, reward total was -21.0. running mean: -20.10522639382716, timestamp: 2022-08-19 21:34:14.216207\n",
      "resetting env. episode 2456, reward total was -21.0. running mean: -20.114174129888887, timestamp: 2022-08-19 21:34:16.995777\n",
      "resetting env. episode 2457, reward total was -20.0. running mean: -20.113032388589996, timestamp: 2022-08-19 21:34:20.756692\n",
      "resetting env. episode 2458, reward total was -20.0. running mean: -20.111902064704097, timestamp: 2022-08-19 21:34:23.746878\n",
      "resetting env. episode 2459, reward total was -21.0. running mean: -20.120783044057056, timestamp: 2022-08-19 21:34:26.904477\n",
      "resetting env. episode 2460, reward total was -21.0. running mean: -20.129575213616487, timestamp: 2022-08-19 21:34:30.154790\n",
      "resetting env. episode 2461, reward total was -21.0. running mean: -20.138279461480323, timestamp: 2022-08-19 21:34:33.419299\n",
      "resetting env. episode 2462, reward total was -21.0. running mean: -20.14689666686552, timestamp: 2022-08-19 21:34:36.687497\n",
      "resetting env. episode 2463, reward total was -21.0. running mean: -20.155427700196864, timestamp: 2022-08-19 21:34:39.907041\n",
      "resetting env. episode 2464, reward total was -21.0. running mean: -20.163873423194897, timestamp: 2022-08-19 21:34:42.593956\n",
      "resetting env. episode 2465, reward total was -18.0. running mean: -20.142234688962947, timestamp: 2022-08-19 21:34:46.135480\n",
      "resetting env. episode 2466, reward total was -19.0. running mean: -20.13081234207332, timestamp: 2022-08-19 21:34:50.294851\n",
      "resetting env. episode 2467, reward total was -20.0. running mean: -20.129504218652585, timestamp: 2022-08-19 21:34:53.825407\n",
      "resetting env. episode 2468, reward total was -21.0. running mean: -20.13820917646606, timestamp: 2022-08-19 21:34:57.024831\n",
      "resetting env. episode 2469, reward total was -21.0. running mean: -20.1468270847014, timestamp: 2022-08-19 21:35:00.000868\n",
      "resetting env. episode 2470, reward total was -21.0. running mean: -20.155358813854388, timestamp: 2022-08-19 21:35:02.992851\n",
      "resetting env. episode 2471, reward total was -19.0. running mean: -20.143805225715845, timestamp: 2022-08-19 21:35:07.459328\n",
      "resetting env. episode 2472, reward total was -21.0. running mean: -20.152367173458686, timestamp: 2022-08-19 21:35:10.919640\n",
      "resetting env. episode 2473, reward total was -20.0. running mean: -20.150843501724097, timestamp: 2022-08-19 21:35:13.960671\n",
      "resetting env. episode 2474, reward total was -19.0. running mean: -20.139335066706856, timestamp: 2022-08-19 21:35:17.018460\n",
      "resetting env. episode 2475, reward total was -20.0. running mean: -20.137941716039787, timestamp: 2022-08-19 21:35:20.395040\n",
      "resetting env. episode 2476, reward total was -21.0. running mean: -20.146562298879388, timestamp: 2022-08-19 21:35:23.361113\n",
      "resetting env. episode 2477, reward total was -21.0. running mean: -20.155096675890594, timestamp: 2022-08-19 21:35:26.605485\n",
      "resetting env. episode 2478, reward total was -18.0. running mean: -20.13354570913169, timestamp: 2022-08-19 21:35:29.714011\n",
      "resetting env. episode 2479, reward total was -20.0. running mean: -20.13221025204037, timestamp: 2022-08-19 21:35:33.221141\n",
      "resetting env. episode 2480, reward total was -21.0. running mean: -20.140888149519967, timestamp: 2022-08-19 21:35:36.523224\n",
      "resetting env. episode 2481, reward total was -19.0. running mean: -20.129479268024767, timestamp: 2022-08-19 21:35:40.226236\n",
      "resetting env. episode 2482, reward total was -21.0. running mean: -20.13818447534452, timestamp: 2022-08-19 21:35:43.611159\n",
      "resetting env. episode 2483, reward total was -21.0. running mean: -20.146802630591075, timestamp: 2022-08-19 21:35:46.573452\n",
      "resetting env. episode 2484, reward total was -20.0. running mean: -20.145334604285164, timestamp: 2022-08-19 21:35:49.172629\n",
      "resetting env. episode 2485, reward total was -21.0. running mean: -20.153881258242315, timestamp: 2022-08-19 21:35:53.061583\n",
      "resetting env. episode 2486, reward total was -20.0. running mean: -20.15234244565989, timestamp: 2022-08-19 21:35:56.649974\n",
      "resetting env. episode 2487, reward total was -20.0. running mean: -20.15081902120329, timestamp: 2022-08-19 21:35:59.960192\n",
      "resetting env. episode 2488, reward total was -20.0. running mean: -20.149310830991258, timestamp: 2022-08-19 21:36:03.714182\n",
      "resetting env. episode 2489, reward total was -21.0. running mean: -20.157817722681347, timestamp: 2022-08-19 21:36:06.210215\n",
      "resetting env. episode 2490, reward total was -20.0. running mean: -20.156239545454532, timestamp: 2022-08-19 21:36:09.710119\n",
      "resetting env. episode 2491, reward total was -21.0. running mean: -20.16467714999999, timestamp: 2022-08-19 21:36:12.356066\n",
      "resetting env. episode 2492, reward total was -20.0. running mean: -20.16303037849999, timestamp: 2022-08-19 21:36:15.251103\n",
      "resetting env. episode 2493, reward total was -20.0. running mean: -20.16140007471499, timestamp: 2022-08-19 21:36:18.175537\n",
      "resetting env. episode 2494, reward total was -19.0. running mean: -20.149786073967842, timestamp: 2022-08-19 21:36:22.068530\n",
      "resetting env. episode 2495, reward total was -21.0. running mean: -20.158288213228165, timestamp: 2022-08-19 21:36:26.237689\n",
      "resetting env. episode 2496, reward total was -20.0. running mean: -20.156705331095882, timestamp: 2022-08-19 21:36:29.305457\n",
      "resetting env. episode 2497, reward total was -20.0. running mean: -20.15513827778492, timestamp: 2022-08-19 21:36:32.916129\n",
      "resetting env. episode 2498, reward total was -21.0. running mean: -20.16358689500707, timestamp: 2022-08-19 21:36:35.834478\n",
      "resetting env. episode 2499, reward total was -20.0. running mean: -20.161951026057, timestamp: 2022-08-19 21:36:38.904246\n",
      "resetting env. episode 2500, reward total was -21.0. running mean: -20.17033151579643, timestamp: 2022-08-19 21:36:42.647898\n",
      "resetting env. episode 2501, reward total was -21.0. running mean: -20.178628200638467, timestamp: 2022-08-19 21:36:45.823047\n",
      "resetting env. episode 2502, reward total was -20.0. running mean: -20.176841918632082, timestamp: 2022-08-19 21:36:48.755194\n",
      "resetting env. episode 2503, reward total was -20.0. running mean: -20.17507349944576, timestamp: 2022-08-19 21:36:52.178361\n",
      "resetting env. episode 2504, reward total was -21.0. running mean: -20.1833227644513, timestamp: 2022-08-19 21:36:55.340252\n",
      "resetting env. episode 2505, reward total was -21.0. running mean: -20.191489536806788, timestamp: 2022-08-19 21:36:57.980203\n",
      "resetting env. episode 2506, reward total was -21.0. running mean: -20.19957464143872, timestamp: 2022-08-19 21:37:00.834565\n",
      "resetting env. episode 2507, reward total was -21.0. running mean: -20.207578895024334, timestamp: 2022-08-19 21:37:03.356318\n",
      "resetting env. episode 2508, reward total was -21.0. running mean: -20.21550310607409, timestamp: 2022-08-19 21:37:06.197336\n",
      "resetting env. episode 2509, reward total was -21.0. running mean: -20.22334807501335, timestamp: 2022-08-19 21:37:09.366105\n",
      "resetting env. episode 2510, reward total was -18.0. running mean: -20.201114594263217, timestamp: 2022-08-19 21:37:13.446583\n",
      "resetting env. episode 2511, reward total was -21.0. running mean: -20.209103448320587, timestamp: 2022-08-19 21:37:16.240565\n",
      "resetting env. episode 2512, reward total was -18.0. running mean: -20.18701241383738, timestamp: 2022-08-19 21:37:19.488847\n",
      "resetting env. episode 2513, reward total was -21.0. running mean: -20.195142289699007, timestamp: 2022-08-19 21:37:22.723205\n",
      "resetting env. episode 2514, reward total was -20.0. running mean: -20.193190866802016, timestamp: 2022-08-19 21:37:26.391398\n",
      "resetting env. episode 2515, reward total was -21.0. running mean: -20.201258958133998, timestamp: 2022-08-19 21:37:29.559259\n",
      "resetting env. episode 2516, reward total was -18.0. running mean: -20.179246368552658, timestamp: 2022-08-19 21:37:32.873732\n",
      "resetting env. episode 2517, reward total was -18.0. running mean: -20.15745390486713, timestamp: 2022-08-19 21:37:36.854080\n",
      "resetting env. episode 2518, reward total was -21.0. running mean: -20.16587936581846, timestamp: 2022-08-19 21:37:39.832119\n",
      "resetting env. episode 2519, reward total was -17.0. running mean: -20.134220572160274, timestamp: 2022-08-19 21:37:43.684481\n",
      "resetting env. episode 2520, reward total was -19.0. running mean: -20.122878366438673, timestamp: 2022-08-19 21:37:47.365954\n",
      "resetting env. episode 2521, reward total was -21.0. running mean: -20.131649582774287, timestamp: 2022-08-19 21:37:50.765051\n",
      "resetting env. episode 2522, reward total was -21.0. running mean: -20.140333086946544, timestamp: 2022-08-19 21:37:53.595692\n",
      "resetting env. episode 2523, reward total was -20.0. running mean: -20.13892975607708, timestamp: 2022-08-19 21:37:56.327735\n",
      "resetting env. episode 2524, reward total was -16.0. running mean: -20.09754045851631, timestamp: 2022-08-19 21:38:00.794333\n",
      "resetting env. episode 2525, reward total was -20.0. running mean: -20.096565053931144, timestamp: 2022-08-19 21:38:03.459959\n",
      "resetting env. episode 2526, reward total was -20.0. running mean: -20.09559940339183, timestamp: 2022-08-19 21:38:06.808593\n",
      "resetting env. episode 2527, reward total was -20.0. running mean: -20.09464340935791, timestamp: 2022-08-19 21:38:09.712826\n",
      "resetting env. episode 2528, reward total was -21.0. running mean: -20.10369697526433, timestamp: 2022-08-19 21:38:13.003989\n",
      "resetting env. episode 2529, reward total was -21.0. running mean: -20.11266000551169, timestamp: 2022-08-19 21:38:15.517199\n",
      "resetting env. episode 2530, reward total was -19.0. running mean: -20.10153340545657, timestamp: 2022-08-19 21:38:18.827822\n",
      "resetting env. episode 2531, reward total was -21.0. running mean: -20.110518071402005, timestamp: 2022-08-19 21:38:22.437254\n",
      "resetting env. episode 2532, reward total was -20.0. running mean: -20.109412890687985, timestamp: 2022-08-19 21:38:25.150838\n",
      "resetting env. episode 2533, reward total was -20.0. running mean: -20.108318761781103, timestamp: 2022-08-19 21:38:28.554989\n",
      "resetting env. episode 2534, reward total was -20.0. running mean: -20.10723557416329, timestamp: 2022-08-19 21:38:31.838237\n",
      "resetting env. episode 2535, reward total was -21.0. running mean: -20.116163218421658, timestamp: 2022-08-19 21:38:34.170991\n",
      "resetting env. episode 2536, reward total was -21.0. running mean: -20.125001586237442, timestamp: 2022-08-19 21:38:37.251174\n",
      "resetting env. episode 2537, reward total was -18.0. running mean: -20.103751570375067, timestamp: 2022-08-19 21:38:40.397756\n",
      "resetting env. episode 2538, reward total was -19.0. running mean: -20.09271405467132, timestamp: 2022-08-19 21:38:43.365822\n",
      "resetting env. episode 2539, reward total was -20.0. running mean: -20.091786914124604, timestamp: 2022-08-19 21:38:46.762543\n",
      "resetting env. episode 2540, reward total was -20.0. running mean: -20.090869044983357, timestamp: 2022-08-19 21:38:50.179381\n",
      "resetting env. episode 2541, reward total was -21.0. running mean: -20.099960354533525, timestamp: 2022-08-19 21:38:53.950358\n",
      "resetting env. episode 2542, reward total was -20.0. running mean: -20.09896075098819, timestamp: 2022-08-19 21:38:57.568995\n",
      "resetting env. episode 2543, reward total was -21.0. running mean: -20.10797114347831, timestamp: 2022-08-19 21:39:00.721338\n",
      "resetting env. episode 2544, reward total was -20.0. running mean: -20.106891432043525, timestamp: 2022-08-19 21:39:04.884172\n",
      "resetting env. episode 2545, reward total was -18.0. running mean: -20.08582251772309, timestamp: 2022-08-19 21:39:08.810649\n",
      "resetting env. episode 2546, reward total was -20.0. running mean: -20.08496429254586, timestamp: 2022-08-19 21:39:12.461881\n",
      "resetting env. episode 2547, reward total was -19.0. running mean: -20.0741146496204, timestamp: 2022-08-19 21:39:16.170407\n",
      "resetting env. episode 2548, reward total was -19.0. running mean: -20.0633735031242, timestamp: 2022-08-19 21:39:20.299372\n",
      "resetting env. episode 2549, reward total was -19.0. running mean: -20.05273976809296, timestamp: 2022-08-19 21:39:24.970536\n",
      "resetting env. episode 2550, reward total was -21.0. running mean: -20.06221237041203, timestamp: 2022-08-19 21:39:29.587247\n",
      "resetting env. episode 2551, reward total was -17.0. running mean: -20.03159024670791, timestamp: 2022-08-19 21:39:34.520449\n",
      "resetting env. episode 2552, reward total was -20.0. running mean: -20.03127434424083, timestamp: 2022-08-19 21:39:38.902731\n",
      "resetting env. episode 2553, reward total was -20.0. running mean: -20.03096160079842, timestamp: 2022-08-19 21:39:43.543333\n",
      "resetting env. episode 2554, reward total was -20.0. running mean: -20.030651984790435, timestamp: 2022-08-19 21:39:48.150009\n",
      "resetting env. episode 2555, reward total was -20.0. running mean: -20.03034546494253, timestamp: 2022-08-19 21:39:52.271988\n",
      "resetting env. episode 2556, reward total was -21.0. running mean: -20.040042010293107, timestamp: 2022-08-19 21:39:58.177204\n",
      "resetting env. episode 2557, reward total was -19.0. running mean: -20.029641590190177, timestamp: 2022-08-19 21:40:02.587941\n",
      "resetting env. episode 2558, reward total was -20.0. running mean: -20.029345174288274, timestamp: 2022-08-19 21:40:06.461586\n",
      "resetting env. episode 2559, reward total was -20.0. running mean: -20.02905172254539, timestamp: 2022-08-19 21:40:11.105583\n",
      "resetting env. episode 2560, reward total was -21.0. running mean: -20.038761205319936, timestamp: 2022-08-19 21:40:16.117198\n",
      "resetting env. episode 2561, reward total was -20.0. running mean: -20.038373593266737, timestamp: 2022-08-19 21:40:20.737833\n",
      "resetting env. episode 2562, reward total was -20.0. running mean: -20.03798985733407, timestamp: 2022-08-19 21:40:25.424304\n",
      "resetting env. episode 2563, reward total was -21.0. running mean: -20.047609958760727, timestamp: 2022-08-19 21:40:28.948883\n",
      "resetting env. episode 2564, reward total was -20.0. running mean: -20.04713385917312, timestamp: 2022-08-19 21:40:33.383089\n",
      "resetting env. episode 2565, reward total was -21.0. running mean: -20.056662520581387, timestamp: 2022-08-19 21:40:36.868776\n",
      "resetting env. episode 2566, reward total was -19.0. running mean: -20.046095895375576, timestamp: 2022-08-19 21:40:41.981234\n",
      "resetting env. episode 2567, reward total was -19.0. running mean: -20.035634936421822, timestamp: 2022-08-19 21:40:46.210814\n",
      "resetting env. episode 2568, reward total was -21.0. running mean: -20.045278587057606, timestamp: 2022-08-19 21:40:50.264964\n",
      "resetting env. episode 2569, reward total was -20.0. running mean: -20.044825801187027, timestamp: 2022-08-19 21:40:53.666870\n",
      "resetting env. episode 2570, reward total was -21.0. running mean: -20.054377543175157, timestamp: 2022-08-19 21:40:57.131634\n",
      "resetting env. episode 2571, reward total was -19.0. running mean: -20.043833767743408, timestamp: 2022-08-19 21:41:01.770389\n",
      "resetting env. episode 2572, reward total was -18.0. running mean: -20.023395430065975, timestamp: 2022-08-19 21:41:06.909537\n",
      "resetting env. episode 2573, reward total was -20.0. running mean: -20.023161475765313, timestamp: 2022-08-19 21:41:11.195096\n",
      "resetting env. episode 2574, reward total was -20.0. running mean: -20.022929861007658, timestamp: 2022-08-19 21:41:15.222316\n",
      "resetting env. episode 2575, reward total was -20.0. running mean: -20.02270056239758, timestamp: 2022-08-19 21:41:19.605598\n",
      "resetting env. episode 2576, reward total was -19.0. running mean: -20.012473556773607, timestamp: 2022-08-19 21:41:24.237220\n",
      "resetting env. episode 2577, reward total was -21.0. running mean: -20.02234882120587, timestamp: 2022-08-19 21:41:27.877488\n",
      "resetting env. episode 2578, reward total was -21.0. running mean: -20.03212533299381, timestamp: 2022-08-19 21:41:32.299666\n",
      "resetting env. episode 2579, reward total was -21.0. running mean: -20.041804079663873, timestamp: 2022-08-19 21:41:35.974337\n",
      "resetting env. episode 2580, reward total was -19.0. running mean: -20.031386038867236, timestamp: 2022-08-19 21:41:40.212009\n",
      "resetting env. episode 2581, reward total was -21.0. running mean: -20.041072178478565, timestamp: 2022-08-19 21:41:44.469523\n",
      "resetting env. episode 2582, reward total was -18.0. running mean: -20.02066145669378, timestamp: 2022-08-19 21:41:49.447217\n",
      "resetting env. episode 2583, reward total was -20.0. running mean: -20.020454842126842, timestamp: 2022-08-19 21:41:53.298925\n",
      "resetting env. episode 2584, reward total was -20.0. running mean: -20.020250293705573, timestamp: 2022-08-19 21:41:57.923560\n",
      "resetting env. episode 2585, reward total was -21.0. running mean: -20.030047790768517, timestamp: 2022-08-19 21:42:01.679522\n",
      "resetting env. episode 2586, reward total was -21.0. running mean: -20.039747312860833, timestamp: 2022-08-19 21:42:06.072184\n",
      "resetting env. episode 2587, reward total was -19.0. running mean: -20.029349839732227, timestamp: 2022-08-19 21:42:09.818718\n",
      "resetting env. episode 2588, reward total was -20.0. running mean: -20.029056341334904, timestamp: 2022-08-19 21:42:13.872887\n",
      "resetting env. episode 2589, reward total was -18.0. running mean: -20.008765777921553, timestamp: 2022-08-19 21:42:18.842598\n",
      "resetting env. episode 2590, reward total was -20.0. running mean: -20.00867812014234, timestamp: 2022-08-19 21:42:23.193964\n",
      "resetting env. episode 2591, reward total was -21.0. running mean: -20.018591338940915, timestamp: 2022-08-19 21:42:27.545212\n",
      "resetting env. episode 2592, reward total was -20.0. running mean: -20.018405425551506, timestamp: 2022-08-19 21:42:31.703076\n",
      "resetting env. episode 2593, reward total was -20.0. running mean: -20.01822137129599, timestamp: 2022-08-19 21:42:35.983983\n",
      "resetting env. episode 2594, reward total was -20.0. running mean: -20.01803915758303, timestamp: 2022-08-19 21:42:41.573737\n",
      "resetting env. episode 2595, reward total was -21.0. running mean: -20.0278587660072, timestamp: 2022-08-19 21:42:45.654449\n",
      "resetting env. episode 2596, reward total was -21.0. running mean: -20.037580178347127, timestamp: 2022-08-19 21:42:49.754499\n",
      "resetting env. episode 2597, reward total was -19.0. running mean: -20.027204376563656, timestamp: 2022-08-19 21:42:53.679994\n",
      "resetting env. episode 2598, reward total was -21.0. running mean: -20.03693233279802, timestamp: 2022-08-19 21:42:57.146096\n",
      "resetting env. episode 2599, reward total was -21.0. running mean: -20.04656300947004, timestamp: 2022-08-19 21:43:00.973142\n",
      "resetting env. episode 2600, reward total was -21.0. running mean: -20.05609737937534, timestamp: 2022-08-19 21:43:04.742104\n",
      "resetting env. episode 2601, reward total was -20.0. running mean: -20.055536405581588, timestamp: 2022-08-19 21:43:10.774494\n",
      "resetting env. episode 2602, reward total was -20.0. running mean: -20.05498104152577, timestamp: 2022-08-19 21:43:15.329795\n",
      "resetting env. episode 2603, reward total was -21.0. running mean: -20.064431231110515, timestamp: 2022-08-19 21:43:19.382870\n",
      "resetting env. episode 2604, reward total was -21.0. running mean: -20.07378691879941, timestamp: 2022-08-19 21:43:23.757178\n",
      "resetting env. episode 2605, reward total was -19.0. running mean: -20.06304904961142, timestamp: 2022-08-19 21:43:27.596529\n",
      "resetting env. episode 2606, reward total was -19.0. running mean: -20.052418559115306, timestamp: 2022-08-19 21:43:32.303979\n",
      "resetting env. episode 2607, reward total was -20.0. running mean: -20.051894373524153, timestamp: 2022-08-19 21:43:36.522915\n",
      "resetting env. episode 2608, reward total was -20.0. running mean: -20.05137542978891, timestamp: 2022-08-19 21:43:40.334731\n",
      "resetting env. episode 2609, reward total was -21.0. running mean: -20.06086167549102, timestamp: 2022-08-19 21:43:43.796252\n",
      "resetting env. episode 2610, reward total was -18.0. running mean: -20.04025305873611, timestamp: 2022-08-19 21:43:48.134638\n",
      "resetting env. episode 2611, reward total was -21.0. running mean: -20.04985052814875, timestamp: 2022-08-19 21:43:52.315464\n",
      "resetting env. episode 2612, reward total was -19.0. running mean: -20.039352022867263, timestamp: 2022-08-19 21:43:56.571785\n",
      "resetting env. episode 2613, reward total was -21.0. running mean: -20.04895850263859, timestamp: 2022-08-19 21:44:00.095339\n",
      "resetting env. episode 2614, reward total was -21.0. running mean: -20.058468917612206, timestamp: 2022-08-19 21:44:05.235600\n",
      "resetting env. episode 2615, reward total was -20.0. running mean: -20.057884228436084, timestamp: 2022-08-19 21:44:08.905814\n",
      "resetting env. episode 2616, reward total was -21.0. running mean: -20.067305386151723, timestamp: 2022-08-19 21:44:13.632859\n",
      "resetting env. episode 2617, reward total was -20.0. running mean: -20.066632332290204, timestamp: 2022-08-19 21:44:18.571641\n",
      "resetting env. episode 2618, reward total was -19.0. running mean: -20.055966008967303, timestamp: 2022-08-19 21:44:23.274070\n",
      "resetting env. episode 2619, reward total was -19.0. running mean: -20.04540634887763, timestamp: 2022-08-19 21:44:27.616464\n",
      "resetting env. episode 2620, reward total was -20.0. running mean: -20.044952285388852, timestamp: 2022-08-19 21:44:31.947903\n",
      "resetting env. episode 2621, reward total was -20.0. running mean: -20.044502762534965, timestamp: 2022-08-19 21:44:36.276745\n",
      "resetting env. episode 2622, reward total was -20.0. running mean: -20.044057734909615, timestamp: 2022-08-19 21:44:40.370803\n",
      "resetting env. episode 2623, reward total was -20.0. running mean: -20.04361715756052, timestamp: 2022-08-19 21:44:45.383543\n",
      "resetting env. episode 2624, reward total was -20.0. running mean: -20.04318098598491, timestamp: 2022-08-19 21:44:48.867230\n",
      "resetting env. episode 2625, reward total was -21.0. running mean: -20.05274917612506, timestamp: 2022-08-19 21:44:53.128845\n",
      "resetting env. episode 2626, reward total was -20.0. running mean: -20.05222168436381, timestamp: 2022-08-19 21:44:58.366839\n",
      "resetting env. episode 2627, reward total was -19.0. running mean: -20.041699467520175, timestamp: 2022-08-19 21:45:02.242480\n",
      "resetting env. episode 2628, reward total was -18.0. running mean: -20.021282472844973, timestamp: 2022-08-19 21:45:06.985815\n",
      "resetting env. episode 2629, reward total was -20.0. running mean: -20.021069648116523, timestamp: 2022-08-19 21:45:10.796061\n",
      "resetting env. episode 2630, reward total was -21.0. running mean: -20.03085895163536, timestamp: 2022-08-19 21:45:14.469236\n",
      "resetting env. episode 2631, reward total was -20.0. running mean: -20.030550362119005, timestamp: 2022-08-19 21:45:18.921337\n",
      "resetting env. episode 2632, reward total was -21.0. running mean: -20.040244858497815, timestamp: 2022-08-19 21:45:23.553366\n",
      "resetting env. episode 2633, reward total was -21.0. running mean: -20.049842409912838, timestamp: 2022-08-19 21:45:26.805847\n",
      "resetting env. episode 2634, reward total was -20.0. running mean: -20.04934398581371, timestamp: 2022-08-19 21:45:30.168858\n",
      "resetting env. episode 2635, reward total was -21.0. running mean: -20.058850545955572, timestamp: 2022-08-19 21:45:32.949440\n",
      "resetting env. episode 2636, reward total was -19.0. running mean: -20.048262040496017, timestamp: 2022-08-19 21:45:37.406525\n",
      "resetting env. episode 2637, reward total was -20.0. running mean: -20.047779420091054, timestamp: 2022-08-19 21:45:40.994926\n",
      "resetting env. episode 2638, reward total was -19.0. running mean: -20.037301625890144, timestamp: 2022-08-19 21:45:44.737915\n",
      "resetting env. episode 2639, reward total was -21.0. running mean: -20.046928609631244, timestamp: 2022-08-19 21:45:49.980899\n",
      "resetting env. episode 2640, reward total was -20.0. running mean: -20.046459323534933, timestamp: 2022-08-19 21:45:55.176893\n",
      "resetting env. episode 2641, reward total was -21.0. running mean: -20.055994730299584, timestamp: 2022-08-19 21:45:59.771368\n",
      "resetting env. episode 2642, reward total was -21.0. running mean: -20.06543478299659, timestamp: 2022-08-19 21:46:03.401662\n",
      "resetting env. episode 2643, reward total was -19.0. running mean: -20.054780435166624, timestamp: 2022-08-19 21:46:08.104106\n",
      "resetting env. episode 2644, reward total was -19.0. running mean: -20.044232630814957, timestamp: 2022-08-19 21:46:11.729400\n",
      "resetting env. episode 2645, reward total was -21.0. running mean: -20.05379030450681, timestamp: 2022-08-19 21:46:16.579438\n",
      "resetting env. episode 2646, reward total was -20.0. running mean: -20.05325240146174, timestamp: 2022-08-19 21:46:20.591152\n",
      "resetting env. episode 2647, reward total was -21.0. running mean: -20.062719877447122, timestamp: 2022-08-19 21:46:24.296224\n",
      "resetting env. episode 2648, reward total was -21.0. running mean: -20.072092678672654, timestamp: 2022-08-19 21:46:29.529305\n",
      "resetting env. episode 2649, reward total was -21.0. running mean: -20.08137175188593, timestamp: 2022-08-19 21:46:33.212404\n",
      "resetting env. episode 2650, reward total was -19.0. running mean: -20.07055803436707, timestamp: 2022-08-19 21:46:37.803154\n",
      "resetting env. episode 2651, reward total was -18.0. running mean: -20.0498524540234, timestamp: 2022-08-19 21:46:43.368153\n",
      "resetting env. episode 2652, reward total was -21.0. running mean: -20.05935392948317, timestamp: 2022-08-19 21:46:46.794548\n",
      "resetting env. episode 2653, reward total was -20.0. running mean: -20.058760390188336, timestamp: 2022-08-19 21:46:51.065138\n",
      "resetting env. episode 2654, reward total was -21.0. running mean: -20.068172786286453, timestamp: 2022-08-19 21:46:54.722541\n",
      "resetting env. episode 2655, reward total was -20.0. running mean: -20.067491058423588, timestamp: 2022-08-19 21:46:59.098638\n",
      "resetting env. episode 2656, reward total was -18.0. running mean: -20.04681614783935, timestamp: 2022-08-19 21:47:03.544746\n",
      "resetting env. episode 2657, reward total was -18.0. running mean: -20.026347986360957, timestamp: 2022-08-19 21:47:09.162735\n",
      "resetting env. episode 2658, reward total was -20.0. running mean: -20.026084506497348, timestamp: 2022-08-19 21:47:13.818290\n",
      "resetting env. episode 2659, reward total was -17.0. running mean: -19.995823661432375, timestamp: 2022-08-19 21:47:18.690270\n",
      "resetting env. episode 2660, reward total was -21.0. running mean: -20.00586542481805, timestamp: 2022-08-19 21:47:23.222432\n",
      "resetting env. episode 2661, reward total was -20.0. running mean: -20.00580677056987, timestamp: 2022-08-19 21:47:27.616687\n",
      "resetting env. episode 2662, reward total was -21.0. running mean: -20.015748702864173, timestamp: 2022-08-19 21:47:31.563168\n",
      "resetting env. episode 2663, reward total was -21.0. running mean: -20.025591215835533, timestamp: 2022-08-19 21:47:35.331072\n",
      "resetting env. episode 2664, reward total was -20.0. running mean: -20.025335303677178, timestamp: 2022-08-19 21:47:39.783192\n",
      "resetting env. episode 2665, reward total was -21.0. running mean: -20.035081950640407, timestamp: 2022-08-19 21:47:43.864255\n",
      "resetting env. episode 2666, reward total was -17.0. running mean: -20.004731131134005, timestamp: 2022-08-19 21:47:48.378193\n",
      "resetting env. episode 2667, reward total was -21.0. running mean: -20.014683819822665, timestamp: 2022-08-19 21:47:52.523259\n",
      "resetting env. episode 2668, reward total was -19.0. running mean: -20.00453698162444, timestamp: 2022-08-19 21:47:57.462024\n",
      "resetting env. episode 2669, reward total was -20.0. running mean: -20.004491611808195, timestamp: 2022-08-19 21:48:01.558103\n",
      "resetting env. episode 2670, reward total was -19.0. running mean: -19.994446695690115, timestamp: 2022-08-19 21:48:06.185610\n",
      "resetting env. episode 2671, reward total was -21.0. running mean: -20.004502228733216, timestamp: 2022-08-19 21:48:10.753052\n",
      "resetting env. episode 2672, reward total was -21.0. running mean: -20.014457206445883, timestamp: 2022-08-19 21:48:13.850765\n",
      "resetting env. episode 2673, reward total was -21.0. running mean: -20.024312634381424, timestamp: 2022-08-19 21:48:18.336771\n",
      "resetting env. episode 2674, reward total was -20.0. running mean: -20.02406950803761, timestamp: 2022-08-19 21:48:22.406916\n",
      "resetting env. episode 2675, reward total was -20.0. running mean: -20.023828812957234, timestamp: 2022-08-19 21:48:26.742304\n",
      "resetting env. episode 2676, reward total was -17.0. running mean: -19.993590524827663, timestamp: 2022-08-19 21:48:31.616326\n",
      "resetting env. episode 2677, reward total was -21.0. running mean: -20.003654619579386, timestamp: 2022-08-19 21:48:36.007555\n",
      "resetting env. episode 2678, reward total was -21.0. running mean: -20.013618073383594, timestamp: 2022-08-19 21:48:40.864556\n",
      "resetting env. episode 2679, reward total was -19.0. running mean: -20.00348189264976, timestamp: 2022-08-19 21:48:45.249834\n",
      "resetting env. episode 2680, reward total was -17.0. running mean: -19.973447073723264, timestamp: 2022-08-19 21:48:50.709255\n",
      "resetting env. episode 2681, reward total was -21.0. running mean: -19.98371260298603, timestamp: 2022-08-19 21:48:54.325509\n",
      "resetting env. episode 2682, reward total was -20.0. running mean: -19.98387547695617, timestamp: 2022-08-19 21:48:59.147654\n",
      "resetting env. episode 2683, reward total was -19.0. running mean: -19.97403672218661, timestamp: 2022-08-19 21:49:03.507992\n",
      "resetting env. episode 2684, reward total was -21.0. running mean: -19.984296354964744, timestamp: 2022-08-19 21:49:07.669866\n",
      "resetting env. episode 2685, reward total was -20.0. running mean: -19.984453391415094, timestamp: 2022-08-19 21:49:11.154554\n",
      "resetting env. episode 2686, reward total was -21.0. running mean: -19.994608857500943, timestamp: 2022-08-19 21:49:15.753271\n",
      "resetting env. episode 2687, reward total was -20.0. running mean: -19.99466276892593, timestamp: 2022-08-19 21:49:21.201730\n",
      "resetting env. episode 2688, reward total was -21.0. running mean: -20.00471614123667, timestamp: 2022-08-19 21:49:24.968432\n",
      "resetting env. episode 2689, reward total was -20.0. running mean: -20.004668979824302, timestamp: 2022-08-19 21:49:28.863019\n",
      "resetting env. episode 2690, reward total was -21.0. running mean: -20.01462229002606, timestamp: 2022-08-19 21:49:33.173531\n",
      "resetting env. episode 2691, reward total was -21.0. running mean: -20.0244760671258, timestamp: 2022-08-19 21:49:37.107846\n",
      "resetting env. episode 2692, reward total was -19.0. running mean: -20.014231306454544, timestamp: 2022-08-19 21:49:41.952896\n",
      "resetting env. episode 2693, reward total was -20.0. running mean: -20.014088993389997, timestamp: 2022-08-19 21:49:46.114852\n",
      "resetting env. episode 2694, reward total was -20.0. running mean: -20.013948103456094, timestamp: 2022-08-19 21:49:50.122145\n",
      "resetting env. episode 2695, reward total was -19.0. running mean: -20.003808622421534, timestamp: 2022-08-19 21:49:54.279097\n",
      "resetting env. episode 2696, reward total was -19.0. running mean: -19.99377053619732, timestamp: 2022-08-19 21:49:58.327211\n",
      "resetting env. episode 2697, reward total was -20.0. running mean: -19.99383283083535, timestamp: 2022-08-19 21:50:02.494072\n",
      "resetting env. episode 2698, reward total was -21.0. running mean: -20.003894502526997, timestamp: 2022-08-19 21:50:06.290926\n",
      "resetting env. episode 2699, reward total was -19.0. running mean: -19.99385555750173, timestamp: 2022-08-19 21:50:10.891717\n",
      "resetting env. episode 2700, reward total was -21.0. running mean: -20.003917001926713, timestamp: 2022-08-19 21:50:14.261172\n",
      "resetting env. episode 2701, reward total was -20.0. running mean: -20.003877831907445, timestamp: 2022-08-19 21:50:17.835367\n",
      "resetting env. episode 2702, reward total was -19.0. running mean: -19.99383905358837, timestamp: 2022-08-19 21:50:21.679121\n",
      "resetting env. episode 2703, reward total was -21.0. running mean: -20.003900663052487, timestamp: 2022-08-19 21:50:24.992592\n",
      "resetting env. episode 2704, reward total was -21.0. running mean: -20.013861656421962, timestamp: 2022-08-19 21:50:28.168083\n",
      "resetting env. episode 2705, reward total was -21.0. running mean: -20.023723039857742, timestamp: 2022-08-19 21:50:30.872768\n",
      "resetting env. episode 2706, reward total was -21.0. running mean: -20.033485809459165, timestamp: 2022-08-19 21:50:34.574150\n",
      "resetting env. episode 2707, reward total was -17.0. running mean: -20.003150951364574, timestamp: 2022-08-19 21:50:38.396745\n",
      "resetting env. episode 2708, reward total was -21.0. running mean: -20.01311944185093, timestamp: 2022-08-19 21:50:42.238347\n",
      "resetting env. episode 2709, reward total was -19.0. running mean: -20.00298824743242, timestamp: 2022-08-19 21:50:46.743097\n",
      "resetting env. episode 2710, reward total was -21.0. running mean: -20.012958364958095, timestamp: 2022-08-19 21:50:51.120398\n",
      "resetting env. episode 2711, reward total was -21.0. running mean: -20.022828781308515, timestamp: 2022-08-19 21:50:55.160598\n",
      "resetting env. episode 2712, reward total was -20.0. running mean: -20.02260049349543, timestamp: 2022-08-19 21:50:59.524936\n",
      "resetting env. episode 2713, reward total was -20.0. running mean: -20.022374488560473, timestamp: 2022-08-19 21:51:03.334748\n",
      "resetting env. episode 2714, reward total was -19.0. running mean: -20.01215074367487, timestamp: 2022-08-19 21:51:07.296160\n",
      "resetting env. episode 2715, reward total was -20.0. running mean: -20.01202923623812, timestamp: 2022-08-19 21:51:11.762540\n",
      "resetting env. episode 2716, reward total was -20.0. running mean: -20.01190894387574, timestamp: 2022-08-19 21:51:16.498175\n",
      "resetting env. episode 2717, reward total was -21.0. running mean: -20.02178985443698, timestamp: 2022-08-19 21:51:20.095442\n",
      "resetting env. episode 2718, reward total was -21.0. running mean: -20.031571955892613, timestamp: 2022-08-19 21:51:23.411578\n",
      "resetting env. episode 2719, reward total was -20.0. running mean: -20.031256236333686, timestamp: 2022-08-19 21:51:27.265278\n",
      "resetting env. episode 2720, reward total was -19.0. running mean: -20.02094367397035, timestamp: 2022-08-19 21:51:32.412518\n",
      "resetting env. episode 2721, reward total was -18.0. running mean: -20.000734237230645, timestamp: 2022-08-19 21:51:36.931438\n",
      "resetting env. episode 2722, reward total was -21.0. running mean: -20.01072689485834, timestamp: 2022-08-19 21:51:39.836673\n",
      "resetting env. episode 2723, reward total was -21.0. running mean: -20.020619625909756, timestamp: 2022-08-19 21:51:43.558725\n",
      "resetting env. episode 2724, reward total was -21.0. running mean: -20.030413429650658, timestamp: 2022-08-19 21:51:46.389158\n",
      "resetting env. episode 2725, reward total was -19.0. running mean: -20.020109295354153, timestamp: 2022-08-19 21:51:51.877489\n",
      "resetting env. episode 2726, reward total was -21.0. running mean: -20.029908202400613, timestamp: 2022-08-19 21:51:54.689975\n",
      "resetting env. episode 2727, reward total was -21.0. running mean: -20.039609120376607, timestamp: 2022-08-19 21:51:58.425985\n",
      "resetting env. episode 2728, reward total was -20.0. running mean: -20.03921302917284, timestamp: 2022-08-19 21:52:02.059274\n",
      "resetting env. episode 2729, reward total was -19.0. running mean: -20.02882089888111, timestamp: 2022-08-19 21:52:07.488759\n",
      "resetting env. episode 2730, reward total was -17.0. running mean: -19.9985326898923, timestamp: 2022-08-19 21:52:12.572170\n",
      "resetting env. episode 2731, reward total was -20.0. running mean: -19.998547362993378, timestamp: 2022-08-19 21:52:17.994827\n",
      "resetting env. episode 2732, reward total was -21.0. running mean: -20.008561889363445, timestamp: 2022-08-19 21:52:21.982166\n",
      "resetting env. episode 2733, reward total was -19.0. running mean: -19.998476270469812, timestamp: 2022-08-19 21:52:26.095174\n",
      "resetting env. episode 2734, reward total was -19.0. running mean: -19.988491507765115, timestamp: 2022-08-19 21:52:31.409630\n",
      "resetting env. episode 2735, reward total was -21.0. running mean: -19.998606592687466, timestamp: 2022-08-19 21:52:34.594698\n",
      "resetting env. episode 2736, reward total was -21.0. running mean: -20.00862052676059, timestamp: 2022-08-19 21:52:38.942076\n",
      "resetting env. episode 2737, reward total was -21.0. running mean: -20.018534321492986, timestamp: 2022-08-19 21:52:43.025161\n",
      "resetting env. episode 2738, reward total was -21.0. running mean: -20.028348978278057, timestamp: 2022-08-19 21:52:47.414176\n",
      "resetting env. episode 2739, reward total was -20.0. running mean: -20.028065488495276, timestamp: 2022-08-19 21:52:51.410496\n",
      "resetting env. episode 2740, reward total was -20.0. running mean: -20.027784833610323, timestamp: 2022-08-19 21:52:55.992274\n",
      "resetting env. episode 2741, reward total was -18.0. running mean: -20.00750698527422, timestamp: 2022-08-19 21:53:01.837847\n",
      "resetting env. episode 2742, reward total was -21.0. running mean: -20.017431915421476, timestamp: 2022-08-19 21:53:05.008391\n",
      "resetting env. episode 2743, reward total was -19.0. running mean: -20.007257596267262, timestamp: 2022-08-19 21:53:09.450046\n",
      "resetting env. episode 2744, reward total was -20.0. running mean: -20.00718502030459, timestamp: 2022-08-19 21:53:13.430023\n",
      "resetting env. episode 2745, reward total was -20.0. running mean: -20.007113170101544, timestamp: 2022-08-19 21:53:17.824277\n",
      "resetting env. episode 2746, reward total was -20.0. running mean: -20.007042038400527, timestamp: 2022-08-19 21:53:21.530371\n",
      "resetting env. episode 2747, reward total was -21.0. running mean: -20.016971618016523, timestamp: 2022-08-19 21:53:24.570245\n",
      "resetting env. episode 2748, reward total was -21.0. running mean: -20.026801901836357, timestamp: 2022-08-19 21:53:29.050269\n",
      "resetting env. episode 2749, reward total was -19.0. running mean: -20.016533882817996, timestamp: 2022-08-19 21:53:33.211163\n",
      "resetting env. episode 2750, reward total was -20.0. running mean: -20.016368543989813, timestamp: 2022-08-19 21:53:37.549556\n",
      "resetting env. episode 2751, reward total was -20.0. running mean: -20.016204858549916, timestamp: 2022-08-19 21:53:42.493325\n",
      "resetting env. episode 2752, reward total was -21.0. running mean: -20.026042809964416, timestamp: 2022-08-19 21:53:46.359997\n",
      "resetting env. episode 2753, reward total was -21.0. running mean: -20.035782381864774, timestamp: 2022-08-19 21:53:49.945406\n",
      "resetting env. episode 2754, reward total was -20.0. running mean: -20.035424558046124, timestamp: 2022-08-19 21:53:54.949031\n",
      "resetting env. episode 2755, reward total was -21.0. running mean: -20.045070312465665, timestamp: 2022-08-19 21:53:58.661110\n",
      "resetting env. episode 2756, reward total was -21.0. running mean: -20.05461960934101, timestamp: 2022-08-19 21:54:01.600253\n",
      "resetting env. episode 2757, reward total was -18.0. running mean: -20.0340734132476, timestamp: 2022-08-19 21:54:05.957799\n",
      "resetting env. episode 2758, reward total was -20.0. running mean: -20.033732679115126, timestamp: 2022-08-19 21:54:08.986697\n",
      "resetting env. episode 2759, reward total was -21.0. running mean: -20.043395352323977, timestamp: 2022-08-19 21:54:12.745651\n",
      "resetting env. episode 2760, reward total was -21.0. running mean: -20.052961398800736, timestamp: 2022-08-19 21:54:16.608323\n",
      "resetting env. episode 2761, reward total was -21.0. running mean: -20.06243178481273, timestamp: 2022-08-19 21:54:20.508247\n",
      "resetting env. episode 2762, reward total was -21.0. running mean: -20.071807466964604, timestamp: 2022-08-19 21:54:24.244236\n",
      "resetting env. episode 2763, reward total was -21.0. running mean: -20.08108939229496, timestamp: 2022-08-19 21:54:27.512410\n",
      "resetting env. episode 2764, reward total was -21.0. running mean: -20.09027849837201, timestamp: 2022-08-19 21:54:31.181601\n",
      "resetting env. episode 2765, reward total was -21.0. running mean: -20.09937571338829, timestamp: 2022-08-19 21:54:35.054214\n",
      "resetting env. episode 2766, reward total was -20.0. running mean: -20.098381956254407, timestamp: 2022-08-19 21:54:38.124989\n",
      "resetting env. episode 2767, reward total was -21.0. running mean: -20.107398136691863, timestamp: 2022-08-19 21:54:41.398426\n",
      "resetting env. episode 2768, reward total was -20.0. running mean: -20.106324155324945, timestamp: 2022-08-19 21:54:44.311439\n",
      "resetting env. episode 2769, reward total was -21.0. running mean: -20.115260913771696, timestamp: 2022-08-19 21:54:48.502236\n",
      "resetting env. episode 2770, reward total was -20.0. running mean: -20.114108304633977, timestamp: 2022-08-19 21:54:52.142542\n",
      "resetting env. episode 2771, reward total was -21.0. running mean: -20.122967221587636, timestamp: 2022-08-19 21:54:55.468593\n",
      "resetting env. episode 2772, reward total was -21.0. running mean: -20.13173754937176, timestamp: 2022-08-19 21:54:59.742275\n",
      "resetting env. episode 2773, reward total was -20.0. running mean: -20.13042017387804, timestamp: 2022-08-19 21:55:03.127226\n",
      "resetting env. episode 2774, reward total was -20.0. running mean: -20.12911597213926, timestamp: 2022-08-19 21:55:06.270624\n",
      "resetting env. episode 2775, reward total was -18.0. running mean: -20.107824812417867, timestamp: 2022-08-19 21:55:10.282080\n",
      "resetting env. episode 2776, reward total was -21.0. running mean: -20.11674656429369, timestamp: 2022-08-19 21:55:13.449258\n",
      "resetting env. episode 2777, reward total was -20.0. running mean: -20.115579098650752, timestamp: 2022-08-19 21:55:17.952221\n",
      "resetting env. episode 2778, reward total was -20.0. running mean: -20.114423307664243, timestamp: 2022-08-19 21:55:21.470843\n",
      "resetting env. episode 2779, reward total was -20.0. running mean: -20.1132790745876, timestamp: 2022-08-19 21:55:24.752046\n",
      "resetting env. episode 2780, reward total was -19.0. running mean: -20.102146283841723, timestamp: 2022-08-19 21:55:28.518005\n",
      "resetting env. episode 2781, reward total was -19.0. running mean: -20.091124821003305, timestamp: 2022-08-19 21:55:32.146306\n",
      "resetting env. episode 2782, reward total was -21.0. running mean: -20.100213572793272, timestamp: 2022-08-19 21:55:35.047130\n",
      "resetting env. episode 2783, reward total was -19.0. running mean: -20.08921143706534, timestamp: 2022-08-19 21:55:38.558019\n",
      "resetting env. episode 2784, reward total was -19.0. running mean: -20.07831932269469, timestamp: 2022-08-19 21:55:42.643234\n",
      "resetting env. episode 2785, reward total was -21.0. running mean: -20.087536129467743, timestamp: 2022-08-19 21:55:46.100189\n",
      "resetting env. episode 2786, reward total was -20.0. running mean: -20.086660768173065, timestamp: 2022-08-19 21:55:49.129755\n",
      "resetting env. episode 2787, reward total was -21.0. running mean: -20.095794160491334, timestamp: 2022-08-19 21:55:52.653129\n",
      "resetting env. episode 2788, reward total was -21.0. running mean: -20.104836218886422, timestamp: 2022-08-19 21:55:56.310388\n",
      "resetting env. episode 2789, reward total was -19.0. running mean: -20.09378785669756, timestamp: 2022-08-19 21:55:59.836374\n",
      "resetting env. episode 2790, reward total was -19.0. running mean: -20.082849978130586, timestamp: 2022-08-19 21:56:03.362644\n",
      "resetting env. episode 2791, reward total was -21.0. running mean: -20.09202147834928, timestamp: 2022-08-19 21:56:06.843341\n",
      "resetting env. episode 2792, reward total was -20.0. running mean: -20.091101263565786, timestamp: 2022-08-19 21:56:10.767667\n",
      "resetting env. episode 2793, reward total was -21.0. running mean: -20.10019025093013, timestamp: 2022-08-19 21:56:14.443755\n",
      "resetting env. episode 2794, reward total was -20.0. running mean: -20.099188348420828, timestamp: 2022-08-19 21:56:18.735974\n",
      "resetting env. episode 2795, reward total was -19.0. running mean: -20.088196464936622, timestamp: 2022-08-19 21:56:22.619887\n",
      "resetting env. episode 2796, reward total was -20.0. running mean: -20.087314500287256, timestamp: 2022-08-19 21:56:26.348930\n",
      "resetting env. episode 2797, reward total was -20.0. running mean: -20.086441355284382, timestamp: 2022-08-19 21:56:30.149471\n",
      "resetting env. episode 2798, reward total was -18.0. running mean: -20.06557694173154, timestamp: 2022-08-19 21:56:34.970656\n",
      "resetting env. episode 2799, reward total was -20.0. running mean: -20.06492117231422, timestamp: 2022-08-19 21:56:39.124268\n",
      "resetting env. episode 2800, reward total was -20.0. running mean: -20.06427196059108, timestamp: 2022-08-19 21:56:42.334827\n",
      "resetting env. episode 2801, reward total was -19.0. running mean: -20.05362924098517, timestamp: 2022-08-19 21:56:45.872593\n",
      "resetting env. episode 2802, reward total was -20.0. running mean: -20.05309294857532, timestamp: 2022-08-19 21:56:49.337505\n",
      "resetting env. episode 2803, reward total was -18.0. running mean: -20.032562019089564, timestamp: 2022-08-19 21:56:53.312944\n",
      "resetting env. episode 2804, reward total was -21.0. running mean: -20.04223639889867, timestamp: 2022-08-19 21:56:56.613135\n",
      "resetting env. episode 2805, reward total was -21.0. running mean: -20.051814034909683, timestamp: 2022-08-19 21:57:00.123348\n",
      "resetting env. episode 2806, reward total was -21.0. running mean: -20.061295894560587, timestamp: 2022-08-19 21:57:03.163107\n",
      "resetting env. episode 2807, reward total was -21.0. running mean: -20.070682935614983, timestamp: 2022-08-19 21:57:06.494268\n",
      "resetting env. episode 2808, reward total was -19.0. running mean: -20.059976106258834, timestamp: 2022-08-19 21:57:10.035729\n",
      "resetting env. episode 2809, reward total was -21.0. running mean: -20.069376345196247, timestamp: 2022-08-19 21:57:14.024065\n",
      "resetting env. episode 2810, reward total was -19.0. running mean: -20.058682581744286, timestamp: 2022-08-19 21:57:17.660684\n",
      "resetting env. episode 2811, reward total was -20.0. running mean: -20.058095755926843, timestamp: 2022-08-19 21:57:20.845604\n",
      "resetting env. episode 2812, reward total was -21.0. running mean: -20.067514798367576, timestamp: 2022-08-19 21:57:23.613521\n",
      "resetting env. episode 2813, reward total was -21.0. running mean: -20.0768396503839, timestamp: 2022-08-19 21:57:27.414376\n",
      "resetting env. episode 2814, reward total was -21.0. running mean: -20.08607125388006, timestamp: 2022-08-19 21:57:30.641762\n",
      "resetting env. episode 2815, reward total was -21.0. running mean: -20.09521054134126, timestamp: 2022-08-19 21:57:33.655184\n",
      "resetting env. episode 2816, reward total was -20.0. running mean: -20.094258435927845, timestamp: 2022-08-19 21:57:36.857329\n",
      "resetting env. episode 2817, reward total was -18.0. running mean: -20.073315851568566, timestamp: 2022-08-19 21:57:41.449868\n",
      "resetting env. episode 2818, reward total was -20.0. running mean: -20.07258269305288, timestamp: 2022-08-19 21:57:45.798383\n",
      "resetting env. episode 2819, reward total was -21.0. running mean: -20.08185686612235, timestamp: 2022-08-19 21:57:49.035729\n",
      "resetting env. episode 2820, reward total was -21.0. running mean: -20.09103829746113, timestamp: 2022-08-19 21:57:53.345500\n",
      "resetting env. episode 2821, reward total was -18.0. running mean: -20.070127914486516, timestamp: 2022-08-19 21:57:57.084085\n",
      "resetting env. episode 2822, reward total was -21.0. running mean: -20.07942663534165, timestamp: 2022-08-19 21:57:59.825103\n",
      "resetting env. episode 2823, reward total was -21.0. running mean: -20.088632368988236, timestamp: 2022-08-19 21:58:02.744478\n",
      "resetting env. episode 2824, reward total was -19.0. running mean: -20.077746045298355, timestamp: 2022-08-19 21:58:07.344007\n",
      "resetting env. episode 2825, reward total was -21.0. running mean: -20.086968584845373, timestamp: 2022-08-19 21:58:11.016403\n",
      "resetting env. episode 2826, reward total was -21.0. running mean: -20.09609889899692, timestamp: 2022-08-19 21:58:13.903748\n",
      "resetting env. episode 2827, reward total was -21.0. running mean: -20.105137910006952, timestamp: 2022-08-19 21:58:16.855244\n",
      "resetting env. episode 2828, reward total was -20.0. running mean: -20.104086530906883, timestamp: 2022-08-19 21:58:20.887706\n",
      "resetting env. episode 2829, reward total was -20.0. running mean: -20.103045665597815, timestamp: 2022-08-19 21:58:25.113403\n",
      "resetting env. episode 2830, reward total was -21.0. running mean: -20.112015208941838, timestamp: 2022-08-19 21:58:27.941500\n",
      "resetting env. episode 2831, reward total was -20.0. running mean: -20.110895056852417, timestamp: 2022-08-19 21:58:31.950767\n",
      "resetting env. episode 2832, reward total was -19.0. running mean: -20.099786106283894, timestamp: 2022-08-19 21:58:37.280437\n",
      "resetting env. episode 2833, reward total was -20.0. running mean: -20.098788245221055, timestamp: 2022-08-19 21:58:40.865882\n",
      "resetting env. episode 2834, reward total was -19.0. running mean: -20.087800362768846, timestamp: 2022-08-19 21:58:44.669920\n",
      "resetting env. episode 2835, reward total was -21.0. running mean: -20.096922359141157, timestamp: 2022-08-19 21:58:48.176950\n",
      "resetting env. episode 2836, reward total was -21.0. running mean: -20.105953135549747, timestamp: 2022-08-19 21:58:51.439991\n",
      "resetting env. episode 2837, reward total was -19.0. running mean: -20.09489360419425, timestamp: 2022-08-19 21:58:56.455220\n",
      "resetting env. episode 2838, reward total was -19.0. running mean: -20.08394466815231, timestamp: 2022-08-19 21:59:00.466965\n",
      "resetting env. episode 2839, reward total was -21.0. running mean: -20.093105221470786, timestamp: 2022-08-19 21:59:03.409105\n",
      "resetting env. episode 2840, reward total was -19.0. running mean: -20.082174169256078, timestamp: 2022-08-19 21:59:07.031389\n",
      "resetting env. episode 2841, reward total was -20.0. running mean: -20.081352427563516, timestamp: 2022-08-19 21:59:10.615958\n",
      "resetting env. episode 2842, reward total was -20.0. running mean: -20.08053890328788, timestamp: 2022-08-19 21:59:13.693737\n",
      "resetting env. episode 2843, reward total was -21.0. running mean: -20.089733514255002, timestamp: 2022-08-19 21:59:16.544278\n",
      "resetting env. episode 2844, reward total was -19.0. running mean: -20.078836179112454, timestamp: 2022-08-19 21:59:20.357285\n",
      "resetting env. episode 2845, reward total was -18.0. running mean: -20.058047817321327, timestamp: 2022-08-19 21:59:24.643425\n",
      "resetting env. episode 2846, reward total was -19.0. running mean: -20.047467339148113, timestamp: 2022-08-19 21:59:28.963805\n",
      "resetting env. episode 2847, reward total was -20.0. running mean: -20.04699266575663, timestamp: 2022-08-19 21:59:32.712638\n",
      "resetting env. episode 2848, reward total was -20.0. running mean: -20.046522739099064, timestamp: 2022-08-19 21:59:36.220962\n",
      "resetting env. episode 2849, reward total was -17.0. running mean: -20.016057511708073, timestamp: 2022-08-19 21:59:40.320121\n",
      "resetting env. episode 2850, reward total was -20.0. running mean: -20.01589693659099, timestamp: 2022-08-19 21:59:43.402452\n",
      "resetting env. episode 2851, reward total was -20.0. running mean: -20.015737967225082, timestamp: 2022-08-19 21:59:46.816918\n",
      "resetting env. episode 2852, reward total was -21.0. running mean: -20.02558058755283, timestamp: 2022-08-19 21:59:49.701271\n",
      "resetting env. episode 2853, reward total was -21.0. running mean: -20.035324781677303, timestamp: 2022-08-19 21:59:53.376284\n",
      "resetting env. episode 2854, reward total was -21.0. running mean: -20.04497153386053, timestamp: 2022-08-19 21:59:57.055311\n",
      "resetting env. episode 2855, reward total was -21.0. running mean: -20.054521818521923, timestamp: 2022-08-19 22:00:00.806285\n",
      "resetting env. episode 2856, reward total was -20.0. running mean: -20.053976600336703, timestamp: 2022-08-19 22:00:04.432073\n",
      "resetting env. episode 2857, reward total was -20.0. running mean: -20.053436834333336, timestamp: 2022-08-19 22:00:07.482915\n",
      "resetting env. episode 2858, reward total was -21.0. running mean: -20.062902465990003, timestamp: 2022-08-19 22:00:11.272780\n",
      "resetting env. episode 2859, reward total was -19.0. running mean: -20.052273441330104, timestamp: 2022-08-19 22:00:15.425336\n",
      "resetting env. episode 2860, reward total was -19.0. running mean: -20.041750706916805, timestamp: 2022-08-19 22:00:19.678365\n",
      "resetting env. episode 2861, reward total was -19.0. running mean: -20.031333199847637, timestamp: 2022-08-19 22:00:23.328803\n",
      "resetting env. episode 2862, reward total was -21.0. running mean: -20.041019867849162, timestamp: 2022-08-19 22:00:26.940450\n",
      "resetting env. episode 2863, reward total was -21.0. running mean: -20.050609669170672, timestamp: 2022-08-19 22:00:30.735305\n",
      "resetting env. episode 2864, reward total was -19.0. running mean: -20.040103572478966, timestamp: 2022-08-19 22:00:34.611995\n",
      "resetting env. episode 2865, reward total was -21.0. running mean: -20.049702536754175, timestamp: 2022-08-19 22:00:38.350100\n",
      "resetting env. episode 2866, reward total was -20.0. running mean: -20.04920551138663, timestamp: 2022-08-19 22:00:42.421208\n",
      "resetting env. episode 2867, reward total was -21.0. running mean: -20.058713456272766, timestamp: 2022-08-19 22:00:46.261737\n",
      "resetting env. episode 2868, reward total was -21.0. running mean: -20.06812632171004, timestamp: 2022-08-19 22:00:49.692293\n",
      "resetting env. episode 2869, reward total was -19.0. running mean: -20.05744505849294, timestamp: 2022-08-19 22:00:53.089278\n",
      "resetting env. episode 2870, reward total was -21.0. running mean: -20.06687060790801, timestamp: 2022-08-19 22:00:56.598880\n",
      "resetting env. episode 2871, reward total was -20.0. running mean: -20.06620190182893, timestamp: 2022-08-19 22:00:59.559961\n",
      "resetting env. episode 2872, reward total was -20.0. running mean: -20.06553988281064, timestamp: 2022-08-19 22:01:02.849081\n",
      "resetting env. episode 2873, reward total was -21.0. running mean: -20.074884483982533, timestamp: 2022-08-19 22:01:06.026921\n",
      "resetting env. episode 2874, reward total was -18.0. running mean: -20.054135639142707, timestamp: 2022-08-19 22:01:10.267013\n",
      "resetting env. episode 2875, reward total was -21.0. running mean: -20.063594282751282, timestamp: 2022-08-19 22:01:14.119376\n",
      "resetting env. episode 2876, reward total was -18.0. running mean: -20.042958339923768, timestamp: 2022-08-19 22:01:18.176500\n",
      "resetting env. episode 2877, reward total was -20.0. running mean: -20.04252875652453, timestamp: 2022-08-19 22:01:22.234131\n",
      "resetting env. episode 2878, reward total was -21.0. running mean: -20.052103468959285, timestamp: 2022-08-19 22:01:24.886044\n",
      "resetting env. episode 2879, reward total was -20.0. running mean: -20.05158243426969, timestamp: 2022-08-19 22:01:27.608266\n",
      "resetting env. episode 2880, reward total was -20.0. running mean: -20.05106660992699, timestamp: 2022-08-19 22:01:31.342524\n",
      "resetting env. episode 2881, reward total was -19.0. running mean: -20.040555943827723, timestamp: 2022-08-19 22:01:35.277428\n",
      "resetting env. episode 2882, reward total was -21.0. running mean: -20.050150384389447, timestamp: 2022-08-19 22:01:38.154695\n",
      "resetting env. episode 2883, reward total was -19.0. running mean: -20.039648880545553, timestamp: 2022-08-19 22:01:42.232969\n",
      "resetting env. episode 2884, reward total was -20.0. running mean: -20.039252391740096, timestamp: 2022-08-19 22:01:45.876240\n",
      "resetting env. episode 2885, reward total was -21.0. running mean: -20.048859867822696, timestamp: 2022-08-19 22:01:48.587748\n",
      "resetting env. episode 2886, reward total was -21.0. running mean: -20.05837126914447, timestamp: 2022-08-19 22:01:51.681478\n",
      "resetting env. episode 2887, reward total was -17.0. running mean: -20.027787556453028, timestamp: 2022-08-19 22:01:56.922327\n",
      "resetting env. episode 2888, reward total was -19.0. running mean: -20.017509680888498, timestamp: 2022-08-19 22:02:00.538479\n",
      "resetting env. episode 2889, reward total was -20.0. running mean: -20.017334584079613, timestamp: 2022-08-19 22:02:04.353694\n",
      "resetting env. episode 2890, reward total was -21.0. running mean: -20.02716123823882, timestamp: 2022-08-19 22:02:07.062357\n",
      "resetting env. episode 2891, reward total was -20.0. running mean: -20.02688962585643, timestamp: 2022-08-19 22:02:10.985246\n",
      "resetting env. episode 2892, reward total was -21.0. running mean: -20.036620729597868, timestamp: 2022-08-19 22:02:13.702517\n",
      "resetting env. episode 2893, reward total was -18.0. running mean: -20.01625452230189, timestamp: 2022-08-19 22:02:17.490522\n",
      "resetting env. episode 2894, reward total was -21.0. running mean: -20.02609197707887, timestamp: 2022-08-19 22:02:20.671553\n",
      "resetting env. episode 2895, reward total was -18.0. running mean: -20.005831057308082, timestamp: 2022-08-19 22:02:24.941203\n",
      "resetting env. episode 2896, reward total was -20.0. running mean: -20.005772746735, timestamp: 2022-08-19 22:02:28.315177\n",
      "resetting env. episode 2897, reward total was -20.0. running mean: -20.00571501926765, timestamp: 2022-08-19 22:02:31.670855\n",
      "resetting env. episode 2898, reward total was -18.0. running mean: -19.985657869074974, timestamp: 2022-08-19 22:02:35.606489\n",
      "resetting env. episode 2899, reward total was -20.0. running mean: -19.985801290384224, timestamp: 2022-08-19 22:02:38.963512\n",
      "resetting env. episode 2900, reward total was -21.0. running mean: -19.995943277480382, timestamp: 2022-08-19 22:02:42.543188\n",
      "resetting env. episode 2901, reward total was -20.0. running mean: -19.995983844705577, timestamp: 2022-08-19 22:02:45.888927\n",
      "resetting env. episode 2902, reward total was -21.0. running mean: -20.00602400625852, timestamp: 2022-08-19 22:02:49.682802\n",
      "resetting env. episode 2903, reward total was -19.0. running mean: -19.99596376619594, timestamp: 2022-08-19 22:02:53.307187\n",
      "resetting env. episode 2904, reward total was -21.0. running mean: -20.00600412853398, timestamp: 2022-08-19 22:02:56.060229\n",
      "resetting env. episode 2905, reward total was -19.0. running mean: -19.995944087248642, timestamp: 2022-08-19 22:03:00.808988\n",
      "resetting env. episode 2906, reward total was -19.0. running mean: -19.985984646376156, timestamp: 2022-08-19 22:03:04.842236\n",
      "resetting env. episode 2907, reward total was -19.0. running mean: -19.976124799912395, timestamp: 2022-08-19 22:03:08.891646\n",
      "resetting env. episode 2908, reward total was -21.0. running mean: -19.98636355191327, timestamp: 2022-08-19 22:03:12.742856\n",
      "resetting env. episode 2909, reward total was -21.0. running mean: -19.99649991639414, timestamp: 2022-08-19 22:03:16.087917\n",
      "resetting env. episode 2910, reward total was -19.0. running mean: -19.9865349172302, timestamp: 2022-08-19 22:03:20.594870\n",
      "resetting env. episode 2911, reward total was -20.0. running mean: -19.986669568057895, timestamp: 2022-08-19 22:03:26.517939\n",
      "resetting env. episode 2912, reward total was -18.0. running mean: -19.966802872377315, timestamp: 2022-08-19 22:03:31.205407\n",
      "resetting env. episode 2913, reward total was -19.0. running mean: -19.95713484365354, timestamp: 2022-08-19 22:03:35.372268\n",
      "resetting env. episode 2914, reward total was -21.0. running mean: -19.967563495217007, timestamp: 2022-08-19 22:03:39.341657\n",
      "resetting env. episode 2915, reward total was -18.0. running mean: -19.947887860264835, timestamp: 2022-08-19 22:03:44.415098\n",
      "resetting env. episode 2916, reward total was -18.0. running mean: -19.928408981662187, timestamp: 2022-08-19 22:03:48.943991\n",
      "resetting env. episode 2917, reward total was -19.0. running mean: -19.919124891845566, timestamp: 2022-08-19 22:03:53.346033\n",
      "resetting env. episode 2918, reward total was -20.0. running mean: -19.91993364292711, timestamp: 2022-08-19 22:03:57.093959\n",
      "resetting env. episode 2919, reward total was -20.0. running mean: -19.920734306497838, timestamp: 2022-08-19 22:04:00.047600\n",
      "resetting env. episode 2920, reward total was -21.0. running mean: -19.931526963432862, timestamp: 2022-08-19 22:04:03.277937\n",
      "resetting env. episode 2921, reward total was -21.0. running mean: -19.942211693798534, timestamp: 2022-08-19 22:04:06.324929\n",
      "resetting env. episode 2922, reward total was -17.0. running mean: -19.91278957686055, timestamp: 2022-08-19 22:04:11.580880\n",
      "resetting env. episode 2923, reward total was -21.0. running mean: -19.923661681091946, timestamp: 2022-08-19 22:04:17.483447\n",
      "resetting env. episode 2924, reward total was -20.0. running mean: -19.924425064281028, timestamp: 2022-08-19 22:04:21.631355\n",
      "resetting env. episode 2925, reward total was -18.0. running mean: -19.905180813638218, timestamp: 2022-08-19 22:04:26.116890\n",
      "resetting env. episode 2926, reward total was -20.0. running mean: -19.906129005501835, timestamp: 2022-08-19 22:04:31.438669\n",
      "resetting env. episode 2927, reward total was -17.0. running mean: -19.87706771544682, timestamp: 2022-08-19 22:04:36.184533\n",
      "resetting env. episode 2928, reward total was -21.0. running mean: -19.888297038292354, timestamp: 2022-08-19 22:04:41.637955\n",
      "resetting env. episode 2929, reward total was -20.0. running mean: -19.889414067909428, timestamp: 2022-08-19 22:04:45.672957\n",
      "resetting env. episode 2930, reward total was -21.0. running mean: -19.900519927230334, timestamp: 2022-08-19 22:04:48.559257\n",
      "resetting env. episode 2931, reward total was -20.0. running mean: -19.90151472795803, timestamp: 2022-08-19 22:04:51.757413\n",
      "resetting env. episode 2932, reward total was -20.0. running mean: -19.902499580678448, timestamp: 2022-08-19 22:04:55.017707\n",
      "resetting env. episode 2933, reward total was -18.0. running mean: -19.883474584871664, timestamp: 2022-08-19 22:04:59.189267\n",
      "resetting env. episode 2934, reward total was -20.0. running mean: -19.884639839022945, timestamp: 2022-08-19 22:05:02.515378\n",
      "resetting env. episode 2935, reward total was -21.0. running mean: -19.895793440632715, timestamp: 2022-08-19 22:05:07.440493\n",
      "resetting env. episode 2936, reward total was -21.0. running mean: -19.90683550622639, timestamp: 2022-08-19 22:05:11.350168\n",
      "resetting env. episode 2937, reward total was -19.0. running mean: -19.89776715116413, timestamp: 2022-08-19 22:05:15.005398\n",
      "resetting env. episode 2938, reward total was -20.0. running mean: -19.898789479652486, timestamp: 2022-08-19 22:05:18.362426\n",
      "resetting env. episode 2939, reward total was -20.0. running mean: -19.89980158485596, timestamp: 2022-08-19 22:05:22.227095\n",
      "resetting env. episode 2940, reward total was -19.0. running mean: -19.890803569007403, timestamp: 2022-08-19 22:05:27.149227\n",
      "resetting env. episode 2941, reward total was -20.0. running mean: -19.891895533317328, timestamp: 2022-08-19 22:05:30.440252\n",
      "resetting env. episode 2942, reward total was -21.0. running mean: -19.902976577984155, timestamp: 2022-08-19 22:05:34.292643\n",
      "resetting env. episode 2943, reward total was -19.0. running mean: -19.893946812204316, timestamp: 2022-08-19 22:05:38.245123\n",
      "resetting env. episode 2944, reward total was -20.0. running mean: -19.895007344082273, timestamp: 2022-08-19 22:05:41.844095\n",
      "resetting env. episode 2945, reward total was -19.0. running mean: -19.88605727064145, timestamp: 2022-08-19 22:05:46.852705\n",
      "resetting env. episode 2946, reward total was -21.0. running mean: -19.897196697935037, timestamp: 2022-08-19 22:05:50.925830\n",
      "resetting env. episode 2947, reward total was -20.0. running mean: -19.898224730955686, timestamp: 2022-08-19 22:05:56.024666\n",
      "resetting env. episode 2948, reward total was -19.0. running mean: -19.88924248364613, timestamp: 2022-08-19 22:05:59.984338\n",
      "resetting env. episode 2949, reward total was -19.0. running mean: -19.880350058809668, timestamp: 2022-08-19 22:06:03.395451\n",
      "resetting env. episode 2950, reward total was -20.0. running mean: -19.881546558221572, timestamp: 2022-08-19 22:06:06.057555\n",
      "resetting env. episode 2951, reward total was -20.0. running mean: -19.882731092639357, timestamp: 2022-08-19 22:06:09.311472\n",
      "resetting env. episode 2952, reward total was -20.0. running mean: -19.883903781712963, timestamp: 2022-08-19 22:06:12.428082\n",
      "resetting env. episode 2953, reward total was -21.0. running mean: -19.895064743895833, timestamp: 2022-08-19 22:06:15.944685\n",
      "resetting env. episode 2954, reward total was -20.0. running mean: -19.896114096456873, timestamp: 2022-08-19 22:06:18.966024\n",
      "resetting env. episode 2955, reward total was -21.0. running mean: -19.907152955492304, timestamp: 2022-08-19 22:06:23.290637\n",
      "resetting env. episode 2956, reward total was -21.0. running mean: -19.91808142593738, timestamp: 2022-08-19 22:06:27.046276\n",
      "resetting env. episode 2957, reward total was -21.0. running mean: -19.928900611678007, timestamp: 2022-08-19 22:06:29.914612\n",
      "resetting env. episode 2958, reward total was -20.0. running mean: -19.929611605561227, timestamp: 2022-08-19 22:06:32.890654\n",
      "resetting env. episode 2959, reward total was -19.0. running mean: -19.920315489505615, timestamp: 2022-08-19 22:06:37.889750\n",
      "resetting env. episode 2960, reward total was -20.0. running mean: -19.92111233461056, timestamp: 2022-08-19 22:06:41.692595\n",
      "resetting env. episode 2961, reward total was -21.0. running mean: -19.931901211264453, timestamp: 2022-08-19 22:06:45.165302\n",
      "resetting env. episode 2962, reward total was -19.0. running mean: -19.922582199151808, timestamp: 2022-08-19 22:06:49.084815\n",
      "resetting env. episode 2963, reward total was -20.0. running mean: -19.92335637716029, timestamp: 2022-08-19 22:06:57.326787\n",
      "resetting env. episode 2964, reward total was -21.0. running mean: -19.934122813388687, timestamp: 2022-08-19 22:07:03.425545\n",
      "resetting env. episode 2965, reward total was -19.0. running mean: -19.924781585254802, timestamp: 2022-08-19 22:07:08.149915\n",
      "resetting env. episode 2966, reward total was -21.0. running mean: -19.935533769402255, timestamp: 2022-08-19 22:07:11.192021\n",
      "resetting env. episode 2967, reward total was -20.0. running mean: -19.936178431708232, timestamp: 2022-08-19 22:07:14.578965\n",
      "resetting env. episode 2968, reward total was -19.0. running mean: -19.92681664739115, timestamp: 2022-08-19 22:07:18.509088\n",
      "resetting env. episode 2969, reward total was -19.0. running mean: -19.91754848091724, timestamp: 2022-08-19 22:07:21.527752\n",
      "resetting env. episode 2970, reward total was -19.0. running mean: -19.90837299610807, timestamp: 2022-08-19 22:07:24.696407\n",
      "resetting env. episode 2971, reward total was -21.0. running mean: -19.91928926614699, timestamp: 2022-08-19 22:07:27.336652\n",
      "resetting env. episode 2972, reward total was -21.0. running mean: -19.930096373485522, timestamp: 2022-08-19 22:07:32.137832\n",
      "resetting env. episode 2973, reward total was -18.0. running mean: -19.910795409750666, timestamp: 2022-08-19 22:07:35.825954\n",
      "resetting env. episode 2974, reward total was -18.0. running mean: -19.89168745565316, timestamp: 2022-08-19 22:07:40.288027\n",
      "resetting env. episode 2975, reward total was -19.0. running mean: -19.88277058109663, timestamp: 2022-08-19 22:07:44.681556\n",
      "resetting env. episode 2976, reward total was -20.0. running mean: -19.883942875285662, timestamp: 2022-08-19 22:07:48.581638\n",
      "resetting env. episode 2977, reward total was -20.0. running mean: -19.885103446532803, timestamp: 2022-08-19 22:07:52.048218\n",
      "resetting env. episode 2978, reward total was -19.0. running mean: -19.876252412067476, timestamp: 2022-08-19 22:07:55.317447\n",
      "resetting env. episode 2979, reward total was -21.0. running mean: -19.887489887946803, timestamp: 2022-08-19 22:07:59.442455\n",
      "resetting env. episode 2980, reward total was -20.0. running mean: -19.888614989067335, timestamp: 2022-08-19 22:08:02.278850\n",
      "resetting env. episode 2981, reward total was -19.0. running mean: -19.879728839176664, timestamp: 2022-08-19 22:08:06.589910\n",
      "resetting env. episode 2982, reward total was -21.0. running mean: -19.8909315507849, timestamp: 2022-08-19 22:08:09.857212\n",
      "resetting env. episode 2983, reward total was -20.0. running mean: -19.89202223527705, timestamp: 2022-08-19 22:08:13.476535\n",
      "resetting env. episode 2984, reward total was -18.0. running mean: -19.873102012924278, timestamp: 2022-08-19 22:08:18.162905\n",
      "resetting env. episode 2985, reward total was -21.0. running mean: -19.884370992795034, timestamp: 2022-08-19 22:08:23.147587\n",
      "resetting env. episode 2986, reward total was -20.0. running mean: -19.885527282867084, timestamp: 2022-08-19 22:08:27.546225\n",
      "resetting env. episode 2987, reward total was -21.0. running mean: -19.896672010038415, timestamp: 2022-08-19 22:08:31.331108\n",
      "resetting env. episode 2988, reward total was -20.0. running mean: -19.89770528993803, timestamp: 2022-08-19 22:08:34.432911\n",
      "resetting env. episode 2989, reward total was -20.0. running mean: -19.89872823703865, timestamp: 2022-08-19 22:08:37.768994\n",
      "resetting env. episode 2990, reward total was -21.0. running mean: -19.909740954668266, timestamp: 2022-08-19 22:08:40.727052\n",
      "resetting env. episode 2991, reward total was -21.0. running mean: -19.920643545121585, timestamp: 2022-08-19 22:08:43.241255\n",
      "resetting env. episode 2992, reward total was -21.0. running mean: -19.93143710967037, timestamp: 2022-08-19 22:08:46.474677\n",
      "resetting env. episode 2993, reward total was -19.0. running mean: -19.922122738573666, timestamp: 2022-08-19 22:08:50.053775\n",
      "resetting env. episode 2994, reward total was -21.0. running mean: -19.93290151118793, timestamp: 2022-08-19 22:08:53.051203\n",
      "resetting env. episode 2995, reward total was -21.0. running mean: -19.94357249607605, timestamp: 2022-08-19 22:08:55.869667\n",
      "resetting env. episode 2996, reward total was -15.0. running mean: -19.89413677111529, timestamp: 2022-08-19 22:09:00.075751\n",
      "resetting env. episode 2997, reward total was -19.0. running mean: -19.885195403404136, timestamp: 2022-08-19 22:09:03.620581\n",
      "resetting env. episode 2998, reward total was -21.0. running mean: -19.896343449370097, timestamp: 2022-08-19 22:09:07.388510\n",
      "resetting env. episode 2999, reward total was -18.0. running mean: -19.877380014876394, timestamp: 2022-08-19 22:09:12.494861\n",
      "resetting env. episode 3000, reward total was -21.0. running mean: -19.88860621472763, timestamp: 2022-08-19 22:09:15.562738\n",
      "resetting env. episode 3001, reward total was -21.0. running mean: -19.899720152580354, timestamp: 2022-08-19 22:09:18.827116\n",
      "resetting env. episode 3002, reward total was -21.0. running mean: -19.910722951054552, timestamp: 2022-08-19 22:09:21.512938\n",
      "resetting env. episode 3003, reward total was -21.0. running mean: -19.921615721544008, timestamp: 2022-08-19 22:09:24.894895\n",
      "resetting env. episode 3004, reward total was -20.0. running mean: -19.92239956432857, timestamp: 2022-08-19 22:09:28.659859\n",
      "resetting env. episode 3005, reward total was -19.0. running mean: -19.913175568685283, timestamp: 2022-08-19 22:09:32.341129\n",
      "resetting env. episode 3006, reward total was -21.0. running mean: -19.92404381299843, timestamp: 2022-08-19 22:09:35.863711\n",
      "resetting env. episode 3007, reward total was -20.0. running mean: -19.924803374868446, timestamp: 2022-08-19 22:09:38.748998\n",
      "resetting env. episode 3008, reward total was -19.0. running mean: -19.915555341119763, timestamp: 2022-08-19 22:09:42.392286\n",
      "resetting env. episode 3009, reward total was -21.0. running mean: -19.926399787708565, timestamp: 2022-08-19 22:09:46.603020\n",
      "resetting env. episode 3010, reward total was -20.0. running mean: -19.92713578983148, timestamp: 2022-08-19 22:09:50.371964\n",
      "resetting env. episode 3011, reward total was -19.0. running mean: -19.917864431933165, timestamp: 2022-08-19 22:09:54.143071\n",
      "resetting env. episode 3012, reward total was -19.0. running mean: -19.908685787613834, timestamp: 2022-08-19 22:09:57.761123\n",
      "resetting env. episode 3013, reward total was -20.0. running mean: -19.909598929737694, timestamp: 2022-08-19 22:10:01.798546\n",
      "resetting env. episode 3014, reward total was -21.0. running mean: -19.92050294044032, timestamp: 2022-08-19 22:10:06.099152\n",
      "resetting env. episode 3015, reward total was -21.0. running mean: -19.931297911035916, timestamp: 2022-08-19 22:10:08.852083\n",
      "resetting env. episode 3016, reward total was -21.0. running mean: -19.941984931925557, timestamp: 2022-08-19 22:10:11.827164\n",
      "resetting env. episode 3017, reward total was -21.0. running mean: -19.952565082606302, timestamp: 2022-08-19 22:10:14.720402\n",
      "resetting env. episode 3018, reward total was -19.0. running mean: -19.94303943178024, timestamp: 2022-08-19 22:10:18.776591\n",
      "resetting env. episode 3019, reward total was -20.0. running mean: -19.943609037462437, timestamp: 2022-08-19 22:10:21.855555\n",
      "resetting env. episode 3020, reward total was -21.0. running mean: -19.954172947087812, timestamp: 2022-08-19 22:10:24.937322\n",
      "resetting env. episode 3021, reward total was -18.0. running mean: -19.934631217616936, timestamp: 2022-08-19 22:10:29.381263\n",
      "resetting env. episode 3022, reward total was -20.0. running mean: -19.935284905440767, timestamp: 2022-08-19 22:10:34.573369\n",
      "resetting env. episode 3023, reward total was -20.0. running mean: -19.93593205638636, timestamp: 2022-08-19 22:10:39.175848\n",
      "resetting env. episode 3024, reward total was -21.0. running mean: -19.946572735822496, timestamp: 2022-08-19 22:10:42.980878\n",
      "resetting env. episode 3025, reward total was -20.0. running mean: -19.947107008464272, timestamp: 2022-08-19 22:10:46.271078\n",
      "resetting env. episode 3026, reward total was -20.0. running mean: -19.94763593837963, timestamp: 2022-08-19 22:10:49.237204\n",
      "resetting env. episode 3027, reward total was -21.0. running mean: -19.958159578995833, timestamp: 2022-08-19 22:10:52.753897\n",
      "resetting env. episode 3028, reward total was -20.0. running mean: -19.958577983205874, timestamp: 2022-08-19 22:10:56.419165\n",
      "resetting env. episode 3029, reward total was -20.0. running mean: -19.958992203373814, timestamp: 2022-08-19 22:10:59.872556\n",
      "resetting env. episode 3030, reward total was -20.0. running mean: -19.959402281340076, timestamp: 2022-08-19 22:11:02.731980\n",
      "resetting env. episode 3031, reward total was -21.0. running mean: -19.969808258526676, timestamp: 2022-08-19 22:11:05.804575\n",
      "resetting env. episode 3032, reward total was -20.0. running mean: -19.970110175941407, timestamp: 2022-08-19 22:11:09.848973\n",
      "resetting env. episode 3033, reward total was -20.0. running mean: -19.970409074181994, timestamp: 2022-08-19 22:11:13.225950\n",
      "resetting env. episode 3034, reward total was -21.0. running mean: -19.980704983440173, timestamp: 2022-08-19 22:11:17.482054\n",
      "resetting env. episode 3035, reward total was -19.0. running mean: -19.970897933605773, timestamp: 2022-08-19 22:11:20.601300\n",
      "resetting env. episode 3036, reward total was -21.0. running mean: -19.981188954269715, timestamp: 2022-08-19 22:11:23.467766\n",
      "resetting env. episode 3037, reward total was -20.0. running mean: -19.981377064727017, timestamp: 2022-08-19 22:11:27.060046\n",
      "resetting env. episode 3038, reward total was -21.0. running mean: -19.991563294079747, timestamp: 2022-08-19 22:11:30.521895\n",
      "resetting env. episode 3039, reward total was -20.0. running mean: -19.99164766113895, timestamp: 2022-08-19 22:11:33.745277\n",
      "resetting env. episode 3040, reward total was -19.0. running mean: -19.98173118452756, timestamp: 2022-08-19 22:11:37.319749\n",
      "resetting env. episode 3041, reward total was -21.0. running mean: -19.991913872682286, timestamp: 2022-08-19 22:11:40.454082\n",
      "resetting env. episode 3042, reward total was -17.0. running mean: -19.961994733955464, timestamp: 2022-08-19 22:11:45.439778\n",
      "resetting env. episode 3043, reward total was -20.0. running mean: -19.962374786615907, timestamp: 2022-08-19 22:11:48.515311\n",
      "resetting env. episode 3044, reward total was -21.0. running mean: -19.97275103874975, timestamp: 2022-08-19 22:11:52.103442\n",
      "resetting env. episode 3045, reward total was -19.0. running mean: -19.963023528362253, timestamp: 2022-08-19 22:11:55.394646\n",
      "resetting env. episode 3046, reward total was -21.0. running mean: -19.973393293078633, timestamp: 2022-08-19 22:11:58.686737\n",
      "resetting env. episode 3047, reward total was -20.0. running mean: -19.973659360147845, timestamp: 2022-08-19 22:12:01.778402\n",
      "resetting env. episode 3048, reward total was -19.0. running mean: -19.963922766546368, timestamp: 2022-08-19 22:12:05.869757\n",
      "resetting env. episode 3049, reward total was -20.0. running mean: -19.964283538880903, timestamp: 2022-08-19 22:12:09.454413\n",
      "resetting env. episode 3050, reward total was -21.0. running mean: -19.974640703492096, timestamp: 2022-08-19 22:12:12.365050\n",
      "resetting env. episode 3051, reward total was -19.0. running mean: -19.964894296457175, timestamp: 2022-08-19 22:12:15.953834\n",
      "resetting env. episode 3052, reward total was -21.0. running mean: -19.975245353492603, timestamp: 2022-08-19 22:12:20.093948\n",
      "resetting env. episode 3053, reward total was -20.0. running mean: -19.975492899957676, timestamp: 2022-08-19 22:12:23.745126\n",
      "resetting env. episode 3054, reward total was -18.0. running mean: -19.955737970958097, timestamp: 2022-08-19 22:12:27.502081\n",
      "resetting env. episode 3055, reward total was -20.0. running mean: -19.956180591248515, timestamp: 2022-08-19 22:12:30.591859\n",
      "resetting env. episode 3056, reward total was -20.0. running mean: -19.95661878533603, timestamp: 2022-08-19 22:12:34.499704\n",
      "resetting env. episode 3057, reward total was -20.0. running mean: -19.95705259748267, timestamp: 2022-08-19 22:12:37.350257\n",
      "resetting env. episode 3058, reward total was -18.0. running mean: -19.93748207150784, timestamp: 2022-08-19 22:12:41.063174\n",
      "resetting env. episode 3059, reward total was -20.0. running mean: -19.93810725079276, timestamp: 2022-08-19 22:12:44.240033\n",
      "resetting env. episode 3060, reward total was -17.0. running mean: -19.908726178284834, timestamp: 2022-08-19 22:12:49.325315\n",
      "resetting env. episode 3061, reward total was -19.0. running mean: -19.899638916501985, timestamp: 2022-08-19 22:12:53.686834\n",
      "resetting env. episode 3062, reward total was -21.0. running mean: -19.910642527336964, timestamp: 2022-08-19 22:12:57.328140\n",
      "resetting env. episode 3063, reward total was -21.0. running mean: -19.921536102063595, timestamp: 2022-08-19 22:13:00.445432\n",
      "resetting env. episode 3064, reward total was -19.0. running mean: -19.91232074104296, timestamp: 2022-08-19 22:13:05.161827\n",
      "resetting env. episode 3065, reward total was -20.0. running mean: -19.91319753363253, timestamp: 2022-08-19 22:13:09.765368\n",
      "resetting env. episode 3066, reward total was -21.0. running mean: -19.924065558296206, timestamp: 2022-08-19 22:13:12.908340\n",
      "resetting env. episode 3067, reward total was -21.0. running mean: -19.934824902713245, timestamp: 2022-08-19 22:13:17.157404\n",
      "resetting env. episode 3068, reward total was -20.0. running mean: -19.935476653686113, timestamp: 2022-08-19 22:13:20.722871\n",
      "resetting env. episode 3069, reward total was -19.0. running mean: -19.926121887149254, timestamp: 2022-08-19 22:13:24.221264\n",
      "resetting env. episode 3070, reward total was -18.0. running mean: -19.906860668277762, timestamp: 2022-08-19 22:13:28.517836\n",
      "resetting env. episode 3071, reward total was -20.0. running mean: -19.907792061594982, timestamp: 2022-08-19 22:13:32.014123\n",
      "resetting env. episode 3072, reward total was -20.0. running mean: -19.908714140979033, timestamp: 2022-08-19 22:13:35.755016\n",
      "resetting env. episode 3073, reward total was -20.0. running mean: -19.90962699956924, timestamp: 2022-08-19 22:13:39.686540\n",
      "resetting env. episode 3074, reward total was -18.0. running mean: -19.89053072957355, timestamp: 2022-08-19 22:13:44.329726\n",
      "resetting env. episode 3075, reward total was -21.0. running mean: -19.901625422277814, timestamp: 2022-08-19 22:13:48.782864\n",
      "resetting env. episode 3076, reward total was -21.0. running mean: -19.912609168055035, timestamp: 2022-08-19 22:13:52.885897\n",
      "resetting env. episode 3077, reward total was -21.0. running mean: -19.923483076374485, timestamp: 2022-08-19 22:13:57.435267\n",
      "resetting env. episode 3078, reward total was -21.0. running mean: -19.93424824561074, timestamp: 2022-08-19 22:14:01.957393\n",
      "resetting env. episode 3079, reward total was -21.0. running mean: -19.944905763154633, timestamp: 2022-08-19 22:14:06.555128\n",
      "resetting env. episode 3080, reward total was -19.0. running mean: -19.935456705523087, timestamp: 2022-08-19 22:14:13.662149\n",
      "resetting env. episode 3081, reward total was -21.0. running mean: -19.946102138467857, timestamp: 2022-08-19 22:14:20.016165\n",
      "resetting env. episode 3082, reward total was -20.0. running mean: -19.94664111708318, timestamp: 2022-08-19 22:14:26.795181\n",
      "resetting env. episode 3083, reward total was -21.0. running mean: -19.957174705912347, timestamp: 2022-08-19 22:14:31.289165\n",
      "resetting env. episode 3084, reward total was -20.0. running mean: -19.957602958853222, timestamp: 2022-08-19 22:14:35.164688\n",
      "resetting env. episode 3085, reward total was -20.0. running mean: -19.95802692926469, timestamp: 2022-08-19 22:14:39.254724\n",
      "resetting env. episode 3086, reward total was -20.0. running mean: -19.958446659972044, timestamp: 2022-08-19 22:14:42.722978\n",
      "resetting env. episode 3087, reward total was -19.0. running mean: -19.948862193372324, timestamp: 2022-08-19 22:14:47.623369\n",
      "resetting env. episode 3088, reward total was -20.0. running mean: -19.9493735714386, timestamp: 2022-08-19 22:14:51.646617\n",
      "resetting env. episode 3089, reward total was -20.0. running mean: -19.94987983572421, timestamp: 2022-08-19 22:14:54.987685\n",
      "resetting env. episode 3090, reward total was -20.0. running mean: -19.950381037366967, timestamp: 2022-08-19 22:14:58.886398\n",
      "resetting env. episode 3091, reward total was -19.0. running mean: -19.940877226993297, timestamp: 2022-08-19 22:15:02.963010\n",
      "resetting env. episode 3092, reward total was -18.0. running mean: -19.921468454723364, timestamp: 2022-08-19 22:15:06.240995\n",
      "resetting env. episode 3093, reward total was -18.0. running mean: -19.90225377017613, timestamp: 2022-08-19 22:15:10.001363\n",
      "resetting env. episode 3094, reward total was -20.0. running mean: -19.90323123247437, timestamp: 2022-08-19 22:15:13.352239\n",
      "resetting env. episode 3095, reward total was -21.0. running mean: -19.914198920149627, timestamp: 2022-08-19 22:15:16.853910\n",
      "resetting env. episode 3096, reward total was -21.0. running mean: -19.92505693094813, timestamp: 2022-08-19 22:15:20.361506\n",
      "resetting env. episode 3097, reward total was -19.0. running mean: -19.91580636163865, timestamp: 2022-08-19 22:15:23.069267\n",
      "resetting env. episode 3098, reward total was -21.0. running mean: -19.926648298022265, timestamp: 2022-08-19 22:15:26.647910\n",
      "resetting env. episode 3099, reward total was -20.0. running mean: -19.92738181504204, timestamp: 2022-08-19 22:15:30.938168\n",
      "resetting env. episode 3100, reward total was -20.0. running mean: -19.92810799689162, timestamp: 2022-08-19 22:15:35.746348\n",
      "resetting env. episode 3101, reward total was -21.0. running mean: -19.938826916922704, timestamp: 2022-08-19 22:15:38.353001\n",
      "resetting env. episode 3102, reward total was -20.0. running mean: -19.939438647753477, timestamp: 2022-08-19 22:15:42.830035\n",
      "resetting env. episode 3103, reward total was -17.0. running mean: -19.910044261275942, timestamp: 2022-08-19 22:15:48.395165\n",
      "resetting env. episode 3104, reward total was -20.0. running mean: -19.91094381866318, timestamp: 2022-08-19 22:15:52.741435\n",
      "resetting env. episode 3105, reward total was -19.0. running mean: -19.90183438047655, timestamp: 2022-08-19 22:15:56.858321\n",
      "resetting env. episode 3106, reward total was -20.0. running mean: -19.902816036671783, timestamp: 2022-08-19 22:16:00.127576\n",
      "resetting env. episode 3107, reward total was -20.0. running mean: -19.903787876305064, timestamp: 2022-08-19 22:16:03.370909\n",
      "resetting env. episode 3108, reward total was -21.0. running mean: -19.914749997542014, timestamp: 2022-08-19 22:16:07.479912\n",
      "resetting env. episode 3109, reward total was -18.0. running mean: -19.895602497566593, timestamp: 2022-08-19 22:16:11.424369\n",
      "resetting env. episode 3110, reward total was -21.0. running mean: -19.90664647259093, timestamp: 2022-08-19 22:16:14.986877\n",
      "resetting env. episode 3111, reward total was -19.0. running mean: -19.89758000786502, timestamp: 2022-08-19 22:16:19.722555\n",
      "resetting env. episode 3112, reward total was -19.0. running mean: -19.888604207786372, timestamp: 2022-08-19 22:16:23.104706\n",
      "resetting env. episode 3113, reward total was -20.0. running mean: -19.88971816570851, timestamp: 2022-08-19 22:16:26.362154\n",
      "resetting env. episode 3114, reward total was -18.0. running mean: -19.870820984051424, timestamp: 2022-08-19 22:16:30.215820\n",
      "resetting env. episode 3115, reward total was -21.0. running mean: -19.88211277421091, timestamp: 2022-08-19 22:16:34.509849\n",
      "resetting env. episode 3116, reward total was -18.0. running mean: -19.8632916464688, timestamp: 2022-08-19 22:16:38.306710\n",
      "resetting env. episode 3117, reward total was -21.0. running mean: -19.87465873000411, timestamp: 2022-08-19 22:16:41.517902\n",
      "resetting env. episode 3118, reward total was -19.0. running mean: -19.865912142704072, timestamp: 2022-08-19 22:16:44.730349\n",
      "resetting env. episode 3119, reward total was -20.0. running mean: -19.86725302127703, timestamp: 2022-08-19 22:16:49.285649\n",
      "resetting env. episode 3120, reward total was -20.0. running mean: -19.868580491064257, timestamp: 2022-08-19 22:16:52.161087\n",
      "resetting env. episode 3121, reward total was -19.0. running mean: -19.859894686153616, timestamp: 2022-08-19 22:16:56.320312\n",
      "resetting env. episode 3122, reward total was -21.0. running mean: -19.87129573929208, timestamp: 2022-08-19 22:16:59.721255\n",
      "resetting env. episode 3123, reward total was -20.0. running mean: -19.87258278189916, timestamp: 2022-08-19 22:17:02.547838\n",
      "resetting env. episode 3124, reward total was -19.0. running mean: -19.863856954080166, timestamp: 2022-08-19 22:17:06.314286\n",
      "resetting env. episode 3125, reward total was -21.0. running mean: -19.875218384539366, timestamp: 2022-08-19 22:17:08.951270\n",
      "resetting env. episode 3126, reward total was -20.0. running mean: -19.876466200693972, timestamp: 2022-08-19 22:17:12.962515\n",
      "resetting env. episode 3127, reward total was -20.0. running mean: -19.87770153868703, timestamp: 2022-08-19 22:17:15.932578\n",
      "resetting env. episode 3128, reward total was -19.0. running mean: -19.868924523300162, timestamp: 2022-08-19 22:17:20.114186\n",
      "resetting env. episode 3129, reward total was -21.0. running mean: -19.88023527806716, timestamp: 2022-08-19 22:17:24.092781\n",
      "resetting env. episode 3130, reward total was -18.0. running mean: -19.86143292528649, timestamp: 2022-08-19 22:17:27.791309\n",
      "resetting env. episode 3131, reward total was -17.0. running mean: -19.832818596033626, timestamp: 2022-08-19 22:17:32.173001\n",
      "resetting env. episode 3132, reward total was -20.0. running mean: -19.83449041007329, timestamp: 2022-08-19 22:17:35.754836\n",
      "resetting env. episode 3133, reward total was -21.0. running mean: -19.846145505972558, timestamp: 2022-08-19 22:17:38.490371\n",
      "resetting env. episode 3134, reward total was -21.0. running mean: -19.857684050912834, timestamp: 2022-08-19 22:17:41.100418\n",
      "resetting env. episode 3135, reward total was -20.0. running mean: -19.859107210403703, timestamp: 2022-08-19 22:17:44.859683\n",
      "resetting env. episode 3136, reward total was -19.0. running mean: -19.850516138299668, timestamp: 2022-08-19 22:17:47.551883\n",
      "resetting env. episode 3137, reward total was -20.0. running mean: -19.85201097691667, timestamp: 2022-08-19 22:17:52.578446\n",
      "resetting env. episode 3138, reward total was -19.0. running mean: -19.843490867147505, timestamp: 2022-08-19 22:17:56.394554\n",
      "resetting env. episode 3139, reward total was -21.0. running mean: -19.85505595847603, timestamp: 2022-08-19 22:17:59.297507\n",
      "resetting env. episode 3140, reward total was -21.0. running mean: -19.86650539889127, timestamp: 2022-08-19 22:18:02.725374\n",
      "resetting env. episode 3141, reward total was -19.0. running mean: -19.85784034490236, timestamp: 2022-08-19 22:18:08.012785\n",
      "resetting env. episode 3142, reward total was -20.0. running mean: -19.859261941453337, timestamp: 2022-08-19 22:18:13.239425\n",
      "resetting env. episode 3143, reward total was -19.0. running mean: -19.850669322038804, timestamp: 2022-08-19 22:18:20.957795\n",
      "resetting env. episode 3144, reward total was -19.0. running mean: -19.842162628818418, timestamp: 2022-08-19 22:18:28.877627\n",
      "resetting env. episode 3145, reward total was -19.0. running mean: -19.833741002530235, timestamp: 2022-08-19 22:18:34.777013\n",
      "resetting env. episode 3146, reward total was -21.0. running mean: -19.845403592504933, timestamp: 2022-08-19 22:18:39.991086\n",
      "resetting env. episode 3147, reward total was -19.0. running mean: -19.836949556579885, timestamp: 2022-08-19 22:18:46.496685\n",
      "resetting env. episode 3148, reward total was -21.0. running mean: -19.848580061014086, timestamp: 2022-08-19 22:18:50.395481\n",
      "resetting env. episode 3149, reward total was -20.0. running mean: -19.850094260403946, timestamp: 2022-08-19 22:18:54.334917\n",
      "resetting env. episode 3150, reward total was -19.0. running mean: -19.84159331779991, timestamp: 2022-08-19 22:18:59.208883\n",
      "resetting env. episode 3151, reward total was -21.0. running mean: -19.85317738462191, timestamp: 2022-08-19 22:19:05.887036\n",
      "resetting env. episode 3152, reward total was -21.0. running mean: -19.864645610775693, timestamp: 2022-08-19 22:19:09.070525\n",
      "resetting env. episode 3153, reward total was -19.0. running mean: -19.855999154667938, timestamp: 2022-08-19 22:19:12.823896\n",
      "resetting env. episode 3154, reward total was -18.0. running mean: -19.837439163121257, timestamp: 2022-08-19 22:19:17.138181\n",
      "resetting env. episode 3155, reward total was -20.0. running mean: -19.839064771490044, timestamp: 2022-08-19 22:19:20.976130\n",
      "resetting env. episode 3156, reward total was -20.0. running mean: -19.84067412377514, timestamp: 2022-08-19 22:19:25.259134\n",
      "resetting env. episode 3157, reward total was -20.0. running mean: -19.84226738253739, timestamp: 2022-08-19 22:19:29.037901\n",
      "resetting env. episode 3158, reward total was -19.0. running mean: -19.833844708712018, timestamp: 2022-08-19 22:19:32.340073\n",
      "resetting env. episode 3159, reward total was -19.0. running mean: -19.8255062616249, timestamp: 2022-08-19 22:19:36.053146\n",
      "resetting env. episode 3160, reward total was -20.0. running mean: -19.82725119900865, timestamp: 2022-08-19 22:19:39.477993\n",
      "resetting env. episode 3161, reward total was -21.0. running mean: -19.838978687018564, timestamp: 2022-08-19 22:19:43.196715\n",
      "resetting env. episode 3162, reward total was -20.0. running mean: -19.840588900148376, timestamp: 2022-08-19 22:19:46.403178\n",
      "resetting env. episode 3163, reward total was -21.0. running mean: -19.85218301114689, timestamp: 2022-08-19 22:19:50.093657\n",
      "resetting env. episode 3164, reward total was -21.0. running mean: -19.863661181035422, timestamp: 2022-08-19 22:19:52.991250\n",
      "resetting env. episode 3165, reward total was -19.0. running mean: -19.85502456922507, timestamp: 2022-08-19 22:19:57.411436\n",
      "resetting env. episode 3166, reward total was -19.0. running mean: -19.84647432353282, timestamp: 2022-08-19 22:20:01.400774\n",
      "resetting env. episode 3167, reward total was -21.0. running mean: -19.858009580297495, timestamp: 2022-08-19 22:20:05.835979\n",
      "resetting env. episode 3168, reward total was -21.0. running mean: -19.86942948449452, timestamp: 2022-08-19 22:20:09.140150\n",
      "resetting env. episode 3169, reward total was -18.0. running mean: -19.850735189649576, timestamp: 2022-08-19 22:20:13.562543\n",
      "resetting env. episode 3170, reward total was -20.0. running mean: -19.85222783775308, timestamp: 2022-08-19 22:20:17.365942\n",
      "resetting env. episode 3171, reward total was -20.0. running mean: -19.85370555937555, timestamp: 2022-08-19 22:20:22.012577\n",
      "resetting env. episode 3172, reward total was -20.0. running mean: -19.85516850378179, timestamp: 2022-08-19 22:20:26.481583\n",
      "resetting env. episode 3173, reward total was -21.0. running mean: -19.866616818743974, timestamp: 2022-08-19 22:20:31.050366\n",
      "resetting env. episode 3174, reward total was -20.0. running mean: -19.867950650556534, timestamp: 2022-08-19 22:20:36.518752\n",
      "resetting env. episode 3175, reward total was -21.0. running mean: -19.879271144050968, timestamp: 2022-08-19 22:20:40.237636\n",
      "resetting env. episode 3176, reward total was -21.0. running mean: -19.890478432610458, timestamp: 2022-08-19 22:20:44.531440\n",
      "resetting env. episode 3177, reward total was -20.0. running mean: -19.891573648284353, timestamp: 2022-08-19 22:20:48.075290\n",
      "resetting env. episode 3178, reward total was -19.0. running mean: -19.882657911801513, timestamp: 2022-08-19 22:20:51.798337\n",
      "resetting env. episode 3179, reward total was -20.0. running mean: -19.883831332683496, timestamp: 2022-08-19 22:20:55.081590\n",
      "resetting env. episode 3180, reward total was -20.0. running mean: -19.88499301935666, timestamp: 2022-08-19 22:20:59.319702\n",
      "resetting env. episode 3181, reward total was -21.0. running mean: -19.896143089163093, timestamp: 2022-08-19 22:21:03.148574\n",
      "resetting env. episode 3182, reward total was -20.0. running mean: -19.89718165827146, timestamp: 2022-08-19 22:21:06.460068\n",
      "resetting env. episode 3183, reward total was -20.0. running mean: -19.898209841688743, timestamp: 2022-08-19 22:21:09.791172\n",
      "resetting env. episode 3184, reward total was -19.0. running mean: -19.889227743271856, timestamp: 2022-08-19 22:21:13.533161\n",
      "resetting env. episode 3185, reward total was -20.0. running mean: -19.890335465839136, timestamp: 2022-08-19 22:21:16.857274\n",
      "resetting env. episode 3186, reward total was -21.0. running mean: -19.901432111180746, timestamp: 2022-08-19 22:21:21.066563\n",
      "resetting env. episode 3187, reward total was -19.0. running mean: -19.89241779006894, timestamp: 2022-08-19 22:21:25.111803\n",
      "resetting env. episode 3188, reward total was -21.0. running mean: -19.90349361216825, timestamp: 2022-08-19 22:21:27.823762\n",
      "resetting env. episode 3189, reward total was -17.0. running mean: -19.87445867604657, timestamp: 2022-08-19 22:21:32.080374\n",
      "resetting env. episode 3190, reward total was -18.0. running mean: -19.855714089286103, timestamp: 2022-08-19 22:21:35.636886\n",
      "resetting env. episode 3191, reward total was -18.0. running mean: -19.83715694839324, timestamp: 2022-08-19 22:21:39.960391\n",
      "resetting env. episode 3192, reward total was -21.0. running mean: -19.84878537890931, timestamp: 2022-08-19 22:21:42.824748\n",
      "resetting env. episode 3193, reward total was -21.0. running mean: -19.860297525120217, timestamp: 2022-08-19 22:21:45.624286\n",
      "resetting env. episode 3194, reward total was -20.0. running mean: -19.861694549869014, timestamp: 2022-08-19 22:21:49.032024\n",
      "resetting env. episode 3195, reward total was -21.0. running mean: -19.873077604370327, timestamp: 2022-08-19 22:21:51.749789\n",
      "resetting env. episode 3196, reward total was -21.0. running mean: -19.884346828326624, timestamp: 2022-08-19 22:21:54.603196\n",
      "resetting env. episode 3197, reward total was -20.0. running mean: -19.88550336004336, timestamp: 2022-08-19 22:21:59.048285\n",
      "resetting env. episode 3198, reward total was -21.0. running mean: -19.896648326442925, timestamp: 2022-08-19 22:22:02.229420\n",
      "resetting env. episode 3199, reward total was -19.0. running mean: -19.8876818431785, timestamp: 2022-08-19 22:22:06.179859\n",
      "resetting env. episode 3200, reward total was -18.0. running mean: -19.868805024746713, timestamp: 2022-08-19 22:22:10.325002\n",
      "resetting env. episode 3201, reward total was -20.0. running mean: -19.870116974499243, timestamp: 2022-08-19 22:22:13.636690\n",
      "resetting env. episode 3202, reward total was -20.0. running mean: -19.87141580475425, timestamp: 2022-08-19 22:22:17.143401\n",
      "resetting env. episode 3203, reward total was -19.0. running mean: -19.862701646706707, timestamp: 2022-08-19 22:22:21.001571\n",
      "resetting env. episode 3204, reward total was -21.0. running mean: -19.87407463023964, timestamp: 2022-08-19 22:22:24.006029\n",
      "resetting env. episode 3205, reward total was -19.0. running mean: -19.865333883937247, timestamp: 2022-08-19 22:22:28.057767\n",
      "resetting env. episode 3206, reward total was -19.0. running mean: -19.856680545097877, timestamp: 2022-08-19 22:22:32.016243\n",
      "resetting env. episode 3207, reward total was -21.0. running mean: -19.868113739646898, timestamp: 2022-08-19 22:22:34.851827\n",
      "resetting env. episode 3208, reward total was -20.0. running mean: -19.869432602250427, timestamp: 2022-08-19 22:22:39.224445\n",
      "resetting env. episode 3209, reward total was -20.0. running mean: -19.87073827622792, timestamp: 2022-08-19 22:22:42.793931\n",
      "resetting env. episode 3210, reward total was -20.0. running mean: -19.87203089346564, timestamp: 2022-08-19 22:22:47.071842\n",
      "resetting env. episode 3211, reward total was -16.0. running mean: -19.833310584530984, timestamp: 2022-08-19 22:22:50.885237\n",
      "resetting env. episode 3212, reward total was -21.0. running mean: -19.844977478685674, timestamp: 2022-08-19 22:22:54.576094\n",
      "resetting env. episode 3213, reward total was -21.0. running mean: -19.85652770389882, timestamp: 2022-08-19 22:22:58.076644\n",
      "resetting env. episode 3214, reward total was -20.0. running mean: -19.85796242685983, timestamp: 2022-08-19 22:23:02.211593\n",
      "resetting env. episode 3215, reward total was -20.0. running mean: -19.85938280259123, timestamp: 2022-08-19 22:23:05.372154\n",
      "resetting env. episode 3216, reward total was -21.0. running mean: -19.87078897456532, timestamp: 2022-08-19 22:23:08.849867\n",
      "resetting env. episode 3217, reward total was -20.0. running mean: -19.872081084819666, timestamp: 2022-08-19 22:23:12.101869\n",
      "resetting env. episode 3218, reward total was -21.0. running mean: -19.88336027397147, timestamp: 2022-08-19 22:23:15.132851\n",
      "resetting env. episode 3219, reward total was -20.0. running mean: -19.884526671231754, timestamp: 2022-08-19 22:23:19.135609\n",
      "resetting env. episode 3220, reward total was -20.0. running mean: -19.885681404519435, timestamp: 2022-08-19 22:23:22.635588\n",
      "resetting env. episode 3221, reward total was -20.0. running mean: -19.88682459047424, timestamp: 2022-08-19 22:23:26.272197\n",
      "resetting env. episode 3222, reward total was -20.0. running mean: -19.8879563445695, timestamp: 2022-08-19 22:23:30.449441\n",
      "resetting env. episode 3223, reward total was -21.0. running mean: -19.899076781123807, timestamp: 2022-08-19 22:23:33.834152\n",
      "resetting env. episode 3224, reward total was -19.0. running mean: -19.89008601331257, timestamp: 2022-08-19 22:23:37.707772\n",
      "resetting env. episode 3225, reward total was -21.0. running mean: -19.901185153179444, timestamp: 2022-08-19 22:23:40.595289\n",
      "resetting env. episode 3226, reward total was -21.0. running mean: -19.912173301647652, timestamp: 2022-08-19 22:23:43.958209\n",
      "resetting env. episode 3227, reward total was -21.0. running mean: -19.923051568631177, timestamp: 2022-08-19 22:23:47.680292\n",
      "resetting env. episode 3228, reward total was -19.0. running mean: -19.913821052944865, timestamp: 2022-08-19 22:23:52.245072\n",
      "resetting env. episode 3229, reward total was -20.0. running mean: -19.914682842415417, timestamp: 2022-08-19 22:23:55.580147\n",
      "resetting env. episode 3230, reward total was -19.0. running mean: -19.905536013991263, timestamp: 2022-08-19 22:23:59.842567\n",
      "resetting env. episode 3231, reward total was -20.0. running mean: -19.90648065385135, timestamp: 2022-08-19 22:24:03.457115\n",
      "resetting env. episode 3232, reward total was -18.0. running mean: -19.887415847312838, timestamp: 2022-08-19 22:24:08.111632\n",
      "resetting env. episode 3233, reward total was -21.0. running mean: -19.89854168883971, timestamp: 2022-08-19 22:24:12.201699\n",
      "resetting env. episode 3234, reward total was -20.0. running mean: -19.89955627195131, timestamp: 2022-08-19 22:24:15.932763\n",
      "resetting env. episode 3235, reward total was -21.0. running mean: -19.9105607092318, timestamp: 2022-08-19 22:24:20.154476\n",
      "resetting env. episode 3236, reward total was -20.0. running mean: -19.91145510213948, timestamp: 2022-08-19 22:24:23.907420\n",
      "resetting env. episode 3237, reward total was -21.0. running mean: -19.922340551118086, timestamp: 2022-08-19 22:24:27.016062\n",
      "resetting env. episode 3238, reward total was -19.0. running mean: -19.913117145606908, timestamp: 2022-08-19 22:24:30.025010\n",
      "resetting env. episode 3239, reward total was -21.0. running mean: -19.92398597415084, timestamp: 2022-08-19 22:24:33.958843\n",
      "resetting env. episode 3240, reward total was -18.0. running mean: -19.90474611440933, timestamp: 2022-08-19 22:24:37.998558\n",
      "resetting env. episode 3241, reward total was -18.0. running mean: -19.885698653265237, timestamp: 2022-08-19 22:24:42.877320\n",
      "resetting env. episode 3242, reward total was -21.0. running mean: -19.896841666732584, timestamp: 2022-08-19 22:24:46.173511\n",
      "resetting env. episode 3243, reward total was -18.0. running mean: -19.877873250065257, timestamp: 2022-08-19 22:24:51.582495\n",
      "resetting env. episode 3244, reward total was -21.0. running mean: -19.889094517564605, timestamp: 2022-08-19 22:24:54.993131\n",
      "resetting env. episode 3245, reward total was -19.0. running mean: -19.88020357238896, timestamp: 2022-08-19 22:24:58.802948\n",
      "resetting env. episode 3246, reward total was -19.0. running mean: -19.871401536665072, timestamp: 2022-08-19 22:25:03.123089\n",
      "resetting env. episode 3247, reward total was -19.0. running mean: -19.862687521298422, timestamp: 2022-08-19 22:25:06.626702\n",
      "resetting env. episode 3248, reward total was -21.0. running mean: -19.87406064608544, timestamp: 2022-08-19 22:25:09.724421\n",
      "resetting env. episode 3249, reward total was -19.0. running mean: -19.865320039624585, timestamp: 2022-08-19 22:25:13.982696\n",
      "resetting env. episode 3250, reward total was -21.0. running mean: -19.87666683922834, timestamp: 2022-08-19 22:25:17.581397\n",
      "resetting env. episode 3251, reward total was -19.0. running mean: -19.867900170836055, timestamp: 2022-08-19 22:25:22.020609\n",
      "resetting env. episode 3252, reward total was -21.0. running mean: -19.879221169127696, timestamp: 2022-08-19 22:25:24.989671\n",
      "resetting env. episode 3253, reward total was -20.0. running mean: -19.88042895743642, timestamp: 2022-08-19 22:25:27.587724\n",
      "resetting env. episode 3254, reward total was -21.0. running mean: -19.891624667862054, timestamp: 2022-08-19 22:25:30.269558\n",
      "resetting env. episode 3255, reward total was -20.0. running mean: -19.892708421183432, timestamp: 2022-08-19 22:25:34.626429\n",
      "resetting env. episode 3256, reward total was -21.0. running mean: -19.903781336971598, timestamp: 2022-08-19 22:25:38.269429\n",
      "resetting env. episode 3257, reward total was -20.0. running mean: -19.90474352360188, timestamp: 2022-08-19 22:25:41.607533\n",
      "resetting env. episode 3258, reward total was -19.0. running mean: -19.895696088365863, timestamp: 2022-08-19 22:25:44.665618\n",
      "resetting env. episode 3259, reward total was -18.0. running mean: -19.876739127482203, timestamp: 2022-08-19 22:25:47.993729\n",
      "resetting env. episode 3260, reward total was -21.0. running mean: -19.887971736207383, timestamp: 2022-08-19 22:25:50.892984\n",
      "resetting env. episode 3261, reward total was -20.0. running mean: -19.889092018845307, timestamp: 2022-08-19 22:25:53.676685\n",
      "resetting env. episode 3262, reward total was -20.0. running mean: -19.890201098656853, timestamp: 2022-08-19 22:25:57.730937\n",
      "resetting env. episode 3263, reward total was -18.0. running mean: -19.871299087670284, timestamp: 2022-08-19 22:26:01.348928\n",
      "resetting env. episode 3264, reward total was -19.0. running mean: -19.86258609679358, timestamp: 2022-08-19 22:26:05.419885\n",
      "resetting env. episode 3265, reward total was -21.0. running mean: -19.873960235825646, timestamp: 2022-08-19 22:26:09.347201\n",
      "resetting env. episode 3266, reward total was -20.0. running mean: -19.87522063346739, timestamp: 2022-08-19 22:26:12.591301\n",
      "resetting env. episode 3267, reward total was -21.0. running mean: -19.886468427132716, timestamp: 2022-08-19 22:26:16.492839\n",
      "resetting env. episode 3268, reward total was -20.0. running mean: -19.887603742861387, timestamp: 2022-08-19 22:26:20.137979\n",
      "resetting env. episode 3269, reward total was -20.0. running mean: -19.88872770543277, timestamp: 2022-08-19 22:26:23.391690\n",
      "resetting env. episode 3270, reward total was -20.0. running mean: -19.88984042837844, timestamp: 2022-08-19 22:26:27.483675\n",
      "resetting env. episode 3271, reward total was -19.0. running mean: -19.880942024094658, timestamp: 2022-08-19 22:26:31.419660\n",
      "resetting env. episode 3272, reward total was -21.0. running mean: -19.89213260385371, timestamp: 2022-08-19 22:26:33.794311\n",
      "resetting env. episode 3273, reward total was -21.0. running mean: -19.903211277815174, timestamp: 2022-08-19 22:26:37.222151\n",
      "resetting env. episode 3274, reward total was -20.0. running mean: -19.90417916503702, timestamp: 2022-08-19 22:26:40.803706\n",
      "resetting env. episode 3275, reward total was -20.0. running mean: -19.90513737338665, timestamp: 2022-08-19 22:26:43.934323\n",
      "resetting env. episode 3276, reward total was -20.0. running mean: -19.906085999652785, timestamp: 2022-08-19 22:26:47.005695\n",
      "resetting env. episode 3277, reward total was -21.0. running mean: -19.917025139656257, timestamp: 2022-08-19 22:26:50.741705\n",
      "resetting env. episode 3278, reward total was -21.0. running mean: -19.927854888259695, timestamp: 2022-08-19 22:26:53.965082\n",
      "resetting env. episode 3279, reward total was -21.0. running mean: -19.9385763393771, timestamp: 2022-08-19 22:26:57.258264\n",
      "resetting env. episode 3280, reward total was -21.0. running mean: -19.94919057598333, timestamp: 2022-08-19 22:27:00.685835\n",
      "resetting env. episode 3281, reward total was -19.0. running mean: -19.939698670223496, timestamp: 2022-08-19 22:27:04.204414\n",
      "resetting env. episode 3282, reward total was -19.0. running mean: -19.93030168352126, timestamp: 2022-08-19 22:27:07.932629\n",
      "resetting env. episode 3283, reward total was -19.0. running mean: -19.92099866668605, timestamp: 2022-08-19 22:27:11.018360\n",
      "resetting env. episode 3284, reward total was -20.0. running mean: -19.921788680019187, timestamp: 2022-08-19 22:27:14.643670\n",
      "resetting env. episode 3285, reward total was -19.0. running mean: -19.912570793218997, timestamp: 2022-08-19 22:27:17.615728\n",
      "resetting env. episode 3286, reward total was -21.0. running mean: -19.923445085286808, timestamp: 2022-08-19 22:27:20.162918\n",
      "resetting env. episode 3287, reward total was -19.0. running mean: -19.914210634433942, timestamp: 2022-08-19 22:27:23.343830\n",
      "resetting env. episode 3288, reward total was -20.0. running mean: -19.915068528089602, timestamp: 2022-08-19 22:27:26.372283\n",
      "resetting env. episode 3289, reward total was -20.0. running mean: -19.915917842808707, timestamp: 2022-08-19 22:27:29.531804\n",
      "resetting env. episode 3290, reward total was -19.0. running mean: -19.90675866438062, timestamp: 2022-08-19 22:27:33.604822\n",
      "resetting env. episode 3291, reward total was -20.0. running mean: -19.907691077736814, timestamp: 2022-08-19 22:27:37.075006\n",
      "resetting env. episode 3292, reward total was -21.0. running mean: -19.918614166959447, timestamp: 2022-08-19 22:27:40.053594\n",
      "resetting env. episode 3293, reward total was -19.0. running mean: -19.909428025289852, timestamp: 2022-08-19 22:27:43.690031\n",
      "resetting env. episode 3294, reward total was -20.0. running mean: -19.910333745036954, timestamp: 2022-08-19 22:27:46.870528\n",
      "resetting env. episode 3295, reward total was -20.0. running mean: -19.911230407586583, timestamp: 2022-08-19 22:27:50.986427\n",
      "resetting env. episode 3296, reward total was -21.0. running mean: -19.92211810351072, timestamp: 2022-08-19 22:27:53.987406\n",
      "resetting env. episode 3297, reward total was -21.0. running mean: -19.932896922475614, timestamp: 2022-08-19 22:27:57.522953\n",
      "resetting env. episode 3298, reward total was -20.0. running mean: -19.933567953250858, timestamp: 2022-08-19 22:28:01.870286\n",
      "resetting env. episode 3299, reward total was -20.0. running mean: -19.934232273718347, timestamp: 2022-08-19 22:28:05.792674\n",
      "resetting env. episode 3300, reward total was -20.0. running mean: -19.934889950981162, timestamp: 2022-08-19 22:28:10.134525\n",
      "resetting env. episode 3301, reward total was -20.0. running mean: -19.93554105147135, timestamp: 2022-08-19 22:28:14.428615\n",
      "resetting env. episode 3302, reward total was -20.0. running mean: -19.936185640956637, timestamp: 2022-08-19 22:28:17.197178\n",
      "resetting env. episode 3303, reward total was -21.0. running mean: -19.94682378454707, timestamp: 2022-08-19 22:28:20.518302\n",
      "resetting env. episode 3304, reward total was -20.0. running mean: -19.947355546701598, timestamp: 2022-08-19 22:28:24.951232\n",
      "resetting env. episode 3305, reward total was -20.0. running mean: -19.94788199123458, timestamp: 2022-08-19 22:28:28.231410\n",
      "resetting env. episode 3306, reward total was -21.0. running mean: -19.958403171322235, timestamp: 2022-08-19 22:28:31.121998\n",
      "resetting env. episode 3307, reward total was -19.0. running mean: -19.948819139609014, timestamp: 2022-08-19 22:28:35.539193\n",
      "resetting env. episode 3308, reward total was -21.0. running mean: -19.959330948212926, timestamp: 2022-08-19 22:28:38.437995\n",
      "resetting env. episode 3309, reward total was -18.0. running mean: -19.939737638730797, timestamp: 2022-08-19 22:28:41.940927\n",
      "resetting env. episode 3310, reward total was -21.0. running mean: -19.95034026234349, timestamp: 2022-08-19 22:28:45.602100\n",
      "resetting env. episode 3311, reward total was -20.0. running mean: -19.950836859720056, timestamp: 2022-08-19 22:28:48.382669\n",
      "resetting env. episode 3312, reward total was -20.0. running mean: -19.951328491122855, timestamp: 2022-08-19 22:28:51.903260\n",
      "resetting env. episode 3313, reward total was -19.0. running mean: -19.941815206211626, timestamp: 2022-08-19 22:28:55.428594\n",
      "resetting env. episode 3314, reward total was -21.0. running mean: -19.95239705414951, timestamp: 2022-08-19 22:28:59.284272\n",
      "resetting env. episode 3315, reward total was -19.0. running mean: -19.942873083608017, timestamp: 2022-08-19 22:29:02.467763\n",
      "resetting env. episode 3316, reward total was -19.0. running mean: -19.93344435277194, timestamp: 2022-08-19 22:29:05.368837\n",
      "resetting env. episode 3317, reward total was -18.0. running mean: -19.91410990924422, timestamp: 2022-08-19 22:29:09.578785\n",
      "resetting env. episode 3318, reward total was -21.0. running mean: -19.92496881015178, timestamp: 2022-08-19 22:29:12.780105\n",
      "resetting env. episode 3319, reward total was -20.0. running mean: -19.92571912205026, timestamp: 2022-08-19 22:29:16.579147\n",
      "resetting env. episode 3320, reward total was -20.0. running mean: -19.926461930829756, timestamp: 2022-08-19 22:29:20.525148\n",
      "resetting env. episode 3321, reward total was -20.0. running mean: -19.927197311521457, timestamp: 2022-08-19 22:29:24.205935\n",
      "resetting env. episode 3322, reward total was -21.0. running mean: -19.93792533840624, timestamp: 2022-08-19 22:29:28.571911\n",
      "resetting env. episode 3323, reward total was -20.0. running mean: -19.93854608502218, timestamp: 2022-08-19 22:29:31.860481\n",
      "resetting env. episode 3324, reward total was -20.0. running mean: -19.939160624171954, timestamp: 2022-08-19 22:29:35.399754\n",
      "resetting env. episode 3325, reward total was -20.0. running mean: -19.939769017930235, timestamp: 2022-08-19 22:29:39.293346\n",
      "resetting env. episode 3326, reward total was -21.0. running mean: -19.950371327750933, timestamp: 2022-08-19 22:29:42.629708\n",
      "resetting env. episode 3327, reward total was -20.0. running mean: -19.950867614473424, timestamp: 2022-08-19 22:29:45.427230\n",
      "resetting env. episode 3328, reward total was -18.0. running mean: -19.93135893832869, timestamp: 2022-08-19 22:29:48.814090\n",
      "resetting env. episode 3329, reward total was -21.0. running mean: -19.942045348945403, timestamp: 2022-08-19 22:29:51.225627\n",
      "resetting env. episode 3330, reward total was -19.0. running mean: -19.932624895455948, timestamp: 2022-08-19 22:29:54.933696\n",
      "resetting env. episode 3331, reward total was -21.0. running mean: -19.94329864650139, timestamp: 2022-08-19 22:29:58.290948\n",
      "resetting env. episode 3332, reward total was -21.0. running mean: -19.953865660036378, timestamp: 2022-08-19 22:30:01.946959\n",
      "resetting env. episode 3333, reward total was -17.0. running mean: -19.924327003436016, timestamp: 2022-08-19 22:30:06.326888\n",
      "resetting env. episode 3334, reward total was -18.0. running mean: -19.905083733401653, timestamp: 2022-08-19 22:30:09.618422\n",
      "resetting env. episode 3335, reward total was -20.0. running mean: -19.906032896067636, timestamp: 2022-08-19 22:30:12.664280\n",
      "resetting env. episode 3336, reward total was -21.0. running mean: -19.91697256710696, timestamp: 2022-08-19 22:30:15.956479\n",
      "resetting env. episode 3337, reward total was -19.0. running mean: -19.907802841435892, timestamp: 2022-08-19 22:30:22.579473\n",
      "resetting env. episode 3338, reward total was -18.0. running mean: -19.888724813021533, timestamp: 2022-08-19 22:30:28.809792\n",
      "resetting env. episode 3339, reward total was -18.0. running mean: -19.869837564891316, timestamp: 2022-08-19 22:30:33.775729\n",
      "resetting env. episode 3340, reward total was -21.0. running mean: -19.881139189242404, timestamp: 2022-08-19 22:30:36.662674\n",
      "resetting env. episode 3341, reward total was -20.0. running mean: -19.88232779734998, timestamp: 2022-08-19 22:30:40.560075\n",
      "resetting env. episode 3342, reward total was -18.0. running mean: -19.86350451937648, timestamp: 2022-08-19 22:30:44.840381\n",
      "resetting env. episode 3343, reward total was -20.0. running mean: -19.864869474182715, timestamp: 2022-08-19 22:30:48.542382\n",
      "resetting env. episode 3344, reward total was -19.0. running mean: -19.85622077944089, timestamp: 2022-08-19 22:30:52.460977\n",
      "resetting env. episode 3345, reward total was -19.0. running mean: -19.84765857164648, timestamp: 2022-08-19 22:30:57.002834\n",
      "resetting env. episode 3346, reward total was -21.0. running mean: -19.859181985930018, timestamp: 2022-08-19 22:31:00.044444\n",
      "resetting env. episode 3347, reward total was -20.0. running mean: -19.86059016607072, timestamp: 2022-08-19 22:31:03.314985\n",
      "resetting env. episode 3348, reward total was -21.0. running mean: -19.871984264410013, timestamp: 2022-08-19 22:31:05.887112\n",
      "resetting env. episode 3349, reward total was -21.0. running mean: -19.883264421765915, timestamp: 2022-08-19 22:31:09.114006\n",
      "resetting env. episode 3350, reward total was -19.0. running mean: -19.874431777548256, timestamp: 2022-08-19 22:31:13.267273\n",
      "resetting env. episode 3351, reward total was -18.0. running mean: -19.855687459772774, timestamp: 2022-08-19 22:31:17.355217\n",
      "resetting env. episode 3352, reward total was -16.0. running mean: -19.817130585175047, timestamp: 2022-08-19 22:31:21.381429\n",
      "resetting env. episode 3353, reward total was -21.0. running mean: -19.828959279323296, timestamp: 2022-08-19 22:31:24.417150\n",
      "resetting env. episode 3354, reward total was -21.0. running mean: -19.840669686530063, timestamp: 2022-08-19 22:31:27.599398\n",
      "resetting env. episode 3355, reward total was -20.0. running mean: -19.84226298966476, timestamp: 2022-08-19 22:31:30.962607\n",
      "resetting env. episode 3356, reward total was -18.0. running mean: -19.823840359768113, timestamp: 2022-08-19 22:31:35.266562\n",
      "resetting env. episode 3357, reward total was -18.0. running mean: -19.80560195617043, timestamp: 2022-08-19 22:31:39.227039\n",
      "resetting env. episode 3358, reward total was -18.0. running mean: -19.787545936608726, timestamp: 2022-08-19 22:31:43.277257\n",
      "resetting env. episode 3359, reward total was -17.0. running mean: -19.75967047724264, timestamp: 2022-08-19 22:31:47.206449\n",
      "resetting env. episode 3360, reward total was -21.0. running mean: -19.772073772470215, timestamp: 2022-08-19 22:31:51.466596\n",
      "resetting env. episode 3361, reward total was -21.0. running mean: -19.784353034745514, timestamp: 2022-08-19 22:31:54.413842\n",
      "resetting env. episode 3362, reward total was -21.0. running mean: -19.79650950439806, timestamp: 2022-08-19 22:31:58.001255\n",
      "resetting env. episode 3363, reward total was -20.0. running mean: -19.79854440935408, timestamp: 2022-08-19 22:32:01.919778\n",
      "resetting env. episode 3364, reward total was -21.0. running mean: -19.81055896526054, timestamp: 2022-08-19 22:32:05.974940\n",
      "resetting env. episode 3365, reward total was -21.0. running mean: -19.822453375607935, timestamp: 2022-08-19 22:32:09.758826\n",
      "resetting env. episode 3366, reward total was -21.0. running mean: -19.834228841851857, timestamp: 2022-08-19 22:32:13.200626\n",
      "resetting env. episode 3367, reward total was -21.0. running mean: -19.84588655343334, timestamp: 2022-08-19 22:32:17.136107\n",
      "resetting env. episode 3368, reward total was -21.0. running mean: -19.857427687899005, timestamp: 2022-08-19 22:32:20.846190\n",
      "resetting env. episode 3369, reward total was -21.0. running mean: -19.868853411020016, timestamp: 2022-08-19 22:32:24.365780\n",
      "resetting env. episode 3370, reward total was -20.0. running mean: -19.870164876909815, timestamp: 2022-08-19 22:32:28.856406\n",
      "resetting env. episode 3371, reward total was -21.0. running mean: -19.881463228140717, timestamp: 2022-08-19 22:32:32.401614\n",
      "resetting env. episode 3372, reward total was -19.0. running mean: -19.87264859585931, timestamp: 2022-08-19 22:32:35.397766\n",
      "resetting env. episode 3373, reward total was -21.0. running mean: -19.883922109900716, timestamp: 2022-08-19 22:32:38.951395\n",
      "resetting env. episode 3374, reward total was -20.0. running mean: -19.88508288880171, timestamp: 2022-08-19 22:32:42.956662\n",
      "resetting env. episode 3375, reward total was -21.0. running mean: -19.896232059913693, timestamp: 2022-08-19 22:32:45.542854\n",
      "resetting env. episode 3376, reward total was -21.0. running mean: -19.907269739314557, timestamp: 2022-08-19 22:32:49.226551\n",
      "resetting env. episode 3377, reward total was -20.0. running mean: -19.90819704192141, timestamp: 2022-08-19 22:32:52.555650\n",
      "resetting env. episode 3378, reward total was -19.0. running mean: -19.899115071502198, timestamp: 2022-08-19 22:32:55.630363\n",
      "resetting env. episode 3379, reward total was -19.0. running mean: -19.89012392078718, timestamp: 2022-08-19 22:32:58.807898\n",
      "resetting env. episode 3380, reward total was -19.0. running mean: -19.88122268157931, timestamp: 2022-08-19 22:33:03.249746\n",
      "resetting env. episode 3381, reward total was -21.0. running mean: -19.892410454763517, timestamp: 2022-08-19 22:33:06.410684\n",
      "resetting env. episode 3382, reward total was -21.0. running mean: -19.903486350215882, timestamp: 2022-08-19 22:33:09.045498\n",
      "resetting env. episode 3383, reward total was -19.0. running mean: -19.894451486713724, timestamp: 2022-08-19 22:33:12.538710\n",
      "resetting env. episode 3384, reward total was -19.0. running mean: -19.88550697184659, timestamp: 2022-08-19 22:33:17.511084\n",
      "resetting env. episode 3385, reward total was -19.0. running mean: -19.876651902128124, timestamp: 2022-08-19 22:33:21.101736\n",
      "resetting env. episode 3386, reward total was -21.0. running mean: -19.887885383106845, timestamp: 2022-08-19 22:33:23.503312\n",
      "resetting env. episode 3387, reward total was -16.0. running mean: -19.849006529275776, timestamp: 2022-08-19 22:33:28.376102\n",
      "resetting env. episode 3388, reward total was -19.0. running mean: -19.84051646398302, timestamp: 2022-08-19 22:33:33.453902\n",
      "resetting env. episode 3389, reward total was -21.0. running mean: -19.85211129934319, timestamp: 2022-08-19 22:33:37.059278\n",
      "resetting env. episode 3390, reward total was -21.0. running mean: -19.863590186349757, timestamp: 2022-08-19 22:33:40.270694\n",
      "resetting env. episode 3391, reward total was -21.0. running mean: -19.87495428448626, timestamp: 2022-08-19 22:33:43.711721\n",
      "resetting env. episode 3392, reward total was -21.0. running mean: -19.8862047416414, timestamp: 2022-08-19 22:33:47.075444\n",
      "resetting env. episode 3393, reward total was -21.0. running mean: -19.897342694224985, timestamp: 2022-08-19 22:33:50.971027\n",
      "resetting env. episode 3394, reward total was -19.0. running mean: -19.888369267282737, timestamp: 2022-08-19 22:33:54.726643\n",
      "resetting env. episode 3395, reward total was -21.0. running mean: -19.899485574609912, timestamp: 2022-08-19 22:33:59.293735\n",
      "resetting env. episode 3396, reward total was -20.0. running mean: -19.90049071886381, timestamp: 2022-08-19 22:34:03.498287\n",
      "resetting env. episode 3397, reward total was -19.0. running mean: -19.891485811675174, timestamp: 2022-08-19 22:34:08.409720\n",
      "resetting env. episode 3398, reward total was -18.0. running mean: -19.872570953558423, timestamp: 2022-08-19 22:34:14.206205\n",
      "resetting env. episode 3399, reward total was -21.0. running mean: -19.88384524402284, timestamp: 2022-08-19 22:34:17.579189\n",
      "resetting env. episode 3400, reward total was -20.0. running mean: -19.88500679158261, timestamp: 2022-08-19 22:34:22.287605\n",
      "resetting env. episode 3401, reward total was -20.0. running mean: -19.886156723666783, timestamp: 2022-08-19 22:34:26.457075\n",
      "resetting env. episode 3402, reward total was -21.0. running mean: -19.897295156430115, timestamp: 2022-08-19 22:34:31.152539\n",
      "resetting env. episode 3403, reward total was -21.0. running mean: -19.908322204865815, timestamp: 2022-08-19 22:34:36.454919\n",
      "resetting env. episode 3404, reward total was -20.0. running mean: -19.909238982817158, timestamp: 2022-08-19 22:34:42.059924\n",
      "resetting env. episode 3405, reward total was -20.0. running mean: -19.910146592988987, timestamp: 2022-08-19 22:34:47.473455\n",
      "resetting env. episode 3406, reward total was -21.0. running mean: -19.9210451270591, timestamp: 2022-08-19 22:34:52.617909\n",
      "resetting env. episode 3407, reward total was -20.0. running mean: -19.921834675788507, timestamp: 2022-08-19 22:34:56.711971\n",
      "resetting env. episode 3408, reward total was -21.0. running mean: -19.932616329030623, timestamp: 2022-08-19 22:35:03.238522\n",
      "resetting env. episode 3409, reward total was -20.0. running mean: -19.933290165740317, timestamp: 2022-08-19 22:35:07.541018\n",
      "resetting env. episode 3410, reward total was -21.0. running mean: -19.943957264082915, timestamp: 2022-08-19 22:35:11.533346\n",
      "resetting env. episode 3411, reward total was -20.0. running mean: -19.944517691442083, timestamp: 2022-08-19 22:35:15.266366\n",
      "resetting env. episode 3412, reward total was -21.0. running mean: -19.955072514527664, timestamp: 2022-08-19 22:35:20.251426\n",
      "resetting env. episode 3413, reward total was -20.0. running mean: -19.955521789382388, timestamp: 2022-08-19 22:35:24.945891\n",
      "resetting env. episode 3414, reward total was -18.0. running mean: -19.935966571488564, timestamp: 2022-08-19 22:35:30.463132\n",
      "resetting env. episode 3415, reward total was -21.0. running mean: -19.946606905773677, timestamp: 2022-08-19 22:35:35.250344\n",
      "resetting env. episode 3416, reward total was -20.0. running mean: -19.94714083671594, timestamp: 2022-08-19 22:35:40.301833\n",
      "resetting env. episode 3417, reward total was -19.0. running mean: -19.93766942834878, timestamp: 2022-08-19 22:35:45.705388\n",
      "resetting env. episode 3418, reward total was -18.0. running mean: -19.918292734065293, timestamp: 2022-08-19 22:35:49.553101\n",
      "resetting env. episode 3419, reward total was -19.0. running mean: -19.90910980672464, timestamp: 2022-08-19 22:35:52.672013\n",
      "resetting env. episode 3420, reward total was -20.0. running mean: -19.910018708657393, timestamp: 2022-08-19 22:35:55.940263\n",
      "resetting env. episode 3421, reward total was -18.0. running mean: -19.890918521570818, timestamp: 2022-08-19 22:36:00.562073\n",
      "resetting env. episode 3422, reward total was -20.0. running mean: -19.89200933635511, timestamp: 2022-08-19 22:36:04.499574\n",
      "resetting env. episode 3423, reward total was -19.0. running mean: -19.88308924299156, timestamp: 2022-08-19 22:36:08.412111\n",
      "resetting env. episode 3424, reward total was -20.0. running mean: -19.884258350561645, timestamp: 2022-08-19 22:36:13.027495\n",
      "resetting env. episode 3425, reward total was -20.0. running mean: -19.885415767056028, timestamp: 2022-08-19 22:36:16.641514\n",
      "resetting env. episode 3426, reward total was -20.0. running mean: -19.886561609385467, timestamp: 2022-08-19 22:36:20.881559\n",
      "resetting env. episode 3427, reward total was -19.0. running mean: -19.877695993291614, timestamp: 2022-08-19 22:36:24.834074\n",
      "resetting env. episode 3428, reward total was -19.0. running mean: -19.868919033358697, timestamp: 2022-08-19 22:36:28.546004\n",
      "resetting env. episode 3429, reward total was -20.0. running mean: -19.870229843025108, timestamp: 2022-08-19 22:36:33.252425\n",
      "resetting env. episode 3430, reward total was -21.0. running mean: -19.881527544594856, timestamp: 2022-08-19 22:36:36.651312\n",
      "resetting env. episode 3431, reward total was -20.0. running mean: -19.882712269148907, timestamp: 2022-08-19 22:36:40.964025\n",
      "resetting env. episode 3432, reward total was -20.0. running mean: -19.883885146457416, timestamp: 2022-08-19 22:36:45.194298\n",
      "resetting env. episode 3433, reward total was -20.0. running mean: -19.88504629499284, timestamp: 2022-08-19 22:36:49.292869\n",
      "resetting env. episode 3434, reward total was -21.0. running mean: -19.896195832042913, timestamp: 2022-08-19 22:36:52.057141\n",
      "resetting env. episode 3435, reward total was -20.0. running mean: -19.897233873722485, timestamp: 2022-08-19 22:36:55.313453\n",
      "resetting env. episode 3436, reward total was -20.0. running mean: -19.89826153498526, timestamp: 2022-08-19 22:36:58.595689\n",
      "resetting env. episode 3437, reward total was -21.0. running mean: -19.90927891963541, timestamp: 2022-08-19 22:37:02.001032\n",
      "resetting env. episode 3438, reward total was -18.0. running mean: -19.890186130439055, timestamp: 2022-08-19 22:37:05.966424\n",
      "resetting env. episode 3439, reward total was -19.0. running mean: -19.881284269134664, timestamp: 2022-08-19 22:37:10.352415\n",
      "resetting env. episode 3440, reward total was -20.0. running mean: -19.882471426443317, timestamp: 2022-08-19 22:37:13.872003\n",
      "resetting env. episode 3441, reward total was -19.0. running mean: -19.873646712178886, timestamp: 2022-08-19 22:37:17.896477\n",
      "resetting env. episode 3442, reward total was -21.0. running mean: -19.884910245057096, timestamp: 2022-08-19 22:37:21.962749\n",
      "resetting env. episode 3443, reward total was -20.0. running mean: -19.886061142606525, timestamp: 2022-08-19 22:37:25.646073\n",
      "resetting env. episode 3444, reward total was -21.0. running mean: -19.89720053118046, timestamp: 2022-08-19 22:37:28.954239\n",
      "resetting env. episode 3445, reward total was -21.0. running mean: -19.908228525868655, timestamp: 2022-08-19 22:37:32.413015\n",
      "resetting env. episode 3446, reward total was -19.0. running mean: -19.89914624060997, timestamp: 2022-08-19 22:37:37.276692\n",
      "resetting env. episode 3447, reward total was -21.0. running mean: -19.91015477820387, timestamp: 2022-08-19 22:37:40.962545\n",
      "resetting env. episode 3448, reward total was -21.0. running mean: -19.921053230421833, timestamp: 2022-08-19 22:37:44.533864\n",
      "resetting env. episode 3449, reward total was -19.0. running mean: -19.911842698117617, timestamp: 2022-08-19 22:37:48.715130\n",
      "resetting env. episode 3450, reward total was -19.0. running mean: -19.902724271136442, timestamp: 2022-08-19 22:37:51.792249\n",
      "resetting env. episode 3451, reward total was -21.0. running mean: -19.91369702842508, timestamp: 2022-08-19 22:37:55.562302\n",
      "resetting env. episode 3452, reward total was -20.0. running mean: -19.91456005814083, timestamp: 2022-08-19 22:37:59.767038\n",
      "resetting env. episode 3453, reward total was -21.0. running mean: -19.92541445755942, timestamp: 2022-08-19 22:38:03.318330\n",
      "resetting env. episode 3454, reward total was -21.0. running mean: -19.936160312983827, timestamp: 2022-08-19 22:38:06.860338\n",
      "resetting env. episode 3455, reward total was -21.0. running mean: -19.94679870985399, timestamp: 2022-08-19 22:38:10.014905\n",
      "resetting env. episode 3456, reward total was -21.0. running mean: -19.95733072275545, timestamp: 2022-08-19 22:38:12.610967\n",
      "resetting env. episode 3457, reward total was -19.0. running mean: -19.947757415527896, timestamp: 2022-08-19 22:38:16.831681\n",
      "resetting env. episode 3458, reward total was -19.0. running mean: -19.93827984137262, timestamp: 2022-08-19 22:38:20.378811\n",
      "resetting env. episode 3459, reward total was -18.0. running mean: -19.918897042958893, timestamp: 2022-08-19 22:38:23.919348\n",
      "resetting env. episode 3460, reward total was -19.0. running mean: -19.909708072529305, timestamp: 2022-08-19 22:38:28.572039\n",
      "resetting env. episode 3461, reward total was -20.0. running mean: -19.91061099180401, timestamp: 2022-08-19 22:38:33.073011\n",
      "resetting env. episode 3462, reward total was -21.0. running mean: -19.92150488188597, timestamp: 2022-08-19 22:38:35.897858\n",
      "resetting env. episode 3463, reward total was -20.0. running mean: -19.922289833067108, timestamp: 2022-08-19 22:38:38.744996\n",
      "resetting env. episode 3464, reward total was -19.0. running mean: -19.913066934736438, timestamp: 2022-08-19 22:38:43.988364\n",
      "resetting env. episode 3465, reward total was -18.0. running mean: -19.893936265389073, timestamp: 2022-08-19 22:38:49.290182\n",
      "resetting env. episode 3466, reward total was -19.0. running mean: -19.884996902735182, timestamp: 2022-08-19 22:38:54.297308\n",
      "resetting env. episode 3467, reward total was -21.0. running mean: -19.89614693370783, timestamp: 2022-08-19 22:38:57.783953\n",
      "resetting env. episode 3468, reward total was -20.0. running mean: -19.89718546437075, timestamp: 2022-08-19 22:39:02.795625\n",
      "resetting env. episode 3469, reward total was -20.0. running mean: -19.89821360972704, timestamp: 2022-08-19 22:39:07.790276\n",
      "resetting env. episode 3470, reward total was -20.0. running mean: -19.89923147362977, timestamp: 2022-08-19 22:39:11.933210\n",
      "resetting env. episode 3471, reward total was -20.0. running mean: -19.90023915889347, timestamp: 2022-08-19 22:39:17.258968\n",
      "resetting env. episode 3472, reward total was -17.0. running mean: -19.871236767304538, timestamp: 2022-08-19 22:39:22.083068\n",
      "resetting env. episode 3473, reward total was -21.0. running mean: -19.882524399631492, timestamp: 2022-08-19 22:39:26.978983\n",
      "resetting env. episode 3474, reward total was -20.0. running mean: -19.883699155635178, timestamp: 2022-08-19 22:39:31.376234\n",
      "resetting env. episode 3475, reward total was -19.0. running mean: -19.874862164078827, timestamp: 2022-08-19 22:39:35.845284\n",
      "resetting env. episode 3476, reward total was -20.0. running mean: -19.876113542438038, timestamp: 2022-08-19 22:39:39.373872\n",
      "resetting env. episode 3477, reward total was -21.0. running mean: -19.88735240701366, timestamp: 2022-08-19 22:39:42.942313\n",
      "resetting env. episode 3478, reward total was -20.0. running mean: -19.88847888294352, timestamp: 2022-08-19 22:39:47.783388\n",
      "resetting env. episode 3479, reward total was -20.0. running mean: -19.889594094114084, timestamp: 2022-08-19 22:39:52.385074\n",
      "resetting env. episode 3480, reward total was -21.0. running mean: -19.900698153172943, timestamp: 2022-08-19 22:39:56.806081\n",
      "resetting env. episode 3481, reward total was -20.0. running mean: -19.90169117164121, timestamp: 2022-08-19 22:40:01.581323\n",
      "resetting env. episode 3482, reward total was -21.0. running mean: -19.9126742599248, timestamp: 2022-08-19 22:40:06.944089\n",
      "resetting env. episode 3483, reward total was -20.0. running mean: -19.91354751732555, timestamp: 2022-08-19 22:40:11.067098\n",
      "resetting env. episode 3484, reward total was -21.0. running mean: -19.924412042152294, timestamp: 2022-08-19 22:40:15.464316\n",
      "resetting env. episode 3485, reward total was -20.0. running mean: -19.925167921730772, timestamp: 2022-08-19 22:40:20.185707\n",
      "resetting env. episode 3486, reward total was -21.0. running mean: -19.935916242513464, timestamp: 2022-08-19 22:40:25.142915\n",
      "resetting env. episode 3487, reward total was -20.0. running mean: -19.936557080088328, timestamp: 2022-08-19 22:40:29.297800\n",
      "resetting env. episode 3488, reward total was -18.0. running mean: -19.917191509287445, timestamp: 2022-08-19 22:40:34.009230\n",
      "resetting env. episode 3489, reward total was -21.0. running mean: -19.92801959419457, timestamp: 2022-08-19 22:40:38.035446\n",
      "resetting env. episode 3490, reward total was -20.0. running mean: -19.928739398252624, timestamp: 2022-08-19 22:40:43.040075\n",
      "resetting env. episode 3491, reward total was -20.0. running mean: -19.929452004270097, timestamp: 2022-08-19 22:40:48.708155\n",
      "resetting env. episode 3492, reward total was -19.0. running mean: -19.920157484227396, timestamp: 2022-08-19 22:40:53.640988\n",
      "resetting env. episode 3493, reward total was -21.0. running mean: -19.930955909385123, timestamp: 2022-08-19 22:40:57.962416\n",
      "resetting env. episode 3494, reward total was -20.0. running mean: -19.93164635029127, timestamp: 2022-08-19 22:41:02.113453\n",
      "resetting env. episode 3495, reward total was -20.0. running mean: -19.932329886788356, timestamp: 2022-08-19 22:41:07.713852\n",
      "resetting env. episode 3496, reward total was -20.0. running mean: -19.93300658792047, timestamp: 2022-08-19 22:41:11.557576\n",
      "resetting env. episode 3497, reward total was -21.0. running mean: -19.943676522041265, timestamp: 2022-08-19 22:41:15.618434\n",
      "resetting env. episode 3498, reward total was -21.0. running mean: -19.954239756820854, timestamp: 2022-08-19 22:41:19.024330\n",
      "resetting env. episode 3499, reward total was -20.0. running mean: -19.954697359252645, timestamp: 2022-08-19 22:41:22.766331\n",
      "resetting env. episode 3500, reward total was -17.0. running mean: -19.92515038566012, timestamp: 2022-08-19 22:41:28.329316\n",
      "resetting env. episode 3501, reward total was -19.0. running mean: -19.91589888180352, timestamp: 2022-08-19 22:41:31.774918\n",
      "resetting env. episode 3502, reward total was -21.0. running mean: -19.926739892985488, timestamp: 2022-08-19 22:41:34.782864\n",
      "resetting env. episode 3503, reward total was -20.0. running mean: -19.927472494055632, timestamp: 2022-08-19 22:41:38.894435\n",
      "resetting env. episode 3504, reward total was -21.0. running mean: -19.938197769115074, timestamp: 2022-08-19 22:41:42.726192\n",
      "resetting env. episode 3505, reward total was -21.0. running mean: -19.948815791423925, timestamp: 2022-08-19 22:41:46.920980\n",
      "resetting env. episode 3506, reward total was -20.0. running mean: -19.949327633509686, timestamp: 2022-08-19 22:41:52.093171\n",
      "resetting env. episode 3507, reward total was -19.0. running mean: -19.93983435717459, timestamp: 2022-08-19 22:41:57.296278\n",
      "resetting env. episode 3508, reward total was -19.0. running mean: -19.930436013602844, timestamp: 2022-08-19 22:42:02.912245\n",
      "resetting env. episode 3509, reward total was -21.0. running mean: -19.941131653466815, timestamp: 2022-08-19 22:42:08.266942\n",
      "resetting env. episode 3510, reward total was -21.0. running mean: -19.951720336932148, timestamp: 2022-08-19 22:42:13.988086\n",
      "resetting env. episode 3511, reward total was -18.0. running mean: -19.932203133562826, timestamp: 2022-08-19 22:42:19.640849\n",
      "resetting env. episode 3512, reward total was -19.0. running mean: -19.922881102227198, timestamp: 2022-08-19 22:42:24.305761\n",
      "resetting env. episode 3513, reward total was -20.0. running mean: -19.923652291204924, timestamp: 2022-08-19 22:42:28.583356\n",
      "resetting env. episode 3514, reward total was -19.0. running mean: -19.914415768292876, timestamp: 2022-08-19 22:42:33.252342\n",
      "resetting env. episode 3515, reward total was -21.0. running mean: -19.925271610609947, timestamp: 2022-08-19 22:42:36.306179\n",
      "resetting env. episode 3516, reward total was -20.0. running mean: -19.926018894503848, timestamp: 2022-08-19 22:42:39.630298\n",
      "resetting env. episode 3517, reward total was -21.0. running mean: -19.93675870555881, timestamp: 2022-08-19 22:42:42.855747\n",
      "resetting env. episode 3518, reward total was -19.0. running mean: -19.927391118503223, timestamp: 2022-08-19 22:42:46.403808\n",
      "resetting env. episode 3519, reward total was -19.0. running mean: -19.918117207318193, timestamp: 2022-08-19 22:42:50.105180\n",
      "resetting env. episode 3520, reward total was -19.0. running mean: -19.908936035245013, timestamp: 2022-08-19 22:42:54.251311\n",
      "resetting env. episode 3521, reward total was -20.0. running mean: -19.909846674892563, timestamp: 2022-08-19 22:42:57.545193\n",
      "resetting env. episode 3522, reward total was -19.0. running mean: -19.90074820814364, timestamp: 2022-08-19 22:43:01.034864\n",
      "resetting env. episode 3523, reward total was -21.0. running mean: -19.911740726062202, timestamp: 2022-08-19 22:43:04.142843\n",
      "resetting env. episode 3524, reward total was -15.0. running mean: -19.862623318801578, timestamp: 2022-08-19 22:43:09.471898\n",
      "resetting env. episode 3525, reward total was -18.0. running mean: -19.843997085613562, timestamp: 2022-08-19 22:43:13.479937\n",
      "resetting env. episode 3526, reward total was -20.0. running mean: -19.845557114757426, timestamp: 2022-08-19 22:43:17.692057\n",
      "resetting env. episode 3527, reward total was -19.0. running mean: -19.837101543609855, timestamp: 2022-08-19 22:43:21.236943\n",
      "resetting env. episode 3528, reward total was -20.0. running mean: -19.838730528173755, timestamp: 2022-08-19 22:43:25.212607\n",
      "resetting env. episode 3529, reward total was -19.0. running mean: -19.83034322289202, timestamp: 2022-08-19 22:43:29.057602\n",
      "resetting env. episode 3530, reward total was -18.0. running mean: -19.812039790663096, timestamp: 2022-08-19 22:43:33.659607\n",
      "resetting env. episode 3531, reward total was -21.0. running mean: -19.823919392756466, timestamp: 2022-08-19 22:43:37.604405\n",
      "resetting env. episode 3532, reward total was -18.0. running mean: -19.8056801988289, timestamp: 2022-08-19 22:43:41.985411\n",
      "resetting env. episode 3533, reward total was -20.0. running mean: -19.807623396840608, timestamp: 2022-08-19 22:43:45.084266\n",
      "resetting env. episode 3534, reward total was -19.0. running mean: -19.7995471628722, timestamp: 2022-08-19 22:43:50.357864\n",
      "resetting env. episode 3535, reward total was -19.0. running mean: -19.79155169124348, timestamp: 2022-08-19 22:43:54.699067\n",
      "resetting env. episode 3536, reward total was -21.0. running mean: -19.803636174331047, timestamp: 2022-08-19 22:43:57.613139\n",
      "resetting env. episode 3537, reward total was -21.0. running mean: -19.815599812587738, timestamp: 2022-08-19 22:44:01.623455\n",
      "resetting env. episode 3538, reward total was -19.0. running mean: -19.807443814461863, timestamp: 2022-08-19 22:44:06.077929\n",
      "resetting env. episode 3539, reward total was -21.0. running mean: -19.819369376317244, timestamp: 2022-08-19 22:44:09.986613\n",
      "resetting env. episode 3540, reward total was -21.0. running mean: -19.831175682554072, timestamp: 2022-08-19 22:44:13.378639\n",
      "resetting env. episode 3541, reward total was -18.0. running mean: -19.812863925728532, timestamp: 2022-08-19 22:44:17.993282\n",
      "resetting env. episode 3542, reward total was -20.0. running mean: -19.814735286471247, timestamp: 2022-08-19 22:44:21.789432\n",
      "resetting env. episode 3543, reward total was -21.0. running mean: -19.826587933606536, timestamp: 2022-08-19 22:44:25.779337\n",
      "resetting env. episode 3544, reward total was -21.0. running mean: -19.83832205427047, timestamp: 2022-08-19 22:44:30.013727\n",
      "resetting env. episode 3545, reward total was -19.0. running mean: -19.829938833727766, timestamp: 2022-08-19 22:44:34.093967\n",
      "resetting env. episode 3546, reward total was -19.0. running mean: -19.82163944539049, timestamp: 2022-08-19 22:44:38.440131\n",
      "resetting env. episode 3547, reward total was -20.0. running mean: -19.823423050936583, timestamp: 2022-08-19 22:44:41.416176\n",
      "resetting env. episode 3548, reward total was -19.0. running mean: -19.815188820427217, timestamp: 2022-08-19 22:44:45.919963\n",
      "resetting env. episode 3549, reward total was -19.0. running mean: -19.807036932222946, timestamp: 2022-08-19 22:44:50.186281\n",
      "resetting env. episode 3550, reward total was -20.0. running mean: -19.808966562900714, timestamp: 2022-08-19 22:44:54.085892\n",
      "resetting env. episode 3551, reward total was -20.0. running mean: -19.810876897271708, timestamp: 2022-08-19 22:44:57.919511\n",
      "resetting env. episode 3552, reward total was -20.0. running mean: -19.81276812829899, timestamp: 2022-08-19 22:45:02.194087\n",
      "resetting env. episode 3553, reward total was -18.0. running mean: -19.794640447016, timestamp: 2022-08-19 22:45:05.605507\n",
      "resetting env. episode 3554, reward total was -21.0. running mean: -19.806694042545843, timestamp: 2022-08-19 22:45:08.738104\n",
      "resetting env. episode 3555, reward total was -20.0. running mean: -19.808627102120383, timestamp: 2022-08-19 22:45:13.199174\n",
      "resetting env. episode 3556, reward total was -18.0. running mean: -19.79054083109918, timestamp: 2022-08-19 22:45:17.794904\n",
      "resetting env. episode 3557, reward total was -20.0. running mean: -19.792635422788187, timestamp: 2022-08-19 22:45:22.083184\n",
      "resetting env. episode 3558, reward total was -21.0. running mean: -19.804709068560307, timestamp: 2022-08-19 22:45:26.329458\n",
      "resetting env. episode 3559, reward total was -21.0. running mean: -19.816661977874706, timestamp: 2022-08-19 22:45:29.283910\n",
      "resetting env. episode 3560, reward total was -21.0. running mean: -19.82849535809596, timestamp: 2022-08-19 22:45:32.867431\n",
      "resetting env. episode 3561, reward total was -20.0. running mean: -19.830210404515, timestamp: 2022-08-19 22:45:37.315027\n",
      "resetting env. episode 3562, reward total was -20.0. running mean: -19.83190830046985, timestamp: 2022-08-19 22:45:41.444643\n",
      "resetting env. episode 3563, reward total was -19.0. running mean: -19.823589217465152, timestamp: 2022-08-19 22:45:45.482845\n",
      "resetting env. episode 3564, reward total was -19.0. running mean: -19.815353325290502, timestamp: 2022-08-19 22:45:49.293297\n",
      "resetting env. episode 3565, reward total was -19.0. running mean: -19.807199792037597, timestamp: 2022-08-19 22:45:53.188155\n",
      "resetting env. episode 3566, reward total was -19.0. running mean: -19.799127794117222, timestamp: 2022-08-19 22:45:57.051164\n",
      "resetting env. episode 3567, reward total was -21.0. running mean: -19.81113651617605, timestamp: 2022-08-19 22:46:00.851176\n",
      "resetting env. episode 3568, reward total was -18.0. running mean: -19.793025151014287, timestamp: 2022-08-19 22:46:05.539675\n",
      "resetting env. episode 3569, reward total was -20.0. running mean: -19.795094899504143, timestamp: 2022-08-19 22:46:09.778136\n",
      "resetting env. episode 3570, reward total was -21.0. running mean: -19.8071439505091, timestamp: 2022-08-19 22:46:13.156101\n",
      "resetting env. episode 3571, reward total was -19.0. running mean: -19.79907251100401, timestamp: 2022-08-19 22:46:17.411620\n",
      "resetting env. episode 3572, reward total was -18.0. running mean: -19.78108178589397, timestamp: 2022-08-19 22:46:21.193512\n",
      "resetting env. episode 3573, reward total was -20.0. running mean: -19.78327096803503, timestamp: 2022-08-19 22:46:25.299914\n",
      "resetting env. episode 3574, reward total was -19.0. running mean: -19.77543825835468, timestamp: 2022-08-19 22:46:29.594837\n",
      "resetting env. episode 3575, reward total was -21.0. running mean: -19.787683875771133, timestamp: 2022-08-19 22:46:33.372317\n",
      "resetting env. episode 3576, reward total was -18.0. running mean: -19.769807037013422, timestamp: 2022-08-19 22:46:37.544044\n",
      "resetting env. episode 3577, reward total was -20.0. running mean: -19.772108966643287, timestamp: 2022-08-19 22:46:42.259882\n",
      "resetting env. episode 3578, reward total was -21.0. running mean: -19.784387876976854, timestamp: 2022-08-19 22:46:46.203341\n",
      "resetting env. episode 3579, reward total was -19.0. running mean: -19.77654399820709, timestamp: 2022-08-19 22:46:51.094341\n",
      "resetting env. episode 3580, reward total was -21.0. running mean: -19.78877855822502, timestamp: 2022-08-19 22:46:54.944388\n",
      "resetting env. episode 3581, reward total was -20.0. running mean: -19.79089077264277, timestamp: 2022-08-19 22:46:57.986259\n",
      "resetting env. episode 3582, reward total was -21.0. running mean: -19.80298186491634, timestamp: 2022-08-19 22:47:00.921411\n",
      "resetting env. episode 3583, reward total was -18.0. running mean: -19.784952046267176, timestamp: 2022-08-19 22:47:05.394503\n",
      "resetting env. episode 3584, reward total was -21.0. running mean: -19.797102525804505, timestamp: 2022-08-19 22:47:08.170085\n",
      "resetting env. episode 3585, reward total was -20.0. running mean: -19.79913150054646, timestamp: 2022-08-19 22:47:11.088281\n",
      "resetting env. episode 3586, reward total was -21.0. running mean: -19.811140185540996, timestamp: 2022-08-19 22:47:14.683699\n",
      "resetting env. episode 3587, reward total was -19.0. running mean: -19.803028783685587, timestamp: 2022-08-19 22:47:18.111763\n",
      "resetting env. episode 3588, reward total was -18.0. running mean: -19.78499849584873, timestamp: 2022-08-19 22:47:22.520917\n",
      "resetting env. episode 3589, reward total was -19.0. running mean: -19.777148510890243, timestamp: 2022-08-19 22:47:26.462299\n",
      "resetting env. episode 3590, reward total was -21.0. running mean: -19.78937702578134, timestamp: 2022-08-19 22:47:29.731181\n",
      "resetting env. episode 3591, reward total was -18.0. running mean: -19.771483255523528, timestamp: 2022-08-19 22:47:33.869540\n",
      "resetting env. episode 3592, reward total was -21.0. running mean: -19.783768422968294, timestamp: 2022-08-19 22:47:38.367314\n",
      "resetting env. episode 3593, reward total was -21.0. running mean: -19.795930738738612, timestamp: 2022-08-19 22:47:42.558565\n",
      "resetting env. episode 3594, reward total was -20.0. running mean: -19.797971431351225, timestamp: 2022-08-19 22:47:47.061585\n",
      "resetting env. episode 3595, reward total was -21.0. running mean: -19.809991717037715, timestamp: 2022-08-19 22:47:51.230198\n",
      "resetting env. episode 3596, reward total was -20.0. running mean: -19.811891799867336, timestamp: 2022-08-19 22:47:54.589508\n",
      "resetting env. episode 3597, reward total was -21.0. running mean: -19.823772881868663, timestamp: 2022-08-19 22:47:58.016967\n",
      "resetting env. episode 3598, reward total was -20.0. running mean: -19.825535153049977, timestamp: 2022-08-19 22:48:02.148635\n",
      "resetting env. episode 3599, reward total was -19.0. running mean: -19.81727980151948, timestamp: 2022-08-19 22:48:05.852476\n",
      "resetting env. episode 3600, reward total was -21.0. running mean: -19.829107003504284, timestamp: 2022-08-19 22:48:10.411344\n",
      "resetting env. episode 3601, reward total was -20.0. running mean: -19.83081593346924, timestamp: 2022-08-19 22:48:14.609920\n",
      "resetting env. episode 3602, reward total was -21.0. running mean: -19.842507774134546, timestamp: 2022-08-19 22:48:18.979240\n",
      "resetting env. episode 3603, reward total was -21.0. running mean: -19.854082696393203, timestamp: 2022-08-19 22:48:23.129211\n",
      "resetting env. episode 3604, reward total was -19.0. running mean: -19.845541869429272, timestamp: 2022-08-19 22:48:27.138118\n",
      "resetting env. episode 3605, reward total was -19.0. running mean: -19.83708645073498, timestamp: 2022-08-19 22:48:31.871221\n",
      "resetting env. episode 3606, reward total was -20.0. running mean: -19.83871558622763, timestamp: 2022-08-19 22:48:37.321322\n",
      "resetting env. episode 3607, reward total was -21.0. running mean: -19.85032843036535, timestamp: 2022-08-19 22:48:42.672215\n",
      "resetting env. episode 3608, reward total was -21.0. running mean: -19.861825146061697, timestamp: 2022-08-19 22:48:46.416384\n",
      "resetting env. episode 3609, reward total was -20.0. running mean: -19.86320689460108, timestamp: 2022-08-19 22:48:51.579220\n",
      "resetting env. episode 3610, reward total was -21.0. running mean: -19.87457482565507, timestamp: 2022-08-19 22:48:55.617712\n",
      "resetting env. episode 3611, reward total was -17.0. running mean: -19.84582907739852, timestamp: 2022-08-19 22:49:01.444560\n",
      "resetting env. episode 3612, reward total was -19.0. running mean: -19.837370786624536, timestamp: 2022-08-19 22:49:06.019055\n",
      "resetting env. episode 3613, reward total was -17.0. running mean: -19.808997078758292, timestamp: 2022-08-19 22:49:10.971000\n",
      "resetting env. episode 3614, reward total was -21.0. running mean: -19.82090710797071, timestamp: 2022-08-19 22:49:15.170697\n",
      "resetting env. episode 3615, reward total was -21.0. running mean: -19.832698036891006, timestamp: 2022-08-19 22:49:20.001656\n",
      "resetting env. episode 3616, reward total was -21.0. running mean: -19.844371056522096, timestamp: 2022-08-19 22:49:23.647899\n",
      "resetting env. episode 3617, reward total was -19.0. running mean: -19.835927345956875, timestamp: 2022-08-19 22:49:27.143847\n",
      "resetting env. episode 3618, reward total was -21.0. running mean: -19.847568072497307, timestamp: 2022-08-19 22:49:30.359220\n",
      "resetting env. episode 3619, reward total was -19.0. running mean: -19.839092391772336, timestamp: 2022-08-19 22:49:33.922692\n",
      "resetting env. episode 3620, reward total was -21.0. running mean: -19.850701467854613, timestamp: 2022-08-19 22:49:37.894077\n",
      "resetting env. episode 3621, reward total was -19.0. running mean: -19.842194453176067, timestamp: 2022-08-19 22:49:41.939051\n",
      "resetting env. episode 3622, reward total was -20.0. running mean: -19.843772508644307, timestamp: 2022-08-19 22:49:45.185344\n",
      "resetting env. episode 3623, reward total was -19.0. running mean: -19.835334783557865, timestamp: 2022-08-19 22:49:48.709603\n",
      "resetting env. episode 3624, reward total was -20.0. running mean: -19.836981435722286, timestamp: 2022-08-19 22:49:51.723546\n",
      "resetting env. episode 3625, reward total was -21.0. running mean: -19.848611621365063, timestamp: 2022-08-19 22:49:55.262882\n",
      "resetting env. episode 3626, reward total was -19.0. running mean: -19.840125505151413, timestamp: 2022-08-19 22:49:58.495510\n",
      "resetting env. episode 3627, reward total was -19.0. running mean: -19.8317242500999, timestamp: 2022-08-19 22:50:02.278068\n",
      "resetting env. episode 3628, reward total was -19.0. running mean: -19.823407007598902, timestamp: 2022-08-19 22:50:06.118807\n",
      "resetting env. episode 3629, reward total was -21.0. running mean: -19.835172937522913, timestamp: 2022-08-19 22:50:09.695288\n",
      "resetting env. episode 3630, reward total was -19.0. running mean: -19.826821208147685, timestamp: 2022-08-19 22:50:13.898118\n",
      "resetting env. episode 3631, reward total was -20.0. running mean: -19.828552996066207, timestamp: 2022-08-19 22:50:18.314133\n",
      "resetting env. episode 3632, reward total was -18.0. running mean: -19.810267466105547, timestamp: 2022-08-19 22:50:22.410188\n",
      "resetting env. episode 3633, reward total was -20.0. running mean: -19.81216479144449, timestamp: 2022-08-19 22:50:26.144795\n",
      "resetting env. episode 3634, reward total was -18.0. running mean: -19.794043143530047, timestamp: 2022-08-19 22:50:30.954930\n",
      "resetting env. episode 3635, reward total was -18.0. running mean: -19.776102712094747, timestamp: 2022-08-19 22:50:35.220450\n",
      "resetting env. episode 3636, reward total was -19.0. running mean: -19.7683416849738, timestamp: 2022-08-19 22:50:38.739041\n",
      "resetting env. episode 3637, reward total was -19.0. running mean: -19.760658268124065, timestamp: 2022-08-19 22:50:43.577869\n",
      "resetting env. episode 3638, reward total was -21.0. running mean: -19.773051685442823, timestamp: 2022-08-19 22:50:47.332983\n",
      "resetting env. episode 3639, reward total was -21.0. running mean: -19.785321168588396, timestamp: 2022-08-19 22:50:50.648193\n",
      "resetting env. episode 3640, reward total was -21.0. running mean: -19.797467956902512, timestamp: 2022-08-19 22:50:54.790053\n",
      "resetting env. episode 3641, reward total was -20.0. running mean: -19.799493277333486, timestamp: 2022-08-19 22:50:59.308774\n",
      "resetting env. episode 3642, reward total was -21.0. running mean: -19.811498344560153, timestamp: 2022-08-19 22:51:02.231961\n",
      "resetting env. episode 3643, reward total was -20.0. running mean: -19.81338336111455, timestamp: 2022-08-19 22:51:06.012203\n",
      "resetting env. episode 3644, reward total was -21.0. running mean: -19.825249527503406, timestamp: 2022-08-19 22:51:09.776983\n",
      "resetting env. episode 3645, reward total was -21.0. running mean: -19.83699703222837, timestamp: 2022-08-19 22:51:12.570516\n",
      "resetting env. episode 3646, reward total was -20.0. running mean: -19.838627061906088, timestamp: 2022-08-19 22:51:16.451172\n",
      "resetting env. episode 3647, reward total was -17.0. running mean: -19.81024079128703, timestamp: 2022-08-19 22:51:20.897667\n",
      "resetting env. episode 3648, reward total was -19.0. running mean: -19.80213838337416, timestamp: 2022-08-19 22:51:25.676887\n",
      "resetting env. episode 3649, reward total was -19.0. running mean: -19.79411699954042, timestamp: 2022-08-19 22:51:29.248342\n",
      "resetting env. episode 3650, reward total was -20.0. running mean: -19.796175829545017, timestamp: 2022-08-19 22:51:33.509949\n",
      "resetting env. episode 3651, reward total was -18.0. running mean: -19.778214071249568, timestamp: 2022-08-19 22:51:40.876378\n",
      "resetting env. episode 3652, reward total was -19.0. running mean: -19.770431930537075, timestamp: 2022-08-19 22:51:47.036909\n",
      "resetting env. episode 3653, reward total was -19.0. running mean: -19.762727611231707, timestamp: 2022-08-19 22:51:50.734027\n",
      "resetting env. episode 3654, reward total was -20.0. running mean: -19.76510033511939, timestamp: 2022-08-19 22:51:55.129279\n",
      "resetting env. episode 3655, reward total was -19.0. running mean: -19.757449331768196, timestamp: 2022-08-19 22:52:00.139889\n",
      "resetting env. episode 3656, reward total was -19.0. running mean: -19.749874838450516, timestamp: 2022-08-19 22:52:04.796443\n",
      "resetting env. episode 3657, reward total was -21.0. running mean: -19.762376090066013, timestamp: 2022-08-19 22:52:11.132508\n",
      "resetting env. episode 3658, reward total was -21.0. running mean: -19.774752329165352, timestamp: 2022-08-19 22:52:16.662857\n",
      "resetting env. episode 3659, reward total was -19.0. running mean: -19.7670048058737, timestamp: 2022-08-19 22:52:20.681117\n",
      "resetting env. episode 3660, reward total was -18.0. running mean: -19.749334757814964, timestamp: 2022-08-19 22:52:24.902828\n",
      "resetting env. episode 3661, reward total was -20.0. running mean: -19.751841410236814, timestamp: 2022-08-19 22:52:29.932384\n",
      "resetting env. episode 3662, reward total was -21.0. running mean: -19.764322996134446, timestamp: 2022-08-19 22:52:33.360221\n",
      "resetting env. episode 3663, reward total was -20.0. running mean: -19.7666797661731, timestamp: 2022-08-19 22:52:36.783072\n",
      "resetting env. episode 3664, reward total was -18.0. running mean: -19.74901296851137, timestamp: 2022-08-19 22:52:40.592888\n",
      "resetting env. episode 3665, reward total was -20.0. running mean: -19.751522838826254, timestamp: 2022-08-19 22:52:44.283229\n",
      "resetting env. episode 3666, reward total was -17.0. running mean: -19.724007610437994, timestamp: 2022-08-19 22:52:49.321108\n",
      "resetting env. episode 3667, reward total was -21.0. running mean: -19.736767534333616, timestamp: 2022-08-19 22:52:52.774876\n",
      "resetting env. episode 3668, reward total was -19.0. running mean: -19.72939985899028, timestamp: 2022-08-19 22:52:58.153537\n",
      "resetting env. episode 3669, reward total was -20.0. running mean: -19.732105860400377, timestamp: 2022-08-19 22:53:01.869025\n",
      "resetting env. episode 3670, reward total was -20.0. running mean: -19.734784801796373, timestamp: 2022-08-19 22:53:06.799847\n",
      "resetting env. episode 3671, reward total was -20.0. running mean: -19.73743695377841, timestamp: 2022-08-19 22:53:11.633897\n",
      "resetting env. episode 3672, reward total was -20.0. running mean: -19.740062584240626, timestamp: 2022-08-19 22:53:15.148686\n",
      "resetting env. episode 3673, reward total was -21.0. running mean: -19.75266195839822, timestamp: 2022-08-19 22:53:18.261368\n",
      "resetting env. episode 3674, reward total was -21.0. running mean: -19.76513533881424, timestamp: 2022-08-19 22:53:22.744383\n",
      "resetting env. episode 3675, reward total was -19.0. running mean: -19.7574839854261, timestamp: 2022-08-19 22:53:27.436870\n",
      "resetting env. episode 3676, reward total was -20.0. running mean: -19.759909145571836, timestamp: 2022-08-19 22:53:30.923523\n",
      "resetting env. episode 3677, reward total was -19.0. running mean: -19.75231005411612, timestamp: 2022-08-19 22:53:34.965717\n",
      "resetting env. episode 3678, reward total was -20.0. running mean: -19.754786953574957, timestamp: 2022-08-19 22:53:38.351667\n",
      "resetting env. episode 3679, reward total was -20.0. running mean: -19.757239084039206, timestamp: 2022-08-19 22:53:42.221343\n",
      "resetting env. episode 3680, reward total was -20.0. running mean: -19.759666693198813, timestamp: 2022-08-19 22:53:46.557728\n",
      "resetting env. episode 3681, reward total was -19.0. running mean: -19.752070026266825, timestamp: 2022-08-19 22:53:50.244060\n",
      "resetting env. episode 3682, reward total was -21.0. running mean: -19.764549326004158, timestamp: 2022-08-19 22:53:53.436132\n",
      "resetting env. episode 3683, reward total was -19.0. running mean: -19.75690383274412, timestamp: 2022-08-19 22:53:57.196069\n",
      "resetting env. episode 3684, reward total was -20.0. running mean: -19.759334794416677, timestamp: 2022-08-19 22:54:00.538402\n",
      "resetting env. episode 3685, reward total was -20.0. running mean: -19.76174144647251, timestamp: 2022-08-19 22:54:05.271437\n",
      "resetting env. episode 3686, reward total was -18.0. running mean: -19.744124032007782, timestamp: 2022-08-19 22:54:10.387735\n",
      "resetting env. episode 3687, reward total was -20.0. running mean: -19.746682791687704, timestamp: 2022-08-19 22:54:14.484776\n",
      "resetting env. episode 3688, reward total was -20.0. running mean: -19.749215963770826, timestamp: 2022-08-19 22:54:19.933227\n",
      "resetting env. episode 3689, reward total was -20.0. running mean: -19.751723804133118, timestamp: 2022-08-19 22:54:24.642630\n",
      "resetting env. episode 3690, reward total was -20.0. running mean: -19.754206566091785, timestamp: 2022-08-19 22:54:27.781312\n",
      "resetting env. episode 3691, reward total was -20.0. running mean: -19.756664500430865, timestamp: 2022-08-19 22:54:31.159793\n",
      "resetting env. episode 3692, reward total was -20.0. running mean: -19.759097855426557, timestamp: 2022-08-19 22:54:34.256507\n",
      "resetting env. episode 3693, reward total was -18.0. running mean: -19.74150687687229, timestamp: 2022-08-19 22:54:38.522072\n",
      "resetting env. episode 3694, reward total was -16.0. running mean: -19.704091808103566, timestamp: 2022-08-19 22:54:43.212948\n",
      "resetting env. episode 3695, reward total was -18.0. running mean: -19.68705089002253, timestamp: 2022-08-19 22:54:49.391598\n",
      "resetting env. episode 3696, reward total was -21.0. running mean: -19.700180381122305, timestamp: 2022-08-19 22:54:53.061463\n",
      "resetting env. episode 3697, reward total was -19.0. running mean: -19.693178577311084, timestamp: 2022-08-19 22:54:56.992736\n",
      "resetting env. episode 3698, reward total was -20.0. running mean: -19.696246791537973, timestamp: 2022-08-19 22:55:02.808665\n",
      "resetting env. episode 3699, reward total was -21.0. running mean: -19.709284323622594, timestamp: 2022-08-19 22:55:05.820000\n",
      "resetting env. episode 3700, reward total was -17.0. running mean: -19.68219148038637, timestamp: 2022-08-19 22:55:09.999936\n",
      "resetting env. episode 3701, reward total was -21.0. running mean: -19.695369565582507, timestamp: 2022-08-19 22:55:14.379061\n",
      "resetting env. episode 3702, reward total was -21.0. running mean: -19.708415869926682, timestamp: 2022-08-19 22:55:18.289600\n",
      "resetting env. episode 3703, reward total was -21.0. running mean: -19.721331711227418, timestamp: 2022-08-19 22:55:21.596758\n",
      "resetting env. episode 3704, reward total was -20.0. running mean: -19.72411839411514, timestamp: 2022-08-19 22:55:25.896290\n",
      "resetting env. episode 3705, reward total was -20.0. running mean: -19.72687721017399, timestamp: 2022-08-19 22:55:29.992710\n",
      "resetting env. episode 3706, reward total was -21.0. running mean: -19.73960843807225, timestamp: 2022-08-19 22:55:33.519274\n",
      "resetting env. episode 3707, reward total was -19.0. running mean: -19.732212353691526, timestamp: 2022-08-19 22:55:37.620318\n",
      "resetting env. episode 3708, reward total was -18.0. running mean: -19.714890230154612, timestamp: 2022-08-19 22:55:42.446388\n",
      "resetting env. episode 3709, reward total was -18.0. running mean: -19.697741327853066, timestamp: 2022-08-19 22:55:46.990249\n",
      "resetting env. episode 3710, reward total was -20.0. running mean: -19.700763914574534, timestamp: 2022-08-19 22:55:51.735556\n",
      "resetting env. episode 3711, reward total was -21.0. running mean: -19.71375627542879, timestamp: 2022-08-19 22:55:55.180348\n",
      "resetting env. episode 3712, reward total was -21.0. running mean: -19.7266187126745, timestamp: 2022-08-19 22:55:59.026357\n",
      "resetting env. episode 3713, reward total was -20.0. running mean: -19.729352525547753, timestamp: 2022-08-19 22:56:02.748806\n",
      "resetting env. episode 3714, reward total was -19.0. running mean: -19.722059000292276, timestamp: 2022-08-19 22:56:06.822765\n",
      "resetting env. episode 3715, reward total was -19.0. running mean: -19.714838410289353, timestamp: 2022-08-19 22:56:11.596712\n",
      "resetting env. episode 3716, reward total was -20.0. running mean: -19.71769002618646, timestamp: 2022-08-19 22:56:15.382951\n",
      "resetting env. episode 3717, reward total was -20.0. running mean: -19.720513125924594, timestamp: 2022-08-19 22:56:19.393809\n",
      "resetting env. episode 3718, reward total was -20.0. running mean: -19.723307994665348, timestamp: 2022-08-19 22:56:23.018114\n",
      "resetting env. episode 3719, reward total was -19.0. running mean: -19.716074914718696, timestamp: 2022-08-19 22:56:27.318404\n",
      "resetting env. episode 3720, reward total was -21.0. running mean: -19.72891416557151, timestamp: 2022-08-19 22:56:30.248570\n",
      "resetting env. episode 3721, reward total was -20.0. running mean: -19.731625023915793, timestamp: 2022-08-19 22:56:33.657490\n",
      "resetting env. episode 3722, reward total was -21.0. running mean: -19.744308773676636, timestamp: 2022-08-19 22:56:36.770869\n",
      "resetting env. episode 3723, reward total was -21.0. running mean: -19.75686568593987, timestamp: 2022-08-19 22:56:40.046082\n",
      "resetting env. episode 3724, reward total was -19.0. running mean: -19.749297029080473, timestamp: 2022-08-19 22:56:43.698316\n",
      "resetting env. episode 3725, reward total was -21.0. running mean: -19.761804058789668, timestamp: 2022-08-19 22:56:47.569049\n",
      "resetting env. episode 3726, reward total was -20.0. running mean: -19.76418601820177, timestamp: 2022-08-19 22:56:51.111579\n",
      "resetting env. episode 3727, reward total was -21.0. running mean: -19.776544158019753, timestamp: 2022-08-19 22:56:54.680969\n",
      "resetting env. episode 3728, reward total was -21.0. running mean: -19.788778716439555, timestamp: 2022-08-19 22:56:58.656182\n",
      "resetting env. episode 3729, reward total was -19.0. running mean: -19.78089092927516, timestamp: 2022-08-19 22:57:02.859496\n",
      "resetting env. episode 3730, reward total was -19.0. running mean: -19.773082019982407, timestamp: 2022-08-19 22:57:06.941724\n",
      "resetting env. episode 3731, reward total was -21.0. running mean: -19.785351199782585, timestamp: 2022-08-19 22:57:10.898559\n",
      "resetting env. episode 3732, reward total was -20.0. running mean: -19.787497687784757, timestamp: 2022-08-19 22:57:13.866263\n",
      "resetting env. episode 3733, reward total was -20.0. running mean: -19.789622710906908, timestamp: 2022-08-19 22:57:17.918433\n",
      "resetting env. episode 3734, reward total was -19.0. running mean: -19.78172648379784, timestamp: 2022-08-19 22:57:21.945573\n",
      "resetting env. episode 3735, reward total was -19.0. running mean: -19.77390921895986, timestamp: 2022-08-19 22:57:26.195794\n",
      "resetting env. episode 3736, reward total was -21.0. running mean: -19.786170126770262, timestamp: 2022-08-19 22:57:30.176149\n",
      "resetting env. episode 3737, reward total was -20.0. running mean: -19.78830842550256, timestamp: 2022-08-19 22:57:34.205233\n",
      "resetting env. episode 3738, reward total was -21.0. running mean: -19.800425341247536, timestamp: 2022-08-19 22:57:38.244293\n",
      "resetting env. episode 3739, reward total was -21.0. running mean: -19.812421087835062, timestamp: 2022-08-19 22:57:41.837255\n",
      "resetting env. episode 3740, reward total was -20.0. running mean: -19.81429687695671, timestamp: 2022-08-19 22:57:45.153423\n",
      "resetting env. episode 3741, reward total was -20.0. running mean: -19.816153908187143, timestamp: 2022-08-19 22:57:49.194019\n",
      "resetting env. episode 3742, reward total was -21.0. running mean: -19.82799236910527, timestamp: 2022-08-19 22:57:52.963985\n",
      "resetting env. episode 3743, reward total was -21.0. running mean: -19.839712445414218, timestamp: 2022-08-19 22:57:56.384865\n",
      "resetting env. episode 3744, reward total was -20.0. running mean: -19.841315320960074, timestamp: 2022-08-19 22:58:00.402104\n",
      "resetting env. episode 3745, reward total was -20.0. running mean: -19.842902167750474, timestamp: 2022-08-19 22:58:03.628479\n",
      "resetting env. episode 3746, reward total was -21.0. running mean: -19.85447314607297, timestamp: 2022-08-19 22:58:06.509805\n",
      "resetting env. episode 3747, reward total was -20.0. running mean: -19.85592841461224, timestamp: 2022-08-19 22:58:09.197599\n",
      "resetting env. episode 3748, reward total was -20.0. running mean: -19.857369130466118, timestamp: 2022-08-19 22:58:13.463198\n",
      "resetting env. episode 3749, reward total was -19.0. running mean: -19.848795439161456, timestamp: 2022-08-19 22:58:18.052451\n",
      "resetting env. episode 3750, reward total was -17.0. running mean: -19.82030748476984, timestamp: 2022-08-19 22:58:22.773605\n",
      "resetting env. episode 3751, reward total was -21.0. running mean: -19.832104409922145, timestamp: 2022-08-19 22:58:26.106680\n",
      "resetting env. episode 3752, reward total was -20.0. running mean: -19.833783365822924, timestamp: 2022-08-19 22:58:31.246003\n",
      "resetting env. episode 3753, reward total was -19.0. running mean: -19.825445532164697, timestamp: 2022-08-19 22:58:36.144860\n",
      "resetting env. episode 3754, reward total was -21.0. running mean: -19.83719107684305, timestamp: 2022-08-19 22:58:40.942022\n",
      "resetting env. episode 3755, reward total was -21.0. running mean: -19.848819166074623, timestamp: 2022-08-19 22:58:45.085947\n",
      "resetting env. episode 3756, reward total was -21.0. running mean: -19.860330974413877, timestamp: 2022-08-19 22:58:49.496629\n",
      "resetting env. episode 3757, reward total was -20.0. running mean: -19.861727664669736, timestamp: 2022-08-19 22:58:53.064048\n",
      "resetting env. episode 3758, reward total was -20.0. running mean: -19.86311038802304, timestamp: 2022-08-19 22:58:57.868217\n",
      "resetting env. episode 3759, reward total was -19.0. running mean: -19.85447928414281, timestamp: 2022-08-19 22:59:01.777820\n",
      "resetting env. episode 3760, reward total was -21.0. running mean: -19.86593449130138, timestamp: 2022-08-19 22:59:06.830570\n",
      "resetting env. episode 3761, reward total was -19.0. running mean: -19.857275146388368, timestamp: 2022-08-19 22:59:10.549886\n",
      "resetting env. episode 3762, reward total was -18.0. running mean: -19.838702394924482, timestamp: 2022-08-19 22:59:14.737673\n",
      "resetting env. episode 3763, reward total was -20.0. running mean: -19.840315370975237, timestamp: 2022-08-19 22:59:17.767517\n",
      "resetting env. episode 3764, reward total was -19.0. running mean: -19.831912217265486, timestamp: 2022-08-19 22:59:21.145490\n",
      "resetting env. episode 3765, reward total was -18.0. running mean: -19.81359309509283, timestamp: 2022-08-19 22:59:25.884896\n",
      "resetting env. episode 3766, reward total was -21.0. running mean: -19.825457164141902, timestamp: 2022-08-19 22:59:29.552572\n",
      "resetting env. episode 3767, reward total was -20.0. running mean: -19.82720259250048, timestamp: 2022-08-19 22:59:34.132357\n",
      "resetting env. episode 3768, reward total was -19.0. running mean: -19.818930566575478, timestamp: 2022-08-19 22:59:37.754678\n",
      "resetting env. episode 3769, reward total was -21.0. running mean: -19.830741260909726, timestamp: 2022-08-19 22:59:42.290550\n",
      "resetting env. episode 3770, reward total was -21.0. running mean: -19.84243384830063, timestamp: 2022-08-19 22:59:45.320448\n",
      "resetting env. episode 3771, reward total was -17.0. running mean: -19.814009509817623, timestamp: 2022-08-19 22:59:50.620283\n",
      "resetting env. episode 3772, reward total was -20.0. running mean: -19.815869414719447, timestamp: 2022-08-19 22:59:53.937634\n",
      "resetting env. episode 3773, reward total was -20.0. running mean: -19.81771072057225, timestamp: 2022-08-19 22:59:57.092205\n",
      "resetting env. episode 3774, reward total was -19.0. running mean: -19.80953361336653, timestamp: 2022-08-19 23:00:01.320769\n",
      "resetting env. episode 3775, reward total was -20.0. running mean: -19.811438277232863, timestamp: 2022-08-19 23:00:05.559667\n",
      "resetting env. episode 3776, reward total was -20.0. running mean: -19.813323894460535, timestamp: 2022-08-19 23:00:09.277042\n",
      "resetting env. episode 3777, reward total was -20.0. running mean: -19.815190655515927, timestamp: 2022-08-19 23:00:13.924616\n",
      "resetting env. episode 3778, reward total was -21.0. running mean: -19.827038748960767, timestamp: 2022-08-19 23:00:17.696533\n",
      "resetting env. episode 3779, reward total was -19.0. running mean: -19.81876836147116, timestamp: 2022-08-19 23:00:21.993526\n",
      "resetting env. episode 3780, reward total was -21.0. running mean: -19.83058067785645, timestamp: 2022-08-19 23:00:25.185496\n",
      "resetting env. episode 3781, reward total was -21.0. running mean: -19.842274871077887, timestamp: 2022-08-19 23:00:28.546843\n",
      "resetting env. episode 3782, reward total was -21.0. running mean: -19.85385212236711, timestamp: 2022-08-19 23:00:31.508926\n",
      "resetting env. episode 3783, reward total was -21.0. running mean: -19.865313601143438, timestamp: 2022-08-19 23:00:34.787147\n",
      "resetting env. episode 3784, reward total was -20.0. running mean: -19.866660465132004, timestamp: 2022-08-19 23:00:38.233935\n",
      "resetting env. episode 3785, reward total was -21.0. running mean: -19.877993860480686, timestamp: 2022-08-19 23:00:41.207987\n",
      "resetting env. episode 3786, reward total was -18.0. running mean: -19.859213921875877, timestamp: 2022-08-19 23:00:46.010148\n",
      "resetting env. episode 3787, reward total was -21.0. running mean: -19.870621782657118, timestamp: 2022-08-19 23:00:49.914844\n",
      "resetting env. episode 3788, reward total was -19.0. running mean: -19.861915564830547, timestamp: 2022-08-19 23:00:54.116617\n",
      "resetting env. episode 3789, reward total was -21.0. running mean: -19.87329640918224, timestamp: 2022-08-19 23:00:58.589659\n",
      "resetting env. episode 3790, reward total was -21.0. running mean: -19.88456344509042, timestamp: 2022-08-19 23:01:01.734837\n",
      "resetting env. episode 3791, reward total was -20.0. running mean: -19.885717810639516, timestamp: 2022-08-19 23:01:05.964045\n",
      "resetting env. episode 3792, reward total was -20.0. running mean: -19.88686063253312, timestamp: 2022-08-19 23:01:09.885569\n",
      "resetting env. episode 3793, reward total was -19.0. running mean: -19.877992026207792, timestamp: 2022-08-19 23:01:14.587993\n",
      "resetting env. episode 3794, reward total was -21.0. running mean: -19.889212105945717, timestamp: 2022-08-19 23:01:17.962971\n",
      "resetting env. episode 3795, reward total was -20.0. running mean: -19.890319984886258, timestamp: 2022-08-19 23:01:22.049374\n",
      "resetting env. episode 3796, reward total was -21.0. running mean: -19.901416785037394, timestamp: 2022-08-19 23:01:25.713579\n",
      "resetting env. episode 3797, reward total was -19.0. running mean: -19.89240261718702, timestamp: 2022-08-19 23:01:30.525716\n",
      "resetting env. episode 3798, reward total was -20.0. running mean: -19.89347859101515, timestamp: 2022-08-19 23:01:33.823351\n",
      "resetting env. episode 3799, reward total was -18.0. running mean: -19.874543805105, timestamp: 2022-08-19 23:01:38.558447\n",
      "resetting env. episode 3800, reward total was -21.0. running mean: -19.88579836705395, timestamp: 2022-08-19 23:01:42.718237\n",
      "resetting env. episode 3801, reward total was -19.0. running mean: -19.876940383383413, timestamp: 2022-08-19 23:01:47.213014\n",
      "resetting env. episode 3802, reward total was -21.0. running mean: -19.88817097954958, timestamp: 2022-08-19 23:01:50.968948\n",
      "resetting env. episode 3803, reward total was -20.0. running mean: -19.889289269754084, timestamp: 2022-08-19 23:01:54.977236\n",
      "resetting env. episode 3804, reward total was -19.0. running mean: -19.880396377056545, timestamp: 2022-08-19 23:01:58.461140\n",
      "resetting env. episode 3805, reward total was -20.0. running mean: -19.88159241328598, timestamp: 2022-08-19 23:02:02.477595\n",
      "resetting env. episode 3806, reward total was -21.0. running mean: -19.89277648915312, timestamp: 2022-08-19 23:02:05.418734\n",
      "resetting env. episode 3807, reward total was -19.0. running mean: -19.88384872426159, timestamp: 2022-08-19 23:02:09.085283\n",
      "resetting env. episode 3808, reward total was -19.0. running mean: -19.875010237018977, timestamp: 2022-08-19 23:02:13.693276\n",
      "resetting env. episode 3809, reward total was -21.0. running mean: -19.886260134648786, timestamp: 2022-08-19 23:02:16.882979\n",
      "resetting env. episode 3810, reward total was -21.0. running mean: -19.8973975333023, timestamp: 2022-08-19 23:02:20.929136\n",
      "resetting env. episode 3811, reward total was -21.0. running mean: -19.90842355796928, timestamp: 2022-08-19 23:02:24.952381\n",
      "resetting env. episode 3812, reward total was -21.0. running mean: -19.919339322389586, timestamp: 2022-08-19 23:02:29.050740\n",
      "resetting env. episode 3813, reward total was -21.0. running mean: -19.93014592916569, timestamp: 2022-08-19 23:02:33.455967\n",
      "resetting env. episode 3814, reward total was -21.0. running mean: -19.940844469874033, timestamp: 2022-08-19 23:02:37.345569\n",
      "resetting env. episode 3815, reward total was -19.0. running mean: -19.931436025175294, timestamp: 2022-08-19 23:02:41.070600\n",
      "resetting env. episode 3816, reward total was -21.0. running mean: -19.94212166492354, timestamp: 2022-08-19 23:02:46.046300\n",
      "resetting env. episode 3817, reward total was -20.0. running mean: -19.942700448274305, timestamp: 2022-08-19 23:02:49.365598\n",
      "resetting env. episode 3818, reward total was -20.0. running mean: -19.94327344379156, timestamp: 2022-08-19 23:02:52.731606\n",
      "resetting env. episode 3819, reward total was -19.0. running mean: -19.933840709353646, timestamp: 2022-08-19 23:02:56.988654\n",
      "resetting env. episode 3820, reward total was -20.0. running mean: -19.93450230226011, timestamp: 2022-08-19 23:03:00.962037\n",
      "resetting env. episode 3821, reward total was -21.0. running mean: -19.94515727923751, timestamp: 2022-08-19 23:03:04.846651\n",
      "resetting env. episode 3822, reward total was -21.0. running mean: -19.955705706445134, timestamp: 2022-08-19 23:03:08.579063\n",
      "resetting env. episode 3823, reward total was -17.0. running mean: -19.926148649380682, timestamp: 2022-08-19 23:03:12.977602\n",
      "resetting env. episode 3824, reward total was -21.0. running mean: -19.936887162886876, timestamp: 2022-08-19 23:03:16.662330\n",
      "resetting env. episode 3825, reward total was -21.0. running mean: -19.947518291258007, timestamp: 2022-08-19 23:03:20.244167\n",
      "resetting env. episode 3826, reward total was -18.0. running mean: -19.928043108345427, timestamp: 2022-08-19 23:03:24.575585\n",
      "resetting env. episode 3827, reward total was -19.0. running mean: -19.918762677261974, timestamp: 2022-08-19 23:03:28.193921\n",
      "resetting env. episode 3828, reward total was -19.0. running mean: -19.909575050489355, timestamp: 2022-08-19 23:03:32.039397\n",
      "resetting env. episode 3829, reward total was -19.0. running mean: -19.90047929998446, timestamp: 2022-08-19 23:03:35.631267\n",
      "resetting env. episode 3830, reward total was -21.0. running mean: -19.911474506984618, timestamp: 2022-08-19 23:03:39.455086\n",
      "resetting env. episode 3831, reward total was -18.0. running mean: -19.892359761914772, timestamp: 2022-08-19 23:03:44.502057\n",
      "resetting env. episode 3832, reward total was -20.0. running mean: -19.893436164295622, timestamp: 2022-08-19 23:03:48.351767\n",
      "resetting env. episode 3833, reward total was -20.0. running mean: -19.894501802652666, timestamp: 2022-08-19 23:03:51.674883\n",
      "resetting env. episode 3834, reward total was -19.0. running mean: -19.88555678462614, timestamp: 2022-08-19 23:03:56.822614\n",
      "resetting env. episode 3835, reward total was -19.0. running mean: -19.876701216779878, timestamp: 2022-08-19 23:04:02.175290\n",
      "resetting env. episode 3836, reward total was -19.0. running mean: -19.86793420461208, timestamp: 2022-08-19 23:04:08.249872\n",
      "resetting env. episode 3837, reward total was -19.0. running mean: -19.85925486256596, timestamp: 2022-08-19 23:04:14.531097\n",
      "resetting env. episode 3838, reward total was -19.0. running mean: -19.850662313940305, timestamp: 2022-08-19 23:04:19.448933\n",
      "resetting env. episode 3839, reward total was -21.0. running mean: -19.862155690800904, timestamp: 2022-08-19 23:04:23.955882\n",
      "resetting env. episode 3840, reward total was -21.0. running mean: -19.873534133892896, timestamp: 2022-08-19 23:04:27.682857\n",
      "resetting env. episode 3841, reward total was -19.0. running mean: -19.86479879255397, timestamp: 2022-08-19 23:04:31.590204\n",
      "resetting env. episode 3842, reward total was -20.0. running mean: -19.86615080462843, timestamp: 2022-08-19 23:04:34.933705\n",
      "resetting env. episode 3843, reward total was -19.0. running mean: -19.857489296582145, timestamp: 2022-08-19 23:04:39.579434\n",
      "resetting env. episode 3844, reward total was -19.0. running mean: -19.848914403616323, timestamp: 2022-08-19 23:04:43.771184\n",
      "resetting env. episode 3845, reward total was -19.0. running mean: -19.84042525958016, timestamp: 2022-08-19 23:04:48.470103\n",
      "resetting env. episode 3846, reward total was -20.0. running mean: -19.84202100698436, timestamp: 2022-08-19 23:04:53.074043\n",
      "resetting env. episode 3847, reward total was -20.0. running mean: -19.843600796914515, timestamp: 2022-08-19 23:04:57.315395\n",
      "resetting env. episode 3848, reward total was -20.0. running mean: -19.845164788945368, timestamp: 2022-08-19 23:05:01.803153\n",
      "resetting env. episode 3849, reward total was -20.0. running mean: -19.846713141055915, timestamp: 2022-08-19 23:05:06.316089\n",
      "resetting env. episode 3850, reward total was -19.0. running mean: -19.838246009645356, timestamp: 2022-08-19 23:05:09.961379\n",
      "resetting env. episode 3851, reward total was -21.0. running mean: -19.849863549548903, timestamp: 2022-08-19 23:05:13.826736\n",
      "resetting env. episode 3852, reward total was -20.0. running mean: -19.851364914053413, timestamp: 2022-08-19 23:05:17.529838\n",
      "resetting env. episode 3853, reward total was -21.0. running mean: -19.86285126491288, timestamp: 2022-08-19 23:05:21.425429\n",
      "resetting env. episode 3854, reward total was -21.0. running mean: -19.87422275226375, timestamp: 2022-08-19 23:05:24.866228\n",
      "resetting env. episode 3855, reward total was -19.0. running mean: -19.865480524741116, timestamp: 2022-08-19 23:05:29.187687\n",
      "resetting env. episode 3856, reward total was -20.0. running mean: -19.866825719493704, timestamp: 2022-08-19 23:05:33.343566\n",
      "resetting env. episode 3857, reward total was -20.0. running mean: -19.868157462298765, timestamp: 2022-08-19 23:05:37.373095\n",
      "resetting env. episode 3858, reward total was -20.0. running mean: -19.869475887675776, timestamp: 2022-08-19 23:05:40.282318\n",
      "resetting env. episode 3859, reward total was -21.0. running mean: -19.88078112879902, timestamp: 2022-08-19 23:05:44.242733\n",
      "resetting env. episode 3860, reward total was -19.0. running mean: -19.871973317511028, timestamp: 2022-08-19 23:05:48.205225\n",
      "resetting env. episode 3861, reward total was -19.0. running mean: -19.86325358433592, timestamp: 2022-08-19 23:05:52.444708\n",
      "resetting env. episode 3862, reward total was -19.0. running mean: -19.85462104849256, timestamp: 2022-08-19 23:05:55.710874\n",
      "resetting env. episode 3863, reward total was -19.0. running mean: -19.846074838007638, timestamp: 2022-08-19 23:06:01.691638\n",
      "resetting env. episode 3864, reward total was -21.0. running mean: -19.857614089627564, timestamp: 2022-08-19 23:06:05.953175\n",
      "resetting env. episode 3865, reward total was -19.0. running mean: -19.84903794873129, timestamp: 2022-08-19 23:06:11.394368\n",
      "resetting env. episode 3866, reward total was -15.0. running mean: -19.800547569243975, timestamp: 2022-08-19 23:06:15.353788\n",
      "resetting env. episode 3867, reward total was -20.0. running mean: -19.802542093551533, timestamp: 2022-08-19 23:06:18.658004\n",
      "resetting env. episode 3868, reward total was -21.0. running mean: -19.81451667261602, timestamp: 2022-08-19 23:06:21.942211\n",
      "resetting env. episode 3869, reward total was -18.0. running mean: -19.79637150588986, timestamp: 2022-08-19 23:06:25.593490\n",
      "resetting env. episode 3870, reward total was -18.0. running mean: -19.77840779083096, timestamp: 2022-08-19 23:06:30.409414\n",
      "resetting env. episode 3871, reward total was -21.0. running mean: -19.790623712922653, timestamp: 2022-08-19 23:06:33.473408\n",
      "resetting env. episode 3872, reward total was -21.0. running mean: -19.802717475793425, timestamp: 2022-08-19 23:06:37.369249\n",
      "resetting env. episode 3873, reward total was -20.0. running mean: -19.80469030103549, timestamp: 2022-08-19 23:06:40.540776\n",
      "resetting env. episode 3874, reward total was -21.0. running mean: -19.816643398025136, timestamp: 2022-08-19 23:06:45.330042\n",
      "resetting env. episode 3875, reward total was -19.0. running mean: -19.808476964044885, timestamp: 2022-08-19 23:06:49.104953\n",
      "resetting env. episode 3876, reward total was -19.0. running mean: -19.800392194404438, timestamp: 2022-08-19 23:06:53.761957\n",
      "resetting env. episode 3877, reward total was -19.0. running mean: -19.792388272460396, timestamp: 2022-08-19 23:06:57.312354\n",
      "resetting env. episode 3878, reward total was -19.0. running mean: -19.784464389735792, timestamp: 2022-08-19 23:07:01.994573\n",
      "resetting env. episode 3879, reward total was -20.0. running mean: -19.786619745838433, timestamp: 2022-08-19 23:07:05.781862\n",
      "resetting env. episode 3880, reward total was -20.0. running mean: -19.788753548380047, timestamp: 2022-08-19 23:07:09.655510\n",
      "resetting env. episode 3881, reward total was -20.0. running mean: -19.790866012896245, timestamp: 2022-08-19 23:07:12.488840\n",
      "resetting env. episode 3882, reward total was -19.0. running mean: -19.782957352767284, timestamp: 2022-08-19 23:07:16.715414\n",
      "resetting env. episode 3883, reward total was -18.0. running mean: -19.76512777923961, timestamp: 2022-08-19 23:07:20.416803\n",
      "resetting env. episode 3884, reward total was -21.0. running mean: -19.777476501447214, timestamp: 2022-08-19 23:07:23.746901\n",
      "resetting env. episode 3885, reward total was -20.0. running mean: -19.77970173643274, timestamp: 2022-08-19 23:07:27.048947\n",
      "resetting env. episode 3886, reward total was -19.0. running mean: -19.771904719068417, timestamp: 2022-08-19 23:07:30.741080\n",
      "resetting env. episode 3887, reward total was -21.0. running mean: -19.784185671877733, timestamp: 2022-08-19 23:07:34.376389\n",
      "resetting env. episode 3888, reward total was -20.0. running mean: -19.786343815158954, timestamp: 2022-08-19 23:07:38.523790\n",
      "resetting env. episode 3889, reward total was -20.0. running mean: -19.788480377007364, timestamp: 2022-08-19 23:07:42.134137\n",
      "resetting env. episode 3890, reward total was -20.0. running mean: -19.79059557323729, timestamp: 2022-08-19 23:07:45.236408\n",
      "resetting env. episode 3891, reward total was -19.0. running mean: -19.782689617504918, timestamp: 2022-08-19 23:07:48.910646\n",
      "resetting env. episode 3892, reward total was -21.0. running mean: -19.79486272132987, timestamp: 2022-08-19 23:07:52.084167\n",
      "resetting env. episode 3893, reward total was -20.0. running mean: -19.79691409411657, timestamp: 2022-08-19 23:07:55.029290\n",
      "resetting env. episode 3894, reward total was -19.0. running mean: -19.788944953175406, timestamp: 2022-08-19 23:07:58.917847\n",
      "resetting env. episode 3895, reward total was -21.0. running mean: -19.801055503643653, timestamp: 2022-08-19 23:08:02.199633\n",
      "resetting env. episode 3896, reward total was -20.0. running mean: -19.803044948607216, timestamp: 2022-08-19 23:08:05.995385\n",
      "resetting env. episode 3897, reward total was -21.0. running mean: -19.815014499121144, timestamp: 2022-08-19 23:08:09.193857\n",
      "resetting env. episode 3898, reward total was -18.0. running mean: -19.796864354129934, timestamp: 2022-08-19 23:08:13.381994\n",
      "resetting env. episode 3899, reward total was -20.0. running mean: -19.798895710588635, timestamp: 2022-08-19 23:08:16.460082\n",
      "resetting env. episode 3900, reward total was -19.0. running mean: -19.79090675348275, timestamp: 2022-08-19 23:08:20.230687\n",
      "resetting env. episode 3901, reward total was -21.0. running mean: -19.802997685947926, timestamp: 2022-08-19 23:08:24.461828\n",
      "resetting env. episode 3902, reward total was -21.0. running mean: -19.814967709088446, timestamp: 2022-08-19 23:08:27.605171\n",
      "resetting env. episode 3903, reward total was -18.0. running mean: -19.79681803199756, timestamp: 2022-08-19 23:08:32.239311\n",
      "resetting env. episode 3904, reward total was -17.0. running mean: -19.768849851677587, timestamp: 2022-08-19 23:08:36.673607\n",
      "resetting env. episode 3905, reward total was -20.0. running mean: -19.77116135316081, timestamp: 2022-08-19 23:08:40.541038\n",
      "resetting env. episode 3906, reward total was -20.0. running mean: -19.7734497396292, timestamp: 2022-08-19 23:08:43.930872\n",
      "resetting env. episode 3907, reward total was -20.0. running mean: -19.775715242232906, timestamp: 2022-08-19 23:08:47.361870\n",
      "resetting env. episode 3908, reward total was -21.0. running mean: -19.787958089810576, timestamp: 2022-08-19 23:08:51.409049\n",
      "resetting env. episode 3909, reward total was -21.0. running mean: -19.80007850891247, timestamp: 2022-08-19 23:08:55.289301\n",
      "resetting env. episode 3910, reward total was -20.0. running mean: -19.802077723823345, timestamp: 2022-08-19 23:08:59.645685\n",
      "resetting env. episode 3911, reward total was -21.0. running mean: -19.81405694658511, timestamp: 2022-08-19 23:09:04.040949\n",
      "resetting env. episode 3912, reward total was -19.0. running mean: -19.80591637711926, timestamp: 2022-08-19 23:09:07.877721\n",
      "resetting env. episode 3913, reward total was -21.0. running mean: -19.81785721334807, timestamp: 2022-08-19 23:09:11.916924\n",
      "resetting env. episode 3914, reward total was -21.0. running mean: -19.82967864121459, timestamp: 2022-08-19 23:09:15.427452\n",
      "resetting env. episode 3915, reward total was -19.0. running mean: -19.821381854802443, timestamp: 2022-08-19 23:09:19.320929\n",
      "resetting env. episode 3916, reward total was -21.0. running mean: -19.83316803625442, timestamp: 2022-08-19 23:09:22.005723\n",
      "resetting env. episode 3917, reward total was -18.0. running mean: -19.814836355891877, timestamp: 2022-08-19 23:09:26.200233\n",
      "resetting env. episode 3918, reward total was -20.0. running mean: -19.81668799233296, timestamp: 2022-08-19 23:09:29.386631\n",
      "resetting env. episode 3919, reward total was -16.0. running mean: -19.778521112409628, timestamp: 2022-08-19 23:09:34.483472\n",
      "resetting env. episode 3920, reward total was -21.0. running mean: -19.790735901285533, timestamp: 2022-08-19 23:09:37.996771\n",
      "resetting env. episode 3921, reward total was -20.0. running mean: -19.792828542272677, timestamp: 2022-08-19 23:09:42.040009\n",
      "resetting env. episode 3922, reward total was -19.0. running mean: -19.78490025684995, timestamp: 2022-08-19 23:09:47.072637\n",
      "resetting env. episode 3923, reward total was -20.0. running mean: -19.78705125428145, timestamp: 2022-08-19 23:09:50.381790\n",
      "resetting env. episode 3924, reward total was -20.0. running mean: -19.789180741738637, timestamp: 2022-08-19 23:09:54.545322\n",
      "resetting env. episode 3925, reward total was -21.0. running mean: -19.801288934321253, timestamp: 2022-08-19 23:09:58.134728\n",
      "resetting env. episode 3926, reward total was -21.0. running mean: -19.813276044978043, timestamp: 2022-08-19 23:10:01.167559\n",
      "resetting env. episode 3927, reward total was -21.0. running mean: -19.825143284528263, timestamp: 2022-08-19 23:10:04.955047\n",
      "resetting env. episode 3928, reward total was -20.0. running mean: -19.82689185168298, timestamp: 2022-08-19 23:10:08.591700\n",
      "resetting env. episode 3929, reward total was -21.0. running mean: -19.83862293316615, timestamp: 2022-08-19 23:10:11.935691\n",
      "resetting env. episode 3930, reward total was -21.0. running mean: -19.85023670383449, timestamp: 2022-08-19 23:10:16.107531\n",
      "resetting env. episode 3931, reward total was -21.0. running mean: -19.861734336796147, timestamp: 2022-08-19 23:10:20.009148\n",
      "resetting env. episode 3932, reward total was -18.0. running mean: -19.843116993428186, timestamp: 2022-08-19 23:10:24.300928\n",
      "resetting env. episode 3933, reward total was -20.0. running mean: -19.844685823493904, timestamp: 2022-08-19 23:10:27.998344\n",
      "resetting env. episode 3934, reward total was -21.0. running mean: -19.856238965258967, timestamp: 2022-08-19 23:10:32.120299\n",
      "resetting env. episode 3935, reward total was -21.0. running mean: -19.867676575606378, timestamp: 2022-08-19 23:10:35.604984\n",
      "resetting env. episode 3936, reward total was -21.0. running mean: -19.878999809850313, timestamp: 2022-08-19 23:10:38.613401\n",
      "resetting env. episode 3937, reward total was -20.0. running mean: -19.880209811751808, timestamp: 2022-08-19 23:10:42.154935\n",
      "resetting env. episode 3938, reward total was -17.0. running mean: -19.85140771363429, timestamp: 2022-08-19 23:10:46.592893\n",
      "resetting env. episode 3939, reward total was -20.0. running mean: -19.852893636497946, timestamp: 2022-08-19 23:10:50.186069\n",
      "resetting env. episode 3940, reward total was -20.0. running mean: -19.854364700132965, timestamp: 2022-08-19 23:10:54.441299\n",
      "resetting env. episode 3941, reward total was -20.0. running mean: -19.855821053131635, timestamp: 2022-08-19 23:10:58.580416\n",
      "resetting env. episode 3942, reward total was -20.0. running mean: -19.857262842600317, timestamp: 2022-08-19 23:11:03.522547\n",
      "resetting env. episode 3943, reward total was -20.0. running mean: -19.858690214174313, timestamp: 2022-08-19 23:11:06.195336\n",
      "resetting env. episode 3944, reward total was -21.0. running mean: -19.87010331203257, timestamp: 2022-08-19 23:11:10.581784\n",
      "resetting env. episode 3945, reward total was -15.0. running mean: -19.82140227891224, timestamp: 2022-08-19 23:11:14.869150\n",
      "resetting env. episode 3946, reward total was -17.0. running mean: -19.79318825612312, timestamp: 2022-08-19 23:11:18.882427\n",
      "resetting env. episode 3947, reward total was -20.0. running mean: -19.795256373561887, timestamp: 2022-08-19 23:11:22.045990\n",
      "resetting env. episode 3948, reward total was -19.0. running mean: -19.78730380982627, timestamp: 2022-08-19 23:11:25.625411\n",
      "resetting env. episode 3949, reward total was -21.0. running mean: -19.79943077172801, timestamp: 2022-08-19 23:11:30.078511\n",
      "resetting env. episode 3950, reward total was -21.0. running mean: -19.81143646401073, timestamp: 2022-08-19 23:11:33.299204\n",
      "resetting env. episode 3951, reward total was -21.0. running mean: -19.82332209937062, timestamp: 2022-08-19 23:11:36.313267\n",
      "resetting env. episode 3952, reward total was -16.0. running mean: -19.785088878376914, timestamp: 2022-08-19 23:11:40.323560\n",
      "resetting env. episode 3953, reward total was -19.0. running mean: -19.777237989593146, timestamp: 2022-08-19 23:11:44.083984\n",
      "resetting env. episode 3954, reward total was -20.0. running mean: -19.779465609697215, timestamp: 2022-08-19 23:11:47.613520\n",
      "resetting env. episode 3955, reward total was -18.0. running mean: -19.761670953600245, timestamp: 2022-08-19 23:11:51.594339\n",
      "resetting env. episode 3956, reward total was -18.0. running mean: -19.74405424406424, timestamp: 2022-08-19 23:11:55.683879\n",
      "resetting env. episode 3957, reward total was -21.0. running mean: -19.7566137016236, timestamp: 2022-08-19 23:11:58.703842\n",
      "resetting env. episode 3958, reward total was -19.0. running mean: -19.749047564607366, timestamp: 2022-08-19 23:12:03.265728\n",
      "resetting env. episode 3959, reward total was -20.0. running mean: -19.75155708896129, timestamp: 2022-08-19 23:12:07.725903\n",
      "resetting env. episode 3960, reward total was -19.0. running mean: -19.74404151807168, timestamp: 2022-08-19 23:12:11.586179\n",
      "resetting env. episode 3961, reward total was -21.0. running mean: -19.75660110289096, timestamp: 2022-08-19 23:12:15.514028\n",
      "resetting env. episode 3962, reward total was -19.0. running mean: -19.74903509186205, timestamp: 2022-08-19 23:12:19.376895\n",
      "resetting env. episode 3963, reward total was -19.0. running mean: -19.741544740943432, timestamp: 2022-08-19 23:12:23.851316\n",
      "resetting env. episode 3964, reward total was -21.0. running mean: -19.754129293534, timestamp: 2022-08-19 23:12:27.200577\n",
      "resetting env. episode 3965, reward total was -17.0. running mean: -19.72658800059866, timestamp: 2022-08-19 23:12:31.612291\n",
      "resetting env. episode 3966, reward total was -20.0. running mean: -19.729322120592673, timestamp: 2022-08-19 23:12:35.475223\n",
      "resetting env. episode 3967, reward total was -20.0. running mean: -19.732028899386744, timestamp: 2022-08-19 23:12:38.610777\n",
      "resetting env. episode 3968, reward total was -20.0. running mean: -19.734708610392875, timestamp: 2022-08-19 23:12:43.688698\n",
      "resetting env. episode 3969, reward total was -20.0. running mean: -19.737361524288946, timestamp: 2022-08-19 23:12:47.026458\n",
      "resetting env. episode 3970, reward total was -20.0. running mean: -19.739987909046057, timestamp: 2022-08-19 23:12:51.387777\n",
      "resetting env. episode 3971, reward total was -19.0. running mean: -19.732588029955597, timestamp: 2022-08-19 23:12:54.609170\n",
      "resetting env. episode 3972, reward total was -21.0. running mean: -19.745262149656043, timestamp: 2022-08-19 23:12:58.483061\n",
      "resetting env. episode 3973, reward total was -20.0. running mean: -19.747809528159483, timestamp: 2022-08-19 23:13:02.532281\n",
      "resetting env. episode 3974, reward total was -20.0. running mean: -19.750331432877886, timestamp: 2022-08-19 23:13:05.875345\n",
      "resetting env. episode 3975, reward total was -20.0. running mean: -19.752828118549107, timestamp: 2022-08-19 23:13:09.431974\n",
      "resetting env. episode 3976, reward total was -18.0. running mean: -19.735299837363616, timestamp: 2022-08-19 23:13:12.983517\n",
      "resetting env. episode 3977, reward total was -20.0. running mean: -19.73794683898998, timestamp: 2022-08-19 23:13:16.872035\n",
      "resetting env. episode 3978, reward total was -19.0. running mean: -19.73056737060008, timestamp: 2022-08-19 23:13:20.324657\n",
      "resetting env. episode 3979, reward total was -19.0. running mean: -19.72326169689408, timestamp: 2022-08-19 23:13:24.944299\n",
      "resetting env. episode 3980, reward total was -19.0. running mean: -19.716029079925143, timestamp: 2022-08-19 23:13:28.894070\n",
      "resetting env. episode 3981, reward total was -21.0. running mean: -19.72886878912589, timestamp: 2022-08-19 23:13:32.068510\n",
      "resetting env. episode 3982, reward total was -20.0. running mean: -19.73158010123463, timestamp: 2022-08-19 23:13:35.103119\n",
      "resetting env. episode 3983, reward total was -19.0. running mean: -19.724264300222284, timestamp: 2022-08-19 23:13:38.790958\n",
      "resetting env. episode 3984, reward total was -21.0. running mean: -19.737021657220062, timestamp: 2022-08-19 23:13:42.654705\n",
      "resetting env. episode 3985, reward total was -21.0. running mean: -19.749651440647863, timestamp: 2022-08-19 23:13:45.836239\n",
      "resetting env. episode 3986, reward total was -20.0. running mean: -19.752154926241385, timestamp: 2022-08-19 23:13:50.334803\n",
      "resetting env. episode 3987, reward total was -20.0. running mean: -19.75463337697897, timestamp: 2022-08-19 23:13:54.387892\n",
      "resetting env. episode 3988, reward total was -21.0. running mean: -19.76708704320918, timestamp: 2022-08-19 23:13:58.811058\n",
      "resetting env. episode 3989, reward total was -18.0. running mean: -19.74941617277709, timestamp: 2022-08-19 23:14:03.302044\n",
      "resetting env. episode 3990, reward total was -20.0. running mean: -19.751922011049317, timestamp: 2022-08-19 23:14:06.388042\n",
      "resetting env. episode 3991, reward total was -19.0. running mean: -19.744402790938825, timestamp: 2022-08-19 23:14:10.009336\n",
      "resetting env. episode 3992, reward total was -18.0. running mean: -19.726958763029437, timestamp: 2022-08-19 23:14:14.643864\n",
      "resetting env. episode 3993, reward total was -21.0. running mean: -19.739689175399143, timestamp: 2022-08-19 23:14:17.844512\n",
      "resetting env. episode 3994, reward total was -21.0. running mean: -19.75229228364515, timestamp: 2022-08-19 23:14:21.119199\n",
      "resetting env. episode 3995, reward total was -19.0. running mean: -19.7447693608087, timestamp: 2022-08-19 23:14:25.696765\n",
      "resetting env. episode 3996, reward total was -18.0. running mean: -19.727321667200613, timestamp: 2022-08-19 23:14:29.282715\n",
      "resetting env. episode 3997, reward total was -20.0. running mean: -19.730048450528606, timestamp: 2022-08-19 23:14:32.521924\n",
      "resetting env. episode 3998, reward total was -20.0. running mean: -19.732747966023318, timestamp: 2022-08-19 23:14:36.411543\n",
      "resetting env. episode 3999, reward total was -18.0. running mean: -19.715420486363083, timestamp: 2022-08-19 23:14:41.233636\n",
      "resetting env. episode 4000, reward total was -20.0. running mean: -19.718266281499453, timestamp: 2022-08-19 23:14:45.451848\n",
      "resetting env. episode 4001, reward total was -20.0. running mean: -19.721083618684457, timestamp: 2022-08-19 23:14:50.139391\n",
      "resetting env. episode 4002, reward total was -20.0. running mean: -19.72387278249761, timestamp: 2022-08-19 23:14:54.090396\n",
      "resetting env. episode 4003, reward total was -20.0. running mean: -19.726634054672633, timestamp: 2022-08-19 23:14:58.492680\n",
      "resetting env. episode 4004, reward total was -19.0. running mean: -19.71936771412591, timestamp: 2022-08-19 23:15:04.273914\n",
      "resetting env. episode 4005, reward total was -19.0. running mean: -19.71217403698465, timestamp: 2022-08-19 23:15:09.214046\n",
      "resetting env. episode 4006, reward total was -20.0. running mean: -19.7150522966148, timestamp: 2022-08-19 23:15:14.373386\n",
      "resetting env. episode 4007, reward total was -20.0. running mean: -19.717901773648652, timestamp: 2022-08-19 23:15:18.479427\n",
      "resetting env. episode 4008, reward total was -20.0. running mean: -19.720722755912163, timestamp: 2022-08-19 23:15:22.756379\n",
      "resetting env. episode 4009, reward total was -20.0. running mean: -19.72351552835304, timestamp: 2022-08-19 23:15:28.649696\n",
      "resetting env. episode 4010, reward total was -21.0. running mean: -19.736280373069512, timestamp: 2022-08-19 23:15:32.145261\n",
      "resetting env. episode 4011, reward total was -21.0. running mean: -19.74891756933882, timestamp: 2022-08-19 23:15:36.289188\n",
      "resetting env. episode 4012, reward total was -20.0. running mean: -19.75142839364543, timestamp: 2022-08-19 23:15:40.268668\n",
      "resetting env. episode 4013, reward total was -19.0. running mean: -19.743914109708978, timestamp: 2022-08-19 23:15:45.661000\n",
      "resetting env. episode 4014, reward total was -20.0. running mean: -19.74647496861189, timestamp: 2022-08-19 23:15:51.128483\n",
      "resetting env. episode 4015, reward total was -21.0. running mean: -19.75901021892577, timestamp: 2022-08-19 23:15:54.195320\n",
      "resetting env. episode 4016, reward total was -19.0. running mean: -19.751420116736515, timestamp: 2022-08-19 23:15:59.098976\n",
      "resetting env. episode 4017, reward total was -17.0. running mean: -19.72390591556915, timestamp: 2022-08-19 23:16:04.177701\n",
      "resetting env. episode 4018, reward total was -20.0. running mean: -19.72666685641346, timestamp: 2022-08-19 23:16:09.290228\n",
      "resetting env. episode 4019, reward total was -15.0. running mean: -19.67940018784932, timestamp: 2022-08-19 23:16:16.412215\n",
      "resetting env. episode 4020, reward total was -21.0. running mean: -19.692606185970828, timestamp: 2022-08-19 23:16:20.600704\n",
      "resetting env. episode 4021, reward total was -19.0. running mean: -19.68568012411112, timestamp: 2022-08-19 23:16:25.223253\n",
      "resetting env. episode 4022, reward total was -17.0. running mean: -19.65882332287001, timestamp: 2022-08-19 23:16:30.675678\n",
      "resetting env. episode 4023, reward total was -21.0. running mean: -19.672235089641312, timestamp: 2022-08-19 23:16:34.176246\n",
      "resetting env. episode 4024, reward total was -19.0. running mean: -19.6655127387449, timestamp: 2022-08-19 23:16:39.110944\n",
      "resetting env. episode 4025, reward total was -19.0. running mean: -19.658857611357455, timestamp: 2022-08-19 23:16:44.768778\n",
      "resetting env. episode 4026, reward total was -21.0. running mean: -19.672269035243882, timestamp: 2022-08-19 23:16:49.326953\n",
      "resetting env. episode 4027, reward total was -20.0. running mean: -19.675546344891444, timestamp: 2022-08-19 23:16:52.574206\n",
      "resetting env. episode 4028, reward total was -20.0. running mean: -19.678790881442527, timestamp: 2022-08-19 23:16:58.071673\n",
      "resetting env. episode 4029, reward total was -20.0. running mean: -19.6820029726281, timestamp: 2022-08-19 23:17:02.024890\n",
      "resetting env. episode 4030, reward total was -21.0. running mean: -19.69518294290182, timestamp: 2022-08-19 23:17:06.704384\n",
      "resetting env. episode 4031, reward total was -19.0. running mean: -19.688231113472803, timestamp: 2022-08-19 23:17:10.515238\n",
      "resetting env. episode 4032, reward total was -21.0. running mean: -19.701348802338075, timestamp: 2022-08-19 23:17:14.044403\n",
      "resetting env. episode 4033, reward total was -20.0. running mean: -19.704335314314694, timestamp: 2022-08-19 23:17:17.561114\n",
      "resetting env. episode 4034, reward total was -20.0. running mean: -19.707291961171546, timestamp: 2022-08-19 23:17:21.214850\n",
      "resetting env. episode 4035, reward total was -19.0. running mean: -19.70021904155983, timestamp: 2022-08-19 23:17:25.331938\n",
      "resetting env. episode 4036, reward total was -21.0. running mean: -19.71321685114423, timestamp: 2022-08-19 23:17:28.321861\n",
      "resetting env. episode 4037, reward total was -21.0. running mean: -19.72608468263279, timestamp: 2022-08-19 23:17:31.791900\n",
      "resetting env. episode 4038, reward total was -19.0. running mean: -19.718823835806464, timestamp: 2022-08-19 23:17:35.008509\n",
      "resetting env. episode 4039, reward total was -19.0. running mean: -19.7116355974484, timestamp: 2022-08-19 23:17:38.902389\n",
      "resetting env. episode 4040, reward total was -18.0. running mean: -19.694519241473916, timestamp: 2022-08-19 23:17:42.967360\n",
      "resetting env. episode 4041, reward total was -19.0. running mean: -19.68757404905918, timestamp: 2022-08-19 23:17:47.199939\n",
      "resetting env. episode 4042, reward total was -20.0. running mean: -19.690698308568585, timestamp: 2022-08-19 23:17:50.711544\n",
      "resetting env. episode 4043, reward total was -20.0. running mean: -19.6937913254829, timestamp: 2022-08-19 23:17:55.380947\n",
      "resetting env. episode 4044, reward total was -21.0. running mean: -19.70685341222807, timestamp: 2022-08-19 23:17:58.608944\n",
      "resetting env. episode 4045, reward total was -19.0. running mean: -19.699784878105792, timestamp: 2022-08-19 23:18:02.718899\n",
      "resetting env. episode 4046, reward total was -19.0. running mean: -19.692787029324734, timestamp: 2022-08-19 23:18:07.005506\n",
      "resetting env. episode 4047, reward total was -21.0. running mean: -19.705859159031487, timestamp: 2022-08-19 23:18:10.387440\n",
      "resetting env. episode 4048, reward total was -20.0. running mean: -19.70880056744117, timestamp: 2022-08-19 23:18:14.554801\n",
      "resetting env. episode 4049, reward total was -20.0. running mean: -19.711712561766756, timestamp: 2022-08-19 23:18:17.726229\n",
      "resetting env. episode 4050, reward total was -20.0. running mean: -19.71459543614909, timestamp: 2022-08-19 23:18:22.446397\n",
      "resetting env. episode 4051, reward total was -18.0. running mean: -19.697449481787597, timestamp: 2022-08-19 23:18:27.603558\n",
      "resetting env. episode 4052, reward total was -20.0. running mean: -19.70047498696972, timestamp: 2022-08-19 23:18:31.970958\n",
      "resetting env. episode 4053, reward total was -19.0. running mean: -19.693470237100023, timestamp: 2022-08-19 23:18:37.541274\n",
      "resetting env. episode 4054, reward total was -20.0. running mean: -19.696535534729023, timestamp: 2022-08-19 23:18:42.168422\n",
      "resetting env. episode 4055, reward total was -21.0. running mean: -19.709570179381732, timestamp: 2022-08-19 23:18:46.951249\n",
      "resetting env. episode 4056, reward total was -21.0. running mean: -19.722474477587916, timestamp: 2022-08-19 23:18:50.523732\n",
      "resetting env. episode 4057, reward total was -19.0. running mean: -19.715249732812037, timestamp: 2022-08-19 23:18:55.334163\n",
      "resetting env. episode 4058, reward total was -21.0. running mean: -19.72809723548392, timestamp: 2022-08-19 23:18:59.669269\n",
      "resetting env. episode 4059, reward total was -20.0. running mean: -19.73081626312908, timestamp: 2022-08-19 23:19:04.449799\n",
      "resetting env. episode 4060, reward total was -20.0. running mean: -19.733508100497787, timestamp: 2022-08-19 23:19:07.482975\n",
      "resetting env. episode 4061, reward total was -19.0. running mean: -19.72617301949281, timestamp: 2022-08-19 23:19:11.765531\n",
      "resetting env. episode 4062, reward total was -21.0. running mean: -19.73891128929788, timestamp: 2022-08-19 23:19:15.314787\n",
      "resetting env. episode 4063, reward total was -17.0. running mean: -19.711522176404905, timestamp: 2022-08-19 23:19:23.216726\n",
      "resetting env. episode 4064, reward total was -18.0. running mean: -19.694406954640854, timestamp: 2022-08-19 23:19:28.321974\n",
      "resetting env. episode 4065, reward total was -21.0. running mean: -19.707462885094447, timestamp: 2022-08-19 23:19:31.401713\n",
      "resetting env. episode 4066, reward total was -20.0. running mean: -19.7103882562435, timestamp: 2022-08-19 23:19:34.779374\n",
      "resetting env. episode 4067, reward total was -19.0. running mean: -19.70328437368107, timestamp: 2022-08-19 23:19:38.733934\n",
      "resetting env. episode 4068, reward total was -18.0. running mean: -19.686251529944258, timestamp: 2022-08-19 23:19:42.836103\n",
      "resetting env. episode 4069, reward total was -19.0. running mean: -19.679389014644816, timestamp: 2022-08-19 23:19:46.826461\n",
      "resetting env. episode 4070, reward total was -20.0. running mean: -19.682595124498366, timestamp: 2022-08-19 23:19:51.921243\n",
      "resetting env. episode 4071, reward total was -21.0. running mean: -19.69576917325338, timestamp: 2022-08-19 23:19:55.839572\n",
      "resetting env. episode 4072, reward total was -20.0. running mean: -19.698811481520845, timestamp: 2022-08-19 23:19:59.103846\n",
      "resetting env. episode 4073, reward total was -20.0. running mean: -19.701823366705636, timestamp: 2022-08-19 23:20:03.511065\n",
      "resetting env. episode 4074, reward total was -20.0. running mean: -19.70480513303858, timestamp: 2022-08-19 23:20:07.132566\n",
      "resetting env. episode 4075, reward total was -21.0. running mean: -19.717757081708193, timestamp: 2022-08-19 23:20:11.333337\n",
      "resetting env. episode 4076, reward total was -21.0. running mean: -19.73057951089111, timestamp: 2022-08-19 23:20:16.931372\n",
      "resetting env. episode 4077, reward total was -19.0. running mean: -19.723273715782202, timestamp: 2022-08-19 23:20:21.787393\n",
      "resetting env. episode 4078, reward total was -21.0. running mean: -19.73604097862438, timestamp: 2022-08-19 23:20:26.008248\n",
      "resetting env. episode 4079, reward total was -19.0. running mean: -19.728680568838136, timestamp: 2022-08-19 23:20:30.099126\n",
      "resetting env. episode 4080, reward total was -20.0. running mean: -19.731393763149754, timestamp: 2022-08-19 23:20:34.092330\n",
      "resetting env. episode 4081, reward total was -21.0. running mean: -19.744079825518256, timestamp: 2022-08-19 23:20:37.351142\n",
      "resetting env. episode 4082, reward total was -20.0. running mean: -19.746639027263072, timestamp: 2022-08-19 23:20:41.131030\n",
      "resetting env. episode 4083, reward total was -21.0. running mean: -19.759172636990442, timestamp: 2022-08-19 23:20:45.055538\n",
      "resetting env. episode 4084, reward total was -19.0. running mean: -19.75158091062054, timestamp: 2022-08-19 23:20:49.973382\n",
      "resetting env. episode 4085, reward total was -17.0. running mean: -19.724065101514334, timestamp: 2022-08-19 23:20:54.480294\n",
      "resetting env. episode 4086, reward total was -20.0. running mean: -19.72682445049919, timestamp: 2022-08-19 23:20:57.361118\n",
      "resetting env. episode 4087, reward total was -20.0. running mean: -19.729556205994196, timestamp: 2022-08-19 23:21:01.291617\n",
      "resetting env. episode 4088, reward total was -20.0. running mean: -19.732260643934254, timestamp: 2022-08-19 23:21:04.331557\n",
      "resetting env. episode 4089, reward total was -18.0. running mean: -19.71493803749491, timestamp: 2022-08-19 23:21:08.041642\n",
      "resetting env. episode 4090, reward total was -19.0. running mean: -19.707788657119963, timestamp: 2022-08-19 23:21:12.576860\n",
      "resetting env. episode 4091, reward total was -20.0. running mean: -19.71071077054876, timestamp: 2022-08-19 23:21:16.795240\n",
      "resetting env. episode 4092, reward total was -19.0. running mean: -19.703603662843275, timestamp: 2022-08-19 23:21:20.999954\n",
      "resetting env. episode 4093, reward total was -19.0. running mean: -19.696567626214843, timestamp: 2022-08-19 23:21:24.711677\n",
      "resetting env. episode 4094, reward total was -18.0. running mean: -19.679601949952694, timestamp: 2022-08-19 23:21:28.874548\n",
      "resetting env. episode 4095, reward total was -18.0. running mean: -19.662805930453167, timestamp: 2022-08-19 23:21:33.522147\n",
      "resetting env. episode 4096, reward total was -20.0. running mean: -19.666177871148633, timestamp: 2022-08-19 23:21:38.076950\n",
      "resetting env. episode 4097, reward total was -21.0. running mean: -19.679516092437147, timestamp: 2022-08-19 23:21:42.473740\n",
      "resetting env. episode 4098, reward total was -18.0. running mean: -19.662720931512776, timestamp: 2022-08-19 23:21:48.006953\n",
      "resetting env. episode 4099, reward total was -20.0. running mean: -19.666093722197648, timestamp: 2022-08-19 23:21:52.465286\n",
      "resetting env. episode 4100, reward total was -18.0. running mean: -19.64943278497567, timestamp: 2022-08-19 23:21:58.181483\n",
      "resetting env. episode 4101, reward total was -20.0. running mean: -19.652938457125913, timestamp: 2022-08-19 23:22:03.681784\n",
      "resetting env. episode 4102, reward total was -19.0. running mean: -19.646409072554654, timestamp: 2022-08-19 23:22:08.466995\n",
      "resetting env. episode 4103, reward total was -21.0. running mean: -19.65994498182911, timestamp: 2022-08-19 23:22:14.965163\n",
      "resetting env. episode 4104, reward total was -21.0. running mean: -19.67334553201082, timestamp: 2022-08-19 23:22:22.363987\n",
      "resetting env. episode 4105, reward total was -18.0. running mean: -19.656612076690713, timestamp: 2022-08-19 23:22:31.307255\n",
      "resetting env. episode 4106, reward total was -18.0. running mean: -19.640045955923807, timestamp: 2022-08-19 23:22:39.472135\n",
      "resetting env. episode 4107, reward total was -19.0. running mean: -19.63364549636457, timestamp: 2022-08-19 23:22:47.159150\n",
      "resetting env. episode 4108, reward total was -18.0. running mean: -19.617309041400922, timestamp: 2022-08-19 23:22:52.438012\n",
      "resetting env. episode 4109, reward total was -19.0. running mean: -19.611135950986913, timestamp: 2022-08-19 23:23:00.274488\n",
      "resetting env. episode 4110, reward total was -21.0. running mean: -19.625024591477043, timestamp: 2022-08-19 23:23:04.866698\n",
      "resetting env. episode 4111, reward total was -21.0. running mean: -19.638774345562272, timestamp: 2022-08-19 23:23:10.390945\n",
      "resetting env. episode 4112, reward total was -20.0. running mean: -19.642386602106647, timestamp: 2022-08-19 23:23:15.432102\n",
      "resetting env. episode 4113, reward total was -21.0. running mean: -19.65596273608558, timestamp: 2022-08-19 23:23:21.830511\n",
      "resetting env. episode 4114, reward total was -20.0. running mean: -19.659403108724725, timestamp: 2022-08-19 23:23:28.522313\n",
      "resetting env. episode 4115, reward total was -19.0. running mean: -19.652809077637478, timestamp: 2022-08-19 23:23:32.367394\n",
      "resetting env. episode 4116, reward total was -21.0. running mean: -19.666280986861103, timestamp: 2022-08-19 23:23:36.276896\n",
      "resetting env. episode 4117, reward total was -21.0. running mean: -19.67961817699249, timestamp: 2022-08-19 23:23:44.323146\n",
      "resetting env. episode 4118, reward total was -17.0. running mean: -19.652821995222567, timestamp: 2022-08-19 23:23:52.387090\n",
      "resetting env. episode 4119, reward total was -21.0. running mean: -19.666293775270344, timestamp: 2022-08-19 23:23:57.471458\n",
      "resetting env. episode 4120, reward total was -19.0. running mean: -19.659630837517643, timestamp: 2022-08-19 23:24:04.102224\n",
      "resetting env. episode 4121, reward total was -20.0. running mean: -19.663034529142465, timestamp: 2022-08-19 23:24:09.368787\n",
      "resetting env. episode 4122, reward total was -19.0. running mean: -19.65640418385104, timestamp: 2022-08-19 23:24:16.171554\n",
      "resetting env. episode 4123, reward total was -20.0. running mean: -19.65984014201253, timestamp: 2022-08-19 23:24:21.722351\n",
      "resetting env. episode 4124, reward total was -19.0. running mean: -19.653241740592406, timestamp: 2022-08-19 23:24:27.362688\n",
      "resetting env. episode 4125, reward total was -21.0. running mean: -19.666709323186485, timestamp: 2022-08-19 23:24:31.953360\n",
      "resetting env. episode 4126, reward total was -20.0. running mean: -19.670042229954618, timestamp: 2022-08-19 23:24:35.720577\n",
      "resetting env. episode 4127, reward total was -20.0. running mean: -19.67334180765507, timestamp: 2022-08-19 23:24:39.306770\n",
      "resetting env. episode 4128, reward total was -21.0. running mean: -19.68660838957852, timestamp: 2022-08-19 23:24:43.954468\n",
      "resetting env. episode 4129, reward total was -16.0. running mean: -19.649742305682736, timestamp: 2022-08-19 23:24:50.194918\n",
      "resetting env. episode 4130, reward total was -19.0. running mean: -19.64324488262591, timestamp: 2022-08-19 23:24:54.583466\n",
      "resetting env. episode 4131, reward total was -18.0. running mean: -19.626812433799653, timestamp: 2022-08-19 23:25:00.228157\n",
      "resetting env. episode 4132, reward total was -21.0. running mean: -19.640544309461657, timestamp: 2022-08-19 23:25:04.590735\n",
      "resetting env. episode 4133, reward total was -21.0. running mean: -19.65413886636704, timestamp: 2022-08-19 23:25:09.336998\n",
      "resetting env. episode 4134, reward total was -19.0. running mean: -19.64759747770337, timestamp: 2022-08-19 23:25:14.616068\n",
      "resetting env. episode 4135, reward total was -20.0. running mean: -19.651121502926337, timestamp: 2022-08-19 23:25:18.819866\n",
      "resetting env. episode 4136, reward total was -19.0. running mean: -19.644610287897073, timestamp: 2022-08-19 23:25:23.043591\n",
      "resetting env. episode 4137, reward total was -20.0. running mean: -19.648164185018103, timestamp: 2022-08-19 23:25:26.798540\n",
      "resetting env. episode 4138, reward total was -21.0. running mean: -19.661682543167924, timestamp: 2022-08-19 23:25:30.749053\n",
      "resetting env. episode 4139, reward total was -19.0. running mean: -19.655065717736246, timestamp: 2022-08-19 23:25:34.642648\n",
      "resetting env. episode 4140, reward total was -19.0. running mean: -19.648515060558886, timestamp: 2022-08-19 23:25:38.729437\n",
      "resetting env. episode 4141, reward total was -19.0. running mean: -19.642029909953298, timestamp: 2022-08-19 23:25:46.474472\n",
      "resetting env. episode 4142, reward total was -21.0. running mean: -19.655609610853766, timestamp: 2022-08-19 23:25:51.580213\n",
      "resetting env. episode 4143, reward total was -20.0. running mean: -19.659053514745228, timestamp: 2022-08-19 23:25:55.571813\n",
      "resetting env. episode 4144, reward total was -20.0. running mean: -19.662462979597773, timestamp: 2022-08-19 23:26:00.567817\n",
      "resetting env. episode 4145, reward total was -18.0. running mean: -19.645838349801796, timestamp: 2022-08-19 23:26:05.672251\n",
      "resetting env. episode 4146, reward total was -21.0. running mean: -19.659379966303778, timestamp: 2022-08-19 23:26:10.281712\n",
      "resetting env. episode 4147, reward total was -21.0. running mean: -19.67278616664074, timestamp: 2022-08-19 23:26:13.949817\n",
      "resetting env. episode 4148, reward total was -19.0. running mean: -19.666058304974335, timestamp: 2022-08-19 23:26:17.969941\n",
      "resetting env. episode 4149, reward total was -21.0. running mean: -19.67939772192459, timestamp: 2022-08-19 23:26:21.888791\n",
      "resetting env. episode 4150, reward total was -16.0. running mean: -19.642603744705344, timestamp: 2022-08-19 23:26:28.043318\n",
      "resetting env. episode 4151, reward total was -21.0. running mean: -19.65617770725829, timestamp: 2022-08-19 23:26:32.664409\n",
      "resetting env. episode 4152, reward total was -21.0. running mean: -19.66961593018571, timestamp: 2022-08-19 23:26:36.380986\n",
      "resetting env. episode 4153, reward total was -19.0. running mean: -19.662919770883853, timestamp: 2022-08-19 23:26:42.516375\n",
      "resetting env. episode 4154, reward total was -18.0. running mean: -19.646290573175015, timestamp: 2022-08-19 23:26:47.446752\n",
      "resetting env. episode 4155, reward total was -18.0. running mean: -19.629827667443266, timestamp: 2022-08-19 23:26:52.160231\n",
      "resetting env. episode 4156, reward total was -20.0. running mean: -19.63352939076883, timestamp: 2022-08-19 23:26:55.634246\n",
      "resetting env. episode 4157, reward total was -21.0. running mean: -19.647194096861146, timestamp: 2022-08-19 23:27:00.334234\n",
      "resetting env. episode 4158, reward total was -21.0. running mean: -19.660722155892536, timestamp: 2022-08-19 23:27:03.861907\n",
      "resetting env. episode 4159, reward total was -19.0. running mean: -19.654114934333613, timestamp: 2022-08-19 23:27:07.435117\n",
      "resetting env. episode 4160, reward total was -19.0. running mean: -19.64757378499028, timestamp: 2022-08-19 23:27:12.490162\n",
      "resetting env. episode 4161, reward total was -20.0. running mean: -19.651098047140376, timestamp: 2022-08-19 23:27:16.984841\n",
      "resetting env. episode 4162, reward total was -19.0. running mean: -19.644587066668972, timestamp: 2022-08-19 23:27:20.355294\n",
      "resetting env. episode 4163, reward total was -21.0. running mean: -19.658141196002283, timestamp: 2022-08-19 23:27:23.870291\n",
      "resetting env. episode 4164, reward total was -20.0. running mean: -19.66155978404226, timestamp: 2022-08-19 23:27:28.607090\n",
      "resetting env. episode 4165, reward total was -21.0. running mean: -19.674944186201838, timestamp: 2022-08-19 23:27:33.180927\n",
      "resetting env. episode 4166, reward total was -18.0. running mean: -19.65819474433982, timestamp: 2022-08-19 23:27:38.152971\n",
      "resetting env. episode 4167, reward total was -21.0. running mean: -19.671612796896422, timestamp: 2022-08-19 23:27:42.387795\n",
      "resetting env. episode 4168, reward total was -21.0. running mean: -19.684896668927458, timestamp: 2022-08-19 23:27:46.611938\n",
      "resetting env. episode 4169, reward total was -21.0. running mean: -19.698047702238185, timestamp: 2022-08-19 23:27:51.525316\n",
      "resetting env. episode 4170, reward total was -19.0. running mean: -19.691067225215804, timestamp: 2022-08-19 23:27:55.880532\n",
      "resetting env. episode 4171, reward total was -21.0. running mean: -19.704156552963646, timestamp: 2022-08-19 23:28:00.114337\n",
      "resetting env. episode 4172, reward total was -21.0. running mean: -19.71711498743401, timestamp: 2022-08-19 23:28:04.206059\n",
      "resetting env. episode 4173, reward total was -21.0. running mean: -19.72994383755967, timestamp: 2022-08-19 23:28:08.123388\n",
      "resetting env. episode 4174, reward total was -21.0. running mean: -19.742644399184073, timestamp: 2022-08-19 23:28:12.555262\n",
      "resetting env. episode 4175, reward total was -21.0. running mean: -19.755217955192233, timestamp: 2022-08-19 23:28:18.578599\n",
      "resetting env. episode 4176, reward total was -18.0. running mean: -19.73766577564031, timestamp: 2022-08-19 23:28:23.548186\n",
      "resetting env. episode 4177, reward total was -19.0. running mean: -19.730289117883906, timestamp: 2022-08-19 23:28:28.358453\n",
      "resetting env. episode 4178, reward total was -18.0. running mean: -19.712986226705066, timestamp: 2022-08-19 23:28:33.406174\n",
      "resetting env. episode 4179, reward total was -15.0. running mean: -19.665856364438014, timestamp: 2022-08-19 23:28:39.331730\n",
      "resetting env. episode 4180, reward total was -19.0. running mean: -19.659197800793635, timestamp: 2022-08-19 23:28:44.397459\n",
      "resetting env. episode 4181, reward total was -20.0. running mean: -19.662605822785697, timestamp: 2022-08-19 23:28:48.813583\n",
      "resetting env. episode 4182, reward total was -21.0. running mean: -19.67597976455784, timestamp: 2022-08-19 23:28:53.074853\n",
      "resetting env. episode 4183, reward total was -18.0. running mean: -19.65921996691226, timestamp: 2022-08-19 23:28:58.540130\n",
      "resetting env. episode 4184, reward total was -19.0. running mean: -19.65262776724314, timestamp: 2022-08-19 23:29:04.801243\n",
      "resetting env. episode 4185, reward total was -19.0. running mean: -19.646101489570707, timestamp: 2022-08-19 23:29:09.482479\n",
      "resetting env. episode 4186, reward total was -19.0. running mean: -19.639640474675, timestamp: 2022-08-19 23:29:13.759201\n",
      "resetting env. episode 4187, reward total was -21.0. running mean: -19.653244069928252, timestamp: 2022-08-19 23:29:17.279444\n",
      "resetting env. episode 4188, reward total was -19.0. running mean: -19.64671162922897, timestamp: 2022-08-19 23:29:23.553544\n",
      "resetting env. episode 4189, reward total was -19.0. running mean: -19.640244512936682, timestamp: 2022-08-19 23:29:28.221539\n",
      "resetting env. episode 4190, reward total was -21.0. running mean: -19.653842067807318, timestamp: 2022-08-19 23:29:33.598988\n",
      "resetting env. episode 4191, reward total was -19.0. running mean: -19.647303647129245, timestamp: 2022-08-19 23:29:40.098034\n",
      "resetting env. episode 4192, reward total was -21.0. running mean: -19.660830610657953, timestamp: 2022-08-19 23:29:44.824121\n",
      "resetting env. episode 4193, reward total was -21.0. running mean: -19.674222304551375, timestamp: 2022-08-19 23:29:48.632362\n",
      "resetting env. episode 4194, reward total was -18.0. running mean: -19.65748008150586, timestamp: 2022-08-19 23:29:53.656184\n",
      "resetting env. episode 4195, reward total was -19.0. running mean: -19.6509052806908, timestamp: 2022-08-19 23:29:58.546270\n",
      "resetting env. episode 4196, reward total was -18.0. running mean: -19.63439622788389, timestamp: 2022-08-19 23:30:03.664780\n",
      "resetting env. episode 4197, reward total was -18.0. running mean: -19.61805226560505, timestamp: 2022-08-19 23:30:09.288727\n",
      "resetting env. episode 4198, reward total was -19.0. running mean: -19.611871742949003, timestamp: 2022-08-19 23:30:14.302868\n",
      "resetting env. episode 4199, reward total was -18.0. running mean: -19.595753025519514, timestamp: 2022-08-19 23:30:19.909765\n",
      "resetting env. episode 4200, reward total was -18.0. running mean: -19.579795495264317, timestamp: 2022-08-19 23:30:23.961656\n",
      "resetting env. episode 4201, reward total was -21.0. running mean: -19.593997540311676, timestamp: 2022-08-19 23:30:27.966674\n",
      "resetting env. episode 4202, reward total was -20.0. running mean: -19.598057564908558, timestamp: 2022-08-19 23:30:31.823898\n",
      "resetting env. episode 4203, reward total was -21.0. running mean: -19.612076989259474, timestamp: 2022-08-19 23:30:34.936959\n",
      "resetting env. episode 4204, reward total was -20.0. running mean: -19.61595621936688, timestamp: 2022-08-19 23:30:39.212640\n",
      "resetting env. episode 4205, reward total was -19.0. running mean: -19.609796657173213, timestamp: 2022-08-19 23:30:43.884792\n",
      "resetting env. episode 4206, reward total was -20.0. running mean: -19.61369869060148, timestamp: 2022-08-19 23:30:47.912416\n",
      "resetting env. episode 4207, reward total was -20.0. running mean: -19.617561703695465, timestamp: 2022-08-19 23:30:51.052731\n",
      "resetting env. episode 4208, reward total was -19.0. running mean: -19.611386086658513, timestamp: 2022-08-19 23:30:57.210637\n",
      "resetting env. episode 4209, reward total was -18.0. running mean: -19.595272225791927, timestamp: 2022-08-19 23:31:02.776095\n",
      "resetting env. episode 4210, reward total was -21.0. running mean: -19.609319503534007, timestamp: 2022-08-19 23:31:06.393209\n",
      "resetting env. episode 4211, reward total was -20.0. running mean: -19.613226308498664, timestamp: 2022-08-19 23:31:10.543195\n",
      "resetting env. episode 4212, reward total was -21.0. running mean: -19.627094045413678, timestamp: 2022-08-19 23:31:14.284775\n",
      "resetting env. episode 4213, reward total was -18.0. running mean: -19.61082310495954, timestamp: 2022-08-19 23:31:18.323198\n",
      "resetting env. episode 4214, reward total was -20.0. running mean: -19.614714873909943, timestamp: 2022-08-19 23:31:21.837130\n",
      "resetting env. episode 4215, reward total was -20.0. running mean: -19.61856772517084, timestamp: 2022-08-19 23:31:26.097286\n",
      "resetting env. episode 4216, reward total was -21.0. running mean: -19.632382047919133, timestamp: 2022-08-19 23:31:29.912985\n",
      "resetting env. episode 4217, reward total was -20.0. running mean: -19.636058227439943, timestamp: 2022-08-19 23:31:34.795396\n",
      "resetting env. episode 4218, reward total was -19.0. running mean: -19.629697645165546, timestamp: 2022-08-19 23:31:39.232430\n",
      "resetting env. episode 4219, reward total was -18.0. running mean: -19.61340066871389, timestamp: 2022-08-19 23:31:45.096823\n",
      "resetting env. episode 4220, reward total was -21.0. running mean: -19.627266662026752, timestamp: 2022-08-19 23:31:50.035093\n",
      "resetting env. episode 4221, reward total was -20.0. running mean: -19.630993995406484, timestamp: 2022-08-19 23:31:54.318342\n",
      "resetting env. episode 4222, reward total was -21.0. running mean: -19.64468405545242, timestamp: 2022-08-19 23:32:00.859994\n",
      "resetting env. episode 4223, reward total was -21.0. running mean: -19.658237214897895, timestamp: 2022-08-19 23:32:04.941636\n",
      "resetting env. episode 4224, reward total was -19.0. running mean: -19.65165484274892, timestamp: 2022-08-19 23:32:09.674163\n",
      "resetting env. episode 4225, reward total was -21.0. running mean: -19.66513829432143, timestamp: 2022-08-19 23:32:13.784687\n",
      "resetting env. episode 4226, reward total was -21.0. running mean: -19.678486911378215, timestamp: 2022-08-19 23:32:18.114907\n",
      "resetting env. episode 4227, reward total was -17.0. running mean: -19.651702042264436, timestamp: 2022-08-19 23:32:26.065942\n",
      "resetting env. episode 4228, reward total was -19.0. running mean: -19.645185021841794, timestamp: 2022-08-19 23:32:31.839874\n",
      "resetting env. episode 4229, reward total was -16.0. running mean: -19.608733171623374, timestamp: 2022-08-19 23:32:40.403304\n",
      "resetting env. episode 4230, reward total was -21.0. running mean: -19.62264583990714, timestamp: 2022-08-19 23:32:45.099091\n",
      "resetting env. episode 4231, reward total was -17.0. running mean: -19.59641938150807, timestamp: 2022-08-19 23:32:50.147564\n",
      "resetting env. episode 4232, reward total was -21.0. running mean: -19.610455187692992, timestamp: 2022-08-19 23:32:54.883189\n",
      "resetting env. episode 4233, reward total was -19.0. running mean: -19.60435063581606, timestamp: 2022-08-19 23:32:59.115589\n",
      "resetting env. episode 4234, reward total was -20.0. running mean: -19.6083071294579, timestamp: 2022-08-19 23:33:03.338384\n",
      "resetting env. episode 4235, reward total was -20.0. running mean: -19.612224058163317, timestamp: 2022-08-19 23:33:07.564087\n",
      "resetting env. episode 4236, reward total was -20.0. running mean: -19.616101817581683, timestamp: 2022-08-19 23:33:11.572070\n",
      "resetting env. episode 4237, reward total was -20.0. running mean: -19.619940799405864, timestamp: 2022-08-19 23:33:16.177418\n",
      "resetting env. episode 4238, reward total was -20.0. running mean: -19.623741391411805, timestamp: 2022-08-19 23:33:21.311458\n",
      "resetting env. episode 4239, reward total was -21.0. running mean: -19.637503977497687, timestamp: 2022-08-19 23:33:25.362537\n",
      "resetting env. episode 4240, reward total was -21.0. running mean: -19.65112893772271, timestamp: 2022-08-19 23:33:30.986714\n",
      "resetting env. episode 4241, reward total was -18.0. running mean: -19.634617648345483, timestamp: 2022-08-19 23:33:37.142912\n",
      "resetting env. episode 4242, reward total was -19.0. running mean: -19.62827147186203, timestamp: 2022-08-19 23:33:44.680745\n",
      "resetting env. episode 4243, reward total was -20.0. running mean: -19.631988757143407, timestamp: 2022-08-19 23:33:49.558706\n",
      "resetting env. episode 4244, reward total was -20.0. running mean: -19.635668869571973, timestamp: 2022-08-19 23:33:54.184341\n",
      "resetting env. episode 4245, reward total was -19.0. running mean: -19.629312180876255, timestamp: 2022-08-19 23:33:58.401070\n",
      "resetting env. episode 4246, reward total was -20.0. running mean: -19.633019059067493, timestamp: 2022-08-19 23:34:02.198918\n",
      "resetting env. episode 4247, reward total was -20.0. running mean: -19.636688868476817, timestamp: 2022-08-19 23:34:07.159668\n",
      "resetting env. episode 4248, reward total was -21.0. running mean: -19.65032197979205, timestamp: 2022-08-19 23:34:12.050661\n",
      "resetting env. episode 4249, reward total was -18.0. running mean: -19.633818759994128, timestamp: 2022-08-19 23:34:16.974466\n",
      "resetting env. episode 4250, reward total was -21.0. running mean: -19.647480572394187, timestamp: 2022-08-19 23:34:21.373719\n",
      "resetting env. episode 4251, reward total was -19.0. running mean: -19.641005766670247, timestamp: 2022-08-19 23:34:26.716294\n",
      "resetting env. episode 4252, reward total was -20.0. running mean: -19.644595709003543, timestamp: 2022-08-19 23:34:30.339609\n",
      "resetting env. episode 4253, reward total was -21.0. running mean: -19.65814975191351, timestamp: 2022-08-19 23:34:35.533332\n",
      "resetting env. episode 4254, reward total was -21.0. running mean: -19.671568254394376, timestamp: 2022-08-19 23:34:38.975128\n",
      "resetting env. episode 4255, reward total was -20.0. running mean: -19.674852571850433, timestamp: 2022-08-19 23:34:42.129104\n",
      "resetting env. episode 4256, reward total was -17.0. running mean: -19.64810404613193, timestamp: 2022-08-19 23:34:46.704780\n",
      "resetting env. episode 4257, reward total was -17.0. running mean: -19.621623005670614, timestamp: 2022-08-19 23:34:52.360856\n",
      "resetting env. episode 4258, reward total was -21.0. running mean: -19.63540677561391, timestamp: 2022-08-19 23:34:56.560304\n",
      "resetting env. episode 4259, reward total was -19.0. running mean: -19.62905270785777, timestamp: 2022-08-19 23:35:01.435916\n",
      "resetting env. episode 4260, reward total was -20.0. running mean: -19.632762180779192, timestamp: 2022-08-19 23:35:05.476810\n",
      "resetting env. episode 4261, reward total was -20.0. running mean: -19.6364345589714, timestamp: 2022-08-19 23:35:09.142011\n",
      "resetting env. episode 4262, reward total was -19.0. running mean: -19.630070213381686, timestamp: 2022-08-19 23:35:13.364255\n",
      "resetting env. episode 4263, reward total was -21.0. running mean: -19.643769511247868, timestamp: 2022-08-19 23:35:17.757513\n",
      "resetting env. episode 4264, reward total was -21.0. running mean: -19.65733181613539, timestamp: 2022-08-19 23:35:20.831392\n",
      "resetting env. episode 4265, reward total was -21.0. running mean: -19.670758497974035, timestamp: 2022-08-19 23:35:24.814385\n",
      "resetting env. episode 4266, reward total was -21.0. running mean: -19.684050912994294, timestamp: 2022-08-19 23:35:28.278961\n",
      "resetting env. episode 4267, reward total was -18.0. running mean: -19.667210403864352, timestamp: 2022-08-19 23:35:31.900103\n",
      "resetting env. episode 4268, reward total was -16.0. running mean: -19.63053829982571, timestamp: 2022-08-19 23:35:35.858911\n",
      "resetting env. episode 4269, reward total was -19.0. running mean: -19.624232916827452, timestamp: 2022-08-19 23:35:39.475740\n",
      "resetting env. episode 4270, reward total was -20.0. running mean: -19.627990587659177, timestamp: 2022-08-19 23:35:42.971965\n",
      "resetting env. episode 4271, reward total was -19.0. running mean: -19.621710681782588, timestamp: 2022-08-19 23:35:47.164094\n",
      "resetting env. episode 4272, reward total was -21.0. running mean: -19.635493574964762, timestamp: 2022-08-19 23:35:49.761175\n",
      "resetting env. episode 4273, reward total was -20.0. running mean: -19.639138639215115, timestamp: 2022-08-19 23:35:52.959624\n",
      "resetting env. episode 4274, reward total was -18.0. running mean: -19.622747252822965, timestamp: 2022-08-19 23:35:57.626240\n",
      "resetting env. episode 4275, reward total was -18.0. running mean: -19.606519780294736, timestamp: 2022-08-19 23:36:01.297246\n",
      "resetting env. episode 4276, reward total was -20.0. running mean: -19.610454582491787, timestamp: 2022-08-19 23:36:04.815842\n",
      "resetting env. episode 4277, reward total was -18.0. running mean: -19.594350036666867, timestamp: 2022-08-19 23:36:08.920806\n",
      "resetting env. episode 4278, reward total was -21.0. running mean: -19.608406536300198, timestamp: 2022-08-19 23:36:12.413888\n",
      "resetting env. episode 4279, reward total was -18.0. running mean: -19.592322470937194, timestamp: 2022-08-19 23:36:17.100914\n",
      "resetting env. episode 4280, reward total was -21.0. running mean: -19.606399246227824, timestamp: 2022-08-19 23:36:20.502191\n",
      "resetting env. episode 4281, reward total was -17.0. running mean: -19.580335253765547, timestamp: 2022-08-19 23:36:24.684217\n",
      "resetting env. episode 4282, reward total was -19.0. running mean: -19.574531901227893, timestamp: 2022-08-19 23:36:28.357402\n",
      "resetting env. episode 4283, reward total was -21.0. running mean: -19.588786582215615, timestamp: 2022-08-19 23:36:31.887963\n",
      "resetting env. episode 4284, reward total was -19.0. running mean: -19.58289871639346, timestamp: 2022-08-19 23:36:35.837416\n",
      "resetting env. episode 4285, reward total was -20.0. running mean: -19.587069729229523, timestamp: 2022-08-19 23:36:40.024190\n",
      "resetting env. episode 4286, reward total was -19.0. running mean: -19.581199031937228, timestamp: 2022-08-19 23:36:44.942764\n",
      "resetting env. episode 4287, reward total was -20.0. running mean: -19.585387041617853, timestamp: 2022-08-19 23:36:48.220189\n",
      "resetting env. episode 4288, reward total was -21.0. running mean: -19.599533171201674, timestamp: 2022-08-19 23:36:51.054433\n",
      "resetting env. episode 4289, reward total was -18.0. running mean: -19.583537839489658, timestamp: 2022-08-19 23:36:55.106108\n",
      "resetting env. episode 4290, reward total was -20.0. running mean: -19.58770246109476, timestamp: 2022-08-19 23:36:57.933718\n",
      "resetting env. episode 4291, reward total was -20.0. running mean: -19.591825436483813, timestamp: 2022-08-19 23:37:01.454226\n",
      "resetting env. episode 4292, reward total was -17.0. running mean: -19.565907182118977, timestamp: 2022-08-19 23:37:04.888673\n",
      "resetting env. episode 4293, reward total was -20.0. running mean: -19.570248110297786, timestamp: 2022-08-19 23:37:07.717385\n",
      "resetting env. episode 4294, reward total was -21.0. running mean: -19.58454562919481, timestamp: 2022-08-19 23:37:10.679182\n",
      "resetting env. episode 4295, reward total was -21.0. running mean: -19.598700172902863, timestamp: 2022-08-19 23:37:12.814428\n",
      "resetting env. episode 4296, reward total was -21.0. running mean: -19.612713171173834, timestamp: 2022-08-19 23:37:15.317670\n",
      "resetting env. episode 4297, reward total was -19.0. running mean: -19.606586039462098, timestamp: 2022-08-19 23:37:18.703094\n",
      "resetting env. episode 4298, reward total was -21.0. running mean: -19.620520179067476, timestamp: 2022-08-19 23:37:21.985420\n",
      "resetting env. episode 4299, reward total was -21.0. running mean: -19.6343149772768, timestamp: 2022-08-19 23:37:24.104835\n",
      "resetting env. episode 4300, reward total was -17.0. running mean: -19.607971827504034, timestamp: 2022-08-19 23:37:27.309956\n",
      "resetting env. episode 4301, reward total was -18.0. running mean: -19.591892109228993, timestamp: 2022-08-19 23:37:30.552200\n",
      "resetting env. episode 4302, reward total was -19.0. running mean: -19.585973188136705, timestamp: 2022-08-19 23:37:33.135242\n",
      "resetting env. episode 4303, reward total was -18.0. running mean: -19.57011345625534, timestamp: 2022-08-19 23:37:36.491962\n",
      "resetting env. episode 4304, reward total was -18.0. running mean: -19.554412321692784, timestamp: 2022-08-19 23:37:39.763658\n",
      "resetting env. episode 4305, reward total was -20.0. running mean: -19.558868198475857, timestamp: 2022-08-19 23:37:42.685926\n",
      "resetting env. episode 4306, reward total was -21.0. running mean: -19.573279516491098, timestamp: 2022-08-19 23:37:45.152250\n",
      "resetting env. episode 4307, reward total was -18.0. running mean: -19.557546721326187, timestamp: 2022-08-19 23:37:48.364470\n",
      "resetting env. episode 4308, reward total was -18.0. running mean: -19.541971254112923, timestamp: 2022-08-19 23:37:51.364966\n",
      "resetting env. episode 4309, reward total was -19.0. running mean: -19.536551541571797, timestamp: 2022-08-19 23:37:55.211352\n",
      "resetting env. episode 4310, reward total was -21.0. running mean: -19.551186026156078, timestamp: 2022-08-19 23:37:58.304969\n",
      "resetting env. episode 4311, reward total was -21.0. running mean: -19.565674165894517, timestamp: 2022-08-19 23:38:01.302132\n",
      "resetting env. episode 4312, reward total was -20.0. running mean: -19.570017424235573, timestamp: 2022-08-19 23:38:04.234752\n",
      "resetting env. episode 4313, reward total was -17.0. running mean: -19.54431724999322, timestamp: 2022-08-19 23:38:08.380614\n",
      "resetting env. episode 4314, reward total was -20.0. running mean: -19.548874077493288, timestamp: 2022-08-19 23:38:11.383877\n",
      "resetting env. episode 4315, reward total was -21.0. running mean: -19.563385336718355, timestamp: 2022-08-19 23:38:14.902817\n",
      "resetting env. episode 4316, reward total was -18.0. running mean: -19.54775148335117, timestamp: 2022-08-19 23:38:18.276458\n",
      "resetting env. episode 4317, reward total was -20.0. running mean: -19.552273968517657, timestamp: 2022-08-19 23:38:21.460935\n",
      "resetting env. episode 4318, reward total was -21.0. running mean: -19.56675122883248, timestamp: 2022-08-19 23:38:24.151916\n",
      "resetting env. episode 4319, reward total was -19.0. running mean: -19.561083716544157, timestamp: 2022-08-19 23:38:27.543757\n",
      "resetting env. episode 4320, reward total was -21.0. running mean: -19.575472879378715, timestamp: 2022-08-19 23:38:30.830990\n",
      "resetting env. episode 4321, reward total was -18.0. running mean: -19.559718150584928, timestamp: 2022-08-19 23:38:34.205027\n",
      "resetting env. episode 4322, reward total was -21.0. running mean: -19.57412096907908, timestamp: 2022-08-19 23:38:36.482034\n",
      "resetting env. episode 4323, reward total was -21.0. running mean: -19.58837975938829, timestamp: 2022-08-19 23:38:39.745120\n",
      "resetting env. episode 4324, reward total was -21.0. running mean: -19.602495961794407, timestamp: 2022-08-19 23:38:43.050096\n",
      "resetting env. episode 4325, reward total was -21.0. running mean: -19.616471002176464, timestamp: 2022-08-19 23:38:46.163094\n",
      "resetting env. episode 4326, reward total was -19.0. running mean: -19.6103062921547, timestamp: 2022-08-19 23:38:49.828245\n",
      "resetting env. episode 4327, reward total was -20.0. running mean: -19.61420322923315, timestamp: 2022-08-19 23:38:52.990575\n",
      "resetting env. episode 4328, reward total was -19.0. running mean: -19.60806119694082, timestamp: 2022-08-19 23:38:55.850111\n",
      "resetting env. episode 4329, reward total was -20.0. running mean: -19.611980584971413, timestamp: 2022-08-19 23:38:59.163068\n",
      "resetting env. episode 4330, reward total was -19.0. running mean: -19.6058607791217, timestamp: 2022-08-19 23:39:02.873018\n",
      "resetting env. episode 4331, reward total was -19.0. running mean: -19.599802171330484, timestamp: 2022-08-19 23:39:05.595532\n",
      "resetting env. episode 4332, reward total was -19.0. running mean: -19.59380414961718, timestamp: 2022-08-19 23:39:08.759265\n",
      "resetting env. episode 4333, reward total was -21.0. running mean: -19.60786610812101, timestamp: 2022-08-19 23:39:11.184575\n",
      "resetting env. episode 4334, reward total was -18.0. running mean: -19.5917874470398, timestamp: 2022-08-19 23:39:14.650496\n",
      "resetting env. episode 4335, reward total was -19.0. running mean: -19.5858695725694, timestamp: 2022-08-19 23:39:18.332094\n",
      "resetting env. episode 4336, reward total was -21.0. running mean: -19.600010876843708, timestamp: 2022-08-19 23:39:21.609207\n",
      "resetting env. episode 4337, reward total was -20.0. running mean: -19.60401076807527, timestamp: 2022-08-19 23:39:24.269014\n",
      "resetting env. episode 4338, reward total was -19.0. running mean: -19.59797066039452, timestamp: 2022-08-19 23:39:27.416449\n",
      "resetting env. episode 4339, reward total was -18.0. running mean: -19.581990953790573, timestamp: 2022-08-19 23:39:30.407656\n",
      "resetting env. episode 4340, reward total was -18.0. running mean: -19.566171044252666, timestamp: 2022-08-19 23:39:33.833150\n",
      "resetting env. episode 4341, reward total was -21.0. running mean: -19.58050933381014, timestamp: 2022-08-19 23:39:36.400337\n",
      "resetting env. episode 4342, reward total was -19.0. running mean: -19.57470424047204, timestamp: 2022-08-19 23:39:39.931641\n",
      "resetting env. episode 4343, reward total was -21.0. running mean: -19.58895719806732, timestamp: 2022-08-19 23:39:43.138384\n",
      "resetting env. episode 4344, reward total was -21.0. running mean: -19.60306762608665, timestamp: 2022-08-19 23:39:46.992083\n",
      "resetting env. episode 4345, reward total was -21.0. running mean: -19.61703694982578, timestamp: 2022-08-19 23:39:50.415966\n",
      "resetting env. episode 4346, reward total was -20.0. running mean: -19.620866580327522, timestamp: 2022-08-19 23:39:54.241363\n",
      "resetting env. episode 4347, reward total was -19.0. running mean: -19.614657914524248, timestamp: 2022-08-19 23:39:58.648833\n",
      "resetting env. episode 4348, reward total was -17.0. running mean: -19.588511335379007, timestamp: 2022-08-19 23:40:02.281329\n",
      "resetting env. episode 4349, reward total was -20.0. running mean: -19.592626222025217, timestamp: 2022-08-19 23:40:05.565133\n",
      "resetting env. episode 4350, reward total was -20.0. running mean: -19.596699959804965, timestamp: 2022-08-19 23:40:09.227603\n",
      "resetting env. episode 4351, reward total was -18.0. running mean: -19.580732960206916, timestamp: 2022-08-19 23:40:13.008234\n",
      "resetting env. episode 4352, reward total was -20.0. running mean: -19.584925630604847, timestamp: 2022-08-19 23:40:17.267842\n",
      "resetting env. episode 4353, reward total was -17.0. running mean: -19.5590763742988, timestamp: 2022-08-19 23:40:20.713524\n",
      "resetting env. episode 4354, reward total was -21.0. running mean: -19.573485610555814, timestamp: 2022-08-19 23:40:23.753890\n",
      "resetting env. episode 4355, reward total was -21.0. running mean: -19.587750754450255, timestamp: 2022-08-19 23:40:27.499384\n",
      "resetting env. episode 4356, reward total was -20.0. running mean: -19.591873246905752, timestamp: 2022-08-19 23:40:31.203413\n",
      "resetting env. episode 4357, reward total was -20.0. running mean: -19.595954514436695, timestamp: 2022-08-19 23:40:34.954096\n",
      "resetting env. episode 4358, reward total was -18.0. running mean: -19.57999496929233, timestamp: 2022-08-19 23:40:38.614306\n",
      "resetting env. episode 4359, reward total was -20.0. running mean: -19.584195019599406, timestamp: 2022-08-19 23:40:41.863678\n",
      "resetting env. episode 4360, reward total was -21.0. running mean: -19.598353069403412, timestamp: 2022-08-19 23:40:45.616326\n",
      "resetting env. episode 4361, reward total was -19.0. running mean: -19.59236953870938, timestamp: 2022-08-19 23:40:50.120874\n",
      "resetting env. episode 4362, reward total was -21.0. running mean: -19.606445843322287, timestamp: 2022-08-19 23:40:53.373012\n",
      "resetting env. episode 4363, reward total was -19.0. running mean: -19.600381384889065, timestamp: 2022-08-19 23:40:57.535811\n",
      "resetting env. episode 4364, reward total was -20.0. running mean: -19.604377571040175, timestamp: 2022-08-19 23:41:00.284379\n",
      "resetting env. episode 4365, reward total was -18.0. running mean: -19.588333795329774, timestamp: 2022-08-19 23:41:04.074462\n",
      "resetting env. episode 4366, reward total was -20.0. running mean: -19.592450457376476, timestamp: 2022-08-19 23:41:06.908886\n",
      "resetting env. episode 4367, reward total was -21.0. running mean: -19.606525952802713, timestamp: 2022-08-19 23:41:10.033535\n",
      "resetting env. episode 4368, reward total was -20.0. running mean: -19.610460693274685, timestamp: 2022-08-19 23:41:13.423296\n",
      "resetting env. episode 4369, reward total was -19.0. running mean: -19.60435608634194, timestamp: 2022-08-19 23:41:17.840489\n",
      "resetting env. episode 4370, reward total was -20.0. running mean: -19.60831252547852, timestamp: 2022-08-19 23:41:21.233452\n",
      "resetting env. episode 4371, reward total was -20.0. running mean: -19.612229400223736, timestamp: 2022-08-19 23:41:25.361140\n",
      "resetting env. episode 4372, reward total was -17.0. running mean: -19.5861071062215, timestamp: 2022-08-19 23:41:29.676607\n",
      "resetting env. episode 4373, reward total was -19.0. running mean: -19.580246035159288, timestamp: 2022-08-19 23:41:33.968857\n",
      "resetting env. episode 4374, reward total was -21.0. running mean: -19.594443574807695, timestamp: 2022-08-19 23:41:37.660495\n",
      "resetting env. episode 4375, reward total was -17.0. running mean: -19.568499139059618, timestamp: 2022-08-19 23:41:42.366857\n",
      "resetting env. episode 4376, reward total was -17.0. running mean: -19.542814147669024, timestamp: 2022-08-19 23:41:47.040310\n",
      "resetting env. episode 4377, reward total was -21.0. running mean: -19.557386006192335, timestamp: 2022-08-19 23:41:49.845179\n",
      "resetting env. episode 4378, reward total was -20.0. running mean: -19.56181214613041, timestamp: 2022-08-19 23:41:52.761357\n",
      "resetting env. episode 4379, reward total was -21.0. running mean: -19.576194024669107, timestamp: 2022-08-19 23:41:55.766414\n",
      "resetting env. episode 4380, reward total was -18.0. running mean: -19.560432084422416, timestamp: 2022-08-19 23:41:59.365616\n",
      "resetting env. episode 4381, reward total was -21.0. running mean: -19.57482776357819, timestamp: 2022-08-19 23:42:02.270203\n",
      "resetting env. episode 4382, reward total was -21.0. running mean: -19.58907948594241, timestamp: 2022-08-19 23:42:06.125513\n",
      "resetting env. episode 4383, reward total was -20.0. running mean: -19.593188691082986, timestamp: 2022-08-19 23:42:09.960778\n",
      "resetting env. episode 4384, reward total was -18.0. running mean: -19.577256804172155, timestamp: 2022-08-19 23:42:14.249758\n",
      "resetting env. episode 4385, reward total was -20.0. running mean: -19.581484236130432, timestamp: 2022-08-19 23:42:18.070748\n",
      "resetting env. episode 4386, reward total was -19.0. running mean: -19.57566939376913, timestamp: 2022-08-19 23:42:21.345971\n",
      "resetting env. episode 4387, reward total was -21.0. running mean: -19.589912699831437, timestamp: 2022-08-19 23:42:25.087383\n",
      "resetting env. episode 4388, reward total was -19.0. running mean: -19.584013572833125, timestamp: 2022-08-19 23:42:28.360147\n",
      "resetting env. episode 4389, reward total was -21.0. running mean: -19.598173437104794, timestamp: 2022-08-19 23:42:31.220502\n",
      "resetting env. episode 4390, reward total was -20.0. running mean: -19.602191702733744, timestamp: 2022-08-19 23:42:34.949476\n",
      "resetting env. episode 4391, reward total was -18.0. running mean: -19.586169785706407, timestamp: 2022-08-19 23:42:39.162774\n",
      "resetting env. episode 4392, reward total was -17.0. running mean: -19.560308087849343, timestamp: 2022-08-19 23:42:43.741427\n",
      "resetting env. episode 4393, reward total was -21.0. running mean: -19.57470500697085, timestamp: 2022-08-19 23:42:46.291611\n",
      "resetting env. episode 4394, reward total was -20.0. running mean: -19.57895795690114, timestamp: 2022-08-19 23:42:49.611871\n",
      "resetting env. episode 4395, reward total was -21.0. running mean: -19.593168377332127, timestamp: 2022-08-19 23:42:52.638299\n",
      "resetting env. episode 4396, reward total was -19.0. running mean: -19.587236693558808, timestamp: 2022-08-19 23:42:57.142734\n",
      "resetting env. episode 4397, reward total was -21.0. running mean: -19.60136432662322, timestamp: 2022-08-19 23:43:00.109131\n",
      "resetting env. episode 4398, reward total was -19.0. running mean: -19.595350683356987, timestamp: 2022-08-19 23:43:04.454745\n",
      "resetting env. episode 4399, reward total was -19.0. running mean: -19.58939717652342, timestamp: 2022-08-19 23:43:10.536490\n",
      "resetting env. episode 4400, reward total was -18.0. running mean: -19.573503204758186, timestamp: 2022-08-19 23:43:15.734699\n",
      "resetting env. episode 4401, reward total was -20.0. running mean: -19.577768172710602, timestamp: 2022-08-19 23:43:18.588490\n",
      "resetting env. episode 4402, reward total was -18.0. running mean: -19.561990490983497, timestamp: 2022-08-19 23:43:21.761486\n",
      "resetting env. episode 4403, reward total was -20.0. running mean: -19.56637058607366, timestamp: 2022-08-19 23:43:24.179723\n",
      "resetting env. episode 4404, reward total was -20.0. running mean: -19.57070688021292, timestamp: 2022-08-19 23:43:27.653163\n",
      "resetting env. episode 4405, reward total was -20.0. running mean: -19.57499981141079, timestamp: 2022-08-19 23:43:30.466143\n",
      "resetting env. episode 4406, reward total was -21.0. running mean: -19.589249813296682, timestamp: 2022-08-19 23:43:33.608346\n",
      "resetting env. episode 4407, reward total was -19.0. running mean: -19.583357315163717, timestamp: 2022-08-19 23:43:36.796941\n",
      "resetting env. episode 4408, reward total was -20.0. running mean: -19.587523742012078, timestamp: 2022-08-19 23:43:39.796680\n",
      "resetting env. episode 4409, reward total was -20.0. running mean: -19.591648504591955, timestamp: 2022-08-19 23:43:42.037664\n",
      "resetting env. episode 4410, reward total was -20.0. running mean: -19.595732019546034, timestamp: 2022-08-19 23:43:44.675272\n",
      "resetting env. episode 4411, reward total was -21.0. running mean: -19.609774699350574, timestamp: 2022-08-19 23:43:47.024475\n",
      "resetting env. episode 4412, reward total was -19.0. running mean: -19.60367695235707, timestamp: 2022-08-19 23:43:49.765320\n",
      "resetting env. episode 4413, reward total was -17.0. running mean: -19.577640182833502, timestamp: 2022-08-19 23:43:53.313736\n",
      "resetting env. episode 4414, reward total was -21.0. running mean: -19.591863781005166, timestamp: 2022-08-19 23:43:55.761657\n",
      "resetting env. episode 4415, reward total was -20.0. running mean: -19.595945143195113, timestamp: 2022-08-19 23:43:59.600651\n",
      "resetting env. episode 4416, reward total was -20.0. running mean: -19.599985691763163, timestamp: 2022-08-19 23:44:02.763242\n",
      "resetting env. episode 4417, reward total was -21.0. running mean: -19.613985834845533, timestamp: 2022-08-19 23:44:05.489952\n",
      "resetting env. episode 4418, reward total was -19.0. running mean: -19.607845976497078, timestamp: 2022-08-19 23:44:08.078091\n",
      "resetting env. episode 4419, reward total was -18.0. running mean: -19.59176751673211, timestamp: 2022-08-19 23:44:10.948378\n",
      "resetting env. episode 4420, reward total was -18.0. running mean: -19.575849841564786, timestamp: 2022-08-19 23:44:13.790246\n",
      "resetting env. episode 4421, reward total was -20.0. running mean: -19.580091343149135, timestamp: 2022-08-19 23:44:16.674642\n",
      "resetting env. episode 4422, reward total was -21.0. running mean: -19.594290429717645, timestamp: 2022-08-19 23:44:18.784396\n",
      "resetting env. episode 4423, reward total was -18.0. running mean: -19.57834752542047, timestamp: 2022-08-19 23:44:22.097601\n",
      "resetting env. episode 4424, reward total was -21.0. running mean: -19.592564050166263, timestamp: 2022-08-19 23:44:25.296276\n",
      "resetting env. episode 4425, reward total was -19.0. running mean: -19.5866384096646, timestamp: 2022-08-19 23:44:28.042643\n",
      "resetting env. episode 4426, reward total was -20.0. running mean: -19.590772025567954, timestamp: 2022-08-19 23:44:32.011069\n",
      "resetting env. episode 4427, reward total was -19.0. running mean: -19.584864305312276, timestamp: 2022-08-19 23:44:35.367447\n",
      "resetting env. episode 4428, reward total was -19.0. running mean: -19.579015662259156, timestamp: 2022-08-19 23:44:38.419354\n",
      "resetting env. episode 4429, reward total was -21.0. running mean: -19.593225505636564, timestamp: 2022-08-19 23:44:41.065174\n",
      "resetting env. episode 4430, reward total was -20.0. running mean: -19.597293250580197, timestamp: 2022-08-19 23:44:44.387595\n",
      "resetting env. episode 4431, reward total was -18.0. running mean: -19.581320318074393, timestamp: 2022-08-19 23:44:48.867947\n",
      "resetting env. episode 4432, reward total was -21.0. running mean: -19.59550711489365, timestamp: 2022-08-19 23:44:51.400508\n",
      "resetting env. episode 4433, reward total was -19.0. running mean: -19.589552043744714, timestamp: 2022-08-19 23:44:54.389910\n",
      "resetting env. episode 4434, reward total was -19.0. running mean: -19.58365652330727, timestamp: 2022-08-19 23:44:57.542244\n",
      "resetting env. episode 4435, reward total was -19.0. running mean: -19.577819958074198, timestamp: 2022-08-19 23:45:00.781099\n",
      "resetting env. episode 4436, reward total was -21.0. running mean: -19.592041758493455, timestamp: 2022-08-19 23:45:03.649568\n",
      "resetting env. episode 4437, reward total was -19.0. running mean: -19.586121340908523, timestamp: 2022-08-19 23:45:06.359047\n",
      "resetting env. episode 4438, reward total was -21.0. running mean: -19.60026012749944, timestamp: 2022-08-19 23:45:09.386954\n",
      "resetting env. episode 4439, reward total was -18.0. running mean: -19.584257526224444, timestamp: 2022-08-19 23:45:12.407035\n",
      "resetting env. episode 4440, reward total was -21.0. running mean: -19.5984149509622, timestamp: 2022-08-19 23:45:15.564303\n",
      "resetting env. episode 4441, reward total was -19.0. running mean: -19.59243080145258, timestamp: 2022-08-19 23:45:19.068071\n",
      "resetting env. episode 4442, reward total was -21.0. running mean: -19.606506493438054, timestamp: 2022-08-19 23:45:21.410416\n",
      "resetting env. episode 4443, reward total was -20.0. running mean: -19.610441428503673, timestamp: 2022-08-19 23:45:23.716851\n",
      "resetting env. episode 4444, reward total was -20.0. running mean: -19.614337014218634, timestamp: 2022-08-19 23:45:26.083296\n",
      "resetting env. episode 4445, reward total was -17.0. running mean: -19.588193644076448, timestamp: 2022-08-19 23:45:29.470590\n",
      "resetting env. episode 4446, reward total was -17.0. running mean: -19.562311707635686, timestamp: 2022-08-19 23:45:32.851529\n",
      "resetting env. episode 4447, reward total was -21.0. running mean: -19.57668859055933, timestamp: 2022-08-19 23:45:36.072575\n",
      "resetting env. episode 4448, reward total was -16.0. running mean: -19.540921704653734, timestamp: 2022-08-19 23:45:40.061362\n",
      "resetting env. episode 4449, reward total was -18.0. running mean: -19.525512487607195, timestamp: 2022-08-19 23:45:44.099969\n",
      "resetting env. episode 4450, reward total was -21.0. running mean: -19.540257362731122, timestamp: 2022-08-19 23:45:47.208624\n",
      "resetting env. episode 4451, reward total was -17.0. running mean: -19.51485478910381, timestamp: 2022-08-19 23:45:50.476593\n",
      "resetting env. episode 4452, reward total was -20.0. running mean: -19.519706241212774, timestamp: 2022-08-19 23:45:53.939879\n",
      "resetting env. episode 4453, reward total was -19.0. running mean: -19.514509178800648, timestamp: 2022-08-19 23:45:58.108736\n",
      "resetting env. episode 4454, reward total was -20.0. running mean: -19.51936408701264, timestamp: 2022-08-19 23:46:01.781390\n",
      "resetting env. episode 4455, reward total was -19.0. running mean: -19.514170446142515, timestamp: 2022-08-19 23:46:05.061269\n",
      "resetting env. episode 4456, reward total was -19.0. running mean: -19.509028741681092, timestamp: 2022-08-19 23:46:08.310322\n",
      "resetting env. episode 4457, reward total was -20.0. running mean: -19.51393845426428, timestamp: 2022-08-19 23:46:11.333241\n",
      "resetting env. episode 4458, reward total was -18.0. running mean: -19.49879906972164, timestamp: 2022-08-19 23:46:16.547487\n",
      "resetting env. episode 4459, reward total was -19.0. running mean: -19.49381107902442, timestamp: 2022-08-19 23:46:20.453747\n",
      "resetting env. episode 4460, reward total was -21.0. running mean: -19.50887296823418, timestamp: 2022-08-19 23:46:23.318909\n",
      "resetting env. episode 4461, reward total was -19.0. running mean: -19.503784238551837, timestamp: 2022-08-19 23:46:27.140854\n",
      "resetting env. episode 4462, reward total was -19.0. running mean: -19.49874639616632, timestamp: 2022-08-19 23:46:30.705060\n",
      "resetting env. episode 4463, reward total was -20.0. running mean: -19.503758932204658, timestamp: 2022-08-19 23:46:33.916123\n",
      "resetting env. episode 4464, reward total was -19.0. running mean: -19.49872134288261, timestamp: 2022-08-19 23:46:38.358809\n",
      "resetting env. episode 4465, reward total was -18.0. running mean: -19.483734129453783, timestamp: 2022-08-19 23:46:41.516979\n",
      "resetting env. episode 4466, reward total was -21.0. running mean: -19.498896788159247, timestamp: 2022-08-19 23:46:44.708813\n",
      "resetting env. episode 4467, reward total was -19.0. running mean: -19.493907820277656, timestamp: 2022-08-19 23:46:48.340628\n",
      "resetting env. episode 4468, reward total was -18.0. running mean: -19.47896874207488, timestamp: 2022-08-19 23:46:52.660148\n",
      "resetting env. episode 4469, reward total was -19.0. running mean: -19.474179054654133, timestamp: 2022-08-19 23:46:56.436874\n",
      "resetting env. episode 4470, reward total was -18.0. running mean: -19.459437264107592, timestamp: 2022-08-19 23:47:00.570377\n",
      "resetting env. episode 4471, reward total was -20.0. running mean: -19.464842891466514, timestamp: 2022-08-19 23:47:04.648360\n",
      "resetting env. episode 4472, reward total was -21.0. running mean: -19.48019446255185, timestamp: 2022-08-19 23:47:08.056739\n",
      "resetting env. episode 4473, reward total was -21.0. running mean: -19.495392517926334, timestamp: 2022-08-19 23:47:11.581671\n",
      "resetting env. episode 4474, reward total was -19.0. running mean: -19.490438592747072, timestamp: 2022-08-19 23:47:15.245878\n",
      "resetting env. episode 4475, reward total was -21.0. running mean: -19.5055342068196, timestamp: 2022-08-19 23:47:18.309615\n",
      "resetting env. episode 4476, reward total was -21.0. running mean: -19.520478864751404, timestamp: 2022-08-19 23:47:21.180413\n",
      "resetting env. episode 4477, reward total was -19.0. running mean: -19.51527407610389, timestamp: 2022-08-19 23:47:24.781111\n",
      "resetting env. episode 4478, reward total was -18.0. running mean: -19.50012133534285, timestamp: 2022-08-19 23:47:29.675345\n",
      "resetting env. episode 4479, reward total was -20.0. running mean: -19.50512012198942, timestamp: 2022-08-19 23:47:33.037574\n",
      "resetting env. episode 4480, reward total was -18.0. running mean: -19.490068920769527, timestamp: 2022-08-19 23:47:36.786605\n",
      "resetting env. episode 4481, reward total was -18.0. running mean: -19.47516823156183, timestamp: 2022-08-19 23:47:40.686614\n",
      "resetting env. episode 4482, reward total was -20.0. running mean: -19.48041654924621, timestamp: 2022-08-19 23:47:44.371886\n",
      "resetting env. episode 4483, reward total was -19.0. running mean: -19.47561238375375, timestamp: 2022-08-19 23:47:47.558458\n",
      "resetting env. episode 4484, reward total was -20.0. running mean: -19.48085625991621, timestamp: 2022-08-19 23:47:51.390732\n",
      "resetting env. episode 4485, reward total was -19.0. running mean: -19.476047697317046, timestamp: 2022-08-19 23:47:55.000409\n",
      "resetting env. episode 4486, reward total was -21.0. running mean: -19.491287220343878, timestamp: 2022-08-19 23:47:58.266113\n",
      "resetting env. episode 4487, reward total was -19.0. running mean: -19.48637434814044, timestamp: 2022-08-19 23:48:03.447453\n",
      "resetting env. episode 4488, reward total was -21.0. running mean: -19.501510604659035, timestamp: 2022-08-19 23:48:07.528353\n",
      "resetting env. episode 4489, reward total was -21.0. running mean: -19.516495498612446, timestamp: 2022-08-19 23:48:10.523912\n",
      "resetting env. episode 4490, reward total was -18.0. running mean: -19.50133054362632, timestamp: 2022-08-19 23:48:14.337217\n",
      "resetting env. episode 4491, reward total was -21.0. running mean: -19.51631723819006, timestamp: 2022-08-19 23:48:18.027532\n",
      "resetting env. episode 4492, reward total was -18.0. running mean: -19.50115406580816, timestamp: 2022-08-19 23:48:22.413256\n",
      "resetting env. episode 4493, reward total was -19.0. running mean: -19.496142525150077, timestamp: 2022-08-19 23:48:26.417908\n",
      "resetting env. episode 4494, reward total was -19.0. running mean: -19.491181099898576, timestamp: 2022-08-19 23:48:30.446474\n",
      "resetting env. episode 4495, reward total was -17.0. running mean: -19.466269288899593, timestamp: 2022-08-19 23:48:34.206474\n",
      "resetting env. episode 4496, reward total was -20.0. running mean: -19.471606596010595, timestamp: 2022-08-19 23:48:37.997875\n",
      "resetting env. episode 4497, reward total was -20.0. running mean: -19.47689053005049, timestamp: 2022-08-19 23:48:41.767908\n",
      "resetting env. episode 4498, reward total was -21.0. running mean: -19.492121624749984, timestamp: 2022-08-19 23:48:44.924750\n",
      "resetting env. episode 4499, reward total was -21.0. running mean: -19.507200408502484, timestamp: 2022-08-19 23:48:48.350525\n",
      "resetting env. episode 4500, reward total was -21.0. running mean: -19.52212840441746, timestamp: 2022-08-19 23:48:51.107874\n",
      "resetting env. episode 4501, reward total was -19.0. running mean: -19.51690712037329, timestamp: 2022-08-19 23:48:54.425734\n",
      "resetting env. episode 4502, reward total was -21.0. running mean: -19.531738049169558, timestamp: 2022-08-19 23:48:57.744053\n",
      "resetting env. episode 4503, reward total was -20.0. running mean: -19.536420668677863, timestamp: 2022-08-19 23:49:01.177844\n",
      "resetting env. episode 4504, reward total was -18.0. running mean: -19.521056461991083, timestamp: 2022-08-19 23:49:05.062552\n",
      "resetting env. episode 4505, reward total was -19.0. running mean: -19.515845897371175, timestamp: 2022-08-19 23:49:09.084212\n",
      "resetting env. episode 4506, reward total was -21.0. running mean: -19.530687438397464, timestamp: 2022-08-19 23:49:12.654728\n",
      "resetting env. episode 4507, reward total was -19.0. running mean: -19.525380564013492, timestamp: 2022-08-19 23:49:16.058665\n",
      "resetting env. episode 4508, reward total was -19.0. running mean: -19.520126758373358, timestamp: 2022-08-19 23:49:19.582133\n",
      "resetting env. episode 4509, reward total was -21.0. running mean: -19.534925490789625, timestamp: 2022-08-19 23:49:22.552016\n",
      "resetting env. episode 4510, reward total was -21.0. running mean: -19.54957623588173, timestamp: 2022-08-19 23:49:25.638151\n",
      "resetting env. episode 4511, reward total was -19.0. running mean: -19.544080473522914, timestamp: 2022-08-19 23:49:29.482237\n",
      "resetting env. episode 4512, reward total was -21.0. running mean: -19.558639668787684, timestamp: 2022-08-19 23:49:31.759230\n",
      "resetting env. episode 4513, reward total was -20.0. running mean: -19.563053272099808, timestamp: 2022-08-19 23:49:34.669450\n",
      "resetting env. episode 4514, reward total was -21.0. running mean: -19.57742273937881, timestamp: 2022-08-19 23:49:38.595893\n",
      "resetting env. episode 4515, reward total was -18.0. running mean: -19.561648511985023, timestamp: 2022-08-19 23:49:42.547921\n",
      "resetting env. episode 4516, reward total was -21.0. running mean: -19.576032026865175, timestamp: 2022-08-19 23:49:45.230118\n",
      "resetting env. episode 4517, reward total was -20.0. running mean: -19.580271706596523, timestamp: 2022-08-19 23:49:47.933680\n",
      "resetting env. episode 4518, reward total was -19.0. running mean: -19.57446898953056, timestamp: 2022-08-19 23:49:50.755171\n",
      "resetting env. episode 4519, reward total was -19.0. running mean: -19.568724299635253, timestamp: 2022-08-19 23:49:54.338939\n",
      "resetting env. episode 4520, reward total was -21.0. running mean: -19.5830370566389, timestamp: 2022-08-19 23:49:57.301028\n",
      "resetting env. episode 4521, reward total was -21.0. running mean: -19.59720668607251, timestamp: 2022-08-19 23:50:00.680324\n",
      "resetting env. episode 4522, reward total was -16.0. running mean: -19.561234619211785, timestamp: 2022-08-19 23:50:04.524444\n",
      "resetting env. episode 4523, reward total was -18.0. running mean: -19.545622273019667, timestamp: 2022-08-19 23:50:07.680790\n",
      "resetting env. episode 4524, reward total was -18.0. running mean: -19.53016605028947, timestamp: 2022-08-19 23:50:10.952151\n",
      "resetting env. episode 4525, reward total was -20.0. running mean: -19.534864389786573, timestamp: 2022-08-19 23:50:14.245725\n",
      "resetting env. episode 4526, reward total was -19.0. running mean: -19.52951574588871, timestamp: 2022-08-19 23:50:17.017347\n",
      "resetting env. episode 4527, reward total was -21.0. running mean: -19.544220588429823, timestamp: 2022-08-19 23:50:20.668922\n",
      "resetting env. episode 4528, reward total was -21.0. running mean: -19.558778382545526, timestamp: 2022-08-19 23:50:24.263322\n",
      "resetting env. episode 4529, reward total was -19.0. running mean: -19.55319059872007, timestamp: 2022-08-19 23:50:27.501467\n",
      "resetting env. episode 4530, reward total was -20.0. running mean: -19.55765869273287, timestamp: 2022-08-19 23:50:30.605570\n",
      "resetting env. episode 4531, reward total was -20.0. running mean: -19.56208210580554, timestamp: 2022-08-19 23:50:34.263688\n",
      "resetting env. episode 4532, reward total was -19.0. running mean: -19.556461284747485, timestamp: 2022-08-19 23:50:36.897839\n",
      "resetting env. episode 4533, reward total was -21.0. running mean: -19.570896671900012, timestamp: 2022-08-19 23:50:39.780192\n",
      "resetting env. episode 4534, reward total was -18.0. running mean: -19.555187705181012, timestamp: 2022-08-19 23:50:43.409860\n",
      "resetting env. episode 4535, reward total was -21.0. running mean: -19.569635828129204, timestamp: 2022-08-19 23:50:46.478801\n",
      "resetting env. episode 4536, reward total was -20.0. running mean: -19.57393946984791, timestamp: 2022-08-19 23:50:49.889004\n",
      "resetting env. episode 4537, reward total was -19.0. running mean: -19.568200075149434, timestamp: 2022-08-19 23:50:53.201131\n",
      "resetting env. episode 4538, reward total was -19.0. running mean: -19.562518074397943, timestamp: 2022-08-19 23:50:58.518912\n",
      "resetting env. episode 4539, reward total was -19.0. running mean: -19.556892893653963, timestamp: 2022-08-19 23:51:03.230320\n",
      "resetting env. episode 4540, reward total was -19.0. running mean: -19.551323964717426, timestamp: 2022-08-19 23:51:06.681094\n",
      "resetting env. episode 4541, reward total was -18.0. running mean: -19.535810725070252, timestamp: 2022-08-19 23:51:11.537113\n",
      "resetting env. episode 4542, reward total was -16.0. running mean: -19.50045261781955, timestamp: 2022-08-19 23:51:16.166137\n",
      "resetting env. episode 4543, reward total was -20.0. running mean: -19.505448091641355, timestamp: 2022-08-19 23:51:19.049037\n",
      "resetting env. episode 4544, reward total was -21.0. running mean: -19.52039361072494, timestamp: 2022-08-19 23:51:23.457361\n",
      "resetting env. episode 4545, reward total was -21.0. running mean: -19.535189674617694, timestamp: 2022-08-19 23:51:27.604479\n",
      "resetting env. episode 4546, reward total was -20.0. running mean: -19.539837777871515, timestamp: 2022-08-19 23:51:32.403757\n",
      "resetting env. episode 4547, reward total was -20.0. running mean: -19.5444394000928, timestamp: 2022-08-19 23:51:35.678823\n",
      "resetting env. episode 4548, reward total was -21.0. running mean: -19.55899500609187, timestamp: 2022-08-19 23:51:38.999339\n",
      "resetting env. episode 4549, reward total was -17.0. running mean: -19.53340505603095, timestamp: 2022-08-19 23:51:42.712453\n",
      "resetting env. episode 4550, reward total was -20.0. running mean: -19.53807100547064, timestamp: 2022-08-19 23:51:45.896813\n",
      "resetting env. episode 4551, reward total was -21.0. running mean: -19.552690295415935, timestamp: 2022-08-19 23:51:49.227094\n",
      "resetting env. episode 4552, reward total was -17.0. running mean: -19.527163392461777, timestamp: 2022-08-19 23:51:52.970278\n",
      "resetting env. episode 4553, reward total was -21.0. running mean: -19.541891758537158, timestamp: 2022-08-19 23:51:55.586776\n",
      "resetting env. episode 4554, reward total was -18.0. running mean: -19.526472840951786, timestamp: 2022-08-19 23:51:59.277899\n",
      "resetting env. episode 4555, reward total was -20.0. running mean: -19.531208112542267, timestamp: 2022-08-19 23:52:03.390270\n",
      "resetting env. episode 4556, reward total was -20.0. running mean: -19.535896031416843, timestamp: 2022-08-19 23:52:06.595278\n",
      "resetting env. episode 4557, reward total was -17.0. running mean: -19.510537071102675, timestamp: 2022-08-19 23:52:10.764163\n",
      "resetting env. episode 4558, reward total was -18.0. running mean: -19.49543170039165, timestamp: 2022-08-19 23:52:14.247824\n",
      "resetting env. episode 4559, reward total was -20.0. running mean: -19.500477383387732, timestamp: 2022-08-19 23:52:18.255268\n",
      "resetting env. episode 4560, reward total was -18.0. running mean: -19.485472609553856, timestamp: 2022-08-19 23:52:21.547083\n",
      "resetting env. episode 4561, reward total was -21.0. running mean: -19.500617883458318, timestamp: 2022-08-19 23:52:24.407045\n",
      "resetting env. episode 4562, reward total was -21.0. running mean: -19.515611704623737, timestamp: 2022-08-19 23:52:28.176419\n",
      "resetting env. episode 4563, reward total was -21.0. running mean: -19.5304555875775, timestamp: 2022-08-19 23:52:30.847336\n",
      "resetting env. episode 4564, reward total was -16.0. running mean: -19.495151031701724, timestamp: 2022-08-19 23:52:34.764922\n",
      "resetting env. episode 4565, reward total was -19.0. running mean: -19.490199521384707, timestamp: 2022-08-19 23:52:38.591658\n",
      "resetting env. episode 4566, reward total was -19.0. running mean: -19.48529752617086, timestamp: 2022-08-19 23:52:42.002758\n",
      "resetting env. episode 4567, reward total was -21.0. running mean: -19.50044455090915, timestamp: 2022-08-19 23:52:45.058884\n",
      "resetting env. episode 4568, reward total was -21.0. running mean: -19.51544010540006, timestamp: 2022-08-19 23:52:49.146795\n",
      "resetting env. episode 4569, reward total was -20.0. running mean: -19.52028570434606, timestamp: 2022-08-19 23:52:52.386549\n",
      "resetting env. episode 4570, reward total was -21.0. running mean: -19.535082847302597, timestamp: 2022-08-19 23:52:55.949637\n",
      "resetting env. episode 4571, reward total was -19.0. running mean: -19.529732018829574, timestamp: 2022-08-19 23:52:58.750201\n",
      "resetting env. episode 4572, reward total was -21.0. running mean: -19.54443469864128, timestamp: 2022-08-19 23:53:03.511112\n",
      "resetting env. episode 4573, reward total was -20.0. running mean: -19.548990351654865, timestamp: 2022-08-19 23:53:07.321942\n",
      "resetting env. episode 4574, reward total was -20.0. running mean: -19.553500448138315, timestamp: 2022-08-19 23:53:10.978031\n",
      "resetting env. episode 4575, reward total was -21.0. running mean: -19.567965443656934, timestamp: 2022-08-19 23:53:14.536409\n",
      "resetting env. episode 4576, reward total was -18.0. running mean: -19.552285789220363, timestamp: 2022-08-19 23:53:18.610148\n",
      "resetting env. episode 4577, reward total was -19.0. running mean: -19.54676293132816, timestamp: 2022-08-19 23:53:22.335241\n",
      "resetting env. episode 4578, reward total was -19.0. running mean: -19.54129530201488, timestamp: 2022-08-19 23:53:26.621304\n",
      "resetting env. episode 4579, reward total was -19.0. running mean: -19.535882348994733, timestamp: 2022-08-19 23:53:30.166246\n",
      "resetting env. episode 4580, reward total was -21.0. running mean: -19.550523525504786, timestamp: 2022-08-19 23:53:33.393521\n",
      "resetting env. episode 4581, reward total was -20.0. running mean: -19.555018290249738, timestamp: 2022-08-19 23:53:36.703711\n",
      "resetting env. episode 4582, reward total was -19.0. running mean: -19.54946810734724, timestamp: 2022-08-19 23:53:40.116510\n",
      "resetting env. episode 4583, reward total was -20.0. running mean: -19.553973426273767, timestamp: 2022-08-19 23:53:42.835740\n",
      "resetting env. episode 4584, reward total was -18.0. running mean: -19.53843369201103, timestamp: 2022-08-19 23:53:47.554285\n",
      "resetting env. episode 4585, reward total was -21.0. running mean: -19.55304935509092, timestamp: 2022-08-19 23:53:51.616702\n",
      "resetting env. episode 4586, reward total was -18.0. running mean: -19.53751886154001, timestamp: 2022-08-19 23:53:55.746231\n",
      "resetting env. episode 4587, reward total was -20.0. running mean: -19.54214367292461, timestamp: 2022-08-19 23:53:58.646205\n",
      "resetting env. episode 4588, reward total was -21.0. running mean: -19.556722236195363, timestamp: 2022-08-19 23:54:02.372877\n",
      "resetting env. episode 4589, reward total was -21.0. running mean: -19.57115501383341, timestamp: 2022-08-19 23:54:05.597599\n",
      "resetting env. episode 4590, reward total was -17.0. running mean: -19.545443463695076, timestamp: 2022-08-19 23:54:09.291982\n",
      "resetting env. episode 4591, reward total was -19.0. running mean: -19.539989029058127, timestamp: 2022-08-19 23:54:13.071091\n",
      "resetting env. episode 4592, reward total was -20.0. running mean: -19.544589138767545, timestamp: 2022-08-19 23:54:16.311496\n",
      "resetting env. episode 4593, reward total was -20.0. running mean: -19.54914324737987, timestamp: 2022-08-19 23:54:20.316181\n",
      "resetting env. episode 4594, reward total was -21.0. running mean: -19.563651814906073, timestamp: 2022-08-19 23:54:22.835556\n",
      "resetting env. episode 4595, reward total was -19.0. running mean: -19.558015296757013, timestamp: 2022-08-19 23:54:27.161522\n",
      "resetting env. episode 4596, reward total was -18.0. running mean: -19.542435143789444, timestamp: 2022-08-19 23:54:31.488907\n",
      "resetting env. episode 4597, reward total was -18.0. running mean: -19.52701079235155, timestamp: 2022-08-19 23:54:34.796972\n",
      "resetting env. episode 4598, reward total was -20.0. running mean: -19.531740684428033, timestamp: 2022-08-19 23:54:38.052128\n",
      "resetting env. episode 4599, reward total was -20.0. running mean: -19.53642327758375, timestamp: 2022-08-19 23:54:40.616273\n",
      "resetting env. episode 4600, reward total was -20.0. running mean: -19.541059044807913, timestamp: 2022-08-19 23:54:45.493486\n",
      "resetting env. episode 4601, reward total was -20.0. running mean: -19.54564845435983, timestamp: 2022-08-19 23:54:49.330216\n",
      "resetting env. episode 4602, reward total was -20.0. running mean: -19.550191969816233, timestamp: 2022-08-19 23:54:52.919170\n",
      "resetting env. episode 4603, reward total was -21.0. running mean: -19.56469005011807, timestamp: 2022-08-19 23:54:55.711847\n",
      "resetting env. episode 4604, reward total was -19.0. running mean: -19.55904314961689, timestamp: 2022-08-19 23:55:00.387864\n",
      "resetting env. episode 4605, reward total was -21.0. running mean: -19.573452718120723, timestamp: 2022-08-19 23:55:04.027352\n",
      "resetting env. episode 4606, reward total was -21.0. running mean: -19.587718190939515, timestamp: 2022-08-19 23:55:06.916840\n",
      "resetting env. episode 4607, reward total was -21.0. running mean: -19.60184100903012, timestamp: 2022-08-19 23:55:10.531254\n",
      "resetting env. episode 4608, reward total was -19.0. running mean: -19.595822598939822, timestamp: 2022-08-19 23:55:13.838342\n",
      "resetting env. episode 4609, reward total was -17.0. running mean: -19.569864372950427, timestamp: 2022-08-19 23:55:17.645236\n",
      "resetting env. episode 4610, reward total was -21.0. running mean: -19.584165729220924, timestamp: 2022-08-19 23:55:21.311064\n",
      "resetting env. episode 4611, reward total was -19.0. running mean: -19.578324071928716, timestamp: 2022-08-19 23:55:24.570869\n",
      "resetting env. episode 4612, reward total was -21.0. running mean: -19.59254083120943, timestamp: 2022-08-19 23:55:28.104303\n",
      "resetting env. episode 4613, reward total was -21.0. running mean: -19.606615422897335, timestamp: 2022-08-19 23:55:31.375506\n",
      "resetting env. episode 4614, reward total was -16.0. running mean: -19.570549268668362, timestamp: 2022-08-19 23:55:35.141687\n",
      "resetting env. episode 4615, reward total was -20.0. running mean: -19.574843775981677, timestamp: 2022-08-19 23:55:39.965831\n",
      "resetting env. episode 4616, reward total was -19.0. running mean: -19.56909533822186, timestamp: 2022-08-19 23:55:43.414780\n",
      "resetting env. episode 4617, reward total was -21.0. running mean: -19.583404384839643, timestamp: 2022-08-19 23:55:46.749096\n",
      "resetting env. episode 4618, reward total was -19.0. running mean: -19.577570340991247, timestamp: 2022-08-19 23:55:50.623301\n",
      "resetting env. episode 4619, reward total was -21.0. running mean: -19.591794637581337, timestamp: 2022-08-19 23:55:54.430099\n",
      "resetting env. episode 4620, reward total was -20.0. running mean: -19.595876691205522, timestamp: 2022-08-19 23:55:58.197062\n",
      "resetting env. episode 4621, reward total was -19.0. running mean: -19.589917924293466, timestamp: 2022-08-19 23:56:03.285596\n",
      "resetting env. episode 4622, reward total was -21.0. running mean: -19.60401874505053, timestamp: 2022-08-19 23:56:08.916516\n",
      "resetting env. episode 4623, reward total was -19.0. running mean: -19.597978557600026, timestamp: 2022-08-19 23:56:13.331614\n",
      "resetting env. episode 4624, reward total was -20.0. running mean: -19.601998772024025, timestamp: 2022-08-19 23:56:18.905429\n",
      "resetting env. episode 4625, reward total was -20.0. running mean: -19.605978784303783, timestamp: 2022-08-19 23:56:22.949001\n",
      "resetting env. episode 4626, reward total was -21.0. running mean: -19.619918996460747, timestamp: 2022-08-19 23:56:27.273414\n",
      "resetting env. episode 4627, reward total was -18.0. running mean: -19.603719806496137, timestamp: 2022-08-19 23:56:32.356577\n",
      "resetting env. episode 4628, reward total was -18.0. running mean: -19.587682608431177, timestamp: 2022-08-19 23:56:37.079327\n",
      "resetting env. episode 4629, reward total was -20.0. running mean: -19.591805782346864, timestamp: 2022-08-19 23:56:41.445671\n",
      "resetting env. episode 4630, reward total was -20.0. running mean: -19.595887724523394, timestamp: 2022-08-19 23:56:45.490079\n",
      "resetting env. episode 4631, reward total was -20.0. running mean: -19.599928847278157, timestamp: 2022-08-19 23:56:49.796575\n",
      "resetting env. episode 4632, reward total was -21.0. running mean: -19.613929558805378, timestamp: 2022-08-19 23:56:54.203267\n",
      "resetting env. episode 4633, reward total was -21.0. running mean: -19.627790263217324, timestamp: 2022-08-19 23:56:58.284541\n",
      "resetting env. episode 4634, reward total was -18.0. running mean: -19.611512360585152, timestamp: 2022-08-19 23:57:03.063297\n",
      "resetting env. episode 4635, reward total was -20.0. running mean: -19.615397236979298, timestamp: 2022-08-19 23:57:06.495627\n",
      "resetting env. episode 4636, reward total was -21.0. running mean: -19.629243264609507, timestamp: 2022-08-19 23:57:10.194706\n",
      "resetting env. episode 4637, reward total was -19.0. running mean: -19.62295083196341, timestamp: 2022-08-19 23:57:14.365564\n",
      "resetting env. episode 4638, reward total was -20.0. running mean: -19.626721323643775, timestamp: 2022-08-19 23:57:19.280427\n",
      "resetting env. episode 4639, reward total was -18.0. running mean: -19.610454110407336, timestamp: 2022-08-19 23:57:24.219218\n",
      "resetting env. episode 4640, reward total was -19.0. running mean: -19.604349569303263, timestamp: 2022-08-19 23:57:29.764396\n",
      "resetting env. episode 4641, reward total was -21.0. running mean: -19.61830607361023, timestamp: 2022-08-19 23:57:33.022915\n",
      "resetting env. episode 4642, reward total was -19.0. running mean: -19.61212301287413, timestamp: 2022-08-19 23:57:37.480948\n",
      "resetting env. episode 4643, reward total was -21.0. running mean: -19.626001782745387, timestamp: 2022-08-19 23:57:41.840280\n",
      "resetting env. episode 4644, reward total was -19.0. running mean: -19.619741764917933, timestamp: 2022-08-19 23:57:45.886356\n",
      "resetting env. episode 4645, reward total was -19.0. running mean: -19.613544347268753, timestamp: 2022-08-19 23:57:50.432206\n",
      "resetting env. episode 4646, reward total was -17.0. running mean: -19.587408903796067, timestamp: 2022-08-19 23:57:55.839669\n",
      "resetting env. episode 4647, reward total was -20.0. running mean: -19.591534814758106, timestamp: 2022-08-19 23:57:59.576534\n",
      "resetting env. episode 4648, reward total was -20.0. running mean: -19.595619466610525, timestamp: 2022-08-19 23:58:03.245727\n",
      "resetting env. episode 4649, reward total was -20.0. running mean: -19.59966327194442, timestamp: 2022-08-19 23:58:07.350754\n",
      "resetting env. episode 4650, reward total was -20.0. running mean: -19.603666639224972, timestamp: 2022-08-19 23:58:11.544579\n",
      "resetting env. episode 4651, reward total was -19.0. running mean: -19.597629972832724, timestamp: 2022-08-19 23:58:16.135435\n",
      "resetting env. episode 4652, reward total was -21.0. running mean: -19.6116536731044, timestamp: 2022-08-19 23:58:20.727370\n",
      "resetting env. episode 4653, reward total was -18.0. running mean: -19.595537136373355, timestamp: 2022-08-19 23:58:25.440743\n",
      "resetting env. episode 4654, reward total was -17.0. running mean: -19.569581765009623, timestamp: 2022-08-19 23:58:30.838320\n",
      "resetting env. episode 4655, reward total was -20.0. running mean: -19.573885947359525, timestamp: 2022-08-19 23:58:35.415083\n",
      "resetting env. episode 4656, reward total was -18.0. running mean: -19.558147087885928, timestamp: 2022-08-19 23:58:39.940985\n",
      "resetting env. episode 4657, reward total was -21.0. running mean: -19.57256561700707, timestamp: 2022-08-19 23:58:44.015098\n",
      "resetting env. episode 4658, reward total was -19.0. running mean: -19.566839960836997, timestamp: 2022-08-19 23:58:48.332729\n",
      "resetting env. episode 4659, reward total was -19.0. running mean: -19.56117156122863, timestamp: 2022-08-19 23:58:52.519198\n",
      "resetting env. episode 4660, reward total was -18.0. running mean: -19.545559845616342, timestamp: 2022-08-19 23:58:57.230515\n",
      "resetting env. episode 4661, reward total was -20.0. running mean: -19.550104247160178, timestamp: 2022-08-19 23:59:00.307771\n",
      "resetting env. episode 4662, reward total was -20.0. running mean: -19.554603204688576, timestamp: 2022-08-19 23:59:03.820426\n",
      "resetting env. episode 4663, reward total was -20.0. running mean: -19.55905717264169, timestamp: 2022-08-19 23:59:06.723635\n",
      "resetting env. episode 4664, reward total was -16.0. running mean: -19.523466600915274, timestamp: 2022-08-19 23:59:10.934374\n",
      "resetting env. episode 4665, reward total was -19.0. running mean: -19.518231934906122, timestamp: 2022-08-19 23:59:15.300708\n",
      "resetting env. episode 4666, reward total was -18.0. running mean: -19.50304961555706, timestamp: 2022-08-19 23:59:20.264718\n",
      "resetting env. episode 4667, reward total was -16.0. running mean: -19.46801911940149, timestamp: 2022-08-19 23:59:25.762803\n",
      "resetting env. episode 4668, reward total was -20.0. running mean: -19.473338928207475, timestamp: 2022-08-19 23:59:29.287347\n",
      "resetting env. episode 4669, reward total was -19.0. running mean: -19.468605538925402, timestamp: 2022-08-19 23:59:33.263199\n",
      "resetting env. episode 4670, reward total was -16.0. running mean: -19.433919483536148, timestamp: 2022-08-19 23:59:38.503845\n",
      "resetting env. episode 4671, reward total was -19.0. running mean: -19.429580288700787, timestamp: 2022-08-19 23:59:42.816879\n",
      "resetting env. episode 4672, reward total was -19.0. running mean: -19.42528448581378, timestamp: 2022-08-19 23:59:46.915911\n",
      "resetting env. episode 4673, reward total was -20.0. running mean: -19.43103164095564, timestamp: 2022-08-19 23:59:50.361752\n",
      "resetting env. episode 4674, reward total was -18.0. running mean: -19.416721324546085, timestamp: 2022-08-19 23:59:55.333502\n",
      "resetting env. episode 4675, reward total was -18.0. running mean: -19.402554111300624, timestamp: 2022-08-19 23:59:59.144022\n",
      "resetting env. episode 4676, reward total was -19.0. running mean: -19.39852857018762, timestamp: 2022-08-20 00:00:04.023729\n",
      "resetting env. episode 4677, reward total was -20.0. running mean: -19.40454328448574, timestamp: 2022-08-20 00:00:07.305966\n",
      "resetting env. episode 4678, reward total was -20.0. running mean: -19.410497851640883, timestamp: 2022-08-20 00:00:11.740914\n",
      "resetting env. episode 4679, reward total was -20.0. running mean: -19.416392873124472, timestamp: 2022-08-20 00:00:16.184303\n",
      "resetting env. episode 4680, reward total was -19.0. running mean: -19.412228944393227, timestamp: 2022-08-20 00:00:20.167912\n",
      "resetting env. episode 4681, reward total was -21.0. running mean: -19.428106654949296, timestamp: 2022-08-20 00:00:24.274307\n",
      "resetting env. episode 4682, reward total was -17.0. running mean: -19.403825588399805, timestamp: 2022-08-20 00:00:29.646743\n",
      "resetting env. episode 4683, reward total was -20.0. running mean: -19.409787332515805, timestamp: 2022-08-20 00:00:34.302305\n",
      "resetting env. episode 4684, reward total was -21.0. running mean: -19.425689459190647, timestamp: 2022-08-20 00:00:38.303639\n",
      "resetting env. episode 4685, reward total was -19.0. running mean: -19.421432564598742, timestamp: 2022-08-20 00:00:42.937409\n",
      "resetting env. episode 4686, reward total was -20.0. running mean: -19.427218238952754, timestamp: 2022-08-20 00:00:46.348425\n",
      "resetting env. episode 4687, reward total was -21.0. running mean: -19.442946056563226, timestamp: 2022-08-20 00:00:50.843726\n",
      "resetting env. episode 4688, reward total was -20.0. running mean: -19.448516595997592, timestamp: 2022-08-20 00:00:54.588643\n",
      "resetting env. episode 4689, reward total was -20.0. running mean: -19.454031430037617, timestamp: 2022-08-20 00:00:58.753468\n",
      "resetting env. episode 4690, reward total was -19.0. running mean: -19.449491115737242, timestamp: 2022-08-20 00:01:02.722287\n",
      "resetting env. episode 4691, reward total was -21.0. running mean: -19.46499620457987, timestamp: 2022-08-20 00:01:06.799266\n",
      "resetting env. episode 4692, reward total was -19.0. running mean: -19.460346242534072, timestamp: 2022-08-20 00:01:12.454282\n",
      "resetting env. episode 4693, reward total was -19.0. running mean: -19.455742780108732, timestamp: 2022-08-20 00:01:16.289240\n",
      "resetting env. episode 4694, reward total was -19.0. running mean: -19.451185352307647, timestamp: 2022-08-20 00:01:21.887905\n",
      "resetting env. episode 4695, reward total was -20.0. running mean: -19.456673498784568, timestamp: 2022-08-20 00:01:26.362630\n",
      "resetting env. episode 4696, reward total was -21.0. running mean: -19.472106763796724, timestamp: 2022-08-20 00:01:30.532980\n",
      "resetting env. episode 4697, reward total was -18.0. running mean: -19.457385696158756, timestamp: 2022-08-20 00:01:35.106410\n",
      "resetting env. episode 4698, reward total was -21.0. running mean: -19.47281183919717, timestamp: 2022-08-20 00:01:39.373055\n",
      "resetting env. episode 4699, reward total was -20.0. running mean: -19.4780837208052, timestamp: 2022-08-20 00:01:43.719199\n",
      "resetting env. episode 4700, reward total was -18.0. running mean: -19.463302883597144, timestamp: 2022-08-20 00:01:48.581611\n",
      "resetting env. episode 4701, reward total was -21.0. running mean: -19.478669854761172, timestamp: 2022-08-20 00:01:51.568158\n",
      "resetting env. episode 4702, reward total was -20.0. running mean: -19.483883156213558, timestamp: 2022-08-20 00:01:55.646264\n",
      "resetting env. episode 4703, reward total was -21.0. running mean: -19.499044324651422, timestamp: 2022-08-20 00:01:58.624297\n",
      "resetting env. episode 4704, reward total was -20.0. running mean: -19.504053881404907, timestamp: 2022-08-20 00:02:03.049450\n",
      "resetting env. episode 4705, reward total was -20.0. running mean: -19.50901334259086, timestamp: 2022-08-20 00:02:07.850356\n",
      "resetting env. episode 4706, reward total was -18.0. running mean: -19.49392320916495, timestamp: 2022-08-20 00:02:12.325392\n",
      "resetting env. episode 4707, reward total was -20.0. running mean: -19.4989839770733, timestamp: 2022-08-20 00:02:16.342566\n",
      "resetting env. episode 4708, reward total was -21.0. running mean: -19.513994137302568, timestamp: 2022-08-20 00:02:20.905331\n",
      "resetting env. episode 4709, reward total was -19.0. running mean: -19.508854195929544, timestamp: 2022-08-20 00:02:24.845795\n",
      "resetting env. episode 4710, reward total was -21.0. running mean: -19.523765653970248, timestamp: 2022-08-20 00:02:28.130019\n",
      "resetting env. episode 4711, reward total was -21.0. running mean: -19.538527997430545, timestamp: 2022-08-20 00:02:32.008277\n",
      "resetting env. episode 4712, reward total was -20.0. running mean: -19.543142717456238, timestamp: 2022-08-20 00:02:37.224246\n",
      "resetting env. episode 4713, reward total was -20.0. running mean: -19.547711290281676, timestamp: 2022-08-20 00:02:41.842899\n",
      "resetting env. episode 4714, reward total was -21.0. running mean: -19.56223417737886, timestamp: 2022-08-20 00:02:45.467423\n",
      "resetting env. episode 4715, reward total was -21.0. running mean: -19.57661183560507, timestamp: 2022-08-20 00:02:49.845703\n",
      "resetting env. episode 4716, reward total was -20.0. running mean: -19.58084571724902, timestamp: 2022-08-20 00:02:53.873937\n",
      "resetting env. episode 4717, reward total was -20.0. running mean: -19.58503726007653, timestamp: 2022-08-20 00:02:58.008888\n",
      "resetting env. episode 4718, reward total was -19.0. running mean: -19.579186887475764, timestamp: 2022-08-20 00:03:02.674411\n",
      "resetting env. episode 4719, reward total was -20.0. running mean: -19.583395018601006, timestamp: 2022-08-20 00:03:06.842273\n",
      "resetting env. episode 4720, reward total was -20.0. running mean: -19.587561068414995, timestamp: 2022-08-20 00:03:10.889445\n",
      "resetting env. episode 4721, reward total was -20.0. running mean: -19.591685457730843, timestamp: 2022-08-20 00:03:14.535739\n",
      "resetting env. episode 4722, reward total was -17.0. running mean: -19.565768603153536, timestamp: 2022-08-20 00:03:19.001362\n",
      "resetting env. episode 4723, reward total was -20.0. running mean: -19.570110917122, timestamp: 2022-08-20 00:03:22.292127\n",
      "resetting env. episode 4724, reward total was -19.0. running mean: -19.56440980795078, timestamp: 2022-08-20 00:03:26.555493\n",
      "resetting env. episode 4725, reward total was -18.0. running mean: -19.548765709871272, timestamp: 2022-08-20 00:03:30.306078\n",
      "resetting env. episode 4726, reward total was -19.0. running mean: -19.54327805277256, timestamp: 2022-08-20 00:03:34.796556\n",
      "resetting env. episode 4727, reward total was -19.0. running mean: -19.537845272244837, timestamp: 2022-08-20 00:03:37.830248\n",
      "resetting env. episode 4728, reward total was -20.0. running mean: -19.54246681952239, timestamp: 2022-08-20 00:03:41.857291\n",
      "resetting env. episode 4729, reward total was -19.0. running mean: -19.537042151327167, timestamp: 2022-08-20 00:03:45.529969\n",
      "resetting env. episode 4730, reward total was -20.0. running mean: -19.541671729813896, timestamp: 2022-08-20 00:03:49.556912\n",
      "resetting env. episode 4731, reward total was -20.0. running mean: -19.546255012515754, timestamp: 2022-08-20 00:03:53.274999\n",
      "resetting env. episode 4732, reward total was -16.0. running mean: -19.510792462390597, timestamp: 2022-08-20 00:03:57.768902\n",
      "resetting env. episode 4733, reward total was -20.0. running mean: -19.515684537766692, timestamp: 2022-08-20 00:04:00.755383\n",
      "resetting env. episode 4734, reward total was -18.0. running mean: -19.500527692389024, timestamp: 2022-08-20 00:04:03.368831\n",
      "resetting env. episode 4735, reward total was -20.0. running mean: -19.505522415465133, timestamp: 2022-08-20 00:04:07.503166\n",
      "resetting env. episode 4736, reward total was -21.0. running mean: -19.520467191310484, timestamp: 2022-08-20 00:04:10.858435\n",
      "resetting env. episode 4737, reward total was -21.0. running mean: -19.53526251939738, timestamp: 2022-08-20 00:04:13.033969\n",
      "resetting env. episode 4738, reward total was -20.0. running mean: -19.539909894203408, timestamp: 2022-08-20 00:04:16.357433\n",
      "resetting env. episode 4739, reward total was -20.0. running mean: -19.544510795261374, timestamp: 2022-08-20 00:04:19.304111\n",
      "resetting env. episode 4740, reward total was -20.0. running mean: -19.549065687308758, timestamp: 2022-08-20 00:04:22.565627\n",
      "resetting env. episode 4741, reward total was -20.0. running mean: -19.55357503043567, timestamp: 2022-08-20 00:04:26.163780\n",
      "resetting env. episode 4742, reward total was -21.0. running mean: -19.568039280131316, timestamp: 2022-08-20 00:04:29.124443\n",
      "resetting env. episode 4743, reward total was -21.0. running mean: -19.582358887330003, timestamp: 2022-08-20 00:04:31.734312\n",
      "resetting env. episode 4744, reward total was -19.0. running mean: -19.576535298456704, timestamp: 2022-08-20 00:04:36.354023\n",
      "resetting env. episode 4745, reward total was -21.0. running mean: -19.59076994547214, timestamp: 2022-08-20 00:04:39.012686\n",
      "resetting env. episode 4746, reward total was -20.0. running mean: -19.594862246017417, timestamp: 2022-08-20 00:04:41.686058\n",
      "resetting env. episode 4747, reward total was -21.0. running mean: -19.608913623557243, timestamp: 2022-08-20 00:04:45.247815\n",
      "resetting env. episode 4748, reward total was -18.0. running mean: -19.59282448732167, timestamp: 2022-08-20 00:04:49.222542\n",
      "resetting env. episode 4749, reward total was -21.0. running mean: -19.606896242448457, timestamp: 2022-08-20 00:04:52.894281\n",
      "resetting env. episode 4750, reward total was -20.0. running mean: -19.610827280023972, timestamp: 2022-08-20 00:04:56.525575\n",
      "resetting env. episode 4751, reward total was -17.0. running mean: -19.584719007223736, timestamp: 2022-08-20 00:05:01.789704\n",
      "resetting env. episode 4752, reward total was -20.0. running mean: -19.5888718171515, timestamp: 2022-08-20 00:05:06.029039\n",
      "resetting env. episode 4753, reward total was -20.0. running mean: -19.592983098979985, timestamp: 2022-08-20 00:05:09.479671\n",
      "resetting env. episode 4754, reward total was -19.0. running mean: -19.587053267990186, timestamp: 2022-08-20 00:05:12.744805\n",
      "resetting env. episode 4755, reward total was -21.0. running mean: -19.601182735310285, timestamp: 2022-08-20 00:05:16.695360\n",
      "resetting env. episode 4756, reward total was -19.0. running mean: -19.595170907957183, timestamp: 2022-08-20 00:05:19.793037\n",
      "resetting env. episode 4757, reward total was -21.0. running mean: -19.60921919887761, timestamp: 2022-08-20 00:05:23.684848\n",
      "resetting env. episode 4758, reward total was -19.0. running mean: -19.603127006888837, timestamp: 2022-08-20 00:05:28.141270\n",
      "resetting env. episode 4759, reward total was -21.0. running mean: -19.617095736819948, timestamp: 2022-08-20 00:05:31.794445\n",
      "resetting env. episode 4760, reward total was -16.0. running mean: -19.58092477945175, timestamp: 2022-08-20 00:05:37.005298\n",
      "resetting env. episode 4761, reward total was -19.0. running mean: -19.575115531657232, timestamp: 2022-08-20 00:05:41.453167\n",
      "resetting env. episode 4762, reward total was -20.0. running mean: -19.57936437634066, timestamp: 2022-08-20 00:05:45.743889\n",
      "resetting env. episode 4763, reward total was -19.0. running mean: -19.573570732577256, timestamp: 2022-08-20 00:05:49.586586\n",
      "resetting env. episode 4764, reward total was -21.0. running mean: -19.587835025251483, timestamp: 2022-08-20 00:05:53.661548\n",
      "resetting env. episode 4765, reward total was -19.0. running mean: -19.58195667499897, timestamp: 2022-08-20 00:05:57.593576\n",
      "resetting env. episode 4766, reward total was -18.0. running mean: -19.56613710824898, timestamp: 2022-08-20 00:06:02.037278\n",
      "resetting env. episode 4767, reward total was -21.0. running mean: -19.58047573716649, timestamp: 2022-08-20 00:06:07.174304\n",
      "resetting env. episode 4768, reward total was -21.0. running mean: -19.594670979794827, timestamp: 2022-08-20 00:06:11.083911\n",
      "resetting env. episode 4769, reward total was -19.0. running mean: -19.58872426999688, timestamp: 2022-08-20 00:06:14.732337\n",
      "resetting env. episode 4770, reward total was -20.0. running mean: -19.592837027296913, timestamp: 2022-08-20 00:06:19.419395\n",
      "resetting env. episode 4771, reward total was -19.0. running mean: -19.586908657023944, timestamp: 2022-08-20 00:06:23.234749\n",
      "resetting env. episode 4772, reward total was -21.0. running mean: -19.601039570453704, timestamp: 2022-08-20 00:06:26.422785\n",
      "resetting env. episode 4773, reward total was -17.0. running mean: -19.57502917474917, timestamp: 2022-08-20 00:06:32.244634\n",
      "resetting env. episode 4774, reward total was -20.0. running mean: -19.579278883001678, timestamp: 2022-08-20 00:06:37.374044\n",
      "resetting env. episode 4775, reward total was -21.0. running mean: -19.593486094171663, timestamp: 2022-08-20 00:06:40.585659\n",
      "resetting env. episode 4776, reward total was -21.0. running mean: -19.607551233229948, timestamp: 2022-08-20 00:06:44.296215\n",
      "resetting env. episode 4777, reward total was -20.0. running mean: -19.611475720897648, timestamp: 2022-08-20 00:06:49.019011\n",
      "resetting env. episode 4778, reward total was -20.0. running mean: -19.61536096368867, timestamp: 2022-08-20 00:06:52.642483\n",
      "resetting env. episode 4779, reward total was -18.0. running mean: -19.59920735405178, timestamp: 2022-08-20 00:06:57.218986\n",
      "resetting env. episode 4780, reward total was -20.0. running mean: -19.603215280511264, timestamp: 2022-08-20 00:07:00.624305\n",
      "resetting env. episode 4781, reward total was -19.0. running mean: -19.597183127706153, timestamp: 2022-08-20 00:07:04.687587\n",
      "resetting env. episode 4782, reward total was -20.0. running mean: -19.60121129642909, timestamp: 2022-08-20 00:07:08.701849\n",
      "resetting env. episode 4783, reward total was -20.0. running mean: -19.605199183464798, timestamp: 2022-08-20 00:07:12.365726\n",
      "resetting env. episode 4784, reward total was -18.0. running mean: -19.58914719163015, timestamp: 2022-08-20 00:07:16.117418\n",
      "resetting env. episode 4785, reward total was -19.0. running mean: -19.58325571971385, timestamp: 2022-08-20 00:07:20.262654\n",
      "resetting env. episode 4786, reward total was -21.0. running mean: -19.597423162516712, timestamp: 2022-08-20 00:07:23.322948\n",
      "resetting env. episode 4787, reward total was -21.0. running mean: -19.611448930891545, timestamp: 2022-08-20 00:07:27.225152\n",
      "resetting env. episode 4788, reward total was -20.0. running mean: -19.61533444158263, timestamp: 2022-08-20 00:07:30.767091\n",
      "resetting env. episode 4789, reward total was -19.0. running mean: -19.609181097166804, timestamp: 2022-08-20 00:07:34.223712\n",
      "resetting env. episode 4790, reward total was -17.0. running mean: -19.583089286195136, timestamp: 2022-08-20 00:07:38.704063\n",
      "resetting env. episode 4791, reward total was -19.0. running mean: -19.577258393333185, timestamp: 2022-08-20 00:07:42.437194\n",
      "resetting env. episode 4792, reward total was -20.0. running mean: -19.58148580939985, timestamp: 2022-08-20 00:07:45.929418\n",
      "resetting env. episode 4793, reward total was -20.0. running mean: -19.58567095130585, timestamp: 2022-08-20 00:07:49.485776\n",
      "resetting env. episode 4794, reward total was -21.0. running mean: -19.599814241792792, timestamp: 2022-08-20 00:07:53.279627\n",
      "resetting env. episode 4795, reward total was -20.0. running mean: -19.603816099374864, timestamp: 2022-08-20 00:07:56.494487\n",
      "resetting env. episode 4796, reward total was -19.0. running mean: -19.597777938381117, timestamp: 2022-08-20 00:07:59.754699\n",
      "resetting env. episode 4797, reward total was -21.0. running mean: -19.61180015899731, timestamp: 2022-08-20 00:08:02.995549\n",
      "resetting env. episode 4798, reward total was -19.0. running mean: -19.605682157407337, timestamp: 2022-08-20 00:08:07.384535\n",
      "resetting env. episode 4799, reward total was -21.0. running mean: -19.619625335833263, timestamp: 2022-08-20 00:08:10.367654\n",
      "resetting env. episode 4800, reward total was -21.0. running mean: -19.63342908247493, timestamp: 2022-08-20 00:08:13.271492\n",
      "resetting env. episode 4801, reward total was -19.0. running mean: -19.62709479165018, timestamp: 2022-08-20 00:08:16.887807\n",
      "resetting env. episode 4802, reward total was -19.0. running mean: -19.620823843733678, timestamp: 2022-08-20 00:08:20.925457\n",
      "resetting env. episode 4803, reward total was -17.0. running mean: -19.594615605296344, timestamp: 2022-08-20 00:08:24.965082\n",
      "resetting env. episode 4804, reward total was -19.0. running mean: -19.588669449243383, timestamp: 2022-08-20 00:08:29.859001\n",
      "resetting env. episode 4805, reward total was -16.0. running mean: -19.55278275475095, timestamp: 2022-08-20 00:08:36.389544\n",
      "resetting env. episode 4806, reward total was -20.0. running mean: -19.55725492720344, timestamp: 2022-08-20 00:08:40.305083\n",
      "resetting env. episode 4807, reward total was -19.0. running mean: -19.551682377931407, timestamp: 2022-08-20 00:08:44.790091\n",
      "resetting env. episode 4808, reward total was -21.0. running mean: -19.566165554152093, timestamp: 2022-08-20 00:08:49.739410\n",
      "resetting env. episode 4809, reward total was -17.0. running mean: -19.540503898610574, timestamp: 2022-08-20 00:08:53.891589\n",
      "resetting env. episode 4810, reward total was -21.0. running mean: -19.55509885962447, timestamp: 2022-08-20 00:08:58.547142\n",
      "resetting env. episode 4811, reward total was -20.0. running mean: -19.559547871028222, timestamp: 2022-08-20 00:09:02.476147\n",
      "resetting env. episode 4812, reward total was -20.0. running mean: -19.56395239231794, timestamp: 2022-08-20 00:09:06.400398\n",
      "resetting env. episode 4813, reward total was -20.0. running mean: -19.56831286839476, timestamp: 2022-08-20 00:09:09.479369\n",
      "resetting env. episode 4814, reward total was -20.0. running mean: -19.572629739710813, timestamp: 2022-08-20 00:09:12.130882\n",
      "resetting env. episode 4815, reward total was -21.0. running mean: -19.586903442313705, timestamp: 2022-08-20 00:09:15.980620\n",
      "resetting env. episode 4816, reward total was -18.0. running mean: -19.57103440789057, timestamp: 2022-08-20 00:09:19.998392\n",
      "resetting env. episode 4817, reward total was -19.0. running mean: -19.565324063811666, timestamp: 2022-08-20 00:09:22.888952\n",
      "resetting env. episode 4818, reward total was -16.0. running mean: -19.52967082317355, timestamp: 2022-08-20 00:09:27.119530\n",
      "resetting env. episode 4819, reward total was -21.0. running mean: -19.544374114941814, timestamp: 2022-08-20 00:09:30.658420\n",
      "resetting env. episode 4820, reward total was -20.0. running mean: -19.548930373792395, timestamp: 2022-08-20 00:09:34.336086\n",
      "resetting env. episode 4821, reward total was -19.0. running mean: -19.54344107005447, timestamp: 2022-08-20 00:09:38.172582\n",
      "resetting env. episode 4822, reward total was -20.0. running mean: -19.548006659353923, timestamp: 2022-08-20 00:09:41.738983\n",
      "resetting env. episode 4823, reward total was -21.0. running mean: -19.562526592760385, timestamp: 2022-08-20 00:09:46.081820\n",
      "resetting env. episode 4824, reward total was -20.0. running mean: -19.56690132683278, timestamp: 2022-08-20 00:09:50.109056\n",
      "resetting env. episode 4825, reward total was -19.0. running mean: -19.561232313564453, timestamp: 2022-08-20 00:09:53.961761\n",
      "resetting env. episode 4826, reward total was -17.0. running mean: -19.53561999042881, timestamp: 2022-08-20 00:09:57.849366\n",
      "resetting env. episode 4827, reward total was -20.0. running mean: -19.54026379052452, timestamp: 2022-08-20 00:10:02.354322\n",
      "resetting env. episode 4828, reward total was -20.0. running mean: -19.544861152619273, timestamp: 2022-08-20 00:10:06.662394\n",
      "resetting env. episode 4829, reward total was -21.0. running mean: -19.55941254109308, timestamp: 2022-08-20 00:10:11.099694\n",
      "resetting env. episode 4830, reward total was -21.0. running mean: -19.57381841568215, timestamp: 2022-08-20 00:10:15.015226\n",
      "resetting env. episode 4831, reward total was -19.0. running mean: -19.568080231525332, timestamp: 2022-08-20 00:10:19.286811\n",
      "resetting env. episode 4832, reward total was -20.0. running mean: -19.57239942921008, timestamp: 2022-08-20 00:10:22.847291\n",
      "resetting env. episode 4833, reward total was -17.0. running mean: -19.54667543491798, timestamp: 2022-08-20 00:10:26.849643\n",
      "resetting env. episode 4834, reward total was -20.0. running mean: -19.5512086805688, timestamp: 2022-08-20 00:10:30.316869\n",
      "resetting env. episode 4835, reward total was -18.0. running mean: -19.53569659376311, timestamp: 2022-08-20 00:10:34.100715\n",
      "resetting env. episode 4836, reward total was -20.0. running mean: -19.540339627825478, timestamp: 2022-08-20 00:10:38.489310\n",
      "resetting env. episode 4837, reward total was -21.0. running mean: -19.554936231547224, timestamp: 2022-08-20 00:10:41.789264\n",
      "resetting env. episode 4838, reward total was -20.0. running mean: -19.55938686923175, timestamp: 2022-08-20 00:10:45.273287\n",
      "resetting env. episode 4839, reward total was -21.0. running mean: -19.573793000539435, timestamp: 2022-08-20 00:10:49.283486\n",
      "resetting env. episode 4840, reward total was -20.0. running mean: -19.57805507053404, timestamp: 2022-08-20 00:10:53.350808\n",
      "resetting env. episode 4841, reward total was -20.0. running mean: -19.5822745198287, timestamp: 2022-08-20 00:10:57.728108\n",
      "resetting env. episode 4842, reward total was -21.0. running mean: -19.596451774630413, timestamp: 2022-08-20 00:11:01.822526\n",
      "resetting env. episode 4843, reward total was -20.0. running mean: -19.600487256884108, timestamp: 2022-08-20 00:11:04.655946\n",
      "resetting env. episode 4844, reward total was -19.0. running mean: -19.594482384315267, timestamp: 2022-08-20 00:11:08.670218\n",
      "resetting env. episode 4845, reward total was -21.0. running mean: -19.608537560472115, timestamp: 2022-08-20 00:11:12.833090\n",
      "resetting env. episode 4846, reward total was -21.0. running mean: -19.622452184867395, timestamp: 2022-08-20 00:11:16.343707\n",
      "resetting env. episode 4847, reward total was -21.0. running mean: -19.636227663018722, timestamp: 2022-08-20 00:11:19.429304\n",
      "resetting env. episode 4848, reward total was -21.0. running mean: -19.649865386388537, timestamp: 2022-08-20 00:11:24.050744\n",
      "resetting env. episode 4849, reward total was -19.0. running mean: -19.643366732524655, timestamp: 2022-08-20 00:11:27.468601\n",
      "resetting env. episode 4850, reward total was -20.0. running mean: -19.646933065199406, timestamp: 2022-08-20 00:11:32.323653\n",
      "resetting env. episode 4851, reward total was -21.0. running mean: -19.660463734547413, timestamp: 2022-08-20 00:11:35.782639\n",
      "resetting env. episode 4852, reward total was -20.0. running mean: -19.66385909720194, timestamp: 2022-08-20 00:11:40.277046\n",
      "resetting env. episode 4853, reward total was -19.0. running mean: -19.657220506229923, timestamp: 2022-08-20 00:11:44.048800\n",
      "resetting env. episode 4854, reward total was -21.0. running mean: -19.670648301167624, timestamp: 2022-08-20 00:11:48.105954\n",
      "resetting env. episode 4855, reward total was -21.0. running mean: -19.683941818155947, timestamp: 2022-08-20 00:11:51.983591\n",
      "resetting env. episode 4856, reward total was -19.0. running mean: -19.677102399974387, timestamp: 2022-08-20 00:11:54.901790\n",
      "resetting env. episode 4857, reward total was -20.0. running mean: -19.680331375974642, timestamp: 2022-08-20 00:11:58.534081\n",
      "resetting env. episode 4858, reward total was -21.0. running mean: -19.693528062214895, timestamp: 2022-08-20 00:12:01.568987\n",
      "resetting env. episode 4859, reward total was -20.0. running mean: -19.696592781592745, timestamp: 2022-08-20 00:12:06.171663\n",
      "resetting env. episode 4860, reward total was -18.0. running mean: -19.679626853776817, timestamp: 2022-08-20 00:12:10.592846\n",
      "resetting env. episode 4861, reward total was -19.0. running mean: -19.67283058523905, timestamp: 2022-08-20 00:12:14.938232\n",
      "resetting env. episode 4862, reward total was -19.0. running mean: -19.666102279386664, timestamp: 2022-08-20 00:12:19.514998\n",
      "resetting env. episode 4863, reward total was -19.0. running mean: -19.6594412565928, timestamp: 2022-08-20 00:12:23.587114\n",
      "resetting env. episode 4864, reward total was -19.0. running mean: -19.65284684402687, timestamp: 2022-08-20 00:12:27.562488\n",
      "resetting env. episode 4865, reward total was -21.0. running mean: -19.666318375586602, timestamp: 2022-08-20 00:12:31.293145\n",
      "resetting env. episode 4866, reward total was -21.0. running mean: -19.679655191830737, timestamp: 2022-08-20 00:12:35.807079\n",
      "resetting env. episode 4867, reward total was -20.0. running mean: -19.68285863991243, timestamp: 2022-08-20 00:12:39.705658\n",
      "resetting env. episode 4868, reward total was -20.0. running mean: -19.686030053513303, timestamp: 2022-08-20 00:12:43.094598\n",
      "resetting env. episode 4869, reward total was -20.0. running mean: -19.68916975297817, timestamp: 2022-08-20 00:12:46.666052\n",
      "resetting env. episode 4870, reward total was -20.0. running mean: -19.692278055448387, timestamp: 2022-08-20 00:12:51.647736\n",
      "resetting env. episode 4871, reward total was -20.0. running mean: -19.695355274893902, timestamp: 2022-08-20 00:12:55.471514\n",
      "resetting env. episode 4872, reward total was -21.0. running mean: -19.708401722144963, timestamp: 2022-08-20 00:12:58.764711\n",
      "resetting env. episode 4873, reward total was -21.0. running mean: -19.721317704923514, timestamp: 2022-08-20 00:13:02.044944\n",
      "resetting env. episode 4874, reward total was -19.0. running mean: -19.71410452787428, timestamp: 2022-08-20 00:13:06.337469\n",
      "resetting env. episode 4875, reward total was -19.0. running mean: -19.706963482595537, timestamp: 2022-08-20 00:13:12.481734\n",
      "resetting env. episode 4876, reward total was -20.0. running mean: -19.70989384776958, timestamp: 2022-08-20 00:13:16.272603\n",
      "resetting env. episode 4877, reward total was -20.0. running mean: -19.712794909291887, timestamp: 2022-08-20 00:13:20.194121\n",
      "resetting env. episode 4878, reward total was -19.0. running mean: -19.70566696019897, timestamp: 2022-08-20 00:13:24.872613\n",
      "resetting env. episode 4879, reward total was -21.0. running mean: -19.718610290596978, timestamp: 2022-08-20 00:13:28.768072\n",
      "resetting env. episode 4880, reward total was -19.0. running mean: -19.71142418769101, timestamp: 2022-08-20 00:13:31.875739\n",
      "resetting env. episode 4881, reward total was -18.0. running mean: -19.694309945814098, timestamp: 2022-08-20 00:13:36.332900\n",
      "resetting env. episode 4882, reward total was -19.0. running mean: -19.687366846355957, timestamp: 2022-08-20 00:13:40.121408\n",
      "resetting env. episode 4883, reward total was -21.0. running mean: -19.700493177892398, timestamp: 2022-08-20 00:13:43.574812\n",
      "resetting env. episode 4884, reward total was -19.0. running mean: -19.693488246113475, timestamp: 2022-08-20 00:13:46.572275\n",
      "resetting env. episode 4885, reward total was -20.0. running mean: -19.696553363652338, timestamp: 2022-08-20 00:13:49.801719\n",
      "resetting env. episode 4886, reward total was -19.0. running mean: -19.689587830015817, timestamp: 2022-08-20 00:13:52.778041\n",
      "resetting env. episode 4887, reward total was -18.0. running mean: -19.67269195171566, timestamp: 2022-08-20 00:13:56.296071\n",
      "resetting env. episode 4888, reward total was -21.0. running mean: -19.685965032198503, timestamp: 2022-08-20 00:13:59.842661\n",
      "resetting env. episode 4889, reward total was -18.0. running mean: -19.669105381876516, timestamp: 2022-08-20 00:14:03.220601\n",
      "resetting env. episode 4890, reward total was -21.0. running mean: -19.682414328057753, timestamp: 2022-08-20 00:14:06.914234\n",
      "resetting env. episode 4891, reward total was -19.0. running mean: -19.675590184777178, timestamp: 2022-08-20 00:14:10.116636\n",
      "resetting env. episode 4892, reward total was -20.0. running mean: -19.678834282929405, timestamp: 2022-08-20 00:14:13.357503\n",
      "resetting env. episode 4893, reward total was -20.0. running mean: -19.68204594010011, timestamp: 2022-08-20 00:14:16.128192\n",
      "resetting env. episode 4894, reward total was -18.0. running mean: -19.66522548069911, timestamp: 2022-08-20 00:14:19.978904\n",
      "resetting env. episode 4895, reward total was -18.0. running mean: -19.648573225892118, timestamp: 2022-08-20 00:14:23.971741\n",
      "resetting env. episode 4896, reward total was -21.0. running mean: -19.662087493633198, timestamp: 2022-08-20 00:14:27.023051\n",
      "resetting env. episode 4897, reward total was -19.0. running mean: -19.655466618696867, timestamp: 2022-08-20 00:14:30.487090\n",
      "resetting env. episode 4898, reward total was -20.0. running mean: -19.658911952509897, timestamp: 2022-08-20 00:14:33.786374\n",
      "resetting env. episode 4899, reward total was -19.0. running mean: -19.652322832984797, timestamp: 2022-08-20 00:14:37.994626\n",
      "resetting env. episode 4900, reward total was -20.0. running mean: -19.65579960465495, timestamp: 2022-08-20 00:14:42.838614\n",
      "resetting env. episode 4901, reward total was -19.0. running mean: -19.6492416086084, timestamp: 2022-08-20 00:14:46.785534\n",
      "resetting env. episode 4902, reward total was -19.0. running mean: -19.642749192522317, timestamp: 2022-08-20 00:14:50.901719\n",
      "resetting env. episode 4903, reward total was -17.0. running mean: -19.616321700597094, timestamp: 2022-08-20 00:14:54.202038\n",
      "resetting env. episode 4904, reward total was -21.0. running mean: -19.630158483591124, timestamp: 2022-08-20 00:14:57.144323\n",
      "resetting env. episode 4905, reward total was -20.0. running mean: -19.633856898755212, timestamp: 2022-08-20 00:14:59.894802\n",
      "resetting env. episode 4906, reward total was -20.0. running mean: -19.63751832976766, timestamp: 2022-08-20 00:15:03.128411\n",
      "resetting env. episode 4907, reward total was -19.0. running mean: -19.631143146469984, timestamp: 2022-08-20 00:15:06.817435\n",
      "resetting env. episode 4908, reward total was -21.0. running mean: -19.644831715005285, timestamp: 2022-08-20 00:15:10.246382\n",
      "resetting env. episode 4909, reward total was -20.0. running mean: -19.64838339785523, timestamp: 2022-08-20 00:15:13.985233\n",
      "resetting env. episode 4910, reward total was -21.0. running mean: -19.66189956387668, timestamp: 2022-08-20 00:15:17.973872\n",
      "resetting env. episode 4911, reward total was -21.0. running mean: -19.675280568237913, timestamp: 2022-08-20 00:15:21.535045\n",
      "resetting env. episode 4912, reward total was -21.0. running mean: -19.688527762555534, timestamp: 2022-08-20 00:15:25.616141\n",
      "resetting env. episode 4913, reward total was -18.0. running mean: -19.67164248492998, timestamp: 2022-08-20 00:15:30.261209\n",
      "resetting env. episode 4914, reward total was -19.0. running mean: -19.66492606008068, timestamp: 2022-08-20 00:15:35.197506\n",
      "resetting env. episode 4915, reward total was -19.0. running mean: -19.658276799479875, timestamp: 2022-08-20 00:15:39.773278\n",
      "resetting env. episode 4916, reward total was -20.0. running mean: -19.661694031485077, timestamp: 2022-08-20 00:15:43.448604\n",
      "resetting env. episode 4917, reward total was -19.0. running mean: -19.655077091170227, timestamp: 2022-08-20 00:15:49.042567\n",
      "resetting env. episode 4918, reward total was -17.0. running mean: -19.628526320258526, timestamp: 2022-08-20 00:15:53.935250\n",
      "resetting env. episode 4919, reward total was -21.0. running mean: -19.64224105705594, timestamp: 2022-08-20 00:16:01.664666\n",
      "resetting env. episode 4920, reward total was -21.0. running mean: -19.655818646485383, timestamp: 2022-08-20 00:16:10.047214\n",
      "resetting env. episode 4921, reward total was -18.0. running mean: -19.639260460020527, timestamp: 2022-08-20 00:16:18.082733\n",
      "resetting env. episode 4922, reward total was -17.0. running mean: -19.612867855420323, timestamp: 2022-08-20 00:16:23.540398\n",
      "resetting env. episode 4923, reward total was -19.0. running mean: -19.60673917686612, timestamp: 2022-08-20 00:16:27.457423\n",
      "resetting env. episode 4924, reward total was -19.0. running mean: -19.60067178509746, timestamp: 2022-08-20 00:16:33.337681\n",
      "resetting env. episode 4925, reward total was -21.0. running mean: -19.614665067246488, timestamp: 2022-08-20 00:16:39.882398\n",
      "resetting env. episode 4926, reward total was -19.0. running mean: -19.608518416574025, timestamp: 2022-08-20 00:16:45.861914\n",
      "resetting env. episode 4927, reward total was -21.0. running mean: -19.622433232408287, timestamp: 2022-08-20 00:16:49.802912\n",
      "resetting env. episode 4928, reward total was -16.0. running mean: -19.586208900084205, timestamp: 2022-08-20 00:16:54.318254\n",
      "resetting env. episode 4929, reward total was -20.0. running mean: -19.590346811083364, timestamp: 2022-08-20 00:16:58.301936\n",
      "resetting env. episode 4930, reward total was -19.0. running mean: -19.58444334297253, timestamp: 2022-08-20 00:17:02.234223\n",
      "resetting env. episode 4931, reward total was -19.0. running mean: -19.578598909542805, timestamp: 2022-08-20 00:17:06.176832\n",
      "resetting env. episode 4932, reward total was -20.0. running mean: -19.582812920447378, timestamp: 2022-08-20 00:17:09.317989\n",
      "resetting env. episode 4933, reward total was -17.0. running mean: -19.556984791242904, timestamp: 2022-08-20 00:17:13.249023\n",
      "resetting env. episode 4934, reward total was -19.0. running mean: -19.551414943330474, timestamp: 2022-08-20 00:17:16.690822\n",
      "resetting env. episode 4935, reward total was -18.0. running mean: -19.53590079389717, timestamp: 2022-08-20 00:17:21.708847\n",
      "resetting env. episode 4936, reward total was -16.0. running mean: -19.500541785958198, timestamp: 2022-08-20 00:17:27.769632\n",
      "resetting env. episode 4937, reward total was -20.0. running mean: -19.505536368098614, timestamp: 2022-08-20 00:17:33.452443\n",
      "resetting env. episode 4938, reward total was -20.0. running mean: -19.510481004417628, timestamp: 2022-08-20 00:17:36.523237\n",
      "resetting env. episode 4939, reward total was -21.0. running mean: -19.52537619437345, timestamp: 2022-08-20 00:17:40.436183\n",
      "resetting env. episode 4940, reward total was -21.0. running mean: -19.540122432429715, timestamp: 2022-08-20 00:17:43.887196\n",
      "resetting env. episode 4941, reward total was -20.0. running mean: -19.54472120810542, timestamp: 2022-08-20 00:17:48.335368\n",
      "resetting env. episode 4942, reward total was -20.0. running mean: -19.549273996024365, timestamp: 2022-08-20 00:17:52.902922\n",
      "resetting env. episode 4943, reward total was -19.0. running mean: -19.543781256064122, timestamp: 2022-08-20 00:17:55.855062\n",
      "resetting env. episode 4944, reward total was -19.0. running mean: -19.538343443503482, timestamp: 2022-08-20 00:17:59.752628\n",
      "resetting env. episode 4945, reward total was -21.0. running mean: -19.55296000906845, timestamp: 2022-08-20 00:18:03.605643\n",
      "resetting env. episode 4946, reward total was -21.0. running mean: -19.567430408977767, timestamp: 2022-08-20 00:18:06.680424\n",
      "resetting env. episode 4947, reward total was -20.0. running mean: -19.57175610488799, timestamp: 2022-08-20 00:18:11.816474\n",
      "resetting env. episode 4948, reward total was -21.0. running mean: -19.58603854383911, timestamp: 2022-08-20 00:18:14.939130\n",
      "resetting env. episode 4949, reward total was -19.0. running mean: -19.58017815840072, timestamp: 2022-08-20 00:18:17.814873\n",
      "resetting env. episode 4950, reward total was -20.0. running mean: -19.584376376816714, timestamp: 2022-08-20 00:18:20.849389\n",
      "resetting env. episode 4951, reward total was -20.0. running mean: -19.588532613048546, timestamp: 2022-08-20 00:18:25.415870\n",
      "resetting env. episode 4952, reward total was -21.0. running mean: -19.60264728691806, timestamp: 2022-08-20 00:18:27.859778\n",
      "resetting env. episode 4953, reward total was -19.0. running mean: -19.59662081404888, timestamp: 2022-08-20 00:18:32.712909\n",
      "resetting env. episode 4954, reward total was -18.0. running mean: -19.58065460590839, timestamp: 2022-08-20 00:18:36.909362\n",
      "resetting env. episode 4955, reward total was -19.0. running mean: -19.574848059849305, timestamp: 2022-08-20 00:18:41.508516\n",
      "resetting env. episode 4956, reward total was -21.0. running mean: -19.589099579250814, timestamp: 2022-08-20 00:18:44.932527\n",
      "resetting env. episode 4957, reward total was -19.0. running mean: -19.58320858345831, timestamp: 2022-08-20 00:18:49.563152\n",
      "resetting env. episode 4958, reward total was -20.0. running mean: -19.587376497623723, timestamp: 2022-08-20 00:18:54.027875\n",
      "resetting env. episode 4959, reward total was -21.0. running mean: -19.601502732647486, timestamp: 2022-08-20 00:18:58.971138\n",
      "resetting env. episode 4960, reward total was -19.0. running mean: -19.595487705321013, timestamp: 2022-08-20 00:19:03.080852\n",
      "resetting env. episode 4961, reward total was -19.0. running mean: -19.589532828267803, timestamp: 2022-08-20 00:19:07.331700\n",
      "resetting env. episode 4962, reward total was -19.0. running mean: -19.583637499985127, timestamp: 2022-08-20 00:19:12.189429\n",
      "resetting env. episode 4963, reward total was -21.0. running mean: -19.597801124985278, timestamp: 2022-08-20 00:19:15.127572\n",
      "resetting env. episode 4964, reward total was -19.0. running mean: -19.591823113735426, timestamp: 2022-08-20 00:19:19.942295\n",
      "resetting env. episode 4965, reward total was -20.0. running mean: -19.59590488259807, timestamp: 2022-08-20 00:19:23.687855\n",
      "resetting env. episode 4966, reward total was -17.0. running mean: -19.569945833772092, timestamp: 2022-08-20 00:19:28.164056\n",
      "resetting env. episode 4967, reward total was -19.0. running mean: -19.564246375434372, timestamp: 2022-08-20 00:19:31.604632\n",
      "resetting env. episode 4968, reward total was -18.0. running mean: -19.54860391168003, timestamp: 2022-08-20 00:19:36.641559\n",
      "resetting env. episode 4969, reward total was -18.0. running mean: -19.533117872563228, timestamp: 2022-08-20 00:19:40.048426\n",
      "resetting env. episode 4970, reward total was -18.0. running mean: -19.517786693837596, timestamp: 2022-08-20 00:19:44.644375\n",
      "resetting env. episode 4971, reward total was -20.0. running mean: -19.52260882689922, timestamp: 2022-08-20 00:19:48.275432\n",
      "resetting env. episode 4972, reward total was -18.0. running mean: -19.507382738630227, timestamp: 2022-08-20 00:19:52.085251\n",
      "resetting env. episode 4973, reward total was -18.0. running mean: -19.492308911243924, timestamp: 2022-08-20 00:19:56.099521\n",
      "resetting env. episode 4974, reward total was -19.0. running mean: -19.487385822131486, timestamp: 2022-08-20 00:20:00.181608\n",
      "resetting env. episode 4975, reward total was -20.0. running mean: -19.49251196391017, timestamp: 2022-08-20 00:20:04.513031\n",
      "resetting env. episode 4976, reward total was -19.0. running mean: -19.48758684427107, timestamp: 2022-08-20 00:20:08.430558\n",
      "resetting env. episode 4977, reward total was -21.0. running mean: -19.50271097582836, timestamp: 2022-08-20 00:20:12.915897\n",
      "resetting env. episode 4978, reward total was -21.0. running mean: -19.51768386607008, timestamp: 2022-08-20 00:20:17.054091\n",
      "resetting env. episode 4979, reward total was -20.0. running mean: -19.52250702740938, timestamp: 2022-08-20 00:20:21.176633\n",
      "resetting env. episode 4980, reward total was -17.0. running mean: -19.497281957135286, timestamp: 2022-08-20 00:20:25.861089\n",
      "resetting env. episode 4981, reward total was -19.0. running mean: -19.492309137563932, timestamp: 2022-08-20 00:20:30.725004\n",
      "resetting env. episode 4982, reward total was -19.0. running mean: -19.487386046188295, timestamp: 2022-08-20 00:20:34.953897\n",
      "resetting env. episode 4983, reward total was -17.0. running mean: -19.462512185726414, timestamp: 2022-08-20 00:20:39.174577\n",
      "resetting env. episode 4984, reward total was -18.0. running mean: -19.44788706386915, timestamp: 2022-08-20 00:20:43.682533\n",
      "resetting env. episode 4985, reward total was -21.0. running mean: -19.46340819323046, timestamp: 2022-08-20 00:20:47.455443\n",
      "resetting env. episode 4986, reward total was -19.0. running mean: -19.45877411129816, timestamp: 2022-08-20 00:20:51.486696\n",
      "resetting env. episode 4987, reward total was -21.0. running mean: -19.474186370185176, timestamp: 2022-08-20 00:20:55.663523\n",
      "resetting env. episode 4988, reward total was -21.0. running mean: -19.489444506483323, timestamp: 2022-08-20 00:21:00.377229\n",
      "resetting env. episode 4989, reward total was -19.0. running mean: -19.484550061418492, timestamp: 2022-08-20 00:21:04.536797\n",
      "resetting env. episode 4990, reward total was -18.0. running mean: -19.469704560804306, timestamp: 2022-08-20 00:21:09.566750\n",
      "resetting env. episode 4991, reward total was -20.0. running mean: -19.475007515196264, timestamp: 2022-08-20 00:21:14.246930\n",
      "resetting env. episode 4992, reward total was -19.0. running mean: -19.470257440044303, timestamp: 2022-08-20 00:21:18.081886\n",
      "resetting env. episode 4993, reward total was -21.0. running mean: -19.48555486564386, timestamp: 2022-08-20 00:21:21.851808\n",
      "resetting env. episode 4994, reward total was -21.0. running mean: -19.500699316987422, timestamp: 2022-08-20 00:21:25.556664\n",
      "resetting env. episode 4995, reward total was -21.0. running mean: -19.51569232381755, timestamp: 2022-08-20 00:21:28.772031\n",
      "resetting env. episode 4996, reward total was -18.0. running mean: -19.500535400579373, timestamp: 2022-08-20 00:21:34.662286\n",
      "resetting env. episode 4997, reward total was -20.0. running mean: -19.50553004657358, timestamp: 2022-08-20 00:21:38.173625\n",
      "resetting env. episode 4998, reward total was -20.0. running mean: -19.510474746107842, timestamp: 2022-08-20 00:21:41.416917\n",
      "resetting env. episode 4999, reward total was -17.0. running mean: -19.485369998646764, timestamp: 2022-08-20 00:21:46.363594\n",
      "resetting env. episode 5000, reward total was -17.0. running mean: -19.4605162986603, timestamp: 2022-08-20 00:21:52.603309\n",
      "resetting env. episode 5001, reward total was -19.0. running mean: -19.455911135673695, timestamp: 2022-08-20 00:21:57.327690\n",
      "resetting env. episode 5002, reward total was -19.0. running mean: -19.451352024316957, timestamp: 2022-08-20 00:22:02.130840\n",
      "resetting env. episode 5003, reward total was -20.0. running mean: -19.456838504073787, timestamp: 2022-08-20 00:22:06.273767\n",
      "resetting env. episode 5004, reward total was -17.0. running mean: -19.43227011903305, timestamp: 2022-08-20 00:22:10.639998\n",
      "resetting env. episode 5005, reward total was -18.0. running mean: -19.41794741784272, timestamp: 2022-08-20 00:22:15.040449\n",
      "resetting env. episode 5006, reward total was -21.0. running mean: -19.433767943664293, timestamp: 2022-08-20 00:22:18.578290\n",
      "resetting env. episode 5007, reward total was -17.0. running mean: -19.40943026422765, timestamp: 2022-08-20 00:22:22.904753\n",
      "resetting env. episode 5008, reward total was -20.0. running mean: -19.415335961585374, timestamp: 2022-08-20 00:22:27.659365\n",
      "resetting env. episode 5009, reward total was -20.0. running mean: -19.42118260196952, timestamp: 2022-08-20 00:22:31.307674\n",
      "resetting env. episode 5010, reward total was -20.0. running mean: -19.426970775949822, timestamp: 2022-08-20 00:22:35.053041\n",
      "resetting env. episode 5011, reward total was -18.0. running mean: -19.412701068190323, timestamp: 2022-08-20 00:22:39.394401\n",
      "resetting env. episode 5012, reward total was -20.0. running mean: -19.41857405750842, timestamp: 2022-08-20 00:22:43.292080\n",
      "resetting env. episode 5013, reward total was -20.0. running mean: -19.424388316933335, timestamp: 2022-08-20 00:22:47.026549\n",
      "resetting env. episode 5014, reward total was -20.0. running mean: -19.430144433764, timestamp: 2022-08-20 00:22:50.883663\n",
      "resetting env. episode 5015, reward total was -21.0. running mean: -19.44584298942636, timestamp: 2022-08-20 00:22:53.971926\n",
      "resetting env. episode 5016, reward total was -21.0. running mean: -19.461384559532096, timestamp: 2022-08-20 00:22:57.691982\n",
      "resetting env. episode 5017, reward total was -21.0. running mean: -19.476770713936777, timestamp: 2022-08-20 00:23:01.373146\n",
      "resetting env. episode 5018, reward total was -21.0. running mean: -19.49200300679741, timestamp: 2022-08-20 00:23:05.286682\n",
      "resetting env. episode 5019, reward total was -19.0. running mean: -19.48708297672944, timestamp: 2022-08-20 00:23:09.492988\n",
      "resetting env. episode 5020, reward total was -21.0. running mean: -19.502212146962147, timestamp: 2022-08-20 00:23:13.539171\n",
      "resetting env. episode 5021, reward total was -18.0. running mean: -19.487190025492527, timestamp: 2022-08-20 00:23:17.415795\n",
      "resetting env. episode 5022, reward total was -18.0. running mean: -19.472318125237603, timestamp: 2022-08-20 00:23:21.929050\n",
      "resetting env. episode 5023, reward total was -19.0. running mean: -19.46759494398523, timestamp: 2022-08-20 00:23:26.462168\n",
      "resetting env. episode 5024, reward total was -16.0. running mean: -19.43291899454538, timestamp: 2022-08-20 00:23:29.999705\n",
      "resetting env. episode 5025, reward total was -21.0. running mean: -19.448589804599926, timestamp: 2022-08-20 00:23:33.673257\n",
      "resetting env. episode 5026, reward total was -17.0. running mean: -19.424103906553928, timestamp: 2022-08-20 00:23:38.305947\n",
      "resetting env. episode 5027, reward total was -21.0. running mean: -19.43986286748839, timestamp: 2022-08-20 00:23:41.339837\n",
      "resetting env. episode 5028, reward total was -19.0. running mean: -19.43546423881351, timestamp: 2022-08-20 00:23:44.996132\n",
      "resetting env. episode 5029, reward total was -19.0. running mean: -19.431109596425376, timestamp: 2022-08-20 00:23:49.528870\n",
      "resetting env. episode 5030, reward total was -17.0. running mean: -19.406798500461125, timestamp: 2022-08-20 00:23:54.859399\n",
      "resetting env. episode 5031, reward total was -19.0. running mean: -19.402730515456515, timestamp: 2022-08-20 00:23:59.533055\n",
      "resetting env. episode 5032, reward total was -18.0. running mean: -19.388703210301948, timestamp: 2022-08-20 00:24:03.174317\n",
      "resetting env. episode 5033, reward total was -18.0. running mean: -19.374816178198927, timestamp: 2022-08-20 00:24:06.935268\n",
      "resetting env. episode 5034, reward total was -21.0. running mean: -19.391068016416938, timestamp: 2022-08-20 00:24:10.160651\n",
      "resetting env. episode 5035, reward total was -21.0. running mean: -19.40715733625277, timestamp: 2022-08-20 00:24:13.731102\n",
      "resetting env. episode 5036, reward total was -21.0. running mean: -19.423085762890242, timestamp: 2022-08-20 00:24:16.436866\n",
      "resetting env. episode 5037, reward total was -19.0. running mean: -19.41885490526134, timestamp: 2022-08-20 00:24:21.328188\n",
      "resetting env. episode 5038, reward total was -21.0. running mean: -19.43466635620873, timestamp: 2022-08-20 00:24:24.896628\n",
      "resetting env. episode 5039, reward total was -20.0. running mean: -19.440319692646643, timestamp: 2022-08-20 00:24:29.402107\n",
      "resetting env. episode 5040, reward total was -20.0. running mean: -19.445916495720176, timestamp: 2022-08-20 00:24:33.439289\n",
      "resetting env. episode 5041, reward total was -20.0. running mean: -19.451457330762974, timestamp: 2022-08-20 00:24:36.907019\n",
      "resetting env. episode 5042, reward total was -20.0. running mean: -19.456942757455344, timestamp: 2022-08-20 00:24:40.379562\n",
      "resetting env. episode 5043, reward total was -20.0. running mean: -19.46237332988079, timestamp: 2022-08-20 00:24:43.940511\n",
      "resetting env. episode 5044, reward total was -20.0. running mean: -19.46774959658198, timestamp: 2022-08-20 00:24:49.079804\n",
      "resetting env. episode 5045, reward total was -19.0. running mean: -19.463072100616163, timestamp: 2022-08-20 00:24:52.904928\n",
      "resetting env. episode 5046, reward total was -18.0. running mean: -19.44844137961, timestamp: 2022-08-20 00:24:56.763092\n",
      "resetting env. episode 5047, reward total was -21.0. running mean: -19.4639569658139, timestamp: 2022-08-20 00:25:00.332130\n",
      "resetting env. episode 5048, reward total was -21.0. running mean: -19.47931739615576, timestamp: 2022-08-20 00:25:04.281570\n",
      "resetting env. episode 5049, reward total was -19.0. running mean: -19.474524222194205, timestamp: 2022-08-20 00:25:08.338728\n",
      "resetting env. episode 5050, reward total was -19.0. running mean: -19.469778979972265, timestamp: 2022-08-20 00:25:12.505601\n",
      "resetting env. episode 5051, reward total was -20.0. running mean: -19.475081190172542, timestamp: 2022-08-20 00:25:16.723027\n",
      "resetting env. episode 5052, reward total was -21.0. running mean: -19.490330378270816, timestamp: 2022-08-20 00:25:20.635571\n",
      "resetting env. episode 5053, reward total was -19.0. running mean: -19.485427074488108, timestamp: 2022-08-20 00:25:24.945251\n",
      "resetting env. episode 5054, reward total was -18.0. running mean: -19.470572803743227, timestamp: 2022-08-20 00:25:29.546234\n",
      "resetting env. episode 5055, reward total was -17.0. running mean: -19.445867075705795, timestamp: 2022-08-20 00:25:33.476728\n",
      "resetting env. episode 5056, reward total was -17.0. running mean: -19.42140840494874, timestamp: 2022-08-20 00:25:37.361332\n",
      "resetting env. episode 5057, reward total was -20.0. running mean: -19.42719432089925, timestamp: 2022-08-20 00:25:41.168178\n",
      "resetting env. episode 5058, reward total was -21.0. running mean: -19.44292237769026, timestamp: 2022-08-20 00:25:45.195418\n",
      "resetting env. episode 5059, reward total was -19.0. running mean: -19.438493153913356, timestamp: 2022-08-20 00:25:49.667202\n",
      "resetting env. episode 5060, reward total was -18.0. running mean: -19.424108222374223, timestamp: 2022-08-20 00:25:54.383418\n",
      "resetting env. episode 5061, reward total was -17.0. running mean: -19.39986714015048, timestamp: 2022-08-20 00:25:59.341112\n",
      "resetting env. episode 5062, reward total was -19.0. running mean: -19.395868468748976, timestamp: 2022-08-20 00:26:02.913563\n",
      "resetting env. episode 5063, reward total was -18.0. running mean: -19.381909784061484, timestamp: 2022-08-20 00:26:07.592953\n",
      "resetting env. episode 5064, reward total was -20.0. running mean: -19.38809068622087, timestamp: 2022-08-20 00:26:10.759888\n",
      "resetting env. episode 5065, reward total was -21.0. running mean: -19.404209779358663, timestamp: 2022-08-20 00:26:14.701356\n",
      "resetting env. episode 5066, reward total was -18.0. running mean: -19.390167681565075, timestamp: 2022-08-20 00:26:18.977792\n",
      "resetting env. episode 5067, reward total was -21.0. running mean: -19.406266004749426, timestamp: 2022-08-20 00:26:22.649945\n",
      "resetting env. episode 5068, reward total was -20.0. running mean: -19.412203344701933, timestamp: 2022-08-20 00:26:26.059830\n",
      "resetting env. episode 5069, reward total was -20.0. running mean: -19.418081311254912, timestamp: 2022-08-20 00:26:29.605354\n",
      "resetting env. episode 5070, reward total was -18.0. running mean: -19.403900498142363, timestamp: 2022-08-20 00:26:34.058492\n",
      "resetting env. episode 5071, reward total was -19.0. running mean: -19.39986149316094, timestamp: 2022-08-20 00:26:38.714130\n",
      "resetting env. episode 5072, reward total was -19.0. running mean: -19.395862878229334, timestamp: 2022-08-20 00:26:42.701746\n",
      "resetting env. episode 5073, reward total was -21.0. running mean: -19.41190424944704, timestamp: 2022-08-20 00:26:47.155458\n",
      "resetting env. episode 5074, reward total was -20.0. running mean: -19.41778520695257, timestamp: 2022-08-20 00:26:50.484470\n",
      "resetting env. episode 5075, reward total was -20.0. running mean: -19.423607354883043, timestamp: 2022-08-20 00:26:54.216674\n",
      "resetting env. episode 5076, reward total was -20.0. running mean: -19.429371281334213, timestamp: 2022-08-20 00:26:56.938397\n",
      "resetting env. episode 5077, reward total was -21.0. running mean: -19.445077568520873, timestamp: 2022-08-20 00:26:59.924193\n",
      "resetting env. episode 5078, reward total was -18.0. running mean: -19.430626792835664, timestamp: 2022-08-20 00:27:04.557098\n",
      "resetting env. episode 5079, reward total was -20.0. running mean: -19.436320524907305, timestamp: 2022-08-20 00:27:08.672763\n",
      "resetting env. episode 5080, reward total was -21.0. running mean: -19.451957319658234, timestamp: 2022-08-20 00:27:12.292373\n",
      "resetting env. episode 5081, reward total was -21.0. running mean: -19.467437746461652, timestamp: 2022-08-20 00:27:15.238498\n",
      "resetting env. episode 5082, reward total was -20.0. running mean: -19.472763368997036, timestamp: 2022-08-20 00:27:20.023394\n",
      "resetting env. episode 5083, reward total was -20.0. running mean: -19.478035735307063, timestamp: 2022-08-20 00:27:24.378850\n",
      "resetting env. episode 5084, reward total was -21.0. running mean: -19.493255377953993, timestamp: 2022-08-20 00:27:27.684018\n",
      "resetting env. episode 5085, reward total was -19.0. running mean: -19.488322824174453, timestamp: 2022-08-20 00:27:31.897705\n",
      "resetting env. episode 5086, reward total was -19.0. running mean: -19.48343959593271, timestamp: 2022-08-20 00:27:34.900074\n",
      "resetting env. episode 5087, reward total was -18.0. running mean: -19.468605199973382, timestamp: 2022-08-20 00:27:39.462020\n",
      "resetting env. episode 5088, reward total was -17.0. running mean: -19.44391914797365, timestamp: 2022-08-20 00:27:44.178080\n",
      "resetting env. episode 5089, reward total was -19.0. running mean: -19.439479956493912, timestamp: 2022-08-20 00:27:48.065687\n",
      "resetting env. episode 5090, reward total was -20.0. running mean: -19.44508515692897, timestamp: 2022-08-20 00:27:51.331174\n",
      "resetting env. episode 5091, reward total was -20.0. running mean: -19.45063430535968, timestamp: 2022-08-20 00:27:55.524484\n",
      "resetting env. episode 5092, reward total was -18.0. running mean: -19.436127962306085, timestamp: 2022-08-20 00:27:59.670404\n",
      "resetting env. episode 5093, reward total was -18.0. running mean: -19.421766682683025, timestamp: 2022-08-20 00:28:05.471647\n",
      "resetting env. episode 5094, reward total was -21.0. running mean: -19.437549015856195, timestamp: 2022-08-20 00:28:08.656380\n",
      "resetting env. episode 5095, reward total was -19.0. running mean: -19.433173525697633, timestamp: 2022-08-20 00:28:12.495358\n",
      "resetting env. episode 5096, reward total was -19.0. running mean: -19.428841790440657, timestamp: 2022-08-20 00:28:18.021180\n",
      "resetting env. episode 5097, reward total was -20.0. running mean: -19.43455337253625, timestamp: 2022-08-20 00:28:22.152165\n",
      "resetting env. episode 5098, reward total was -19.0. running mean: -19.43020783881089, timestamp: 2022-08-20 00:28:27.373924\n",
      "resetting env. episode 5099, reward total was -19.0. running mean: -19.425905760422783, timestamp: 2022-08-20 00:28:32.121201\n",
      "resetting env. episode 5100, reward total was -20.0. running mean: -19.431646702818554, timestamp: 2022-08-20 00:28:35.969913\n",
      "resetting env. episode 5101, reward total was -21.0. running mean: -19.447330235790368, timestamp: 2022-08-20 00:28:39.178716\n",
      "resetting env. episode 5102, reward total was -20.0. running mean: -19.452856933432464, timestamp: 2022-08-20 00:28:43.537733\n",
      "resetting env. episode 5103, reward total was -20.0. running mean: -19.45832836409814, timestamp: 2022-08-20 00:28:48.129009\n",
      "resetting env. episode 5104, reward total was -20.0. running mean: -19.46374508045716, timestamp: 2022-08-20 00:28:51.780028\n",
      "resetting env. episode 5105, reward total was -20.0. running mean: -19.469107629652587, timestamp: 2022-08-20 00:28:56.225712\n",
      "resetting env. episode 5106, reward total was -19.0. running mean: -19.464416553356063, timestamp: 2022-08-20 00:28:59.532874\n",
      "resetting env. episode 5107, reward total was -17.0. running mean: -19.439772387822504, timestamp: 2022-08-20 00:29:04.003432\n",
      "resetting env. episode 5108, reward total was -19.0. running mean: -19.43537466394428, timestamp: 2022-08-20 00:29:07.923100\n",
      "resetting env. episode 5109, reward total was -20.0. running mean: -19.441020917304837, timestamp: 2022-08-20 00:29:12.303396\n",
      "resetting env. episode 5110, reward total was -20.0. running mean: -19.446610708131786, timestamp: 2022-08-20 00:29:16.341924\n",
      "resetting env. episode 5111, reward total was -19.0. running mean: -19.44214460105047, timestamp: 2022-08-20 00:29:20.115829\n",
      "resetting env. episode 5112, reward total was -21.0. running mean: -19.457723155039965, timestamp: 2022-08-20 00:29:24.225374\n",
      "resetting env. episode 5113, reward total was -18.0. running mean: -19.443145923489563, timestamp: 2022-08-20 00:29:27.955403\n",
      "resetting env. episode 5114, reward total was -21.0. running mean: -19.45871446425467, timestamp: 2022-08-20 00:29:31.660483\n",
      "resetting env. episode 5115, reward total was -14.0. running mean: -19.404127319612122, timestamp: 2022-08-20 00:29:37.026658\n",
      "resetting env. episode 5116, reward total was -17.0. running mean: -19.380086046416004, timestamp: 2022-08-20 00:29:41.605389\n",
      "resetting env. episode 5117, reward total was -19.0. running mean: -19.376285185951843, timestamp: 2022-08-20 00:29:46.062675\n",
      "resetting env. episode 5118, reward total was -19.0. running mean: -19.372522334092327, timestamp: 2022-08-20 00:29:50.321417\n",
      "resetting env. episode 5119, reward total was -20.0. running mean: -19.378797110751403, timestamp: 2022-08-20 00:29:55.047716\n",
      "resetting env. episode 5120, reward total was -21.0. running mean: -19.39500913964389, timestamp: 2022-08-20 00:29:59.018100\n",
      "resetting env. episode 5121, reward total was -21.0. running mean: -19.411059048247452, timestamp: 2022-08-20 00:30:02.394077\n",
      "resetting env. episode 5122, reward total was -17.0. running mean: -19.38694845776498, timestamp: 2022-08-20 00:30:07.443201\n",
      "resetting env. episode 5123, reward total was -21.0. running mean: -19.40307897318733, timestamp: 2022-08-20 00:30:11.167025\n",
      "resetting env. episode 5124, reward total was -18.0. running mean: -19.389048183455458, timestamp: 2022-08-20 00:30:15.840235\n",
      "resetting env. episode 5125, reward total was -20.0. running mean: -19.395157701620903, timestamp: 2022-08-20 00:30:19.005469\n",
      "resetting env. episode 5126, reward total was -17.0. running mean: -19.371206124604697, timestamp: 2022-08-20 00:30:22.815153\n",
      "resetting env. episode 5127, reward total was -20.0. running mean: -19.37749406335865, timestamp: 2022-08-20 00:30:26.410535\n",
      "resetting env. episode 5128, reward total was -20.0. running mean: -19.38371912272506, timestamp: 2022-08-20 00:30:29.665833\n",
      "resetting env. episode 5129, reward total was -17.0. running mean: -19.359881931497814, timestamp: 2022-08-20 00:30:33.924450\n",
      "resetting env. episode 5130, reward total was -19.0. running mean: -19.356283112182837, timestamp: 2022-08-20 00:30:39.523264\n",
      "resetting env. episode 5131, reward total was -21.0. running mean: -19.37272028106101, timestamp: 2022-08-20 00:30:43.641890\n",
      "resetting env. episode 5132, reward total was -21.0. running mean: -19.3889930782504, timestamp: 2022-08-20 00:30:47.632221\n",
      "resetting env. episode 5133, reward total was -19.0. running mean: -19.3851031474679, timestamp: 2022-08-20 00:30:52.119851\n",
      "resetting env. episode 5134, reward total was -20.0. running mean: -19.39125211599322, timestamp: 2022-08-20 00:30:55.932432\n",
      "resetting env. episode 5135, reward total was -18.0. running mean: -19.377339594833284, timestamp: 2022-08-20 00:31:00.449119\n",
      "resetting env. episode 5136, reward total was -19.0. running mean: -19.37356619888495, timestamp: 2022-08-20 00:31:04.299822\n",
      "resetting env. episode 5137, reward total was -21.0. running mean: -19.389830536896103, timestamp: 2022-08-20 00:31:08.233237\n",
      "resetting env. episode 5138, reward total was -21.0. running mean: -19.405932231527142, timestamp: 2022-08-20 00:31:11.996169\n",
      "resetting env. episode 5139, reward total was -21.0. running mean: -19.42187290921187, timestamp: 2022-08-20 00:31:15.601777\n",
      "resetting env. episode 5140, reward total was -18.0. running mean: -19.407654180119753, timestamp: 2022-08-20 00:31:20.590750\n",
      "resetting env. episode 5141, reward total was -19.0. running mean: -19.403577638318556, timestamp: 2022-08-20 00:31:25.130454\n",
      "resetting env. episode 5142, reward total was -21.0. running mean: -19.41954186193537, timestamp: 2022-08-20 00:31:28.856469\n",
      "resetting env. episode 5143, reward total was -20.0. running mean: -19.425346443316016, timestamp: 2022-08-20 00:31:32.646337\n",
      "resetting env. episode 5144, reward total was -21.0. running mean: -19.441092978882857, timestamp: 2022-08-20 00:31:36.772621\n",
      "resetting env. episode 5145, reward total was -20.0. running mean: -19.446682049094026, timestamp: 2022-08-20 00:31:41.093828\n",
      "resetting env. episode 5146, reward total was -18.0. running mean: -19.432215228603084, timestamp: 2022-08-20 00:31:45.041275\n",
      "resetting env. episode 5147, reward total was -20.0. running mean: -19.437893076317053, timestamp: 2022-08-20 00:31:49.406214\n",
      "resetting env. episode 5148, reward total was -19.0. running mean: -19.433514145553882, timestamp: 2022-08-20 00:31:53.977984\n",
      "resetting env. episode 5149, reward total was -17.0. running mean: -19.409179004098345, timestamp: 2022-08-20 00:31:58.889454\n",
      "resetting env. episode 5150, reward total was -19.0. running mean: -19.405087214057364, timestamp: 2022-08-20 00:32:02.977524\n",
      "resetting env. episode 5151, reward total was -18.0. running mean: -19.39103634191679, timestamp: 2022-08-20 00:32:06.392394\n",
      "resetting env. episode 5152, reward total was -21.0. running mean: -19.407125978497625, timestamp: 2022-08-20 00:32:10.278008\n",
      "resetting env. episode 5153, reward total was -20.0. running mean: -19.413054718712647, timestamp: 2022-08-20 00:32:15.079176\n",
      "resetting env. episode 5154, reward total was -18.0. running mean: -19.398924171525522, timestamp: 2022-08-20 00:32:20.060292\n",
      "resetting env. episode 5155, reward total was -18.0. running mean: -19.384934929810267, timestamp: 2022-08-20 00:32:25.482348\n",
      "resetting env. episode 5156, reward total was -18.0. running mean: -19.371085580512165, timestamp: 2022-08-20 00:32:29.509709\n",
      "resetting env. episode 5157, reward total was -21.0. running mean: -19.387374724707044, timestamp: 2022-08-20 00:32:34.341201\n",
      "resetting env. episode 5158, reward total was -20.0. running mean: -19.393500977459972, timestamp: 2022-08-20 00:32:38.203875\n",
      "resetting env. episode 5159, reward total was -18.0. running mean: -19.379565967685373, timestamp: 2022-08-20 00:32:43.683228\n",
      "resetting env. episode 5160, reward total was -21.0. running mean: -19.39577030800852, timestamp: 2022-08-20 00:32:47.133009\n",
      "resetting env. episode 5161, reward total was -19.0. running mean: -19.391812604928436, timestamp: 2022-08-20 00:32:50.923062\n",
      "resetting env. episode 5162, reward total was -20.0. running mean: -19.397894478879152, timestamp: 2022-08-20 00:32:54.774132\n",
      "resetting env. episode 5163, reward total was -18.0. running mean: -19.38391553409036, timestamp: 2022-08-20 00:32:59.331898\n",
      "resetting env. episode 5164, reward total was -19.0. running mean: -19.380076378749457, timestamp: 2022-08-20 00:33:03.260896\n",
      "resetting env. episode 5165, reward total was -18.0. running mean: -19.366275614961964, timestamp: 2022-08-20 00:33:08.256576\n",
      "resetting env. episode 5166, reward total was -21.0. running mean: -19.382612858812344, timestamp: 2022-08-20 00:33:12.217590\n",
      "resetting env. episode 5167, reward total was -17.0. running mean: -19.35878673022422, timestamp: 2022-08-20 00:33:17.417444\n",
      "resetting env. episode 5168, reward total was -18.0. running mean: -19.34519886292198, timestamp: 2022-08-20 00:33:21.655090\n",
      "resetting env. episode 5169, reward total was -17.0. running mean: -19.32174687429276, timestamp: 2022-08-20 00:33:25.803001\n",
      "resetting env. episode 5170, reward total was -19.0. running mean: -19.318529405549835, timestamp: 2022-08-20 00:33:29.164787\n",
      "resetting env. episode 5171, reward total was -19.0. running mean: -19.315344111494337, timestamp: 2022-08-20 00:33:32.849445\n",
      "resetting env. episode 5172, reward total was -20.0. running mean: -19.322190670379392, timestamp: 2022-08-20 00:33:36.403945\n",
      "resetting env. episode 5173, reward total was -21.0. running mean: -19.3389687636756, timestamp: 2022-08-20 00:33:39.271314\n",
      "resetting env. episode 5174, reward total was -21.0. running mean: -19.355579076038843, timestamp: 2022-08-20 00:33:42.711934\n",
      "resetting env. episode 5175, reward total was -20.0. running mean: -19.362023285278454, timestamp: 2022-08-20 00:33:46.097868\n",
      "resetting env. episode 5176, reward total was -20.0. running mean: -19.36840305242567, timestamp: 2022-08-20 00:33:50.384425\n",
      "resetting env. episode 5177, reward total was -19.0. running mean: -19.364719021901415, timestamp: 2022-08-20 00:33:54.159518\n",
      "resetting env. episode 5178, reward total was -21.0. running mean: -19.3810718316824, timestamp: 2022-08-20 00:33:58.553752\n",
      "resetting env. episode 5179, reward total was -18.0. running mean: -19.367261113365576, timestamp: 2022-08-20 00:34:03.545051\n",
      "resetting env. episode 5180, reward total was -21.0. running mean: -19.38358850223192, timestamp: 2022-08-20 00:34:08.074012\n",
      "resetting env. episode 5181, reward total was -21.0. running mean: -19.3997526172096, timestamp: 2022-08-20 00:34:12.532191\n",
      "resetting env. episode 5182, reward total was -17.0. running mean: -19.375755091037504, timestamp: 2022-08-20 00:34:16.779026\n",
      "resetting env. episode 5183, reward total was -19.0. running mean: -19.37199754012713, timestamp: 2022-08-20 00:34:20.919990\n",
      "resetting env. episode 5184, reward total was -18.0. running mean: -19.358277564725856, timestamp: 2022-08-20 00:34:25.752070\n",
      "resetting env. episode 5185, reward total was -20.0. running mean: -19.364694789078598, timestamp: 2022-08-20 00:34:29.092141\n",
      "resetting env. episode 5186, reward total was -18.0. running mean: -19.35104784118781, timestamp: 2022-08-20 00:34:32.588529\n",
      "resetting env. episode 5187, reward total was -19.0. running mean: -19.347537362775935, timestamp: 2022-08-20 00:34:37.681909\n",
      "resetting env. episode 5188, reward total was -21.0. running mean: -19.364061989148176, timestamp: 2022-08-20 00:34:41.298187\n",
      "resetting env. episode 5189, reward total was -20.0. running mean: -19.370421369256693, timestamp: 2022-08-20 00:34:45.003187\n",
      "resetting env. episode 5190, reward total was -20.0. running mean: -19.376717155564126, timestamp: 2022-08-20 00:34:48.380607\n",
      "resetting env. episode 5191, reward total was -21.0. running mean: -19.392949984008485, timestamp: 2022-08-20 00:34:52.029854\n",
      "resetting env. episode 5192, reward total was -19.0. running mean: -19.3890204841684, timestamp: 2022-08-20 00:34:55.823098\n",
      "resetting env. episode 5193, reward total was -18.0. running mean: -19.37513027932672, timestamp: 2022-08-20 00:35:00.095676\n",
      "resetting env. episode 5194, reward total was -21.0. running mean: -19.391378976533453, timestamp: 2022-08-20 00:35:03.778364\n",
      "resetting env. episode 5195, reward total was -21.0. running mean: -19.407465186768118, timestamp: 2022-08-20 00:35:08.237971\n",
      "resetting env. episode 5196, reward total was -19.0. running mean: -19.40339053490044, timestamp: 2022-08-20 00:35:11.871272\n",
      "resetting env. episode 5197, reward total was -18.0. running mean: -19.389356629551433, timestamp: 2022-08-20 00:35:16.598246\n",
      "resetting env. episode 5198, reward total was -18.0. running mean: -19.375463063255918, timestamp: 2022-08-20 00:35:20.610879\n",
      "resetting env. episode 5199, reward total was -20.0. running mean: -19.38170843262336, timestamp: 2022-08-20 00:35:24.699942\n",
      "resetting env. episode 5200, reward total was -20.0. running mean: -19.387891348297124, timestamp: 2022-08-20 00:35:28.835424\n",
      "resetting env. episode 5201, reward total was -20.0. running mean: -19.39401243481415, timestamp: 2022-08-20 00:35:32.006707\n",
      "resetting env. episode 5202, reward total was -21.0. running mean: -19.41007231046601, timestamp: 2022-08-20 00:35:35.213136\n",
      "resetting env. episode 5203, reward total was -20.0. running mean: -19.415971587361348, timestamp: 2022-08-20 00:35:38.593777\n",
      "resetting env. episode 5204, reward total was -19.0. running mean: -19.411811871487735, timestamp: 2022-08-20 00:35:42.391065\n",
      "resetting env. episode 5205, reward total was -16.0. running mean: -19.377693752772856, timestamp: 2022-08-20 00:35:46.699775\n",
      "resetting env. episode 5206, reward total was -20.0. running mean: -19.383916815245126, timestamp: 2022-08-20 00:35:50.780867\n",
      "resetting env. episode 5207, reward total was -19.0. running mean: -19.380077647092676, timestamp: 2022-08-20 00:35:55.586842\n",
      "resetting env. episode 5208, reward total was -21.0. running mean: -19.39627687062175, timestamp: 2022-08-20 00:35:59.522608\n",
      "resetting env. episode 5209, reward total was -20.0. running mean: -19.402314101915533, timestamp: 2022-08-20 00:36:03.544022\n",
      "resetting env. episode 5210, reward total was -19.0. running mean: -19.39829096089638, timestamp: 2022-08-20 00:36:08.168661\n",
      "resetting env. episode 5211, reward total was -19.0. running mean: -19.394308051287418, timestamp: 2022-08-20 00:36:12.193900\n",
      "resetting env. episode 5212, reward total was -18.0. running mean: -19.380364970774544, timestamp: 2022-08-20 00:36:16.786659\n",
      "resetting env. episode 5213, reward total was -17.0. running mean: -19.3565613210668, timestamp: 2022-08-20 00:36:21.647115\n",
      "resetting env. episode 5214, reward total was -20.0. running mean: -19.36299570785613, timestamp: 2022-08-20 00:36:25.661234\n",
      "resetting env. episode 5215, reward total was -19.0. running mean: -19.35936575077757, timestamp: 2022-08-20 00:36:29.983123\n",
      "resetting env. episode 5216, reward total was -19.0. running mean: -19.355772093269795, timestamp: 2022-08-20 00:36:34.428840\n",
      "resetting env. episode 5217, reward total was -19.0. running mean: -19.352214372337098, timestamp: 2022-08-20 00:36:38.529365\n",
      "resetting env. episode 5218, reward total was -17.0. running mean: -19.32869222861373, timestamp: 2022-08-20 00:36:42.863778\n",
      "resetting env. episode 5219, reward total was -19.0. running mean: -19.325405306327593, timestamp: 2022-08-20 00:36:46.572379\n",
      "resetting env. episode 5220, reward total was -21.0. running mean: -19.342151253264316, timestamp: 2022-08-20 00:36:50.023123\n",
      "resetting env. episode 5221, reward total was -19.0. running mean: -19.338729740731672, timestamp: 2022-08-20 00:36:54.239851\n",
      "resetting env. episode 5222, reward total was -21.0. running mean: -19.355342443324357, timestamp: 2022-08-20 00:36:57.888047\n",
      "resetting env. episode 5223, reward total was -19.0. running mean: -19.351789018891115, timestamp: 2022-08-20 00:37:01.802658\n",
      "resetting env. episode 5224, reward total was -20.0. running mean: -19.358271128702203, timestamp: 2022-08-20 00:37:05.164896\n",
      "resetting env. episode 5225, reward total was -20.0. running mean: -19.36468841741518, timestamp: 2022-08-20 00:37:08.465324\n",
      "resetting env. episode 5226, reward total was -21.0. running mean: -19.381041533241028, timestamp: 2022-08-20 00:37:12.054726\n",
      "resetting env. episode 5227, reward total was -19.0. running mean: -19.377231117908618, timestamp: 2022-08-20 00:37:15.924314\n",
      "resetting env. episode 5228, reward total was -21.0. running mean: -19.393458806729534, timestamp: 2022-08-20 00:37:20.136057\n",
      "resetting env. episode 5229, reward total was -20.0. running mean: -19.399524218662236, timestamp: 2022-08-20 00:37:23.776326\n",
      "resetting env. episode 5230, reward total was -18.0. running mean: -19.385528976475612, timestamp: 2022-08-20 00:37:28.048938\n",
      "resetting env. episode 5231, reward total was -20.0. running mean: -19.391673686710856, timestamp: 2022-08-20 00:37:32.179311\n",
      "resetting env. episode 5232, reward total was -20.0. running mean: -19.397756949843746, timestamp: 2022-08-20 00:37:36.224475\n",
      "resetting env. episode 5233, reward total was -21.0. running mean: -19.41377938034531, timestamp: 2022-08-20 00:37:39.734318\n",
      "resetting env. episode 5234, reward total was -20.0. running mean: -19.419641586541857, timestamp: 2022-08-20 00:37:43.633893\n",
      "resetting env. episode 5235, reward total was -20.0. running mean: -19.425445170676436, timestamp: 2022-08-20 00:37:47.148497\n",
      "resetting env. episode 5236, reward total was -19.0. running mean: -19.421190718969672, timestamp: 2022-08-20 00:37:51.060392\n",
      "resetting env. episode 5237, reward total was -21.0. running mean: -19.436978811779976, timestamp: 2022-08-20 00:37:55.185139\n",
      "resetting env. episode 5238, reward total was -21.0. running mean: -19.452609023662177, timestamp: 2022-08-20 00:37:58.546772\n",
      "resetting env. episode 5239, reward total was -17.0. running mean: -19.428082933425557, timestamp: 2022-08-20 00:38:03.697137\n",
      "resetting env. episode 5240, reward total was -17.0. running mean: -19.4038021040913, timestamp: 2022-08-20 00:38:07.872981\n",
      "resetting env. episode 5241, reward total was -19.0. running mean: -19.39976408305039, timestamp: 2022-08-20 00:38:11.616033\n",
      "resetting env. episode 5242, reward total was -18.0. running mean: -19.385766442219886, timestamp: 2022-08-20 00:38:15.784893\n",
      "resetting env. episode 5243, reward total was -19.0. running mean: -19.381908777797687, timestamp: 2022-08-20 00:38:20.545104\n",
      "resetting env. episode 5244, reward total was -19.0. running mean: -19.37808969001971, timestamp: 2022-08-20 00:38:24.399547\n",
      "resetting env. episode 5245, reward total was -19.0. running mean: -19.374308793119514, timestamp: 2022-08-20 00:38:28.797151\n",
      "resetting env. episode 5246, reward total was -20.0. running mean: -19.380565705188317, timestamp: 2022-08-20 00:38:32.747458\n",
      "resetting env. episode 5247, reward total was -17.0. running mean: -19.356760048136437, timestamp: 2022-08-20 00:38:37.170609\n",
      "resetting env. episode 5248, reward total was -19.0. running mean: -19.353192447655072, timestamp: 2022-08-20 00:38:41.580231\n",
      "resetting env. episode 5249, reward total was -15.0. running mean: -19.30966052317852, timestamp: 2022-08-20 00:38:46.532810\n",
      "resetting env. episode 5250, reward total was -20.0. running mean: -19.31656391794673, timestamp: 2022-08-20 00:38:51.210743\n",
      "resetting env. episode 5251, reward total was -19.0. running mean: -19.313398278767263, timestamp: 2022-08-20 00:38:55.813274\n",
      "resetting env. episode 5252, reward total was -19.0. running mean: -19.310264295979593, timestamp: 2022-08-20 00:39:00.634646\n",
      "resetting env. episode 5253, reward total was -21.0. running mean: -19.327161653019797, timestamp: 2022-08-20 00:39:03.669175\n",
      "resetting env. episode 5254, reward total was -19.0. running mean: -19.3238900364896, timestamp: 2022-08-20 00:39:07.795750\n",
      "resetting env. episode 5255, reward total was -18.0. running mean: -19.310651136124704, timestamp: 2022-08-20 00:39:13.044151\n",
      "resetting env. episode 5256, reward total was -20.0. running mean: -19.317544624763457, timestamp: 2022-08-20 00:39:16.727006\n",
      "resetting env. episode 5257, reward total was -20.0. running mean: -19.32436917851582, timestamp: 2022-08-20 00:39:21.437390\n",
      "resetting env. episode 5258, reward total was -19.0. running mean: -19.32112548673066, timestamp: 2022-08-20 00:39:26.094225\n",
      "resetting env. episode 5259, reward total was -19.0. running mean: -19.317914231863355, timestamp: 2022-08-20 00:39:30.025103\n",
      "resetting env. episode 5260, reward total was -21.0. running mean: -19.334735089544722, timestamp: 2022-08-20 00:39:33.325277\n",
      "resetting env. episode 5261, reward total was -21.0. running mean: -19.351387738649276, timestamp: 2022-08-20 00:39:36.936107\n",
      "resetting env. episode 5262, reward total was -18.0. running mean: -19.337873861262782, timestamp: 2022-08-20 00:39:40.693069\n",
      "resetting env. episode 5263, reward total was -21.0. running mean: -19.354495122650157, timestamp: 2022-08-20 00:39:44.646999\n",
      "resetting env. episode 5264, reward total was -17.0. running mean: -19.330950171423655, timestamp: 2022-08-20 00:39:49.143980\n",
      "resetting env. episode 5265, reward total was -19.0. running mean: -19.32764066970942, timestamp: 2022-08-20 00:39:53.193154\n",
      "resetting env. episode 5266, reward total was -19.0. running mean: -19.324364263012328, timestamp: 2022-08-20 00:39:56.823452\n",
      "resetting env. episode 5267, reward total was -21.0. running mean: -19.341120620382206, timestamp: 2022-08-20 00:40:00.976676\n",
      "resetting env. episode 5268, reward total was -19.0. running mean: -19.337709414178384, timestamp: 2022-08-20 00:40:06.126919\n",
      "resetting env. episode 5269, reward total was -21.0. running mean: -19.3543323200366, timestamp: 2022-08-20 00:40:10.109550\n",
      "resetting env. episode 5270, reward total was -19.0. running mean: -19.350788996836236, timestamp: 2022-08-20 00:40:14.380005\n",
      "resetting env. episode 5271, reward total was -21.0. running mean: -19.367281106867875, timestamp: 2022-08-20 00:40:17.608412\n",
      "resetting env. episode 5272, reward total was -16.0. running mean: -19.333608295799195, timestamp: 2022-08-20 00:40:23.615955\n",
      "resetting env. episode 5273, reward total was -18.0. running mean: -19.320272212841203, timestamp: 2022-08-20 00:40:27.481184\n",
      "resetting env. episode 5274, reward total was -19.0. running mean: -19.317069490712793, timestamp: 2022-08-20 00:40:31.417972\n",
      "resetting env. episode 5275, reward total was -18.0. running mean: -19.303898795805665, timestamp: 2022-08-20 00:40:35.887105\n",
      "resetting env. episode 5276, reward total was -18.0. running mean: -19.290859807847607, timestamp: 2022-08-20 00:40:41.066451\n",
      "resetting env. episode 5277, reward total was -17.0. running mean: -19.267951209769134, timestamp: 2022-08-20 00:40:46.744520\n",
      "resetting env. episode 5278, reward total was -19.0. running mean: -19.265271697671444, timestamp: 2022-08-20 00:40:51.428952\n",
      "resetting env. episode 5279, reward total was -21.0. running mean: -19.282618980694732, timestamp: 2022-08-20 00:40:54.919620\n",
      "resetting env. episode 5280, reward total was -21.0. running mean: -19.299792790887786, timestamp: 2022-08-20 00:40:58.351823\n",
      "resetting env. episode 5281, reward total was -20.0. running mean: -19.306794862978908, timestamp: 2022-08-20 00:41:02.005029\n",
      "resetting env. episode 5282, reward total was -20.0. running mean: -19.313726914349118, timestamp: 2022-08-20 00:41:05.784921\n",
      "resetting env. episode 5283, reward total was -16.0. running mean: -19.280589645205627, timestamp: 2022-08-20 00:41:10.862572\n",
      "resetting env. episode 5284, reward total was -18.0. running mean: -19.26778374875357, timestamp: 2022-08-20 00:41:14.929263\n",
      "resetting env. episode 5285, reward total was -19.0. running mean: -19.265105911266033, timestamp: 2022-08-20 00:41:19.525462\n",
      "resetting env. episode 5286, reward total was -21.0. running mean: -19.282454852153375, timestamp: 2022-08-20 00:41:22.286084\n",
      "resetting env. episode 5287, reward total was -21.0. running mean: -19.29963030363184, timestamp: 2022-08-20 00:41:25.762788\n",
      "resetting env. episode 5288, reward total was -18.0. running mean: -19.286634000595523, timestamp: 2022-08-20 00:41:31.236126\n",
      "resetting env. episode 5289, reward total was -21.0. running mean: -19.303767660589568, timestamp: 2022-08-20 00:41:34.847474\n",
      "resetting env. episode 5290, reward total was -21.0. running mean: -19.32072998398367, timestamp: 2022-08-20 00:41:37.795592\n",
      "resetting env. episode 5291, reward total was -20.0. running mean: -19.327522684143833, timestamp: 2022-08-20 00:41:42.596827\n",
      "resetting env. episode 5292, reward total was -19.0. running mean: -19.324247457302395, timestamp: 2022-08-20 00:41:47.008520\n",
      "resetting env. episode 5293, reward total was -20.0. running mean: -19.33100498272937, timestamp: 2022-08-20 00:41:51.261428\n",
      "resetting env. episode 5294, reward total was -19.0. running mean: -19.32769493290208, timestamp: 2022-08-20 00:41:54.924305\n",
      "resetting env. episode 5295, reward total was -19.0. running mean: -19.32441798357306, timestamp: 2022-08-20 00:41:58.845849\n",
      "resetting env. episode 5296, reward total was -21.0. running mean: -19.34117380373733, timestamp: 2022-08-20 00:42:03.082487\n",
      "resetting env. episode 5297, reward total was -21.0. running mean: -19.35776206569996, timestamp: 2022-08-20 00:42:06.604089\n",
      "resetting env. episode 5298, reward total was -18.0. running mean: -19.34418444504296, timestamp: 2022-08-20 00:42:10.697167\n",
      "resetting env. episode 5299, reward total was -17.0. running mean: -19.32074260059253, timestamp: 2022-08-20 00:42:14.603693\n",
      "resetting env. episode 5300, reward total was -21.0. running mean: -19.337535174586606, timestamp: 2022-08-20 00:42:18.623972\n",
      "resetting env. episode 5301, reward total was -19.0. running mean: -19.33415982284074, timestamp: 2022-08-20 00:42:22.104641\n",
      "resetting env. episode 5302, reward total was -21.0. running mean: -19.350818224612333, timestamp: 2022-08-20 00:42:25.408811\n",
      "resetting env. episode 5303, reward total was -20.0. running mean: -19.35731004236621, timestamp: 2022-08-20 00:42:29.695935\n",
      "resetting env. episode 5304, reward total was -19.0. running mean: -19.353736941942547, timestamp: 2022-08-20 00:42:32.913969\n",
      "resetting env. episode 5305, reward total was -19.0. running mean: -19.350199572523124, timestamp: 2022-08-20 00:42:37.715836\n",
      "resetting env. episode 5306, reward total was -19.0. running mean: -19.346697576797894, timestamp: 2022-08-20 00:42:42.758863\n",
      "resetting env. episode 5307, reward total was -17.0. running mean: -19.323230601029916, timestamp: 2022-08-20 00:42:48.325012\n",
      "resetting env. episode 5308, reward total was -19.0. running mean: -19.31999829501962, timestamp: 2022-08-20 00:42:53.094565\n",
      "resetting env. episode 5309, reward total was -21.0. running mean: -19.336798312069423, timestamp: 2022-08-20 00:42:56.592218\n",
      "resetting env. episode 5310, reward total was -20.0. running mean: -19.343430328948727, timestamp: 2022-08-20 00:43:00.683083\n",
      "resetting env. episode 5311, reward total was -19.0. running mean: -19.339996025659243, timestamp: 2022-08-20 00:43:05.469301\n",
      "resetting env. episode 5312, reward total was -19.0. running mean: -19.336596065402652, timestamp: 2022-08-20 00:43:09.813724\n",
      "resetting env. episode 5313, reward total was -19.0. running mean: -19.333230104748626, timestamp: 2022-08-20 00:43:13.720570\n",
      "resetting env. episode 5314, reward total was -21.0. running mean: -19.34989780370114, timestamp: 2022-08-20 00:43:17.383696\n",
      "resetting env. episode 5315, reward total was -20.0. running mean: -19.356398825664126, timestamp: 2022-08-20 00:43:20.926020\n",
      "resetting env. episode 5316, reward total was -18.0. running mean: -19.342834837407484, timestamp: 2022-08-20 00:43:24.546849\n",
      "resetting env. episode 5317, reward total was -21.0. running mean: -19.35940648903341, timestamp: 2022-08-20 00:43:28.242947\n",
      "resetting env. episode 5318, reward total was -20.0. running mean: -19.365812424143076, timestamp: 2022-08-20 00:43:31.391651\n",
      "resetting env. episode 5319, reward total was -21.0. running mean: -19.382154299901647, timestamp: 2022-08-20 00:43:36.002451\n",
      "resetting env. episode 5320, reward total was -19.0. running mean: -19.37833275690263, timestamp: 2022-08-20 00:43:39.427293\n",
      "resetting env. episode 5321, reward total was -20.0. running mean: -19.384549429333603, timestamp: 2022-08-20 00:43:43.397687\n",
      "resetting env. episode 5322, reward total was -21.0. running mean: -19.40070393504027, timestamp: 2022-08-20 00:43:46.758663\n",
      "resetting env. episode 5323, reward total was -21.0. running mean: -19.416696895689867, timestamp: 2022-08-20 00:43:50.840751\n",
      "resetting env. episode 5324, reward total was -20.0. running mean: -19.422529926732967, timestamp: 2022-08-20 00:43:55.017588\n",
      "resetting env. episode 5325, reward total was -20.0. running mean: -19.428304627465636, timestamp: 2022-08-20 00:43:58.940110\n",
      "resetting env. episode 5326, reward total was -16.0. running mean: -19.39402158119098, timestamp: 2022-08-20 00:44:03.729897\n",
      "resetting env. episode 5327, reward total was -21.0. running mean: -19.41008136537907, timestamp: 2022-08-20 00:44:07.055022\n",
      "resetting env. episode 5328, reward total was -19.0. running mean: -19.405980551725282, timestamp: 2022-08-20 00:44:11.418670\n",
      "resetting env. episode 5329, reward total was -21.0. running mean: -19.42192074620803, timestamp: 2022-08-20 00:44:14.622357\n",
      "resetting env. episode 5330, reward total was -19.0. running mean: -19.417701538745952, timestamp: 2022-08-20 00:44:19.154300\n",
      "resetting env. episode 5331, reward total was -21.0. running mean: -19.433524523358493, timestamp: 2022-08-20 00:44:23.676214\n",
      "resetting env. episode 5332, reward total was -18.0. running mean: -19.419189278124907, timestamp: 2022-08-20 00:44:28.665706\n",
      "resetting env. episode 5333, reward total was -19.0. running mean: -19.41499738534366, timestamp: 2022-08-20 00:44:32.573257\n",
      "resetting env. episode 5334, reward total was -19.0. running mean: -19.410847411490224, timestamp: 2022-08-20 00:44:37.163452\n",
      "resetting env. episode 5335, reward total was -20.0. running mean: -19.41673893737532, timestamp: 2022-08-20 00:44:41.012271\n",
      "resetting env. episode 5336, reward total was -19.0. running mean: -19.41257154800157, timestamp: 2022-08-20 00:44:45.924141\n",
      "resetting env. episode 5337, reward total was -19.0. running mean: -19.408445832521554, timestamp: 2022-08-20 00:44:49.520541\n",
      "resetting env. episode 5338, reward total was -18.0. running mean: -19.39436137419634, timestamp: 2022-08-20 00:44:53.991290\n",
      "resetting env. episode 5339, reward total was -21.0. running mean: -19.410417760454376, timestamp: 2022-08-20 00:44:57.617813\n",
      "resetting env. episode 5340, reward total was -21.0. running mean: -19.426313582849833, timestamp: 2022-08-20 00:45:02.460842\n",
      "resetting env. episode 5341, reward total was -20.0. running mean: -19.432050447021332, timestamp: 2022-08-20 00:45:05.473897\n",
      "resetting env. episode 5342, reward total was -20.0. running mean: -19.43772994255112, timestamp: 2022-08-20 00:45:09.659705\n",
      "resetting env. episode 5343, reward total was -20.0. running mean: -19.443352643125607, timestamp: 2022-08-20 00:45:13.373108\n",
      "resetting env. episode 5344, reward total was -17.0. running mean: -19.41891911669435, timestamp: 2022-08-20 00:45:18.320885\n",
      "resetting env. episode 5345, reward total was -18.0. running mean: -19.404729925527405, timestamp: 2022-08-20 00:45:22.711147\n",
      "resetting env. episode 5346, reward total was -21.0. running mean: -19.420682626272132, timestamp: 2022-08-20 00:45:26.393317\n",
      "resetting env. episode 5347, reward total was -20.0. running mean: -19.42647580000941, timestamp: 2022-08-20 00:45:30.581117\n",
      "resetting env. episode 5348, reward total was -17.0. running mean: -19.402211042009316, timestamp: 2022-08-20 00:45:34.184326\n",
      "resetting env. episode 5349, reward total was -18.0. running mean: -19.388188931589223, timestamp: 2022-08-20 00:45:38.724671\n",
      "resetting env. episode 5350, reward total was -20.0. running mean: -19.39430704227333, timestamp: 2022-08-20 00:45:42.169458\n",
      "resetting env. episode 5351, reward total was -19.0. running mean: -19.390363971850597, timestamp: 2022-08-20 00:45:46.006745\n",
      "resetting env. episode 5352, reward total was -20.0. running mean: -19.39646033213209, timestamp: 2022-08-20 00:45:50.071879\n",
      "resetting env. episode 5353, reward total was -20.0. running mean: -19.40249572881077, timestamp: 2022-08-20 00:45:53.915605\n",
      "resetting env. episode 5354, reward total was -18.0. running mean: -19.388470771522663, timestamp: 2022-08-20 00:45:58.023800\n",
      "resetting env. episode 5355, reward total was -18.0. running mean: -19.374586063807435, timestamp: 2022-08-20 00:46:02.899768\n",
      "resetting env. episode 5356, reward total was -21.0. running mean: -19.39084020316936, timestamp: 2022-08-20 00:46:06.817478\n",
      "resetting env. episode 5357, reward total was -18.0. running mean: -19.376931801137665, timestamp: 2022-08-20 00:46:10.649128\n",
      "resetting env. episode 5358, reward total was -14.0. running mean: -19.32316248312629, timestamp: 2022-08-20 00:46:16.209959\n",
      "resetting env. episode 5359, reward total was -20.0. running mean: -19.329930858295025, timestamp: 2022-08-20 00:46:19.550542\n",
      "resetting env. episode 5360, reward total was -19.0. running mean: -19.326631549712076, timestamp: 2022-08-20 00:46:23.739129\n",
      "resetting env. episode 5361, reward total was -20.0. running mean: -19.333365234214956, timestamp: 2022-08-20 00:46:27.157330\n",
      "resetting env. episode 5362, reward total was -17.0. running mean: -19.310031581872806, timestamp: 2022-08-20 00:46:31.662274\n",
      "resetting env. episode 5363, reward total was -21.0. running mean: -19.32693126605408, timestamp: 2022-08-20 00:46:35.547440\n",
      "resetting env. episode 5364, reward total was -18.0. running mean: -19.313661953393538, timestamp: 2022-08-20 00:46:39.781727\n",
      "resetting env. episode 5365, reward total was -20.0. running mean: -19.320525333859603, timestamp: 2022-08-20 00:46:44.062423\n",
      "resetting env. episode 5366, reward total was -21.0. running mean: -19.337320080521007, timestamp: 2022-08-20 00:46:47.234939\n",
      "resetting env. episode 5367, reward total was -21.0. running mean: -19.353946879715796, timestamp: 2022-08-20 00:46:51.336833\n",
      "resetting env. episode 5368, reward total was -21.0. running mean: -19.370407410918638, timestamp: 2022-08-20 00:46:55.410918\n",
      "resetting env. episode 5369, reward total was -20.0. running mean: -19.376703336809452, timestamp: 2022-08-20 00:46:58.885627\n",
      "resetting env. episode 5370, reward total was -19.0. running mean: -19.37293630344136, timestamp: 2022-08-20 00:47:03.742702\n",
      "resetting env. episode 5371, reward total was -21.0. running mean: -19.389206940406947, timestamp: 2022-08-20 00:47:06.781489\n",
      "resetting env. episode 5372, reward total was -20.0. running mean: -19.395314871002878, timestamp: 2022-08-20 00:47:11.239571\n",
      "resetting env. episode 5373, reward total was -19.0. running mean: -19.39136172229285, timestamp: 2022-08-20 00:47:16.126108\n",
      "resetting env. episode 5374, reward total was -16.0. running mean: -19.35744810506992, timestamp: 2022-08-20 00:47:22.012534\n",
      "resetting env. episode 5375, reward total was -21.0. running mean: -19.37387362401922, timestamp: 2022-08-20 00:47:26.010822\n",
      "resetting env. episode 5376, reward total was -16.0. running mean: -19.34013488777903, timestamp: 2022-08-20 00:47:30.133799\n",
      "resetting env. episode 5377, reward total was -21.0. running mean: -19.35673353890124, timestamp: 2022-08-20 00:47:33.483441\n",
      "resetting env. episode 5378, reward total was -20.0. running mean: -19.363166203512225, timestamp: 2022-08-20 00:47:37.258350\n",
      "resetting env. episode 5379, reward total was -21.0. running mean: -19.379534541477103, timestamp: 2022-08-20 00:47:40.631338\n",
      "resetting env. episode 5380, reward total was -20.0. running mean: -19.38573919606233, timestamp: 2022-08-20 00:47:43.895612\n",
      "resetting env. episode 5381, reward total was -19.0. running mean: -19.38188180410171, timestamp: 2022-08-20 00:47:48.965668\n",
      "resetting env. episode 5382, reward total was -21.0. running mean: -19.398062986060694, timestamp: 2022-08-20 00:47:52.596960\n",
      "resetting env. episode 5383, reward total was -19.0. running mean: -19.394082356200087, timestamp: 2022-08-20 00:47:56.941393\n",
      "resetting env. episode 5384, reward total was -17.0. running mean: -19.370141532638087, timestamp: 2022-08-20 00:48:01.477233\n",
      "resetting env. episode 5385, reward total was -21.0. running mean: -19.386440117311707, timestamp: 2022-08-20 00:48:04.857292\n",
      "resetting env. episode 5386, reward total was -19.0. running mean: -19.382575716138593, timestamp: 2022-08-20 00:48:10.088683\n",
      "resetting env. episode 5387, reward total was -21.0. running mean: -19.39874995897721, timestamp: 2022-08-20 00:48:15.639845\n",
      "resetting env. episode 5388, reward total was -18.0. running mean: -19.384762459387435, timestamp: 2022-08-20 00:48:21.267841\n",
      "resetting env. episode 5389, reward total was -19.0. running mean: -19.38091483479356, timestamp: 2022-08-20 00:48:25.814522\n",
      "resetting env. episode 5390, reward total was -19.0. running mean: -19.377105686445628, timestamp: 2022-08-20 00:48:31.187189\n",
      "resetting env. episode 5391, reward total was -21.0. running mean: -19.393334629581172, timestamp: 2022-08-20 00:48:35.825197\n",
      "resetting env. episode 5392, reward total was -19.0. running mean: -19.389401283285363, timestamp: 2022-08-20 00:48:39.865079\n",
      "resetting env. episode 5393, reward total was -18.0. running mean: -19.37550727045251, timestamp: 2022-08-20 00:48:44.046974\n",
      "resetting env. episode 5394, reward total was -20.0. running mean: -19.381752197747982, timestamp: 2022-08-20 00:48:48.323929\n",
      "resetting env. episode 5395, reward total was -20.0. running mean: -19.387934675770502, timestamp: 2022-08-20 00:48:52.522854\n",
      "resetting env. episode 5396, reward total was -19.0. running mean: -19.3840553290128, timestamp: 2022-08-20 00:48:57.656027\n",
      "resetting env. episode 5397, reward total was -21.0. running mean: -19.400214775722674, timestamp: 2022-08-20 00:49:01.711091\n",
      "resetting env. episode 5398, reward total was -19.0. running mean: -19.396212627965447, timestamp: 2022-08-20 00:49:06.425995\n",
      "resetting env. episode 5399, reward total was -21.0. running mean: -19.412250501685794, timestamp: 2022-08-20 00:49:09.596504\n",
      "resetting env. episode 5400, reward total was -20.0. running mean: -19.418127996668936, timestamp: 2022-08-20 00:49:13.750587\n",
      "resetting env. episode 5401, reward total was -20.0. running mean: -19.423946716702247, timestamp: 2022-08-20 00:49:17.602012\n",
      "resetting env. episode 5402, reward total was -19.0. running mean: -19.419707249535225, timestamp: 2022-08-20 00:49:22.265221\n",
      "resetting env. episode 5403, reward total was -19.0. running mean: -19.415510177039874, timestamp: 2022-08-20 00:49:26.145896\n",
      "resetting env. episode 5404, reward total was -21.0. running mean: -19.431355075269476, timestamp: 2022-08-20 00:49:31.627741\n",
      "resetting env. episode 5405, reward total was -21.0. running mean: -19.44704152451678, timestamp: 2022-08-20 00:49:35.864110\n",
      "resetting env. episode 5406, reward total was -20.0. running mean: -19.452571109271613, timestamp: 2022-08-20 00:49:39.373804\n",
      "resetting env. episode 5407, reward total was -21.0. running mean: -19.468045398178898, timestamp: 2022-08-20 00:49:43.177577\n",
      "resetting env. episode 5408, reward total was -21.0. running mean: -19.48336494419711, timestamp: 2022-08-20 00:49:48.178268\n",
      "resetting env. episode 5409, reward total was -17.0. running mean: -19.45853129475514, timestamp: 2022-08-20 00:49:54.506111\n",
      "resetting env. episode 5410, reward total was -21.0. running mean: -19.47394598180759, timestamp: 2022-08-20 00:49:59.474079\n",
      "resetting env. episode 5411, reward total was -21.0. running mean: -19.489206521989512, timestamp: 2022-08-20 00:50:03.289885\n",
      "resetting env. episode 5412, reward total was -21.0. running mean: -19.504314456769617, timestamp: 2022-08-20 00:50:07.402732\n",
      "resetting env. episode 5413, reward total was -18.0. running mean: -19.48927131220192, timestamp: 2022-08-20 00:50:12.169081\n",
      "resetting env. episode 5414, reward total was -21.0. running mean: -19.504378599079903, timestamp: 2022-08-20 00:50:16.459581\n",
      "resetting env. episode 5415, reward total was -20.0. running mean: -19.509334813089104, timestamp: 2022-08-20 00:50:19.935439\n",
      "resetting env. episode 5416, reward total was -19.0. running mean: -19.504241464958213, timestamp: 2022-08-20 00:50:24.196359\n",
      "resetting env. episode 5417, reward total was -19.0. running mean: -19.499199050308633, timestamp: 2022-08-20 00:50:28.879258\n",
      "resetting env. episode 5418, reward total was -20.0. running mean: -19.504207059805545, timestamp: 2022-08-20 00:50:33.031258\n",
      "resetting env. episode 5419, reward total was -19.0. running mean: -19.49916498920749, timestamp: 2022-08-20 00:50:37.318390\n",
      "resetting env. episode 5420, reward total was -18.0. running mean: -19.484173339315415, timestamp: 2022-08-20 00:50:43.741870\n",
      "resetting env. episode 5421, reward total was -21.0. running mean: -19.49933160592226, timestamp: 2022-08-20 00:50:47.996613\n",
      "resetting env. episode 5422, reward total was -21.0. running mean: -19.51433828986304, timestamp: 2022-08-20 00:50:52.053134\n",
      "resetting env. episode 5423, reward total was -20.0. running mean: -19.519194906964408, timestamp: 2022-08-20 00:50:56.014573\n",
      "resetting env. episode 5424, reward total was -20.0. running mean: -19.524002957894762, timestamp: 2022-08-20 00:51:00.028875\n",
      "resetting env. episode 5425, reward total was -21.0. running mean: -19.538762928315816, timestamp: 2022-08-20 00:51:03.854523\n",
      "resetting env. episode 5426, reward total was -17.0. running mean: -19.51337529903266, timestamp: 2022-08-20 00:51:08.978940\n",
      "resetting env. episode 5427, reward total was -20.0. running mean: -19.518241546042333, timestamp: 2022-08-20 00:51:12.525518\n",
      "resetting env. episode 5428, reward total was -16.0. running mean: -19.48305913058191, timestamp: 2022-08-20 00:51:18.043882\n",
      "resetting env. episode 5429, reward total was -20.0. running mean: -19.48822853927609, timestamp: 2022-08-20 00:51:22.429130\n",
      "resetting env. episode 5430, reward total was -18.0. running mean: -19.473346253883328, timestamp: 2022-08-20 00:51:27.251657\n",
      "resetting env. episode 5431, reward total was -21.0. running mean: -19.488612791344494, timestamp: 2022-08-20 00:51:30.829220\n",
      "resetting env. episode 5432, reward total was -20.0. running mean: -19.493726663431048, timestamp: 2022-08-20 00:51:34.806020\n",
      "resetting env. episode 5433, reward total was -20.0. running mean: -19.498789396796735, timestamp: 2022-08-20 00:51:38.905097\n",
      "resetting env. episode 5434, reward total was -20.0. running mean: -19.503801502828765, timestamp: 2022-08-20 00:51:43.155588\n",
      "resetting env. episode 5435, reward total was -19.0. running mean: -19.498763487800478, timestamp: 2022-08-20 00:51:46.795303\n",
      "resetting env. episode 5436, reward total was -20.0. running mean: -19.503775852922473, timestamp: 2022-08-20 00:51:50.236607\n",
      "resetting env. episode 5437, reward total was -21.0. running mean: -19.51873809439325, timestamp: 2022-08-20 00:51:55.191883\n",
      "resetting env. episode 5438, reward total was -19.0. running mean: -19.51355071344932, timestamp: 2022-08-20 00:51:59.134332\n",
      "resetting env. episode 5439, reward total was -18.0. running mean: -19.498415206314824, timestamp: 2022-08-20 00:52:02.649699\n",
      "resetting env. episode 5440, reward total was -20.0. running mean: -19.503431054251674, timestamp: 2022-08-20 00:52:06.800811\n",
      "resetting env. episode 5441, reward total was -17.0. running mean: -19.47839674370916, timestamp: 2022-08-20 00:52:11.631083\n",
      "resetting env. episode 5442, reward total was -19.0. running mean: -19.473612776272066, timestamp: 2022-08-20 00:52:16.342298\n",
      "resetting env. episode 5443, reward total was -20.0. running mean: -19.478876648509345, timestamp: 2022-08-20 00:52:20.015248\n",
      "resetting env. episode 5444, reward total was -20.0. running mean: -19.48408788202425, timestamp: 2022-08-20 00:52:24.769666\n",
      "resetting env. episode 5445, reward total was -21.0. running mean: -19.499247003204008, timestamp: 2022-08-20 00:52:30.315819\n",
      "resetting env. episode 5446, reward total was -20.0. running mean: -19.504254533171967, timestamp: 2022-08-20 00:52:35.687738\n",
      "resetting env. episode 5447, reward total was -21.0. running mean: -19.519211987840247, timestamp: 2022-08-20 00:52:39.886770\n",
      "resetting env. episode 5448, reward total was -20.0. running mean: -19.524019867961844, timestamp: 2022-08-20 00:52:44.011236\n",
      "resetting env. episode 5449, reward total was -20.0. running mean: -19.528779669282226, timestamp: 2022-08-20 00:52:48.542279\n",
      "resetting env. episode 5450, reward total was -19.0. running mean: -19.523491872589403, timestamp: 2022-08-20 00:52:52.242517\n",
      "resetting env. episode 5451, reward total was -17.0. running mean: -19.49825695386351, timestamp: 2022-08-20 00:52:57.664059\n",
      "resetting env. episode 5452, reward total was -21.0. running mean: -19.513274384324877, timestamp: 2022-08-20 00:53:02.157372\n",
      "resetting env. episode 5453, reward total was -18.0. running mean: -19.498141640481627, timestamp: 2022-08-20 00:53:06.081994\n",
      "resetting env. episode 5454, reward total was -21.0. running mean: -19.513160224076813, timestamp: 2022-08-20 00:53:09.685763\n",
      "resetting env. episode 5455, reward total was -21.0. running mean: -19.528028621836047, timestamp: 2022-08-20 00:53:16.185041\n",
      "resetting env. episode 5456, reward total was -21.0. running mean: -19.542748335617688, timestamp: 2022-08-20 00:53:21.197892\n",
      "resetting env. episode 5457, reward total was -20.0. running mean: -19.54732085226151, timestamp: 2022-08-20 00:53:26.141231\n",
      "resetting env. episode 5458, reward total was -20.0. running mean: -19.551847643738895, timestamp: 2022-08-20 00:53:30.108219\n",
      "resetting env. episode 5459, reward total was -19.0. running mean: -19.546329167301508, timestamp: 2022-08-20 00:53:34.573759\n",
      "resetting env. episode 5460, reward total was -20.0. running mean: -19.550865875628492, timestamp: 2022-08-20 00:53:38.327919\n",
      "resetting env. episode 5461, reward total was -20.0. running mean: -19.555357216872206, timestamp: 2022-08-20 00:53:42.846328\n",
      "resetting env. episode 5462, reward total was -21.0. running mean: -19.569803644703484, timestamp: 2022-08-20 00:53:47.554940\n",
      "resetting env. episode 5463, reward total was -17.0. running mean: -19.54410560825645, timestamp: 2022-08-20 00:53:51.994067\n",
      "resetting env. episode 5464, reward total was -20.0. running mean: -19.548664552173886, timestamp: 2022-08-20 00:53:57.078977\n",
      "resetting env. episode 5465, reward total was -21.0. running mean: -19.563177906652147, timestamp: 2022-08-20 00:54:01.705096\n",
      "resetting env. episode 5466, reward total was -19.0. running mean: -19.557546127585628, timestamp: 2022-08-20 00:54:06.273328\n",
      "resetting env. episode 5467, reward total was -19.0. running mean: -19.551970666309774, timestamp: 2022-08-20 00:54:10.207847\n",
      "resetting env. episode 5468, reward total was -21.0. running mean: -19.566450959646676, timestamp: 2022-08-20 00:54:14.781961\n",
      "resetting env. episode 5469, reward total was -19.0. running mean: -19.560786450050212, timestamp: 2022-08-20 00:54:19.064677\n",
      "resetting env. episode 5470, reward total was -20.0. running mean: -19.56517858554971, timestamp: 2022-08-20 00:54:24.016208\n",
      "resetting env. episode 5471, reward total was -18.0. running mean: -19.549526799694213, timestamp: 2022-08-20 00:54:28.865203\n",
      "resetting env. episode 5472, reward total was -21.0. running mean: -19.56403153169727, timestamp: 2022-08-20 00:54:32.572750\n",
      "resetting env. episode 5473, reward total was -19.0. running mean: -19.5583912163803, timestamp: 2022-08-20 00:54:38.018161\n",
      "resetting env. episode 5474, reward total was -20.0. running mean: -19.5628073042165, timestamp: 2022-08-20 00:54:43.196450\n",
      "resetting env. episode 5475, reward total was -21.0. running mean: -19.577179231174334, timestamp: 2022-08-20 00:54:47.098939\n",
      "resetting env. episode 5476, reward total was -20.0. running mean: -19.58140743886259, timestamp: 2022-08-20 00:54:50.973582\n",
      "resetting env. episode 5477, reward total was -19.0. running mean: -19.575593364473967, timestamp: 2022-08-20 00:54:56.063888\n",
      "resetting env. episode 5478, reward total was -17.0. running mean: -19.54983743082923, timestamp: 2022-08-20 00:55:01.139812\n",
      "resetting env. episode 5479, reward total was -20.0. running mean: -19.554339056520934, timestamp: 2022-08-20 00:55:06.325640\n",
      "resetting env. episode 5480, reward total was -19.0. running mean: -19.548795665955726, timestamp: 2022-08-20 00:55:10.730456\n",
      "resetting env. episode 5481, reward total was -21.0. running mean: -19.56330770929617, timestamp: 2022-08-20 00:55:15.219397\n",
      "resetting env. episode 5482, reward total was -20.0. running mean: -19.567674632203207, timestamp: 2022-08-20 00:55:19.313206\n",
      "resetting env. episode 5483, reward total was -20.0. running mean: -19.571997885881174, timestamp: 2022-08-20 00:55:24.043086\n",
      "resetting env. episode 5484, reward total was -19.0. running mean: -19.566277907022364, timestamp: 2022-08-20 00:55:27.777080\n",
      "resetting env. episode 5485, reward total was -20.0. running mean: -19.57061512795214, timestamp: 2022-08-20 00:55:31.181536\n",
      "resetting env. episode 5486, reward total was -19.0. running mean: -19.564908976672623, timestamp: 2022-08-20 00:55:36.202226\n",
      "resetting env. episode 5487, reward total was -17.0. running mean: -19.5392598869059, timestamp: 2022-08-20 00:55:42.240801\n",
      "resetting env. episode 5488, reward total was -20.0. running mean: -19.54386728803684, timestamp: 2022-08-20 00:55:46.428498\n",
      "resetting env. episode 5489, reward total was -20.0. running mean: -19.54842861515647, timestamp: 2022-08-20 00:55:51.631769\n",
      "resetting env. episode 5490, reward total was -21.0. running mean: -19.562944329004907, timestamp: 2022-08-20 00:55:56.052045\n",
      "resetting env. episode 5491, reward total was -21.0. running mean: -19.57731488571486, timestamp: 2022-08-20 00:56:00.688897\n",
      "resetting env. episode 5492, reward total was -21.0. running mean: -19.59154173685771, timestamp: 2022-08-20 00:56:04.455419\n",
      "resetting env. episode 5493, reward total was -19.0. running mean: -19.585626319489133, timestamp: 2022-08-20 00:56:09.389275\n",
      "resetting env. episode 5494, reward total was -21.0. running mean: -19.599770056294243, timestamp: 2022-08-20 00:56:14.219601\n",
      "resetting env. episode 5495, reward total was -20.0. running mean: -19.6037723557313, timestamp: 2022-08-20 00:56:19.463338\n",
      "resetting env. episode 5496, reward total was -19.0. running mean: -19.59773463217399, timestamp: 2022-08-20 00:56:24.280428\n",
      "resetting env. episode 5497, reward total was -21.0. running mean: -19.61175728585225, timestamp: 2022-08-20 00:56:28.333042\n",
      "resetting env. episode 5498, reward total was -15.0. running mean: -19.565639712993725, timestamp: 2022-08-20 00:56:34.211106\n",
      "resetting env. episode 5499, reward total was -16.0. running mean: -19.529983315863788, timestamp: 2022-08-20 00:56:40.092017\n",
      "resetting env. episode 5500, reward total was -18.0. running mean: -19.51468348270515, timestamp: 2022-08-20 00:56:45.325049\n",
      "resetting env. episode 5501, reward total was -15.0. running mean: -19.469536647878094, timestamp: 2022-08-20 00:56:51.740717\n",
      "resetting env. episode 5502, reward total was -17.0. running mean: -19.444841281399313, timestamp: 2022-08-20 00:56:57.120789\n",
      "resetting env. episode 5503, reward total was -16.0. running mean: -19.41039286858532, timestamp: 2022-08-20 00:57:02.198643\n",
      "resetting env. episode 5504, reward total was -20.0. running mean: -19.416288939899466, timestamp: 2022-08-20 00:57:05.761107\n",
      "resetting env. episode 5505, reward total was -18.0. running mean: -19.40212605050047, timestamp: 2022-08-20 00:57:10.883215\n",
      "resetting env. episode 5506, reward total was -19.0. running mean: -19.398104789995468, timestamp: 2022-08-20 00:57:15.913497\n",
      "resetting env. episode 5507, reward total was -21.0. running mean: -19.414123742095516, timestamp: 2022-08-20 00:57:19.789714\n",
      "resetting env. episode 5508, reward total was -18.0. running mean: -19.39998250467456, timestamp: 2022-08-20 00:57:24.820637\n",
      "resetting env. episode 5509, reward total was -16.0. running mean: -19.365982679627816, timestamp: 2022-08-20 00:57:30.153208\n",
      "resetting env. episode 5510, reward total was -20.0. running mean: -19.372322852831537, timestamp: 2022-08-20 00:57:35.522446\n",
      "resetting env. episode 5511, reward total was -21.0. running mean: -19.38859962430322, timestamp: 2022-08-20 00:57:41.204033\n",
      "resetting env. episode 5512, reward total was -20.0. running mean: -19.394713628060188, timestamp: 2022-08-20 00:57:45.240304\n",
      "resetting env. episode 5513, reward total was -17.0. running mean: -19.370766491779587, timestamp: 2022-08-20 00:57:49.981611\n",
      "resetting env. episode 5514, reward total was -19.0. running mean: -19.367058826861793, timestamp: 2022-08-20 00:57:54.469614\n",
      "resetting env. episode 5515, reward total was -21.0. running mean: -19.383388238593177, timestamp: 2022-08-20 00:57:58.663619\n",
      "resetting env. episode 5516, reward total was -19.0. running mean: -19.379554356207247, timestamp: 2022-08-20 00:58:03.207018\n",
      "resetting env. episode 5517, reward total was -19.0. running mean: -19.375758812645177, timestamp: 2022-08-20 00:58:07.065553\n",
      "resetting env. episode 5518, reward total was -20.0. running mean: -19.382001224518724, timestamp: 2022-08-20 00:58:10.457245\n",
      "resetting env. episode 5519, reward total was -19.0. running mean: -19.37818121227354, timestamp: 2022-08-20 00:58:15.245670\n",
      "resetting env. episode 5520, reward total was -21.0. running mean: -19.394399400150803, timestamp: 2022-08-20 00:58:19.907906\n",
      "resetting env. episode 5521, reward total was -20.0. running mean: -19.400455406149295, timestamp: 2022-08-20 00:58:24.971231\n",
      "resetting env. episode 5522, reward total was -21.0. running mean: -19.416450852087802, timestamp: 2022-08-20 00:58:28.317404\n",
      "resetting env. episode 5523, reward total was -19.0. running mean: -19.412286343566926, timestamp: 2022-08-20 00:58:33.790449\n",
      "resetting env. episode 5524, reward total was -20.0. running mean: -19.418163480131255, timestamp: 2022-08-20 00:58:37.978259\n",
      "resetting env. episode 5525, reward total was -20.0. running mean: -19.42398184532994, timestamp: 2022-08-20 00:58:42.651367\n",
      "resetting env. episode 5526, reward total was -19.0. running mean: -19.41974202687664, timestamp: 2022-08-20 00:58:48.265410\n",
      "resetting env. episode 5527, reward total was -20.0. running mean: -19.425544606607872, timestamp: 2022-08-20 00:58:52.723169\n",
      "resetting env. episode 5528, reward total was -19.0. running mean: -19.421289160541793, timestamp: 2022-08-20 00:58:57.187275\n",
      "resetting env. episode 5529, reward total was -21.0. running mean: -19.437076268936377, timestamp: 2022-08-20 00:59:00.534655\n",
      "resetting env. episode 5530, reward total was -21.0. running mean: -19.452705506247014, timestamp: 2022-08-20 00:59:05.053525\n",
      "resetting env. episode 5531, reward total was -19.0. running mean: -19.448178451184546, timestamp: 2022-08-20 00:59:10.305739\n",
      "resetting env. episode 5532, reward total was -21.0. running mean: -19.4636966666727, timestamp: 2022-08-20 00:59:14.914398\n",
      "resetting env. episode 5533, reward total was -20.0. running mean: -19.46905970000597, timestamp: 2022-08-20 00:59:19.578953\n",
      "resetting env. episode 5534, reward total was -21.0. running mean: -19.48436910300591, timestamp: 2022-08-20 00:59:24.149302\n",
      "resetting env. episode 5535, reward total was -21.0. running mean: -19.499525411975853, timestamp: 2022-08-20 00:59:27.423430\n",
      "resetting env. episode 5536, reward total was -19.0. running mean: -19.494530157856094, timestamp: 2022-08-20 00:59:31.880844\n",
      "resetting env. episode 5537, reward total was -18.0. running mean: -19.479584856277533, timestamp: 2022-08-20 00:59:35.870189\n",
      "resetting env. episode 5538, reward total was -21.0. running mean: -19.494789007714758, timestamp: 2022-08-20 00:59:39.668237\n",
      "resetting env. episode 5539, reward total was -19.0. running mean: -19.48984111763761, timestamp: 2022-08-20 00:59:44.619213\n",
      "resetting env. episode 5540, reward total was -19.0. running mean: -19.484942706461236, timestamp: 2022-08-20 00:59:49.442976\n",
      "resetting env. episode 5541, reward total was -20.0. running mean: -19.490093279396625, timestamp: 2022-08-20 00:59:54.461561\n",
      "resetting env. episode 5542, reward total was -20.0. running mean: -19.495192346602657, timestamp: 2022-08-20 00:59:59.410461\n",
      "resetting env. episode 5543, reward total was -20.0. running mean: -19.50024042313663, timestamp: 2022-08-20 01:00:04.000165\n",
      "resetting env. episode 5544, reward total was -20.0. running mean: -19.505238018905263, timestamp: 2022-08-20 01:00:08.904002\n",
      "resetting env. episode 5545, reward total was -21.0. running mean: -19.52018563871621, timestamp: 2022-08-20 01:00:13.054900\n",
      "resetting env. episode 5546, reward total was -20.0. running mean: -19.52498378232905, timestamp: 2022-08-20 01:00:17.485117\n",
      "resetting env. episode 5547, reward total was -19.0. running mean: -19.51973394450576, timestamp: 2022-08-20 01:00:22.675991\n",
      "resetting env. episode 5548, reward total was -21.0. running mean: -19.5345366050607, timestamp: 2022-08-20 01:00:27.266275\n",
      "resetting env. episode 5549, reward total was -16.0. running mean: -19.499191239010095, timestamp: 2022-08-20 01:00:33.765738\n",
      "resetting env. episode 5550, reward total was -20.0. running mean: -19.504199326619993, timestamp: 2022-08-20 01:00:37.945998\n",
      "resetting env. episode 5551, reward total was -21.0. running mean: -19.519157333353792, timestamp: 2022-08-20 01:00:41.688720\n",
      "resetting env. episode 5552, reward total was -21.0. running mean: -19.533965760020255, timestamp: 2022-08-20 01:00:45.558379\n",
      "resetting env. episode 5553, reward total was -19.0. running mean: -19.528626102420052, timestamp: 2022-08-20 01:00:50.247204\n",
      "resetting env. episode 5554, reward total was -19.0. running mean: -19.523339841395853, timestamp: 2022-08-20 01:00:55.651146\n",
      "resetting env. episode 5555, reward total was -21.0. running mean: -19.538106442981896, timestamp: 2022-08-20 01:01:00.052287\n",
      "resetting env. episode 5556, reward total was -20.0. running mean: -19.542725378552074, timestamp: 2022-08-20 01:01:04.381133\n",
      "resetting env. episode 5557, reward total was -19.0. running mean: -19.537298124766554, timestamp: 2022-08-20 01:01:08.845850\n",
      "resetting env. episode 5558, reward total was -18.0. running mean: -19.52192514351889, timestamp: 2022-08-20 01:01:14.346301\n",
      "resetting env. episode 5559, reward total was -20.0. running mean: -19.526705892083697, timestamp: 2022-08-20 01:01:19.084687\n",
      "resetting env. episode 5560, reward total was -21.0. running mean: -19.54143883316286, timestamp: 2022-08-20 01:01:22.808339\n",
      "resetting env. episode 5561, reward total was -16.0. running mean: -19.506024444831233, timestamp: 2022-08-20 01:01:28.265411\n",
      "resetting env. episode 5562, reward total was -20.0. running mean: -19.51096420038292, timestamp: 2022-08-20 01:01:32.320438\n",
      "resetting env. episode 5563, reward total was -19.0. running mean: -19.50585455837909, timestamp: 2022-08-20 01:01:36.600671\n",
      "resetting env. episode 5564, reward total was -18.0. running mean: -19.4907960127953, timestamp: 2022-08-20 01:01:41.514693\n",
      "resetting env. episode 5565, reward total was -19.0. running mean: -19.48588805266735, timestamp: 2022-08-20 01:01:46.691384\n",
      "resetting env. episode 5566, reward total was -20.0. running mean: -19.491029172140674, timestamp: 2022-08-20 01:01:51.439424\n",
      "resetting env. episode 5567, reward total was -18.0. running mean: -19.476118880419268, timestamp: 2022-08-20 01:01:56.215651\n",
      "resetting env. episode 5568, reward total was -20.0. running mean: -19.481357691615074, timestamp: 2022-08-20 01:02:03.381496\n",
      "resetting env. episode 5569, reward total was -19.0. running mean: -19.476544114698925, timestamp: 2022-08-20 01:02:10.474536\n",
      "resetting env. episode 5570, reward total was -21.0. running mean: -19.491778673551938, timestamp: 2022-08-20 01:02:14.322251\n",
      "resetting env. episode 5571, reward total was -19.0. running mean: -19.48686088681642, timestamp: 2022-08-20 01:02:19.422621\n",
      "resetting env. episode 5572, reward total was -20.0. running mean: -19.491992277948256, timestamp: 2022-08-20 01:02:23.590479\n",
      "resetting env. episode 5573, reward total was -18.0. running mean: -19.477072355168772, timestamp: 2022-08-20 01:02:27.946300\n",
      "resetting env. episode 5574, reward total was -19.0. running mean: -19.472301631617086, timestamp: 2022-08-20 01:02:32.171278\n",
      "resetting env. episode 5575, reward total was -19.0. running mean: -19.467578615300916, timestamp: 2022-08-20 01:02:36.746376\n",
      "resetting env. episode 5576, reward total was -17.0. running mean: -19.442902829147908, timestamp: 2022-08-20 01:02:42.843356\n",
      "resetting env. episode 5577, reward total was -21.0. running mean: -19.458473800856428, timestamp: 2022-08-20 01:02:48.021500\n",
      "resetting env. episode 5578, reward total was -20.0. running mean: -19.463889062847862, timestamp: 2022-08-20 01:02:52.234935\n",
      "resetting env. episode 5579, reward total was -17.0. running mean: -19.439250172219385, timestamp: 2022-08-20 01:02:57.773789\n",
      "resetting env. episode 5580, reward total was -19.0. running mean: -19.43485767049719, timestamp: 2022-08-20 01:03:01.768704\n",
      "resetting env. episode 5581, reward total was -21.0. running mean: -19.45050909379222, timestamp: 2022-08-20 01:03:06.600654\n",
      "resetting env. episode 5582, reward total was -20.0. running mean: -19.456004002854296, timestamp: 2022-08-20 01:03:10.997018\n",
      "resetting env. episode 5583, reward total was -18.0. running mean: -19.441443962825755, timestamp: 2022-08-20 01:03:16.458879\n",
      "resetting env. episode 5584, reward total was -19.0. running mean: -19.4370295231975, timestamp: 2022-08-20 01:03:21.170298\n",
      "resetting env. episode 5585, reward total was -19.0. running mean: -19.432659227965523, timestamp: 2022-08-20 01:03:24.862415\n",
      "resetting env. episode 5586, reward total was -19.0. running mean: -19.42833263568587, timestamp: 2022-08-20 01:03:29.640708\n",
      "resetting env. episode 5587, reward total was -21.0. running mean: -19.44404930932901, timestamp: 2022-08-20 01:03:33.359155\n",
      "resetting env. episode 5588, reward total was -20.0. running mean: -19.44960881623572, timestamp: 2022-08-20 01:03:38.281346\n",
      "resetting env. episode 5589, reward total was -19.0. running mean: -19.445112728073365, timestamp: 2022-08-20 01:03:42.429149\n",
      "resetting env. episode 5590, reward total was -18.0. running mean: -19.430661600792632, timestamp: 2022-08-20 01:03:47.193373\n",
      "resetting env. episode 5591, reward total was -21.0. running mean: -19.44635498478471, timestamp: 2022-08-20 01:03:51.746763\n",
      "resetting env. episode 5592, reward total was -21.0. running mean: -19.461891434936863, timestamp: 2022-08-20 01:03:55.195197\n",
      "resetting env. episode 5593, reward total was -19.0. running mean: -19.457272520587495, timestamp: 2022-08-20 01:04:00.100079\n",
      "resetting env. episode 5594, reward total was -18.0. running mean: -19.442699795381618, timestamp: 2022-08-20 01:04:04.782720\n",
      "resetting env. episode 5595, reward total was -19.0. running mean: -19.438272797427803, timestamp: 2022-08-20 01:04:09.217239\n",
      "resetting env. episode 5596, reward total was -21.0. running mean: -19.453890069453525, timestamp: 2022-08-20 01:04:13.807441\n",
      "resetting env. episode 5597, reward total was -19.0. running mean: -19.44935116875899, timestamp: 2022-08-20 01:04:18.329030\n",
      "resetting env. episode 5598, reward total was -21.0. running mean: -19.464857657071402, timestamp: 2022-08-20 01:04:22.711263\n",
      "resetting env. episode 5599, reward total was -21.0. running mean: -19.48020908050069, timestamp: 2022-08-20 01:04:27.422108\n",
      "resetting env. episode 5600, reward total was -19.0. running mean: -19.475406989695685, timestamp: 2022-08-20 01:04:32.591608\n",
      "resetting env. episode 5601, reward total was -20.0. running mean: -19.48065291979873, timestamp: 2022-08-20 01:04:36.531357\n",
      "resetting env. episode 5602, reward total was -20.0. running mean: -19.48584639060074, timestamp: 2022-08-20 01:04:40.928191\n",
      "resetting env. episode 5603, reward total was -19.0. running mean: -19.480987926694734, timestamp: 2022-08-20 01:04:46.333578\n",
      "resetting env. episode 5604, reward total was -20.0. running mean: -19.486178047427785, timestamp: 2022-08-20 01:04:51.745325\n",
      "resetting env. episode 5605, reward total was -20.0. running mean: -19.491316266953508, timestamp: 2022-08-20 01:04:56.045852\n",
      "resetting env. episode 5606, reward total was -21.0. running mean: -19.506403104283972, timestamp: 2022-08-20 01:05:01.030842\n",
      "resetting env. episode 5607, reward total was -21.0. running mean: -19.521339073241133, timestamp: 2022-08-20 01:05:05.532876\n",
      "resetting env. episode 5608, reward total was -21.0. running mean: -19.53612568250872, timestamp: 2022-08-20 01:05:10.661663\n",
      "resetting env. episode 5609, reward total was -19.0. running mean: -19.530764425683635, timestamp: 2022-08-20 01:05:15.045954\n",
      "resetting env. episode 5610, reward total was -17.0. running mean: -19.5054567814268, timestamp: 2022-08-20 01:05:20.556750\n",
      "resetting env. episode 5611, reward total was -18.0. running mean: -19.490402213612533, timestamp: 2022-08-20 01:05:25.331031\n",
      "resetting env. episode 5612, reward total was -17.0. running mean: -19.46549819147641, timestamp: 2022-08-20 01:05:30.879847\n",
      "resetting env. episode 5613, reward total was -20.0. running mean: -19.470843209561647, timestamp: 2022-08-20 01:05:36.066815\n",
      "resetting env. episode 5614, reward total was -20.0. running mean: -19.47613477746603, timestamp: 2022-08-20 01:05:41.288996\n",
      "resetting env. episode 5615, reward total was -18.0. running mean: -19.461373429691367, timestamp: 2022-08-20 01:05:46.578358\n",
      "resetting env. episode 5616, reward total was -19.0. running mean: -19.456759695394453, timestamp: 2022-08-20 01:05:51.372642\n",
      "resetting env. episode 5617, reward total was -21.0. running mean: -19.47219209844051, timestamp: 2022-08-20 01:05:56.602399\n",
      "resetting env. episode 5618, reward total was -19.0. running mean: -19.467470177456104, timestamp: 2022-08-20 01:06:00.862107\n",
      "resetting env. episode 5619, reward total was -19.0. running mean: -19.462795475681542, timestamp: 2022-08-20 01:06:04.669587\n",
      "resetting env. episode 5620, reward total was -20.0. running mean: -19.468167520924727, timestamp: 2022-08-20 01:06:07.820400\n",
      "resetting env. episode 5621, reward total was -18.0. running mean: -19.45348584571548, timestamp: 2022-08-20 01:06:11.201878\n",
      "resetting env. episode 5622, reward total was -20.0. running mean: -19.458950987258326, timestamp: 2022-08-20 01:06:15.951547\n",
      "resetting env. episode 5623, reward total was -18.0. running mean: -19.444361477385744, timestamp: 2022-08-20 01:06:21.872167\n",
      "resetting env. episode 5624, reward total was -19.0. running mean: -19.43991786261189, timestamp: 2022-08-20 01:06:28.907239\n",
      "resetting env. episode 5625, reward total was -20.0. running mean: -19.445518683985767, timestamp: 2022-08-20 01:06:35.696255\n",
      "resetting env. episode 5626, reward total was -17.0. running mean: -19.421063497145912, timestamp: 2022-08-20 01:06:40.573435\n",
      "resetting env. episode 5627, reward total was -20.0. running mean: -19.426852862174453, timestamp: 2022-08-20 01:06:45.517210\n",
      "resetting env. episode 5628, reward total was -19.0. running mean: -19.42258433355271, timestamp: 2022-08-20 01:06:51.736254\n",
      "resetting env. episode 5629, reward total was -21.0. running mean: -19.438358490217183, timestamp: 2022-08-20 01:06:57.004806\n",
      "resetting env. episode 5630, reward total was -16.0. running mean: -19.40397490531501, timestamp: 2022-08-20 01:07:02.364777\n",
      "resetting env. episode 5631, reward total was -21.0. running mean: -19.41993515626186, timestamp: 2022-08-20 01:07:07.568046\n",
      "resetting env. episode 5632, reward total was -18.0. running mean: -19.40573580469924, timestamp: 2022-08-20 01:07:12.903997\n",
      "resetting env. episode 5633, reward total was -15.0. running mean: -19.361678446652245, timestamp: 2022-08-20 01:07:19.848252\n",
      "resetting env. episode 5634, reward total was -18.0. running mean: -19.34806166218572, timestamp: 2022-08-20 01:07:25.652123\n",
      "resetting env. episode 5635, reward total was -20.0. running mean: -19.35458104556386, timestamp: 2022-08-20 01:07:31.600895\n",
      "resetting env. episode 5636, reward total was -21.0. running mean: -19.371035235108224, timestamp: 2022-08-20 01:07:35.340161\n",
      "resetting env. episode 5637, reward total was -18.0. running mean: -19.35732488275714, timestamp: 2022-08-20 01:07:40.168734\n",
      "resetting env. episode 5638, reward total was -21.0. running mean: -19.37375163392957, timestamp: 2022-08-20 01:07:44.058894\n",
      "resetting env. episode 5639, reward total was -21.0. running mean: -19.390014117590272, timestamp: 2022-08-20 01:07:47.974949\n",
      "resetting env. episode 5640, reward total was -18.0. running mean: -19.37611397641437, timestamp: 2022-08-20 01:07:52.311029\n",
      "resetting env. episode 5641, reward total was -21.0. running mean: -19.392352836650225, timestamp: 2022-08-20 01:07:58.084308\n",
      "resetting env. episode 5642, reward total was -21.0. running mean: -19.408429308283722, timestamp: 2022-08-20 01:08:02.253966\n",
      "resetting env. episode 5643, reward total was -20.0. running mean: -19.414345015200883, timestamp: 2022-08-20 01:08:06.613293\n",
      "resetting env. episode 5644, reward total was -19.0. running mean: -19.410201565048876, timestamp: 2022-08-20 01:08:12.239149\n",
      "resetting env. episode 5645, reward total was -18.0. running mean: -19.396099549398386, timestamp: 2022-08-20 01:08:18.562672\n",
      "resetting env. episode 5646, reward total was -21.0. running mean: -19.412138553904402, timestamp: 2022-08-20 01:08:24.141912\n",
      "resetting env. episode 5647, reward total was -21.0. running mean: -19.428017168365358, timestamp: 2022-08-20 01:08:30.892398\n",
      "resetting env. episode 5648, reward total was -20.0. running mean: -19.433736996681702, timestamp: 2022-08-20 01:08:38.201987\n",
      "resetting env. episode 5649, reward total was -15.0. running mean: -19.389399626714884, timestamp: 2022-08-20 01:08:49.478873\n",
      "resetting env. episode 5650, reward total was -20.0. running mean: -19.395505630447733, timestamp: 2022-08-20 01:08:55.062680\n",
      "resetting env. episode 5651, reward total was -19.0. running mean: -19.391550574143256, timestamp: 2022-08-20 01:09:01.281465\n",
      "resetting env. episode 5652, reward total was -20.0. running mean: -19.397635068401822, timestamp: 2022-08-20 01:09:09.389295\n",
      "resetting env. episode 5653, reward total was -19.0. running mean: -19.393658717717805, timestamp: 2022-08-20 01:09:15.495677\n",
      "resetting env. episode 5654, reward total was -19.0. running mean: -19.38972213054063, timestamp: 2022-08-20 01:09:23.547387\n",
      "resetting env. episode 5655, reward total was -21.0. running mean: -19.405824909235225, timestamp: 2022-08-20 01:09:29.356563\n",
      "resetting env. episode 5656, reward total was -21.0. running mean: -19.421766660142872, timestamp: 2022-08-20 01:09:34.384281\n",
      "resetting env. episode 5657, reward total was -20.0. running mean: -19.427548993541443, timestamp: 2022-08-20 01:09:41.886505\n",
      "resetting env. episode 5658, reward total was -19.0. running mean: -19.42327350360603, timestamp: 2022-08-20 01:09:48.137879\n",
      "resetting env. episode 5659, reward total was -20.0. running mean: -19.42904076856997, timestamp: 2022-08-20 01:09:53.721326\n",
      "resetting env. episode 5660, reward total was -18.0. running mean: -19.41475036088427, timestamp: 2022-08-20 01:09:59.699237\n",
      "resetting env. episode 5661, reward total was -19.0. running mean: -19.41060285727543, timestamp: 2022-08-20 01:10:04.930893\n",
      "resetting env. episode 5662, reward total was -19.0. running mean: -19.406496828702675, timestamp: 2022-08-20 01:10:10.369871\n",
      "resetting env. episode 5663, reward total was -16.0. running mean: -19.37243186041565, timestamp: 2022-08-20 01:10:16.033669\n",
      "resetting env. episode 5664, reward total was -19.0. running mean: -19.368707541811492, timestamp: 2022-08-20 01:10:21.882556\n",
      "resetting env. episode 5665, reward total was -17.0. running mean: -19.34502046639338, timestamp: 2022-08-20 01:10:27.633271\n",
      "resetting env. episode 5666, reward total was -17.0. running mean: -19.32157026172945, timestamp: 2022-08-20 01:10:34.123636\n",
      "resetting env. episode 5667, reward total was -19.0. running mean: -19.318354559112155, timestamp: 2022-08-20 01:10:38.953446\n",
      "resetting env. episode 5668, reward total was -16.0. running mean: -19.285171013521033, timestamp: 2022-08-20 01:10:44.102695\n",
      "resetting env. episode 5669, reward total was -20.0. running mean: -19.29231930338582, timestamp: 2022-08-20 01:10:50.009209\n",
      "resetting env. episode 5670, reward total was -21.0. running mean: -19.309396110351962, timestamp: 2022-08-20 01:10:55.134493\n",
      "resetting env. episode 5671, reward total was -20.0. running mean: -19.31630214924844, timestamp: 2022-08-20 01:11:00.276679\n",
      "resetting env. episode 5672, reward total was -21.0. running mean: -19.333139127755956, timestamp: 2022-08-20 01:11:03.414646\n",
      "resetting env. episode 5673, reward total was -21.0. running mean: -19.349807736478397, timestamp: 2022-08-20 01:11:06.351238\n",
      "resetting env. episode 5674, reward total was -21.0. running mean: -19.366309659113615, timestamp: 2022-08-20 01:11:10.163241\n",
      "resetting env. episode 5675, reward total was -20.0. running mean: -19.372646562522476, timestamp: 2022-08-20 01:11:14.099808\n",
      "resetting env. episode 5676, reward total was -19.0. running mean: -19.368920096897252, timestamp: 2022-08-20 01:11:18.830085\n",
      "resetting env. episode 5677, reward total was -14.0. running mean: -19.31523089592828, timestamp: 2022-08-20 01:11:24.346944\n",
      "resetting env. episode 5678, reward total was -20.0. running mean: -19.322078586968995, timestamp: 2022-08-20 01:11:29.259853\n",
      "resetting env. episode 5679, reward total was -20.0. running mean: -19.328857801099304, timestamp: 2022-08-20 01:11:33.766341\n",
      "resetting env. episode 5680, reward total was -20.0. running mean: -19.33556922308831, timestamp: 2022-08-20 01:11:38.539443\n",
      "resetting env. episode 5681, reward total was -18.0. running mean: -19.322213530857425, timestamp: 2022-08-20 01:11:45.418754\n",
      "resetting env. episode 5682, reward total was -20.0. running mean: -19.32899139554885, timestamp: 2022-08-20 01:11:50.974060\n",
      "resetting env. episode 5683, reward total was -16.0. running mean: -19.295701481593362, timestamp: 2022-08-20 01:11:57.216676\n",
      "resetting env. episode 5684, reward total was -21.0. running mean: -19.312744466777428, timestamp: 2022-08-20 01:12:01.720221\n",
      "resetting env. episode 5685, reward total was -21.0. running mean: -19.329617022109655, timestamp: 2022-08-20 01:12:06.665443\n",
      "resetting env. episode 5686, reward total was -18.0. running mean: -19.31632085188856, timestamp: 2022-08-20 01:12:12.184568\n",
      "resetting env. episode 5687, reward total was -20.0. running mean: -19.323157643369672, timestamp: 2022-08-20 01:12:17.969460\n",
      "resetting env. episode 5688, reward total was -21.0. running mean: -19.339926066935977, timestamp: 2022-08-20 01:12:22.391221\n",
      "resetting env. episode 5689, reward total was -17.0. running mean: -19.31652680626662, timestamp: 2022-08-20 01:12:28.098537\n",
      "resetting env. episode 5690, reward total was -17.0. running mean: -19.293361538203953, timestamp: 2022-08-20 01:12:33.770112\n",
      "resetting env. episode 5691, reward total was -20.0. running mean: -19.300427922821914, timestamp: 2022-08-20 01:12:39.639455\n",
      "resetting env. episode 5692, reward total was -16.0. running mean: -19.267423643593695, timestamp: 2022-08-20 01:12:45.193985\n",
      "resetting env. episode 5693, reward total was -19.0. running mean: -19.26474940715776, timestamp: 2022-08-20 01:12:49.725694\n",
      "resetting env. episode 5694, reward total was -19.0. running mean: -19.26210191308618, timestamp: 2022-08-20 01:12:54.071180\n",
      "resetting env. episode 5695, reward total was -20.0. running mean: -19.26948089395532, timestamp: 2022-08-20 01:12:58.812803\n",
      "resetting env. episode 5696, reward total was -19.0. running mean: -19.266786085015767, timestamp: 2022-08-20 01:13:05.450093\n",
      "resetting env. episode 5697, reward total was -21.0. running mean: -19.28411822416561, timestamp: 2022-08-20 01:13:11.948950\n",
      "resetting env. episode 5698, reward total was -21.0. running mean: -19.301277041923953, timestamp: 2022-08-20 01:13:17.628655\n",
      "resetting env. episode 5699, reward total was -21.0. running mean: -19.318264271504713, timestamp: 2022-08-20 01:13:22.590330\n",
      "resetting env. episode 5700, reward total was -19.0. running mean: -19.315081628789667, timestamp: 2022-08-20 01:13:28.345428\n",
      "resetting env. episode 5701, reward total was -21.0. running mean: -19.33193081250177, timestamp: 2022-08-20 01:13:34.915842\n",
      "resetting env. episode 5702, reward total was -16.0. running mean: -19.29861150437675, timestamp: 2022-08-20 01:13:41.297232\n",
      "resetting env. episode 5703, reward total was -17.0. running mean: -19.275625389332987, timestamp: 2022-08-20 01:13:47.444643\n",
      "resetting env. episode 5704, reward total was -21.0. running mean: -19.29286913543966, timestamp: 2022-08-20 01:13:53.161809\n",
      "resetting env. episode 5705, reward total was -20.0. running mean: -19.299940444085262, timestamp: 2022-08-20 01:13:58.889501\n",
      "resetting env. episode 5706, reward total was -20.0. running mean: -19.306941039644407, timestamp: 2022-08-20 01:14:04.392467\n",
      "resetting env. episode 5707, reward total was -19.0. running mean: -19.303871629247965, timestamp: 2022-08-20 01:14:09.752544\n",
      "resetting env. episode 5708, reward total was -20.0. running mean: -19.310832912955483, timestamp: 2022-08-20 01:14:13.449674\n",
      "resetting env. episode 5709, reward total was -19.0. running mean: -19.30772458382593, timestamp: 2022-08-20 01:14:17.784718\n",
      "resetting env. episode 5710, reward total was -20.0. running mean: -19.31464733798767, timestamp: 2022-08-20 01:14:23.661890\n",
      "resetting env. episode 5711, reward total was -20.0. running mean: -19.321500864607792, timestamp: 2022-08-20 01:14:29.314269\n",
      "resetting env. episode 5712, reward total was -17.0. running mean: -19.298285855961716, timestamp: 2022-08-20 01:14:35.117768\n",
      "resetting env. episode 5713, reward total was -19.0. running mean: -19.2953029974021, timestamp: 2022-08-20 01:14:40.554697\n",
      "resetting env. episode 5714, reward total was -19.0. running mean: -19.29234996742808, timestamp: 2022-08-20 01:14:46.157013\n",
      "resetting env. episode 5715, reward total was -20.0. running mean: -19.2994264677538, timestamp: 2022-08-20 01:14:50.663264\n",
      "resetting env. episode 5716, reward total was -17.0. running mean: -19.276432203076265, timestamp: 2022-08-20 01:14:57.412698\n",
      "resetting env. episode 5717, reward total was -21.0. running mean: -19.293667881045504, timestamp: 2022-08-20 01:15:02.469149\n",
      "resetting env. episode 5718, reward total was -20.0. running mean: -19.30073120223505, timestamp: 2022-08-20 01:15:07.151688\n",
      "resetting env. episode 5719, reward total was -18.0. running mean: -19.2877238902127, timestamp: 2022-08-20 01:15:12.901647\n",
      "resetting env. episode 5720, reward total was -17.0. running mean: -19.264846651310574, timestamp: 2022-08-20 01:15:18.756167\n",
      "resetting env. episode 5721, reward total was -20.0. running mean: -19.272198184797467, timestamp: 2022-08-20 01:15:25.605726\n",
      "resetting env. episode 5722, reward total was -19.0. running mean: -19.269476202949495, timestamp: 2022-08-20 01:15:30.214836\n",
      "resetting env. episode 5723, reward total was -21.0. running mean: -19.28678144092, timestamp: 2022-08-20 01:15:36.202774\n",
      "resetting env. episode 5724, reward total was -18.0. running mean: -19.273913626510797, timestamp: 2022-08-20 01:15:41.690430\n",
      "resetting env. episode 5725, reward total was -19.0. running mean: -19.27117449024569, timestamp: 2022-08-20 01:15:46.909633\n",
      "resetting env. episode 5726, reward total was -17.0. running mean: -19.248462745343236, timestamp: 2022-08-20 01:15:54.035675\n",
      "resetting env. episode 5727, reward total was -21.0. running mean: -19.265978117889805, timestamp: 2022-08-20 01:15:59.477368\n",
      "resetting env. episode 5728, reward total was -21.0. running mean: -19.28331833671091, timestamp: 2022-08-20 01:16:04.847166\n",
      "resetting env. episode 5729, reward total was -19.0. running mean: -19.2804851533438, timestamp: 2022-08-20 01:16:11.142990\n",
      "resetting env. episode 5730, reward total was -19.0. running mean: -19.277680301810364, timestamp: 2022-08-20 01:16:16.264415\n",
      "resetting env. episode 5731, reward total was -19.0. running mean: -19.274903498792263, timestamp: 2022-08-20 01:16:20.486662\n",
      "resetting env. episode 5732, reward total was -16.0. running mean: -19.24215446380434, timestamp: 2022-08-20 01:16:26.798247\n",
      "resetting env. episode 5733, reward total was -20.0. running mean: -19.249732919166295, timestamp: 2022-08-20 01:16:31.194783\n",
      "resetting env. episode 5734, reward total was -20.0. running mean: -19.25723558997463, timestamp: 2022-08-20 01:16:38.163973\n",
      "resetting env. episode 5735, reward total was -21.0. running mean: -19.274663234074886, timestamp: 2022-08-20 01:16:42.951107\n",
      "resetting env. episode 5736, reward total was -20.0. running mean: -19.281916601734135, timestamp: 2022-08-20 01:16:49.062515\n",
      "resetting env. episode 5737, reward total was -20.0. running mean: -19.289097435716794, timestamp: 2022-08-20 01:16:55.337626\n",
      "resetting env. episode 5738, reward total was -21.0. running mean: -19.306206461359626, timestamp: 2022-08-20 01:17:01.246234\n",
      "resetting env. episode 5739, reward total was -18.0. running mean: -19.29314439674603, timestamp: 2022-08-20 01:17:05.984252\n",
      "resetting env. episode 5740, reward total was -19.0. running mean: -19.29021295277857, timestamp: 2022-08-20 01:17:11.304000\n",
      "resetting env. episode 5741, reward total was -21.0. running mean: -19.307310823250788, timestamp: 2022-08-20 01:17:17.011059\n",
      "resetting env. episode 5742, reward total was -21.0. running mean: -19.32423771501828, timestamp: 2022-08-20 01:17:20.723654\n",
      "resetting env. episode 5743, reward total was -21.0. running mean: -19.340995337868097, timestamp: 2022-08-20 01:17:26.393762\n",
      "resetting env. episode 5744, reward total was -19.0. running mean: -19.33758538448942, timestamp: 2022-08-20 01:17:32.186974\n",
      "resetting env. episode 5745, reward total was -18.0. running mean: -19.324209530644524, timestamp: 2022-08-20 01:17:37.113743\n",
      "resetting env. episode 5746, reward total was -17.0. running mean: -19.30096743533808, timestamp: 2022-08-20 01:17:42.869939\n",
      "resetting env. episode 5747, reward total was -20.0. running mean: -19.3079577609847, timestamp: 2022-08-20 01:17:48.694867\n",
      "resetting env. episode 5748, reward total was -19.0. running mean: -19.304878183374854, timestamp: 2022-08-20 01:17:54.291465\n",
      "resetting env. episode 5749, reward total was -16.0. running mean: -19.271829401541105, timestamp: 2022-08-20 01:18:01.009282\n",
      "resetting env. episode 5750, reward total was -21.0. running mean: -19.289111107525695, timestamp: 2022-08-20 01:18:06.807629\n",
      "resetting env. episode 5751, reward total was -18.0. running mean: -19.276219996450436, timestamp: 2022-08-20 01:18:11.684883\n",
      "resetting env. episode 5752, reward total was -20.0. running mean: -19.28345779648593, timestamp: 2022-08-20 01:18:16.545418\n",
      "resetting env. episode 5753, reward total was -19.0. running mean: -19.28062321852107, timestamp: 2022-08-20 01:18:23.846840\n",
      "resetting env. episode 5754, reward total was -20.0. running mean: -19.28781698633586, timestamp: 2022-08-20 01:18:30.231228\n",
      "resetting env. episode 5755, reward total was -15.0. running mean: -19.244938816472498, timestamp: 2022-08-20 01:18:36.375030\n",
      "resetting env. episode 5756, reward total was -20.0. running mean: -19.252489428307772, timestamp: 2022-08-20 01:18:41.008149\n",
      "resetting env. episode 5757, reward total was -20.0. running mean: -19.259964534024693, timestamp: 2022-08-20 01:18:46.117689\n",
      "resetting env. episode 5758, reward total was -17.0. running mean: -19.237364888684446, timestamp: 2022-08-20 01:18:52.930044\n",
      "resetting env. episode 5759, reward total was -19.0. running mean: -19.2349912397976, timestamp: 2022-08-20 01:19:00.041133\n",
      "resetting env. episode 5760, reward total was -20.0. running mean: -19.242641327399625, timestamp: 2022-08-20 01:19:05.802248\n",
      "resetting env. episode 5761, reward total was -19.0. running mean: -19.24021491412563, timestamp: 2022-08-20 01:19:11.405684\n",
      "resetting env. episode 5762, reward total was -17.0. running mean: -19.217812764984377, timestamp: 2022-08-20 01:19:17.188060\n",
      "resetting env. episode 5763, reward total was -19.0. running mean: -19.215634637334535, timestamp: 2022-08-20 01:19:22.418716\n",
      "resetting env. episode 5764, reward total was -21.0. running mean: -19.23347829096119, timestamp: 2022-08-20 01:19:27.514634\n",
      "resetting env. episode 5765, reward total was -19.0. running mean: -19.23114350805158, timestamp: 2022-08-20 01:19:34.515102\n",
      "resetting env. episode 5766, reward total was -20.0. running mean: -19.238832072971064, timestamp: 2022-08-20 01:19:39.836704\n",
      "resetting env. episode 5767, reward total was -21.0. running mean: -19.256443752241353, timestamp: 2022-08-20 01:19:43.032664\n",
      "resetting env. episode 5768, reward total was -19.0. running mean: -19.25387931471894, timestamp: 2022-08-20 01:19:48.061694\n",
      "resetting env. episode 5769, reward total was -18.0. running mean: -19.24134052157175, timestamp: 2022-08-20 01:19:52.582708\n",
      "resetting env. episode 5770, reward total was -17.0. running mean: -19.218927116356035, timestamp: 2022-08-20 01:19:57.934341\n",
      "resetting env. episode 5771, reward total was -17.0. running mean: -19.196737845192477, timestamp: 2022-08-20 01:20:02.433316\n",
      "resetting env. episode 5772, reward total was -20.0. running mean: -19.204770466740552, timestamp: 2022-08-20 01:20:06.872000\n",
      "resetting env. episode 5773, reward total was -18.0. running mean: -19.192722762073146, timestamp: 2022-08-20 01:20:10.776075\n",
      "resetting env. episode 5774, reward total was -18.0. running mean: -19.180795534452415, timestamp: 2022-08-20 01:20:16.516679\n",
      "resetting env. episode 5775, reward total was -14.0. running mean: -19.12898757910789, timestamp: 2022-08-20 01:20:22.281012\n",
      "resetting env. episode 5776, reward total was -19.0. running mean: -19.127697703316812, timestamp: 2022-08-20 01:20:26.225543\n",
      "resetting env. episode 5777, reward total was -20.0. running mean: -19.136420726283642, timestamp: 2022-08-20 01:20:31.014845\n",
      "resetting env. episode 5778, reward total was -21.0. running mean: -19.155056519020807, timestamp: 2022-08-20 01:20:35.064496\n",
      "resetting env. episode 5779, reward total was -21.0. running mean: -19.1735059538306, timestamp: 2022-08-20 01:20:38.480172\n",
      "resetting env. episode 5780, reward total was -17.0. running mean: -19.151770894292294, timestamp: 2022-08-20 01:20:43.366329\n",
      "resetting env. episode 5781, reward total was -21.0. running mean: -19.170253185349374, timestamp: 2022-08-20 01:20:46.279430\n",
      "resetting env. episode 5782, reward total was -17.0. running mean: -19.14855065349588, timestamp: 2022-08-20 01:20:50.444298\n",
      "resetting env. episode 5783, reward total was -19.0. running mean: -19.147065146960923, timestamp: 2022-08-20 01:20:56.026702\n",
      "resetting env. episode 5784, reward total was -18.0. running mean: -19.135594495491315, timestamp: 2022-08-20 01:21:00.339376\n",
      "resetting env. episode 5785, reward total was -19.0. running mean: -19.134238550536402, timestamp: 2022-08-20 01:21:04.411981\n",
      "resetting env. episode 5786, reward total was -18.0. running mean: -19.122896165031037, timestamp: 2022-08-20 01:21:08.236877\n",
      "resetting env. episode 5787, reward total was -20.0. running mean: -19.131667203380726, timestamp: 2022-08-20 01:21:13.030817\n",
      "resetting env. episode 5788, reward total was -21.0. running mean: -19.15035053134692, timestamp: 2022-08-20 01:21:17.689514\n",
      "resetting env. episode 5789, reward total was -20.0. running mean: -19.15884702603345, timestamp: 2022-08-20 01:21:22.781322\n",
      "resetting env. episode 5790, reward total was -20.0. running mean: -19.167258555773113, timestamp: 2022-08-20 01:21:27.733342\n",
      "resetting env. episode 5791, reward total was -19.0. running mean: -19.165585970215382, timestamp: 2022-08-20 01:21:32.116352\n",
      "resetting env. episode 5792, reward total was -20.0. running mean: -19.173930110513226, timestamp: 2022-08-20 01:21:36.324044\n",
      "resetting env. episode 5793, reward total was -20.0. running mean: -19.18219080940809, timestamp: 2022-08-20 01:21:41.633377\n",
      "resetting env. episode 5794, reward total was -20.0. running mean: -19.19036890131401, timestamp: 2022-08-20 01:21:45.265669\n",
      "resetting env. episode 5795, reward total was -21.0. running mean: -19.20846521230087, timestamp: 2022-08-20 01:21:49.039029\n",
      "resetting env. episode 5796, reward total was -20.0. running mean: -19.21638056017786, timestamp: 2022-08-20 01:21:53.218185\n",
      "resetting env. episode 5797, reward total was -19.0. running mean: -19.214216754576082, timestamp: 2022-08-20 01:21:59.786609\n",
      "resetting env. episode 5798, reward total was -19.0. running mean: -19.212074587030322, timestamp: 2022-08-20 01:22:04.222399\n",
      "resetting env. episode 5799, reward total was -20.0. running mean: -19.219953841160017, timestamp: 2022-08-20 01:22:08.349561\n",
      "resetting env. episode 5800, reward total was -17.0. running mean: -19.197754302748418, timestamp: 2022-08-20 01:22:13.806005\n",
      "resetting env. episode 5801, reward total was -18.0. running mean: -19.185776759720934, timestamp: 2022-08-20 01:22:18.826780\n",
      "resetting env. episode 5802, reward total was -21.0. running mean: -19.203918992123725, timestamp: 2022-08-20 01:22:23.120250\n",
      "resetting env. episode 5803, reward total was -19.0. running mean: -19.201879802202487, timestamp: 2022-08-20 01:22:27.406388\n",
      "resetting env. episode 5804, reward total was -19.0. running mean: -19.199861004180462, timestamp: 2022-08-20 01:22:32.923109\n",
      "resetting env. episode 5805, reward total was -20.0. running mean: -19.207862394138658, timestamp: 2022-08-20 01:22:36.450297\n",
      "resetting env. episode 5806, reward total was -21.0. running mean: -19.22578377019727, timestamp: 2022-08-20 01:22:41.407810\n",
      "resetting env. episode 5807, reward total was -21.0. running mean: -19.2435259324953, timestamp: 2022-08-20 01:22:45.681417\n",
      "resetting env. episode 5808, reward total was -19.0. running mean: -19.241090673170348, timestamp: 2022-08-20 01:22:49.989564\n",
      "resetting env. episode 5809, reward total was -19.0. running mean: -19.238679766438647, timestamp: 2022-08-20 01:22:54.745226\n",
      "resetting env. episode 5810, reward total was -18.0. running mean: -19.22629296877426, timestamp: 2022-08-20 01:22:58.826489\n",
      "resetting env. episode 5811, reward total was -18.0. running mean: -19.214030039086516, timestamp: 2022-08-20 01:23:03.193648\n",
      "resetting env. episode 5812, reward total was -21.0. running mean: -19.231889738695653, timestamp: 2022-08-20 01:23:08.386381\n",
      "resetting env. episode 5813, reward total was -18.0. running mean: -19.219570841308695, timestamp: 2022-08-20 01:23:12.577205\n",
      "resetting env. episode 5814, reward total was -20.0. running mean: -19.227375132895606, timestamp: 2022-08-20 01:23:16.082579\n",
      "resetting env. episode 5815, reward total was -17.0. running mean: -19.205101381566653, timestamp: 2022-08-20 01:23:20.560209\n",
      "resetting env. episode 5816, reward total was -17.0. running mean: -19.183050367750987, timestamp: 2022-08-20 01:23:24.853835\n",
      "resetting env. episode 5817, reward total was -19.0. running mean: -19.181219864073476, timestamp: 2022-08-20 01:23:29.615256\n",
      "resetting env. episode 5818, reward total was -21.0. running mean: -19.19940766543274, timestamp: 2022-08-20 01:23:33.696861\n",
      "resetting env. episode 5819, reward total was -19.0. running mean: -19.197413588778414, timestamp: 2022-08-20 01:23:38.524365\n",
      "resetting env. episode 5820, reward total was -19.0. running mean: -19.195439452890632, timestamp: 2022-08-20 01:23:42.493181\n",
      "resetting env. episode 5821, reward total was -20.0. running mean: -19.203485058361725, timestamp: 2022-08-20 01:23:46.953040\n",
      "resetting env. episode 5822, reward total was -19.0. running mean: -19.20145020777811, timestamp: 2022-08-20 01:23:51.106586\n",
      "resetting env. episode 5823, reward total was -19.0. running mean: -19.199435705700328, timestamp: 2022-08-20 01:23:56.442541\n",
      "resetting env. episode 5824, reward total was -17.0. running mean: -19.177441348643328, timestamp: 2022-08-20 01:24:01.658182\n",
      "resetting env. episode 5825, reward total was -19.0. running mean: -19.175666935156894, timestamp: 2022-08-20 01:24:07.131945\n",
      "resetting env. episode 5826, reward total was -20.0. running mean: -19.183910265805324, timestamp: 2022-08-20 01:24:10.952028\n",
      "resetting env. episode 5827, reward total was -21.0. running mean: -19.20207116314727, timestamp: 2022-08-20 01:24:14.792794\n",
      "resetting env. episode 5828, reward total was -20.0. running mean: -19.210050451515798, timestamp: 2022-08-20 01:24:18.425319\n",
      "resetting env. episode 5829, reward total was -20.0. running mean: -19.21794994700064, timestamp: 2022-08-20 01:24:22.617146\n",
      "resetting env. episode 5830, reward total was -20.0. running mean: -19.225770447530632, timestamp: 2022-08-20 01:24:26.676263\n",
      "resetting env. episode 5831, reward total was -19.0. running mean: -19.223512743055327, timestamp: 2022-08-20 01:24:31.781622\n",
      "resetting env. episode 5832, reward total was -17.0. running mean: -19.201277615624775, timestamp: 2022-08-20 01:24:36.280294\n",
      "resetting env. episode 5833, reward total was -21.0. running mean: -19.21926483946853, timestamp: 2022-08-20 01:24:43.377463\n",
      "resetting env. episode 5834, reward total was -19.0. running mean: -19.217072191073846, timestamp: 2022-08-20 01:24:48.868765\n",
      "resetting env. episode 5835, reward total was -19.0. running mean: -19.21490146916311, timestamp: 2022-08-20 01:24:52.331508\n",
      "resetting env. episode 5836, reward total was -21.0. running mean: -19.23275245447148, timestamp: 2022-08-20 01:24:57.172992\n",
      "resetting env. episode 5837, reward total was -21.0. running mean: -19.250424929926766, timestamp: 2022-08-20 01:25:02.845262\n",
      "resetting env. episode 5838, reward total was -21.0. running mean: -19.267920680627498, timestamp: 2022-08-20 01:25:07.124702\n",
      "resetting env. episode 5839, reward total was -17.0. running mean: -19.245241473821224, timestamp: 2022-08-20 01:25:13.707480\n",
      "resetting env. episode 5840, reward total was -20.0. running mean: -19.25278905908301, timestamp: 2022-08-20 01:25:17.834431\n",
      "resetting env. episode 5841, reward total was -17.0. running mean: -19.23026116849218, timestamp: 2022-08-20 01:25:22.549107\n",
      "resetting env. episode 5842, reward total was -20.0. running mean: -19.237958556807257, timestamp: 2022-08-20 01:25:26.630190\n",
      "resetting env. episode 5843, reward total was -19.0. running mean: -19.235578971239185, timestamp: 2022-08-20 01:25:31.234009\n",
      "resetting env. episode 5844, reward total was -19.0. running mean: -19.233223181526796, timestamp: 2022-08-20 01:25:35.940386\n",
      "resetting env. episode 5845, reward total was -17.0. running mean: -19.21089094971153, timestamp: 2022-08-20 01:25:40.942726\n",
      "resetting env. episode 5846, reward total was -19.0. running mean: -19.208782040214416, timestamp: 2022-08-20 01:25:44.538876\n",
      "resetting env. episode 5847, reward total was -21.0. running mean: -19.226694219812273, timestamp: 2022-08-20 01:25:49.247014\n",
      "resetting env. episode 5848, reward total was -20.0. running mean: -19.23442727761415, timestamp: 2022-08-20 01:25:53.395523\n",
      "resetting env. episode 5849, reward total was -17.0. running mean: -19.212083004838007, timestamp: 2022-08-20 01:25:58.340689\n",
      "resetting env. episode 5850, reward total was -20.0. running mean: -19.219962174789625, timestamp: 2022-08-20 01:26:03.122487\n",
      "resetting env. episode 5851, reward total was -16.0. running mean: -19.18776255304173, timestamp: 2022-08-20 01:26:07.960004\n",
      "resetting env. episode 5852, reward total was -19.0. running mean: -19.185884927511314, timestamp: 2022-08-20 01:26:12.280825\n",
      "resetting env. episode 5853, reward total was -18.0. running mean: -19.1740260782362, timestamp: 2022-08-20 01:26:16.443442\n",
      "resetting env. episode 5854, reward total was -20.0. running mean: -19.182285817453838, timestamp: 2022-08-20 01:26:20.081020\n",
      "resetting env. episode 5855, reward total was -21.0. running mean: -19.2004629592793, timestamp: 2022-08-20 01:26:24.341077\n",
      "resetting env. episode 5856, reward total was -17.0. running mean: -19.178458329686507, timestamp: 2022-08-20 01:26:29.821431\n",
      "resetting env. episode 5857, reward total was -20.0. running mean: -19.18667374638964, timestamp: 2022-08-20 01:26:34.141881\n",
      "resetting env. episode 5858, reward total was -17.0. running mean: -19.164807008925745, timestamp: 2022-08-20 01:26:40.371645\n",
      "resetting env. episode 5859, reward total was -17.0. running mean: -19.14315893883649, timestamp: 2022-08-20 01:26:47.349253\n",
      "resetting env. episode 5860, reward total was -17.0. running mean: -19.121727349448125, timestamp: 2022-08-20 01:26:53.122915\n",
      "resetting env. episode 5861, reward total was -20.0. running mean: -19.130510075953644, timestamp: 2022-08-20 01:26:56.358963\n",
      "resetting env. episode 5862, reward total was -19.0. running mean: -19.12920497519411, timestamp: 2022-08-20 01:27:01.389825\n",
      "resetting env. episode 5863, reward total was -20.0. running mean: -19.13791292544217, timestamp: 2022-08-20 01:27:06.023415\n",
      "resetting env. episode 5864, reward total was -19.0. running mean: -19.13653379618775, timestamp: 2022-08-20 01:27:10.782974\n",
      "resetting env. episode 5865, reward total was -17.0. running mean: -19.115168458225874, timestamp: 2022-08-20 01:27:14.665594\n",
      "resetting env. episode 5866, reward total was -20.0. running mean: -19.124016773643614, timestamp: 2022-08-20 01:27:18.939417\n",
      "resetting env. episode 5867, reward total was -20.0. running mean: -19.13277660590718, timestamp: 2022-08-20 01:27:23.350236\n",
      "resetting env. episode 5868, reward total was -20.0. running mean: -19.141448839848106, timestamp: 2022-08-20 01:27:27.493143\n",
      "resetting env. episode 5869, reward total was -19.0. running mean: -19.140034351449625, timestamp: 2022-08-20 01:27:31.732715\n",
      "resetting env. episode 5870, reward total was -20.0. running mean: -19.14863400793513, timestamp: 2022-08-20 01:27:36.132646\n",
      "resetting env. episode 5871, reward total was -21.0. running mean: -19.16714766785578, timestamp: 2022-08-20 01:27:40.604695\n",
      "resetting env. episode 5872, reward total was -17.0. running mean: -19.145476191177224, timestamp: 2022-08-20 01:27:46.063842\n",
      "resetting env. episode 5873, reward total was -19.0. running mean: -19.144021429265454, timestamp: 2022-08-20 01:27:50.425144\n",
      "resetting env. episode 5874, reward total was -20.0. running mean: -19.1525812149728, timestamp: 2022-08-20 01:27:54.902170\n",
      "resetting env. episode 5875, reward total was -17.0. running mean: -19.131055402823073, timestamp: 2022-08-20 01:28:00.355592\n",
      "resetting env. episode 5876, reward total was -20.0. running mean: -19.13974484879484, timestamp: 2022-08-20 01:28:05.436199\n",
      "resetting env. episode 5877, reward total was -21.0. running mean: -19.158347400306894, timestamp: 2022-08-20 01:28:09.801663\n",
      "resetting env. episode 5878, reward total was -18.0. running mean: -19.146763926303827, timestamp: 2022-08-20 01:28:14.932832\n",
      "resetting env. episode 5879, reward total was -19.0. running mean: -19.14529628704079, timestamp: 2022-08-20 01:28:21.401494\n",
      "resetting env. episode 5880, reward total was -19.0. running mean: -19.143843324170383, timestamp: 2022-08-20 01:28:25.383847\n",
      "resetting env. episode 5881, reward total was -19.0. running mean: -19.14240489092868, timestamp: 2022-08-20 01:28:30.503306\n",
      "resetting env. episode 5882, reward total was -21.0. running mean: -19.160980842019395, timestamp: 2022-08-20 01:28:35.744646\n",
      "resetting env. episode 5883, reward total was -19.0. running mean: -19.159371033599204, timestamp: 2022-08-20 01:28:40.479996\n",
      "resetting env. episode 5884, reward total was -21.0. running mean: -19.17777732326321, timestamp: 2022-08-20 01:28:44.864299\n",
      "resetting env. episode 5885, reward total was -19.0. running mean: -19.17599955003058, timestamp: 2022-08-20 01:28:50.940032\n",
      "resetting env. episode 5886, reward total was -21.0. running mean: -19.194239554530274, timestamp: 2022-08-20 01:28:58.723224\n",
      "resetting env. episode 5887, reward total was -20.0. running mean: -19.20229715898497, timestamp: 2022-08-20 01:29:05.268728\n",
      "resetting env. episode 5888, reward total was -21.0. running mean: -19.22027418739512, timestamp: 2022-08-20 01:29:09.731800\n",
      "resetting env. episode 5889, reward total was -20.0. running mean: -19.228071445521167, timestamp: 2022-08-20 01:29:15.685887\n",
      "resetting env. episode 5890, reward total was -21.0. running mean: -19.245790731065956, timestamp: 2022-08-20 01:29:21.380661\n",
      "resetting env. episode 5891, reward total was -18.0. running mean: -19.233332823755294, timestamp: 2022-08-20 01:29:26.014975\n",
      "resetting env. episode 5892, reward total was -20.0. running mean: -19.24099949551774, timestamp: 2022-08-20 01:29:30.571309\n",
      "resetting env. episode 5893, reward total was -19.0. running mean: -19.238589500562565, timestamp: 2022-08-20 01:29:35.330835\n",
      "resetting env. episode 5894, reward total was -21.0. running mean: -19.25620360555694, timestamp: 2022-08-20 01:29:38.879351\n",
      "resetting env. episode 5895, reward total was -21.0. running mean: -19.273641569501372, timestamp: 2022-08-20 01:29:43.496597\n",
      "resetting env. episode 5896, reward total was -19.0. running mean: -19.27090515380636, timestamp: 2022-08-20 01:29:48.498124\n",
      "resetting env. episode 5897, reward total was -19.0. running mean: -19.2681961022683, timestamp: 2022-08-20 01:29:53.625871\n",
      "resetting env. episode 5898, reward total was -17.0. running mean: -19.245514141245618, timestamp: 2022-08-20 01:29:58.798195\n",
      "resetting env. episode 5899, reward total was -20.0. running mean: -19.25305899983316, timestamp: 2022-08-20 01:30:03.474713\n",
      "resetting env. episode 5900, reward total was -18.0. running mean: -19.24052840983483, timestamp: 2022-08-20 01:30:10.209239\n",
      "resetting env. episode 5901, reward total was -20.0. running mean: -19.24812312573648, timestamp: 2022-08-20 01:30:15.696543\n",
      "resetting env. episode 5902, reward total was -19.0. running mean: -19.245641894479117, timestamp: 2022-08-20 01:30:20.732246\n",
      "resetting env. episode 5903, reward total was -21.0. running mean: -19.26318547553433, timestamp: 2022-08-20 01:30:26.882796\n",
      "resetting env. episode 5904, reward total was -19.0. running mean: -19.260553620778985, timestamp: 2022-08-20 01:30:31.786183\n",
      "resetting env. episode 5905, reward total was -20.0. running mean: -19.267948084571195, timestamp: 2022-08-20 01:30:38.549454\n",
      "resetting env. episode 5906, reward total was -18.0. running mean: -19.255268603725483, timestamp: 2022-08-20 01:30:42.828570\n",
      "resetting env. episode 5907, reward total was -17.0. running mean: -19.23271591768823, timestamp: 2022-08-20 01:30:48.534318\n",
      "resetting env. episode 5908, reward total was -16.0. running mean: -19.200388758511345, timestamp: 2022-08-20 01:30:54.810575\n",
      "resetting env. episode 5909, reward total was -18.0. running mean: -19.18838487092623, timestamp: 2022-08-20 01:31:00.091343\n",
      "resetting env. episode 5910, reward total was -21.0. running mean: -19.20650102221697, timestamp: 2022-08-20 01:31:04.975191\n",
      "resetting env. episode 5911, reward total was -16.0. running mean: -19.1744360119948, timestamp: 2022-08-20 01:31:09.532842\n",
      "resetting env. episode 5912, reward total was -18.0. running mean: -19.16269165187485, timestamp: 2022-08-20 01:31:14.186576\n",
      "resetting env. episode 5913, reward total was -18.0. running mean: -19.1510647353561, timestamp: 2022-08-20 01:31:17.692374\n",
      "resetting env. episode 5914, reward total was -18.0. running mean: -19.13955408800254, timestamp: 2022-08-20 01:31:21.406441\n",
      "resetting env. episode 5915, reward total was -21.0. running mean: -19.158158547122515, timestamp: 2022-08-20 01:31:25.613361\n",
      "resetting env. episode 5916, reward total was -19.0. running mean: -19.15657696165129, timestamp: 2022-08-20 01:31:30.061297\n",
      "resetting env. episode 5917, reward total was -15.0. running mean: -19.115011192034775, timestamp: 2022-08-20 01:31:35.093906\n",
      "resetting env. episode 5918, reward total was -17.0. running mean: -19.09386108011443, timestamp: 2022-08-20 01:31:41.926376\n",
      "resetting env. episode 5919, reward total was -19.0. running mean: -19.092922469313287, timestamp: 2022-08-20 01:31:46.801288\n",
      "resetting env. episode 5920, reward total was -20.0. running mean: -19.101993244620154, timestamp: 2022-08-20 01:31:51.396964\n",
      "resetting env. episode 5921, reward total was -19.0. running mean: -19.100973312173952, timestamp: 2022-08-20 01:31:57.346714\n",
      "resetting env. episode 5922, reward total was -20.0. running mean: -19.109963579052213, timestamp: 2022-08-20 01:32:02.952728\n",
      "resetting env. episode 5923, reward total was -18.0. running mean: -19.09886394326169, timestamp: 2022-08-20 01:32:08.685430\n",
      "resetting env. episode 5924, reward total was -20.0. running mean: -19.107875303829072, timestamp: 2022-08-20 01:32:13.005853\n",
      "resetting env. episode 5925, reward total was -18.0. running mean: -19.09679655079078, timestamp: 2022-08-20 01:32:18.571974\n",
      "resetting env. episode 5926, reward total was -19.0. running mean: -19.095828585282874, timestamp: 2022-08-20 01:32:23.658058\n",
      "resetting env. episode 5927, reward total was -20.0. running mean: -19.104870299430043, timestamp: 2022-08-20 01:32:27.831420\n",
      "resetting env. episode 5928, reward total was -17.0. running mean: -19.083821596435744, timestamp: 2022-08-20 01:32:33.202200\n",
      "resetting env. episode 5929, reward total was -17.0. running mean: -19.062983380471387, timestamp: 2022-08-20 01:32:37.935058\n",
      "resetting env. episode 5930, reward total was -19.0. running mean: -19.062353546666674, timestamp: 2022-08-20 01:32:42.642909\n",
      "resetting env. episode 5931, reward total was -20.0. running mean: -19.071730011200007, timestamp: 2022-08-20 01:32:46.530376\n",
      "resetting env. episode 5932, reward total was -17.0. running mean: -19.05101271108801, timestamp: 2022-08-20 01:32:51.009362\n",
      "resetting env. episode 5933, reward total was -20.0. running mean: -19.06050258397713, timestamp: 2022-08-20 01:32:55.749745\n",
      "resetting env. episode 5934, reward total was -18.0. running mean: -19.049897558137356, timestamp: 2022-08-20 01:33:00.811500\n",
      "resetting env. episode 5935, reward total was -20.0. running mean: -19.059398582555982, timestamp: 2022-08-20 01:33:04.750971\n",
      "resetting env. episode 5936, reward total was -21.0. running mean: -19.07880459673042, timestamp: 2022-08-20 01:33:08.911824\n",
      "resetting env. episode 5937, reward total was -21.0. running mean: -19.098016550763116, timestamp: 2022-08-20 01:33:12.418300\n",
      "resetting env. episode 5938, reward total was -18.0. running mean: -19.087036385255484, timestamp: 2022-08-20 01:33:17.613431\n",
      "resetting env. episode 5939, reward total was -20.0. running mean: -19.09616602140293, timestamp: 2022-08-20 01:33:21.599481\n",
      "resetting env. episode 5940, reward total was -18.0. running mean: -19.0852043611889, timestamp: 2022-08-20 01:33:26.116837\n",
      "resetting env. episode 5941, reward total was -21.0. running mean: -19.10435231757701, timestamp: 2022-08-20 01:33:30.358586\n",
      "resetting env. episode 5942, reward total was -19.0. running mean: -19.10330879440124, timestamp: 2022-08-20 01:33:34.591443\n",
      "resetting env. episode 5943, reward total was -21.0. running mean: -19.122275706457227, timestamp: 2022-08-20 01:33:39.216419\n",
      "resetting env. episode 5944, reward total was -20.0. running mean: -19.131052949392654, timestamp: 2022-08-20 01:33:43.770188\n",
      "resetting env. episode 5945, reward total was -20.0. running mean: -19.139742419898727, timestamp: 2022-08-20 01:33:47.907130\n",
      "resetting env. episode 5946, reward total was -16.0. running mean: -19.10834499569974, timestamp: 2022-08-20 01:33:53.453455\n",
      "resetting env. episode 5947, reward total was -21.0. running mean: -19.12726154574274, timestamp: 2022-08-20 01:33:58.212734\n",
      "resetting env. episode 5948, reward total was -17.0. running mean: -19.105988930285314, timestamp: 2022-08-20 01:34:03.597746\n",
      "resetting env. episode 5949, reward total was -17.0. running mean: -19.084929040982463, timestamp: 2022-08-20 01:34:09.245482\n",
      "resetting env. episode 5950, reward total was -20.0. running mean: -19.094079750572636, timestamp: 2022-08-20 01:34:13.566982\n",
      "resetting env. episode 5951, reward total was -20.0. running mean: -19.10313895306691, timestamp: 2022-08-20 01:34:17.572698\n",
      "resetting env. episode 5952, reward total was -19.0. running mean: -19.102107563536244, timestamp: 2022-08-20 01:34:22.271138\n",
      "resetting env. episode 5953, reward total was -16.0. running mean: -19.07108648790088, timestamp: 2022-08-20 01:34:27.696845\n",
      "resetting env. episode 5954, reward total was -20.0. running mean: -19.080375623021872, timestamp: 2022-08-20 01:34:32.689400\n",
      "resetting env. episode 5955, reward total was -19.0. running mean: -19.079571866791653, timestamp: 2022-08-20 01:34:38.937733\n",
      "resetting env. episode 5956, reward total was -21.0. running mean: -19.098776148123736, timestamp: 2022-08-20 01:34:42.253354\n",
      "resetting env. episode 5957, reward total was -19.0. running mean: -19.0977883866425, timestamp: 2022-08-20 01:34:46.779416\n",
      "resetting env. episode 5958, reward total was -19.0. running mean: -19.096810502776076, timestamp: 2022-08-20 01:34:50.504322\n",
      "resetting env. episode 5959, reward total was -21.0. running mean: -19.115842397748317, timestamp: 2022-08-20 01:34:54.844653\n",
      "resetting env. episode 5960, reward total was -19.0. running mean: -19.114683973770834, timestamp: 2022-08-20 01:34:58.734865\n",
      "resetting env. episode 5961, reward total was -19.0. running mean: -19.113537134033127, timestamp: 2022-08-20 01:35:03.000369\n",
      "resetting env. episode 5962, reward total was -18.0. running mean: -19.102401762692796, timestamp: 2022-08-20 01:35:08.059158\n",
      "resetting env. episode 5963, reward total was -20.0. running mean: -19.111377745065866, timestamp: 2022-08-20 01:35:13.938437\n",
      "resetting env. episode 5964, reward total was -18.0. running mean: -19.100263967615206, timestamp: 2022-08-20 01:35:18.287164\n",
      "resetting env. episode 5965, reward total was -19.0. running mean: -19.099261327939054, timestamp: 2022-08-20 01:35:23.535084\n",
      "resetting env. episode 5966, reward total was -19.0. running mean: -19.098268714659664, timestamp: 2022-08-20 01:35:27.454604\n",
      "resetting env. episode 5967, reward total was -18.0. running mean: -19.087286027513066, timestamp: 2022-08-20 01:35:31.537888\n",
      "resetting env. episode 5968, reward total was -19.0. running mean: -19.086413167237936, timestamp: 2022-08-20 01:35:36.105672\n",
      "resetting env. episode 5969, reward total was -20.0. running mean: -19.095549035565554, timestamp: 2022-08-20 01:35:40.967963\n",
      "resetting env. episode 5970, reward total was -19.0. running mean: -19.0945935452099, timestamp: 2022-08-20 01:35:46.647891\n",
      "resetting env. episode 5971, reward total was -19.0. running mean: -19.093647609757802, timestamp: 2022-08-20 01:35:51.878820\n",
      "resetting env. episode 5972, reward total was -19.0. running mean: -19.092711133660224, timestamp: 2022-08-20 01:35:56.593232\n",
      "resetting env. episode 5973, reward total was -19.0. running mean: -19.091784022323623, timestamp: 2022-08-20 01:36:01.185306\n",
      "resetting env. episode 5974, reward total was -17.0. running mean: -19.07086618210039, timestamp: 2022-08-20 01:36:05.677021\n",
      "resetting env. episode 5975, reward total was -19.0. running mean: -19.070157520279388, timestamp: 2022-08-20 01:36:11.044146\n",
      "resetting env. episode 5976, reward total was -20.0. running mean: -19.079455945076592, timestamp: 2022-08-20 01:36:15.492257\n",
      "resetting env. episode 5977, reward total was -20.0. running mean: -19.088661385625826, timestamp: 2022-08-20 01:36:20.520254\n",
      "resetting env. episode 5978, reward total was -19.0. running mean: -19.08777477176957, timestamp: 2022-08-20 01:36:24.783164\n",
      "resetting env. episode 5979, reward total was -19.0. running mean: -19.086897024051876, timestamp: 2022-08-20 01:36:29.680309\n",
      "resetting env. episode 5980, reward total was -20.0. running mean: -19.096028053811356, timestamp: 2022-08-20 01:36:34.483246\n",
      "resetting env. episode 5981, reward total was -17.0. running mean: -19.075067773273243, timestamp: 2022-08-20 01:36:39.729598\n",
      "resetting env. episode 5982, reward total was -19.0. running mean: -19.07431709554051, timestamp: 2022-08-20 01:36:44.957345\n",
      "resetting env. episode 5983, reward total was -17.0. running mean: -19.05357392458511, timestamp: 2022-08-20 01:36:50.267390\n",
      "resetting env. episode 5984, reward total was -20.0. running mean: -19.063038185339256, timestamp: 2022-08-20 01:36:55.451046\n",
      "resetting env. episode 5985, reward total was -18.0. running mean: -19.052407803485863, timestamp: 2022-08-20 01:37:00.033792\n",
      "resetting env. episode 5986, reward total was -20.0. running mean: -19.061883725451004, timestamp: 2022-08-20 01:37:05.856222\n",
      "resetting env. episode 5987, reward total was -20.0. running mean: -19.07126488819649, timestamp: 2022-08-20 01:37:10.973013\n",
      "resetting env. episode 5988, reward total was -17.0. running mean: -19.050552239314527, timestamp: 2022-08-20 01:37:17.308080\n",
      "resetting env. episode 5989, reward total was -19.0. running mean: -19.050046716921383, timestamp: 2022-08-20 01:37:22.956210\n",
      "resetting env. episode 5990, reward total was -21.0. running mean: -19.069546249752168, timestamp: 2022-08-20 01:37:28.014976\n",
      "resetting env. episode 5991, reward total was -19.0. running mean: -19.068850787254647, timestamp: 2022-08-20 01:37:32.761655\n",
      "resetting env. episode 5992, reward total was -20.0. running mean: -19.0781622793821, timestamp: 2022-08-20 01:37:38.051488\n",
      "resetting env. episode 5993, reward total was -20.0. running mean: -19.087380656588277, timestamp: 2022-08-20 01:37:42.471672\n",
      "resetting env. episode 5994, reward total was -19.0. running mean: -19.086506850022396, timestamp: 2022-08-20 01:37:47.900598\n",
      "resetting env. episode 5995, reward total was -17.0. running mean: -19.065641781522174, timestamp: 2022-08-20 01:37:54.063549\n",
      "resetting env. episode 5996, reward total was -21.0. running mean: -19.084985363706952, timestamp: 2022-08-20 01:37:58.811830\n",
      "resetting env. episode 5997, reward total was -16.0. running mean: -19.054135510069884, timestamp: 2022-08-20 01:38:04.263458\n",
      "resetting env. episode 5998, reward total was -17.0. running mean: -19.033594154969187, timestamp: 2022-08-20 01:38:09.392713\n",
      "resetting env. episode 5999, reward total was -18.0. running mean: -19.023258213419496, timestamp: 2022-08-20 01:38:16.008469\n",
      "resetting env. episode 6000, reward total was -21.0. running mean: -19.0430256312853, timestamp: 2022-08-20 01:38:21.830089\n",
      "resetting env. episode 6001, reward total was -17.0. running mean: -19.022595374972447, timestamp: 2022-08-20 01:38:26.998597\n",
      "resetting env. episode 6002, reward total was -18.0. running mean: -19.012369421222722, timestamp: 2022-08-20 01:38:34.298521\n",
      "resetting env. episode 6003, reward total was -21.0. running mean: -19.032245727010494, timestamp: 2022-08-20 01:38:40.644226\n",
      "resetting env. episode 6004, reward total was -19.0. running mean: -19.03192326974039, timestamp: 2022-08-20 01:38:45.436079\n",
      "resetting env. episode 6005, reward total was -18.0. running mean: -19.021604037042984, timestamp: 2022-08-20 01:38:51.887062\n",
      "resetting env. episode 6006, reward total was -19.0. running mean: -19.021387996672555, timestamp: 2022-08-20 01:38:58.379320\n",
      "resetting env. episode 6007, reward total was -20.0. running mean: -19.031174116705827, timestamp: 2022-08-20 01:39:04.548571\n",
      "resetting env. episode 6008, reward total was -21.0. running mean: -19.05086237553877, timestamp: 2022-08-20 01:39:08.962770\n",
      "resetting env. episode 6009, reward total was -21.0. running mean: -19.070353751783383, timestamp: 2022-08-20 01:39:14.418187\n",
      "resetting env. episode 6010, reward total was -17.0. running mean: -19.04965021426555, timestamp: 2022-08-20 01:39:20.372623\n",
      "resetting env. episode 6011, reward total was -20.0. running mean: -19.059153712122896, timestamp: 2022-08-20 01:39:25.617981\n",
      "resetting env. episode 6012, reward total was -20.0. running mean: -19.068562175001667, timestamp: 2022-08-20 01:39:30.698350\n",
      "resetting env. episode 6013, reward total was -19.0. running mean: -19.06787655325165, timestamp: 2022-08-20 01:39:35.473299\n",
      "resetting env. episode 6014, reward total was -19.0. running mean: -19.067197787719135, timestamp: 2022-08-20 01:39:41.525156\n",
      "resetting env. episode 6015, reward total was -19.0. running mean: -19.066525809841945, timestamp: 2022-08-20 01:39:47.880155\n",
      "resetting env. episode 6016, reward total was -21.0. running mean: -19.085860551743526, timestamp: 2022-08-20 01:39:53.713429\n",
      "resetting env. episode 6017, reward total was -18.0. running mean: -19.07500194622609, timestamp: 2022-08-20 01:39:59.075062\n",
      "resetting env. episode 6018, reward total was -20.0. running mean: -19.08425192676383, timestamp: 2022-08-20 01:40:05.192779\n",
      "resetting env. episode 6019, reward total was -19.0. running mean: -19.083409407496195, timestamp: 2022-08-20 01:40:09.758564\n",
      "resetting env. episode 6020, reward total was -21.0. running mean: -19.102575313421234, timestamp: 2022-08-20 01:40:14.332333\n",
      "resetting env. episode 6021, reward total was -21.0. running mean: -19.121549560287022, timestamp: 2022-08-20 01:40:19.659481\n",
      "resetting env. episode 6022, reward total was -19.0. running mean: -19.120334064684155, timestamp: 2022-08-20 01:40:23.954037\n",
      "resetting env. episode 6023, reward total was -19.0. running mean: -19.119130724037316, timestamp: 2022-08-20 01:40:29.733570\n",
      "resetting env. episode 6024, reward total was -17.0. running mean: -19.097939416796944, timestamp: 2022-08-20 01:40:35.216713\n",
      "resetting env. episode 6025, reward total was -18.0. running mean: -19.086960022628976, timestamp: 2022-08-20 01:40:41.554758\n",
      "resetting env. episode 6026, reward total was -19.0. running mean: -19.086090422402687, timestamp: 2022-08-20 01:40:46.692055\n",
      "resetting env. episode 6027, reward total was -19.0. running mean: -19.08522951817866, timestamp: 2022-08-20 01:40:53.627347\n",
      "resetting env. episode 6028, reward total was -18.0. running mean: -19.074377222996873, timestamp: 2022-08-20 01:40:59.484821\n",
      "resetting env. episode 6029, reward total was -18.0. running mean: -19.063633450766904, timestamp: 2022-08-20 01:41:04.734557\n",
      "resetting env. episode 6030, reward total was -20.0. running mean: -19.072997116259234, timestamp: 2022-08-20 01:41:10.871179\n",
      "resetting env. episode 6031, reward total was -18.0. running mean: -19.06226714509664, timestamp: 2022-08-20 01:41:18.150147\n",
      "resetting env. episode 6032, reward total was -20.0. running mean: -19.071644473645673, timestamp: 2022-08-20 01:41:24.948937\n",
      "resetting env. episode 6033, reward total was -13.0. running mean: -19.010928028909216, timestamp: 2022-08-20 01:41:31.990703\n",
      "resetting env. episode 6034, reward total was -20.0. running mean: -19.020818748620123, timestamp: 2022-08-20 01:41:37.689471\n",
      "resetting env. episode 6035, reward total was -18.0. running mean: -19.01061056113392, timestamp: 2022-08-20 01:41:44.208049\n",
      "resetting env. episode 6036, reward total was -19.0. running mean: -19.010504455522582, timestamp: 2022-08-20 01:41:49.778148\n",
      "resetting env. episode 6037, reward total was -19.0. running mean: -19.01039941096736, timestamp: 2022-08-20 01:41:55.546756\n",
      "resetting env. episode 6038, reward total was -21.0. running mean: -19.030295416857687, timestamp: 2022-08-20 01:41:59.988091\n",
      "resetting env. episode 6039, reward total was -21.0. running mean: -19.04999246268911, timestamp: 2022-08-20 01:42:05.275935\n",
      "resetting env. episode 6040, reward total was -16.0. running mean: -19.01949253806222, timestamp: 2022-08-20 01:42:11.526225\n",
      "resetting env. episode 6041, reward total was -18.0. running mean: -19.009297612681596, timestamp: 2022-08-20 01:42:18.683126\n",
      "resetting env. episode 6042, reward total was -17.0. running mean: -18.98920463655478, timestamp: 2022-08-20 01:42:25.629671\n",
      "resetting env. episode 6043, reward total was -18.0. running mean: -18.979312590189235, timestamp: 2022-08-20 01:42:31.045662\n",
      "resetting env. episode 6044, reward total was -19.0. running mean: -18.979519464287343, timestamp: 2022-08-20 01:42:36.126937\n",
      "resetting env. episode 6045, reward total was -16.0. running mean: -18.94972426964447, timestamp: 2022-08-20 01:42:43.880197\n",
      "resetting env. episode 6046, reward total was -18.0. running mean: -18.940227026948026, timestamp: 2022-08-20 01:42:49.514135\n",
      "resetting env. episode 6047, reward total was -17.0. running mean: -18.92082475667855, timestamp: 2022-08-20 01:42:56.115496\n",
      "resetting env. episode 6048, reward total was -19.0. running mean: -18.921616509111765, timestamp: 2022-08-20 01:43:01.466636\n",
      "resetting env. episode 6049, reward total was -17.0. running mean: -18.90240034402065, timestamp: 2022-08-20 01:43:06.734552\n",
      "resetting env. episode 6050, reward total was -13.0. running mean: -18.84337634058044, timestamp: 2022-08-20 01:43:15.372859\n",
      "resetting env. episode 6051, reward total was -21.0. running mean: -18.864942577174638, timestamp: 2022-08-20 01:43:19.951901\n",
      "resetting env. episode 6052, reward total was -19.0. running mean: -18.866293151402893, timestamp: 2022-08-20 01:43:25.531993\n",
      "resetting env. episode 6053, reward total was -17.0. running mean: -18.847630219888867, timestamp: 2022-08-20 01:43:32.675893\n",
      "resetting env. episode 6054, reward total was -20.0. running mean: -18.859153917689977, timestamp: 2022-08-20 01:43:38.272615\n",
      "resetting env. episode 6055, reward total was -19.0. running mean: -18.860562378513077, timestamp: 2022-08-20 01:43:43.858682\n",
      "resetting env. episode 6056, reward total was -19.0. running mean: -18.86195675472795, timestamp: 2022-08-20 01:43:47.734325\n",
      "resetting env. episode 6057, reward total was -17.0. running mean: -18.84333718718067, timestamp: 2022-08-20 01:43:53.749246\n",
      "resetting env. episode 6058, reward total was -19.0. running mean: -18.844903815308864, timestamp: 2022-08-20 01:43:58.646641\n",
      "resetting env. episode 6059, reward total was -18.0. running mean: -18.836454777155776, timestamp: 2022-08-20 01:44:04.837281\n",
      "resetting env. episode 6060, reward total was -20.0. running mean: -18.848090229384216, timestamp: 2022-08-20 01:44:11.962211\n",
      "resetting env. episode 6061, reward total was -17.0. running mean: -18.829609327090374, timestamp: 2022-08-20 01:44:17.894358\n",
      "resetting env. episode 6062, reward total was -17.0. running mean: -18.811313233819472, timestamp: 2022-08-20 01:44:24.789925\n",
      "resetting env. episode 6063, reward total was -17.0. running mean: -18.79320010148128, timestamp: 2022-08-20 01:44:31.814163\n",
      "resetting env. episode 6064, reward total was -21.0. running mean: -18.81526810046647, timestamp: 2022-08-20 01:44:37.587713\n",
      "resetting env. episode 6065, reward total was -19.0. running mean: -18.817115419461803, timestamp: 2022-08-20 01:44:44.560087\n",
      "resetting env. episode 6066, reward total was -17.0. running mean: -18.79894426526719, timestamp: 2022-08-20 01:44:52.204141\n",
      "resetting env. episode 6067, reward total was -19.0. running mean: -18.800954822614518, timestamp: 2022-08-20 01:44:57.569634\n",
      "resetting env. episode 6068, reward total was -21.0. running mean: -18.822945274388374, timestamp: 2022-08-20 01:45:03.957766\n",
      "resetting env. episode 6069, reward total was -19.0. running mean: -18.824715821644492, timestamp: 2022-08-20 01:45:10.408473\n",
      "resetting env. episode 6070, reward total was -18.0. running mean: -18.816468663428047, timestamp: 2022-08-20 01:45:16.716604\n",
      "resetting env. episode 6071, reward total was -20.0. running mean: -18.828303976793766, timestamp: 2022-08-20 01:45:22.632741\n",
      "resetting env. episode 6072, reward total was -19.0. running mean: -18.83002093702583, timestamp: 2022-08-20 01:45:30.363080\n",
      "resetting env. episode 6073, reward total was -19.0. running mean: -18.831720727655572, timestamp: 2022-08-20 01:45:35.624022\n",
      "resetting env. episode 6074, reward total was -19.0. running mean: -18.83340352037902, timestamp: 2022-08-20 01:45:42.085743\n",
      "resetting env. episode 6075, reward total was -17.0. running mean: -18.81506948517523, timestamp: 2022-08-20 01:45:50.747991\n",
      "resetting env. episode 6076, reward total was -17.0. running mean: -18.796918790323478, timestamp: 2022-08-20 01:45:56.167487\n",
      "resetting env. episode 6077, reward total was -18.0. running mean: -18.788949602420242, timestamp: 2022-08-20 01:46:01.825377\n",
      "resetting env. episode 6078, reward total was -19.0. running mean: -18.791060106396042, timestamp: 2022-08-20 01:46:08.015387\n",
      "resetting env. episode 6079, reward total was -17.0. running mean: -18.773149505332082, timestamp: 2022-08-20 01:46:14.122342\n",
      "resetting env. episode 6080, reward total was -20.0. running mean: -18.78541801027876, timestamp: 2022-08-20 01:46:21.120600\n",
      "resetting env. episode 6081, reward total was -18.0. running mean: -18.77756383017597, timestamp: 2022-08-20 01:46:26.973955\n",
      "resetting env. episode 6082, reward total was -19.0. running mean: -18.779788191874214, timestamp: 2022-08-20 01:46:34.152729\n",
      "resetting env. episode 6083, reward total was -17.0. running mean: -18.761990309955472, timestamp: 2022-08-20 01:46:40.293031\n",
      "resetting env. episode 6084, reward total was -19.0. running mean: -18.764370406855917, timestamp: 2022-08-20 01:46:45.221881\n",
      "resetting env. episode 6085, reward total was -21.0. running mean: -18.78672670278736, timestamp: 2022-08-20 01:46:51.216218\n",
      "resetting env. episode 6086, reward total was -20.0. running mean: -18.798859435759486, timestamp: 2022-08-20 01:46:56.226853\n",
      "resetting env. episode 6087, reward total was -21.0. running mean: -18.82087084140189, timestamp: 2022-08-20 01:47:01.525660\n",
      "resetting env. episode 6088, reward total was -18.0. running mean: -18.81266213298787, timestamp: 2022-08-20 01:47:08.129080\n",
      "resetting env. episode 6089, reward total was -18.0. running mean: -18.804535511657992, timestamp: 2022-08-20 01:47:14.009363\n",
      "resetting env. episode 6090, reward total was -21.0. running mean: -18.826490156541414, timestamp: 2022-08-20 01:47:20.639676\n",
      "resetting env. episode 6091, reward total was -19.0. running mean: -18.828225254976, timestamp: 2022-08-20 01:47:26.351388\n",
      "resetting env. episode 6092, reward total was -18.0. running mean: -18.81994300242624, timestamp: 2022-08-20 01:47:31.955393\n",
      "resetting env. episode 6093, reward total was -20.0. running mean: -18.831743572401976, timestamp: 2022-08-20 01:47:36.471771\n",
      "resetting env. episode 6094, reward total was -20.0. running mean: -18.843426136677955, timestamp: 2022-08-20 01:47:41.449478\n",
      "resetting env. episode 6095, reward total was -17.0. running mean: -18.824991875311177, timestamp: 2022-08-20 01:47:47.050494\n",
      "resetting env. episode 6096, reward total was -20.0. running mean: -18.836741956558065, timestamp: 2022-08-20 01:47:53.860475\n",
      "resetting env. episode 6097, reward total was -19.0. running mean: -18.838374536992486, timestamp: 2022-08-20 01:47:59.497425\n",
      "resetting env. episode 6098, reward total was -20.0. running mean: -18.84999079162256, timestamp: 2022-08-20 01:48:06.764742\n",
      "resetting env. episode 6099, reward total was -19.0. running mean: -18.851490883706337, timestamp: 2022-08-20 01:48:12.538760\n",
      "resetting env. episode 6100, reward total was -21.0. running mean: -18.872975974869274, timestamp: 2022-08-20 01:48:17.756727\n",
      "resetting env. episode 6101, reward total was -19.0. running mean: -18.874246215120582, timestamp: 2022-08-20 01:48:24.205015\n",
      "resetting env. episode 6102, reward total was -20.0. running mean: -18.885503752969374, timestamp: 2022-08-20 01:48:30.570005\n",
      "resetting env. episode 6103, reward total was -18.0. running mean: -18.87664871543968, timestamp: 2022-08-20 01:48:37.231197\n",
      "resetting env. episode 6104, reward total was -20.0. running mean: -18.88788222828528, timestamp: 2022-08-20 01:48:42.222855\n",
      "resetting env. episode 6105, reward total was -19.0. running mean: -18.88900340600243, timestamp: 2022-08-20 01:48:48.901003\n",
      "resetting env. episode 6106, reward total was -20.0. running mean: -18.900113371942407, timestamp: 2022-08-20 01:48:54.939685\n",
      "resetting env. episode 6107, reward total was -17.0. running mean: -18.881112238222983, timestamp: 2022-08-20 01:49:02.538011\n",
      "resetting env. episode 6108, reward total was -17.0. running mean: -18.862301115840754, timestamp: 2022-08-20 01:49:09.053602\n",
      "resetting env. episode 6109, reward total was -20.0. running mean: -18.873678104682345, timestamp: 2022-08-20 01:49:14.264703\n",
      "resetting env. episode 6110, reward total was -19.0. running mean: -18.87494132363552, timestamp: 2022-08-20 01:49:19.556539\n",
      "resetting env. episode 6111, reward total was -21.0. running mean: -18.896191910399168, timestamp: 2022-08-20 01:49:25.815255\n",
      "resetting env. episode 6112, reward total was -19.0. running mean: -18.897229991295177, timestamp: 2022-08-20 01:49:30.998306\n",
      "resetting env. episode 6113, reward total was -20.0. running mean: -18.908257691382225, timestamp: 2022-08-20 01:49:36.317087\n",
      "resetting env. episode 6114, reward total was -17.0. running mean: -18.889175114468404, timestamp: 2022-08-20 01:49:42.610579\n",
      "resetting env. episode 6115, reward total was -19.0. running mean: -18.89028336332372, timestamp: 2022-08-20 01:49:50.792271\n",
      "resetting env. episode 6116, reward total was -20.0. running mean: -18.901380529690485, timestamp: 2022-08-20 01:49:57.131344\n",
      "resetting env. episode 6117, reward total was -17.0. running mean: -18.88236672439358, timestamp: 2022-08-20 01:50:03.703326\n",
      "resetting env. episode 6118, reward total was -20.0. running mean: -18.893543057149643, timestamp: 2022-08-20 01:50:08.653246\n",
      "resetting env. episode 6119, reward total was -18.0. running mean: -18.884607626578145, timestamp: 2022-08-20 01:50:13.631937\n",
      "resetting env. episode 6120, reward total was -21.0. running mean: -18.905761550312363, timestamp: 2022-08-20 01:50:18.750285\n",
      "resetting env. episode 6121, reward total was -19.0. running mean: -18.90670393480924, timestamp: 2022-08-20 01:50:24.186756\n",
      "resetting env. episode 6122, reward total was -17.0. running mean: -18.88763689546115, timestamp: 2022-08-20 01:50:30.362265\n",
      "resetting env. episode 6123, reward total was -18.0. running mean: -18.878760526506536, timestamp: 2022-08-20 01:50:36.831925\n",
      "resetting env. episode 6124, reward total was -18.0. running mean: -18.86997292124147, timestamp: 2022-08-20 01:50:43.994979\n",
      "resetting env. episode 6125, reward total was -18.0. running mean: -18.861273192029053, timestamp: 2022-08-20 01:50:50.889761\n",
      "resetting env. episode 6126, reward total was -18.0. running mean: -18.852660460108762, timestamp: 2022-08-20 01:50:56.880384\n",
      "resetting env. episode 6127, reward total was -19.0. running mean: -18.854133855507676, timestamp: 2022-08-20 01:51:03.090782\n",
      "resetting env. episode 6128, reward total was -18.0. running mean: -18.8455925169526, timestamp: 2022-08-20 01:51:09.716073\n",
      "resetting env. episode 6129, reward total was -21.0. running mean: -18.867136591783073, timestamp: 2022-08-20 01:51:14.837087\n",
      "resetting env. episode 6130, reward total was -18.0. running mean: -18.858465225865242, timestamp: 2022-08-20 01:51:21.188325\n",
      "resetting env. episode 6131, reward total was -19.0. running mean: -18.859880573606592, timestamp: 2022-08-20 01:51:25.882755\n",
      "resetting env. episode 6132, reward total was -17.0. running mean: -18.841281767870527, timestamp: 2022-08-20 01:51:31.879751\n",
      "resetting env. episode 6133, reward total was -18.0. running mean: -18.83286895019182, timestamp: 2022-08-20 01:51:38.029790\n",
      "resetting env. episode 6134, reward total was -18.0. running mean: -18.8245402606899, timestamp: 2022-08-20 01:51:43.649379\n",
      "resetting env. episode 6135, reward total was -19.0. running mean: -18.826294858083003, timestamp: 2022-08-20 01:51:48.529334\n",
      "resetting env. episode 6136, reward total was -20.0. running mean: -18.83803190950217, timestamp: 2022-08-20 01:51:53.155970\n",
      "resetting env. episode 6137, reward total was -21.0. running mean: -18.85965159040715, timestamp: 2022-08-20 01:51:59.449161\n",
      "resetting env. episode 6138, reward total was -17.0. running mean: -18.841055074503082, timestamp: 2022-08-20 01:52:05.356390\n",
      "resetting env. episode 6139, reward total was -21.0. running mean: -18.862644523758053, timestamp: 2022-08-20 01:52:10.023880\n",
      "resetting env. episode 6140, reward total was -17.0. running mean: -18.844018078520474, timestamp: 2022-08-20 01:52:17.854948\n",
      "resetting env. episode 6141, reward total was -20.0. running mean: -18.85557789773527, timestamp: 2022-08-20 01:52:24.778975\n",
      "resetting env. episode 6142, reward total was -19.0. running mean: -18.857022118757918, timestamp: 2022-08-20 01:52:32.736541\n",
      "resetting env. episode 6143, reward total was -16.0. running mean: -18.82845189757034, timestamp: 2022-08-20 01:52:39.840546\n",
      "resetting env. episode 6144, reward total was -20.0. running mean: -18.840167378594636, timestamp: 2022-08-20 01:52:47.057024\n",
      "resetting env. episode 6145, reward total was -20.0. running mean: -18.851765704808688, timestamp: 2022-08-20 01:52:51.690636\n",
      "resetting env. episode 6146, reward total was -21.0. running mean: -18.8732480477606, timestamp: 2022-08-20 01:52:56.400048\n",
      "resetting env. episode 6147, reward total was -19.0. running mean: -18.874515567282995, timestamp: 2022-08-20 01:53:00.604847\n",
      "resetting env. episode 6148, reward total was -14.0. running mean: -18.825770411610165, timestamp: 2022-08-20 01:53:07.356761\n",
      "resetting env. episode 6149, reward total was -19.0. running mean: -18.827512707494066, timestamp: 2022-08-20 01:53:13.313837\n",
      "resetting env. episode 6150, reward total was -18.0. running mean: -18.819237580419124, timestamp: 2022-08-20 01:53:18.795185\n",
      "resetting env. episode 6151, reward total was -21.0. running mean: -18.841045204614932, timestamp: 2022-08-20 01:53:24.786766\n",
      "resetting env. episode 6152, reward total was -21.0. running mean: -18.862634752568784, timestamp: 2022-08-20 01:53:30.288098\n",
      "resetting env. episode 6153, reward total was -18.0. running mean: -18.854008405043096, timestamp: 2022-08-20 01:53:37.111817\n",
      "resetting env. episode 6154, reward total was -20.0. running mean: -18.865468320992665, timestamp: 2022-08-20 01:53:43.841848\n",
      "resetting env. episode 6155, reward total was -20.0. running mean: -18.87681363778274, timestamp: 2022-08-20 01:53:50.479082\n",
      "resetting env. episode 6156, reward total was -19.0. running mean: -18.878045501404912, timestamp: 2022-08-20 01:53:55.234534\n",
      "resetting env. episode 6157, reward total was -21.0. running mean: -18.899265046390862, timestamp: 2022-08-20 01:53:59.751970\n",
      "resetting env. episode 6158, reward total was -19.0. running mean: -18.900272395926955, timestamp: 2022-08-20 01:54:05.646935\n",
      "resetting env. episode 6159, reward total was -17.0. running mean: -18.881269671967686, timestamp: 2022-08-20 01:54:10.640301\n",
      "resetting env. episode 6160, reward total was -20.0. running mean: -18.89245697524801, timestamp: 2022-08-20 01:54:15.984707\n",
      "resetting env. episode 6161, reward total was -16.0. running mean: -18.86353240549553, timestamp: 2022-08-20 01:54:21.377446\n",
      "resetting env. episode 6162, reward total was -20.0. running mean: -18.874897081440572, timestamp: 2022-08-20 01:54:27.538947\n",
      "resetting env. episode 6163, reward total was -21.0. running mean: -18.896148110626168, timestamp: 2022-08-20 01:54:32.756850\n",
      "resetting env. episode 6164, reward total was -20.0. running mean: -18.907186629519906, timestamp: 2022-08-20 01:54:38.832654\n",
      "resetting env. episode 6165, reward total was -21.0. running mean: -18.92811476322471, timestamp: 2022-08-20 01:54:42.844929\n",
      "resetting env. episode 6166, reward total was -19.0. running mean: -18.928833615592463, timestamp: 2022-08-20 01:54:46.481050\n",
      "resetting env. episode 6167, reward total was -18.0. running mean: -18.919545279436537, timestamp: 2022-08-20 01:54:52.172400\n",
      "resetting env. episode 6168, reward total was -20.0. running mean: -18.93034982664217, timestamp: 2022-08-20 01:54:56.315964\n",
      "resetting env. episode 6169, reward total was -21.0. running mean: -18.95104632837575, timestamp: 2022-08-20 01:55:00.251286\n",
      "resetting env. episode 6170, reward total was -19.0. running mean: -18.951535865091994, timestamp: 2022-08-20 01:55:04.714131\n",
      "resetting env. episode 6171, reward total was -18.0. running mean: -18.942020506441075, timestamp: 2022-08-20 01:55:09.346249\n",
      "resetting env. episode 6172, reward total was -20.0. running mean: -18.952600301376663, timestamp: 2022-08-20 01:55:13.339566\n",
      "resetting env. episode 6173, reward total was -19.0. running mean: -18.953074298362896, timestamp: 2022-08-20 01:55:18.391304\n",
      "resetting env. episode 6174, reward total was -19.0. running mean: -18.95354355537927, timestamp: 2022-08-20 01:55:22.832126\n",
      "resetting env. episode 6175, reward total was -19.0. running mean: -18.954008119825478, timestamp: 2022-08-20 01:55:27.765582\n",
      "resetting env. episode 6176, reward total was -20.0. running mean: -18.96446803862722, timestamp: 2022-08-20 01:55:32.712308\n",
      "resetting env. episode 6177, reward total was -21.0. running mean: -18.98482335824095, timestamp: 2022-08-20 01:55:37.281498\n",
      "resetting env. episode 6178, reward total was -17.0. running mean: -18.96497512465854, timestamp: 2022-08-20 01:55:42.471414\n",
      "resetting env. episode 6179, reward total was -21.0. running mean: -18.985325373411957, timestamp: 2022-08-20 01:55:47.107997\n",
      "resetting env. episode 6180, reward total was -21.0. running mean: -19.005472119677837, timestamp: 2022-08-20 01:55:51.422507\n",
      "resetting env. episode 6181, reward total was -15.0. running mean: -18.96541739848106, timestamp: 2022-08-20 01:55:56.660643\n",
      "resetting env. episode 6182, reward total was -19.0. running mean: -18.96576322449625, timestamp: 2022-08-20 01:56:01.347658\n",
      "resetting env. episode 6183, reward total was -19.0. running mean: -18.96610559225129, timestamp: 2022-08-20 01:56:06.043306\n",
      "resetting env. episode 6184, reward total was -19.0. running mean: -18.966444536328776, timestamp: 2022-08-20 01:56:10.474743\n",
      "resetting env. episode 6185, reward total was -18.0. running mean: -18.956780090965488, timestamp: 2022-08-20 01:56:15.168198\n",
      "resetting env. episode 6186, reward total was -20.0. running mean: -18.967212290055834, timestamp: 2022-08-20 01:56:19.770287\n",
      "resetting env. episode 6187, reward total was -19.0. running mean: -18.967540167155278, timestamp: 2022-08-20 01:56:25.133422\n",
      "resetting env. episode 6188, reward total was -20.0. running mean: -18.977864765483723, timestamp: 2022-08-20 01:56:30.494177\n",
      "resetting env. episode 6189, reward total was -19.0. running mean: -18.978086117828887, timestamp: 2022-08-20 01:56:35.891361\n",
      "resetting env. episode 6190, reward total was -19.0. running mean: -18.9783052566506, timestamp: 2022-08-20 01:56:40.499954\n",
      "resetting env. episode 6191, reward total was -21.0. running mean: -18.998522204084093, timestamp: 2022-08-20 01:56:44.686440\n",
      "resetting env. episode 6192, reward total was -21.0. running mean: -19.01853698204325, timestamp: 2022-08-20 01:56:49.543605\n",
      "resetting env. episode 6193, reward total was -19.0. running mean: -19.01835161222282, timestamp: 2022-08-20 01:56:54.815707\n",
      "resetting env. episode 6194, reward total was -18.0. running mean: -19.00816809610059, timestamp: 2022-08-20 01:57:00.692506\n",
      "resetting env. episode 6195, reward total was -19.0. running mean: -19.008086415139584, timestamp: 2022-08-20 01:57:05.241626\n",
      "resetting env. episode 6196, reward total was -19.0. running mean: -19.008005550988187, timestamp: 2022-08-20 01:57:10.801313\n",
      "resetting env. episode 6197, reward total was -18.0. running mean: -18.997925495478306, timestamp: 2022-08-20 01:57:16.025414\n",
      "resetting env. episode 6198, reward total was -21.0. running mean: -19.017946240523525, timestamp: 2022-08-20 01:57:20.534655\n",
      "resetting env. episode 6199, reward total was -20.0. running mean: -19.027766778118288, timestamp: 2022-08-20 01:57:24.731862\n",
      "resetting env. episode 6200, reward total was -17.0. running mean: -19.007489110337108, timestamp: 2022-08-20 01:57:28.983774\n",
      "resetting env. episode 6201, reward total was -19.0. running mean: -19.007414219233738, timestamp: 2022-08-20 01:57:34.454340\n",
      "resetting env. episode 6202, reward total was -19.0. running mean: -19.007340077041402, timestamp: 2022-08-20 01:57:38.994556\n",
      "resetting env. episode 6203, reward total was -20.0. running mean: -19.017266676270985, timestamp: 2022-08-20 01:57:43.675500\n",
      "resetting env. episode 6204, reward total was -21.0. running mean: -19.037094009508277, timestamp: 2022-08-20 01:57:48.930489\n",
      "resetting env. episode 6205, reward total was -21.0. running mean: -19.056723069413195, timestamp: 2022-08-20 01:57:54.724404\n",
      "resetting env. episode 6206, reward total was -21.0. running mean: -19.076155838719064, timestamp: 2022-08-20 01:57:59.577414\n",
      "resetting env. episode 6207, reward total was -17.0. running mean: -19.055394280331875, timestamp: 2022-08-20 01:58:03.645876\n",
      "resetting env. episode 6208, reward total was -19.0. running mean: -19.054840337528557, timestamp: 2022-08-20 01:58:08.995060\n",
      "resetting env. episode 6209, reward total was -14.0. running mean: -19.004291934153272, timestamp: 2022-08-20 01:58:14.327920\n",
      "resetting env. episode 6210, reward total was -21.0. running mean: -19.02424901481174, timestamp: 2022-08-20 01:58:19.880874\n",
      "resetting env. episode 6211, reward total was -20.0. running mean: -19.03400652466362, timestamp: 2022-08-20 01:58:24.205881\n",
      "resetting env. episode 6212, reward total was -21.0. running mean: -19.053666459416984, timestamp: 2022-08-20 01:58:29.619409\n",
      "resetting env. episode 6213, reward total was -21.0. running mean: -19.073129794822815, timestamp: 2022-08-20 01:58:34.441492\n",
      "resetting env. episode 6214, reward total was -16.0. running mean: -19.042398496874586, timestamp: 2022-08-20 01:58:39.388268\n",
      "resetting env. episode 6215, reward total was -19.0. running mean: -19.041974511905842, timestamp: 2022-08-20 01:58:43.464742\n",
      "resetting env. episode 6216, reward total was -19.0. running mean: -19.041554766786785, timestamp: 2022-08-20 01:58:48.589564\n",
      "resetting env. episode 6217, reward total was -19.0. running mean: -19.041139219118918, timestamp: 2022-08-20 01:58:53.095525\n",
      "resetting env. episode 6218, reward total was -21.0. running mean: -19.060727826927728, timestamp: 2022-08-20 01:58:56.899502\n",
      "resetting env. episode 6219, reward total was -17.0. running mean: -19.040120548658454, timestamp: 2022-08-20 01:59:02.869415\n",
      "resetting env. episode 6220, reward total was -19.0. running mean: -19.03971934317187, timestamp: 2022-08-20 01:59:07.120232\n",
      "resetting env. episode 6221, reward total was -21.0. running mean: -19.059322149740154, timestamp: 2022-08-20 01:59:11.446833\n",
      "resetting env. episode 6222, reward total was -21.0. running mean: -19.078728928242754, timestamp: 2022-08-20 01:59:16.011535\n",
      "resetting env. episode 6223, reward total was -20.0. running mean: -19.087941638960324, timestamp: 2022-08-20 01:59:20.971476\n",
      "resetting env. episode 6224, reward total was -17.0. running mean: -19.067062222570723, timestamp: 2022-08-20 01:59:27.151611\n",
      "resetting env. episode 6225, reward total was -17.0. running mean: -19.046391600345018, timestamp: 2022-08-20 01:59:32.410384\n",
      "resetting env. episode 6226, reward total was -20.0. running mean: -19.055927684341565, timestamp: 2022-08-20 01:59:38.129446\n",
      "resetting env. episode 6227, reward total was -19.0. running mean: -19.05536840749815, timestamp: 2022-08-20 01:59:43.677176\n",
      "resetting env. episode 6228, reward total was -19.0. running mean: -19.05481472342317, timestamp: 2022-08-20 01:59:48.926627\n",
      "resetting env. episode 6229, reward total was -19.0. running mean: -19.05426657618894, timestamp: 2022-08-20 01:59:53.565053\n",
      "resetting env. episode 6230, reward total was -19.0. running mean: -19.053723910427053, timestamp: 2022-08-20 01:59:57.669894\n",
      "resetting env. episode 6231, reward total was -20.0. running mean: -19.063186671322782, timestamp: 2022-08-20 02:00:02.125561\n",
      "resetting env. episode 6232, reward total was -19.0. running mean: -19.062554804609555, timestamp: 2022-08-20 02:00:06.239908\n",
      "resetting env. episode 6233, reward total was -20.0. running mean: -19.071929256563457, timestamp: 2022-08-20 02:00:09.776449\n",
      "resetting env. episode 6234, reward total was -19.0. running mean: -19.071209963997823, timestamp: 2022-08-20 02:00:14.248106\n",
      "resetting env. episode 6235, reward total was -19.0. running mean: -19.070497864357847, timestamp: 2022-08-20 02:00:18.645324\n",
      "resetting env. episode 6236, reward total was -16.0. running mean: -19.03979288571427, timestamp: 2022-08-20 02:00:24.469463\n",
      "resetting env. episode 6237, reward total was -18.0. running mean: -19.02939495685713, timestamp: 2022-08-20 02:00:29.068332\n",
      "resetting env. episode 6238, reward total was -21.0. running mean: -19.04910100728856, timestamp: 2022-08-20 02:00:33.057725\n",
      "resetting env. episode 6239, reward total was -20.0. running mean: -19.058609997215672, timestamp: 2022-08-20 02:00:37.459100\n",
      "resetting env. episode 6240, reward total was -15.0. running mean: -19.018023897243513, timestamp: 2022-08-20 02:00:43.091333\n",
      "resetting env. episode 6241, reward total was -17.0. running mean: -18.99784365827108, timestamp: 2022-08-20 02:00:49.307665\n",
      "resetting env. episode 6242, reward total was -17.0. running mean: -18.977865221688372, timestamp: 2022-08-20 02:00:54.988749\n",
      "resetting env. episode 6243, reward total was -18.0. running mean: -18.968086569471488, timestamp: 2022-08-20 02:01:00.107164\n",
      "resetting env. episode 6244, reward total was -19.0. running mean: -18.968405703776774, timestamp: 2022-08-20 02:01:04.664566\n",
      "resetting env. episode 6245, reward total was -18.0. running mean: -18.958721646739008, timestamp: 2022-08-20 02:01:09.736650\n",
      "resetting env. episode 6246, reward total was -20.0. running mean: -18.969134430271616, timestamp: 2022-08-20 02:01:14.473440\n",
      "resetting env. episode 6247, reward total was -19.0. running mean: -18.9694430859689, timestamp: 2022-08-20 02:01:19.873831\n",
      "resetting env. episode 6248, reward total was -19.0. running mean: -18.969748655109214, timestamp: 2022-08-20 02:01:23.968552\n",
      "resetting env. episode 6249, reward total was -17.0. running mean: -18.950051168558122, timestamp: 2022-08-20 02:01:28.670597\n",
      "resetting env. episode 6250, reward total was -19.0. running mean: -18.950550656872544, timestamp: 2022-08-20 02:01:33.083472\n",
      "resetting env. episode 6251, reward total was -20.0. running mean: -18.961045150303818, timestamp: 2022-08-20 02:01:37.431599\n",
      "resetting env. episode 6252, reward total was -19.0. running mean: -18.96143469880078, timestamp: 2022-08-20 02:01:42.072949\n",
      "resetting env. episode 6253, reward total was -19.0. running mean: -18.961820351812772, timestamp: 2022-08-20 02:01:47.237384\n",
      "resetting env. episode 6254, reward total was -19.0. running mean: -18.962202148294647, timestamp: 2022-08-20 02:01:52.294089\n",
      "resetting env. episode 6255, reward total was -20.0. running mean: -18.9725801268117, timestamp: 2022-08-20 02:01:56.436429\n",
      "resetting env. episode 6256, reward total was -19.0. running mean: -18.972854325543583, timestamp: 2022-08-20 02:02:01.267202\n",
      "resetting env. episode 6257, reward total was -18.0. running mean: -18.963125782288145, timestamp: 2022-08-20 02:02:05.836928\n",
      "resetting env. episode 6258, reward total was -18.0. running mean: -18.953494524465263, timestamp: 2022-08-20 02:02:11.348960\n",
      "resetting env. episode 6259, reward total was -16.0. running mean: -18.92395957922061, timestamp: 2022-08-20 02:02:15.983402\n",
      "resetting env. episode 6260, reward total was -18.0. running mean: -18.914719983428405, timestamp: 2022-08-20 02:02:20.857234\n",
      "resetting env. episode 6261, reward total was -20.0. running mean: -18.92557278359412, timestamp: 2022-08-20 02:02:24.357876\n",
      "resetting env. episode 6262, reward total was -21.0. running mean: -18.94631705575818, timestamp: 2022-08-20 02:02:28.543432\n",
      "resetting env. episode 6263, reward total was -18.0. running mean: -18.9368538852006, timestamp: 2022-08-20 02:02:33.063349\n",
      "resetting env. episode 6264, reward total was -17.0. running mean: -18.917485346348595, timestamp: 2022-08-20 02:02:37.651400\n",
      "resetting env. episode 6265, reward total was -20.0. running mean: -18.928310492885107, timestamp: 2022-08-20 02:02:42.522079\n",
      "resetting env. episode 6266, reward total was -19.0. running mean: -18.929027387956257, timestamp: 2022-08-20 02:02:46.772700\n",
      "resetting env. episode 6267, reward total was -21.0. running mean: -18.949737114076694, timestamp: 2022-08-20 02:02:52.447785\n",
      "resetting env. episode 6268, reward total was -21.0. running mean: -18.970239742935927, timestamp: 2022-08-20 02:02:56.644448\n",
      "resetting env. episode 6269, reward total was -17.0. running mean: -18.950537345506568, timestamp: 2022-08-20 02:03:02.226260\n",
      "resetting env. episode 6270, reward total was -21.0. running mean: -18.971031972051502, timestamp: 2022-08-20 02:03:06.656328\n",
      "resetting env. episode 6271, reward total was -20.0. running mean: -18.981321652330987, timestamp: 2022-08-20 02:03:11.271024\n",
      "resetting env. episode 6272, reward total was -18.0. running mean: -18.971508435807678, timestamp: 2022-08-20 02:03:16.530051\n",
      "resetting env. episode 6273, reward total was -20.0. running mean: -18.9817933514496, timestamp: 2022-08-20 02:03:21.411283\n",
      "resetting env. episode 6274, reward total was -17.0. running mean: -18.961975417935104, timestamp: 2022-08-20 02:03:25.405725\n",
      "resetting env. episode 6275, reward total was -21.0. running mean: -18.982355663755754, timestamp: 2022-08-20 02:03:29.296347\n",
      "resetting env. episode 6276, reward total was -19.0. running mean: -18.9825321071182, timestamp: 2022-08-20 02:03:33.377406\n",
      "resetting env. episode 6277, reward total was -18.0. running mean: -18.972706786047016, timestamp: 2022-08-20 02:03:38.940607\n",
      "resetting env. episode 6278, reward total was -17.0. running mean: -18.952979718186548, timestamp: 2022-08-20 02:03:43.358436\n",
      "resetting env. episode 6279, reward total was -20.0. running mean: -18.96344992100468, timestamp: 2022-08-20 02:03:47.806549\n",
      "resetting env. episode 6280, reward total was -18.0. running mean: -18.953815421794634, timestamp: 2022-08-20 02:03:53.036139\n",
      "resetting env. episode 6281, reward total was -20.0. running mean: -18.964277267576687, timestamp: 2022-08-20 02:03:57.312840\n",
      "resetting env. episode 6282, reward total was -20.0. running mean: -18.97463449490092, timestamp: 2022-08-20 02:04:01.911528\n",
      "resetting env. episode 6283, reward total was -18.0. running mean: -18.964888149951907, timestamp: 2022-08-20 02:04:07.102606\n",
      "resetting env. episode 6284, reward total was -19.0. running mean: -18.96523926845239, timestamp: 2022-08-20 02:04:12.218349\n",
      "resetting env. episode 6285, reward total was -17.0. running mean: -18.945586875767866, timestamp: 2022-08-20 02:04:17.948007\n",
      "resetting env. episode 6286, reward total was -19.0. running mean: -18.946131007010187, timestamp: 2022-08-20 02:04:22.720223\n",
      "resetting env. episode 6287, reward total was -21.0. running mean: -18.966669696940087, timestamp: 2022-08-20 02:04:27.070573\n",
      "resetting env. episode 6288, reward total was -20.0. running mean: -18.977002999970686, timestamp: 2022-08-20 02:04:30.990094\n",
      "resetting env. episode 6289, reward total was -19.0. running mean: -18.97723296997098, timestamp: 2022-08-20 02:04:35.970154\n",
      "resetting env. episode 6290, reward total was -19.0. running mean: -18.97746064027127, timestamp: 2022-08-20 02:04:40.341013\n",
      "resetting env. episode 6291, reward total was -19.0. running mean: -18.977686033868558, timestamp: 2022-08-20 02:04:44.688001\n",
      "resetting env. episode 6292, reward total was -20.0. running mean: -18.98790917352987, timestamp: 2022-08-20 02:04:49.061331\n",
      "resetting env. episode 6293, reward total was -18.0. running mean: -18.97803008179457, timestamp: 2022-08-20 02:04:54.224363\n",
      "resetting env. episode 6294, reward total was -20.0. running mean: -18.988249780976624, timestamp: 2022-08-20 02:04:57.940438\n",
      "resetting env. episode 6295, reward total was -21.0. running mean: -19.00836728316686, timestamp: 2022-08-20 02:05:01.495603\n",
      "resetting env. episode 6296, reward total was -16.0. running mean: -18.97828361033519, timestamp: 2022-08-20 02:05:07.024250\n",
      "resetting env. episode 6297, reward total was -21.0. running mean: -18.99850077423184, timestamp: 2022-08-20 02:05:12.040738\n",
      "resetting env. episode 6298, reward total was -20.0. running mean: -19.00851576648952, timestamp: 2022-08-20 02:05:16.245162\n",
      "resetting env. episode 6299, reward total was -17.0. running mean: -18.988430608824626, timestamp: 2022-08-20 02:05:21.089542\n",
      "resetting env. episode 6300, reward total was -20.0. running mean: -18.99854630273638, timestamp: 2022-08-20 02:05:26.372954\n",
      "resetting env. episode 6301, reward total was -21.0. running mean: -19.018560839709018, timestamp: 2022-08-20 02:05:30.449057\n",
      "resetting env. episode 6302, reward total was -19.0. running mean: -19.01837523131193, timestamp: 2022-08-20 02:05:35.576314\n",
      "resetting env. episode 6303, reward total was -15.0. running mean: -18.97819147899881, timestamp: 2022-08-20 02:05:40.498837\n",
      "resetting env. episode 6304, reward total was -19.0. running mean: -18.97840956420882, timestamp: 2022-08-20 02:05:45.406897\n",
      "resetting env. episode 6305, reward total was -19.0. running mean: -18.978625468566733, timestamp: 2022-08-20 02:05:49.758240\n",
      "resetting env. episode 6306, reward total was -19.0. running mean: -18.978839213881066, timestamp: 2022-08-20 02:05:53.904413\n",
      "resetting env. episode 6307, reward total was -17.0. running mean: -18.959050821742256, timestamp: 2022-08-20 02:05:59.453532\n",
      "resetting env. episode 6308, reward total was -19.0. running mean: -18.959460313524836, timestamp: 2022-08-20 02:06:04.611351\n",
      "resetting env. episode 6309, reward total was -21.0. running mean: -18.97986571038959, timestamp: 2022-08-20 02:06:08.509389\n",
      "resetting env. episode 6310, reward total was -19.0. running mean: -18.980067053285694, timestamp: 2022-08-20 02:06:14.441190\n",
      "resetting env. episode 6311, reward total was -21.0. running mean: -19.000266382752837, timestamp: 2022-08-20 02:06:19.103314\n",
      "resetting env. episode 6312, reward total was -17.0. running mean: -18.98026371892531, timestamp: 2022-08-20 02:06:24.805845\n",
      "resetting env. episode 6313, reward total was -20.0. running mean: -18.990461081736058, timestamp: 2022-08-20 02:06:29.320774\n",
      "resetting env. episode 6314, reward total was -19.0. running mean: -18.990556470918698, timestamp: 2022-08-20 02:06:34.324401\n",
      "resetting env. episode 6315, reward total was -17.0. running mean: -18.970650906209514, timestamp: 2022-08-20 02:06:40.230771\n",
      "resetting env. episode 6316, reward total was -21.0. running mean: -18.99094439714742, timestamp: 2022-08-20 02:06:44.202182\n",
      "resetting env. episode 6317, reward total was -20.0. running mean: -19.001034953175946, timestamp: 2022-08-20 02:06:48.461139\n",
      "resetting env. episode 6318, reward total was -21.0. running mean: -19.021024603644186, timestamp: 2022-08-20 02:06:52.752778\n",
      "resetting env. episode 6319, reward total was -20.0. running mean: -19.030814357607742, timestamp: 2022-08-20 02:06:56.758473\n",
      "resetting env. episode 6320, reward total was -21.0. running mean: -19.050506214031664, timestamp: 2022-08-20 02:07:00.490063\n",
      "resetting env. episode 6321, reward total was -20.0. running mean: -19.060001151891345, timestamp: 2022-08-20 02:07:05.112859\n",
      "resetting env. episode 6322, reward total was -16.0. running mean: -19.029401140372432, timestamp: 2022-08-20 02:07:09.809237\n",
      "resetting env. episode 6323, reward total was -16.0. running mean: -18.999107128968706, timestamp: 2022-08-20 02:07:15.207314\n",
      "resetting env. episode 6324, reward total was -19.0. running mean: -18.99911605767902, timestamp: 2022-08-20 02:07:20.827192\n",
      "resetting env. episode 6325, reward total was -18.0. running mean: -18.98912489710223, timestamp: 2022-08-20 02:07:26.247146\n",
      "resetting env. episode 6326, reward total was -18.0. running mean: -18.979233648131206, timestamp: 2022-08-20 02:07:30.953439\n",
      "resetting env. episode 6327, reward total was -20.0. running mean: -18.989441311649895, timestamp: 2022-08-20 02:07:35.694766\n",
      "resetting env. episode 6328, reward total was -21.0. running mean: -19.009546898533397, timestamp: 2022-08-20 02:07:40.949358\n",
      "resetting env. episode 6329, reward total was -18.0. running mean: -18.999451429548063, timestamp: 2022-08-20 02:07:45.510131\n",
      "resetting env. episode 6330, reward total was -20.0. running mean: -19.00945691525258, timestamp: 2022-08-20 02:07:49.947638\n",
      "resetting env. episode 6331, reward total was -18.0. running mean: -18.999362346100057, timestamp: 2022-08-20 02:07:54.982162\n",
      "resetting env. episode 6332, reward total was -20.0. running mean: -19.009368722639056, timestamp: 2022-08-20 02:07:59.884268\n",
      "resetting env. episode 6333, reward total was -14.0. running mean: -18.959275035412666, timestamp: 2022-08-20 02:08:05.173838\n",
      "resetting env. episode 6334, reward total was -21.0. running mean: -18.97968228505854, timestamp: 2022-08-20 02:08:08.508122\n",
      "resetting env. episode 6335, reward total was -17.0. running mean: -18.959885462207957, timestamp: 2022-08-20 02:08:13.328651\n",
      "resetting env. episode 6336, reward total was -18.0. running mean: -18.950286607585877, timestamp: 2022-08-20 02:08:18.817497\n",
      "resetting env. episode 6337, reward total was -19.0. running mean: -18.95078374151002, timestamp: 2022-08-20 02:08:22.814457\n",
      "resetting env. episode 6338, reward total was -20.0. running mean: -18.96127590409492, timestamp: 2022-08-20 02:08:27.992040\n",
      "resetting env. episode 6339, reward total was -19.0. running mean: -18.961663145053972, timestamp: 2022-08-20 02:08:33.253000\n",
      "resetting env. episode 6340, reward total was -18.0. running mean: -18.95204651360343, timestamp: 2022-08-20 02:08:39.048033\n",
      "resetting env. episode 6341, reward total was -21.0. running mean: -18.972526048467397, timestamp: 2022-08-20 02:08:44.528523\n",
      "resetting env. episode 6342, reward total was -17.0. running mean: -18.952800787982724, timestamp: 2022-08-20 02:08:49.857014\n",
      "resetting env. episode 6343, reward total was -18.0. running mean: -18.943272780102898, timestamp: 2022-08-20 02:08:55.150123\n",
      "resetting env. episode 6344, reward total was -18.0. running mean: -18.933840052301868, timestamp: 2022-08-20 02:09:00.002333\n",
      "resetting env. episode 6345, reward total was -14.0. running mean: -18.884501651778848, timestamp: 2022-08-20 02:09:05.692240\n",
      "resetting env. episode 6346, reward total was -17.0. running mean: -18.86565663526106, timestamp: 2022-08-20 02:09:11.092576\n",
      "resetting env. episode 6347, reward total was -20.0. running mean: -18.87700006890845, timestamp: 2022-08-20 02:09:15.396660\n",
      "resetting env. episode 6348, reward total was -20.0. running mean: -18.888230068219364, timestamp: 2022-08-20 02:09:20.146925\n",
      "resetting env. episode 6349, reward total was -17.0. running mean: -18.86934776753717, timestamp: 2022-08-20 02:09:25.215243\n",
      "resetting env. episode 6350, reward total was -20.0. running mean: -18.8806542898618, timestamp: 2022-08-20 02:09:30.248857\n",
      "resetting env. episode 6351, reward total was -20.0. running mean: -18.89184774696318, timestamp: 2022-08-20 02:09:34.514096\n",
      "resetting env. episode 6352, reward total was -17.0. running mean: -18.87292926949355, timestamp: 2022-08-20 02:09:39.990336\n",
      "resetting env. episode 6353, reward total was -17.0. running mean: -18.854199976798615, timestamp: 2022-08-20 02:09:45.337011\n",
      "resetting env. episode 6354, reward total was -19.0. running mean: -18.85565797703063, timestamp: 2022-08-20 02:09:50.027473\n",
      "resetting env. episode 6355, reward total was -19.0. running mean: -18.857101397260326, timestamp: 2022-08-20 02:09:56.020862\n",
      "resetting env. episode 6356, reward total was -19.0. running mean: -18.858530383287725, timestamp: 2022-08-20 02:10:01.307140\n",
      "resetting env. episode 6357, reward total was -19.0. running mean: -18.85994507945485, timestamp: 2022-08-20 02:10:06.219855\n",
      "resetting env. episode 6358, reward total was -18.0. running mean: -18.8513456286603, timestamp: 2022-08-20 02:10:12.129079\n",
      "resetting env. episode 6359, reward total was -19.0. running mean: -18.8528321723737, timestamp: 2022-08-20 02:10:17.668372\n",
      "resetting env. episode 6360, reward total was -19.0. running mean: -18.854303850649963, timestamp: 2022-08-20 02:10:22.252602\n",
      "resetting env. episode 6361, reward total was -20.0. running mean: -18.865760812143463, timestamp: 2022-08-20 02:10:26.315549\n",
      "resetting env. episode 6362, reward total was -17.0. running mean: -18.84710320402203, timestamp: 2022-08-20 02:10:31.295709\n",
      "resetting env. episode 6363, reward total was -19.0. running mean: -18.848632171981812, timestamp: 2022-08-20 02:10:36.614385\n",
      "resetting env. episode 6364, reward total was -21.0. running mean: -18.870145850261995, timestamp: 2022-08-20 02:10:41.064052\n",
      "resetting env. episode 6365, reward total was -20.0. running mean: -18.881444391759374, timestamp: 2022-08-20 02:10:45.545560\n",
      "resetting env. episode 6366, reward total was -21.0. running mean: -18.90262994784178, timestamp: 2022-08-20 02:10:49.856071\n",
      "resetting env. episode 6367, reward total was -19.0. running mean: -18.903603648363365, timestamp: 2022-08-20 02:10:54.956683\n",
      "resetting env. episode 6368, reward total was -21.0. running mean: -18.92456761187973, timestamp: 2022-08-20 02:10:59.726093\n",
      "resetting env. episode 6369, reward total was -18.0. running mean: -18.915321935760932, timestamp: 2022-08-20 02:11:04.612608\n",
      "resetting env. episode 6370, reward total was -19.0. running mean: -18.916168716403323, timestamp: 2022-08-20 02:11:09.165430\n",
      "resetting env. episode 6371, reward total was -21.0. running mean: -18.93700702923929, timestamp: 2022-08-20 02:11:13.161648\n",
      "resetting env. episode 6372, reward total was -17.0. running mean: -18.917636958946897, timestamp: 2022-08-20 02:11:19.093094\n",
      "resetting env. episode 6373, reward total was -18.0. running mean: -18.90846058935743, timestamp: 2022-08-20 02:11:24.840632\n",
      "resetting env. episode 6374, reward total was -19.0. running mean: -18.909375983463857, timestamp: 2022-08-20 02:11:29.301822\n",
      "resetting env. episode 6375, reward total was -18.0. running mean: -18.90028222362922, timestamp: 2022-08-20 02:11:33.924864\n",
      "resetting env. episode 6376, reward total was -18.0. running mean: -18.891279401392925, timestamp: 2022-08-20 02:11:38.689538\n",
      "resetting env. episode 6377, reward total was -19.0. running mean: -18.892366607378996, timestamp: 2022-08-20 02:11:43.624374\n",
      "resetting env. episode 6378, reward total was -20.0. running mean: -18.903442941305205, timestamp: 2022-08-20 02:11:48.682722\n",
      "resetting env. episode 6379, reward total was -19.0. running mean: -18.904408511892154, timestamp: 2022-08-20 02:11:52.584727\n",
      "resetting env. episode 6380, reward total was -20.0. running mean: -18.91536442677323, timestamp: 2022-08-20 02:11:57.770854\n",
      "resetting env. episode 6381, reward total was -20.0. running mean: -18.926210782505496, timestamp: 2022-08-20 02:12:01.934895\n",
      "resetting env. episode 6382, reward total was -20.0. running mean: -18.93694867468044, timestamp: 2022-08-20 02:12:05.712966\n",
      "resetting env. episode 6383, reward total was -18.0. running mean: -18.927579187933635, timestamp: 2022-08-20 02:12:10.651204\n",
      "resetting env. episode 6384, reward total was -19.0. running mean: -18.9283033960543, timestamp: 2022-08-20 02:12:15.521607\n",
      "resetting env. episode 6385, reward total was -17.0. running mean: -18.90902036209376, timestamp: 2022-08-20 02:12:20.573113\n",
      "resetting env. episode 6386, reward total was -21.0. running mean: -18.92993015847282, timestamp: 2022-08-20 02:12:25.191445\n",
      "resetting env. episode 6387, reward total was -19.0. running mean: -18.930630856888094, timestamp: 2022-08-20 02:12:31.413121\n",
      "resetting env. episode 6388, reward total was -20.0. running mean: -18.941324548319212, timestamp: 2022-08-20 02:12:35.595452\n",
      "resetting env. episode 6389, reward total was -19.0. running mean: -18.941911302836022, timestamp: 2022-08-20 02:12:41.244319\n",
      "resetting env. episode 6390, reward total was -20.0. running mean: -18.95249218980766, timestamp: 2022-08-20 02:12:45.433119\n",
      "resetting env. episode 6391, reward total was -21.0. running mean: -18.972967267909585, timestamp: 2022-08-20 02:12:50.269817\n",
      "resetting env. episode 6392, reward total was -19.0. running mean: -18.97323759523049, timestamp: 2022-08-20 02:12:54.196089\n",
      "resetting env. episode 6393, reward total was -16.0. running mean: -18.943505219278187, timestamp: 2022-08-20 02:13:00.174879\n",
      "resetting env. episode 6394, reward total was -20.0. running mean: -18.954070167085405, timestamp: 2022-08-20 02:13:04.091239\n",
      "resetting env. episode 6395, reward total was -19.0. running mean: -18.954529465414552, timestamp: 2022-08-20 02:13:08.038694\n",
      "resetting env. episode 6396, reward total was -18.0. running mean: -18.944984170760407, timestamp: 2022-08-20 02:13:12.618261\n",
      "resetting env. episode 6397, reward total was -19.0. running mean: -18.945534329052805, timestamp: 2022-08-20 02:13:17.301819\n",
      "resetting env. episode 6398, reward total was -17.0. running mean: -18.926078985762278, timestamp: 2022-08-20 02:13:22.818690\n",
      "resetting env. episode 6399, reward total was -17.0. running mean: -18.906818195904656, timestamp: 2022-08-20 02:13:28.091291\n",
      "resetting env. episode 6400, reward total was -16.0. running mean: -18.877750013945608, timestamp: 2022-08-20 02:13:33.657812\n",
      "resetting env. episode 6401, reward total was -18.0. running mean: -18.868972513806153, timestamp: 2022-08-20 02:13:39.198786\n",
      "resetting env. episode 6402, reward total was -19.0. running mean: -18.870282788668092, timestamp: 2022-08-20 02:13:44.219456\n",
      "resetting env. episode 6403, reward total was -19.0. running mean: -18.871579960781414, timestamp: 2022-08-20 02:13:48.733550\n",
      "resetting env. episode 6404, reward total was -19.0. running mean: -18.872864161173602, timestamp: 2022-08-20 02:13:53.892546\n",
      "resetting env. episode 6405, reward total was -21.0. running mean: -18.894135519561868, timestamp: 2022-08-20 02:13:57.855569\n",
      "resetting env. episode 6406, reward total was -19.0. running mean: -18.89519416436625, timestamp: 2022-08-20 02:14:02.741077\n",
      "resetting env. episode 6407, reward total was -20.0. running mean: -18.906242222722586, timestamp: 2022-08-20 02:14:09.523946\n",
      "resetting env. episode 6408, reward total was -19.0. running mean: -18.90717980049536, timestamp: 2022-08-20 02:14:15.654927\n",
      "resetting env. episode 6409, reward total was -16.0. running mean: -18.878108002490407, timestamp: 2022-08-20 02:14:20.927946\n",
      "resetting env. episode 6410, reward total was -19.0. running mean: -18.879326922465506, timestamp: 2022-08-20 02:14:25.719776\n",
      "resetting env. episode 6411, reward total was -21.0. running mean: -18.900533653240853, timestamp: 2022-08-20 02:14:29.732306\n",
      "resetting env. episode 6412, reward total was -19.0. running mean: -18.901528316708447, timestamp: 2022-08-20 02:14:34.504023\n",
      "resetting env. episode 6413, reward total was -21.0. running mean: -18.922513033541364, timestamp: 2022-08-20 02:14:38.930324\n",
      "resetting env. episode 6414, reward total was -20.0. running mean: -18.93328790320595, timestamp: 2022-08-20 02:14:43.414407\n",
      "resetting env. episode 6415, reward total was -20.0. running mean: -18.943955024173892, timestamp: 2022-08-20 02:14:47.792394\n",
      "resetting env. episode 6416, reward total was -20.0. running mean: -18.95451547393215, timestamp: 2022-08-20 02:14:52.711718\n",
      "resetting env. episode 6417, reward total was -19.0. running mean: -18.95497031919283, timestamp: 2022-08-20 02:14:57.634485\n",
      "resetting env. episode 6418, reward total was -18.0. running mean: -18.945420616000902, timestamp: 2022-08-20 02:15:02.533919\n",
      "resetting env. episode 6419, reward total was -19.0. running mean: -18.945966409840896, timestamp: 2022-08-20 02:15:07.104799\n",
      "resetting env. episode 6420, reward total was -16.0. running mean: -18.91650674574249, timestamp: 2022-08-20 02:15:13.229033\n",
      "resetting env. episode 6421, reward total was -19.0. running mean: -18.917341678285066, timestamp: 2022-08-20 02:15:18.635378\n",
      "resetting env. episode 6422, reward total was -19.0. running mean: -18.918168261502217, timestamp: 2022-08-20 02:15:22.899039\n",
      "resetting env. episode 6423, reward total was -20.0. running mean: -18.928986578887194, timestamp: 2022-08-20 02:15:29.149950\n",
      "resetting env. episode 6424, reward total was -19.0. running mean: -18.929696713098323, timestamp: 2022-08-20 02:15:34.429794\n",
      "resetting env. episode 6425, reward total was -20.0. running mean: -18.94039974596734, timestamp: 2022-08-20 02:15:39.366700\n",
      "resetting env. episode 6426, reward total was -20.0. running mean: -18.950995748507665, timestamp: 2022-08-20 02:15:43.678024\n",
      "resetting env. episode 6427, reward total was -18.0. running mean: -18.94148579102259, timestamp: 2022-08-20 02:15:48.692726\n",
      "resetting env. episode 6428, reward total was -19.0. running mean: -18.942070933112365, timestamp: 2022-08-20 02:15:53.687884\n",
      "resetting env. episode 6429, reward total was -20.0. running mean: -18.95265022378124, timestamp: 2022-08-20 02:15:58.072166\n",
      "resetting env. episode 6430, reward total was -21.0. running mean: -18.97312372154343, timestamp: 2022-08-20 02:16:02.287382\n",
      "resetting env. episode 6431, reward total was -19.0. running mean: -18.973392484328, timestamp: 2022-08-20 02:16:07.636535\n",
      "resetting env. episode 6432, reward total was -19.0. running mean: -18.97365855948472, timestamp: 2022-08-20 02:16:12.415002\n",
      "resetting env. episode 6433, reward total was -20.0. running mean: -18.98392197388987, timestamp: 2022-08-20 02:16:16.637101\n",
      "resetting env. episode 6434, reward total was -20.0. running mean: -18.99408275415097, timestamp: 2022-08-20 02:16:21.834860\n",
      "resetting env. episode 6435, reward total was -20.0. running mean: -19.00414192660946, timestamp: 2022-08-20 02:16:27.134152\n",
      "resetting env. episode 6436, reward total was -20.0. running mean: -19.014100507343365, timestamp: 2022-08-20 02:16:31.721830\n",
      "resetting env. episode 6437, reward total was -20.0. running mean: -19.02395950226993, timestamp: 2022-08-20 02:16:37.198260\n",
      "resetting env. episode 6438, reward total was -18.0. running mean: -19.01371990724723, timestamp: 2022-08-20 02:16:41.321980\n",
      "resetting env. episode 6439, reward total was -19.0. running mean: -19.013582708174756, timestamp: 2022-08-20 02:16:46.179243\n",
      "resetting env. episode 6440, reward total was -19.0. running mean: -19.01344688109301, timestamp: 2022-08-20 02:16:51.371878\n",
      "resetting env. episode 6441, reward total was -17.0. running mean: -18.99331241228208, timestamp: 2022-08-20 02:16:56.522683\n",
      "resetting env. episode 6442, reward total was -15.0. running mean: -18.953379288159258, timestamp: 2022-08-20 02:17:02.827957\n",
      "resetting env. episode 6443, reward total was -21.0. running mean: -18.973845495277665, timestamp: 2022-08-20 02:17:09.322596\n",
      "resetting env. episode 6444, reward total was -18.0. running mean: -18.964107040324887, timestamp: 2022-08-20 02:17:16.082526\n",
      "resetting env. episode 6445, reward total was -18.0. running mean: -18.95446596992164, timestamp: 2022-08-20 02:17:21.961536\n",
      "resetting env. episode 6446, reward total was -20.0. running mean: -18.964921310222422, timestamp: 2022-08-20 02:17:26.413205\n",
      "resetting env. episode 6447, reward total was -20.0. running mean: -18.975272097120197, timestamp: 2022-08-20 02:17:30.292500\n",
      "resetting env. episode 6448, reward total was -20.0. running mean: -18.985519376148993, timestamp: 2022-08-20 02:17:33.917415\n",
      "resetting env. episode 6449, reward total was -20.0. running mean: -18.9956641823875, timestamp: 2022-08-20 02:17:37.586607\n",
      "resetting env. episode 6450, reward total was -17.0. running mean: -18.975707540563626, timestamp: 2022-08-20 02:17:43.390119\n",
      "resetting env. episode 6451, reward total was -18.0. running mean: -18.965950465157988, timestamp: 2022-08-20 02:17:50.006697\n",
      "resetting env. episode 6452, reward total was -18.0. running mean: -18.956290960506408, timestamp: 2022-08-20 02:17:54.959025\n",
      "resetting env. episode 6453, reward total was -17.0. running mean: -18.936728050901344, timestamp: 2022-08-20 02:17:59.422038\n",
      "resetting env. episode 6454, reward total was -16.0. running mean: -18.90736077039233, timestamp: 2022-08-20 02:18:04.317450\n",
      "resetting env. episode 6455, reward total was -19.0. running mean: -18.908287162688406, timestamp: 2022-08-20 02:18:08.809771\n",
      "resetting env. episode 6456, reward total was -20.0. running mean: -18.919204291061522, timestamp: 2022-08-20 02:18:13.909319\n",
      "resetting env. episode 6457, reward total was -21.0. running mean: -18.940012248150907, timestamp: 2022-08-20 02:18:17.629064\n",
      "resetting env. episode 6458, reward total was -20.0. running mean: -18.950612125669398, timestamp: 2022-08-20 02:18:22.371640\n",
      "resetting env. episode 6459, reward total was -18.0. running mean: -18.941106004412703, timestamp: 2022-08-20 02:18:26.951395\n",
      "resetting env. episode 6460, reward total was -17.0. running mean: -18.92169494436858, timestamp: 2022-08-20 02:18:31.921942\n",
      "resetting env. episode 6461, reward total was -19.0. running mean: -18.922477994924893, timestamp: 2022-08-20 02:18:37.384560\n",
      "resetting env. episode 6462, reward total was -18.0. running mean: -18.913253214975644, timestamp: 2022-08-20 02:18:41.959268\n",
      "resetting env. episode 6463, reward total was -14.0. running mean: -18.864120682825888, timestamp: 2022-08-20 02:18:47.597524\n",
      "resetting env. episode 6464, reward total was -20.0. running mean: -18.87547947599763, timestamp: 2022-08-20 02:18:51.645061\n",
      "resetting env. episode 6465, reward total was -21.0. running mean: -18.896724681237654, timestamp: 2022-08-20 02:18:55.631398\n",
      "resetting env. episode 6466, reward total was -18.0. running mean: -18.887757434425275, timestamp: 2022-08-20 02:18:59.623478\n",
      "resetting env. episode 6467, reward total was -18.0. running mean: -18.87887986008102, timestamp: 2022-08-20 02:19:04.149380\n",
      "resetting env. episode 6468, reward total was -17.0. running mean: -18.86009106148021, timestamp: 2022-08-20 02:19:09.034326\n",
      "resetting env. episode 6469, reward total was -20.0. running mean: -18.87149015086541, timestamp: 2022-08-20 02:19:14.373789\n",
      "resetting env. episode 6470, reward total was -19.0. running mean: -18.872775249356756, timestamp: 2022-08-20 02:19:19.825134\n",
      "resetting env. episode 6471, reward total was -19.0. running mean: -18.87404749686319, timestamp: 2022-08-20 02:19:23.601876\n",
      "resetting env. episode 6472, reward total was -18.0. running mean: -18.86530702189456, timestamp: 2022-08-20 02:19:29.249174\n",
      "resetting env. episode 6473, reward total was -19.0. running mean: -18.866653951675612, timestamp: 2022-08-20 02:19:33.807943\n",
      "resetting env. episode 6474, reward total was -21.0. running mean: -18.887987412158857, timestamp: 2022-08-20 02:19:38.238273\n",
      "resetting env. episode 6475, reward total was -20.0. running mean: -18.899107538037267, timestamp: 2022-08-20 02:19:43.806177\n",
      "resetting env. episode 6476, reward total was -19.0. running mean: -18.900116462656896, timestamp: 2022-08-20 02:19:48.227608\n",
      "resetting env. episode 6477, reward total was -17.0. running mean: -18.88111529803033, timestamp: 2022-08-20 02:19:53.894664\n",
      "resetting env. episode 6478, reward total was -20.0. running mean: -18.892304145050026, timestamp: 2022-08-20 02:19:58.215140\n",
      "resetting env. episode 6479, reward total was -20.0. running mean: -18.903381103599525, timestamp: 2022-08-20 02:20:02.065108\n",
      "resetting env. episode 6480, reward total was -19.0. running mean: -18.904347292563532, timestamp: 2022-08-20 02:20:06.440020\n",
      "resetting env. episode 6481, reward total was -19.0. running mean: -18.905303819637897, timestamp: 2022-08-20 02:20:11.840865\n",
      "resetting env. episode 6482, reward total was -19.0. running mean: -18.906250781441518, timestamp: 2022-08-20 02:20:16.415300\n",
      "resetting env. episode 6483, reward total was -17.0. running mean: -18.887188273627103, timestamp: 2022-08-20 02:20:21.868305\n",
      "resetting env. episode 6484, reward total was -21.0. running mean: -18.908316390890832, timestamp: 2022-08-20 02:20:26.529739\n",
      "resetting env. episode 6485, reward total was -20.0. running mean: -18.919233226981923, timestamp: 2022-08-20 02:20:31.740810\n",
      "resetting env. episode 6486, reward total was -20.0. running mean: -18.930040894712103, timestamp: 2022-08-20 02:20:38.341169\n",
      "resetting env. episode 6487, reward total was -19.0. running mean: -18.930740485764982, timestamp: 2022-08-20 02:20:43.260767\n",
      "resetting env. episode 6488, reward total was -20.0. running mean: -18.94143308090733, timestamp: 2022-08-20 02:20:48.221844\n",
      "resetting env. episode 6489, reward total was -20.0. running mean: -18.952018750098258, timestamp: 2022-08-20 02:20:54.557180\n",
      "resetting env. episode 6490, reward total was -21.0. running mean: -18.972498562597277, timestamp: 2022-08-20 02:20:58.293411\n",
      "resetting env. episode 6491, reward total was -19.0. running mean: -18.972773576971306, timestamp: 2022-08-20 02:21:03.156312\n",
      "resetting env. episode 6492, reward total was -20.0. running mean: -18.98304584120159, timestamp: 2022-08-20 02:21:07.129918\n",
      "resetting env. episode 6493, reward total was -16.0. running mean: -18.953215382789576, timestamp: 2022-08-20 02:21:12.071582\n",
      "resetting env. episode 6494, reward total was -16.0. running mean: -18.923683228961682, timestamp: 2022-08-20 02:21:16.534821\n",
      "resetting env. episode 6495, reward total was -20.0. running mean: -18.934446396672065, timestamp: 2022-08-20 02:21:20.922476\n",
      "resetting env. episode 6496, reward total was -18.0. running mean: -18.925101932705346, timestamp: 2022-08-20 02:21:27.626980\n",
      "resetting env. episode 6497, reward total was -19.0. running mean: -18.925850913378294, timestamp: 2022-08-20 02:21:33.312254\n",
      "resetting env. episode 6498, reward total was -20.0. running mean: -18.93659240424451, timestamp: 2022-08-20 02:21:37.607272\n",
      "resetting env. episode 6499, reward total was -19.0. running mean: -18.937226480202067, timestamp: 2022-08-20 02:21:42.994173\n",
      "resetting env. episode 6500, reward total was -19.0. running mean: -18.937854215400048, timestamp: 2022-08-20 02:21:47.472737\n",
      "resetting env. episode 6501, reward total was -21.0. running mean: -18.95847567324605, timestamp: 2022-08-20 02:21:51.997988\n",
      "resetting env. episode 6502, reward total was -17.0. running mean: -18.93889091651359, timestamp: 2022-08-20 02:21:58.111118\n",
      "resetting env. episode 6503, reward total was -19.0. running mean: -18.939502007348455, timestamp: 2022-08-20 02:22:03.411745\n",
      "resetting env. episode 6504, reward total was -17.0. running mean: -18.920106987274973, timestamp: 2022-08-20 02:22:08.645676\n",
      "resetting env. episode 6505, reward total was -20.0. running mean: -18.930905917402225, timestamp: 2022-08-20 02:22:13.029539\n",
      "resetting env. episode 6506, reward total was -19.0. running mean: -18.931596858228204, timestamp: 2022-08-20 02:22:18.308400\n",
      "resetting env. episode 6507, reward total was -19.0. running mean: -18.932280889645924, timestamp: 2022-08-20 02:22:22.446419\n",
      "resetting env. episode 6508, reward total was -17.0. running mean: -18.912958080749465, timestamp: 2022-08-20 02:22:26.624247\n",
      "resetting env. episode 6509, reward total was -20.0. running mean: -18.92382849994197, timestamp: 2022-08-20 02:22:31.721323\n",
      "resetting env. episode 6510, reward total was -19.0. running mean: -18.92459021494255, timestamp: 2022-08-20 02:22:36.461443\n",
      "resetting env. episode 6511, reward total was -20.0. running mean: -18.935344312793124, timestamp: 2022-08-20 02:22:40.801825\n",
      "resetting env. episode 6512, reward total was -18.0. running mean: -18.925990869665192, timestamp: 2022-08-20 02:22:45.049351\n",
      "resetting env. episode 6513, reward total was -18.0. running mean: -18.91673096096854, timestamp: 2022-08-20 02:22:49.909941\n",
      "resetting env. episode 6514, reward total was -19.0. running mean: -18.917563651358854, timestamp: 2022-08-20 02:22:55.007470\n",
      "resetting env. episode 6515, reward total was -21.0. running mean: -18.938388014845266, timestamp: 2022-08-20 02:22:58.821113\n",
      "resetting env. episode 6516, reward total was -16.0. running mean: -18.909004134696815, timestamp: 2022-08-20 02:23:04.171207\n",
      "resetting env. episode 6517, reward total was -19.0. running mean: -18.909914093349848, timestamp: 2022-08-20 02:23:08.987960\n",
      "resetting env. episode 6518, reward total was -19.0. running mean: -18.91081495241635, timestamp: 2022-08-20 02:23:13.916633\n",
      "resetting env. episode 6519, reward total was -20.0. running mean: -18.921706802892185, timestamp: 2022-08-20 02:23:18.942639\n",
      "resetting env. episode 6520, reward total was -17.0. running mean: -18.902489734863266, timestamp: 2022-08-20 02:23:23.276948\n",
      "resetting env. episode 6521, reward total was -19.0. running mean: -18.903464837514633, timestamp: 2022-08-20 02:23:28.124782\n",
      "resetting env. episode 6522, reward total was -19.0. running mean: -18.90443018913949, timestamp: 2022-08-20 02:23:34.289300\n",
      "resetting env. episode 6523, reward total was -21.0. running mean: -18.925385887248094, timestamp: 2022-08-20 02:23:38.666487\n",
      "resetting env. episode 6524, reward total was -19.0. running mean: -18.926132028375616, timestamp: 2022-08-20 02:23:44.210699\n",
      "resetting env. episode 6525, reward total was -16.0. running mean: -18.89687070809186, timestamp: 2022-08-20 02:23:50.006695\n",
      "resetting env. episode 6526, reward total was -20.0. running mean: -18.907902001010942, timestamp: 2022-08-20 02:23:54.782982\n",
      "resetting env. episode 6527, reward total was -21.0. running mean: -18.928822981000835, timestamp: 2022-08-20 02:23:58.895354\n",
      "resetting env. episode 6528, reward total was -19.0. running mean: -18.92953475119083, timestamp: 2022-08-20 02:24:03.797110\n",
      "resetting env. episode 6529, reward total was -21.0. running mean: -18.95023940367892, timestamp: 2022-08-20 02:24:08.828310\n",
      "resetting env. episode 6530, reward total was -20.0. running mean: -18.96073700964213, timestamp: 2022-08-20 02:24:12.216722\n",
      "resetting env. episode 6531, reward total was -21.0. running mean: -18.98112963954571, timestamp: 2022-08-20 02:24:16.217327\n",
      "resetting env. episode 6532, reward total was -19.0. running mean: -18.981318343150253, timestamp: 2022-08-20 02:24:22.407078\n",
      "resetting env. episode 6533, reward total was -17.0. running mean: -18.96150515971875, timestamp: 2022-08-20 02:24:27.257402\n",
      "resetting env. episode 6534, reward total was -19.0. running mean: -18.961890108121565, timestamp: 2022-08-20 02:24:32.701173\n",
      "resetting env. episode 6535, reward total was -20.0. running mean: -18.97227120704035, timestamp: 2022-08-20 02:24:35.871912\n",
      "resetting env. episode 6536, reward total was -15.0. running mean: -18.932548494969947, timestamp: 2022-08-20 02:24:41.785836\n",
      "resetting env. episode 6537, reward total was -20.0. running mean: -18.943223010020247, timestamp: 2022-08-20 02:24:47.112651\n",
      "resetting env. episode 6538, reward total was -19.0. running mean: -18.943790779920047, timestamp: 2022-08-20 02:24:51.266074\n",
      "resetting env. episode 6539, reward total was -17.0. running mean: -18.92435287212085, timestamp: 2022-08-20 02:24:55.443513\n",
      "resetting env. episode 6540, reward total was -19.0. running mean: -18.92510934339964, timestamp: 2022-08-20 02:25:01.068872\n",
      "resetting env. episode 6541, reward total was -21.0. running mean: -18.945858249965646, timestamp: 2022-08-20 02:25:04.709173\n",
      "resetting env. episode 6542, reward total was -21.0. running mean: -18.96639966746599, timestamp: 2022-08-20 02:25:08.925635\n",
      "resetting env. episode 6543, reward total was -20.0. running mean: -18.976735670791328, timestamp: 2022-08-20 02:25:13.170277\n",
      "resetting env. episode 6544, reward total was -21.0. running mean: -18.996968314083414, timestamp: 2022-08-20 02:25:16.805463\n",
      "resetting env. episode 6545, reward total was -18.0. running mean: -18.98699863094258, timestamp: 2022-08-20 02:25:22.069222\n",
      "resetting env. episode 6546, reward total was -21.0. running mean: -19.007128644633156, timestamp: 2022-08-20 02:25:25.691580\n",
      "resetting env. episode 6547, reward total was -19.0. running mean: -19.007057358186824, timestamp: 2022-08-20 02:25:29.884300\n",
      "resetting env. episode 6548, reward total was -19.0. running mean: -19.00698678460496, timestamp: 2022-08-20 02:25:35.158030\n",
      "resetting env. episode 6549, reward total was -21.0. running mean: -19.02691691675891, timestamp: 2022-08-20 02:25:39.815844\n",
      "resetting env. episode 6550, reward total was -19.0. running mean: -19.026647747591323, timestamp: 2022-08-20 02:25:44.456475\n",
      "resetting env. episode 6551, reward total was -21.0. running mean: -19.04638127011541, timestamp: 2022-08-20 02:25:48.344914\n",
      "resetting env. episode 6552, reward total was -21.0. running mean: -19.06591745741426, timestamp: 2022-08-20 02:25:52.044292\n",
      "resetting env. episode 6553, reward total was -16.0. running mean: -19.035258282840115, timestamp: 2022-08-20 02:25:58.516948\n",
      "resetting env. episode 6554, reward total was -16.0. running mean: -19.004905700011715, timestamp: 2022-08-20 02:26:03.801564\n",
      "resetting env. episode 6555, reward total was -15.0. running mean: -18.964856643011597, timestamp: 2022-08-20 02:26:09.614632\n",
      "resetting env. episode 6556, reward total was -17.0. running mean: -18.945208076581483, timestamp: 2022-08-20 02:26:15.269778\n",
      "resetting env. episode 6557, reward total was -20.0. running mean: -18.955755995815668, timestamp: 2022-08-20 02:26:20.929697\n",
      "resetting env. episode 6558, reward total was -18.0. running mean: -18.94619843585751, timestamp: 2022-08-20 02:26:26.452680\n",
      "resetting env. episode 6559, reward total was -21.0. running mean: -18.966736451498935, timestamp: 2022-08-20 02:26:32.006895\n",
      "resetting env. episode 6560, reward total was -20.0. running mean: -18.977069086983946, timestamp: 2022-08-20 02:26:37.083701\n",
      "resetting env. episode 6561, reward total was -21.0. running mean: -18.997298396114108, timestamp: 2022-08-20 02:26:41.570865\n",
      "resetting env. episode 6562, reward total was -19.0. running mean: -18.997325412152968, timestamp: 2022-08-20 02:26:45.688891\n",
      "resetting env. episode 6563, reward total was -21.0. running mean: -19.01735215803144, timestamp: 2022-08-20 02:26:49.907383\n",
      "resetting env. episode 6564, reward total was -19.0. running mean: -19.017178636451128, timestamp: 2022-08-20 02:26:54.759201\n",
      "resetting env. episode 6565, reward total was -20.0. running mean: -19.027006850086615, timestamp: 2022-08-20 02:26:58.980070\n",
      "resetting env. episode 6566, reward total was -19.0. running mean: -19.02673678158575, timestamp: 2022-08-20 02:27:04.532931\n",
      "resetting env. episode 6567, reward total was -20.0. running mean: -19.036469413769893, timestamp: 2022-08-20 02:27:09.488656\n",
      "resetting env. episode 6568, reward total was -20.0. running mean: -19.046104719632194, timestamp: 2022-08-20 02:27:14.391538\n",
      "resetting env. episode 6569, reward total was -19.0. running mean: -19.045643672435872, timestamp: 2022-08-20 02:27:20.158035\n",
      "resetting env. episode 6570, reward total was -21.0. running mean: -19.065187235711516, timestamp: 2022-08-20 02:27:25.416978\n",
      "resetting env. episode 6571, reward total was -21.0. running mean: -19.0845353633544, timestamp: 2022-08-20 02:27:30.226893\n",
      "resetting env. episode 6572, reward total was -20.0. running mean: -19.093690009720856, timestamp: 2022-08-20 02:27:35.632376\n",
      "resetting env. episode 6573, reward total was -19.0. running mean: -19.092753109623647, timestamp: 2022-08-20 02:27:39.791111\n",
      "resetting env. episode 6574, reward total was -21.0. running mean: -19.111825578527412, timestamp: 2022-08-20 02:27:44.702210\n",
      "resetting env. episode 6575, reward total was -21.0. running mean: -19.13070732274214, timestamp: 2022-08-20 02:27:49.349433\n",
      "resetting env. episode 6576, reward total was -17.0. running mean: -19.10940024951472, timestamp: 2022-08-20 02:27:55.181931\n",
      "resetting env. episode 6577, reward total was -20.0. running mean: -19.11830624701957, timestamp: 2022-08-20 02:27:59.441701\n",
      "resetting env. episode 6578, reward total was -21.0. running mean: -19.137123184549377, timestamp: 2022-08-20 02:28:03.516835\n",
      "resetting env. episode 6579, reward total was -17.0. running mean: -19.115751952703885, timestamp: 2022-08-20 02:28:08.255025\n",
      "resetting env. episode 6580, reward total was -19.0. running mean: -19.114594433176848, timestamp: 2022-08-20 02:28:12.311542\n",
      "resetting env. episode 6581, reward total was -20.0. running mean: -19.123448488845078, timestamp: 2022-08-20 02:28:16.959741\n",
      "resetting env. episode 6582, reward total was -18.0. running mean: -19.112214003956627, timestamp: 2022-08-20 02:28:21.382956\n",
      "resetting env. episode 6583, reward total was -18.0. running mean: -19.10109186391706, timestamp: 2022-08-20 02:28:26.285933\n",
      "resetting env. episode 6584, reward total was -20.0. running mean: -19.110080945277886, timestamp: 2022-08-20 02:28:32.095293\n",
      "resetting env. episode 6585, reward total was -20.0. running mean: -19.118980135825108, timestamp: 2022-08-20 02:28:37.247856\n",
      "resetting env. episode 6586, reward total was -21.0. running mean: -19.137790334466857, timestamp: 2022-08-20 02:28:41.351398\n",
      "resetting env. episode 6587, reward total was -20.0. running mean: -19.146412431122187, timestamp: 2022-08-20 02:28:45.836387\n",
      "resetting env. episode 6588, reward total was -18.0. running mean: -19.134948306810966, timestamp: 2022-08-20 02:28:50.942937\n",
      "resetting env. episode 6589, reward total was -19.0. running mean: -19.133598823742858, timestamp: 2022-08-20 02:28:55.864702\n",
      "resetting env. episode 6590, reward total was -15.0. running mean: -19.092262835505426, timestamp: 2022-08-20 02:29:00.834612\n",
      "resetting env. episode 6591, reward total was -18.0. running mean: -19.081340207150372, timestamp: 2022-08-20 02:29:05.399408\n",
      "resetting env. episode 6592, reward total was -18.0. running mean: -19.070526805078867, timestamp: 2022-08-20 02:29:11.433097\n",
      "resetting env. episode 6593, reward total was -19.0. running mean: -19.06982153702808, timestamp: 2022-08-20 02:29:18.348964\n",
      "resetting env. episode 6594, reward total was -21.0. running mean: -19.0891233216578, timestamp: 2022-08-20 02:29:23.771821\n",
      "resetting env. episode 6595, reward total was -15.0. running mean: -19.04823208844122, timestamp: 2022-08-20 02:29:30.611028\n",
      "resetting env. episode 6596, reward total was -21.0. running mean: -19.06774976755681, timestamp: 2022-08-20 02:29:35.533694\n",
      "resetting env. episode 6597, reward total was -17.0. running mean: -19.04707226988124, timestamp: 2022-08-20 02:29:41.179425\n",
      "resetting env. episode 6598, reward total was -21.0. running mean: -19.06660154718243, timestamp: 2022-08-20 02:29:45.226607\n",
      "resetting env. episode 6599, reward total was -19.0. running mean: -19.065935531710608, timestamp: 2022-08-20 02:29:50.969979\n",
      "resetting env. episode 6600, reward total was -20.0. running mean: -19.0752761763935, timestamp: 2022-08-20 02:29:55.257156\n",
      "resetting env. episode 6601, reward total was -17.0. running mean: -19.054523414629568, timestamp: 2022-08-20 02:30:00.355451\n",
      "resetting env. episode 6602, reward total was -21.0. running mean: -19.073978180483273, timestamp: 2022-08-20 02:30:05.085030\n",
      "resetting env. episode 6603, reward total was -18.0. running mean: -19.06323839867844, timestamp: 2022-08-20 02:30:10.459321\n",
      "resetting env. episode 6604, reward total was -19.0. running mean: -19.062606014691656, timestamp: 2022-08-20 02:30:17.743461\n",
      "resetting env. episode 6605, reward total was -20.0. running mean: -19.07197995454474, timestamp: 2022-08-20 02:30:21.857632\n",
      "resetting env. episode 6606, reward total was -20.0. running mean: -19.081260154999292, timestamp: 2022-08-20 02:30:27.036022\n",
      "resetting env. episode 6607, reward total was -18.0. running mean: -19.0704475534493, timestamp: 2022-08-20 02:30:32.404667\n",
      "resetting env. episode 6608, reward total was -18.0. running mean: -19.059743077914806, timestamp: 2022-08-20 02:30:37.420928\n",
      "resetting env. episode 6609, reward total was -20.0. running mean: -19.069145647135656, timestamp: 2022-08-20 02:30:41.356898\n",
      "resetting env. episode 6610, reward total was -20.0. running mean: -19.0784541906643, timestamp: 2022-08-20 02:30:45.775974\n",
      "resetting env. episode 6611, reward total was -20.0. running mean: -19.087669648757654, timestamp: 2022-08-20 02:30:51.292853\n",
      "resetting env. episode 6612, reward total was -15.0. running mean: -19.046792952270074, timestamp: 2022-08-20 02:30:57.503191\n",
      "resetting env. episode 6613, reward total was -21.0. running mean: -19.066325022747375, timestamp: 2022-08-20 02:31:02.271366\n",
      "resetting env. episode 6614, reward total was -15.0. running mean: -19.0256617725199, timestamp: 2022-08-20 02:31:08.276797\n",
      "resetting env. episode 6615, reward total was -19.0. running mean: -19.0254051547947, timestamp: 2022-08-20 02:31:13.941874\n",
      "resetting env. episode 6616, reward total was -16.0. running mean: -18.995151103246755, timestamp: 2022-08-20 02:31:19.018523\n",
      "resetting env. episode 6617, reward total was -17.0. running mean: -18.975199592214288, timestamp: 2022-08-20 02:31:24.243674\n",
      "resetting env. episode 6618, reward total was -21.0. running mean: -18.995447596292145, timestamp: 2022-08-20 02:31:28.263490\n",
      "resetting env. episode 6619, reward total was -19.0. running mean: -18.995493120329225, timestamp: 2022-08-20 02:31:34.791705\n",
      "resetting env. episode 6620, reward total was -19.0. running mean: -18.995538189125934, timestamp: 2022-08-20 02:31:40.157359\n",
      "resetting env. episode 6621, reward total was -17.0. running mean: -18.975582807234677, timestamp: 2022-08-20 02:31:45.957690\n",
      "resetting env. episode 6622, reward total was -18.0. running mean: -18.96582697916233, timestamp: 2022-08-20 02:31:50.579390\n",
      "resetting env. episode 6623, reward total was -18.0. running mean: -18.956168709370704, timestamp: 2022-08-20 02:31:55.960019\n",
      "resetting env. episode 6624, reward total was -20.0. running mean: -18.966607022276996, timestamp: 2022-08-20 02:32:01.828363\n",
      "resetting env. episode 6625, reward total was -19.0. running mean: -18.966940952054227, timestamp: 2022-08-20 02:32:07.723575\n",
      "resetting env. episode 6626, reward total was -20.0. running mean: -18.977271542533682, timestamp: 2022-08-20 02:32:13.024405\n",
      "resetting env. episode 6627, reward total was -20.0. running mean: -18.987498827108343, timestamp: 2022-08-20 02:32:18.389078\n",
      "resetting env. episode 6628, reward total was -19.0. running mean: -18.987623838837262, timestamp: 2022-08-20 02:32:23.834527\n",
      "resetting env. episode 6629, reward total was -19.0. running mean: -18.98774760044889, timestamp: 2022-08-20 02:32:29.695130\n",
      "resetting env. episode 6630, reward total was -19.0. running mean: -18.987870124444402, timestamp: 2022-08-20 02:32:34.754848\n",
      "resetting env. episode 6631, reward total was -20.0. running mean: -18.997991423199956, timestamp: 2022-08-20 02:32:38.787990\n",
      "resetting env. episode 6632, reward total was -17.0. running mean: -18.978011508967956, timestamp: 2022-08-20 02:32:43.905114\n",
      "resetting env. episode 6633, reward total was -19.0. running mean: -18.97823139387828, timestamp: 2022-08-20 02:32:50.433265\n",
      "resetting env. episode 6634, reward total was -16.0. running mean: -18.948449079939497, timestamp: 2022-08-20 02:32:54.741404\n",
      "resetting env. episode 6635, reward total was -18.0. running mean: -18.938964589140102, timestamp: 2022-08-20 02:33:00.458982\n",
      "resetting env. episode 6636, reward total was -19.0. running mean: -18.9395749432487, timestamp: 2022-08-20 02:33:04.903781\n",
      "resetting env. episode 6637, reward total was -19.0. running mean: -18.940179193816213, timestamp: 2022-08-20 02:33:10.014359\n",
      "resetting env. episode 6638, reward total was -18.0. running mean: -18.93077740187805, timestamp: 2022-08-20 02:33:15.541560\n",
      "resetting env. episode 6639, reward total was -18.0. running mean: -18.92146962785927, timestamp: 2022-08-20 02:33:21.361362\n",
      "resetting env. episode 6640, reward total was -20.0. running mean: -18.932254931580676, timestamp: 2022-08-20 02:33:27.297676\n",
      "resetting env. episode 6641, reward total was -19.0. running mean: -18.93293238226487, timestamp: 2022-08-20 02:33:31.846221\n",
      "resetting env. episode 6642, reward total was -19.0. running mean: -18.933603058442223, timestamp: 2022-08-20 02:33:37.981573\n",
      "resetting env. episode 6643, reward total was -21.0. running mean: -18.954267027857803, timestamp: 2022-08-20 02:33:43.374188\n",
      "resetting env. episode 6644, reward total was -19.0. running mean: -18.954724357579227, timestamp: 2022-08-20 02:33:48.469537\n",
      "resetting env. episode 6645, reward total was -20.0. running mean: -18.965177114003435, timestamp: 2022-08-20 02:33:53.160929\n",
      "resetting env. episode 6646, reward total was -17.0. running mean: -18.9455253428634, timestamp: 2022-08-20 02:34:00.034560\n",
      "resetting env. episode 6647, reward total was -19.0. running mean: -18.94607008943477, timestamp: 2022-08-20 02:34:07.031654\n",
      "resetting env. episode 6648, reward total was -18.0. running mean: -18.936609388540422, timestamp: 2022-08-20 02:34:14.474822\n",
      "resetting env. episode 6649, reward total was -18.0. running mean: -18.927243294655018, timestamp: 2022-08-20 02:34:21.844929\n",
      "resetting env. episode 6650, reward total was -20.0. running mean: -18.937970861708468, timestamp: 2022-08-20 02:34:28.194961\n",
      "resetting env. episode 6651, reward total was -19.0. running mean: -18.938591153091384, timestamp: 2022-08-20 02:34:33.723176\n",
      "resetting env. episode 6652, reward total was -20.0. running mean: -18.94920524156047, timestamp: 2022-08-20 02:34:39.215549\n",
      "resetting env. episode 6653, reward total was -21.0. running mean: -18.969713189144866, timestamp: 2022-08-20 02:34:45.404570\n",
      "resetting env. episode 6654, reward total was -20.0. running mean: -18.980016057253415, timestamp: 2022-08-20 02:34:50.589192\n",
      "resetting env. episode 6655, reward total was -19.0. running mean: -18.980215896680882, timestamp: 2022-08-20 02:34:55.197874\n",
      "resetting env. episode 6656, reward total was -19.0. running mean: -18.980413737714073, timestamp: 2022-08-20 02:35:00.593724\n",
      "resetting env. episode 6657, reward total was -20.0. running mean: -18.99060960033693, timestamp: 2022-08-20 02:35:05.841107\n",
      "resetting env. episode 6658, reward total was -21.0. running mean: -19.010703504333563, timestamp: 2022-08-20 02:35:10.157612\n",
      "resetting env. episode 6659, reward total was -19.0. running mean: -19.010596469290228, timestamp: 2022-08-20 02:35:14.636483\n",
      "resetting env. episode 6660, reward total was -18.0. running mean: -19.000490504597323, timestamp: 2022-08-20 02:35:19.607253\n",
      "resetting env. episode 6661, reward total was -20.0. running mean: -19.010485599551348, timestamp: 2022-08-20 02:35:26.458943\n",
      "resetting env. episode 6662, reward total was -18.0. running mean: -19.000380743555834, timestamp: 2022-08-20 02:35:32.878779\n",
      "resetting env. episode 6663, reward total was -18.0. running mean: -18.990376936120274, timestamp: 2022-08-20 02:35:38.203548\n",
      "resetting env. episode 6664, reward total was -18.0. running mean: -18.980473166759072, timestamp: 2022-08-20 02:35:45.052238\n",
      "resetting env. episode 6665, reward total was -18.0. running mean: -18.970668435091483, timestamp: 2022-08-20 02:35:51.429203\n",
      "resetting env. episode 6666, reward total was -18.0. running mean: -18.960961750740566, timestamp: 2022-08-20 02:35:57.704750\n",
      "resetting env. episode 6667, reward total was -18.0. running mean: -18.95135213323316, timestamp: 2022-08-20 02:36:03.733856\n",
      "resetting env. episode 6668, reward total was -18.0. running mean: -18.94183861190083, timestamp: 2022-08-20 02:36:10.539668\n",
      "resetting env. episode 6669, reward total was -14.0. running mean: -18.892420225781823, timestamp: 2022-08-20 02:36:19.402271\n",
      "resetting env. episode 6670, reward total was -21.0. running mean: -18.913496023524004, timestamp: 2022-08-20 02:36:24.504653\n",
      "resetting env. episode 6671, reward total was -19.0. running mean: -18.914361063288766, timestamp: 2022-08-20 02:36:30.136913\n",
      "resetting env. episode 6672, reward total was -19.0. running mean: -18.91521745265588, timestamp: 2022-08-20 02:36:37.721623\n",
      "resetting env. episode 6673, reward total was -17.0. running mean: -18.896065278129324, timestamp: 2022-08-20 02:36:43.899615\n",
      "resetting env. episode 6674, reward total was -15.0. running mean: -18.85710462534803, timestamp: 2022-08-20 02:36:50.206614\n",
      "resetting env. episode 6675, reward total was -18.0. running mean: -18.84853357909455, timestamp: 2022-08-20 02:36:55.075739\n",
      "resetting env. episode 6676, reward total was -20.0. running mean: -18.860048243303602, timestamp: 2022-08-20 02:37:01.739668\n",
      "resetting env. episode 6677, reward total was -17.0. running mean: -18.84144776087057, timestamp: 2022-08-20 02:37:08.473669\n",
      "resetting env. episode 6678, reward total was -21.0. running mean: -18.863033283261863, timestamp: 2022-08-20 02:37:13.202161\n",
      "resetting env. episode 6679, reward total was -21.0. running mean: -18.884402950429244, timestamp: 2022-08-20 02:37:18.148944\n",
      "resetting env. episode 6680, reward total was -18.0. running mean: -18.875558920924952, timestamp: 2022-08-20 02:37:23.059098\n",
      "resetting env. episode 6681, reward total was -19.0. running mean: -18.876803331715703, timestamp: 2022-08-20 02:37:28.673446\n",
      "resetting env. episode 6682, reward total was -17.0. running mean: -18.858035298398548, timestamp: 2022-08-20 02:37:33.574618\n",
      "resetting env. episode 6683, reward total was -20.0. running mean: -18.86945494541456, timestamp: 2022-08-20 02:37:38.529116\n",
      "resetting env. episode 6684, reward total was -17.0. running mean: -18.850760395960418, timestamp: 2022-08-20 02:37:43.339705\n",
      "resetting env. episode 6685, reward total was -21.0. running mean: -18.872252792000815, timestamp: 2022-08-20 02:37:47.467887\n",
      "resetting env. episode 6686, reward total was -20.0. running mean: -18.883530264080807, timestamp: 2022-08-20 02:37:52.047244\n",
      "resetting env. episode 6687, reward total was -19.0. running mean: -18.88469496144, timestamp: 2022-08-20 02:37:56.802897\n",
      "resetting env. episode 6688, reward total was -21.0. running mean: -18.9058480118256, timestamp: 2022-08-20 02:38:01.069506\n",
      "resetting env. episode 6689, reward total was -21.0. running mean: -18.926789531707346, timestamp: 2022-08-20 02:38:05.710330\n",
      "resetting env. episode 6690, reward total was -21.0. running mean: -18.947521636390274, timestamp: 2022-08-20 02:38:10.272078\n",
      "resetting env. episode 6691, reward total was -18.0. running mean: -18.93804642002637, timestamp: 2022-08-20 02:38:15.269567\n",
      "resetting env. episode 6692, reward total was -19.0. running mean: -18.93866595582611, timestamp: 2022-08-20 02:38:20.374354\n",
      "resetting env. episode 6693, reward total was -17.0. running mean: -18.91927929626785, timestamp: 2022-08-20 02:38:24.950947\n",
      "resetting env. episode 6694, reward total was -20.0. running mean: -18.93008650330517, timestamp: 2022-08-20 02:38:29.985790\n",
      "resetting env. episode 6695, reward total was -21.0. running mean: -18.95078563827212, timestamp: 2022-08-20 02:38:36.041078\n",
      "resetting env. episode 6696, reward total was -21.0. running mean: -18.9712777818894, timestamp: 2022-08-20 02:38:39.972580\n",
      "resetting env. episode 6697, reward total was -18.0. running mean: -18.961565004070504, timestamp: 2022-08-20 02:38:45.068850\n",
      "resetting env. episode 6698, reward total was -17.0. running mean: -18.941949354029802, timestamp: 2022-08-20 02:38:50.509877\n",
      "resetting env. episode 6699, reward total was -17.0. running mean: -18.922529860489504, timestamp: 2022-08-20 02:38:57.453932\n",
      "resetting env. episode 6700, reward total was -15.0. running mean: -18.883304561884607, timestamp: 2022-08-20 02:39:04.176359\n",
      "resetting env. episode 6701, reward total was -21.0. running mean: -18.90447151626576, timestamp: 2022-08-20 02:39:09.447315\n",
      "resetting env. episode 6702, reward total was -21.0. running mean: -18.925426801103104, timestamp: 2022-08-20 02:39:13.507973\n",
      "resetting env. episode 6703, reward total was -18.0. running mean: -18.916172533092073, timestamp: 2022-08-20 02:39:18.428376\n",
      "resetting env. episode 6704, reward total was -17.0. running mean: -18.897010807761156, timestamp: 2022-08-20 02:39:23.299137\n",
      "resetting env. episode 6705, reward total was -20.0. running mean: -18.908040699683543, timestamp: 2022-08-20 02:39:27.094412\n",
      "resetting env. episode 6706, reward total was -20.0. running mean: -18.918960292686705, timestamp: 2022-08-20 02:39:30.836363\n",
      "resetting env. episode 6707, reward total was -18.0. running mean: -18.90977068975984, timestamp: 2022-08-20 02:39:35.839915\n",
      "resetting env. episode 6708, reward total was -21.0. running mean: -18.93067298286224, timestamp: 2022-08-20 02:39:41.883460\n",
      "resetting env. episode 6709, reward total was -18.0. running mean: -18.921366253033618, timestamp: 2022-08-20 02:39:47.748997\n",
      "resetting env. episode 6710, reward total was -19.0. running mean: -18.922152590503284, timestamp: 2022-08-20 02:39:52.968008\n",
      "resetting env. episode 6711, reward total was -21.0. running mean: -18.942931064598252, timestamp: 2022-08-20 02:39:57.391646\n",
      "resetting env. episode 6712, reward total was -17.0. running mean: -18.92350175395227, timestamp: 2022-08-20 02:40:02.820333\n",
      "resetting env. episode 6713, reward total was -16.0. running mean: -18.894266736412746, timestamp: 2022-08-20 02:40:07.135022\n",
      "resetting env. episode 6714, reward total was -18.0. running mean: -18.885324069048618, timestamp: 2022-08-20 02:40:11.974472\n",
      "resetting env. episode 6715, reward total was -19.0. running mean: -18.88647082835813, timestamp: 2022-08-20 02:40:16.475825\n",
      "resetting env. episode 6716, reward total was -19.0. running mean: -18.88760612007455, timestamp: 2022-08-20 02:40:20.726280\n",
      "resetting env. episode 6717, reward total was -15.0. running mean: -18.848730058873805, timestamp: 2022-08-20 02:40:27.977896\n",
      "resetting env. episode 6718, reward total was -17.0. running mean: -18.830242758285067, timestamp: 2022-08-20 02:40:33.788250\n",
      "resetting env. episode 6719, reward total was -18.0. running mean: -18.821940330702216, timestamp: 2022-08-20 02:40:39.261400\n",
      "resetting env. episode 6720, reward total was -19.0. running mean: -18.823720927395193, timestamp: 2022-08-20 02:40:44.652369\n",
      "resetting env. episode 6721, reward total was -19.0. running mean: -18.82548371812124, timestamp: 2022-08-20 02:40:49.715674\n",
      "resetting env. episode 6722, reward total was -18.0. running mean: -18.81722888094003, timestamp: 2022-08-20 02:40:56.014816\n",
      "resetting env. episode 6723, reward total was -19.0. running mean: -18.81905659213063, timestamp: 2022-08-20 02:41:00.779319\n",
      "resetting env. episode 6724, reward total was -21.0. running mean: -18.840866026209323, timestamp: 2022-08-20 02:41:05.154405\n",
      "resetting env. episode 6725, reward total was -19.0. running mean: -18.84245736594723, timestamp: 2022-08-20 02:41:08.785642\n",
      "resetting env. episode 6726, reward total was -19.0. running mean: -18.84403279228776, timestamp: 2022-08-20 02:41:14.246931\n",
      "resetting env. episode 6727, reward total was -17.0. running mean: -18.825592464364885, timestamp: 2022-08-20 02:41:19.987333\n",
      "resetting env. episode 6728, reward total was -16.0. running mean: -18.797336539721236, timestamp: 2022-08-20 02:41:27.332574\n",
      "resetting env. episode 6729, reward total was -17.0. running mean: -18.779363174324025, timestamp: 2022-08-20 02:41:35.956519\n",
      "resetting env. episode 6730, reward total was -18.0. running mean: -18.771569542580785, timestamp: 2022-08-20 02:41:45.010320\n",
      "resetting env. episode 6731, reward total was -21.0. running mean: -18.793853847154978, timestamp: 2022-08-20 02:41:52.277893\n",
      "resetting env. episode 6732, reward total was -21.0. running mean: -18.81591530868343, timestamp: 2022-08-20 02:42:02.679093\n",
      "resetting env. episode 6733, reward total was -20.0. running mean: -18.827756155596596, timestamp: 2022-08-20 02:42:12.013142\n",
      "resetting env. episode 6734, reward total was -17.0. running mean: -18.80947859404063, timestamp: 2022-08-20 02:42:20.651463\n",
      "resetting env. episode 6735, reward total was -21.0. running mean: -18.831383808100224, timestamp: 2022-08-20 02:42:26.987527\n",
      "resetting env. episode 6736, reward total was -18.0. running mean: -18.823069970019223, timestamp: 2022-08-20 02:42:34.496054\n",
      "resetting env. episode 6737, reward total was -19.0. running mean: -18.824839270319032, timestamp: 2022-08-20 02:42:40.129957\n",
      "resetting env. episode 6738, reward total was -17.0. running mean: -18.806590877615843, timestamp: 2022-08-20 02:42:47.058436\n",
      "resetting env. episode 6739, reward total was -21.0. running mean: -18.828524968839684, timestamp: 2022-08-20 02:42:54.748884\n",
      "resetting env. episode 6740, reward total was -19.0. running mean: -18.830239719151287, timestamp: 2022-08-20 02:43:01.655424\n",
      "resetting env. episode 6741, reward total was -20.0. running mean: -18.841937321959772, timestamp: 2022-08-20 02:43:08.722534\n",
      "resetting env. episode 6742, reward total was -20.0. running mean: -18.853517948740173, timestamp: 2022-08-20 02:43:14.102397\n",
      "resetting env. episode 6743, reward total was -21.0. running mean: -18.87498276925277, timestamp: 2022-08-20 02:43:19.429900\n",
      "resetting env. episode 6744, reward total was -17.0. running mean: -18.856232941560243, timestamp: 2022-08-20 02:43:25.272321\n",
      "resetting env. episode 6745, reward total was -20.0. running mean: -18.86767061214464, timestamp: 2022-08-20 02:43:30.142463\n",
      "resetting env. episode 6746, reward total was -21.0. running mean: -18.888993906023195, timestamp: 2022-08-20 02:43:35.944211\n",
      "resetting env. episode 6747, reward total was -20.0. running mean: -18.900103966962963, timestamp: 2022-08-20 02:43:42.638125\n",
      "resetting env. episode 6748, reward total was -21.0. running mean: -18.921102927293333, timestamp: 2022-08-20 02:43:47.148013\n",
      "resetting env. episode 6749, reward total was -18.0. running mean: -18.9118918980204, timestamp: 2022-08-20 02:43:52.764997\n",
      "resetting env. episode 6750, reward total was -21.0. running mean: -18.932772979040198, timestamp: 2022-08-20 02:43:57.143808\n",
      "resetting env. episode 6751, reward total was -20.0. running mean: -18.943445249249795, timestamp: 2022-08-20 02:44:03.515628\n",
      "resetting env. episode 6752, reward total was -19.0. running mean: -18.944010796757297, timestamp: 2022-08-20 02:44:08.135446\n",
      "resetting env. episode 6753, reward total was -19.0. running mean: -18.944570688789724, timestamp: 2022-08-20 02:44:13.267821\n",
      "resetting env. episode 6754, reward total was -21.0. running mean: -18.965124981901827, timestamp: 2022-08-20 02:44:16.981978\n",
      "resetting env. episode 6755, reward total was -19.0. running mean: -18.96547373208281, timestamp: 2022-08-20 02:44:21.696498\n",
      "resetting env. episode 6756, reward total was -19.0. running mean: -18.96581899476198, timestamp: 2022-08-20 02:44:26.980706\n",
      "resetting env. episode 6757, reward total was -18.0. running mean: -18.95616080481436, timestamp: 2022-08-20 02:44:32.166693\n",
      "resetting env. episode 6758, reward total was -18.0. running mean: -18.946599196766215, timestamp: 2022-08-20 02:44:37.559393\n",
      "resetting env. episode 6759, reward total was -18.0. running mean: -18.937133204798553, timestamp: 2022-08-20 02:44:41.728732\n",
      "resetting env. episode 6760, reward total was -19.0. running mean: -18.937761872750567, timestamp: 2022-08-20 02:44:46.949200\n",
      "resetting env. episode 6761, reward total was -21.0. running mean: -18.958384254023063, timestamp: 2022-08-20 02:44:52.261825\n",
      "resetting env. episode 6762, reward total was -18.0. running mean: -18.948800411482832, timestamp: 2022-08-20 02:44:58.167984\n",
      "resetting env. episode 6763, reward total was -20.0. running mean: -18.959312407368003, timestamp: 2022-08-20 02:45:04.453889\n",
      "resetting env. episode 6764, reward total was -19.0. running mean: -18.959719283294323, timestamp: 2022-08-20 02:45:09.100491\n",
      "resetting env. episode 6765, reward total was -19.0. running mean: -18.960122090461383, timestamp: 2022-08-20 02:45:14.493869\n",
      "resetting env. episode 6766, reward total was -19.0. running mean: -18.96052086955677, timestamp: 2022-08-20 02:45:19.435990\n",
      "resetting env. episode 6767, reward total was -21.0. running mean: -18.980915660861204, timestamp: 2022-08-20 02:45:23.857268\n",
      "resetting env. episode 6768, reward total was -16.0. running mean: -18.951106504252593, timestamp: 2022-08-20 02:45:29.401768\n",
      "resetting env. episode 6769, reward total was -21.0. running mean: -18.971595439210066, timestamp: 2022-08-20 02:45:33.033062\n",
      "resetting env. episode 6770, reward total was -17.0. running mean: -18.95187948481797, timestamp: 2022-08-20 02:45:38.885829\n",
      "resetting env. episode 6771, reward total was -21.0. running mean: -18.97236068996979, timestamp: 2022-08-20 02:45:43.951535\n",
      "resetting env. episode 6772, reward total was -13.0. running mean: -18.91263708307009, timestamp: 2022-08-20 02:45:50.317136\n",
      "resetting env. episode 6773, reward total was -17.0. running mean: -18.893510712239394, timestamp: 2022-08-20 02:45:55.925250\n",
      "resetting env. episode 6774, reward total was -19.0. running mean: -18.894575605117, timestamp: 2022-08-20 02:46:00.823358\n",
      "resetting env. episode 6775, reward total was -19.0. running mean: -18.895629849065834, timestamp: 2022-08-20 02:46:05.062853\n",
      "resetting env. episode 6776, reward total was -19.0. running mean: -18.896673550575176, timestamp: 2022-08-20 02:46:09.997886\n",
      "resetting env. episode 6777, reward total was -15.0. running mean: -18.857706815069424, timestamp: 2022-08-20 02:46:17.691212\n",
      "resetting env. episode 6778, reward total was -21.0. running mean: -18.879129746918732, timestamp: 2022-08-20 02:46:21.817919\n",
      "resetting env. episode 6779, reward total was -20.0. running mean: -18.890338449449544, timestamp: 2022-08-20 02:46:25.319558\n",
      "resetting env. episode 6780, reward total was -19.0. running mean: -18.89143506495505, timestamp: 2022-08-20 02:46:30.920683\n",
      "resetting env. episode 6781, reward total was -18.0. running mean: -18.8825207143055, timestamp: 2022-08-20 02:46:35.162537\n",
      "resetting env. episode 6782, reward total was -19.0. running mean: -18.883695507162447, timestamp: 2022-08-20 02:46:39.649509\n",
      "resetting env. episode 6783, reward total was -20.0. running mean: -18.89485855209082, timestamp: 2022-08-20 02:46:44.309579\n",
      "resetting env. episode 6784, reward total was -18.0. running mean: -18.885909966569912, timestamp: 2022-08-20 02:46:48.535584\n",
      "resetting env. episode 6785, reward total was -20.0. running mean: -18.897050866904213, timestamp: 2022-08-20 02:46:53.316645\n",
      "resetting env. episode 6786, reward total was -19.0. running mean: -18.898080358235173, timestamp: 2022-08-20 02:46:58.477164\n",
      "resetting env. episode 6787, reward total was -21.0. running mean: -18.91909955465282, timestamp: 2022-08-20 02:47:02.948015\n",
      "resetting env. episode 6788, reward total was -21.0. running mean: -18.939908559106293, timestamp: 2022-08-20 02:47:07.731980\n",
      "resetting env. episode 6789, reward total was -18.0. running mean: -18.93050947351523, timestamp: 2022-08-20 02:47:13.019303\n",
      "resetting env. episode 6790, reward total was -17.0. running mean: -18.911204378780077, timestamp: 2022-08-20 02:47:19.254335\n",
      "resetting env. episode 6791, reward total was -18.0. running mean: -18.902092334992275, timestamp: 2022-08-20 02:47:24.941964\n",
      "resetting env. episode 6792, reward total was -19.0. running mean: -18.903071411642355, timestamp: 2022-08-20 02:47:29.905649\n",
      "resetting env. episode 6793, reward total was -21.0. running mean: -18.924040697525932, timestamp: 2022-08-20 02:47:34.254990\n",
      "resetting env. episode 6794, reward total was -21.0. running mean: -18.944800290550674, timestamp: 2022-08-20 02:47:38.425264\n",
      "resetting env. episode 6795, reward total was -17.0. running mean: -18.92535228764517, timestamp: 2022-08-20 02:47:43.839806\n",
      "resetting env. episode 6796, reward total was -15.0. running mean: -18.886098764768715, timestamp: 2022-08-20 02:47:50.188973\n",
      "resetting env. episode 6797, reward total was -20.0. running mean: -18.897237777121028, timestamp: 2022-08-20 02:47:54.611965\n",
      "resetting env. episode 6798, reward total was -20.0. running mean: -18.908265399349816, timestamp: 2022-08-20 02:47:59.719792\n",
      "resetting env. episode 6799, reward total was -15.0. running mean: -18.869182745356316, timestamp: 2022-08-20 02:48:07.415016\n",
      "resetting env. episode 6800, reward total was -19.0. running mean: -18.870490917902753, timestamp: 2022-08-20 02:48:13.247420\n",
      "resetting env. episode 6801, reward total was -19.0. running mean: -18.871786008723728, timestamp: 2022-08-20 02:48:18.465257\n",
      "resetting env. episode 6802, reward total was -19.0. running mean: -18.87306814863649, timestamp: 2022-08-20 02:48:23.336026\n",
      "resetting env. episode 6803, reward total was -21.0. running mean: -18.894337467150127, timestamp: 2022-08-20 02:48:27.594293\n",
      "resetting env. episode 6804, reward total was -14.0. running mean: -18.845394092478625, timestamp: 2022-08-20 02:48:32.816278\n",
      "resetting env. episode 6805, reward total was -18.0. running mean: -18.836940151553836, timestamp: 2022-08-20 02:48:38.582690\n",
      "resetting env. episode 6806, reward total was -19.0. running mean: -18.8385707500383, timestamp: 2022-08-20 02:48:43.158738\n",
      "resetting env. episode 6807, reward total was -21.0. running mean: -18.860185042537918, timestamp: 2022-08-20 02:48:46.854055\n",
      "resetting env. episode 6808, reward total was -20.0. running mean: -18.87158319211254, timestamp: 2022-08-20 02:48:52.624473\n",
      "resetting env. episode 6809, reward total was -21.0. running mean: -18.892867360191413, timestamp: 2022-08-20 02:48:56.895370\n",
      "resetting env. episode 6810, reward total was -21.0. running mean: -18.9139386865895, timestamp: 2022-08-20 02:49:02.380143\n",
      "resetting env. episode 6811, reward total was -20.0. running mean: -18.924799299723603, timestamp: 2022-08-20 02:49:07.349485\n",
      "resetting env. episode 6812, reward total was -16.0. running mean: -18.895551306726368, timestamp: 2022-08-20 02:49:12.638449\n",
      "resetting env. episode 6813, reward total was -18.0. running mean: -18.886595793659104, timestamp: 2022-08-20 02:49:17.509379\n",
      "resetting env. episode 6814, reward total was -18.0. running mean: -18.877729835722512, timestamp: 2022-08-20 02:49:21.416143\n",
      "resetting env. episode 6815, reward total was -20.0. running mean: -18.888952537365284, timestamp: 2022-08-20 02:49:26.401834\n",
      "resetting env. episode 6816, reward total was -20.0. running mean: -18.90006301199163, timestamp: 2022-08-20 02:49:31.211933\n",
      "resetting env. episode 6817, reward total was -15.0. running mean: -18.86106238187171, timestamp: 2022-08-20 02:49:36.505330\n",
      "resetting env. episode 6818, reward total was -20.0. running mean: -18.872451758052993, timestamp: 2022-08-20 02:49:42.077895\n",
      "resetting env. episode 6819, reward total was -17.0. running mean: -18.853727240472466, timestamp: 2022-08-20 02:49:48.143960\n",
      "resetting env. episode 6820, reward total was -19.0. running mean: -18.85518996806774, timestamp: 2022-08-20 02:49:53.651367\n",
      "resetting env. episode 6821, reward total was -21.0. running mean: -18.876638068387063, timestamp: 2022-08-20 02:49:58.595763\n",
      "resetting env. episode 6822, reward total was -19.0. running mean: -18.877871687703195, timestamp: 2022-08-20 02:50:04.226012\n",
      "resetting env. episode 6823, reward total was -15.0. running mean: -18.83909297082616, timestamp: 2022-08-20 02:50:09.604910\n",
      "resetting env. episode 6824, reward total was -18.0. running mean: -18.8307020411179, timestamp: 2022-08-20 02:50:15.108338\n",
      "resetting env. episode 6825, reward total was -19.0. running mean: -18.83239502070672, timestamp: 2022-08-20 02:50:20.470399\n",
      "resetting env. episode 6826, reward total was -20.0. running mean: -18.844071070499652, timestamp: 2022-08-20 02:50:25.598708\n",
      "resetting env. episode 6827, reward total was -15.0. running mean: -18.805630359794655, timestamp: 2022-08-20 02:50:32.148516\n",
      "resetting env. episode 6828, reward total was -19.0. running mean: -18.80757405619671, timestamp: 2022-08-20 02:50:37.546132\n",
      "resetting env. episode 6829, reward total was -16.0. running mean: -18.779498315634743, timestamp: 2022-08-20 02:50:43.449693\n",
      "resetting env. episode 6830, reward total was -19.0. running mean: -18.781703332478397, timestamp: 2022-08-20 02:50:49.187764\n",
      "resetting env. episode 6831, reward total was -19.0. running mean: -18.783886299153615, timestamp: 2022-08-20 02:50:54.311585\n",
      "resetting env. episode 6832, reward total was -19.0. running mean: -18.78604743616208, timestamp: 2022-08-20 02:50:58.119308\n",
      "resetting env. episode 6833, reward total was -19.0. running mean: -18.78818696180046, timestamp: 2022-08-20 02:51:02.855022\n",
      "resetting env. episode 6834, reward total was -20.0. running mean: -18.800305092182455, timestamp: 2022-08-20 02:51:08.061531\n",
      "resetting env. episode 6835, reward total was -19.0. running mean: -18.80230204126063, timestamp: 2022-08-20 02:51:12.735053\n",
      "resetting env. episode 6836, reward total was -19.0. running mean: -18.804279020848025, timestamp: 2022-08-20 02:51:18.356296\n",
      "resetting env. episode 6837, reward total was -19.0. running mean: -18.806236230639545, timestamp: 2022-08-20 02:51:23.746512\n",
      "resetting env. episode 6838, reward total was -17.0. running mean: -18.78817386833315, timestamp: 2022-08-20 02:51:29.245551\n",
      "resetting env. episode 6839, reward total was -19.0. running mean: -18.79029212964982, timestamp: 2022-08-20 02:51:34.698883\n",
      "resetting env. episode 6840, reward total was -17.0. running mean: -18.772389208353324, timestamp: 2022-08-20 02:51:40.206465\n",
      "resetting env. episode 6841, reward total was -18.0. running mean: -18.76466531626979, timestamp: 2022-08-20 02:51:46.694615\n",
      "resetting env. episode 6842, reward total was -17.0. running mean: -18.747018663107095, timestamp: 2022-08-20 02:51:53.009738\n",
      "resetting env. episode 6843, reward total was -18.0. running mean: -18.739548476476024, timestamp: 2022-08-20 02:52:00.531688\n",
      "resetting env. episode 6844, reward total was -17.0. running mean: -18.722152991711265, timestamp: 2022-08-20 02:52:06.666518\n",
      "resetting env. episode 6845, reward total was -15.0. running mean: -18.68493146179415, timestamp: 2022-08-20 02:52:13.898609\n",
      "resetting env. episode 6846, reward total was -15.0. running mean: -18.648082147176208, timestamp: 2022-08-20 02:52:20.092086\n",
      "resetting env. episode 6847, reward total was -17.0. running mean: -18.631601325704448, timestamp: 2022-08-20 02:52:26.238615\n",
      "resetting env. episode 6848, reward total was -20.0. running mean: -18.645285312447403, timestamp: 2022-08-20 02:52:31.732176\n",
      "resetting env. episode 6849, reward total was -17.0. running mean: -18.62883245932293, timestamp: 2022-08-20 02:52:38.158500\n",
      "resetting env. episode 6850, reward total was -20.0. running mean: -18.6425441347297, timestamp: 2022-08-20 02:52:44.273156\n",
      "resetting env. episode 6851, reward total was -21.0. running mean: -18.666118693382405, timestamp: 2022-08-20 02:52:52.346576\n",
      "resetting env. episode 6852, reward total was -21.0. running mean: -18.68945750644858, timestamp: 2022-08-20 02:52:57.746172\n",
      "resetting env. episode 6853, reward total was -21.0. running mean: -18.712562931384095, timestamp: 2022-08-20 02:53:03.081880\n",
      "resetting env. episode 6854, reward total was -17.0. running mean: -18.695437302070257, timestamp: 2022-08-20 02:53:11.246082\n",
      "resetting env. episode 6855, reward total was -16.0. running mean: -18.668482929049553, timestamp: 2022-08-20 02:53:18.833333\n",
      "resetting env. episode 6856, reward total was -19.0. running mean: -18.67179809975906, timestamp: 2022-08-20 02:53:24.730504\n",
      "resetting env. episode 6857, reward total was -19.0. running mean: -18.675080118761468, timestamp: 2022-08-20 02:53:30.482310\n",
      "resetting env. episode 6858, reward total was -21.0. running mean: -18.698329317573855, timestamp: 2022-08-20 02:53:36.833359\n",
      "resetting env. episode 6859, reward total was -21.0. running mean: -18.721346024398116, timestamp: 2022-08-20 02:53:42.612921\n",
      "resetting env. episode 6860, reward total was -15.0. running mean: -18.684132564154133, timestamp: 2022-08-20 02:53:50.761102\n",
      "resetting env. episode 6861, reward total was -18.0. running mean: -18.67729123851259, timestamp: 2022-08-20 02:53:56.658426\n",
      "resetting env. episode 6862, reward total was -19.0. running mean: -18.680518326127466, timestamp: 2022-08-20 02:54:04.111507\n",
      "resetting env. episode 6863, reward total was -18.0. running mean: -18.67371314286619, timestamp: 2022-08-20 02:54:09.718742\n",
      "resetting env. episode 6864, reward total was -15.0. running mean: -18.63697601143753, timestamp: 2022-08-20 02:54:18.805452\n",
      "resetting env. episode 6865, reward total was -19.0. running mean: -18.640606251323156, timestamp: 2022-08-20 02:54:25.706033\n",
      "resetting env. episode 6866, reward total was -18.0. running mean: -18.634200188809924, timestamp: 2022-08-20 02:54:31.247194\n",
      "resetting env. episode 6867, reward total was -20.0. running mean: -18.647858186921823, timestamp: 2022-08-20 02:54:37.870494\n",
      "resetting env. episode 6868, reward total was -19.0. running mean: -18.651379605052608, timestamp: 2022-08-20 02:54:44.764793\n",
      "resetting env. episode 6869, reward total was -21.0. running mean: -18.674865809002082, timestamp: 2022-08-20 02:54:50.388772\n",
      "resetting env. episode 6870, reward total was -19.0. running mean: -18.678117150912062, timestamp: 2022-08-20 02:54:56.688008\n",
      "resetting env. episode 6871, reward total was -19.0. running mean: -18.68133597940294, timestamp: 2022-08-20 02:55:03.761297\n",
      "resetting env. episode 6872, reward total was -17.0. running mean: -18.664522619608913, timestamp: 2022-08-20 02:55:10.907230\n",
      "resetting env. episode 6873, reward total was -17.0. running mean: -18.647877393412827, timestamp: 2022-08-20 02:55:16.501270\n",
      "resetting env. episode 6874, reward total was -17.0. running mean: -18.631398619478702, timestamp: 2022-08-20 02:55:23.990249\n",
      "resetting env. episode 6875, reward total was -18.0. running mean: -18.625084633283915, timestamp: 2022-08-20 02:55:30.173723\n",
      "resetting env. episode 6876, reward total was -20.0. running mean: -18.638833786951075, timestamp: 2022-08-20 02:55:35.798890\n",
      "resetting env. episode 6877, reward total was -17.0. running mean: -18.622445449081567, timestamp: 2022-08-20 02:55:41.021930\n",
      "resetting env. episode 6878, reward total was -21.0. running mean: -18.646220994590752, timestamp: 2022-08-20 02:55:47.193952\n",
      "resetting env. episode 6879, reward total was -17.0. running mean: -18.629758784644846, timestamp: 2022-08-20 02:55:52.991480\n",
      "resetting env. episode 6880, reward total was -17.0. running mean: -18.613461196798397, timestamp: 2022-08-20 02:56:03.677887\n",
      "resetting env. episode 6881, reward total was -18.0. running mean: -18.607326584830414, timestamp: 2022-08-20 02:56:15.463755\n",
      "resetting env. episode 6882, reward total was -21.0. running mean: -18.63125331898211, timestamp: 2022-08-20 02:56:23.254887\n",
      "resetting env. episode 6883, reward total was -17.0. running mean: -18.614940785792292, timestamp: 2022-08-20 02:56:34.206611\n",
      "resetting env. episode 6884, reward total was -17.0. running mean: -18.598791377934372, timestamp: 2022-08-20 02:56:43.396082\n",
      "resetting env. episode 6885, reward total was -20.0. running mean: -18.61280346415503, timestamp: 2022-08-20 02:56:49.021013\n",
      "resetting env. episode 6886, reward total was -16.0. running mean: -18.586675429513477, timestamp: 2022-08-20 02:56:57.677874\n",
      "resetting env. episode 6887, reward total was -19.0. running mean: -18.590808675218344, timestamp: 2022-08-20 02:57:04.824770\n",
      "resetting env. episode 6888, reward total was -17.0. running mean: -18.574900588466164, timestamp: 2022-08-20 02:57:11.700398\n",
      "resetting env. episode 6889, reward total was -21.0. running mean: -18.599151582581502, timestamp: 2022-08-20 02:57:18.541106\n",
      "resetting env. episode 6890, reward total was -18.0. running mean: -18.593160066755686, timestamp: 2022-08-20 02:57:24.563008\n",
      "resetting env. episode 6891, reward total was -19.0. running mean: -18.59722846608813, timestamp: 2022-08-20 02:57:32.126790\n",
      "resetting env. episode 6892, reward total was -19.0. running mean: -18.60125618142725, timestamp: 2022-08-20 02:57:37.380484\n",
      "resetting env. episode 6893, reward total was -17.0. running mean: -18.585243619612978, timestamp: 2022-08-20 02:57:43.047407\n",
      "resetting env. episode 6894, reward total was -19.0. running mean: -18.58939118341685, timestamp: 2022-08-20 02:57:49.081266\n",
      "resetting env. episode 6895, reward total was -16.0. running mean: -18.563497271582683, timestamp: 2022-08-20 02:57:55.757423\n",
      "resetting env. episode 6896, reward total was -19.0. running mean: -18.567862298866856, timestamp: 2022-08-20 02:58:02.127719\n",
      "resetting env. episode 6897, reward total was -20.0. running mean: -18.582183675878188, timestamp: 2022-08-20 02:58:07.854413\n",
      "resetting env. episode 6898, reward total was -19.0. running mean: -18.58636183911941, timestamp: 2022-08-20 02:58:15.795420\n",
      "resetting env. episode 6899, reward total was -20.0. running mean: -18.600498220728213, timestamp: 2022-08-20 02:58:21.386487\n",
      "resetting env. episode 6900, reward total was -19.0. running mean: -18.60449323852093, timestamp: 2022-08-20 02:58:28.826588\n",
      "resetting env. episode 6901, reward total was -20.0. running mean: -18.618448306135722, timestamp: 2022-08-20 02:58:33.917977\n",
      "resetting env. episode 6902, reward total was -18.0. running mean: -18.612263823074365, timestamp: 2022-08-20 02:58:41.188579\n",
      "resetting env. episode 6903, reward total was -18.0. running mean: -18.606141184843622, timestamp: 2022-08-20 02:58:47.412725\n",
      "resetting env. episode 6904, reward total was -19.0. running mean: -18.61007977299519, timestamp: 2022-08-20 02:58:53.650025\n",
      "resetting env. episode 6905, reward total was -19.0. running mean: -18.613978975265237, timestamp: 2022-08-20 02:58:59.302963\n",
      "resetting env. episode 6906, reward total was -15.0. running mean: -18.577839185512584, timestamp: 2022-08-20 02:59:06.490742\n",
      "resetting env. episode 6907, reward total was -20.0. running mean: -18.592060793657456, timestamp: 2022-08-20 02:59:12.053977\n",
      "resetting env. episode 6908, reward total was -20.0. running mean: -18.606140185720882, timestamp: 2022-08-20 02:59:17.523082\n",
      "resetting env. episode 6909, reward total was -19.0. running mean: -18.610078783863674, timestamp: 2022-08-20 02:59:23.508701\n",
      "resetting env. episode 6910, reward total was -21.0. running mean: -18.63397799602504, timestamp: 2022-08-20 02:59:29.645036\n",
      "resetting env. episode 6911, reward total was -21.0. running mean: -18.65763821606479, timestamp: 2022-08-20 02:59:37.136982\n",
      "resetting env. episode 6912, reward total was -20.0. running mean: -18.67106183390414, timestamp: 2022-08-20 02:59:43.811139\n",
      "resetting env. episode 6913, reward total was -19.0. running mean: -18.6743512155651, timestamp: 2022-08-20 02:59:49.882029\n",
      "resetting env. episode 6914, reward total was -19.0. running mean: -18.67760770340945, timestamp: 2022-08-20 02:59:56.542809\n",
      "resetting env. episode 6915, reward total was -17.0. running mean: -18.66083162637536, timestamp: 2022-08-20 03:00:03.287249\n",
      "resetting env. episode 6916, reward total was -20.0. running mean: -18.674223310111604, timestamp: 2022-08-20 03:00:08.323197\n",
      "resetting env. episode 6917, reward total was -17.0. running mean: -18.657481077010488, timestamp: 2022-08-20 03:00:14.983318\n",
      "resetting env. episode 6918, reward total was -16.0. running mean: -18.630906266240384, timestamp: 2022-08-20 03:00:21.579682\n",
      "resetting env. episode 6919, reward total was -20.0. running mean: -18.64459720357798, timestamp: 2022-08-20 03:00:27.732249\n",
      "resetting env. episode 6920, reward total was -17.0. running mean: -18.6281512315422, timestamp: 2022-08-20 03:00:33.627493\n",
      "resetting env. episode 6921, reward total was -21.0. running mean: -18.65186971922678, timestamp: 2022-08-20 03:00:40.057538\n",
      "resetting env. episode 6922, reward total was -21.0. running mean: -18.675351022034512, timestamp: 2022-08-20 03:00:45.632953\n",
      "resetting env. episode 6923, reward total was -19.0. running mean: -18.678597511814168, timestamp: 2022-08-20 03:00:51.629247\n",
      "resetting env. episode 6924, reward total was -16.0. running mean: -18.651811536696027, timestamp: 2022-08-20 03:00:59.908151\n",
      "resetting env. episode 6925, reward total was -19.0. running mean: -18.655293421329066, timestamp: 2022-08-20 03:01:07.337259\n",
      "resetting env. episode 6926, reward total was -19.0. running mean: -18.658740487115775, timestamp: 2022-08-20 03:01:13.608502\n",
      "resetting env. episode 6927, reward total was -20.0. running mean: -18.672153082244616, timestamp: 2022-08-20 03:01:19.044991\n",
      "resetting env. episode 6928, reward total was -21.0. running mean: -18.69543155142217, timestamp: 2022-08-20 03:01:24.328244\n",
      "resetting env. episode 6929, reward total was -21.0. running mean: -18.71847723590795, timestamp: 2022-08-20 03:01:30.193563\n",
      "resetting env. episode 6930, reward total was -19.0. running mean: -18.721292463548874, timestamp: 2022-08-20 03:01:36.457452\n",
      "resetting env. episode 6931, reward total was -19.0. running mean: -18.724079538913387, timestamp: 2022-08-20 03:01:43.768025\n",
      "resetting env. episode 6932, reward total was -20.0. running mean: -18.736838743524252, timestamp: 2022-08-20 03:01:49.620384\n",
      "resetting env. episode 6933, reward total was -18.0. running mean: -18.72947035608901, timestamp: 2022-08-20 03:01:56.262869\n",
      "resetting env. episode 6934, reward total was -17.0. running mean: -18.71217565252812, timestamp: 2022-08-20 03:02:03.156945\n",
      "resetting env. episode 6935, reward total was -19.0. running mean: -18.71505389600284, timestamp: 2022-08-20 03:02:09.126981\n",
      "resetting env. episode 6936, reward total was -18.0. running mean: -18.70790335704281, timestamp: 2022-08-20 03:02:15.536875\n",
      "resetting env. episode 6937, reward total was -20.0. running mean: -18.72082432347238, timestamp: 2022-08-20 03:02:23.602274\n",
      "resetting env. episode 6938, reward total was -19.0. running mean: -18.723616080237658, timestamp: 2022-08-20 03:02:30.460274\n",
      "resetting env. episode 6939, reward total was -18.0. running mean: -18.71637991943528, timestamp: 2022-08-20 03:02:36.617980\n",
      "resetting env. episode 6940, reward total was -21.0. running mean: -18.73921612024093, timestamp: 2022-08-20 03:02:43.020899\n",
      "resetting env. episode 6941, reward total was -19.0. running mean: -18.74182395903852, timestamp: 2022-08-20 03:02:48.277742\n",
      "resetting env. episode 6942, reward total was -18.0. running mean: -18.734405719448134, timestamp: 2022-08-20 03:02:55.111481\n",
      "resetting env. episode 6943, reward total was -19.0. running mean: -18.737061662253655, timestamp: 2022-08-20 03:03:00.912964\n",
      "resetting env. episode 6944, reward total was -21.0. running mean: -18.75969104563112, timestamp: 2022-08-20 03:03:05.852758\n",
      "resetting env. episode 6945, reward total was -20.0. running mean: -18.772094135174807, timestamp: 2022-08-20 03:03:10.711769\n",
      "resetting env. episode 6946, reward total was -17.0. running mean: -18.75437319382306, timestamp: 2022-08-20 03:03:17.755960\n",
      "resetting env. episode 6947, reward total was -20.0. running mean: -18.76682946188483, timestamp: 2022-08-20 03:03:24.154848\n",
      "resetting env. episode 6948, reward total was -17.0. running mean: -18.74916116726598, timestamp: 2022-08-20 03:03:29.805730\n",
      "resetting env. episode 6949, reward total was -20.0. running mean: -18.761669555593322, timestamp: 2022-08-20 03:03:36.285715\n",
      "resetting env. episode 6950, reward total was -20.0. running mean: -18.774052860037386, timestamp: 2022-08-20 03:03:42.009414\n",
      "resetting env. episode 6951, reward total was -19.0. running mean: -18.776312331437012, timestamp: 2022-08-20 03:03:49.328853\n",
      "resetting env. episode 6952, reward total was -19.0. running mean: -18.778549208122644, timestamp: 2022-08-20 03:03:55.307838\n",
      "resetting env. episode 6953, reward total was -17.0. running mean: -18.76076371604142, timestamp: 2022-08-20 03:04:01.718681\n",
      "resetting env. episode 6954, reward total was -17.0. running mean: -18.743156078881007, timestamp: 2022-08-20 03:04:07.124239\n",
      "resetting env. episode 6955, reward total was -16.0. running mean: -18.7157245180922, timestamp: 2022-08-20 03:04:13.376516\n",
      "resetting env. episode 6956, reward total was -11.0. running mean: -18.638567272911274, timestamp: 2022-08-20 03:04:21.920676\n",
      "resetting env. episode 6957, reward total was -20.0. running mean: -18.65218160018216, timestamp: 2022-08-20 03:04:27.004101\n",
      "resetting env. episode 6958, reward total was -17.0. running mean: -18.63565978418034, timestamp: 2022-08-20 03:04:35.164530\n",
      "resetting env. episode 6959, reward total was -20.0. running mean: -18.649303186338535, timestamp: 2022-08-20 03:04:40.302889\n",
      "resetting env. episode 6960, reward total was -20.0. running mean: -18.66281015447515, timestamp: 2022-08-20 03:04:45.499003\n",
      "resetting env. episode 6961, reward total was -17.0. running mean: -18.6461820529304, timestamp: 2022-08-20 03:04:52.439647\n",
      "resetting env. episode 6962, reward total was -19.0. running mean: -18.649720232401098, timestamp: 2022-08-20 03:04:57.709551\n",
      "resetting env. episode 6963, reward total was -19.0. running mean: -18.653223030077086, timestamp: 2022-08-20 03:05:04.791835\n",
      "resetting env. episode 6964, reward total was -20.0. running mean: -18.666690799776315, timestamp: 2022-08-20 03:05:10.542434\n",
      "resetting env. episode 6965, reward total was -19.0. running mean: -18.670023891778552, timestamp: 2022-08-20 03:05:18.204157\n",
      "resetting env. episode 6966, reward total was -21.0. running mean: -18.693323652860766, timestamp: 2022-08-20 03:05:24.623995\n",
      "resetting env. episode 6967, reward total was -19.0. running mean: -18.69639041633216, timestamp: 2022-08-20 03:05:29.966722\n",
      "resetting env. episode 6968, reward total was -20.0. running mean: -18.70942651216884, timestamp: 2022-08-20 03:05:36.207058\n",
      "resetting env. episode 6969, reward total was -17.0. running mean: -18.69233224704715, timestamp: 2022-08-20 03:05:44.242330\n",
      "resetting env. episode 6970, reward total was -21.0. running mean: -18.715408924576682, timestamp: 2022-08-20 03:05:50.367748\n",
      "resetting env. episode 6971, reward total was -19.0. running mean: -18.718254835330917, timestamp: 2022-08-20 03:05:55.381327\n",
      "resetting env. episode 6972, reward total was -19.0. running mean: -18.72107228697761, timestamp: 2022-08-20 03:06:01.002179\n",
      "resetting env. episode 6973, reward total was -19.0. running mean: -18.723861564107835, timestamp: 2022-08-20 03:06:07.107891\n",
      "resetting env. episode 6974, reward total was -18.0. running mean: -18.716622948466757, timestamp: 2022-08-20 03:06:14.711178\n",
      "resetting env. episode 6975, reward total was -19.0. running mean: -18.71945671898209, timestamp: 2022-08-20 03:06:19.523347\n",
      "resetting env. episode 6976, reward total was -21.0. running mean: -18.74226215179227, timestamp: 2022-08-20 03:06:26.205456\n",
      "resetting env. episode 6977, reward total was -19.0. running mean: -18.74483953027435, timestamp: 2022-08-20 03:06:32.856714\n",
      "resetting env. episode 6978, reward total was -20.0. running mean: -18.757391134971606, timestamp: 2022-08-20 03:06:38.019875\n",
      "resetting env. episode 6979, reward total was -15.0. running mean: -18.719817223621888, timestamp: 2022-08-20 03:06:44.571407\n",
      "resetting env. episode 6980, reward total was -17.0. running mean: -18.70261905138567, timestamp: 2022-08-20 03:06:52.573207\n",
      "resetting env. episode 6981, reward total was -21.0. running mean: -18.725592860871814, timestamp: 2022-08-20 03:06:57.849721\n",
      "resetting env. episode 6982, reward total was -18.0. running mean: -18.718336932263096, timestamp: 2022-08-20 03:07:03.582363\n",
      "resetting env. episode 6983, reward total was -18.0. running mean: -18.711153562940464, timestamp: 2022-08-20 03:07:11.101230\n",
      "resetting env. episode 6984, reward total was -20.0. running mean: -18.724042027311057, timestamp: 2022-08-20 03:07:17.585946\n",
      "resetting env. episode 6985, reward total was -20.0. running mean: -18.736801607037947, timestamp: 2022-08-20 03:07:24.778668\n",
      "resetting env. episode 6986, reward total was -19.0. running mean: -18.739433590967568, timestamp: 2022-08-20 03:07:31.629385\n",
      "resetting env. episode 6987, reward total was -21.0. running mean: -18.762039255057893, timestamp: 2022-08-20 03:07:37.502023\n",
      "resetting env. episode 6988, reward total was -21.0. running mean: -18.784418862507316, timestamp: 2022-08-20 03:07:43.113002\n",
      "resetting env. episode 6989, reward total was -19.0. running mean: -18.786574673882242, timestamp: 2022-08-20 03:07:48.794801\n",
      "resetting env. episode 6990, reward total was -19.0. running mean: -18.78870892714342, timestamp: 2022-08-20 03:07:54.303923\n",
      "resetting env. episode 6991, reward total was -20.0. running mean: -18.800821837871986, timestamp: 2022-08-20 03:08:00.367708\n",
      "resetting env. episode 6992, reward total was -19.0. running mean: -18.802813619493268, timestamp: 2022-08-20 03:08:05.970635\n",
      "resetting env. episode 6993, reward total was -17.0. running mean: -18.784785483298336, timestamp: 2022-08-20 03:08:13.493528\n",
      "resetting env. episode 6994, reward total was -20.0. running mean: -18.79693762846535, timestamp: 2022-08-20 03:08:19.040710\n",
      "resetting env. episode 6995, reward total was -19.0. running mean: -18.7989682521807, timestamp: 2022-08-20 03:08:25.210207\n",
      "resetting env. episode 6996, reward total was -19.0. running mean: -18.800978569658895, timestamp: 2022-08-20 03:08:29.667249\n",
      "resetting env. episode 6997, reward total was -19.0. running mean: -18.802968783962307, timestamp: 2022-08-20 03:08:36.600743\n",
      "resetting env. episode 6998, reward total was -19.0. running mean: -18.804939096122684, timestamp: 2022-08-20 03:08:42.040179\n",
      "resetting env. episode 6999, reward total was -19.0. running mean: -18.80688970516146, timestamp: 2022-08-20 03:08:48.205735\n",
      "resetting env. episode 7000, reward total was -18.0. running mean: -18.798820808109845, timestamp: 2022-08-20 03:08:54.482426\n",
      "resetting env. episode 7001, reward total was -19.0. running mean: -18.80083260002875, timestamp: 2022-08-20 03:09:00.488142\n",
      "resetting env. episode 7002, reward total was -17.0. running mean: -18.782824274028464, timestamp: 2022-08-20 03:09:07.746499\n",
      "resetting env. episode 7003, reward total was -19.0. running mean: -18.78499603128818, timestamp: 2022-08-20 03:09:15.697437\n",
      "resetting env. episode 7004, reward total was -17.0. running mean: -18.7671460709753, timestamp: 2022-08-20 03:09:21.361297\n",
      "resetting env. episode 7005, reward total was -20.0. running mean: -18.779474610265545, timestamp: 2022-08-20 03:09:27.178749\n",
      "resetting env. episode 7006, reward total was -21.0. running mean: -18.80167986416289, timestamp: 2022-08-20 03:09:31.813411\n",
      "resetting env. episode 7007, reward total was -16.0. running mean: -18.77366306552126, timestamp: 2022-08-20 03:09:38.982225\n",
      "resetting env. episode 7008, reward total was -20.0. running mean: -18.785926434866045, timestamp: 2022-08-20 03:09:47.603267\n",
      "resetting env. episode 7009, reward total was -20.0. running mean: -18.798067170517385, timestamp: 2022-08-20 03:09:54.059013\n",
      "resetting env. episode 7010, reward total was -21.0. running mean: -18.820086498812213, timestamp: 2022-08-20 03:10:00.744148\n",
      "resetting env. episode 7011, reward total was -17.0. running mean: -18.801885633824092, timestamp: 2022-08-20 03:10:07.223823\n",
      "resetting env. episode 7012, reward total was -17.0. running mean: -18.78386677748585, timestamp: 2022-08-20 03:10:14.189205\n",
      "resetting env. episode 7013, reward total was -19.0. running mean: -18.786028109710994, timestamp: 2022-08-20 03:10:21.460597\n",
      "resetting env. episode 7014, reward total was -20.0. running mean: -18.798167828613884, timestamp: 2022-08-20 03:10:29.057237\n",
      "resetting env. episode 7015, reward total was -17.0. running mean: -18.780186150327747, timestamp: 2022-08-20 03:10:35.491056\n",
      "resetting env. episode 7016, reward total was -19.0. running mean: -18.78238428882447, timestamp: 2022-08-20 03:10:42.123362\n",
      "resetting env. episode 7017, reward total was -20.0. running mean: -18.794560445936224, timestamp: 2022-08-20 03:10:48.372666\n",
      "resetting env. episode 7018, reward total was -19.0. running mean: -18.796614841476863, timestamp: 2022-08-20 03:10:55.548588\n",
      "resetting env. episode 7019, reward total was -21.0. running mean: -18.818648693062094, timestamp: 2022-08-20 03:11:01.065848\n",
      "resetting env. episode 7020, reward total was -17.0. running mean: -18.800462206131474, timestamp: 2022-08-20 03:11:09.240998\n",
      "resetting env. episode 7021, reward total was -17.0. running mean: -18.782457584070162, timestamp: 2022-08-20 03:11:16.416843\n",
      "resetting env. episode 7022, reward total was -17.0. running mean: -18.764633008229463, timestamp: 2022-08-20 03:11:23.908537\n",
      "resetting env. episode 7023, reward total was -21.0. running mean: -18.78698667814717, timestamp: 2022-08-20 03:11:28.300588\n",
      "resetting env. episode 7024, reward total was -21.0. running mean: -18.809116811365698, timestamp: 2022-08-20 03:11:34.931798\n",
      "resetting env. episode 7025, reward total was -17.0. running mean: -18.79102564325204, timestamp: 2022-08-20 03:11:41.089886\n",
      "resetting env. episode 7026, reward total was -18.0. running mean: -18.78311538681952, timestamp: 2022-08-20 03:11:47.168815\n",
      "resetting env. episode 7027, reward total was -19.0. running mean: -18.785284232951327, timestamp: 2022-08-20 03:11:53.893456\n",
      "resetting env. episode 7028, reward total was -19.0. running mean: -18.787431390621816, timestamp: 2022-08-20 03:12:01.525062\n",
      "resetting env. episode 7029, reward total was -19.0. running mean: -18.7895570767156, timestamp: 2022-08-20 03:12:07.589149\n",
      "resetting env. episode 7030, reward total was -18.0. running mean: -18.781661505948442, timestamp: 2022-08-20 03:12:15.097087\n",
      "resetting env. episode 7031, reward total was -19.0. running mean: -18.783844890888957, timestamp: 2022-08-20 03:12:23.420035\n",
      "resetting env. episode 7032, reward total was -18.0. running mean: -18.77600644198007, timestamp: 2022-08-20 03:12:29.677827\n",
      "resetting env. episode 7033, reward total was -19.0. running mean: -18.77824637756027, timestamp: 2022-08-20 03:12:36.255230\n",
      "resetting env. episode 7034, reward total was -19.0. running mean: -18.78046391378467, timestamp: 2022-08-20 03:12:43.197707\n",
      "resetting env. episode 7035, reward total was -21.0. running mean: -18.80265927464682, timestamp: 2022-08-20 03:12:50.007470\n",
      "resetting env. episode 7036, reward total was -20.0. running mean: -18.814632681900353, timestamp: 2022-08-20 03:12:56.720451\n",
      "resetting env. episode 7037, reward total was -20.0. running mean: -18.826486355081347, timestamp: 2022-08-20 03:13:03.025595\n",
      "resetting env. episode 7038, reward total was -19.0. running mean: -18.828221491530535, timestamp: 2022-08-20 03:13:09.409007\n",
      "resetting env. episode 7039, reward total was -18.0. running mean: -18.81993927661523, timestamp: 2022-08-20 03:13:15.821773\n",
      "resetting env. episode 7040, reward total was -21.0. running mean: -18.84173988384908, timestamp: 2022-08-20 03:13:22.731973\n",
      "resetting env. episode 7041, reward total was -17.0. running mean: -18.82332248501059, timestamp: 2022-08-20 03:13:28.768801\n",
      "resetting env. episode 7042, reward total was -14.0. running mean: -18.775089260160485, timestamp: 2022-08-20 03:13:34.753803\n",
      "resetting env. episode 7043, reward total was -19.0. running mean: -18.77733836755888, timestamp: 2022-08-20 03:13:39.937485\n",
      "resetting env. episode 7044, reward total was -21.0. running mean: -18.799564983883293, timestamp: 2022-08-20 03:13:45.522558\n",
      "resetting env. episode 7045, reward total was -19.0. running mean: -18.801569334044462, timestamp: 2022-08-20 03:13:51.882569\n",
      "resetting env. episode 7046, reward total was -20.0. running mean: -18.813553640704015, timestamp: 2022-08-20 03:13:57.433720\n",
      "resetting env. episode 7047, reward total was -21.0. running mean: -18.835418104296977, timestamp: 2022-08-20 03:14:05.729554\n",
      "resetting env. episode 7048, reward total was -18.0. running mean: -18.827063923254006, timestamp: 2022-08-20 03:14:13.433961\n",
      "resetting env. episode 7049, reward total was -20.0. running mean: -18.838793284021463, timestamp: 2022-08-20 03:14:18.743757\n",
      "resetting env. episode 7050, reward total was -20.0. running mean: -18.850405351181248, timestamp: 2022-08-20 03:14:24.781618\n",
      "resetting env. episode 7051, reward total was -19.0. running mean: -18.851901297669436, timestamp: 2022-08-20 03:14:31.124970\n",
      "resetting env. episode 7052, reward total was -20.0. running mean: -18.86338228469274, timestamp: 2022-08-20 03:14:36.650682\n",
      "resetting env. episode 7053, reward total was -21.0. running mean: -18.884748461845813, timestamp: 2022-08-20 03:14:43.247822\n",
      "resetting env. episode 7054, reward total was -17.0. running mean: -18.865900977227355, timestamp: 2022-08-20 03:14:49.913020\n",
      "resetting env. episode 7055, reward total was -20.0. running mean: -18.87724196745508, timestamp: 2022-08-20 03:14:55.166893\n",
      "resetting env. episode 7056, reward total was -19.0. running mean: -18.878469547780533, timestamp: 2022-08-20 03:15:01.103025\n",
      "resetting env. episode 7057, reward total was -19.0. running mean: -18.879684852302727, timestamp: 2022-08-20 03:15:07.571386\n",
      "resetting env. episode 7058, reward total was -19.0. running mean: -18.880888003779702, timestamp: 2022-08-20 03:15:14.571681\n",
      "resetting env. episode 7059, reward total was -20.0. running mean: -18.892079123741905, timestamp: 2022-08-20 03:15:21.332151\n",
      "resetting env. episode 7060, reward total was -20.0. running mean: -18.903158332504486, timestamp: 2022-08-20 03:15:28.183045\n",
      "resetting env. episode 7061, reward total was -21.0. running mean: -18.924126749179443, timestamp: 2022-08-20 03:15:33.156751\n",
      "resetting env. episode 7062, reward total was -20.0. running mean: -18.934885481687648, timestamp: 2022-08-20 03:15:38.390763\n",
      "resetting env. episode 7063, reward total was -20.0. running mean: -18.94553662687077, timestamp: 2022-08-20 03:15:44.543327\n",
      "resetting env. episode 7064, reward total was -20.0. running mean: -18.956081260602062, timestamp: 2022-08-20 03:15:49.747535\n",
      "resetting env. episode 7065, reward total was -17.0. running mean: -18.936520447996042, timestamp: 2022-08-20 03:15:57.577358\n",
      "resetting env. episode 7066, reward total was -20.0. running mean: -18.94715524351608, timestamp: 2022-08-20 03:16:04.182585\n",
      "resetting env. episode 7067, reward total was -19.0. running mean: -18.94768369108092, timestamp: 2022-08-20 03:16:10.850203\n",
      "resetting env. episode 7068, reward total was -18.0. running mean: -18.938206854170108, timestamp: 2022-08-20 03:16:18.304307\n",
      "resetting env. episode 7069, reward total was -19.0. running mean: -18.93882478562841, timestamp: 2022-08-20 03:16:24.774905\n",
      "resetting env. episode 7070, reward total was -18.0. running mean: -18.929436537772123, timestamp: 2022-08-20 03:16:32.485297\n",
      "resetting env. episode 7071, reward total was -15.0. running mean: -18.8901421723944, timestamp: 2022-08-20 03:16:39.760031\n",
      "resetting env. episode 7072, reward total was -20.0. running mean: -18.901240750670453, timestamp: 2022-08-20 03:16:44.587100\n",
      "resetting env. episode 7073, reward total was -21.0. running mean: -18.92222834316375, timestamp: 2022-08-20 03:16:49.944783\n",
      "resetting env. episode 7074, reward total was -17.0. running mean: -18.903006059732114, timestamp: 2022-08-20 03:16:55.891888\n",
      "resetting env. episode 7075, reward total was -19.0. running mean: -18.903975999134794, timestamp: 2022-08-20 03:17:03.348950\n",
      "resetting env. episode 7076, reward total was -19.0. running mean: -18.904936239143446, timestamp: 2022-08-20 03:17:10.004219\n",
      "resetting env. episode 7077, reward total was -21.0. running mean: -18.925886876752013, timestamp: 2022-08-20 03:17:15.675061\n",
      "resetting env. episode 7078, reward total was -21.0. running mean: -18.946628007984494, timestamp: 2022-08-20 03:17:20.983866\n",
      "resetting env. episode 7079, reward total was -19.0. running mean: -18.94716172790465, timestamp: 2022-08-20 03:17:27.940273\n",
      "resetting env. episode 7080, reward total was -21.0. running mean: -18.967690110625604, timestamp: 2022-08-20 03:17:33.682956\n",
      "resetting env. episode 7081, reward total was -17.0. running mean: -18.94801320951935, timestamp: 2022-08-20 03:17:41.285415\n",
      "resetting env. episode 7082, reward total was -21.0. running mean: -18.968533077424155, timestamp: 2022-08-20 03:17:47.885779\n",
      "resetting env. episode 7083, reward total was -18.0. running mean: -18.958847746649912, timestamp: 2022-08-20 03:17:54.697567\n",
      "resetting env. episode 7084, reward total was -20.0. running mean: -18.96925926918341, timestamp: 2022-08-20 03:18:01.522729\n",
      "resetting env. episode 7085, reward total was -19.0. running mean: -18.969566676491578, timestamp: 2022-08-20 03:18:07.913637\n",
      "resetting env. episode 7086, reward total was -20.0. running mean: -18.97987100972666, timestamp: 2022-08-20 03:18:12.457268\n",
      "resetting env. episode 7087, reward total was -21.0. running mean: -19.000072299629394, timestamp: 2022-08-20 03:18:21.615009\n",
      "resetting env. episode 7088, reward total was -20.0. running mean: -19.0100715766331, timestamp: 2022-08-20 03:18:26.542819\n",
      "resetting env. episode 7089, reward total was -19.0. running mean: -19.00997086086677, timestamp: 2022-08-20 03:18:32.770171\n",
      "resetting env. episode 7090, reward total was -19.0. running mean: -19.009871152258103, timestamp: 2022-08-20 03:18:40.343924\n",
      "resetting env. episode 7091, reward total was -17.0. running mean: -18.989772440735525, timestamp: 2022-08-20 03:18:47.445211\n",
      "resetting env. episode 7092, reward total was -19.0. running mean: -18.98987471632817, timestamp: 2022-08-20 03:18:52.854744\n",
      "resetting env. episode 7093, reward total was -15.0. running mean: -18.949975969164885, timestamp: 2022-08-20 03:18:59.358339\n",
      "resetting env. episode 7094, reward total was -19.0. running mean: -18.950476209473237, timestamp: 2022-08-20 03:19:05.677308\n",
      "resetting env. episode 7095, reward total was -20.0. running mean: -18.960971447378505, timestamp: 2022-08-20 03:19:11.447887\n",
      "resetting env. episode 7096, reward total was -20.0. running mean: -18.971361732904718, timestamp: 2022-08-20 03:19:18.020826\n",
      "resetting env. episode 7097, reward total was -19.0. running mean: -18.97164811557567, timestamp: 2022-08-20 03:19:24.399801\n",
      "resetting env. episode 7098, reward total was -17.0. running mean: -18.951931634419918, timestamp: 2022-08-20 03:19:30.756777\n",
      "resetting env. episode 7099, reward total was -16.0. running mean: -18.922412318075718, timestamp: 2022-08-20 03:19:39.016126\n",
      "resetting env. episode 7100, reward total was -20.0. running mean: -18.93318819489496, timestamp: 2022-08-20 03:19:44.471136\n",
      "resetting env. episode 7101, reward total was -21.0. running mean: -18.953856312946012, timestamp: 2022-08-20 03:19:50.907226\n",
      "resetting env. episode 7102, reward total was -21.0. running mean: -18.974317749816553, timestamp: 2022-08-20 03:19:56.682093\n",
      "resetting env. episode 7103, reward total was -20.0. running mean: -18.984574572318387, timestamp: 2022-08-20 03:20:03.236237\n",
      "resetting env. episode 7104, reward total was -18.0. running mean: -18.974728826595204, timestamp: 2022-08-20 03:20:09.664109\n",
      "resetting env. episode 7105, reward total was -18.0. running mean: -18.96498153832925, timestamp: 2022-08-20 03:20:17.023921\n",
      "resetting env. episode 7106, reward total was -19.0. running mean: -18.965331722945958, timestamp: 2022-08-20 03:20:22.306836\n",
      "resetting env. episode 7107, reward total was -18.0. running mean: -18.955678405716498, timestamp: 2022-08-20 03:20:28.959018\n",
      "resetting env. episode 7108, reward total was -15.0. running mean: -18.916121621659332, timestamp: 2022-08-20 03:20:36.460963\n",
      "resetting env. episode 7109, reward total was -20.0. running mean: -18.92696040544274, timestamp: 2022-08-20 03:20:43.637823\n",
      "resetting env. episode 7110, reward total was -20.0. running mean: -18.93769080138831, timestamp: 2022-08-20 03:20:49.908018\n",
      "resetting env. episode 7111, reward total was -16.0. running mean: -18.908313893374427, timestamp: 2022-08-20 03:20:58.679954\n",
      "resetting env. episode 7112, reward total was -18.0. running mean: -18.899230754440683, timestamp: 2022-08-20 03:21:05.554543\n",
      "resetting env. episode 7113, reward total was -20.0. running mean: -18.910238446896276, timestamp: 2022-08-20 03:21:13.092787\n",
      "resetting env. episode 7114, reward total was -20.0. running mean: -18.921136062427312, timestamp: 2022-08-20 03:21:19.385943\n",
      "resetting env. episode 7115, reward total was -19.0. running mean: -18.92192470180304, timestamp: 2022-08-20 03:21:24.921142\n",
      "resetting env. episode 7116, reward total was -13.0. running mean: -18.862705454785008, timestamp: 2022-08-20 03:21:32.972713\n",
      "resetting env. episode 7117, reward total was -18.0. running mean: -18.854078400237157, timestamp: 2022-08-20 03:21:40.553532\n",
      "resetting env. episode 7118, reward total was -21.0. running mean: -18.875537616234787, timestamp: 2022-08-20 03:21:46.322106\n",
      "resetting env. episode 7119, reward total was -18.0. running mean: -18.86678224007244, timestamp: 2022-08-20 03:21:54.232885\n",
      "resetting env. episode 7120, reward total was -19.0. running mean: -18.868114417671716, timestamp: 2022-08-20 03:22:00.247841\n",
      "resetting env. episode 7121, reward total was -18.0. running mean: -18.859433273495, timestamp: 2022-08-20 03:22:05.691859\n",
      "resetting env. episode 7122, reward total was -19.0. running mean: -18.86083894076005, timestamp: 2022-08-20 03:22:12.839078\n",
      "resetting env. episode 7123, reward total was -21.0. running mean: -18.88223055135245, timestamp: 2022-08-20 03:22:18.252585\n",
      "resetting env. episode 7124, reward total was -18.0. running mean: -18.873408245838924, timestamp: 2022-08-20 03:22:25.686708\n",
      "resetting env. episode 7125, reward total was -19.0. running mean: -18.874674163380536, timestamp: 2022-08-20 03:22:33.524640\n",
      "resetting env. episode 7126, reward total was -18.0. running mean: -18.86592742174673, timestamp: 2022-08-20 03:22:40.087163\n",
      "resetting env. episode 7127, reward total was -20.0. running mean: -18.87726814752926, timestamp: 2022-08-20 03:22:46.563810\n",
      "resetting env. episode 7128, reward total was -20.0. running mean: -18.888495466053968, timestamp: 2022-08-20 03:22:53.238947\n",
      "resetting env. episode 7129, reward total was -20.0. running mean: -18.899610511393426, timestamp: 2022-08-20 03:22:58.570705\n",
      "resetting env. episode 7130, reward total was -16.0. running mean: -18.870614406279493, timestamp: 2022-08-20 03:23:05.874588\n",
      "resetting env. episode 7131, reward total was -19.0. running mean: -18.8719082622167, timestamp: 2022-08-20 03:23:12.168093\n",
      "resetting env. episode 7132, reward total was -20.0. running mean: -18.88318917959453, timestamp: 2022-08-20 03:23:16.745888\n",
      "resetting env. episode 7133, reward total was -18.0. running mean: -18.874357287798585, timestamp: 2022-08-20 03:23:23.759111\n",
      "resetting env. episode 7134, reward total was -16.0. running mean: -18.8456137149206, timestamp: 2022-08-20 03:23:30.554968\n",
      "resetting env. episode 7135, reward total was -21.0. running mean: -18.867157577771394, timestamp: 2022-08-20 03:23:36.918062\n",
      "resetting env. episode 7136, reward total was -21.0. running mean: -18.88848600199368, timestamp: 2022-08-20 03:23:43.334082\n",
      "resetting env. episode 7137, reward total was -21.0. running mean: -18.909601141973745, timestamp: 2022-08-20 03:23:49.456473\n",
      "resetting env. episode 7138, reward total was -19.0. running mean: -18.910505130554007, timestamp: 2022-08-20 03:23:55.328777\n",
      "resetting env. episode 7139, reward total was -17.0. running mean: -18.89140007924847, timestamp: 2022-08-20 03:24:01.495295\n",
      "resetting env. episode 7140, reward total was -19.0. running mean: -18.892486078455985, timestamp: 2022-08-20 03:24:08.020141\n",
      "resetting env. episode 7141, reward total was -17.0. running mean: -18.873561217671426, timestamp: 2022-08-20 03:24:14.152085\n",
      "resetting env. episode 7142, reward total was -21.0. running mean: -18.894825605494713, timestamp: 2022-08-20 03:24:18.735786\n",
      "resetting env. episode 7143, reward total was -17.0. running mean: -18.87587734943977, timestamp: 2022-08-20 03:24:23.149381\n",
      "resetting env. episode 7144, reward total was -20.0. running mean: -18.88711857594537, timestamp: 2022-08-20 03:24:29.214351\n",
      "resetting env. episode 7145, reward total was -19.0. running mean: -18.888247390185917, timestamp: 2022-08-20 03:24:34.500048\n",
      "resetting env. episode 7146, reward total was -18.0. running mean: -18.879364916284057, timestamp: 2022-08-20 03:24:39.757763\n",
      "resetting env. episode 7147, reward total was -19.0. running mean: -18.88057126712122, timestamp: 2022-08-20 03:24:45.633523\n",
      "resetting env. episode 7148, reward total was -19.0. running mean: -18.88176555445001, timestamp: 2022-08-20 03:24:52.916934\n",
      "resetting env. episode 7149, reward total was -20.0. running mean: -18.892947898905508, timestamp: 2022-08-20 03:24:57.632099\n",
      "resetting env. episode 7150, reward total was -20.0. running mean: -18.90401841991645, timestamp: 2022-08-20 03:25:04.057066\n",
      "resetting env. episode 7151, reward total was -17.0. running mean: -18.884978235717288, timestamp: 2022-08-20 03:25:09.043538\n",
      "resetting env. episode 7152, reward total was -21.0. running mean: -18.906128453360115, timestamp: 2022-08-20 03:25:13.750749\n",
      "resetting env. episode 7153, reward total was -19.0. running mean: -18.907067168826515, timestamp: 2022-08-20 03:25:19.173554\n",
      "resetting env. episode 7154, reward total was -18.0. running mean: -18.897996497138248, timestamp: 2022-08-20 03:25:24.606496\n",
      "resetting env. episode 7155, reward total was -19.0. running mean: -18.899016532166865, timestamp: 2022-08-20 03:25:31.129470\n",
      "resetting env. episode 7156, reward total was -21.0. running mean: -18.920026366845196, timestamp: 2022-08-20 03:25:36.087889\n",
      "resetting env. episode 7157, reward total was -18.0. running mean: -18.910826103176742, timestamp: 2022-08-20 03:25:40.873589\n",
      "resetting env. episode 7158, reward total was -16.0. running mean: -18.881717842144976, timestamp: 2022-08-20 03:25:45.724223\n",
      "resetting env. episode 7159, reward total was -17.0. running mean: -18.86290066372353, timestamp: 2022-08-20 03:25:51.166239\n",
      "resetting env. episode 7160, reward total was -19.0. running mean: -18.864271657086295, timestamp: 2022-08-20 03:25:56.276751\n",
      "resetting env. episode 7161, reward total was -19.0. running mean: -18.865628940515432, timestamp: 2022-08-20 03:26:01.890594\n",
      "resetting env. episode 7162, reward total was -18.0. running mean: -18.856972651110276, timestamp: 2022-08-20 03:26:07.353164\n",
      "resetting env. episode 7163, reward total was -20.0. running mean: -18.868402924599174, timestamp: 2022-08-20 03:26:12.916048\n",
      "resetting env. episode 7164, reward total was -19.0. running mean: -18.869718895353184, timestamp: 2022-08-20 03:26:17.625489\n",
      "resetting env. episode 7165, reward total was -21.0. running mean: -18.891021706399652, timestamp: 2022-08-20 03:26:23.066365\n",
      "resetting env. episode 7166, reward total was -17.0. running mean: -18.87211148933566, timestamp: 2022-08-20 03:26:28.362222\n",
      "resetting env. episode 7167, reward total was -21.0. running mean: -18.8933903744423, timestamp: 2022-08-20 03:26:32.707189\n",
      "resetting env. episode 7168, reward total was -21.0. running mean: -18.91445647069788, timestamp: 2022-08-20 03:26:38.091269\n",
      "resetting env. episode 7169, reward total was -19.0. running mean: -18.9153119059909, timestamp: 2022-08-20 03:26:43.431447\n",
      "resetting env. episode 7170, reward total was -21.0. running mean: -18.936158786930992, timestamp: 2022-08-20 03:26:50.097532\n",
      "resetting env. episode 7171, reward total was -19.0. running mean: -18.936797199061683, timestamp: 2022-08-20 03:26:56.121997\n",
      "resetting env. episode 7172, reward total was -18.0. running mean: -18.927429227071066, timestamp: 2022-08-20 03:27:02.246216\n",
      "resetting env. episode 7173, reward total was -15.0. running mean: -18.888154934800355, timestamp: 2022-08-20 03:27:11.485270\n",
      "resetting env. episode 7174, reward total was -17.0. running mean: -18.869273385452352, timestamp: 2022-08-20 03:27:19.987608\n",
      "resetting env. episode 7175, reward total was -19.0. running mean: -18.87058065159783, timestamp: 2022-08-20 03:27:27.542255\n",
      "resetting env. episode 7176, reward total was -19.0. running mean: -18.87187484508185, timestamp: 2022-08-20 03:27:32.958274\n",
      "resetting env. episode 7177, reward total was -21.0. running mean: -18.893156096631035, timestamp: 2022-08-20 03:27:38.185685\n",
      "resetting env. episode 7178, reward total was -19.0. running mean: -18.894224535664726, timestamp: 2022-08-20 03:27:45.275544\n",
      "resetting env. episode 7179, reward total was -18.0. running mean: -18.88528229030808, timestamp: 2022-08-20 03:27:50.633324\n",
      "resetting env. episode 7180, reward total was -20.0. running mean: -18.896429467405, timestamp: 2022-08-20 03:27:56.017862\n",
      "resetting env. episode 7181, reward total was -21.0. running mean: -18.91746517273095, timestamp: 2022-08-20 03:28:01.332623\n",
      "resetting env. episode 7182, reward total was -20.0. running mean: -18.92829052100364, timestamp: 2022-08-20 03:28:06.442964\n",
      "resetting env. episode 7183, reward total was -20.0. running mean: -18.939007615793603, timestamp: 2022-08-20 03:28:11.764738\n",
      "resetting env. episode 7184, reward total was -19.0. running mean: -18.93961753963567, timestamp: 2022-08-20 03:28:17.634057\n",
      "resetting env. episode 7185, reward total was -20.0. running mean: -18.95022136423931, timestamp: 2022-08-20 03:28:22.768363\n",
      "resetting env. episode 7186, reward total was -19.0. running mean: -18.95071915059692, timestamp: 2022-08-20 03:28:29.486371\n",
      "resetting env. episode 7187, reward total was -19.0. running mean: -18.95121195909095, timestamp: 2022-08-20 03:28:34.518944\n",
      "resetting env. episode 7188, reward total was -18.0. running mean: -18.941699839500043, timestamp: 2022-08-20 03:28:40.850998\n",
      "resetting env. episode 7189, reward total was -21.0. running mean: -18.962282841105043, timestamp: 2022-08-20 03:28:44.930095\n",
      "resetting env. episode 7190, reward total was -21.0. running mean: -18.982660012693994, timestamp: 2022-08-20 03:28:50.233917\n",
      "resetting env. episode 7191, reward total was -14.0. running mean: -18.932833412567057, timestamp: 2022-08-20 03:28:56.672706\n",
      "resetting env. episode 7192, reward total was -17.0. running mean: -18.91350507844139, timestamp: 2022-08-20 03:29:01.916703\n",
      "resetting env. episode 7193, reward total was -19.0. running mean: -18.914370027656975, timestamp: 2022-08-20 03:29:08.577889\n",
      "resetting env. episode 7194, reward total was -19.0. running mean: -18.915226327380406, timestamp: 2022-08-20 03:29:14.004380\n",
      "resetting env. episode 7195, reward total was -19.0. running mean: -18.916074064106603, timestamp: 2022-08-20 03:29:20.828141\n",
      "resetting env. episode 7196, reward total was -18.0. running mean: -18.906913323465535, timestamp: 2022-08-20 03:29:26.522916\n",
      "resetting env. episode 7197, reward total was -17.0. running mean: -18.88784419023088, timestamp: 2022-08-20 03:29:32.710380\n",
      "resetting env. episode 7198, reward total was -15.0. running mean: -18.84896574832857, timestamp: 2022-08-20 03:29:39.717694\n",
      "resetting env. episode 7199, reward total was -19.0. running mean: -18.850476090845287, timestamp: 2022-08-20 03:29:44.117903\n",
      "resetting env. episode 7200, reward total was -18.0. running mean: -18.841971329936833, timestamp: 2022-08-20 03:29:49.943343\n",
      "resetting env. episode 7201, reward total was -19.0. running mean: -18.843551616637466, timestamp: 2022-08-20 03:29:56.225849\n",
      "resetting env. episode 7202, reward total was -21.0. running mean: -18.86511610047109, timestamp: 2022-08-20 03:30:01.173625\n",
      "resetting env. episode 7203, reward total was -20.0. running mean: -18.87646493946638, timestamp: 2022-08-20 03:30:05.778317\n",
      "resetting env. episode 7204, reward total was -19.0. running mean: -18.87770029007172, timestamp: 2022-08-20 03:30:11.077163\n",
      "resetting env. episode 7205, reward total was -19.0. running mean: -18.878923287171002, timestamp: 2022-08-20 03:30:17.645886\n",
      "resetting env. episode 7206, reward total was -17.0. running mean: -18.860134054299294, timestamp: 2022-08-20 03:30:25.944305\n",
      "resetting env. episode 7207, reward total was -21.0. running mean: -18.881532713756304, timestamp: 2022-08-20 03:30:31.105443\n",
      "resetting env. episode 7208, reward total was -18.0. running mean: -18.872717386618742, timestamp: 2022-08-20 03:30:37.280643\n",
      "resetting env. episode 7209, reward total was -20.0. running mean: -18.883990212752554, timestamp: 2022-08-20 03:30:42.394625\n",
      "resetting env. episode 7210, reward total was -18.0. running mean: -18.875150310625028, timestamp: 2022-08-20 03:30:47.012295\n",
      "resetting env. episode 7211, reward total was -19.0. running mean: -18.87639880751878, timestamp: 2022-08-20 03:30:50.685936\n",
      "resetting env. episode 7212, reward total was -19.0. running mean: -18.877634819443593, timestamp: 2022-08-20 03:30:54.450547\n",
      "resetting env. episode 7213, reward total was -21.0. running mean: -18.898858471249156, timestamp: 2022-08-20 03:30:58.260614\n",
      "resetting env. episode 7214, reward total was -21.0. running mean: -18.919869886536667, timestamp: 2022-08-20 03:31:01.924829\n",
      "resetting env. episode 7215, reward total was -20.0. running mean: -18.930671187671297, timestamp: 2022-08-20 03:31:07.091501\n",
      "resetting env. episode 7216, reward total was -21.0. running mean: -18.951364475794584, timestamp: 2022-08-20 03:31:11.117192\n",
      "resetting env. episode 7217, reward total was -19.0. running mean: -18.95185083103664, timestamp: 2022-08-20 03:31:15.431003\n",
      "resetting env. episode 7218, reward total was -19.0. running mean: -18.952332322726274, timestamp: 2022-08-20 03:31:20.020079\n",
      "resetting env. episode 7219, reward total was -17.0. running mean: -18.932808999499013, timestamp: 2022-08-20 03:31:24.631474\n",
      "resetting env. episode 7220, reward total was -19.0. running mean: -18.933480909504024, timestamp: 2022-08-20 03:31:29.841264\n",
      "resetting env. episode 7221, reward total was -18.0. running mean: -18.924146100408983, timestamp: 2022-08-20 03:31:34.586246\n",
      "resetting env. episode 7222, reward total was -19.0. running mean: -18.924904639404893, timestamp: 2022-08-20 03:31:39.025694\n",
      "resetting env. episode 7223, reward total was -19.0. running mean: -18.925655593010845, timestamp: 2022-08-20 03:31:42.826595\n",
      "resetting env. episode 7224, reward total was -19.0. running mean: -18.92639903708074, timestamp: 2022-08-20 03:31:47.573573\n",
      "resetting env. episode 7225, reward total was -20.0. running mean: -18.93713504670993, timestamp: 2022-08-20 03:31:51.700492\n",
      "resetting env. episode 7226, reward total was -20.0. running mean: -18.94776369624283, timestamp: 2022-08-20 03:31:56.289776\n",
      "resetting env. episode 7227, reward total was -18.0. running mean: -18.9382860592804, timestamp: 2022-08-20 03:32:01.104013\n",
      "resetting env. episode 7228, reward total was -19.0. running mean: -18.938903198687598, timestamp: 2022-08-20 03:32:05.797361\n",
      "resetting env. episode 7229, reward total was -17.0. running mean: -18.919514166700722, timestamp: 2022-08-20 03:32:10.384276\n",
      "resetting env. episode 7230, reward total was -21.0. running mean: -18.940319025033716, timestamp: 2022-08-20 03:32:14.913042\n",
      "resetting env. episode 7231, reward total was -21.0. running mean: -18.96091583478338, timestamp: 2022-08-20 03:32:19.752461\n",
      "resetting env. episode 7232, reward total was -19.0. running mean: -18.961306676435544, timestamp: 2022-08-20 03:32:23.626909\n",
      "resetting env. episode 7233, reward total was -19.0. running mean: -18.96169360967119, timestamp: 2022-08-20 03:32:27.749392\n",
      "resetting env. episode 7234, reward total was -19.0. running mean: -18.96207667357448, timestamp: 2022-08-20 03:32:31.404612\n",
      "resetting env. episode 7235, reward total was -18.0. running mean: -18.952455906838733, timestamp: 2022-08-20 03:32:36.572906\n",
      "resetting env. episode 7236, reward total was -18.0. running mean: -18.942931347770344, timestamp: 2022-08-20 03:32:40.870847\n",
      "resetting env. episode 7237, reward total was -18.0. running mean: -18.93350203429264, timestamp: 2022-08-20 03:32:44.847091\n",
      "resetting env. episode 7238, reward total was -19.0. running mean: -18.934167013949715, timestamp: 2022-08-20 03:32:49.230415\n",
      "resetting env. episode 7239, reward total was -19.0. running mean: -18.934825343810218, timestamp: 2022-08-20 03:32:53.781919\n",
      "resetting env. episode 7240, reward total was -21.0. running mean: -18.955477090372117, timestamp: 2022-08-20 03:32:58.328047\n",
      "resetting env. episode 7241, reward total was -17.0. running mean: -18.935922319468396, timestamp: 2022-08-20 03:33:02.230624\n",
      "resetting env. episode 7242, reward total was -18.0. running mean: -18.92656309627371, timestamp: 2022-08-20 03:33:05.918391\n",
      "resetting env. episode 7243, reward total was -18.0. running mean: -18.917297465310973, timestamp: 2022-08-20 03:33:09.429274\n",
      "resetting env. episode 7244, reward total was -17.0. running mean: -18.898124490657864, timestamp: 2022-08-20 03:33:13.912563\n",
      "resetting env. episode 7245, reward total was -19.0. running mean: -18.899143245751286, timestamp: 2022-08-20 03:33:18.054357\n",
      "resetting env. episode 7246, reward total was -20.0. running mean: -18.910151813293773, timestamp: 2022-08-20 03:33:22.032564\n",
      "resetting env. episode 7247, reward total was -18.0. running mean: -18.901050295160836, timestamp: 2022-08-20 03:33:26.434179\n",
      "resetting env. episode 7248, reward total was -19.0. running mean: -18.90203979220923, timestamp: 2022-08-20 03:33:29.981856\n",
      "resetting env. episode 7249, reward total was -19.0. running mean: -18.90301939428714, timestamp: 2022-08-20 03:33:34.003846\n",
      "resetting env. episode 7250, reward total was -18.0. running mean: -18.893989200344265, timestamp: 2022-08-20 03:33:38.986443\n",
      "resetting env. episode 7251, reward total was -16.0. running mean: -18.865049308340822, timestamp: 2022-08-20 03:33:44.241799\n",
      "resetting env. episode 7252, reward total was -21.0. running mean: -18.886398815257415, timestamp: 2022-08-20 03:33:48.932292\n",
      "resetting env. episode 7253, reward total was -20.0. running mean: -18.897534827104842, timestamp: 2022-08-20 03:33:53.360359\n",
      "resetting env. episode 7254, reward total was -20.0. running mean: -18.90855947883379, timestamp: 2022-08-20 03:33:57.113352\n",
      "resetting env. episode 7255, reward total was -18.0. running mean: -18.899473884045452, timestamp: 2022-08-20 03:34:00.805207\n",
      "resetting env. episode 7256, reward total was -19.0. running mean: -18.900479145205, timestamp: 2022-08-20 03:34:04.814550\n",
      "resetting env. episode 7257, reward total was -21.0. running mean: -18.921474353752952, timestamp: 2022-08-20 03:34:09.326248\n",
      "resetting env. episode 7258, reward total was -20.0. running mean: -18.93225961021542, timestamp: 2022-08-20 03:34:12.741995\n",
      "resetting env. episode 7259, reward total was -17.0. running mean: -18.912937014113268, timestamp: 2022-08-20 03:34:16.418740\n",
      "resetting env. episode 7260, reward total was -20.0. running mean: -18.923807643972136, timestamp: 2022-08-20 03:34:20.581450\n",
      "resetting env. episode 7261, reward total was -18.0. running mean: -18.914569567532414, timestamp: 2022-08-20 03:34:25.495042\n",
      "resetting env. episode 7262, reward total was -21.0. running mean: -18.93542387185709, timestamp: 2022-08-20 03:34:29.936158\n",
      "resetting env. episode 7263, reward total was -21.0. running mean: -18.95606963313852, timestamp: 2022-08-20 03:34:33.331965\n",
      "resetting env. episode 7264, reward total was -21.0. running mean: -18.976508936807136, timestamp: 2022-08-20 03:34:37.608102\n",
      "resetting env. episode 7265, reward total was -16.0. running mean: -18.946743847439066, timestamp: 2022-08-20 03:34:43.465331\n",
      "resetting env. episode 7266, reward total was -21.0. running mean: -18.967276408964675, timestamp: 2022-08-20 03:34:48.347932\n",
      "resetting env. episode 7267, reward total was -17.0. running mean: -18.94760364487503, timestamp: 2022-08-20 03:34:52.058994\n",
      "resetting env. episode 7268, reward total was -18.0. running mean: -18.93812760842628, timestamp: 2022-08-20 03:34:56.025554\n",
      "resetting env. episode 7269, reward total was -17.0. running mean: -18.91874633234202, timestamp: 2022-08-20 03:35:00.101977\n",
      "resetting env. episode 7270, reward total was -19.0. running mean: -18.9195588690186, timestamp: 2022-08-20 03:35:06.080497\n",
      "resetting env. episode 7271, reward total was -21.0. running mean: -18.940363280328416, timestamp: 2022-08-20 03:35:11.362369\n",
      "resetting env. episode 7272, reward total was -19.0. running mean: -18.940959647525133, timestamp: 2022-08-20 03:35:17.608112\n",
      "resetting env. episode 7273, reward total was -21.0. running mean: -18.961550051049883, timestamp: 2022-08-20 03:35:20.970316\n",
      "resetting env. episode 7274, reward total was -19.0. running mean: -18.961934550539386, timestamp: 2022-08-20 03:35:25.711285\n",
      "resetting env. episode 7275, reward total was -21.0. running mean: -18.98231520503399, timestamp: 2022-08-20 03:35:29.402841\n",
      "resetting env. episode 7276, reward total was -20.0. running mean: -18.99249205298365, timestamp: 2022-08-20 03:35:33.222391\n",
      "resetting env. episode 7277, reward total was -17.0. running mean: -18.972567132453815, timestamp: 2022-08-20 03:35:37.758793\n",
      "resetting env. episode 7278, reward total was -14.0. running mean: -18.922841461129277, timestamp: 2022-08-20 03:35:43.485422\n",
      "resetting env. episode 7279, reward total was -21.0. running mean: -18.943613046517985, timestamp: 2022-08-20 03:35:48.089927\n",
      "resetting env. episode 7280, reward total was -19.0. running mean: -18.944176916052808, timestamp: 2022-08-20 03:35:52.513513\n",
      "resetting env. episode 7281, reward total was -20.0. running mean: -18.95473514689228, timestamp: 2022-08-20 03:35:56.688482\n",
      "resetting env. episode 7282, reward total was -18.0. running mean: -18.945187795423355, timestamp: 2022-08-20 03:36:00.417072\n",
      "resetting env. episode 7283, reward total was -19.0. running mean: -18.945735917469122, timestamp: 2022-08-20 03:36:04.440931\n",
      "resetting env. episode 7284, reward total was -17.0. running mean: -18.92627855829443, timestamp: 2022-08-20 03:36:09.547370\n",
      "resetting env. episode 7285, reward total was -20.0. running mean: -18.937015772711487, timestamp: 2022-08-20 03:36:13.549455\n",
      "resetting env. episode 7286, reward total was -21.0. running mean: -18.957645614984372, timestamp: 2022-08-20 03:36:18.196714\n",
      "resetting env. episode 7287, reward total was -21.0. running mean: -18.97806915883453, timestamp: 2022-08-20 03:36:22.428010\n",
      "resetting env. episode 7288, reward total was -18.0. running mean: -18.968288467246182, timestamp: 2022-08-20 03:36:27.544208\n",
      "resetting env. episode 7289, reward total was -20.0. running mean: -18.97860558257372, timestamp: 2022-08-20 03:36:32.000697\n",
      "resetting env. episode 7290, reward total was -19.0. running mean: -18.978819526747984, timestamp: 2022-08-20 03:36:35.329841\n",
      "resetting env. episode 7291, reward total was -21.0. running mean: -18.999031331480506, timestamp: 2022-08-20 03:36:39.355103\n",
      "resetting env. episode 7292, reward total was -16.0. running mean: -18.9690410181657, timestamp: 2022-08-20 03:36:44.964501\n",
      "resetting env. episode 7293, reward total was -18.0. running mean: -18.959350607984042, timestamp: 2022-08-20 03:36:49.550783\n",
      "resetting env. episode 7294, reward total was -19.0. running mean: -18.959757101904202, timestamp: 2022-08-20 03:36:53.368090\n",
      "resetting env. episode 7295, reward total was -19.0. running mean: -18.96015953088516, timestamp: 2022-08-20 03:36:58.391337\n",
      "resetting env. episode 7296, reward total was -16.0. running mean: -18.93055793557631, timestamp: 2022-08-20 03:37:03.157439\n",
      "resetting env. episode 7297, reward total was -20.0. running mean: -18.941252356220545, timestamp: 2022-08-20 03:37:07.584533\n",
      "resetting env. episode 7298, reward total was -18.0. running mean: -18.93183983265834, timestamp: 2022-08-20 03:37:12.294522\n",
      "resetting env. episode 7299, reward total was -19.0. running mean: -18.932521434331758, timestamp: 2022-08-20 03:37:16.848478\n",
      "resetting env. episode 7300, reward total was -20.0. running mean: -18.94319621998844, timestamp: 2022-08-20 03:37:21.482757\n",
      "resetting env. episode 7301, reward total was -19.0. running mean: -18.94376425778856, timestamp: 2022-08-20 03:37:27.667242\n",
      "resetting env. episode 7302, reward total was -18.0. running mean: -18.934326615210672, timestamp: 2022-08-20 03:37:32.605372\n",
      "resetting env. episode 7303, reward total was -18.0. running mean: -18.924983349058564, timestamp: 2022-08-20 03:37:37.194092\n",
      "resetting env. episode 7304, reward total was -20.0. running mean: -18.93573351556798, timestamp: 2022-08-20 03:37:40.783569\n",
      "resetting env. episode 7305, reward total was -17.0. running mean: -18.9163761804123, timestamp: 2022-08-20 03:37:45.115748\n",
      "resetting env. episode 7306, reward total was -18.0. running mean: -18.907212418608175, timestamp: 2022-08-20 03:37:48.914079\n",
      "resetting env. episode 7307, reward total was -19.0. running mean: -18.908140294422093, timestamp: 2022-08-20 03:37:52.874854\n",
      "resetting env. episode 7308, reward total was -21.0. running mean: -18.929058891477872, timestamp: 2022-08-20 03:37:56.167660\n",
      "resetting env. episode 7309, reward total was -21.0. running mean: -18.949768302563093, timestamp: 2022-08-20 03:37:59.290761\n",
      "resetting env. episode 7310, reward total was -17.0. running mean: -18.930270619537463, timestamp: 2022-08-20 03:38:03.937497\n",
      "resetting env. episode 7311, reward total was -20.0. running mean: -18.94096791334209, timestamp: 2022-08-20 03:38:07.779181\n",
      "resetting env. episode 7312, reward total was -18.0. running mean: -18.931558234208666, timestamp: 2022-08-20 03:38:12.008803\n",
      "resetting env. episode 7313, reward total was -21.0. running mean: -18.95224265186658, timestamp: 2022-08-20 03:38:16.298533\n",
      "resetting env. episode 7314, reward total was -17.0. running mean: -18.932720225347914, timestamp: 2022-08-20 03:38:21.694747\n",
      "resetting env. episode 7315, reward total was -19.0. running mean: -18.933393023094435, timestamp: 2022-08-20 03:38:26.483118\n",
      "resetting env. episode 7316, reward total was -18.0. running mean: -18.92405909286349, timestamp: 2022-08-20 03:38:30.580002\n",
      "resetting env. episode 7317, reward total was -20.0. running mean: -18.934818501934856, timestamp: 2022-08-20 03:38:35.571089\n",
      "resetting env. episode 7318, reward total was -17.0. running mean: -18.91547031691551, timestamp: 2022-08-20 03:38:41.414258\n",
      "resetting env. episode 7319, reward total was -17.0. running mean: -18.896315613746356, timestamp: 2022-08-20 03:38:47.318804\n",
      "resetting env. episode 7320, reward total was -15.0. running mean: -18.85735245760889, timestamp: 2022-08-20 03:38:54.493815\n",
      "resetting env. episode 7321, reward total was -16.0. running mean: -18.8287789330328, timestamp: 2022-08-20 03:39:01.053245\n",
      "resetting env. episode 7322, reward total was -17.0. running mean: -18.810491143702475, timestamp: 2022-08-20 03:39:06.794267\n",
      "resetting env. episode 7323, reward total was -20.0. running mean: -18.822386232265448, timestamp: 2022-08-20 03:39:12.425516\n",
      "resetting env. episode 7324, reward total was -19.0. running mean: -18.824162369942794, timestamp: 2022-08-20 03:39:18.609629\n",
      "resetting env. episode 7325, reward total was -17.0. running mean: -18.805920746243366, timestamp: 2022-08-20 03:39:24.062586\n",
      "resetting env. episode 7326, reward total was -17.0. running mean: -18.787861538780934, timestamp: 2022-08-20 03:39:29.084798\n",
      "resetting env. episode 7327, reward total was -18.0. running mean: -18.779982923393124, timestamp: 2022-08-20 03:39:35.114467\n",
      "resetting env. episode 7328, reward total was -20.0. running mean: -18.792183094159192, timestamp: 2022-08-20 03:39:40.091699\n",
      "resetting env. episode 7329, reward total was -20.0. running mean: -18.8042612632176, timestamp: 2022-08-20 03:39:45.444621\n",
      "resetting env. episode 7330, reward total was -21.0. running mean: -18.826218650585425, timestamp: 2022-08-20 03:39:50.981541\n",
      "resetting env. episode 7331, reward total was -19.0. running mean: -18.82795646407957, timestamp: 2022-08-20 03:39:56.104710\n",
      "resetting env. episode 7332, reward total was -21.0. running mean: -18.849676899438776, timestamp: 2022-08-20 03:40:01.662157\n",
      "resetting env. episode 7333, reward total was -18.0. running mean: -18.84118013044439, timestamp: 2022-08-20 03:40:07.543774\n",
      "resetting env. episode 7334, reward total was -18.0. running mean: -18.832768329139945, timestamp: 2022-08-20 03:40:13.613620\n",
      "resetting env. episode 7335, reward total was -19.0. running mean: -18.834440645848545, timestamp: 2022-08-20 03:40:19.366193\n",
      "resetting env. episode 7336, reward total was -21.0. running mean: -18.85609623939006, timestamp: 2022-08-20 03:40:24.882854\n",
      "resetting env. episode 7337, reward total was -19.0. running mean: -18.85753527699616, timestamp: 2022-08-20 03:40:29.697608\n",
      "resetting env. episode 7338, reward total was -19.0. running mean: -18.8589599242262, timestamp: 2022-08-20 03:40:36.839747\n",
      "resetting env. episode 7339, reward total was -18.0. running mean: -18.850370324983935, timestamp: 2022-08-20 03:40:42.201983\n",
      "resetting env. episode 7340, reward total was -17.0. running mean: -18.831866621734097, timestamp: 2022-08-20 03:40:49.607325\n",
      "resetting env. episode 7341, reward total was -20.0. running mean: -18.843547955516755, timestamp: 2022-08-20 03:40:56.214724\n",
      "resetting env. episode 7342, reward total was -19.0. running mean: -18.84511247596159, timestamp: 2022-08-20 03:41:00.175893\n",
      "resetting env. episode 7343, reward total was -17.0. running mean: -18.826661351201974, timestamp: 2022-08-20 03:41:06.734435\n",
      "resetting env. episode 7344, reward total was -15.0. running mean: -18.788394737689952, timestamp: 2022-08-20 03:41:12.826039\n",
      "resetting env. episode 7345, reward total was -15.0. running mean: -18.75051079031305, timestamp: 2022-08-20 03:41:19.415635\n",
      "resetting env. episode 7346, reward total was -21.0. running mean: -18.77300568240992, timestamp: 2022-08-20 03:41:23.752752\n",
      "resetting env. episode 7347, reward total was -17.0. running mean: -18.755275625585824, timestamp: 2022-08-20 03:41:30.235726\n",
      "resetting env. episode 7348, reward total was -20.0. running mean: -18.767722869329965, timestamp: 2022-08-20 03:41:33.760107\n",
      "resetting env. episode 7349, reward total was -19.0. running mean: -18.770045640636667, timestamp: 2022-08-20 03:41:38.872345\n",
      "resetting env. episode 7350, reward total was -20.0. running mean: -18.782345184230298, timestamp: 2022-08-20 03:41:43.455403\n",
      "resetting env. episode 7351, reward total was -20.0. running mean: -18.794521732387995, timestamp: 2022-08-20 03:41:48.748364\n",
      "resetting env. episode 7352, reward total was -20.0. running mean: -18.806576515064116, timestamp: 2022-08-20 03:41:53.406820\n",
      "resetting env. episode 7353, reward total was -20.0. running mean: -18.818510749913475, timestamp: 2022-08-20 03:41:59.541634\n",
      "resetting env. episode 7354, reward total was -18.0. running mean: -18.81032564241434, timestamp: 2022-08-20 03:42:05.756102\n",
      "resetting env. episode 7355, reward total was -17.0. running mean: -18.7922223859902, timestamp: 2022-08-20 03:42:11.475356\n",
      "resetting env. episode 7356, reward total was -19.0. running mean: -18.7943001621303, timestamp: 2022-08-20 03:42:18.246658\n",
      "resetting env. episode 7357, reward total was -18.0. running mean: -18.786357160508995, timestamp: 2022-08-20 03:42:23.177379\n",
      "resetting env. episode 7358, reward total was -19.0. running mean: -18.788493588903908, timestamp: 2022-08-20 03:42:28.616159\n",
      "resetting env. episode 7359, reward total was -21.0. running mean: -18.81060865301487, timestamp: 2022-08-20 03:42:34.692285\n",
      "resetting env. episode 7360, reward total was -17.0. running mean: -18.792502566484725, timestamp: 2022-08-20 03:42:41.001740\n",
      "resetting env. episode 7361, reward total was -19.0. running mean: -18.79457754081988, timestamp: 2022-08-20 03:42:46.242418\n",
      "resetting env. episode 7362, reward total was -18.0. running mean: -18.78663176541168, timestamp: 2022-08-20 03:42:50.930777\n",
      "resetting env. episode 7363, reward total was -20.0. running mean: -18.798765447757564, timestamp: 2022-08-20 03:42:56.717200\n",
      "resetting env. episode 7364, reward total was -19.0. running mean: -18.80077779327999, timestamp: 2022-08-20 03:43:01.986785\n",
      "resetting env. episode 7365, reward total was -19.0. running mean: -18.802770015347193, timestamp: 2022-08-20 03:43:07.218437\n",
      "resetting env. episode 7366, reward total was -18.0. running mean: -18.79474231519372, timestamp: 2022-08-20 03:43:13.044209\n",
      "resetting env. episode 7367, reward total was -19.0. running mean: -18.796794892041785, timestamp: 2022-08-20 03:43:18.530879\n",
      "resetting env. episode 7368, reward total was -18.0. running mean: -18.788826943121368, timestamp: 2022-08-20 03:43:23.662727\n",
      "resetting env. episode 7369, reward total was -18.0. running mean: -18.780938673690155, timestamp: 2022-08-20 03:43:29.354724\n",
      "resetting env. episode 7370, reward total was -16.0. running mean: -18.753129286953254, timestamp: 2022-08-20 03:43:36.571044\n",
      "resetting env. episode 7371, reward total was -20.0. running mean: -18.76559799408372, timestamp: 2022-08-20 03:43:42.114626\n",
      "resetting env. episode 7372, reward total was -16.0. running mean: -18.73794201414288, timestamp: 2022-08-20 03:43:49.074148\n",
      "resetting env. episode 7373, reward total was -18.0. running mean: -18.73056259400145, timestamp: 2022-08-20 03:43:54.229621\n",
      "resetting env. episode 7374, reward total was -18.0. running mean: -18.72325696806144, timestamp: 2022-08-20 03:43:58.976932\n",
      "resetting env. episode 7375, reward total was -17.0. running mean: -18.706024398380826, timestamp: 2022-08-20 03:44:06.887438\n",
      "resetting env. episode 7376, reward total was -21.0. running mean: -18.72896415439702, timestamp: 2022-08-20 03:44:13.092613\n",
      "resetting env. episode 7377, reward total was -19.0. running mean: -18.73167451285305, timestamp: 2022-08-20 03:44:19.251243\n",
      "resetting env. episode 7378, reward total was -19.0. running mean: -18.73435776772452, timestamp: 2022-08-20 03:44:27.807017\n",
      "resetting env. episode 7379, reward total was -15.0. running mean: -18.697014190047273, timestamp: 2022-08-20 03:44:36.696299\n",
      "resetting env. episode 7380, reward total was -16.0. running mean: -18.6700440481468, timestamp: 2022-08-20 03:44:43.053420\n",
      "resetting env. episode 7381, reward total was -17.0. running mean: -18.653343607665335, timestamp: 2022-08-20 03:44:49.100381\n",
      "resetting env. episode 7382, reward total was -17.0. running mean: -18.63681017158868, timestamp: 2022-08-20 03:44:59.312406\n",
      "resetting env. episode 7383, reward total was -21.0. running mean: -18.660442069872797, timestamp: 2022-08-20 03:45:09.861284\n",
      "resetting env. episode 7384, reward total was -21.0. running mean: -18.68383764917407, timestamp: 2022-08-20 03:45:20.453099\n",
      "resetting env. episode 7385, reward total was -20.0. running mean: -18.696999272682326, timestamp: 2022-08-20 03:45:29.715977\n",
      "resetting env. episode 7386, reward total was -19.0. running mean: -18.700029279955505, timestamp: 2022-08-20 03:45:36.705534\n",
      "resetting env. episode 7387, reward total was -20.0. running mean: -18.713028987155948, timestamp: 2022-08-20 03:45:43.232228\n",
      "resetting env. episode 7388, reward total was -19.0. running mean: -18.715898697284388, timestamp: 2022-08-20 03:45:49.528529\n",
      "resetting env. episode 7389, reward total was -19.0. running mean: -18.718739710311546, timestamp: 2022-08-20 03:45:56.616563\n",
      "resetting env. episode 7390, reward total was -21.0. running mean: -18.74155231320843, timestamp: 2022-08-20 03:46:02.675676\n",
      "resetting env. episode 7391, reward total was -21.0. running mean: -18.764136790076346, timestamp: 2022-08-20 03:46:09.033298\n",
      "resetting env. episode 7392, reward total was -17.0. running mean: -18.746495422175585, timestamp: 2022-08-20 03:46:16.084444\n",
      "resetting env. episode 7393, reward total was -18.0. running mean: -18.739030467953828, timestamp: 2022-08-20 03:46:24.617519\n",
      "resetting env. episode 7394, reward total was -16.0. running mean: -18.71164016327429, timestamp: 2022-08-20 03:46:32.668432\n",
      "resetting env. episode 7395, reward total was -16.0. running mean: -18.684523761641547, timestamp: 2022-08-20 03:46:41.555658\n",
      "resetting env. episode 7396, reward total was -17.0. running mean: -18.66767852402513, timestamp: 2022-08-20 03:46:48.926430\n",
      "resetting env. episode 7397, reward total was -19.0. running mean: -18.67100173878488, timestamp: 2022-08-20 03:46:55.959488\n",
      "resetting env. episode 7398, reward total was -20.0. running mean: -18.68429172139703, timestamp: 2022-08-20 03:47:03.693360\n",
      "resetting env. episode 7399, reward total was -20.0. running mean: -18.69744880418306, timestamp: 2022-08-20 03:47:10.728053\n",
      "resetting env. episode 7400, reward total was -18.0. running mean: -18.69047431614123, timestamp: 2022-08-20 03:47:20.687061\n",
      "resetting env. episode 7401, reward total was -17.0. running mean: -18.67356957297982, timestamp: 2022-08-20 03:47:28.378282\n",
      "resetting env. episode 7402, reward total was -19.0. running mean: -18.676833877250022, timestamp: 2022-08-20 03:47:36.289269\n",
      "resetting env. episode 7403, reward total was -17.0. running mean: -18.660065538477525, timestamp: 2022-08-20 03:47:45.266345\n",
      "resetting env. episode 7404, reward total was -19.0. running mean: -18.66346488309275, timestamp: 2022-08-20 03:47:51.928216\n",
      "resetting env. episode 7405, reward total was -21.0. running mean: -18.686830234261823, timestamp: 2022-08-20 03:48:00.049674\n",
      "resetting env. episode 7406, reward total was -21.0. running mean: -18.709961931919207, timestamp: 2022-08-20 03:48:05.596768\n",
      "resetting env. episode 7407, reward total was -21.0. running mean: -18.732862312600016, timestamp: 2022-08-20 03:48:12.149822\n",
      "resetting env. episode 7408, reward total was -14.0. running mean: -18.685533689474017, timestamp: 2022-08-20 03:48:19.545640\n",
      "resetting env. episode 7409, reward total was -18.0. running mean: -18.678678352579276, timestamp: 2022-08-20 03:48:28.154787\n",
      "resetting env. episode 7410, reward total was -19.0. running mean: -18.681891569053484, timestamp: 2022-08-20 03:48:36.867939\n",
      "resetting env. episode 7411, reward total was -21.0. running mean: -18.70507265336295, timestamp: 2022-08-20 03:48:44.290378\n",
      "resetting env. episode 7412, reward total was -18.0. running mean: -18.69802192682932, timestamp: 2022-08-20 03:48:50.946224\n",
      "resetting env. episode 7413, reward total was -18.0. running mean: -18.691041707561027, timestamp: 2022-08-20 03:49:00.177839\n",
      "resetting env. episode 7414, reward total was -21.0. running mean: -18.71413129048542, timestamp: 2022-08-20 03:49:05.969593\n",
      "resetting env. episode 7415, reward total was -20.0. running mean: -18.726989977580565, timestamp: 2022-08-20 03:49:12.278052\n",
      "resetting env. episode 7416, reward total was -19.0. running mean: -18.72972007780476, timestamp: 2022-08-20 03:49:21.103947\n",
      "resetting env. episode 7417, reward total was -18.0. running mean: -18.722422877026712, timestamp: 2022-08-20 03:49:28.388604\n",
      "resetting env. episode 7418, reward total was -19.0. running mean: -18.725198648256445, timestamp: 2022-08-20 03:49:38.446484\n",
      "resetting env. episode 7419, reward total was -15.0. running mean: -18.68794666177388, timestamp: 2022-08-20 03:49:47.388247\n",
      "resetting env. episode 7420, reward total was -19.0. running mean: -18.69106719515614, timestamp: 2022-08-20 03:49:56.774969\n",
      "resetting env. episode 7421, reward total was -21.0. running mean: -18.71415652320458, timestamp: 2022-08-20 03:50:04.984766\n",
      "resetting env. episode 7422, reward total was -16.0. running mean: -18.687014957972533, timestamp: 2022-08-20 03:50:13.258549\n",
      "resetting env. episode 7423, reward total was -19.0. running mean: -18.69014480839281, timestamp: 2022-08-20 03:50:19.086669\n",
      "resetting env. episode 7424, reward total was -15.0. running mean: -18.653243360308878, timestamp: 2022-08-20 03:50:29.920697\n",
      "resetting env. episode 7425, reward total was -21.0. running mean: -18.67671092670579, timestamp: 2022-08-20 03:50:37.774050\n",
      "resetting env. episode 7426, reward total was -19.0. running mean: -18.679943817438733, timestamp: 2022-08-20 03:50:45.042334\n",
      "resetting env. episode 7427, reward total was -15.0. running mean: -18.643144379264346, timestamp: 2022-08-20 03:50:54.692763\n",
      "resetting env. episode 7428, reward total was -20.0. running mean: -18.656712935471703, timestamp: 2022-08-20 03:51:00.499584\n",
      "resetting env. episode 7429, reward total was -17.0. running mean: -18.640145806116987, timestamp: 2022-08-20 03:51:06.241666\n",
      "resetting env. episode 7430, reward total was -21.0. running mean: -18.66374434805582, timestamp: 2022-08-20 03:51:11.246062\n",
      "resetting env. episode 7431, reward total was -19.0. running mean: -18.66710690457526, timestamp: 2022-08-20 03:51:17.474243\n",
      "resetting env. episode 7432, reward total was -19.0. running mean: -18.670435835529506, timestamp: 2022-08-20 03:51:23.569425\n",
      "resetting env. episode 7433, reward total was -14.0. running mean: -18.62373147717421, timestamp: 2022-08-20 03:51:31.470376\n",
      "resetting env. episode 7434, reward total was -19.0. running mean: -18.62749416240247, timestamp: 2022-08-20 03:51:41.211966\n",
      "resetting env. episode 7435, reward total was -20.0. running mean: -18.641219220778446, timestamp: 2022-08-20 03:51:47.244654\n",
      "resetting env. episode 7436, reward total was -16.0. running mean: -18.61480702857066, timestamp: 2022-08-20 03:51:55.402816\n",
      "resetting env. episode 7437, reward total was -21.0. running mean: -18.638658958284953, timestamp: 2022-08-20 03:52:04.133990\n",
      "resetting env. episode 7438, reward total was -19.0. running mean: -18.642272368702105, timestamp: 2022-08-20 03:52:11.111295\n",
      "resetting env. episode 7439, reward total was -19.0. running mean: -18.645849645015087, timestamp: 2022-08-20 03:52:20.760572\n",
      "resetting env. episode 7440, reward total was -20.0. running mean: -18.659391148564936, timestamp: 2022-08-20 03:52:27.269391\n",
      "resetting env. episode 7441, reward total was -20.0. running mean: -18.672797237079287, timestamp: 2022-08-20 03:52:33.347005\n",
      "resetting env. episode 7442, reward total was -21.0. running mean: -18.696069264708495, timestamp: 2022-08-20 03:52:38.617291\n",
      "resetting env. episode 7443, reward total was -20.0. running mean: -18.70910857206141, timestamp: 2022-08-20 03:52:44.592586\n",
      "resetting env. episode 7444, reward total was -18.0. running mean: -18.702017486340797, timestamp: 2022-08-20 03:52:51.792312\n",
      "resetting env. episode 7445, reward total was -20.0. running mean: -18.714997311477386, timestamp: 2022-08-20 03:52:58.098472\n",
      "resetting env. episode 7446, reward total was -20.0. running mean: -18.72784733836261, timestamp: 2022-08-20 03:53:03.893700\n",
      "resetting env. episode 7447, reward total was -17.0. running mean: -18.71056886497899, timestamp: 2022-08-20 03:53:10.779102\n",
      "resetting env. episode 7448, reward total was -18.0. running mean: -18.703463176329198, timestamp: 2022-08-20 03:53:17.819577\n",
      "resetting env. episode 7449, reward total was -16.0. running mean: -18.676428544565905, timestamp: 2022-08-20 03:53:26.563592\n",
      "resetting env. episode 7450, reward total was -21.0. running mean: -18.699664259120247, timestamp: 2022-08-20 03:53:34.677142\n",
      "resetting env. episode 7451, reward total was -18.0. running mean: -18.692667616529043, timestamp: 2022-08-20 03:53:42.242629\n",
      "resetting env. episode 7452, reward total was -19.0. running mean: -18.695740940363752, timestamp: 2022-08-20 03:53:49.253648\n",
      "resetting env. episode 7453, reward total was -19.0. running mean: -18.698783530960117, timestamp: 2022-08-20 03:53:54.622105\n",
      "resetting env. episode 7454, reward total was -18.0. running mean: -18.691795695650516, timestamp: 2022-08-20 03:54:01.636777\n",
      "resetting env. episode 7455, reward total was -21.0. running mean: -18.71487773869401, timestamp: 2022-08-20 03:54:08.221525\n",
      "resetting env. episode 7456, reward total was -18.0. running mean: -18.70772896130707, timestamp: 2022-08-20 03:54:14.268852\n",
      "resetting env. episode 7457, reward total was -19.0. running mean: -18.710651671694, timestamp: 2022-08-20 03:54:24.134646\n",
      "resetting env. episode 7458, reward total was -18.0. running mean: -18.703545154977057, timestamp: 2022-08-20 03:54:38.163797\n",
      "resetting env. episode 7459, reward total was -19.0. running mean: -18.706509703427287, timestamp: 2022-08-20 03:54:50.773231\n",
      "resetting env. episode 7460, reward total was -15.0. running mean: -18.66944460639301, timestamp: 2022-08-20 03:55:04.096269\n",
      "resetting env. episode 7461, reward total was -19.0. running mean: -18.67275016032908, timestamp: 2022-08-20 03:55:14.179297\n",
      "resetting env. episode 7462, reward total was -18.0. running mean: -18.66602265872579, timestamp: 2022-08-20 03:55:22.422210\n",
      "resetting env. episode 7463, reward total was -19.0. running mean: -18.669362432138534, timestamp: 2022-08-20 03:55:31.032708\n",
      "resetting env. episode 7464, reward total was -19.0. running mean: -18.67266880781715, timestamp: 2022-08-20 03:55:41.938806\n",
      "resetting env. episode 7465, reward total was -19.0. running mean: -18.67594211973898, timestamp: 2022-08-20 03:55:50.393976\n",
      "resetting env. episode 7466, reward total was -21.0. running mean: -18.69918269854159, timestamp: 2022-08-20 03:55:57.660786\n",
      "resetting env. episode 7467, reward total was -20.0. running mean: -18.712190871556174, timestamp: 2022-08-20 03:56:04.513907\n",
      "resetting env. episode 7468, reward total was -20.0. running mean: -18.725068962840613, timestamp: 2022-08-20 03:56:10.303281\n",
      "resetting env. episode 7469, reward total was -19.0. running mean: -18.727818273212208, timestamp: 2022-08-20 03:56:18.234834\n",
      "resetting env. episode 7470, reward total was -19.0. running mean: -18.730540090480087, timestamp: 2022-08-20 03:56:25.393313\n",
      "resetting env. episode 7471, reward total was -15.0. running mean: -18.693234689575284, timestamp: 2022-08-20 03:56:33.795603\n",
      "resetting env. episode 7472, reward total was -17.0. running mean: -18.676302342679534, timestamp: 2022-08-20 03:56:41.563413\n",
      "resetting env. episode 7473, reward total was -21.0. running mean: -18.69953931925274, timestamp: 2022-08-20 03:56:47.626974\n",
      "resetting env. episode 7474, reward total was -21.0. running mean: -18.72254392606021, timestamp: 2022-08-20 03:56:53.404757\n",
      "resetting env. episode 7475, reward total was -19.0. running mean: -18.725318486799612, timestamp: 2022-08-20 03:56:58.014612\n",
      "resetting env. episode 7476, reward total was -20.0. running mean: -18.738065301931616, timestamp: 2022-08-20 03:57:04.800044\n",
      "resetting env. episode 7477, reward total was -19.0. running mean: -18.7406846489123, timestamp: 2022-08-20 03:57:11.943790\n",
      "resetting env. episode 7478, reward total was -15.0. running mean: -18.703277802423177, timestamp: 2022-08-20 03:57:18.187580\n",
      "resetting env. episode 7479, reward total was -20.0. running mean: -18.716245024398944, timestamp: 2022-08-20 03:57:24.417336\n",
      "resetting env. episode 7480, reward total was -21.0. running mean: -18.739082574154956, timestamp: 2022-08-20 03:57:30.466923\n",
      "resetting env. episode 7481, reward total was -20.0. running mean: -18.751691748413407, timestamp: 2022-08-20 03:57:36.690265\n",
      "resetting env. episode 7482, reward total was -20.0. running mean: -18.76417483092927, timestamp: 2022-08-20 03:57:42.897517\n",
      "resetting env. episode 7483, reward total was -21.0. running mean: -18.78653308261998, timestamp: 2022-08-20 03:57:48.634507\n",
      "resetting env. episode 7484, reward total was -19.0. running mean: -18.78866775179378, timestamp: 2022-08-20 03:57:55.433897\n",
      "resetting env. episode 7485, reward total was -19.0. running mean: -18.790781074275845, timestamp: 2022-08-20 03:58:02.176658\n",
      "resetting env. episode 7486, reward total was -21.0. running mean: -18.81287326353309, timestamp: 2022-08-20 03:58:09.150259\n",
      "resetting env. episode 7487, reward total was -19.0. running mean: -18.81474453089776, timestamp: 2022-08-20 03:58:17.011651\n",
      "resetting env. episode 7488, reward total was -19.0. running mean: -18.816597085588782, timestamp: 2022-08-20 03:58:23.534759\n",
      "resetting env. episode 7489, reward total was -18.0. running mean: -18.808431114732894, timestamp: 2022-08-20 03:58:30.063706\n",
      "resetting env. episode 7490, reward total was -18.0. running mean: -18.800346803585565, timestamp: 2022-08-20 03:58:37.678247\n",
      "resetting env. episode 7491, reward total was -21.0. running mean: -18.82234333554971, timestamp: 2022-08-20 03:58:42.129078\n",
      "resetting env. episode 7492, reward total was -19.0. running mean: -18.824119902194216, timestamp: 2022-08-20 03:58:52.627951\n",
      "resetting env. episode 7493, reward total was -19.0. running mean: -18.825878703172275, timestamp: 2022-08-20 03:59:01.752228\n",
      "resetting env. episode 7494, reward total was -17.0. running mean: -18.807619916140553, timestamp: 2022-08-20 03:59:15.467940\n",
      "resetting env. episode 7495, reward total was -21.0. running mean: -18.82954371697915, timestamp: 2022-08-20 03:59:28.819492\n",
      "resetting env. episode 7496, reward total was -17.0. running mean: -18.81124827980936, timestamp: 2022-08-20 03:59:37.235277\n",
      "resetting env. episode 7497, reward total was -18.0. running mean: -18.803135797011265, timestamp: 2022-08-20 03:59:46.865202\n",
      "resetting env. episode 7498, reward total was -19.0. running mean: -18.805104439041152, timestamp: 2022-08-20 04:00:03.956498\n",
      "resetting env. episode 7499, reward total was -16.0. running mean: -18.77705339465074, timestamp: 2022-08-20 04:00:21.846231\n",
      "resetting env. episode 7500, reward total was -19.0. running mean: -18.77928286070423, timestamp: 2022-08-20 04:00:38.208758\n",
      "resetting env. episode 7501, reward total was -19.0. running mean: -18.781490032097192, timestamp: 2022-08-20 04:00:46.614093\n",
      "resetting env. episode 7502, reward total was -19.0. running mean: -18.78367513177622, timestamp: 2022-08-20 04:00:59.090230\n",
      "resetting env. episode 7503, reward total was -15.0. running mean: -18.74583838045846, timestamp: 2022-08-20 04:01:09.431624\n",
      "resetting env. episode 7504, reward total was -16.0. running mean: -18.718379996653873, timestamp: 2022-08-20 04:01:19.011316\n",
      "resetting env. episode 7505, reward total was -18.0. running mean: -18.711196196687332, timestamp: 2022-08-20 04:01:25.728730\n",
      "resetting env. episode 7506, reward total was -21.0. running mean: -18.73408423472046, timestamp: 2022-08-20 04:01:32.278406\n",
      "resetting env. episode 7507, reward total was -16.0. running mean: -18.706743392373255, timestamp: 2022-08-20 04:01:37.628282\n",
      "resetting env. episode 7508, reward total was -15.0. running mean: -18.66967595844952, timestamp: 2022-08-20 04:01:43.381397\n",
      "resetting env. episode 7509, reward total was -17.0. running mean: -18.652979198865026, timestamp: 2022-08-20 04:01:49.321036\n",
      "resetting env. episode 7510, reward total was -20.0. running mean: -18.666449406876374, timestamp: 2022-08-20 04:01:54.016196\n",
      "resetting env. episode 7511, reward total was -18.0. running mean: -18.65978491280761, timestamp: 2022-08-20 04:02:01.217224\n",
      "resetting env. episode 7512, reward total was -20.0. running mean: -18.67318706367953, timestamp: 2022-08-20 04:02:09.047749\n",
      "resetting env. episode 7513, reward total was -19.0. running mean: -18.676455193042738, timestamp: 2022-08-20 04:02:16.446553\n",
      "resetting env. episode 7514, reward total was -18.0. running mean: -18.66969064111231, timestamp: 2022-08-20 04:02:22.434700\n",
      "resetting env. episode 7515, reward total was -21.0. running mean: -18.69299373470119, timestamp: 2022-08-20 04:02:27.992885\n",
      "resetting env. episode 7516, reward total was -16.0. running mean: -18.666063797354177, timestamp: 2022-08-20 04:02:33.699353\n",
      "resetting env. episode 7517, reward total was -18.0. running mean: -18.659403159380634, timestamp: 2022-08-20 04:02:41.448352\n",
      "resetting env. episode 7518, reward total was -21.0. running mean: -18.68280912778683, timestamp: 2022-08-20 04:02:46.739008\n",
      "resetting env. episode 7519, reward total was -17.0. running mean: -18.665981036508963, timestamp: 2022-08-20 04:02:51.128893\n",
      "resetting env. episode 7520, reward total was -18.0. running mean: -18.659321226143874, timestamp: 2022-08-20 04:02:56.368813\n",
      "resetting env. episode 7521, reward total was -19.0. running mean: -18.662728013882436, timestamp: 2022-08-20 04:03:00.737297\n",
      "resetting env. episode 7522, reward total was -11.0. running mean: -18.58610073374361, timestamp: 2022-08-20 04:03:07.799708\n",
      "resetting env. episode 7523, reward total was -18.0. running mean: -18.580239726406173, timestamp: 2022-08-20 04:03:13.852010\n",
      "resetting env. episode 7524, reward total was -17.0. running mean: -18.564437329142113, timestamp: 2022-08-20 04:03:18.736145\n",
      "resetting env. episode 7525, reward total was -20.0. running mean: -18.57879295585069, timestamp: 2022-08-20 04:03:23.137082\n",
      "resetting env. episode 7526, reward total was -20.0. running mean: -18.593005026292182, timestamp: 2022-08-20 04:03:30.357137\n",
      "resetting env. episode 7527, reward total was -18.0. running mean: -18.58707497602926, timestamp: 2022-08-20 04:03:36.597811\n",
      "resetting env. episode 7528, reward total was -18.0. running mean: -18.581204226268966, timestamp: 2022-08-20 04:03:41.328234\n",
      "resetting env. episode 7529, reward total was -19.0. running mean: -18.585392184006277, timestamp: 2022-08-20 04:03:46.502107\n",
      "resetting env. episode 7530, reward total was -19.0. running mean: -18.589538262166215, timestamp: 2022-08-20 04:03:52.379411\n",
      "resetting env. episode 7531, reward total was -16.0. running mean: -18.563642879544552, timestamp: 2022-08-20 04:03:59.329801\n",
      "resetting env. episode 7532, reward total was -19.0. running mean: -18.56800645074911, timestamp: 2022-08-20 04:04:04.815202\n",
      "resetting env. episode 7533, reward total was -19.0. running mean: -18.57232638624162, timestamp: 2022-08-20 04:04:10.531088\n",
      "resetting env. episode 7534, reward total was -19.0. running mean: -18.576603122379204, timestamp: 2022-08-20 04:04:14.983984\n",
      "resetting env. episode 7535, reward total was -20.0. running mean: -18.59083709115541, timestamp: 2022-08-20 04:04:19.525736\n",
      "resetting env. episode 7536, reward total was -16.0. running mean: -18.564928720243856, timestamp: 2022-08-20 04:04:25.078557\n",
      "resetting env. episode 7537, reward total was -17.0. running mean: -18.54927943304142, timestamp: 2022-08-20 04:04:30.038009\n",
      "resetting env. episode 7538, reward total was -18.0. running mean: -18.543786638711005, timestamp: 2022-08-20 04:04:34.577010\n",
      "resetting env. episode 7539, reward total was -18.0. running mean: -18.538348772323893, timestamp: 2022-08-20 04:04:39.055541\n",
      "resetting env. episode 7540, reward total was -21.0. running mean: -18.562965284600654, timestamp: 2022-08-20 04:04:42.760096\n",
      "resetting env. episode 7541, reward total was -19.0. running mean: -18.56733563175465, timestamp: 2022-08-20 04:04:47.504280\n",
      "resetting env. episode 7542, reward total was -16.0. running mean: -18.5416622754371, timestamp: 2022-08-20 04:04:52.303403\n",
      "resetting env. episode 7543, reward total was -21.0. running mean: -18.56624565268273, timestamp: 2022-08-20 04:04:56.979918\n",
      "resetting env. episode 7544, reward total was -20.0. running mean: -18.580583196155903, timestamp: 2022-08-20 04:05:01.397745\n",
      "resetting env. episode 7545, reward total was -17.0. running mean: -18.564777364194345, timestamp: 2022-08-20 04:05:06.806908\n",
      "resetting env. episode 7546, reward total was -19.0. running mean: -18.569129590552404, timestamp: 2022-08-20 04:05:11.885553\n",
      "resetting env. episode 7547, reward total was -19.0. running mean: -18.57343829464688, timestamp: 2022-08-20 04:05:15.834899\n",
      "resetting env. episode 7548, reward total was -18.0. running mean: -18.567703911700413, timestamp: 2022-08-20 04:05:20.848551\n",
      "resetting env. episode 7549, reward total was -21.0. running mean: -18.59202687258341, timestamp: 2022-08-20 04:05:25.704699\n",
      "resetting env. episode 7550, reward total was -17.0. running mean: -18.57610660385758, timestamp: 2022-08-20 04:05:30.995165\n",
      "resetting env. episode 7551, reward total was -18.0. running mean: -18.570345537819, timestamp: 2022-08-20 04:05:35.833128\n",
      "resetting env. episode 7552, reward total was -21.0. running mean: -18.594642082440814, timestamp: 2022-08-20 04:05:42.789210\n",
      "resetting env. episode 7553, reward total was -19.0. running mean: -18.598695661616407, timestamp: 2022-08-20 04:05:50.246215\n",
      "resetting env. episode 7554, reward total was -13.0. running mean: -18.54270870500024, timestamp: 2022-08-20 04:05:57.957230\n",
      "resetting env. episode 7555, reward total was -19.0. running mean: -18.54728161795024, timestamp: 2022-08-20 04:06:05.597490\n",
      "resetting env. episode 7556, reward total was -19.0. running mean: -18.55180880177074, timestamp: 2022-08-20 04:06:12.145509\n",
      "resetting env. episode 7557, reward total was -21.0. running mean: -18.576290713753032, timestamp: 2022-08-20 04:06:18.858583\n",
      "resetting env. episode 7558, reward total was -18.0. running mean: -18.5705278066155, timestamp: 2022-08-20 04:06:26.346812\n",
      "resetting env. episode 7559, reward total was -16.0. running mean: -18.544822528549346, timestamp: 2022-08-20 04:06:33.651470\n",
      "resetting env. episode 7560, reward total was -19.0. running mean: -18.549374303263853, timestamp: 2022-08-20 04:06:39.985252\n",
      "resetting env. episode 7561, reward total was -20.0. running mean: -18.563880560231215, timestamp: 2022-08-20 04:06:46.482896\n",
      "resetting env. episode 7562, reward total was -20.0. running mean: -18.578241754628902, timestamp: 2022-08-20 04:06:51.280056\n",
      "resetting env. episode 7563, reward total was -21.0. running mean: -18.602459337082614, timestamp: 2022-08-20 04:06:56.141139\n",
      "resetting env. episode 7564, reward total was -17.0. running mean: -18.586434743711788, timestamp: 2022-08-20 04:07:04.017865\n",
      "resetting env. episode 7565, reward total was -19.0. running mean: -18.59057039627467, timestamp: 2022-08-20 04:07:10.975208\n",
      "resetting env. episode 7566, reward total was -18.0. running mean: -18.584664692311925, timestamp: 2022-08-20 04:07:19.445472\n",
      "resetting env. episode 7567, reward total was -19.0. running mean: -18.588818045388805, timestamp: 2022-08-20 04:07:24.921456\n",
      "resetting env. episode 7568, reward total was -15.0. running mean: -18.552929864934917, timestamp: 2022-08-20 04:07:31.687336\n",
      "resetting env. episode 7569, reward total was -19.0. running mean: -18.55740056628557, timestamp: 2022-08-20 04:07:37.727267\n",
      "resetting env. episode 7570, reward total was -14.0. running mean: -18.511826560622715, timestamp: 2022-08-20 04:07:45.950662\n",
      "resetting env. episode 7571, reward total was -17.0. running mean: -18.49670829501649, timestamp: 2022-08-20 04:07:52.801761\n",
      "resetting env. episode 7572, reward total was -19.0. running mean: -18.501741212066324, timestamp: 2022-08-20 04:07:59.028901\n",
      "resetting env. episode 7573, reward total was -18.0. running mean: -18.49672379994566, timestamp: 2022-08-20 04:08:06.201911\n",
      "resetting env. episode 7574, reward total was -17.0. running mean: -18.481756561946206, timestamp: 2022-08-20 04:08:13.735962\n",
      "resetting env. episode 7575, reward total was -19.0. running mean: -18.486938996326746, timestamp: 2022-08-20 04:08:22.659597\n",
      "resetting env. episode 7576, reward total was -20.0. running mean: -18.502069606363477, timestamp: 2022-08-20 04:08:28.038124\n",
      "resetting env. episode 7577, reward total was -18.0. running mean: -18.497048910299842, timestamp: 2022-08-20 04:08:36.071305\n",
      "resetting env. episode 7578, reward total was -15.0. running mean: -18.462078421196843, timestamp: 2022-08-20 04:08:41.983507\n",
      "resetting env. episode 7579, reward total was -21.0. running mean: -18.487457636984875, timestamp: 2022-08-20 04:08:49.517083\n",
      "resetting env. episode 7580, reward total was -20.0. running mean: -18.502583060615024, timestamp: 2022-08-20 04:08:56.489082\n",
      "resetting env. episode 7581, reward total was -19.0. running mean: -18.507557230008874, timestamp: 2022-08-20 04:09:04.386065\n",
      "resetting env. episode 7582, reward total was -18.0. running mean: -18.502481657708785, timestamp: 2022-08-20 04:09:10.710684\n",
      "resetting env. episode 7583, reward total was -20.0. running mean: -18.517456841131697, timestamp: 2022-08-20 04:09:17.319203\n",
      "resetting env. episode 7584, reward total was -17.0. running mean: -18.502282272720382, timestamp: 2022-08-20 04:09:25.905107\n",
      "resetting env. episode 7585, reward total was -18.0. running mean: -18.497259449993177, timestamp: 2022-08-20 04:09:32.208883\n",
      "resetting env. episode 7586, reward total was -18.0. running mean: -18.492286855493244, timestamp: 2022-08-20 04:09:40.327698\n",
      "resetting env. episode 7587, reward total was -19.0. running mean: -18.497363986938314, timestamp: 2022-08-20 04:09:48.129074\n",
      "resetting env. episode 7588, reward total was -20.0. running mean: -18.51239034706893, timestamp: 2022-08-20 04:09:55.049753\n",
      "resetting env. episode 7589, reward total was -18.0. running mean: -18.50726644359824, timestamp: 2022-08-20 04:10:05.807146\n",
      "resetting env. episode 7590, reward total was -16.0. running mean: -18.48219377916226, timestamp: 2022-08-20 04:10:16.841416\n",
      "resetting env. episode 7591, reward total was -16.0. running mean: -18.457371841370637, timestamp: 2022-08-20 04:10:27.507686\n",
      "resetting env. episode 7592, reward total was -19.0. running mean: -18.462798122956933, timestamp: 2022-08-20 04:10:39.763331\n",
      "resetting env. episode 7593, reward total was -16.0. running mean: -18.438170141727362, timestamp: 2022-08-20 04:10:46.519669\n",
      "resetting env. episode 7594, reward total was -20.0. running mean: -18.45378844031009, timestamp: 2022-08-20 04:10:52.772016\n",
      "resetting env. episode 7595, reward total was -14.0. running mean: -18.409250555906986, timestamp: 2022-08-20 04:11:00.299995\n",
      "resetting env. episode 7596, reward total was -19.0. running mean: -18.415158050347916, timestamp: 2022-08-20 04:11:11.274596\n",
      "resetting env. episode 7597, reward total was -19.0. running mean: -18.42100646984444, timestamp: 2022-08-20 04:11:19.648019\n",
      "resetting env. episode 7598, reward total was -18.0. running mean: -18.416796405145995, timestamp: 2022-08-20 04:11:27.658167\n",
      "resetting env. episode 7599, reward total was -15.0. running mean: -18.382628441094532, timestamp: 2022-08-20 04:11:34.645743\n",
      "resetting env. episode 7600, reward total was -21.0. running mean: -18.40880215668359, timestamp: 2022-08-20 04:11:43.303684\n",
      "resetting env. episode 7601, reward total was -14.0. running mean: -18.364714135116753, timestamp: 2022-08-20 04:11:52.143447\n",
      "resetting env. episode 7602, reward total was -19.0. running mean: -18.371066993765588, timestamp: 2022-08-20 04:12:00.412881\n",
      "resetting env. episode 7603, reward total was -18.0. running mean: -18.36735632382793, timestamp: 2022-08-20 04:12:09.890066\n",
      "resetting env. episode 7604, reward total was -20.0. running mean: -18.38368276058965, timestamp: 2022-08-20 04:12:16.988568\n",
      "resetting env. episode 7605, reward total was -18.0. running mean: -18.379845932983752, timestamp: 2022-08-20 04:12:23.674714\n",
      "resetting env. episode 7606, reward total was -20.0. running mean: -18.396047473653912, timestamp: 2022-08-20 04:12:31.732208\n",
      "resetting env. episode 7607, reward total was -21.0. running mean: -18.422086998917372, timestamp: 2022-08-20 04:12:39.274151\n",
      "resetting env. episode 7608, reward total was -18.0. running mean: -18.417866128928196, timestamp: 2022-08-20 04:12:44.454903\n",
      "resetting env. episode 7609, reward total was -19.0. running mean: -18.423687467638917, timestamp: 2022-08-20 04:12:51.742621\n",
      "resetting env. episode 7610, reward total was -19.0. running mean: -18.429450592962528, timestamp: 2022-08-20 04:12:58.543518\n",
      "resetting env. episode 7611, reward total was -18.0. running mean: -18.425156087032903, timestamp: 2022-08-20 04:13:03.246236\n",
      "resetting env. episode 7612, reward total was -18.0. running mean: -18.420904526162573, timestamp: 2022-08-20 04:13:09.045535\n",
      "resetting env. episode 7613, reward total was -18.0. running mean: -18.416695480900948, timestamp: 2022-08-20 04:13:14.428600\n",
      "resetting env. episode 7614, reward total was -13.0. running mean: -18.36252852609194, timestamp: 2022-08-20 04:13:21.737172\n",
      "resetting env. episode 7615, reward total was -17.0. running mean: -18.34890324083102, timestamp: 2022-08-20 04:13:26.523273\n",
      "resetting env. episode 7616, reward total was -17.0. running mean: -18.335414208422712, timestamp: 2022-08-20 04:13:31.612373\n",
      "resetting env. episode 7617, reward total was -18.0. running mean: -18.332060066338485, timestamp: 2022-08-20 04:13:36.219347\n",
      "resetting env. episode 7618, reward total was -20.0. running mean: -18.3487394656751, timestamp: 2022-08-20 04:13:42.016644\n",
      "resetting env. episode 7619, reward total was -20.0. running mean: -18.365252071018347, timestamp: 2022-08-20 04:13:47.924936\n",
      "resetting env. episode 7620, reward total was -17.0. running mean: -18.351599550308165, timestamp: 2022-08-20 04:13:53.171395\n",
      "resetting env. episode 7621, reward total was -16.0. running mean: -18.328083554805083, timestamp: 2022-08-20 04:13:58.558943\n",
      "resetting env. episode 7622, reward total was -19.0. running mean: -18.334802719257034, timestamp: 2022-08-20 04:14:03.736186\n",
      "resetting env. episode 7623, reward total was -19.0. running mean: -18.341454692064463, timestamp: 2022-08-20 04:14:09.856549\n",
      "resetting env. episode 7624, reward total was -17.0. running mean: -18.32804014514382, timestamp: 2022-08-20 04:14:15.626312\n",
      "resetting env. episode 7625, reward total was -20.0. running mean: -18.344759743692382, timestamp: 2022-08-20 04:14:22.580554\n",
      "resetting env. episode 7626, reward total was -18.0. running mean: -18.341312146255458, timestamp: 2022-08-20 04:14:27.263455\n",
      "resetting env. episode 7627, reward total was -19.0. running mean: -18.347899024792905, timestamp: 2022-08-20 04:14:33.537555\n",
      "resetting env. episode 7628, reward total was -20.0. running mean: -18.364420034544974, timestamp: 2022-08-20 04:14:38.747671\n",
      "resetting env. episode 7629, reward total was -19.0. running mean: -18.370775834199524, timestamp: 2022-08-20 04:14:45.184579\n",
      "resetting env. episode 7630, reward total was -19.0. running mean: -18.37706807585753, timestamp: 2022-08-20 04:14:50.924719\n",
      "resetting env. episode 7631, reward total was -19.0. running mean: -18.383297395098957, timestamp: 2022-08-20 04:14:55.508355\n",
      "resetting env. episode 7632, reward total was -19.0. running mean: -18.38946442114797, timestamp: 2022-08-20 04:14:59.488671\n",
      "resetting env. episode 7633, reward total was -20.0. running mean: -18.40556977693649, timestamp: 2022-08-20 04:15:04.370961\n",
      "resetting env. episode 7634, reward total was -17.0. running mean: -18.391514079167123, timestamp: 2022-08-20 04:15:09.021029\n",
      "resetting env. episode 7635, reward total was -19.0. running mean: -18.397598938375452, timestamp: 2022-08-20 04:15:14.702748\n",
      "resetting env. episode 7636, reward total was -19.0. running mean: -18.4036229489917, timestamp: 2022-08-20 04:15:20.595733\n",
      "resetting env. episode 7637, reward total was -19.0. running mean: -18.409586719501785, timestamp: 2022-08-20 04:15:24.927801\n",
      "resetting env. episode 7638, reward total was -21.0. running mean: -18.435490852306767, timestamp: 2022-08-20 04:15:29.183784\n",
      "resetting env. episode 7639, reward total was -17.0. running mean: -18.4211359437837, timestamp: 2022-08-20 04:15:34.516889\n",
      "resetting env. episode 7640, reward total was -18.0. running mean: -18.416924584345864, timestamp: 2022-08-20 04:15:39.351904\n",
      "resetting env. episode 7641, reward total was -20.0. running mean: -18.432755338502403, timestamp: 2022-08-20 04:15:43.867942\n",
      "resetting env. episode 7642, reward total was -17.0. running mean: -18.41842778511738, timestamp: 2022-08-20 04:15:50.178390\n",
      "resetting env. episode 7643, reward total was -17.0. running mean: -18.40424350726621, timestamp: 2022-08-20 04:15:55.483415\n",
      "resetting env. episode 7644, reward total was -14.0. running mean: -18.360201072193547, timestamp: 2022-08-20 04:16:00.094500\n",
      "resetting env. episode 7645, reward total was -18.0. running mean: -18.356599061471613, timestamp: 2022-08-20 04:16:04.482854\n",
      "resetting env. episode 7646, reward total was -19.0. running mean: -18.363033070856897, timestamp: 2022-08-20 04:16:08.613222\n",
      "resetting env. episode 7647, reward total was -18.0. running mean: -18.359402740148326, timestamp: 2022-08-20 04:16:14.148105\n",
      "resetting env. episode 7648, reward total was -19.0. running mean: -18.365808712746844, timestamp: 2022-08-20 04:16:18.346718\n",
      "resetting env. episode 7649, reward total was -17.0. running mean: -18.352150625619377, timestamp: 2022-08-20 04:16:23.173847\n",
      "resetting env. episode 7650, reward total was -19.0. running mean: -18.358629119363183, timestamp: 2022-08-20 04:16:28.274925\n",
      "resetting env. episode 7651, reward total was -15.0. running mean: -18.32504282816955, timestamp: 2022-08-20 04:16:34.654857\n",
      "resetting env. episode 7652, reward total was -17.0. running mean: -18.311792399887857, timestamp: 2022-08-20 04:16:39.241035\n",
      "resetting env. episode 7653, reward total was -17.0. running mean: -18.29867447588898, timestamp: 2022-08-20 04:16:43.933621\n",
      "resetting env. episode 7654, reward total was -20.0. running mean: -18.31568773113009, timestamp: 2022-08-20 04:16:49.425860\n",
      "resetting env. episode 7655, reward total was -16.0. running mean: -18.29253085381879, timestamp: 2022-08-20 04:16:57.330510\n",
      "resetting env. episode 7656, reward total was -19.0. running mean: -18.299605545280603, timestamp: 2022-08-20 04:17:03.370016\n",
      "resetting env. episode 7657, reward total was -19.0. running mean: -18.306609489827796, timestamp: 2022-08-20 04:17:09.400618\n",
      "resetting env. episode 7658, reward total was -19.0. running mean: -18.313543394929518, timestamp: 2022-08-20 04:17:14.064271\n",
      "resetting env. episode 7659, reward total was -16.0. running mean: -18.29040796098022, timestamp: 2022-08-20 04:17:19.489840\n",
      "resetting env. episode 7660, reward total was -18.0. running mean: -18.28750388137042, timestamp: 2022-08-20 04:17:24.156599\n",
      "resetting env. episode 7661, reward total was -13.0. running mean: -18.234628842556713, timestamp: 2022-08-20 04:17:29.398162\n",
      "resetting env. episode 7662, reward total was -18.0. running mean: -18.232282554131146, timestamp: 2022-08-20 04:17:33.807947\n",
      "resetting env. episode 7663, reward total was -20.0. running mean: -18.249959728589833, timestamp: 2022-08-20 04:17:37.874197\n",
      "resetting env. episode 7664, reward total was -15.0. running mean: -18.217460131303934, timestamp: 2022-08-20 04:17:43.413607\n",
      "resetting env. episode 7665, reward total was -14.0. running mean: -18.175285529990894, timestamp: 2022-08-20 04:17:49.604634\n",
      "resetting env. episode 7666, reward total was -17.0. running mean: -18.163532674690988, timestamp: 2022-08-20 04:17:54.625951\n",
      "resetting env. episode 7667, reward total was -17.0. running mean: -18.15189734794408, timestamp: 2022-08-20 04:17:59.071450\n",
      "resetting env. episode 7668, reward total was -21.0. running mean: -18.180378374464638, timestamp: 2022-08-20 04:18:03.552149\n",
      "resetting env. episode 7669, reward total was -17.0. running mean: -18.16857459071999, timestamp: 2022-08-20 04:18:07.954403\n",
      "resetting env. episode 7670, reward total was -18.0. running mean: -18.166888844812792, timestamp: 2022-08-20 04:18:13.474212\n",
      "resetting env. episode 7671, reward total was -18.0. running mean: -18.165219956364663, timestamp: 2022-08-20 04:18:19.828712\n",
      "resetting env. episode 7672, reward total was -21.0. running mean: -18.193567756801016, timestamp: 2022-08-20 04:18:25.359577\n",
      "resetting env. episode 7673, reward total was -21.0. running mean: -18.221632079233007, timestamp: 2022-08-20 04:18:29.903844\n",
      "resetting env. episode 7674, reward total was -16.0. running mean: -18.199415758440676, timestamp: 2022-08-20 04:18:36.392234\n",
      "resetting env. episode 7675, reward total was -20.0. running mean: -18.21742160085627, timestamp: 2022-08-20 04:18:41.447447\n",
      "resetting env. episode 7676, reward total was -19.0. running mean: -18.22524738484771, timestamp: 2022-08-20 04:18:47.302226\n",
      "resetting env. episode 7677, reward total was -19.0. running mean: -18.23299491099923, timestamp: 2022-08-20 04:18:52.846266\n",
      "resetting env. episode 7678, reward total was -16.0. running mean: -18.21066496188924, timestamp: 2022-08-20 04:18:58.054656\n",
      "resetting env. episode 7679, reward total was -17.0. running mean: -18.19855831227035, timestamp: 2022-08-20 04:19:02.947177\n",
      "resetting env. episode 7680, reward total was -20.0. running mean: -18.216572729147646, timestamp: 2022-08-20 04:19:09.238291\n",
      "resetting env. episode 7681, reward total was -18.0. running mean: -18.21440700185617, timestamp: 2022-08-20 04:19:14.360079\n",
      "resetting env. episode 7682, reward total was -17.0. running mean: -18.20226293183761, timestamp: 2022-08-20 04:19:20.677813\n",
      "resetting env. episode 7683, reward total was -17.0. running mean: -18.190240302519236, timestamp: 2022-08-20 04:19:25.097253\n",
      "resetting env. episode 7684, reward total was -20.0. running mean: -18.208337899494044, timestamp: 2022-08-20 04:19:29.197912\n",
      "resetting env. episode 7685, reward total was -18.0. running mean: -18.206254520499105, timestamp: 2022-08-20 04:19:33.789706\n",
      "resetting env. episode 7686, reward total was -17.0. running mean: -18.194191975294114, timestamp: 2022-08-20 04:19:39.601115\n",
      "resetting env. episode 7687, reward total was -19.0. running mean: -18.202250055541175, timestamp: 2022-08-20 04:19:45.464388\n",
      "resetting env. episode 7688, reward total was -20.0. running mean: -18.22022755498576, timestamp: 2022-08-20 04:19:50.361583\n",
      "resetting env. episode 7689, reward total was -19.0. running mean: -18.228025279435904, timestamp: 2022-08-20 04:19:54.978807\n",
      "resetting env. episode 7690, reward total was -19.0. running mean: -18.235745026641546, timestamp: 2022-08-20 04:20:00.970731\n",
      "resetting env. episode 7691, reward total was -19.0. running mean: -18.24338757637513, timestamp: 2022-08-20 04:20:06.558683\n",
      "resetting env. episode 7692, reward total was -17.0. running mean: -18.23095370061138, timestamp: 2022-08-20 04:20:10.644078\n",
      "resetting env. episode 7693, reward total was -21.0. running mean: -18.25864416360527, timestamp: 2022-08-20 04:20:16.745770\n",
      "resetting env. episode 7694, reward total was -16.0. running mean: -18.236057721969214, timestamp: 2022-08-20 04:20:21.960573\n",
      "resetting env. episode 7695, reward total was -19.0. running mean: -18.24369714474952, timestamp: 2022-08-20 04:20:27.891831\n",
      "resetting env. episode 7696, reward total was -17.0. running mean: -18.23126017330203, timestamp: 2022-08-20 04:20:34.817538\n",
      "resetting env. episode 7697, reward total was -15.0. running mean: -18.198947571569008, timestamp: 2022-08-20 04:20:40.602368\n",
      "resetting env. episode 7698, reward total was -20.0. running mean: -18.216958095853318, timestamp: 2022-08-20 04:20:46.578298\n",
      "resetting env. episode 7699, reward total was -20.0. running mean: -18.234788514894785, timestamp: 2022-08-20 04:20:50.711633\n",
      "resetting env. episode 7700, reward total was -19.0. running mean: -18.242440629745836, timestamp: 2022-08-20 04:20:56.339315\n",
      "resetting env. episode 7701, reward total was -17.0. running mean: -18.23001622344838, timestamp: 2022-08-20 04:21:02.481770\n",
      "resetting env. episode 7702, reward total was -18.0. running mean: -18.227716061213897, timestamp: 2022-08-20 04:21:07.642572\n",
      "resetting env. episode 7703, reward total was -19.0. running mean: -18.23543890060176, timestamp: 2022-08-20 04:21:12.521781\n",
      "resetting env. episode 7704, reward total was -18.0. running mean: -18.23308451159574, timestamp: 2022-08-20 04:21:17.496020\n",
      "resetting env. episode 7705, reward total was -19.0. running mean: -18.240753666479787, timestamp: 2022-08-20 04:21:21.041243\n",
      "resetting env. episode 7706, reward total was -17.0. running mean: -18.22834612981499, timestamp: 2022-08-20 04:21:26.191921\n",
      "resetting env. episode 7707, reward total was -17.0. running mean: -18.21606266851684, timestamp: 2022-08-20 04:21:30.858252\n",
      "resetting env. episode 7708, reward total was -19.0. running mean: -18.223902041831675, timestamp: 2022-08-20 04:21:35.987871\n",
      "resetting env. episode 7709, reward total was -20.0. running mean: -18.241663021413355, timestamp: 2022-08-20 04:21:41.858021\n",
      "resetting env. episode 7710, reward total was -15.0. running mean: -18.20924639119922, timestamp: 2022-08-20 04:21:49.603308\n",
      "resetting env. episode 7711, reward total was -18.0. running mean: -18.207153927287226, timestamp: 2022-08-20 04:21:53.931116\n",
      "resetting env. episode 7712, reward total was -17.0. running mean: -18.195082388014356, timestamp: 2022-08-20 04:21:59.782665\n",
      "resetting env. episode 7713, reward total was -17.0. running mean: -18.183131564134214, timestamp: 2022-08-20 04:22:04.295252\n",
      "resetting env. episode 7714, reward total was -17.0. running mean: -18.171300248492873, timestamp: 2022-08-20 04:22:09.800788\n",
      "resetting env. episode 7715, reward total was -19.0. running mean: -18.179587246007944, timestamp: 2022-08-20 04:22:14.860247\n",
      "resetting env. episode 7716, reward total was -16.0. running mean: -18.157791373547866, timestamp: 2022-08-20 04:22:20.061453\n",
      "resetting env. episode 7717, reward total was -18.0. running mean: -18.15621345981239, timestamp: 2022-08-20 04:22:24.877222\n",
      "resetting env. episode 7718, reward total was -18.0. running mean: -18.154651325214264, timestamp: 2022-08-20 04:22:31.436766\n",
      "resetting env. episode 7719, reward total was -15.0. running mean: -18.12310481196212, timestamp: 2022-08-20 04:22:38.436933\n",
      "resetting env. episode 7720, reward total was -14.0. running mean: -18.0818737638425, timestamp: 2022-08-20 04:22:44.137047\n",
      "resetting env. episode 7721, reward total was -21.0. running mean: -18.111055026204074, timestamp: 2022-08-20 04:22:48.144386\n",
      "resetting env. episode 7722, reward total was -18.0. running mean: -18.109944475942033, timestamp: 2022-08-20 04:22:53.761611\n",
      "resetting env. episode 7723, reward total was -19.0. running mean: -18.118845031182612, timestamp: 2022-08-20 04:23:00.840621\n",
      "resetting env. episode 7724, reward total was -15.0. running mean: -18.087656580870785, timestamp: 2022-08-20 04:23:07.235653\n",
      "resetting env. episode 7725, reward total was -20.0. running mean: -18.106780015062075, timestamp: 2022-08-20 04:23:12.130675\n",
      "resetting env. episode 7726, reward total was -17.0. running mean: -18.095712214911455, timestamp: 2022-08-20 04:23:17.612610\n",
      "resetting env. episode 7727, reward total was -19.0. running mean: -18.104755092762343, timestamp: 2022-08-20 04:23:22.801573\n",
      "resetting env. episode 7728, reward total was -17.0. running mean: -18.09370754183472, timestamp: 2022-08-20 04:23:28.890054\n",
      "resetting env. episode 7729, reward total was -20.0. running mean: -18.11277046641637, timestamp: 2022-08-20 04:23:35.137210\n",
      "resetting env. episode 7730, reward total was -19.0. running mean: -18.12164276175221, timestamp: 2022-08-20 04:23:39.832977\n",
      "resetting env. episode 7731, reward total was -17.0. running mean: -18.11042633413469, timestamp: 2022-08-20 04:23:45.614212\n",
      "resetting env. episode 7732, reward total was -17.0. running mean: -18.099322070793345, timestamp: 2022-08-20 04:23:50.635876\n",
      "resetting env. episode 7733, reward total was -21.0. running mean: -18.128328850085413, timestamp: 2022-08-20 04:23:56.724237\n",
      "resetting env. episode 7734, reward total was -19.0. running mean: -18.13704556158456, timestamp: 2022-08-20 04:24:02.767999\n",
      "resetting env. episode 7735, reward total was -13.0. running mean: -18.085675105968715, timestamp: 2022-08-20 04:24:10.046966\n",
      "resetting env. episode 7736, reward total was -17.0. running mean: -18.07481835490903, timestamp: 2022-08-20 04:24:16.130721\n",
      "resetting env. episode 7737, reward total was -18.0. running mean: -18.07407017135994, timestamp: 2022-08-20 04:24:22.235707\n",
      "resetting env. episode 7738, reward total was -17.0. running mean: -18.06332946964634, timestamp: 2022-08-20 04:24:28.070650\n",
      "resetting env. episode 7739, reward total was -17.0. running mean: -18.05269617494988, timestamp: 2022-08-20 04:24:35.259224\n",
      "resetting env. episode 7740, reward total was -18.0. running mean: -18.05216921320038, timestamp: 2022-08-20 04:24:41.122500\n",
      "resetting env. episode 7741, reward total was -16.0. running mean: -18.031647521068376, timestamp: 2022-08-20 04:24:48.537845\n",
      "resetting env. episode 7742, reward total was -19.0. running mean: -18.041331045857692, timestamp: 2022-08-20 04:24:54.068101\n",
      "resetting env. episode 7743, reward total was -18.0. running mean: -18.040917735399116, timestamp: 2022-08-20 04:24:59.873196\n",
      "resetting env. episode 7744, reward total was -21.0. running mean: -18.070508558045127, timestamp: 2022-08-20 04:25:05.485270\n",
      "resetting env. episode 7745, reward total was -18.0. running mean: -18.069803472464674, timestamp: 2022-08-20 04:25:11.330764\n",
      "resetting env. episode 7746, reward total was -19.0. running mean: -18.07910543774003, timestamp: 2022-08-20 04:25:16.057770\n",
      "resetting env. episode 7747, reward total was -16.0. running mean: -18.058314383362628, timestamp: 2022-08-20 04:25:21.633096\n",
      "resetting env. episode 7748, reward total was -17.0. running mean: -18.047731239529003, timestamp: 2022-08-20 04:25:27.049452\n",
      "resetting env. episode 7749, reward total was -18.0. running mean: -18.047253927133713, timestamp: 2022-08-20 04:25:32.938928\n",
      "resetting env. episode 7750, reward total was -19.0. running mean: -18.056781387862376, timestamp: 2022-08-20 04:25:37.633997\n",
      "resetting env. episode 7751, reward total was -18.0. running mean: -18.05621357398375, timestamp: 2022-08-20 04:25:41.916359\n",
      "resetting env. episode 7752, reward total was -21.0. running mean: -18.085651438243914, timestamp: 2022-08-20 04:25:47.713745\n",
      "resetting env. episode 7753, reward total was -20.0. running mean: -18.104794923861473, timestamp: 2022-08-20 04:25:54.180759\n",
      "resetting env. episode 7754, reward total was -15.0. running mean: -18.073746974622857, timestamp: 2022-08-20 04:26:00.221346\n",
      "resetting env. episode 7755, reward total was -19.0. running mean: -18.083009504876628, timestamp: 2022-08-20 04:26:06.000668\n",
      "resetting env. episode 7756, reward total was -18.0. running mean: -18.082179409827862, timestamp: 2022-08-20 04:26:12.906542\n",
      "resetting env. episode 7757, reward total was -21.0. running mean: -18.111357615729585, timestamp: 2022-08-20 04:26:18.945062\n",
      "resetting env. episode 7758, reward total was -17.0. running mean: -18.10024403957229, timestamp: 2022-08-20 04:26:26.081288\n",
      "resetting env. episode 7759, reward total was -20.0. running mean: -18.119241599176565, timestamp: 2022-08-20 04:26:33.035841\n",
      "resetting env. episode 7760, reward total was -20.0. running mean: -18.138049183184798, timestamp: 2022-08-20 04:26:37.467344\n",
      "resetting env. episode 7761, reward total was -20.0. running mean: -18.156668691352948, timestamp: 2022-08-20 04:26:42.076640\n",
      "resetting env. episode 7762, reward total was -20.0. running mean: -18.175102004439417, timestamp: 2022-08-20 04:26:46.264562\n",
      "resetting env. episode 7763, reward total was -20.0. running mean: -18.19335098439502, timestamp: 2022-08-20 04:26:50.761634\n",
      "resetting env. episode 7764, reward total was -15.0. running mean: -18.16141747455107, timestamp: 2022-08-20 04:26:56.179337\n",
      "resetting env. episode 7765, reward total was -17.0. running mean: -18.14980329980556, timestamp: 2022-08-20 04:27:01.645909\n",
      "resetting env. episode 7766, reward total was -18.0. running mean: -18.1483052668075, timestamp: 2022-08-20 04:27:06.042222\n",
      "resetting env. episode 7767, reward total was -16.0. running mean: -18.126822214139427, timestamp: 2022-08-20 04:27:10.385539\n",
      "resetting env. episode 7768, reward total was -18.0. running mean: -18.125553991998032, timestamp: 2022-08-20 04:27:15.018317\n",
      "resetting env. episode 7769, reward total was -21.0. running mean: -18.154298452078052, timestamp: 2022-08-20 04:27:19.562462\n",
      "resetting env. episode 7770, reward total was -17.0. running mean: -18.142755467557272, timestamp: 2022-08-20 04:27:26.623887\n",
      "resetting env. episode 7771, reward total was -17.0. running mean: -18.1313279128817, timestamp: 2022-08-20 04:27:32.011680\n",
      "resetting env. episode 7772, reward total was -19.0. running mean: -18.140014633752887, timestamp: 2022-08-20 04:27:37.376379\n",
      "resetting env. episode 7773, reward total was -19.0. running mean: -18.148614487415358, timestamp: 2022-08-20 04:27:47.076252\n",
      "resetting env. episode 7774, reward total was -21.0. running mean: -18.177128342541206, timestamp: 2022-08-20 04:27:51.431091\n",
      "resetting env. episode 7775, reward total was -17.0. running mean: -18.165357059115795, timestamp: 2022-08-20 04:27:57.681535\n",
      "resetting env. episode 7776, reward total was -19.0. running mean: -18.173703488524637, timestamp: 2022-08-20 04:28:02.688417\n",
      "resetting env. episode 7777, reward total was -19.0. running mean: -18.181966453639394, timestamp: 2022-08-20 04:28:08.242769\n",
      "resetting env. episode 7778, reward total was -19.0. running mean: -18.190146789103, timestamp: 2022-08-20 04:28:13.972339\n",
      "resetting env. episode 7779, reward total was -17.0. running mean: -18.17824532121197, timestamp: 2022-08-20 04:28:18.763605\n",
      "resetting env. episode 7780, reward total was -19.0. running mean: -18.186462867999854, timestamp: 2022-08-20 04:28:24.718768\n",
      "resetting env. episode 7781, reward total was -17.0. running mean: -18.174598239319856, timestamp: 2022-08-20 04:28:31.710864\n",
      "resetting env. episode 7782, reward total was -19.0. running mean: -18.182852256926658, timestamp: 2022-08-20 04:28:38.735677\n",
      "resetting env. episode 7783, reward total was -21.0. running mean: -18.211023734357394, timestamp: 2022-08-20 04:28:44.496444\n",
      "resetting env. episode 7784, reward total was -19.0. running mean: -18.21891349701382, timestamp: 2022-08-20 04:28:51.080421\n",
      "resetting env. episode 7785, reward total was -19.0. running mean: -18.226724362043683, timestamp: 2022-08-20 04:28:56.095074\n",
      "resetting env. episode 7786, reward total was -21.0. running mean: -18.254457118423247, timestamp: 2022-08-20 04:29:00.186271\n",
      "resetting env. episode 7787, reward total was -17.0. running mean: -18.241912547239014, timestamp: 2022-08-20 04:29:05.838196\n",
      "resetting env. episode 7788, reward total was -17.0. running mean: -18.229493421766627, timestamp: 2022-08-20 04:29:10.338657\n",
      "resetting env. episode 7789, reward total was -19.0. running mean: -18.237198487548962, timestamp: 2022-08-20 04:29:14.409153\n",
      "resetting env. episode 7790, reward total was -14.0. running mean: -18.19482650267347, timestamp: 2022-08-20 04:29:20.855561\n",
      "resetting env. episode 7791, reward total was -21.0. running mean: -18.22287823764674, timestamp: 2022-08-20 04:29:27.508134\n",
      "resetting env. episode 7792, reward total was -20.0. running mean: -18.240649455270272, timestamp: 2022-08-20 04:29:32.315347\n",
      "resetting env. episode 7793, reward total was -19.0. running mean: -18.248242960717572, timestamp: 2022-08-20 04:29:39.019984\n",
      "resetting env. episode 7794, reward total was -18.0. running mean: -18.245760531110395, timestamp: 2022-08-20 04:29:46.411220\n",
      "resetting env. episode 7795, reward total was -18.0. running mean: -18.24330292579929, timestamp: 2022-08-20 04:29:53.156120\n",
      "resetting env. episode 7796, reward total was -21.0. running mean: -18.2708698965413, timestamp: 2022-08-20 04:29:58.481900\n",
      "resetting env. episode 7797, reward total was -13.0. running mean: -18.218161197575885, timestamp: 2022-08-20 04:30:03.984550\n",
      "resetting env. episode 7798, reward total was -15.0. running mean: -18.185979585600123, timestamp: 2022-08-20 04:30:11.380160\n",
      "resetting env. episode 7799, reward total was -19.0. running mean: -18.19411978974412, timestamp: 2022-08-20 04:30:18.842766\n",
      "resetting env. episode 7800, reward total was -17.0. running mean: -18.182178591846682, timestamp: 2022-08-20 04:30:24.756695\n",
      "resetting env. episode 7801, reward total was -19.0. running mean: -18.190356805928218, timestamp: 2022-08-20 04:30:29.722232\n",
      "resetting env. episode 7802, reward total was -18.0. running mean: -18.188453237868934, timestamp: 2022-08-20 04:30:35.138495\n",
      "resetting env. episode 7803, reward total was -21.0. running mean: -18.216568705490246, timestamp: 2022-08-20 04:30:40.881293\n",
      "resetting env. episode 7804, reward total was -19.0. running mean: -18.224403018435346, timestamp: 2022-08-20 04:30:46.061585\n",
      "resetting env. episode 7805, reward total was -14.0. running mean: -18.182158988250993, timestamp: 2022-08-20 04:30:52.772695\n",
      "resetting env. episode 7806, reward total was -19.0. running mean: -18.190337398368484, timestamp: 2022-08-20 04:30:58.221793\n",
      "resetting env. episode 7807, reward total was -17.0. running mean: -18.178434024384803, timestamp: 2022-08-20 04:31:02.478129\n",
      "resetting env. episode 7808, reward total was -15.0. running mean: -18.146649684140954, timestamp: 2022-08-20 04:31:09.278910\n",
      "resetting env. episode 7809, reward total was -19.0. running mean: -18.155183187299546, timestamp: 2022-08-20 04:31:14.197499\n",
      "resetting env. episode 7810, reward total was -17.0. running mean: -18.143631355426553, timestamp: 2022-08-20 04:31:19.228710\n",
      "resetting env. episode 7811, reward total was -12.0. running mean: -18.08219504187229, timestamp: 2022-08-20 04:31:25.259335\n",
      "resetting env. episode 7812, reward total was -16.0. running mean: -18.061373091453568, timestamp: 2022-08-20 04:31:32.544279\n",
      "resetting env. episode 7813, reward total was -21.0. running mean: -18.09075936053903, timestamp: 2022-08-20 04:31:37.037460\n",
      "resetting env. episode 7814, reward total was -19.0. running mean: -18.099851766933643, timestamp: 2022-08-20 04:31:43.488658\n",
      "resetting env. episode 7815, reward total was -18.0. running mean: -18.098853249264305, timestamp: 2022-08-20 04:31:48.111586\n",
      "resetting env. episode 7816, reward total was -20.0. running mean: -18.11786471677166, timestamp: 2022-08-20 04:31:54.213922\n",
      "resetting env. episode 7817, reward total was -20.0. running mean: -18.136686069603943, timestamp: 2022-08-20 04:32:00.447473\n",
      "resetting env. episode 7818, reward total was -16.0. running mean: -18.115319208907902, timestamp: 2022-08-20 04:32:06.246153\n",
      "resetting env. episode 7819, reward total was -19.0. running mean: -18.124166016818823, timestamp: 2022-08-20 04:32:12.387107\n",
      "resetting env. episode 7820, reward total was -18.0. running mean: -18.122924356650636, timestamp: 2022-08-20 04:32:19.457454\n",
      "resetting env. episode 7821, reward total was -19.0. running mean: -18.13169511308413, timestamp: 2022-08-20 04:32:26.811673\n",
      "resetting env. episode 7822, reward total was -21.0. running mean: -18.16037816195329, timestamp: 2022-08-20 04:32:32.682652\n",
      "resetting env. episode 7823, reward total was -20.0. running mean: -18.178774380333756, timestamp: 2022-08-20 04:32:37.958290\n",
      "resetting env. episode 7824, reward total was -19.0. running mean: -18.18698663653042, timestamp: 2022-08-20 04:32:42.323483\n",
      "resetting env. episode 7825, reward total was -19.0. running mean: -18.195116770165118, timestamp: 2022-08-20 04:32:48.123337\n",
      "resetting env. episode 7826, reward total was -18.0. running mean: -18.193165602463466, timestamp: 2022-08-20 04:32:54.697354\n",
      "resetting env. episode 7827, reward total was -19.0. running mean: -18.201233946438833, timestamp: 2022-08-20 04:32:59.949289\n",
      "resetting env. episode 7828, reward total was -16.0. running mean: -18.179221606974444, timestamp: 2022-08-20 04:33:06.588828\n",
      "resetting env. episode 7829, reward total was -17.0. running mean: -18.1674293909047, timestamp: 2022-08-20 04:33:12.177523\n",
      "resetting env. episode 7830, reward total was -20.0. running mean: -18.185755096995653, timestamp: 2022-08-20 04:33:17.514472\n",
      "resetting env. episode 7831, reward total was -15.0. running mean: -18.153897546025696, timestamp: 2022-08-20 04:33:25.498634\n",
      "resetting env. episode 7832, reward total was -20.0. running mean: -18.17235857056544, timestamp: 2022-08-20 04:33:30.593179\n",
      "resetting env. episode 7833, reward total was -19.0. running mean: -18.180634984859786, timestamp: 2022-08-20 04:33:36.464044\n",
      "resetting env. episode 7834, reward total was -18.0. running mean: -18.178828635011186, timestamp: 2022-08-20 04:33:42.027946\n",
      "resetting env. episode 7835, reward total was -16.0. running mean: -18.157040348661074, timestamp: 2022-08-20 04:33:47.559665\n",
      "resetting env. episode 7836, reward total was -17.0. running mean: -18.145469945174465, timestamp: 2022-08-20 04:33:54.374997\n",
      "resetting env. episode 7837, reward total was -19.0. running mean: -18.15401524572272, timestamp: 2022-08-20 04:34:00.912151\n",
      "resetting env. episode 7838, reward total was -18.0. running mean: -18.152475093265494, timestamp: 2022-08-20 04:34:07.437905\n",
      "resetting env. episode 7839, reward total was -16.0. running mean: -18.130950342332838, timestamp: 2022-08-20 04:34:14.521516\n",
      "resetting env. episode 7840, reward total was -17.0. running mean: -18.11964083890951, timestamp: 2022-08-20 04:34:21.884572\n",
      "resetting env. episode 7841, reward total was -17.0. running mean: -18.108444430520418, timestamp: 2022-08-20 04:34:28.696120\n",
      "resetting env. episode 7842, reward total was -18.0. running mean: -18.107359986215215, timestamp: 2022-08-20 04:34:33.245847\n",
      "resetting env. episode 7843, reward total was -13.0. running mean: -18.05628638635306, timestamp: 2022-08-20 04:34:39.443967\n",
      "resetting env. episode 7844, reward total was -18.0. running mean: -18.05572352248953, timestamp: 2022-08-20 04:34:44.510523\n",
      "resetting env. episode 7845, reward total was -19.0. running mean: -18.065166287264635, timestamp: 2022-08-20 04:34:48.528171\n",
      "resetting env. episode 7846, reward total was -19.0. running mean: -18.07451462439199, timestamp: 2022-08-20 04:34:53.277051\n",
      "resetting env. episode 7847, reward total was -16.0. running mean: -18.05376947814807, timestamp: 2022-08-20 04:34:58.291279\n",
      "resetting env. episode 7848, reward total was -17.0. running mean: -18.04323178336659, timestamp: 2022-08-20 04:35:04.141570\n",
      "resetting env. episode 7849, reward total was -19.0. running mean: -18.052799465532924, timestamp: 2022-08-20 04:35:09.767269\n",
      "resetting env. episode 7850, reward total was -20.0. running mean: -18.072271470877595, timestamp: 2022-08-20 04:35:14.747578\n",
      "resetting env. episode 7851, reward total was -18.0. running mean: -18.07154875616882, timestamp: 2022-08-20 04:35:20.098532\n",
      "resetting env. episode 7852, reward total was -21.0. running mean: -18.100833268607133, timestamp: 2022-08-20 04:35:23.852643\n",
      "resetting env. episode 7853, reward total was -21.0. running mean: -18.12982493592106, timestamp: 2022-08-20 04:35:29.644233\n",
      "resetting env. episode 7854, reward total was -21.0. running mean: -18.15852668656185, timestamp: 2022-08-20 04:35:35.971986\n",
      "resetting env. episode 7855, reward total was -20.0. running mean: -18.17694141969623, timestamp: 2022-08-20 04:35:41.905377\n",
      "resetting env. episode 7856, reward total was -20.0. running mean: -18.195172005499266, timestamp: 2022-08-20 04:35:47.783988\n",
      "resetting env. episode 7857, reward total was -17.0. running mean: -18.183220285444275, timestamp: 2022-08-20 04:35:53.284996\n",
      "resetting env. episode 7858, reward total was -15.0. running mean: -18.15138808258983, timestamp: 2022-08-20 04:35:59.856209\n",
      "resetting env. episode 7859, reward total was -18.0. running mean: -18.14987420176393, timestamp: 2022-08-20 04:36:05.643180\n",
      "resetting env. episode 7860, reward total was -14.0. running mean: -18.10837545974629, timestamp: 2022-08-20 04:36:10.631741\n",
      "resetting env. episode 7861, reward total was -19.0. running mean: -18.11729170514883, timestamp: 2022-08-20 04:36:16.373529\n",
      "resetting env. episode 7862, reward total was -18.0. running mean: -18.116118788097342, timestamp: 2022-08-20 04:36:20.583599\n",
      "resetting env. episode 7863, reward total was -19.0. running mean: -18.12495760021637, timestamp: 2022-08-20 04:36:25.655524\n",
      "resetting env. episode 7864, reward total was -20.0. running mean: -18.143708024214206, timestamp: 2022-08-20 04:36:30.897667\n",
      "resetting env. episode 7865, reward total was -14.0. running mean: -18.102270943972066, timestamp: 2022-08-20 04:36:38.655423\n",
      "resetting env. episode 7866, reward total was -19.0. running mean: -18.111248234532347, timestamp: 2022-08-20 04:36:46.190443\n",
      "resetting env. episode 7867, reward total was -20.0. running mean: -18.130135752187023, timestamp: 2022-08-20 04:36:53.121154\n",
      "resetting env. episode 7868, reward total was -19.0. running mean: -18.138834394665153, timestamp: 2022-08-20 04:36:58.763618\n",
      "resetting env. episode 7869, reward total was -20.0. running mean: -18.1574460507185, timestamp: 2022-08-20 04:37:05.108016\n",
      "resetting env. episode 7870, reward total was -18.0. running mean: -18.155871590211316, timestamp: 2022-08-20 04:37:11.005062\n",
      "resetting env. episode 7871, reward total was -21.0. running mean: -18.184312874309203, timestamp: 2022-08-20 04:37:16.418552\n",
      "resetting env. episode 7872, reward total was -21.0. running mean: -18.21246974556611, timestamp: 2022-08-20 04:37:21.194795\n",
      "resetting env. episode 7873, reward total was -21.0. running mean: -18.24034504811045, timestamp: 2022-08-20 04:37:26.147314\n",
      "resetting env. episode 7874, reward total was -20.0. running mean: -18.257941597629344, timestamp: 2022-08-20 04:37:30.798415\n",
      "resetting env. episode 7875, reward total was -20.0. running mean: -18.27536218165305, timestamp: 2022-08-20 04:37:34.876727\n",
      "resetting env. episode 7876, reward total was -18.0. running mean: -18.27260855983652, timestamp: 2022-08-20 04:37:41.261165\n",
      "resetting env. episode 7877, reward total was -18.0. running mean: -18.269882474238155, timestamp: 2022-08-20 04:37:47.080924\n",
      "resetting env. episode 7878, reward total was -16.0. running mean: -18.247183649495774, timestamp: 2022-08-20 04:37:53.226638\n",
      "resetting env. episode 7879, reward total was -18.0. running mean: -18.244711813000816, timestamp: 2022-08-20 04:37:59.104579\n",
      "resetting env. episode 7880, reward total was -19.0. running mean: -18.25226469487081, timestamp: 2022-08-20 04:38:09.175819\n",
      "resetting env. episode 7881, reward total was -20.0. running mean: -18.2697420479221, timestamp: 2022-08-20 04:38:15.034721\n",
      "resetting env. episode 7882, reward total was -21.0. running mean: -18.29704462744288, timestamp: 2022-08-20 04:38:20.562997\n",
      "resetting env. episode 7883, reward total was -20.0. running mean: -18.31407418116845, timestamp: 2022-08-20 04:38:25.998905\n",
      "resetting env. episode 7884, reward total was -16.0. running mean: -18.290933439356767, timestamp: 2022-08-20 04:38:31.170498\n",
      "resetting env. episode 7885, reward total was -18.0. running mean: -18.2880241049632, timestamp: 2022-08-20 04:38:36.660720\n",
      "resetting env. episode 7886, reward total was -21.0. running mean: -18.31514386391357, timestamp: 2022-08-20 04:38:42.561804\n",
      "resetting env. episode 7887, reward total was -16.0. running mean: -18.291992425274433, timestamp: 2022-08-20 04:38:47.660602\n",
      "resetting env. episode 7888, reward total was -19.0. running mean: -18.29907250102169, timestamp: 2022-08-20 04:38:54.377678\n",
      "resetting env. episode 7889, reward total was -19.0. running mean: -18.306081776011474, timestamp: 2022-08-20 04:38:58.927407\n",
      "resetting env. episode 7890, reward total was -20.0. running mean: -18.32302095825136, timestamp: 2022-08-20 04:39:04.432373\n",
      "resetting env. episode 7891, reward total was -19.0. running mean: -18.329790748668845, timestamp: 2022-08-20 04:39:08.960676\n",
      "resetting env. episode 7892, reward total was -19.0. running mean: -18.336492841182157, timestamp: 2022-08-20 04:39:13.376755\n",
      "resetting env. episode 7893, reward total was -21.0. running mean: -18.363127912770334, timestamp: 2022-08-20 04:39:17.724294\n",
      "resetting env. episode 7894, reward total was -18.0. running mean: -18.35949663364263, timestamp: 2022-08-20 04:39:22.982866\n",
      "resetting env. episode 7895, reward total was -19.0. running mean: -18.365901667306208, timestamp: 2022-08-20 04:39:29.167729\n",
      "resetting env. episode 7896, reward total was -20.0. running mean: -18.382242650633145, timestamp: 2022-08-20 04:39:35.503387\n",
      "resetting env. episode 7897, reward total was -20.0. running mean: -18.398420224126813, timestamp: 2022-08-20 04:39:40.448564\n",
      "resetting env. episode 7898, reward total was -19.0. running mean: -18.404436021885545, timestamp: 2022-08-20 04:39:47.617020\n",
      "resetting env. episode 7899, reward total was -18.0. running mean: -18.40039166166669, timestamp: 2022-08-20 04:39:53.198703\n",
      "resetting env. episode 7900, reward total was -20.0. running mean: -18.41638774505002, timestamp: 2022-08-20 04:39:57.038319\n",
      "resetting env. episode 7901, reward total was -19.0. running mean: -18.42222386759952, timestamp: 2022-08-20 04:40:03.093701\n",
      "resetting env. episode 7902, reward total was -19.0. running mean: -18.428001628923525, timestamp: 2022-08-20 04:40:08.056599\n",
      "resetting env. episode 7903, reward total was -19.0. running mean: -18.43372161263429, timestamp: 2022-08-20 04:40:13.040861\n",
      "resetting env. episode 7904, reward total was -20.0. running mean: -18.449384396507945, timestamp: 2022-08-20 04:40:19.319853\n",
      "resetting env. episode 7905, reward total was -19.0. running mean: -18.454890552542867, timestamp: 2022-08-20 04:40:24.572393\n",
      "resetting env. episode 7906, reward total was -14.0. running mean: -18.41034164701744, timestamp: 2022-08-20 04:40:32.141413\n",
      "resetting env. episode 7907, reward total was -20.0. running mean: -18.426238230547263, timestamp: 2022-08-20 04:40:39.292841\n",
      "resetting env. episode 7908, reward total was -19.0. running mean: -18.43197584824179, timestamp: 2022-08-20 04:40:45.979495\n",
      "resetting env. episode 7909, reward total was -21.0. running mean: -18.457656089759375, timestamp: 2022-08-20 04:40:52.460375\n",
      "resetting env. episode 7910, reward total was -17.0. running mean: -18.443079528861784, timestamp: 2022-08-20 04:40:58.935245\n",
      "resetting env. episode 7911, reward total was -18.0. running mean: -18.438648733573164, timestamp: 2022-08-20 04:41:03.275564\n",
      "resetting env. episode 7912, reward total was -19.0. running mean: -18.444262246237432, timestamp: 2022-08-20 04:41:08.911655\n",
      "resetting env. episode 7913, reward total was -15.0. running mean: -18.409819623775057, timestamp: 2022-08-20 04:41:13.953210\n",
      "resetting env. episode 7914, reward total was -18.0. running mean: -18.405721427537305, timestamp: 2022-08-20 04:41:18.793166\n",
      "resetting env. episode 7915, reward total was -17.0. running mean: -18.391664213261933, timestamp: 2022-08-20 04:41:24.282061\n",
      "resetting env. episode 7916, reward total was -21.0. running mean: -18.417747571129315, timestamp: 2022-08-20 04:41:30.159852\n",
      "resetting env. episode 7917, reward total was -20.0. running mean: -18.43357009541802, timestamp: 2022-08-20 04:41:35.666670\n",
      "resetting env. episode 7918, reward total was -20.0. running mean: -18.44923439446384, timestamp: 2022-08-20 04:41:40.290058\n",
      "resetting env. episode 7919, reward total was -19.0. running mean: -18.454742050519204, timestamp: 2022-08-20 04:41:44.928137\n",
      "resetting env. episode 7920, reward total was -21.0. running mean: -18.48019463001401, timestamp: 2022-08-20 04:41:52.052750\n",
      "resetting env. episode 7921, reward total was -20.0. running mean: -18.49539268371387, timestamp: 2022-08-20 04:41:57.643729\n",
      "resetting env. episode 7922, reward total was -16.0. running mean: -18.47043875687673, timestamp: 2022-08-20 04:42:04.366620\n",
      "resetting env. episode 7923, reward total was -15.0. running mean: -18.435734369307962, timestamp: 2022-08-20 04:42:11.142606\n",
      "resetting env. episode 7924, reward total was -18.0. running mean: -18.431377025614882, timestamp: 2022-08-20 04:42:16.690466\n",
      "resetting env. episode 7925, reward total was -19.0. running mean: -18.437063255358733, timestamp: 2022-08-20 04:42:23.930836\n",
      "resetting env. episode 7926, reward total was -17.0. running mean: -18.422692622805148, timestamp: 2022-08-20 04:42:30.397591\n",
      "resetting env. episode 7927, reward total was -19.0. running mean: -18.428465696577096, timestamp: 2022-08-20 04:42:35.287616\n",
      "resetting env. episode 7928, reward total was -19.0. running mean: -18.434181039611325, timestamp: 2022-08-20 04:42:40.455432\n",
      "resetting env. episode 7929, reward total was -13.0. running mean: -18.37983922921521, timestamp: 2022-08-20 04:42:45.926054\n",
      "resetting env. episode 7930, reward total was -17.0. running mean: -18.36604083692306, timestamp: 2022-08-20 04:42:51.789605\n",
      "resetting env. episode 7931, reward total was -17.0. running mean: -18.35238042855383, timestamp: 2022-08-20 04:42:57.202785\n",
      "resetting env. episode 7932, reward total was -18.0. running mean: -18.34885662426829, timestamp: 2022-08-20 04:43:03.231312\n",
      "resetting env. episode 7933, reward total was -19.0. running mean: -18.355368058025608, timestamp: 2022-08-20 04:43:09.909218\n",
      "resetting env. episode 7934, reward total was -21.0. running mean: -18.38181437744535, timestamp: 2022-08-20 04:43:14.704406\n",
      "resetting env. episode 7935, reward total was -17.0. running mean: -18.3679962336709, timestamp: 2022-08-20 04:43:19.986864\n",
      "resetting env. episode 7936, reward total was -18.0. running mean: -18.364316271334193, timestamp: 2022-08-20 04:43:25.748480\n",
      "resetting env. episode 7937, reward total was -18.0. running mean: -18.36067310862085, timestamp: 2022-08-20 04:43:30.620259\n",
      "resetting env. episode 7938, reward total was -20.0. running mean: -18.377066377534643, timestamp: 2022-08-20 04:43:37.185176\n",
      "resetting env. episode 7939, reward total was -21.0. running mean: -18.4032957137593, timestamp: 2022-08-20 04:43:42.901036\n",
      "resetting env. episode 7940, reward total was -18.0. running mean: -18.399262756621706, timestamp: 2022-08-20 04:43:50.241570\n",
      "resetting env. episode 7941, reward total was -16.0. running mean: -18.37527012905549, timestamp: 2022-08-20 04:43:58.434801\n",
      "resetting env. episode 7942, reward total was -19.0. running mean: -18.381517427764937, timestamp: 2022-08-20 04:44:04.666480\n",
      "resetting env. episode 7943, reward total was -15.0. running mean: -18.347702253487284, timestamp: 2022-08-20 04:44:10.720683\n",
      "resetting env. episode 7944, reward total was -19.0. running mean: -18.354225230952412, timestamp: 2022-08-20 04:44:16.473945\n",
      "resetting env. episode 7945, reward total was -20.0. running mean: -18.370682978642886, timestamp: 2022-08-20 04:44:21.187461\n",
      "resetting env. episode 7946, reward total was -19.0. running mean: -18.376976148856457, timestamp: 2022-08-20 04:44:26.997267\n",
      "resetting env. episode 7947, reward total was -16.0. running mean: -18.35320638736789, timestamp: 2022-08-20 04:44:32.153712\n",
      "resetting env. episode 7948, reward total was -17.0. running mean: -18.339674323494215, timestamp: 2022-08-20 04:44:38.404734\n",
      "resetting env. episode 7949, reward total was -18.0. running mean: -18.33627758025927, timestamp: 2022-08-20 04:44:46.648198\n",
      "resetting env. episode 7950, reward total was -21.0. running mean: -18.36291480445668, timestamp: 2022-08-20 04:44:51.868886\n",
      "resetting env. episode 7951, reward total was -16.0. running mean: -18.339285656412113, timestamp: 2022-08-20 04:44:57.690955\n",
      "resetting env. episode 7952, reward total was -19.0. running mean: -18.34589279984799, timestamp: 2022-08-20 04:45:02.504090\n",
      "resetting env. episode 7953, reward total was -19.0. running mean: -18.352433871849513, timestamp: 2022-08-20 04:45:07.294704\n",
      "resetting env. episode 7954, reward total was -20.0. running mean: -18.368909533131017, timestamp: 2022-08-20 04:45:12.321736\n",
      "resetting env. episode 7955, reward total was -21.0. running mean: -18.395220437799708, timestamp: 2022-08-20 04:45:17.813118\n",
      "resetting env. episode 7956, reward total was -19.0. running mean: -18.40126823342171, timestamp: 2022-08-20 04:45:22.396579\n",
      "resetting env. episode 7957, reward total was -16.0. running mean: -18.377255551087494, timestamp: 2022-08-20 04:45:28.831056\n",
      "resetting env. episode 7958, reward total was -14.0. running mean: -18.33348299557662, timestamp: 2022-08-20 04:45:37.177646\n",
      "resetting env. episode 7959, reward total was -17.0. running mean: -18.320148165620857, timestamp: 2022-08-20 04:45:43.701026\n",
      "resetting env. episode 7960, reward total was -21.0. running mean: -18.34694668396465, timestamp: 2022-08-20 04:45:49.211362\n",
      "resetting env. episode 7961, reward total was -18.0. running mean: -18.343477217125002, timestamp: 2022-08-20 04:45:54.850988\n",
      "resetting env. episode 7962, reward total was -20.0. running mean: -18.360042444953752, timestamp: 2022-08-20 04:46:00.815394\n",
      "resetting env. episode 7963, reward total was -17.0. running mean: -18.346442020504217, timestamp: 2022-08-20 04:46:05.489962\n",
      "resetting env. episode 7964, reward total was -19.0. running mean: -18.352977600299177, timestamp: 2022-08-20 04:46:11.436923\n",
      "resetting env. episode 7965, reward total was -18.0. running mean: -18.349447824296185, timestamp: 2022-08-20 04:46:16.064221\n",
      "resetting env. episode 7966, reward total was -18.0. running mean: -18.34595334605322, timestamp: 2022-08-20 04:46:21.783096\n",
      "resetting env. episode 7967, reward total was -18.0. running mean: -18.34249381259269, timestamp: 2022-08-20 04:46:26.695200\n",
      "resetting env. episode 7968, reward total was -19.0. running mean: -18.349068874466763, timestamp: 2022-08-20 04:46:31.577310\n",
      "resetting env. episode 7969, reward total was -19.0. running mean: -18.355578185722095, timestamp: 2022-08-20 04:46:38.744096\n",
      "resetting env. episode 7970, reward total was -17.0. running mean: -18.342022403864874, timestamp: 2022-08-20 04:46:47.532459\n",
      "resetting env. episode 7971, reward total was -19.0. running mean: -18.348602179826226, timestamp: 2022-08-20 04:46:52.868464\n",
      "resetting env. episode 7972, reward total was -21.0. running mean: -18.375116158027964, timestamp: 2022-08-20 04:46:57.513946\n",
      "resetting env. episode 7973, reward total was -15.0. running mean: -18.341364996447684, timestamp: 2022-08-20 04:47:03.239160\n",
      "resetting env. episode 7974, reward total was -18.0. running mean: -18.337951346483205, timestamp: 2022-08-20 04:47:08.333556\n",
      "resetting env. episode 7975, reward total was -20.0. running mean: -18.354571833018372, timestamp: 2022-08-20 04:47:13.701629\n",
      "resetting env. episode 7976, reward total was -15.0. running mean: -18.321026114688188, timestamp: 2022-08-20 04:47:19.377678\n",
      "resetting env. episode 7977, reward total was -19.0. running mean: -18.327815853541306, timestamp: 2022-08-20 04:47:24.577880\n",
      "resetting env. episode 7978, reward total was -19.0. running mean: -18.334537695005896, timestamp: 2022-08-20 04:47:29.671368\n",
      "resetting env. episode 7979, reward total was -19.0. running mean: -18.34119231805584, timestamp: 2022-08-20 04:47:34.107735\n",
      "resetting env. episode 7980, reward total was -19.0. running mean: -18.347780394875283, timestamp: 2022-08-20 04:47:39.513021\n",
      "resetting env. episode 7981, reward total was -18.0. running mean: -18.344302590926528, timestamp: 2022-08-20 04:47:44.046321\n",
      "resetting env. episode 7982, reward total was -17.0. running mean: -18.330859565017263, timestamp: 2022-08-20 04:47:49.151171\n",
      "resetting env. episode 7983, reward total was -19.0. running mean: -18.337550969367094, timestamp: 2022-08-20 04:47:53.475039\n",
      "resetting env. episode 7984, reward total was -20.0. running mean: -18.35417545967342, timestamp: 2022-08-20 04:47:59.519310\n",
      "resetting env. episode 7985, reward total was -21.0. running mean: -18.380633705076686, timestamp: 2022-08-20 04:48:05.410940\n",
      "resetting env. episode 7986, reward total was -13.0. running mean: -18.326827368025917, timestamp: 2022-08-20 04:48:13.619434\n",
      "resetting env. episode 7987, reward total was -18.0. running mean: -18.323559094345658, timestamp: 2022-08-20 04:48:19.894603\n",
      "resetting env. episode 7988, reward total was -19.0. running mean: -18.3303235034022, timestamp: 2022-08-20 04:48:26.274418\n",
      "resetting env. episode 7989, reward total was -18.0. running mean: -18.32702026836818, timestamp: 2022-08-20 04:48:31.338500\n",
      "resetting env. episode 7990, reward total was -18.0. running mean: -18.323750065684496, timestamp: 2022-08-20 04:48:36.872763\n",
      "resetting env. episode 7991, reward total was -15.0. running mean: -18.29051256502765, timestamp: 2022-08-20 04:48:42.480508\n",
      "resetting env. episode 7992, reward total was -19.0. running mean: -18.297607439377376, timestamp: 2022-08-20 04:48:47.245027\n",
      "resetting env. episode 7993, reward total was -19.0. running mean: -18.304631364983603, timestamp: 2022-08-20 04:48:54.235012\n",
      "resetting env. episode 7994, reward total was -19.0. running mean: -18.31158505133377, timestamp: 2022-08-20 04:48:58.835808\n",
      "resetting env. episode 7995, reward total was -17.0. running mean: -18.29846920082043, timestamp: 2022-08-20 04:49:05.000112\n",
      "resetting env. episode 7996, reward total was -20.0. running mean: -18.315484508812226, timestamp: 2022-08-20 04:49:10.766629\n",
      "resetting env. episode 7997, reward total was -21.0. running mean: -18.342329663724104, timestamp: 2022-08-20 04:49:17.804034\n",
      "resetting env. episode 7998, reward total was -19.0. running mean: -18.348906367086865, timestamp: 2022-08-20 04:49:23.915443\n",
      "resetting env. episode 7999, reward total was -16.0. running mean: -18.325417303415996, timestamp: 2022-08-20 04:49:31.276871\n",
      "resetting env. episode 8000, reward total was -17.0. running mean: -18.312163130381837, timestamp: 2022-08-20 04:49:36.834064\n",
      "peak memory: 567.90 MiB, increment: 315.35 MiB\n"
     ]
    }
   ],
   "source": [
    "file_name = 'hist1_last_.csv'\n",
    "%memit hist1,hist_2 = train_model(env, model, total_episodes=8000)\n",
    "np.savetxt(file_name, hist1, delimiter =\",\", fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "def plot_graph2(data):\n",
    "    for line in data:\n",
    "        xs.append(float(line[0]))\n",
    "        ys.append(float(line[1]))\n",
    "        ax1.clear()\n",
    "        \n",
    "    ax1.plot(xs, ys)\n",
    "    plt.pause(1)\n",
    "    plt.show()\n",
    "\n",
    "plot_graph2(hist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHYCDYwhlVLV",
    "outputId": "44023870-3ed0-46f5-84e7-df559e94ffc0"
   },
   "outputs": [],
   "source": [
    "#%time hist2 = train_model(env, model, total_episodes=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "8fheN9DRlWXQ",
    "outputId": "23490ad9-3ac8-4899-824b-44400caa8afd"
   },
   "outputs": [],
   "source": [
    "#play_game(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AxOcQhIsKow",
    "outputId": "68d93a54-196d-4d91-a6f6-731aa0de23c4"
   },
   "outputs": [],
   "source": [
    "#%time hist3 = train_model(env, model, total_episodes=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "w2NblmwDsL3y",
    "outputId": "f3dc32bf-ab84-418d-b830-407510690d12"
   },
   "outputs": [],
   "source": [
    "#play_game(env, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "H=200 le-4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "83a8a37af132a2fa5bd73ffbd7034c1e5f9f9b0bef7ee17d2a911228df5d8f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
