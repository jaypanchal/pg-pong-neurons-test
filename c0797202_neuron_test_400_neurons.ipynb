{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cWACPRL869I4"
   },
   "outputs": [],
   "source": [
    "# C0797202 JAY PANCHAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from memory_profiler) (5.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (1.23.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (2.1.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (0.0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JSAnimation in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.36.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[accept-rom-license,atari] in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (1.23.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (2.1.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: ale-py~=0.7.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.7.5)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.28.1)\n",
      "Requirement already satisfied: click in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.3)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "UsageError: Line magic function `%%file` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install memory_profiler\n",
    "%load_ext memory_profiler\n",
    "%pip install gym\n",
    "%pip install JSAnimation\n",
    "%pip install matplotlib\n",
    "%pip install -U gym >= 0.21.0\n",
    "%pip install -U gym[atari,accept-rom-license]\n",
    "\n",
    "%%file training.py\n",
    "\n",
    "%%python -m memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wotUOa_e6edP"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "from matplotlib import animation\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R66_INeZ9nYX"
   },
   "source": [
    "## Initiating Ping Pong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtT2GyK_6edc",
    "outputId": "6ef17a84-3563-4157-caf3-2c50438190ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\envs\\registration.py:593: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "# Importing gym library and creating environment\n",
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRE6WmXQJ1Z0",
    "outputId": "41a4b484-4f7e-4fd6-fc69-e626adec0523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trwRXI-h6eeI",
    "outputId": "42368b9e-2477-41ef-fb42-30ced75282c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished without success, accumulated reward = -18.0\n"
     ]
    }
   ],
   "source": [
    "# Run a demo of the environment\n",
    "observation = env.reset()\n",
    "cumulated_reward = 0\n",
    "\n",
    "frames = []\n",
    "for t in range(1000):\n",
    "#     print(observation)\n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    # very stupid agent, just makes a random action within the allowd action space\n",
    "    action = env.action_space.sample()\n",
    "#     print(\"Action: {}\".format(t+1))    \n",
    "    observation, reward, done, info = env.step(action)\n",
    "#     print(reward)\n",
    "    cumulated_reward += reward\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
    "        break\n",
    "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3zZTecVWLLes"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
    "\n",
    "def prepro(I):\n",
    "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "  I = I[35:195] # crop\n",
    "  I = I[::2,::2,0] # downsample by factor of 2\n",
    "  I[I == 144] = 0 # erase background (background type 1)\n",
    "  I[I == 109] = 0 # erase background (background type 2)\n",
    "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "  return I.astype(np.float).ravel()\n",
    "\n",
    "def policy_forward(x):\n",
    "  h = np.dot(model['W1'], x)\n",
    "  h[h<0] = 0 # ReLU nonlinearity\n",
    "  logp = np.dot(model['W2'], h)\n",
    "  p = sigmoid(logp)\n",
    "  return p, h # return probability of taking action 2, and hidden state\n",
    "\n",
    "def model_step(model, observation, prev_x):\n",
    "  # preprocess the observation, set input to network to be difference image\n",
    "  cur_x = prepro(observation)\n",
    "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "  prev_x = cur_x\n",
    "  \n",
    "  # forward the policy network and sample an action from the returned probability\n",
    "  aprob, _ = policy_forward(x)\n",
    "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
    "  \n",
    "  return action, prev_x\n",
    "\n",
    "def play_game(env, model):\n",
    "  observation = env.reset()\n",
    "\n",
    "  frames = []\n",
    "  cumulated_reward = 0\n",
    "\n",
    "  prev_x = None # used in computing the difference frame\n",
    "\n",
    "  for t in range(1000):\n",
    "      frames.append(env.render(mode = 'rgb_array'))\n",
    "      action, prev_x = model_step(model, observation, prev_x)\n",
    "      observation, reward, done, info = env.step(action)\n",
    "      cumulated_reward += reward\n",
    "      if done:\n",
    "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
    "          break\n",
    "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
    "  display_frames_as_gif(frames)\n",
    "  env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gWvZQ7AQLQt"
   },
   "source": [
    "# Logic behind the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eqFm7hqcItWl"
   },
   "outputs": [],
   "source": [
    "# Init the model\n",
    "\n",
    "# number of neurons\n",
    "H = 400 \n",
    "\n",
    "# input dimensionality: 80x80 grid\n",
    "D = 80 * 80 \n",
    "\n",
    "model = {}\n",
    "def update_neurons(neurons = 400):\n",
    "    H = neurons\n",
    "    \n",
    "    # \"Xavier\" initialization\n",
    "    \n",
    "    model['W1'] = np.random.randn(H,D) / np.sqrt(D)\n",
    "    model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "update_neurons(H)\n",
    "\n",
    "# import pickle\n",
    "#  model = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TwjiwKisQM19"
   },
   "outputs": [],
   "source": [
    "\n",
    "# hyperparameters\n",
    "batch_size = 10 # every how many episodes to do a param update?\n",
    "\n",
    "# learning_rate = 1e-4\n",
    "learning_rate = 1e-4\n",
    " \n",
    "# discount factor for reward\n",
    "gamma = 0.99 \n",
    "\n",
    "# decay factor for RMSProp leaky sum of grad^2\n",
    "decay_rate = 0.99 \n",
    "  \n",
    "# update buffers that add up gradients over a batch\n",
    "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } \n",
    "\n",
    "# rmsprop memory\n",
    "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } \n",
    "\n",
    "def discount_rewards(r):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "def policy_backward(epx, eph, epdlogp):\n",
    "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
    "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "  dh = np.outer(epdlogp, model['W2'])\n",
    "  dh[eph <= 0] = 0 # backpro prelu\n",
    "  dW1 = np.dot(dh.T, epx)\n",
    "  return {'W1':dW1, 'W2':dW2}\n",
    "\n",
    "\n",
    "def train_model(env, model, total_episodes = 100):\n",
    "  hist = []\n",
    "  hist_2 = []\n",
    "  observation = env.reset()\n",
    "\n",
    "  prev_x = None # used in computing the difference frame\n",
    "  xs,hs,dlogps,drs = [],[],[],[]\n",
    "  running_reward = None\n",
    "  reward_sum = 0\n",
    "  episode_number = 0\n",
    "\n",
    "  from datetime import datetime\n",
    "\n",
    "  now = datetime.now()\n",
    "  print(f'Start time: {now}')\n",
    "\n",
    "  last_export_time = now\n",
    "\n",
    "  while True:\n",
    "    # preprocess the observation, set input to network to be difference image\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # forward the policy network and sample an action from the returned probability\n",
    "    aprob, h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
    "\n",
    "    # record various intermediates (needed later for backprop)\n",
    "    xs.append(x) # observation\n",
    "    hs.append(h) # hidden state\n",
    "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
    "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
    "\n",
    "    # step the environment and get new measurements\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "    if done: # an episode finished\n",
    "      episode_number += 1\n",
    "\n",
    "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "      epx = np.vstack(xs)\n",
    "      eph = np.vstack(hs)\n",
    "      epdlogp = np.vstack(dlogps)\n",
    "      epr = np.vstack(drs)\n",
    "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
    "\n",
    "      # compute the discounted reward backwards through time\n",
    "      discounted_epr = discount_rewards(epr)\n",
    "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "      discounted_epr -= np.mean(discounted_epr)\n",
    "      discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
    "      grad = policy_backward(epx, eph, epdlogp)\n",
    "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
    "\n",
    "      # perform rmsprop parameter update every batch_size episodes\n",
    "      if episode_number % batch_size == 0:\n",
    "        for k,v in model.items():\n",
    "          g = grad_buffer[k] # gradient\n",
    "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
    "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
    "\n",
    "      # boring book-keeping\n",
    "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "      hist.append((episode_number, reward_sum, running_reward,datetime.now()))\n",
    "      hist_2.append((episode_number, running_reward))\n",
    "      \n",
    "      if ((datetime.now() - last_export_time).total_seconds() > 30):\n",
    "        file_name = 'hist1_'+ str(total_episodes) + '_H_400.csv'\n",
    "        np.savetxt(file_name, hist, delimiter =\",\", fmt ='% s')\n",
    "        last_export_time = datetime.now()\n",
    "        \n",
    "      print (f'resetting env. episode {episode_number}, reward total was {reward_sum}. running mean: {running_reward}, timestamp: {datetime.now()}')\n",
    "            \n",
    "      reward_sum = 0\n",
    "      observation = env.reset() # reset env\n",
    "      prev_x = None\n",
    "      if running_reward > -15.95:\n",
    "        sys.exit()\n",
    "      if episode_number == total_episodes:\n",
    "        return hist, hist_2\n",
    "\n",
    "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
    "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6Ka_5Vl9Orm",
    "outputId": "75de5744-f8e4-4aea-c00f-2cb2977a38cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2022-08-19 18:26:01.291376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaypanchal\\AppData\\Local\\Temp\\ipykernel_4480\\1818632268.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return I.astype(np.float).ravel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode 1, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-19 18:26:03.105396\n",
      "resetting env. episode 2, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-19 18:26:04.968418\n",
      "resetting env. episode 3, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-19 18:26:06.544435\n",
      "resetting env. episode 4, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-19 18:26:08.694461\n",
      "resetting env. episode 5, reward total was -20.0. running mean: -20.99, timestamp: 2022-08-19 18:26:11.064488\n",
      "resetting env. episode 6, reward total was -19.0. running mean: -20.9701, timestamp: 2022-08-19 18:26:13.064511\n",
      "resetting env. episode 7, reward total was -21.0. running mean: -20.970399, timestamp: 2022-08-19 18:26:14.628530\n",
      "resetting env. episode 8, reward total was -21.0. running mean: -20.97069501, timestamp: 2022-08-19 18:26:16.467552\n",
      "resetting env. episode 9, reward total was -21.0. running mean: -20.9709880599, timestamp: 2022-08-19 18:26:18.810576\n",
      "resetting env. episode 10, reward total was -21.0. running mean: -20.971278179301002, timestamp: 2022-08-19 18:26:20.727597\n",
      "resetting env. episode 11, reward total was -21.0. running mean: -20.971565397507995, timestamp: 2022-08-19 18:26:22.316619\n",
      "resetting env. episode 12, reward total was -19.0. running mean: -20.951849743532915, timestamp: 2022-08-19 18:26:24.407642\n",
      "resetting env. episode 13, reward total was -20.0. running mean: -20.942331246097584, timestamp: 2022-08-19 18:26:26.473665\n",
      "resetting env. episode 14, reward total was -21.0. running mean: -20.942907933636608, timestamp: 2022-08-19 18:26:28.336686\n",
      "resetting env. episode 15, reward total was -21.0. running mean: -20.943478854300242, timestamp: 2022-08-19 18:26:30.231709\n",
      "resetting env. episode 16, reward total was -21.0. running mean: -20.94404406575724, timestamp: 2022-08-19 18:26:32.354732\n",
      "resetting env. episode 17, reward total was -19.0. running mean: -20.924603625099667, timestamp: 2022-08-19 18:26:34.808760\n",
      "resetting env. episode 18, reward total was -21.0. running mean: -20.925357588848673, timestamp: 2022-08-19 18:26:36.496781\n",
      "resetting env. episode 19, reward total was -21.0. running mean: -20.926104012960188, timestamp: 2022-08-19 18:26:38.825807\n",
      "resetting env. episode 20, reward total was -19.0. running mean: -20.90684297283059, timestamp: 2022-08-19 18:26:42.791854\n",
      "resetting env. episode 21, reward total was -21.0. running mean: -20.907774543102285, timestamp: 2022-08-19 18:26:45.286881\n",
      "resetting env. episode 22, reward total was -21.0. running mean: -20.90869679767126, timestamp: 2022-08-19 18:26:47.489907\n",
      "resetting env. episode 23, reward total was -20.0. running mean: -20.899609829694548, timestamp: 2022-08-19 18:26:50.266939\n",
      "resetting env. episode 24, reward total was -19.0. running mean: -20.880613731397602, timestamp: 2022-08-19 18:26:53.247973\n",
      "resetting env. episode 25, reward total was -21.0. running mean: -20.88180759408363, timestamp: 2022-08-19 18:26:55.441000\n",
      "resetting env. episode 26, reward total was -21.0. running mean: -20.882989518142793, timestamp: 2022-08-19 18:26:57.400021\n",
      "resetting env. episode 27, reward total was -21.0. running mean: -20.884159622961366, timestamp: 2022-08-19 18:26:59.114041\n",
      "resetting env. episode 28, reward total was -21.0. running mean: -20.885318026731753, timestamp: 2022-08-19 18:27:01.233064\n",
      "resetting env. episode 29, reward total was -19.0. running mean: -20.866464846464435, timestamp: 2022-08-19 18:27:03.922097\n",
      "resetting env. episode 30, reward total was -21.0. running mean: -20.86780019799979, timestamp: 2022-08-19 18:27:05.972120\n",
      "resetting env. episode 31, reward total was -20.0. running mean: -20.859122196019793, timestamp: 2022-08-19 18:27:08.038144\n",
      "resetting env. episode 32, reward total was -21.0. running mean: -20.860530974059596, timestamp: 2022-08-19 18:27:10.373169\n",
      "resetting env. episode 33, reward total was -20.0. running mean: -20.851925664319, timestamp: 2022-08-19 18:27:12.583198\n",
      "resetting env. episode 34, reward total was -21.0. running mean: -20.853406407675813, timestamp: 2022-08-19 18:27:14.606220\n",
      "resetting env. episode 35, reward total was -21.0. running mean: -20.854872343599055, timestamp: 2022-08-19 18:27:16.666246\n",
      "resetting env. episode 36, reward total was -20.0. running mean: -20.846323620163062, timestamp: 2022-08-19 18:27:18.511266\n",
      "resetting env. episode 37, reward total was -21.0. running mean: -20.847860383961432, timestamp: 2022-08-19 18:27:20.968292\n",
      "resetting env. episode 38, reward total was -21.0. running mean: -20.849381780121817, timestamp: 2022-08-19 18:27:22.879317\n",
      "resetting env. episode 39, reward total was -19.0. running mean: -20.8308879623206, timestamp: 2022-08-19 18:27:25.476347\n",
      "resetting env. episode 40, reward total was -21.0. running mean: -20.832579082697393, timestamp: 2022-08-19 18:27:27.229365\n",
      "resetting env. episode 41, reward total was -21.0. running mean: -20.834253291870418, timestamp: 2022-08-19 18:27:28.779383\n",
      "resetting env. episode 42, reward total was -21.0. running mean: -20.835910758951716, timestamp: 2022-08-19 18:27:30.828933\n",
      "resetting env. episode 43, reward total was -21.0. running mean: -20.8375516513622, timestamp: 2022-08-19 18:27:33.290962\n",
      "resetting env. episode 44, reward total was -21.0. running mean: -20.83917613484858, timestamp: 2022-08-19 18:27:35.068982\n",
      "resetting env. episode 45, reward total was -21.0. running mean: -20.840784373500092, timestamp: 2022-08-19 18:27:36.682000\n",
      "resetting env. episode 46, reward total was -20.0. running mean: -20.832376529765092, timestamp: 2022-08-19 18:27:38.859026\n",
      "resetting env. episode 47, reward total was -20.0. running mean: -20.82405276446744, timestamp: 2022-08-19 18:27:40.913051\n",
      "resetting env. episode 48, reward total was -21.0. running mean: -20.825812236822767, timestamp: 2022-08-19 18:27:42.394068\n",
      "resetting env. episode 49, reward total was -21.0. running mean: -20.82755411445454, timestamp: 2022-08-19 18:27:44.246089\n",
      "resetting env. episode 50, reward total was -21.0. running mean: -20.829278573309995, timestamp: 2022-08-19 18:27:46.170109\n",
      "resetting env. episode 51, reward total was -21.0. running mean: -20.830985787576896, timestamp: 2022-08-19 18:27:48.253137\n",
      "resetting env. episode 52, reward total was -21.0. running mean: -20.83267592970113, timestamp: 2022-08-19 18:27:49.911154\n",
      "resetting env. episode 53, reward total was -20.0. running mean: -20.824349170404115, timestamp: 2022-08-19 18:27:52.314181\n",
      "resetting env. episode 54, reward total was -21.0. running mean: -20.826105678700074, timestamp: 2022-08-19 18:27:54.224204\n",
      "resetting env. episode 55, reward total was -18.0. running mean: -20.79784462191307, timestamp: 2022-08-19 18:27:56.737233\n",
      "resetting env. episode 56, reward total was -21.0. running mean: -20.799866175693943, timestamp: 2022-08-19 18:27:58.985259\n",
      "resetting env. episode 57, reward total was -21.0. running mean: -20.801867513937005, timestamp: 2022-08-19 18:28:01.045283\n",
      "resetting env. episode 58, reward total was -21.0. running mean: -20.803848838797634, timestamp: 2022-08-19 18:28:02.708302\n",
      "resetting env. episode 59, reward total was -19.0. running mean: -20.78581035040966, timestamp: 2022-08-19 18:28:05.093332\n",
      "resetting env. episode 60, reward total was -21.0. running mean: -20.78795224690556, timestamp: 2022-08-19 18:28:06.997351\n",
      "resetting env. episode 61, reward total was -20.0. running mean: -20.780072724436504, timestamp: 2022-08-19 18:28:08.841373\n",
      "resetting env. episode 62, reward total was -20.0. running mean: -20.77227199719214, timestamp: 2022-08-19 18:28:10.988399\n",
      "resetting env. episode 63, reward total was -20.0. running mean: -20.764549277220215, timestamp: 2022-08-19 18:28:12.926422\n",
      "resetting env. episode 64, reward total was -21.0. running mean: -20.766903784448015, timestamp: 2022-08-19 18:28:14.942443\n",
      "resetting env. episode 65, reward total was -21.0. running mean: -20.769234746603537, timestamp: 2022-08-19 18:28:16.963468\n",
      "resetting env. episode 66, reward total was -19.0. running mean: -20.751542399137502, timestamp: 2022-08-19 18:28:18.753493\n",
      "resetting env. episode 67, reward total was -19.0. running mean: -20.73402697514613, timestamp: 2022-08-19 18:28:21.264517\n",
      "resetting env. episode 68, reward total was -21.0. running mean: -20.736686705394668, timestamp: 2022-08-19 18:28:23.518070\n",
      "resetting env. episode 69, reward total was -20.0. running mean: -20.72931983834072, timestamp: 2022-08-19 18:28:25.809095\n",
      "resetting env. episode 70, reward total was -21.0. running mean: -20.732026639957315, timestamp: 2022-08-19 18:28:27.661114\n",
      "resetting env. episode 71, reward total was -20.0. running mean: -20.72470637355774, timestamp: 2022-08-19 18:28:29.667145\n",
      "resetting env. episode 72, reward total was -21.0. running mean: -20.727459309822162, timestamp: 2022-08-19 18:28:31.461160\n",
      "resetting env. episode 73, reward total was -21.0. running mean: -20.73018471672394, timestamp: 2022-08-19 18:28:33.136181\n",
      "resetting env. episode 74, reward total was -19.0. running mean: -20.7128828695567, timestamp: 2022-08-19 18:28:35.262206\n",
      "resetting env. episode 75, reward total was -21.0. running mean: -20.715754040861135, timestamp: 2022-08-19 18:28:37.113225\n",
      "resetting env. episode 76, reward total was -20.0. running mean: -20.708596500452522, timestamp: 2022-08-19 18:28:39.681256\n",
      "resetting env. episode 77, reward total was -21.0. running mean: -20.711510535447996, timestamp: 2022-08-19 18:28:41.499286\n",
      "resetting env. episode 78, reward total was -21.0. running mean: -20.714395430093518, timestamp: 2022-08-19 18:28:43.722302\n",
      "resetting env. episode 79, reward total was -21.0. running mean: -20.717251475792583, timestamp: 2022-08-19 18:28:45.494323\n",
      "resetting env. episode 80, reward total was -18.0. running mean: -20.690078961034658, timestamp: 2022-08-19 18:28:48.392355\n",
      "resetting env. episode 81, reward total was -19.0. running mean: -20.67317817142431, timestamp: 2022-08-19 18:28:50.817385\n",
      "resetting env. episode 82, reward total was -21.0. running mean: -20.67644638971007, timestamp: 2022-08-19 18:28:52.888408\n",
      "resetting env. episode 83, reward total was -21.0. running mean: -20.679681925812968, timestamp: 2022-08-19 18:28:54.765431\n",
      "resetting env. episode 84, reward total was -21.0. running mean: -20.68288510655484, timestamp: 2022-08-19 18:28:56.697452\n",
      "resetting env. episode 85, reward total was -21.0. running mean: -20.68605625548929, timestamp: 2022-08-19 18:28:58.298472\n",
      "resetting env. episode 86, reward total was -21.0. running mean: -20.689195692934398, timestamp: 2022-08-19 18:28:59.974490\n",
      "resetting env. episode 87, reward total was -21.0. running mean: -20.692303736005055, timestamp: 2022-08-19 18:29:02.134516\n",
      "resetting env. episode 88, reward total was -21.0. running mean: -20.695380698645007, timestamp: 2022-08-19 18:29:04.239543\n",
      "resetting env. episode 89, reward total was -20.0. running mean: -20.688426891658555, timestamp: 2022-08-19 18:29:06.698571\n",
      "resetting env. episode 90, reward total was -21.0. running mean: -20.69154262274197, timestamp: 2022-08-19 18:29:08.204584\n",
      "resetting env. episode 91, reward total was -18.0. running mean: -20.66462719651455, timestamp: 2022-08-19 18:29:10.385613\n",
      "resetting env. episode 92, reward total was -19.0. running mean: -20.647980924549408, timestamp: 2022-08-19 18:29:12.598638\n",
      "resetting env. episode 93, reward total was -21.0. running mean: -20.651501115303915, timestamp: 2022-08-19 18:29:14.227657\n",
      "resetting env. episode 94, reward total was -21.0. running mean: -20.654986104150876, timestamp: 2022-08-19 18:29:15.722673\n",
      "resetting env. episode 95, reward total was -21.0. running mean: -20.658436243109367, timestamp: 2022-08-19 18:29:17.633697\n",
      "resetting env. episode 96, reward total was -19.0. running mean: -20.641851880678274, timestamp: 2022-08-19 18:29:20.028724\n",
      "resetting env. episode 97, reward total was -21.0. running mean: -20.645433361871493, timestamp: 2022-08-19 18:29:21.955746\n",
      "resetting env. episode 98, reward total was -21.0. running mean: -20.64897902825278, timestamp: 2022-08-19 18:29:23.510764\n",
      "resetting env. episode 99, reward total was -21.0. running mean: -20.65248923797025, timestamp: 2022-08-19 18:29:25.322785\n",
      "resetting env. episode 100, reward total was -19.0. running mean: -20.635964345590548, timestamp: 2022-08-19 18:29:27.732813\n",
      "resetting env. episode 101, reward total was -21.0. running mean: -20.639604702134644, timestamp: 2022-08-19 18:29:29.499834\n",
      "resetting env. episode 102, reward total was -21.0. running mean: -20.6432086551133, timestamp: 2022-08-19 18:29:31.246854\n",
      "resetting env. episode 103, reward total was -20.0. running mean: -20.636776568562166, timestamp: 2022-08-19 18:29:33.793884\n",
      "resetting env. episode 104, reward total was -21.0. running mean: -20.640408802876543, timestamp: 2022-08-19 18:29:35.372901\n",
      "resetting env. episode 105, reward total was -21.0. running mean: -20.644004714847778, timestamp: 2022-08-19 18:29:36.943920\n",
      "resetting env. episode 106, reward total was -21.0. running mean: -20.6475646676993, timestamp: 2022-08-19 18:29:38.969943\n",
      "resetting env. episode 107, reward total was -20.0. running mean: -20.641089021022307, timestamp: 2022-08-19 18:29:40.947967\n",
      "resetting env. episode 108, reward total was -18.0. running mean: -20.614678130812084, timestamp: 2022-08-19 18:29:43.563997\n",
      "resetting env. episode 109, reward total was -20.0. running mean: -20.608531349503963, timestamp: 2022-08-19 18:29:45.634022\n",
      "resetting env. episode 110, reward total was -21.0. running mean: -20.612446036008922, timestamp: 2022-08-19 18:29:47.618046\n",
      "resetting env. episode 111, reward total was -21.0. running mean: -20.616321575648833, timestamp: 2022-08-19 18:29:49.934073\n",
      "resetting env. episode 112, reward total was -21.0. running mean: -20.620158359892343, timestamp: 2022-08-19 18:29:52.639104\n",
      "resetting env. episode 113, reward total was -20.0. running mean: -20.61395677629342, timestamp: 2022-08-19 18:29:54.910129\n",
      "resetting env. episode 114, reward total was -21.0. running mean: -20.617817208530486, timestamp: 2022-08-19 18:29:57.157155\n",
      "resetting env. episode 115, reward total was -20.0. running mean: -20.61163903644518, timestamp: 2022-08-19 18:29:59.031176\n",
      "resetting env. episode 116, reward total was -21.0. running mean: -20.615522646080727, timestamp: 2022-08-19 18:30:00.579195\n",
      "resetting env. episode 117, reward total was -21.0. running mean: -20.61936741961992, timestamp: 2022-08-19 18:30:02.540217\n",
      "resetting env. episode 118, reward total was -21.0. running mean: -20.62317374542372, timestamp: 2022-08-19 18:30:04.448238\n",
      "resetting env. episode 119, reward total was -21.0. running mean: -20.626942007969483, timestamp: 2022-08-19 18:30:06.170260\n",
      "resetting env. episode 120, reward total was -20.0. running mean: -20.620672587889786, timestamp: 2022-08-19 18:30:08.092284\n",
      "resetting env. episode 121, reward total was -21.0. running mean: -20.62446586201089, timestamp: 2022-08-19 18:30:09.910302\n",
      "resetting env. episode 122, reward total was -20.0. running mean: -20.61822120339078, timestamp: 2022-08-19 18:30:11.882325\n",
      "resetting env. episode 123, reward total was -20.0. running mean: -20.612038991356872, timestamp: 2022-08-19 18:30:13.497343\n",
      "resetting env. episode 124, reward total was -21.0. running mean: -20.615918601443305, timestamp: 2022-08-19 18:30:15.181363\n",
      "resetting env. episode 125, reward total was -21.0. running mean: -20.619759415428874, timestamp: 2022-08-19 18:30:17.072385\n",
      "resetting env. episode 126, reward total was -21.0. running mean: -20.623561821274585, timestamp: 2022-08-19 18:30:19.076411\n",
      "resetting env. episode 127, reward total was -21.0. running mean: -20.62732620306184, timestamp: 2022-08-19 18:30:20.839428\n",
      "resetting env. episode 128, reward total was -21.0. running mean: -20.631052941031225, timestamp: 2022-08-19 18:30:22.935455\n",
      "resetting env. episode 129, reward total was -19.0. running mean: -20.614742411620913, timestamp: 2022-08-19 18:30:25.281481\n",
      "resetting env. episode 130, reward total was -21.0. running mean: -20.618594987504704, timestamp: 2022-08-19 18:30:27.179503\n",
      "resetting env. episode 131, reward total was -21.0. running mean: -20.62240903762966, timestamp: 2022-08-19 18:30:28.822522\n",
      "resetting env. episode 132, reward total was -21.0. running mean: -20.626184947253364, timestamp: 2022-08-19 18:30:30.780544\n",
      "resetting env. episode 133, reward total was -21.0. running mean: -20.629923097780832, timestamp: 2022-08-19 18:30:32.592565\n",
      "resetting env. episode 134, reward total was -21.0. running mean: -20.633623866803024, timestamp: 2022-08-19 18:30:34.385588\n",
      "resetting env. episode 135, reward total was -21.0. running mean: -20.637287628134995, timestamp: 2022-08-19 18:30:36.702613\n",
      "resetting env. episode 136, reward total was -21.0. running mean: -20.640914751853646, timestamp: 2022-08-19 18:30:38.704636\n",
      "resetting env. episode 137, reward total was -21.0. running mean: -20.644505604335112, timestamp: 2022-08-19 18:30:40.531660\n",
      "resetting env. episode 138, reward total was -20.0. running mean: -20.63806054829176, timestamp: 2022-08-19 18:30:42.160677\n",
      "resetting env. episode 139, reward total was -20.0. running mean: -20.631679942808844, timestamp: 2022-08-19 18:30:44.695708\n",
      "resetting env. episode 140, reward total was -20.0. running mean: -20.625363143380756, timestamp: 2022-08-19 18:30:46.647728\n",
      "resetting env. episode 141, reward total was -20.0. running mean: -20.61910951194695, timestamp: 2022-08-19 18:30:49.028755\n",
      "resetting env. episode 142, reward total was -21.0. running mean: -20.62291841682748, timestamp: 2022-08-19 18:30:50.821779\n",
      "resetting env. episode 143, reward total was -21.0. running mean: -20.626689232659206, timestamp: 2022-08-19 18:30:52.639798\n",
      "resetting env. episode 144, reward total was -18.0. running mean: -20.600422340332614, timestamp: 2022-08-19 18:30:55.167827\n",
      "resetting env. episode 145, reward total was -21.0. running mean: -20.60441811692929, timestamp: 2022-08-19 18:30:57.071849\n",
      "resetting env. episode 146, reward total was -20.0. running mean: -20.598373935759994, timestamp: 2022-08-19 18:30:59.132874\n",
      "resetting env. episode 147, reward total was -21.0. running mean: -20.602390196402396, timestamp: 2022-08-19 18:31:00.693892\n",
      "resetting env. episode 148, reward total was -21.0. running mean: -20.606366294438374, timestamp: 2022-08-19 18:31:02.605913\n",
      "resetting env. episode 149, reward total was -20.0. running mean: -20.60030263149399, timestamp: 2022-08-19 18:31:04.682937\n",
      "resetting env. episode 150, reward total was -20.0. running mean: -20.59429960517905, timestamp: 2022-08-19 18:31:06.799961\n",
      "resetting env. episode 151, reward total was -21.0. running mean: -20.598356609127258, timestamp: 2022-08-19 18:31:08.448981\n",
      "resetting env. episode 152, reward total was -20.0. running mean: -20.592373043035984, timestamp: 2022-08-19 18:31:10.617007\n",
      "resetting env. episode 153, reward total was -17.0. running mean: -20.556449312605626, timestamp: 2022-08-19 18:31:13.091034\n",
      "resetting env. episode 154, reward total was -20.0. running mean: -20.550884819479567, timestamp: 2022-08-19 18:31:14.963055\n",
      "resetting env. episode 155, reward total was -19.0. running mean: -20.535375971284772, timestamp: 2022-08-19 18:31:17.093081\n",
      "resetting env. episode 156, reward total was -21.0. running mean: -20.540022211571923, timestamp: 2022-08-19 18:31:19.444109\n",
      "resetting env. episode 157, reward total was -21.0. running mean: -20.544621989456203, timestamp: 2022-08-19 18:31:21.151128\n",
      "resetting env. episode 158, reward total was -20.0. running mean: -20.53917576956164, timestamp: 2022-08-19 18:31:23.191150\n",
      "resetting env. episode 159, reward total was -21.0. running mean: -20.543784011866027, timestamp: 2022-08-19 18:31:25.305177\n",
      "resetting env. episode 160, reward total was -20.0. running mean: -20.538346171747367, timestamp: 2022-08-19 18:31:28.023206\n",
      "resetting env. episode 161, reward total was -21.0. running mean: -20.542962710029894, timestamp: 2022-08-19 18:31:29.492226\n",
      "resetting env. episode 162, reward total was -21.0. running mean: -20.547533082929597, timestamp: 2022-08-19 18:31:31.410244\n",
      "resetting env. episode 163, reward total was -18.0. running mean: -20.522057752100302, timestamp: 2022-08-19 18:31:33.821273\n",
      "resetting env. episode 164, reward total was -21.0. running mean: -20.5268371745793, timestamp: 2022-08-19 18:31:35.604293\n",
      "resetting env. episode 165, reward total was -21.0. running mean: -20.531568802833508, timestamp: 2022-08-19 18:31:37.889319\n",
      "resetting env. episode 166, reward total was -20.0. running mean: -20.526253114805172, timestamp: 2022-08-19 18:31:39.712342\n",
      "resetting env. episode 167, reward total was -21.0. running mean: -20.530990583657122, timestamp: 2022-08-19 18:31:41.544360\n",
      "resetting env. episode 168, reward total was -21.0. running mean: -20.53568067782055, timestamp: 2022-08-19 18:31:43.585385\n",
      "resetting env. episode 169, reward total was -21.0. running mean: -20.540323871042347, timestamp: 2022-08-19 18:31:45.069403\n",
      "resetting env. episode 170, reward total was -19.0. running mean: -20.524920632331924, timestamp: 2022-08-19 18:31:47.237425\n",
      "resetting env. episode 171, reward total was -20.0. running mean: -20.519671426008603, timestamp: 2022-08-19 18:31:49.428452\n",
      "resetting env. episode 172, reward total was -20.0. running mean: -20.514474711748516, timestamp: 2022-08-19 18:31:51.610478\n",
      "resetting env. episode 173, reward total was -19.0. running mean: -20.49932996463103, timestamp: 2022-08-19 18:31:53.958504\n",
      "resetting env. episode 174, reward total was -21.0. running mean: -20.50433666498472, timestamp: 2022-08-19 18:31:56.074530\n",
      "resetting env. episode 175, reward total was -21.0. running mean: -20.509293298334875, timestamp: 2022-08-19 18:31:57.616546\n",
      "resetting env. episode 176, reward total was -19.0. running mean: -20.494200365351528, timestamp: 2022-08-19 18:32:00.936586\n",
      "resetting env. episode 177, reward total was -20.0. running mean: -20.489258361698013, timestamp: 2022-08-19 18:32:02.714605\n",
      "resetting env. episode 178, reward total was -20.0. running mean: -20.48436577808103, timestamp: 2022-08-19 18:32:05.301635\n",
      "resetting env. episode 179, reward total was -21.0. running mean: -20.489522120300222, timestamp: 2022-08-19 18:32:07.256659\n",
      "resetting env. episode 180, reward total was -20.0. running mean: -20.48462689909722, timestamp: 2022-08-19 18:32:09.389680\n",
      "resetting env. episode 181, reward total was -21.0. running mean: -20.489780630106246, timestamp: 2022-08-19 18:32:11.247704\n",
      "resetting env. episode 182, reward total was -21.0. running mean: -20.494882823805185, timestamp: 2022-08-19 18:32:13.596730\n",
      "resetting env. episode 183, reward total was -19.0. running mean: -20.479933995567134, timestamp: 2022-08-19 18:32:16.063759\n",
      "resetting env. episode 184, reward total was -21.0. running mean: -20.485134655611464, timestamp: 2022-08-19 18:32:17.734780\n",
      "resetting env. episode 185, reward total was -20.0. running mean: -20.48028330905535, timestamp: 2022-08-19 18:32:19.774801\n",
      "resetting env. episode 186, reward total was -21.0. running mean: -20.485480475964795, timestamp: 2022-08-19 18:32:21.480826\n",
      "resetting env. episode 187, reward total was -21.0. running mean: -20.490625671205148, timestamp: 2022-08-19 18:32:23.613845\n",
      "resetting env. episode 188, reward total was -21.0. running mean: -20.4957194144931, timestamp: 2022-08-19 18:32:25.376865\n",
      "resetting env. episode 189, reward total was -19.0. running mean: -20.48076222034817, timestamp: 2022-08-19 18:32:27.688892\n",
      "resetting env. episode 190, reward total was -21.0. running mean: -20.485954598144687, timestamp: 2022-08-19 18:32:29.541912\n",
      "resetting env. episode 191, reward total was -19.0. running mean: -20.471095052163243, timestamp: 2022-08-19 18:32:31.907941\n",
      "resetting env. episode 192, reward total was -21.0. running mean: -20.47638410164161, timestamp: 2022-08-19 18:32:34.217966\n",
      "resetting env. episode 193, reward total was -20.0. running mean: -20.471620260625194, timestamp: 2022-08-19 18:32:36.435992\n",
      "resetting env. episode 194, reward total was -21.0. running mean: -20.476904058018942, timestamp: 2022-08-19 18:32:38.553016\n",
      "resetting env. episode 195, reward total was -20.0. running mean: -20.472135017438752, timestamp: 2022-08-19 18:32:40.651040\n",
      "resetting env. episode 196, reward total was -20.0. running mean: -20.467413667264363, timestamp: 2022-08-19 18:32:42.204058\n",
      "resetting env. episode 197, reward total was -19.0. running mean: -20.45273953059172, timestamp: 2022-08-19 18:32:44.124081\n",
      "resetting env. episode 198, reward total was -21.0. running mean: -20.458212135285805, timestamp: 2022-08-19 18:32:46.086103\n",
      "resetting env. episode 199, reward total was -21.0. running mean: -20.46363001393295, timestamp: 2022-08-19 18:32:47.831125\n",
      "resetting env. episode 200, reward total was -21.0. running mean: -20.46899371379362, timestamp: 2022-08-19 18:32:49.407140\n",
      "resetting env. episode 201, reward total was -21.0. running mean: -20.474303776655685, timestamp: 2022-08-19 18:32:51.450165\n",
      "resetting env. episode 202, reward total was -20.0. running mean: -20.469560738889125, timestamp: 2022-08-19 18:32:53.525188\n",
      "resetting env. episode 203, reward total was -21.0. running mean: -20.474865131500234, timestamp: 2022-08-19 18:32:55.611215\n",
      "resetting env. episode 204, reward total was -20.0. running mean: -20.47011648018523, timestamp: 2022-08-19 18:32:57.546236\n",
      "resetting env. episode 205, reward total was -20.0. running mean: -20.465415315383375, timestamp: 2022-08-19 18:32:59.306258\n",
      "resetting env. episode 206, reward total was -21.0. running mean: -20.470761162229543, timestamp: 2022-08-19 18:33:01.130278\n",
      "resetting env. episode 207, reward total was -21.0. running mean: -20.476053550607247, timestamp: 2022-08-19 18:33:02.798297\n",
      "resetting env. episode 208, reward total was -21.0. running mean: -20.481293015101176, timestamp: 2022-08-19 18:33:04.814322\n",
      "resetting env. episode 209, reward total was -21.0. running mean: -20.486480084950166, timestamp: 2022-08-19 18:33:06.930344\n",
      "resetting env. episode 210, reward total was -19.0. running mean: -20.471615284100665, timestamp: 2022-08-19 18:33:09.090370\n",
      "resetting env. episode 211, reward total was -21.0. running mean: -20.47689913125966, timestamp: 2022-08-19 18:33:10.491384\n",
      "resetting env. episode 212, reward total was -21.0. running mean: -20.482130139947063, timestamp: 2022-08-19 18:33:12.115404\n",
      "resetting env. episode 213, reward total was -21.0. running mean: -20.487308838547595, timestamp: 2022-08-19 18:33:13.612422\n",
      "resetting env. episode 214, reward total was -21.0. running mean: -20.49243575016212, timestamp: 2022-08-19 18:33:15.212439\n",
      "resetting env. episode 215, reward total was -21.0. running mean: -20.4975113926605, timestamp: 2022-08-19 18:33:17.097460\n",
      "resetting env. episode 216, reward total was -21.0. running mean: -20.502536278733896, timestamp: 2022-08-19 18:33:18.966483\n",
      "resetting env. episode 217, reward total was -21.0. running mean: -20.507510915946558, timestamp: 2022-08-19 18:33:20.608501\n",
      "resetting env. episode 218, reward total was -19.0. running mean: -20.492435806787093, timestamp: 2022-08-19 18:33:23.020528\n",
      "resetting env. episode 219, reward total was -20.0. running mean: -20.48751144871922, timestamp: 2022-08-19 18:33:24.999553\n",
      "resetting env. episode 220, reward total was -20.0. running mean: -20.48263633423203, timestamp: 2022-08-19 18:33:26.840571\n",
      "resetting env. episode 221, reward total was -20.0. running mean: -20.47780997088971, timestamp: 2022-08-19 18:33:29.376604\n",
      "resetting env. episode 222, reward total was -19.0. running mean: -20.463031871180814, timestamp: 2022-08-19 18:33:31.209622\n",
      "resetting env. episode 223, reward total was -21.0. running mean: -20.468401552469007, timestamp: 2022-08-19 18:33:33.480648\n",
      "resetting env. episode 224, reward total was -21.0. running mean: -20.473717536944317, timestamp: 2022-08-19 18:33:35.530673\n",
      "resetting env. episode 225, reward total was -21.0. running mean: -20.478980361574873, timestamp: 2022-08-19 18:33:37.391693\n",
      "resetting env. episode 226, reward total was -18.0. running mean: -20.454190557959123, timestamp: 2022-08-19 18:33:39.716721\n",
      "resetting env. episode 227, reward total was -20.0. running mean: -20.44964865237953, timestamp: 2022-08-19 18:33:41.354739\n",
      "resetting env. episode 228, reward total was -21.0. running mean: -20.455152165855736, timestamp: 2022-08-19 18:33:43.252763\n",
      "resetting env. episode 229, reward total was -21.0. running mean: -20.46060064419718, timestamp: 2022-08-19 18:33:44.964780\n",
      "resetting env. episode 230, reward total was -20.0. running mean: -20.455994637755207, timestamp: 2022-08-19 18:33:47.594810\n",
      "resetting env. episode 231, reward total was -20.0. running mean: -20.451434691377653, timestamp: 2022-08-19 18:33:49.390832\n",
      "resetting env. episode 232, reward total was -20.0. running mean: -20.446920344463877, timestamp: 2022-08-19 18:33:51.277852\n",
      "resetting env. episode 233, reward total was -20.0. running mean: -20.442451141019237, timestamp: 2022-08-19 18:33:53.084875\n",
      "resetting env. episode 234, reward total was -21.0. running mean: -20.448026629609046, timestamp: 2022-08-19 18:33:54.669890\n",
      "resetting env. episode 235, reward total was -21.0. running mean: -20.453546363312956, timestamp: 2022-08-19 18:33:56.481910\n",
      "resetting env. episode 236, reward total was -19.0. running mean: -20.43901089967983, timestamp: 2022-08-19 18:33:58.404933\n",
      "resetting env. episode 237, reward total was -21.0. running mean: -20.444620790683032, timestamp: 2022-08-19 18:34:00.496959\n",
      "resetting env. episode 238, reward total was -21.0. running mean: -20.450174582776203, timestamp: 2022-08-19 18:34:02.192978\n",
      "resetting env. episode 239, reward total was -20.0. running mean: -20.44567283694844, timestamp: 2022-08-19 18:34:04.180000\n",
      "resetting env. episode 240, reward total was -21.0. running mean: -20.451216108578954, timestamp: 2022-08-19 18:34:06.401023\n",
      "resetting env. episode 241, reward total was -19.0. running mean: -20.436703947493164, timestamp: 2022-08-19 18:34:08.544050\n",
      "resetting env. episode 242, reward total was -21.0. running mean: -20.442336908018234, timestamp: 2022-08-19 18:34:10.135068\n",
      "resetting env. episode 243, reward total was -21.0. running mean: -20.447913538938053, timestamp: 2022-08-19 18:34:11.866086\n",
      "resetting env. episode 244, reward total was -21.0. running mean: -20.453434403548673, timestamp: 2022-08-19 18:34:14.140113\n",
      "resetting env. episode 245, reward total was -20.0. running mean: -20.448900059513186, timestamp: 2022-08-19 18:34:15.912135\n",
      "resetting env. episode 246, reward total was -20.0. running mean: -20.444411058918053, timestamp: 2022-08-19 18:34:17.620152\n",
      "resetting env. episode 247, reward total was -20.0. running mean: -20.439966948328873, timestamp: 2022-08-19 18:34:19.622175\n",
      "resetting env. episode 248, reward total was -21.0. running mean: -20.445567278845584, timestamp: 2022-08-19 18:34:21.484197\n",
      "resetting env. episode 249, reward total was -21.0. running mean: -20.45111160605713, timestamp: 2022-08-19 18:34:23.439220\n",
      "resetting env. episode 250, reward total was -21.0. running mean: -20.456600489996557, timestamp: 2022-08-19 18:34:25.308239\n",
      "resetting env. episode 251, reward total was -21.0. running mean: -20.46203448509659, timestamp: 2022-08-19 18:34:27.049259\n",
      "resetting env. episode 252, reward total was -21.0. running mean: -20.467414140245626, timestamp: 2022-08-19 18:34:28.511276\n",
      "resetting env. episode 253, reward total was -21.0. running mean: -20.47273999884317, timestamp: 2022-08-19 18:34:30.561303\n",
      "resetting env. episode 254, reward total was -21.0. running mean: -20.47801259885474, timestamp: 2022-08-19 18:34:32.594323\n",
      "resetting env. episode 255, reward total was -20.0. running mean: -20.47323247286619, timestamp: 2022-08-19 18:34:34.569347\n",
      "resetting env. episode 256, reward total was -21.0. running mean: -20.478500148137528, timestamp: 2022-08-19 18:34:36.355368\n",
      "resetting env. episode 257, reward total was -21.0. running mean: -20.483715146656152, timestamp: 2022-08-19 18:34:38.345388\n",
      "resetting env. episode 258, reward total was -21.0. running mean: -20.48887799518959, timestamp: 2022-08-19 18:34:40.292412\n",
      "resetting env. episode 259, reward total was -21.0. running mean: -20.493989215237693, timestamp: 2022-08-19 18:34:42.118432\n",
      "resetting env. episode 260, reward total was -21.0. running mean: -20.499049323085316, timestamp: 2022-08-19 18:34:44.249455\n",
      "resetting env. episode 261, reward total was -21.0. running mean: -20.504058829854465, timestamp: 2022-08-19 18:34:45.582476\n",
      "resetting env. episode 262, reward total was -21.0. running mean: -20.50901824155592, timestamp: 2022-08-19 18:34:47.426491\n",
      "resetting env. episode 263, reward total was -19.0. running mean: -20.493928059140362, timestamp: 2022-08-19 18:34:49.672518\n",
      "resetting env. episode 264, reward total was -21.0. running mean: -20.49898877854896, timestamp: 2022-08-19 18:34:51.408540\n",
      "resetting env. episode 265, reward total was -21.0. running mean: -20.50399889076347, timestamp: 2022-08-19 18:34:53.240560\n",
      "resetting env. episode 266, reward total was -20.0. running mean: -20.498958901855833, timestamp: 2022-08-19 18:34:55.461584\n",
      "resetting env. episode 267, reward total was -21.0. running mean: -20.503969312837274, timestamp: 2022-08-19 18:34:57.653610\n",
      "resetting env. episode 268, reward total was -21.0. running mean: -20.5089296197089, timestamp: 2022-08-19 18:34:59.304627\n",
      "resetting env. episode 269, reward total was -21.0. running mean: -20.51384032351181, timestamp: 2022-08-19 18:35:01.237650\n",
      "resetting env. episode 270, reward total was -20.0. running mean: -20.508701920276692, timestamp: 2022-08-19 18:35:03.243671\n",
      "resetting env. episode 271, reward total was -20.0. running mean: -20.503614901073924, timestamp: 2022-08-19 18:35:06.088705\n",
      "resetting env. episode 272, reward total was -21.0. running mean: -20.508578752063187, timestamp: 2022-08-19 18:35:08.236729\n",
      "resetting env. episode 273, reward total was -20.0. running mean: -20.503492964542556, timestamp: 2022-08-19 18:35:10.449756\n",
      "resetting env. episode 274, reward total was -21.0. running mean: -20.50845803489713, timestamp: 2022-08-19 18:35:11.828774\n",
      "resetting env. episode 275, reward total was -18.0. running mean: -20.48337345454816, timestamp: 2022-08-19 18:35:14.309800\n",
      "resetting env. episode 276, reward total was -21.0. running mean: -20.48853972000268, timestamp: 2022-08-19 18:35:16.356822\n",
      "resetting env. episode 277, reward total was -19.0. running mean: -20.473654322802656, timestamp: 2022-08-19 18:35:18.473846\n",
      "resetting env. episode 278, reward total was -20.0. running mean: -20.468917779574628, timestamp: 2022-08-19 18:35:20.708873\n",
      "resetting env. episode 279, reward total was -21.0. running mean: -20.474228601778883, timestamp: 2022-08-19 18:35:22.446893\n",
      "resetting env. episode 280, reward total was -21.0. running mean: -20.479486315761093, timestamp: 2022-08-19 18:35:24.238911\n",
      "resetting env. episode 281, reward total was -20.0. running mean: -20.47469145260348, timestamp: 2022-08-19 18:35:26.544947\n",
      "resetting env. episode 282, reward total was -21.0. running mean: -20.479944538077447, timestamp: 2022-08-19 18:35:28.666962\n",
      "resetting env. episode 283, reward total was -21.0. running mean: -20.485145092696673, timestamp: 2022-08-19 18:35:30.769987\n",
      "resetting env. episode 284, reward total was -21.0. running mean: -20.490293641769707, timestamp: 2022-08-19 18:35:32.142001\n",
      "resetting env. episode 285, reward total was -21.0. running mean: -20.495390705352012, timestamp: 2022-08-19 18:35:33.838020\n",
      "resetting env. episode 286, reward total was -21.0. running mean: -20.50043679829849, timestamp: 2022-08-19 18:35:35.189038\n",
      "resetting env. episode 287, reward total was -21.0. running mean: -20.50543243031551, timestamp: 2022-08-19 18:35:36.759057\n",
      "resetting env. episode 288, reward total was -21.0. running mean: -20.510378106012354, timestamp: 2022-08-19 18:35:38.519075\n",
      "resetting env. episode 289, reward total was -21.0. running mean: -20.51527432495223, timestamp: 2022-08-19 18:35:40.020092\n",
      "resetting env. episode 290, reward total was -21.0. running mean: -20.520121581702707, timestamp: 2022-08-19 18:35:42.239115\n",
      "resetting env. episode 291, reward total was -21.0. running mean: -20.52492036588568, timestamp: 2022-08-19 18:35:43.958137\n",
      "resetting env. episode 292, reward total was -21.0. running mean: -20.529671162226826, timestamp: 2022-08-19 18:35:45.707158\n",
      "resetting env. episode 293, reward total was -19.0. running mean: -20.51437445060456, timestamp: 2022-08-19 18:35:47.856182\n",
      "resetting env. episode 294, reward total was -21.0. running mean: -20.519230706098515, timestamp: 2022-08-19 18:35:49.877202\n",
      "resetting env. episode 295, reward total was -21.0. running mean: -20.52403839903753, timestamp: 2022-08-19 18:35:52.095227\n",
      "resetting env. episode 296, reward total was -20.0. running mean: -20.518798015047153, timestamp: 2022-08-19 18:35:54.130250\n",
      "resetting env. episode 297, reward total was -20.0. running mean: -20.51361003489668, timestamp: 2022-08-19 18:35:56.223274\n",
      "resetting env. episode 298, reward total was -19.0. running mean: -20.498473934547714, timestamp: 2022-08-19 18:35:58.108297\n",
      "resetting env. episode 299, reward total was -21.0. running mean: -20.50348919520224, timestamp: 2022-08-19 18:35:59.921319\n",
      "resetting env. episode 300, reward total was -20.0. running mean: -20.498454303250217, timestamp: 2022-08-19 18:36:01.985338\n",
      "resetting env. episode 301, reward total was -19.0. running mean: -20.483469760217716, timestamp: 2022-08-19 18:36:03.885368\n",
      "resetting env. episode 302, reward total was -19.0. running mean: -20.46863506261554, timestamp: 2022-08-19 18:36:06.280390\n",
      "resetting env. episode 303, reward total was -21.0. running mean: -20.473948711989387, timestamp: 2022-08-19 18:36:07.968407\n",
      "resetting env. episode 304, reward total was -20.0. running mean: -20.46920922486949, timestamp: 2022-08-19 18:36:10.032432\n",
      "resetting env. episode 305, reward total was -21.0. running mean: -20.474517132620797, timestamp: 2022-08-19 18:36:11.997452\n",
      "resetting env. episode 306, reward total was -21.0. running mean: -20.47977196129459, timestamp: 2022-08-19 18:36:13.997477\n",
      "resetting env. episode 307, reward total was -20.0. running mean: -20.474974241681643, timestamp: 2022-08-19 18:36:15.978498\n",
      "resetting env. episode 308, reward total was -19.0. running mean: -20.46022449926483, timestamp: 2022-08-19 18:36:18.448526\n",
      "resetting env. episode 309, reward total was -21.0. running mean: -20.46562225427218, timestamp: 2022-08-19 18:36:20.293546\n",
      "resetting env. episode 310, reward total was -19.0. running mean: -20.450966031729457, timestamp: 2022-08-19 18:36:22.727575\n",
      "resetting env. episode 311, reward total was -21.0. running mean: -20.456456371412163, timestamp: 2022-08-19 18:36:24.872600\n",
      "resetting env. episode 312, reward total was -20.0. running mean: -20.45189180769804, timestamp: 2022-08-19 18:36:26.998624\n",
      "resetting env. episode 313, reward total was -20.0. running mean: -20.447372889621057, timestamp: 2022-08-19 18:36:28.773643\n",
      "resetting env. episode 314, reward total was -21.0. running mean: -20.452899160724847, timestamp: 2022-08-19 18:36:30.588664\n",
      "resetting env. episode 315, reward total was -21.0. running mean: -20.4583701691176, timestamp: 2022-08-19 18:36:32.611688\n",
      "resetting env. episode 316, reward total was -21.0. running mean: -20.463786467426424, timestamp: 2022-08-19 18:36:33.976701\n",
      "resetting env. episode 317, reward total was -20.0. running mean: -20.45914860275216, timestamp: 2022-08-19 18:36:37.022738\n",
      "resetting env. episode 318, reward total was -21.0. running mean: -20.464557116724638, timestamp: 2022-08-19 18:36:38.920757\n",
      "resetting env. episode 319, reward total was -21.0. running mean: -20.46991154555739, timestamp: 2022-08-19 18:36:40.888780\n",
      "resetting env. episode 320, reward total was -20.0. running mean: -20.465212430101815, timestamp: 2022-08-19 18:36:42.913801\n",
      "resetting env. episode 321, reward total was -21.0. running mean: -20.4705603058008, timestamp: 2022-08-19 18:36:45.142829\n",
      "resetting env. episode 322, reward total was -21.0. running mean: -20.47585470274279, timestamp: 2022-08-19 18:36:46.847848\n",
      "resetting env. episode 323, reward total was -20.0. running mean: -20.47109615571536, timestamp: 2022-08-19 18:36:48.721875\n",
      "resetting env. episode 324, reward total was -21.0. running mean: -20.47638519415821, timestamp: 2022-08-19 18:36:50.768891\n",
      "resetting env. episode 325, reward total was -21.0. running mean: -20.481621342216627, timestamp: 2022-08-19 18:36:52.596914\n",
      "resetting env. episode 326, reward total was -21.0. running mean: -20.48680512879446, timestamp: 2022-08-19 18:36:54.476933\n",
      "resetting env. episode 327, reward total was -21.0. running mean: -20.491937077506517, timestamp: 2022-08-19 18:36:56.468958\n",
      "resetting env. episode 328, reward total was -19.0. running mean: -20.477017706731452, timestamp: 2022-08-19 18:36:58.905985\n",
      "resetting env. episode 329, reward total was -21.0. running mean: -20.48224752966414, timestamp: 2022-08-19 18:37:01.026010\n",
      "resetting env. episode 330, reward total was -20.0. running mean: -20.477425054367497, timestamp: 2022-08-19 18:37:02.682026\n",
      "resetting env. episode 331, reward total was -20.0. running mean: -20.47265080382382, timestamp: 2022-08-19 18:37:04.530046\n",
      "resetting env. episode 332, reward total was -21.0. running mean: -20.477924295785584, timestamp: 2022-08-19 18:37:06.212067\n",
      "resetting env. episode 333, reward total was -20.0. running mean: -20.47314505282773, timestamp: 2022-08-19 18:37:08.006088\n",
      "resetting env. episode 334, reward total was -21.0. running mean: -20.47841360229945, timestamp: 2022-08-19 18:37:09.566103\n",
      "resetting env. episode 335, reward total was -21.0. running mean: -20.483629466276458, timestamp: 2022-08-19 18:37:11.550129\n",
      "resetting env. episode 336, reward total was -21.0. running mean: -20.488793171613693, timestamp: 2022-08-19 18:37:13.440150\n",
      "resetting env. episode 337, reward total was -21.0. running mean: -20.493905239897558, timestamp: 2022-08-19 18:37:15.274170\n",
      "resetting env. episode 338, reward total was -21.0. running mean: -20.49896618749858, timestamp: 2022-08-19 18:37:17.508193\n",
      "resetting env. episode 339, reward total was -21.0. running mean: -20.503976525623596, timestamp: 2022-08-19 18:37:19.546215\n",
      "resetting env. episode 340, reward total was -18.0. running mean: -20.47893676036736, timestamp: 2022-08-19 18:37:22.089243\n",
      "resetting env. episode 341, reward total was -19.0. running mean: -20.46414739276369, timestamp: 2022-08-19 18:37:24.226267\n",
      "resetting env. episode 342, reward total was -20.0. running mean: -20.45950591883605, timestamp: 2022-08-19 18:37:26.238292\n",
      "resetting env. episode 343, reward total was -19.0. running mean: -20.444910859647692, timestamp: 2022-08-19 18:37:28.732318\n",
      "resetting env. episode 344, reward total was -20.0. running mean: -20.440461751051213, timestamp: 2022-08-19 18:37:31.245345\n",
      "resetting env. episode 345, reward total was -19.0. running mean: -20.426057133540702, timestamp: 2022-08-19 18:37:33.449373\n",
      "resetting env. episode 346, reward total was -20.0. running mean: -20.421796562205294, timestamp: 2022-08-19 18:37:35.134388\n",
      "resetting env. episode 347, reward total was -21.0. running mean: -20.427578596583242, timestamp: 2022-08-19 18:37:36.864411\n",
      "resetting env. episode 348, reward total was -21.0. running mean: -20.43330281061741, timestamp: 2022-08-19 18:37:38.728429\n",
      "resetting env. episode 349, reward total was -21.0. running mean: -20.438969782511236, timestamp: 2022-08-19 18:37:40.236446\n",
      "resetting env. episode 350, reward total was -21.0. running mean: -20.444580084686123, timestamp: 2022-08-19 18:37:42.007465\n",
      "resetting env. episode 351, reward total was -21.0. running mean: -20.45013428383926, timestamp: 2022-08-19 18:37:43.626485\n",
      "resetting env. episode 352, reward total was -21.0. running mean: -20.45563294100087, timestamp: 2022-08-19 18:37:45.494504\n",
      "resetting env. episode 353, reward total was -20.0. running mean: -20.45107661159086, timestamp: 2022-08-19 18:37:47.261525\n",
      "resetting env. episode 354, reward total was -21.0. running mean: -20.45656584547495, timestamp: 2022-08-19 18:37:49.313548\n",
      "resetting env. episode 355, reward total was -21.0. running mean: -20.4620001870202, timestamp: 2022-08-19 18:37:51.159570\n",
      "resetting env. episode 356, reward total was -19.0. running mean: -20.44738018515, timestamp: 2022-08-19 18:37:53.208593\n",
      "resetting env. episode 357, reward total was -19.0. running mean: -20.4329063832985, timestamp: 2022-08-19 18:37:55.256616\n",
      "resetting env. episode 358, reward total was -21.0. running mean: -20.438577319465516, timestamp: 2022-08-19 18:37:57.299640\n",
      "resetting env. episode 359, reward total was -20.0. running mean: -20.43419154627086, timestamp: 2022-08-19 18:37:59.143659\n",
      "resetting env. episode 360, reward total was -21.0. running mean: -20.43984963080815, timestamp: 2022-08-19 18:38:00.737678\n",
      "resetting env. episode 361, reward total was -20.0. running mean: -20.43545113450007, timestamp: 2022-08-19 18:38:03.026703\n",
      "resetting env. episode 362, reward total was -21.0. running mean: -20.44109662315507, timestamp: 2022-08-19 18:38:05.091725\n",
      "resetting env. episode 363, reward total was -20.0. running mean: -20.43668565692352, timestamp: 2022-08-19 18:38:07.058747\n",
      "resetting env. episode 364, reward total was -21.0. running mean: -20.442318800354283, timestamp: 2022-08-19 18:38:08.755766\n",
      "resetting env. episode 365, reward total was -19.0. running mean: -20.427895612350742, timestamp: 2022-08-19 18:38:10.894790\n",
      "resetting env. episode 366, reward total was -21.0. running mean: -20.433616656227237, timestamp: 2022-08-19 18:38:12.746810\n",
      "resetting env. episode 367, reward total was -21.0. running mean: -20.439280489664966, timestamp: 2022-08-19 18:38:14.596833\n",
      "resetting env. episode 368, reward total was -21.0. running mean: -20.444887684768318, timestamp: 2022-08-19 18:38:16.648856\n",
      "resetting env. episode 369, reward total was -21.0. running mean: -20.450438807920637, timestamp: 2022-08-19 18:38:18.259875\n",
      "resetting env. episode 370, reward total was -21.0. running mean: -20.45593441984143, timestamp: 2022-08-19 18:38:20.310894\n",
      "resetting env. episode 371, reward total was -21.0. running mean: -20.461375075643016, timestamp: 2022-08-19 18:38:22.084925\n",
      "resetting env. episode 372, reward total was -21.0. running mean: -20.466761324886587, timestamp: 2022-08-19 18:38:23.725933\n",
      "resetting env. episode 373, reward total was -21.0. running mean: -20.472093711637722, timestamp: 2022-08-19 18:38:25.685957\n",
      "resetting env. episode 374, reward total was -21.0. running mean: -20.477372774521346, timestamp: 2022-08-19 18:38:27.643978\n",
      "resetting env. episode 375, reward total was -20.0. running mean: -20.472599046776132, timestamp: 2022-08-19 18:38:30.389008\n",
      "resetting env. episode 376, reward total was -18.0. running mean: -20.44787305630837, timestamp: 2022-08-19 18:38:33.307042\n",
      "resetting env. episode 377, reward total was -21.0. running mean: -20.453394325745286, timestamp: 2022-08-19 18:38:35.111063\n",
      "resetting env. episode 378, reward total was -21.0. running mean: -20.458860382487835, timestamp: 2022-08-19 18:38:36.542077\n",
      "resetting env. episode 379, reward total was -19.0. running mean: -20.44427177866296, timestamp: 2022-08-19 18:38:38.467102\n",
      "resetting env. episode 380, reward total was -20.0. running mean: -20.439829060876328, timestamp: 2022-08-19 18:38:40.387121\n",
      "resetting env. episode 381, reward total was -20.0. running mean: -20.435430770267562, timestamp: 2022-08-19 18:38:42.158143\n",
      "resetting env. episode 382, reward total was -20.0. running mean: -20.431076462564885, timestamp: 2022-08-19 18:38:44.232163\n",
      "resetting env. episode 383, reward total was -17.0. running mean: -20.396765697939237, timestamp: 2022-08-19 18:38:47.023195\n",
      "resetting env. episode 384, reward total was -21.0. running mean: -20.402798040959844, timestamp: 2022-08-19 18:38:48.784215\n",
      "resetting env. episode 385, reward total was -21.0. running mean: -20.408770060550246, timestamp: 2022-08-19 18:38:50.873237\n",
      "resetting env. episode 386, reward total was -20.0. running mean: -20.404682359944744, timestamp: 2022-08-19 18:38:52.606258\n",
      "resetting env. episode 387, reward total was -20.0. running mean: -20.400635536345295, timestamp: 2022-08-19 18:38:55.058285\n",
      "resetting env. episode 388, reward total was -21.0. running mean: -20.40662918098184, timestamp: 2022-08-19 18:38:56.917305\n",
      "resetting env. episode 389, reward total was -20.0. running mean: -20.40256288917202, timestamp: 2022-08-19 18:38:59.128331\n",
      "resetting env. episode 390, reward total was -20.0. running mean: -20.3985372602803, timestamp: 2022-08-19 18:39:01.294352\n",
      "resetting env. episode 391, reward total was -21.0. running mean: -20.404551887677496, timestamp: 2022-08-19 18:39:03.033376\n",
      "resetting env. episode 392, reward total was -21.0. running mean: -20.41050636880072, timestamp: 2022-08-19 18:39:04.717394\n",
      "resetting env. episode 393, reward total was -21.0. running mean: -20.416401305112714, timestamp: 2022-08-19 18:39:06.533420\n",
      "resetting env. episode 394, reward total was -20.0. running mean: -20.412237292061587, timestamp: 2022-08-19 18:39:08.968438\n",
      "resetting env. episode 395, reward total was -21.0. running mean: -20.418114919140972, timestamp: 2022-08-19 18:39:11.001464\n",
      "resetting env. episode 396, reward total was -20.0. running mean: -20.413933769949562, timestamp: 2022-08-19 18:39:13.047484\n",
      "resetting env. episode 397, reward total was -21.0. running mean: -20.419794432250068, timestamp: 2022-08-19 18:39:14.987508\n",
      "resetting env. episode 398, reward total was -20.0. running mean: -20.415596487927566, timestamp: 2022-08-19 18:39:17.054529\n",
      "resetting env. episode 399, reward total was -21.0. running mean: -20.42144052304829, timestamp: 2022-08-19 18:39:18.937548\n",
      "resetting env. episode 400, reward total was -19.0. running mean: -20.407226117817807, timestamp: 2022-08-19 18:39:21.024571\n",
      "resetting env. episode 401, reward total was -21.0. running mean: -20.413153856639628, timestamp: 2022-08-19 18:39:22.974593\n",
      "resetting env. episode 402, reward total was -21.0. running mean: -20.41902231807323, timestamp: 2022-08-19 18:39:24.579614\n",
      "resetting env. episode 403, reward total was -21.0. running mean: -20.4248320948925, timestamp: 2022-08-19 18:39:25.945627\n",
      "resetting env. episode 404, reward total was -21.0. running mean: -20.430583773943578, timestamp: 2022-08-19 18:39:27.924649\n",
      "resetting env. episode 405, reward total was -21.0. running mean: -20.436277936204142, timestamp: 2022-08-19 18:39:29.749670\n",
      "resetting env. episode 406, reward total was -20.0. running mean: -20.4319151568421, timestamp: 2022-08-19 18:39:32.308699\n",
      "resetting env. episode 407, reward total was -21.0. running mean: -20.43759600527368, timestamp: 2022-08-19 18:39:33.673715\n",
      "resetting env. episode 408, reward total was -20.0. running mean: -20.433220045220942, timestamp: 2022-08-19 18:39:35.421732\n",
      "resetting env. episode 409, reward total was -20.0. running mean: -20.42888784476873, timestamp: 2022-08-19 18:39:37.381758\n",
      "resetting env. episode 410, reward total was -21.0. running mean: -20.434598966321044, timestamp: 2022-08-19 18:39:39.077773\n",
      "resetting env. episode 411, reward total was -21.0. running mean: -20.440252976657835, timestamp: 2022-08-19 18:39:41.258801\n",
      "resetting env. episode 412, reward total was -20.0. running mean: -20.435850446891255, timestamp: 2022-08-19 18:39:43.554822\n",
      "resetting env. episode 413, reward total was -21.0. running mean: -20.441491942422342, timestamp: 2022-08-19 18:39:45.566845\n",
      "resetting env. episode 414, reward total was -19.0. running mean: -20.42707702299812, timestamp: 2022-08-19 18:39:48.002872\n",
      "resetting env. episode 415, reward total was -20.0. running mean: -20.422806252768137, timestamp: 2022-08-19 18:39:51.007904\n",
      "resetting env. episode 416, reward total was -21.0. running mean: -20.428578190240454, timestamp: 2022-08-19 18:39:52.924930\n",
      "resetting env. episode 417, reward total was -21.0. running mean: -20.43429240833805, timestamp: 2022-08-19 18:39:54.601945\n",
      "resetting env. episode 418, reward total was -20.0. running mean: -20.429949484254667, timestamp: 2022-08-19 18:39:56.397965\n",
      "resetting env. episode 419, reward total was -20.0. running mean: -20.42564998941212, timestamp: 2022-08-19 18:39:58.603989\n",
      "resetting env. episode 420, reward total was -21.0. running mean: -20.431393489517998, timestamp: 2022-08-19 18:40:00.697012\n",
      "resetting env. episode 421, reward total was -21.0. running mean: -20.43707955462282, timestamp: 2022-08-19 18:40:02.662038\n",
      "resetting env. episode 422, reward total was -21.0. running mean: -20.44270875907659, timestamp: 2022-08-19 18:40:04.286054\n",
      "resetting env. episode 423, reward total was -20.0. running mean: -20.438281671485825, timestamp: 2022-08-19 18:40:06.475078\n",
      "resetting env. episode 424, reward total was -20.0. running mean: -20.433898854770966, timestamp: 2022-08-19 18:40:08.482103\n",
      "resetting env. episode 425, reward total was -21.0. running mean: -20.439559866223256, timestamp: 2022-08-19 18:40:10.483121\n",
      "resetting env. episode 426, reward total was -21.0. running mean: -20.445164267561022, timestamp: 2022-08-19 18:40:12.188141\n",
      "resetting env. episode 427, reward total was -20.0. running mean: -20.44071262488541, timestamp: 2022-08-19 18:40:14.090162\n",
      "resetting env. episode 428, reward total was -21.0. running mean: -20.44630549863656, timestamp: 2022-08-19 18:40:16.208184\n",
      "resetting env. episode 429, reward total was -20.0. running mean: -20.44184244365019, timestamp: 2022-08-19 18:40:18.679213\n",
      "resetting env. episode 430, reward total was -19.0. running mean: -20.427424019213692, timestamp: 2022-08-19 18:40:20.875235\n",
      "resetting env. episode 431, reward total was -21.0. running mean: -20.433149779021555, timestamp: 2022-08-19 18:40:22.493255\n",
      "resetting env. episode 432, reward total was -21.0. running mean: -20.43881828123134, timestamp: 2022-08-19 18:40:24.680279\n",
      "resetting env. episode 433, reward total was -20.0. running mean: -20.43443009841903, timestamp: 2022-08-19 18:40:26.450301\n",
      "resetting env. episode 434, reward total was -20.0. running mean: -20.430085797434838, timestamp: 2022-08-19 18:40:28.748323\n",
      "resetting env. episode 435, reward total was -21.0. running mean: -20.43578493946049, timestamp: 2022-08-19 18:40:30.708347\n",
      "resetting env. episode 436, reward total was -18.0. running mean: -20.411427090065885, timestamp: 2022-08-19 18:40:32.648367\n",
      "resetting env. episode 437, reward total was -21.0. running mean: -20.417312819165225, timestamp: 2022-08-19 18:40:34.668392\n",
      "resetting env. episode 438, reward total was -19.0. running mean: -20.403139690973575, timestamp: 2022-08-19 18:40:36.723413\n",
      "resetting env. episode 439, reward total was -20.0. running mean: -20.399108294063836, timestamp: 2022-08-19 18:40:38.404433\n",
      "resetting env. episode 440, reward total was -21.0. running mean: -20.405117211123198, timestamp: 2022-08-19 18:40:40.087448\n",
      "resetting env. episode 441, reward total was -20.0. running mean: -20.401066039011965, timestamp: 2022-08-19 18:40:41.855470\n",
      "resetting env. episode 442, reward total was -20.0. running mean: -20.397055378621843, timestamp: 2022-08-19 18:40:44.087494\n",
      "resetting env. episode 443, reward total was -19.0. running mean: -20.383084824835628, timestamp: 2022-08-19 18:40:45.997517\n",
      "resetting env. episode 444, reward total was -20.0. running mean: -20.379253976587272, timestamp: 2022-08-19 18:40:48.409544\n",
      "resetting env. episode 445, reward total was -20.0. running mean: -20.375461436821396, timestamp: 2022-08-19 18:40:50.135560\n",
      "resetting env. episode 446, reward total was -19.0. running mean: -20.361706822453183, timestamp: 2022-08-19 18:40:52.172584\n",
      "resetting env. episode 447, reward total was -20.0. running mean: -20.35808975422865, timestamp: 2022-08-19 18:40:54.171606\n",
      "resetting env. episode 448, reward total was -20.0. running mean: -20.354508856686362, timestamp: 2022-08-19 18:40:55.831624\n",
      "resetting env. episode 449, reward total was -21.0. running mean: -20.3609637681195, timestamp: 2022-08-19 18:40:57.739646\n",
      "resetting env. episode 450, reward total was -20.0. running mean: -20.357354130438303, timestamp: 2022-08-19 18:41:00.419675\n",
      "resetting env. episode 451, reward total was -21.0. running mean: -20.36378058913392, timestamp: 2022-08-19 18:41:02.148695\n",
      "resetting env. episode 452, reward total was -20.0. running mean: -20.36014278324258, timestamp: 2022-08-19 18:41:03.983718\n",
      "resetting env. episode 453, reward total was -21.0. running mean: -20.366541355410156, timestamp: 2022-08-19 18:41:05.740734\n",
      "resetting env. episode 454, reward total was -20.0. running mean: -20.362875941856053, timestamp: 2022-08-19 18:41:07.805759\n",
      "resetting env. episode 455, reward total was -19.0. running mean: -20.349247182437495, timestamp: 2022-08-19 18:41:10.235785\n",
      "resetting env. episode 456, reward total was -21.0. running mean: -20.35575471061312, timestamp: 2022-08-19 18:41:11.797804\n",
      "resetting env. episode 457, reward total was -19.0. running mean: -20.342197163506988, timestamp: 2022-08-19 18:41:13.742826\n",
      "resetting env. episode 458, reward total was -19.0. running mean: -20.32877519187192, timestamp: 2022-08-19 18:41:16.481857\n",
      "resetting env. episode 459, reward total was -21.0. running mean: -20.3354874399532, timestamp: 2022-08-19 18:41:18.361876\n",
      "resetting env. episode 460, reward total was -21.0. running mean: -20.34213256555367, timestamp: 2022-08-19 18:41:20.724906\n",
      "resetting env. episode 461, reward total was -21.0. running mean: -20.348711239898133, timestamp: 2022-08-19 18:41:22.341930\n",
      "resetting env. episode 462, reward total was -21.0. running mean: -20.355224127499152, timestamp: 2022-08-19 18:41:24.121941\n",
      "resetting env. episode 463, reward total was -21.0. running mean: -20.361671886224162, timestamp: 2022-08-19 18:41:26.251967\n",
      "resetting env. episode 464, reward total was -20.0. running mean: -20.35805516736192, timestamp: 2022-08-19 18:41:28.327989\n",
      "resetting env. episode 465, reward total was -21.0. running mean: -20.364474615688298, timestamp: 2022-08-19 18:41:30.487017\n",
      "resetting env. episode 466, reward total was -21.0. running mean: -20.370829869531416, timestamp: 2022-08-19 18:41:32.357035\n",
      "resetting env. episode 467, reward total was -21.0. running mean: -20.377121570836103, timestamp: 2022-08-19 18:41:33.767050\n",
      "resetting env. episode 468, reward total was -20.0. running mean: -20.37335035512774, timestamp: 2022-08-19 18:41:35.743072\n",
      "resetting env. episode 469, reward total was -21.0. running mean: -20.379616851576465, timestamp: 2022-08-19 18:41:37.675097\n",
      "resetting env. episode 470, reward total was -21.0. running mean: -20.3858206830607, timestamp: 2022-08-19 18:41:39.889120\n",
      "resetting env. episode 471, reward total was -21.0. running mean: -20.391962476230095, timestamp: 2022-08-19 18:41:41.847142\n",
      "resetting env. episode 472, reward total was -20.0. running mean: -20.388042851467794, timestamp: 2022-08-19 18:41:44.068166\n",
      "resetting env. episode 473, reward total was -21.0. running mean: -20.394162422953116, timestamp: 2022-08-19 18:41:46.526195\n",
      "resetting env. episode 474, reward total was -20.0. running mean: -20.390220798723583, timestamp: 2022-08-19 18:41:48.458219\n",
      "resetting env. episode 475, reward total was -19.0. running mean: -20.376318590736346, timestamp: 2022-08-19 18:41:50.784242\n",
      "resetting env. episode 476, reward total was -20.0. running mean: -20.372555404828983, timestamp: 2022-08-19 18:41:52.353266\n",
      "resetting env. episode 477, reward total was -20.0. running mean: -20.368829850780692, timestamp: 2022-08-19 18:41:54.513284\n",
      "resetting env. episode 478, reward total was -21.0. running mean: -20.375141552272886, timestamp: 2022-08-19 18:41:56.318308\n",
      "resetting env. episode 479, reward total was -21.0. running mean: -20.38139013675016, timestamp: 2022-08-19 18:41:58.040326\n",
      "resetting env. episode 480, reward total was -19.0. running mean: -20.367576235382657, timestamp: 2022-08-19 18:42:00.321349\n",
      "resetting env. episode 481, reward total was -21.0. running mean: -20.373900473028833, timestamp: 2022-08-19 18:42:02.192379\n",
      "resetting env. episode 482, reward total was -19.0. running mean: -20.360161468298546, timestamp: 2022-08-19 18:42:04.695403\n",
      "resetting env. episode 483, reward total was -17.0. running mean: -20.326559853615564, timestamp: 2022-08-19 18:42:07.456431\n",
      "resetting env. episode 484, reward total was -19.0. running mean: -20.31329425507941, timestamp: 2022-08-19 18:42:09.761458\n",
      "resetting env. episode 485, reward total was -20.0. running mean: -20.310161312528614, timestamp: 2022-08-19 18:42:11.596477\n",
      "resetting env. episode 486, reward total was -21.0. running mean: -20.317059699403327, timestamp: 2022-08-19 18:42:13.602502\n",
      "resetting env. episode 487, reward total was -20.0. running mean: -20.31388910240929, timestamp: 2022-08-19 18:42:15.364521\n",
      "resetting env. episode 488, reward total was -21.0. running mean: -20.3207502113852, timestamp: 2022-08-19 18:42:17.329546\n",
      "resetting env. episode 489, reward total was -19.0. running mean: -20.30754270927135, timestamp: 2022-08-19 18:42:19.812571\n",
      "resetting env. episode 490, reward total was -21.0. running mean: -20.314467282178637, timestamp: 2022-08-19 18:42:21.805593\n",
      "resetting env. episode 491, reward total was -19.0. running mean: -20.301322609356852, timestamp: 2022-08-19 18:42:23.616615\n",
      "resetting env. episode 492, reward total was -21.0. running mean: -20.308309383263285, timestamp: 2022-08-19 18:42:25.600640\n",
      "resetting env. episode 493, reward total was -21.0. running mean: -20.315226289430655, timestamp: 2022-08-19 18:42:27.539660\n",
      "resetting env. episode 494, reward total was -18.0. running mean: -20.292074026536348, timestamp: 2022-08-19 18:42:29.899686\n",
      "resetting env. episode 495, reward total was -20.0. running mean: -20.289153286270984, timestamp: 2022-08-19 18:42:32.039711\n",
      "resetting env. episode 496, reward total was -21.0. running mean: -20.296261753408274, timestamp: 2022-08-19 18:42:33.624728\n",
      "resetting env. episode 497, reward total was -21.0. running mean: -20.30329913587419, timestamp: 2022-08-19 18:42:35.756753\n",
      "resetting env. episode 498, reward total was -20.0. running mean: -20.300266144515447, timestamp: 2022-08-19 18:42:37.812777\n",
      "resetting env. episode 499, reward total was -20.0. running mean: -20.297263483070292, timestamp: 2022-08-19 18:42:39.925801\n",
      "resetting env. episode 500, reward total was -19.0. running mean: -20.28429084823959, timestamp: 2022-08-19 18:42:41.924825\n",
      "resetting env. episode 501, reward total was -20.0. running mean: -20.281447939757193, timestamp: 2022-08-19 18:42:44.080849\n",
      "resetting env. episode 502, reward total was -21.0. running mean: -20.288633460359623, timestamp: 2022-08-19 18:42:46.018874\n",
      "resetting env. episode 503, reward total was -21.0. running mean: -20.295747125756026, timestamp: 2022-08-19 18:42:47.971891\n",
      "resetting env. episode 504, reward total was -19.0. running mean: -20.28278965449847, timestamp: 2022-08-19 18:42:50.257919\n",
      "resetting env. episode 505, reward total was -21.0. running mean: -20.289961757953485, timestamp: 2022-08-19 18:42:51.654935\n",
      "resetting env. episode 506, reward total was -21.0. running mean: -20.29706214037395, timestamp: 2022-08-19 18:42:53.376956\n",
      "resetting env. episode 507, reward total was -21.0. running mean: -20.30409151897021, timestamp: 2022-08-19 18:42:55.106975\n",
      "resetting env. episode 508, reward total was -21.0. running mean: -20.311050603780508, timestamp: 2022-08-19 18:42:57.063996\n",
      "resetting env. episode 509, reward total was -20.0. running mean: -20.3079400977427, timestamp: 2022-08-19 18:42:58.905018\n",
      "resetting env. episode 510, reward total was -21.0. running mean: -20.314860696765276, timestamp: 2022-08-19 18:43:01.067044\n",
      "resetting env. episode 511, reward total was -21.0. running mean: -20.321712089797625, timestamp: 2022-08-19 18:43:02.757060\n",
      "resetting env. episode 512, reward total was -18.0. running mean: -20.29849496889965, timestamp: 2022-08-19 18:43:04.646082\n",
      "resetting env. episode 513, reward total was -21.0. running mean: -20.305510019210654, timestamp: 2022-08-19 18:43:06.659105\n",
      "resetting env. episode 514, reward total was -21.0. running mean: -20.31245491901855, timestamp: 2022-08-19 18:43:08.641128\n",
      "resetting env. episode 515, reward total was -20.0. running mean: -20.309330369828363, timestamp: 2022-08-19 18:43:10.500150\n",
      "resetting env. episode 516, reward total was -21.0. running mean: -20.31623706613008, timestamp: 2022-08-19 18:43:12.089168\n",
      "resetting env. episode 517, reward total was -19.0. running mean: -20.30307469546878, timestamp: 2022-08-19 18:43:14.120192\n",
      "resetting env. episode 518, reward total was -21.0. running mean: -20.310043948514092, timestamp: 2022-08-19 18:43:16.086213\n",
      "resetting env. episode 519, reward total was -21.0. running mean: -20.316943509028953, timestamp: 2022-08-19 18:43:18.325241\n",
      "resetting env. episode 520, reward total was -20.0. running mean: -20.313774073938664, timestamp: 2022-08-19 18:43:20.025259\n",
      "resetting env. episode 521, reward total was -21.0. running mean: -20.32063633319928, timestamp: 2022-08-19 18:43:21.953280\n",
      "resetting env. episode 522, reward total was -20.0. running mean: -20.317429969867284, timestamp: 2022-08-19 18:43:23.829303\n",
      "resetting env. episode 523, reward total was -19.0. running mean: -20.30425567016861, timestamp: 2022-08-19 18:43:25.958328\n",
      "resetting env. episode 524, reward total was -21.0. running mean: -20.311213113466927, timestamp: 2022-08-19 18:43:27.433344\n",
      "resetting env. episode 525, reward total was -21.0. running mean: -20.318100982332258, timestamp: 2022-08-19 18:43:29.171365\n",
      "resetting env. episode 526, reward total was -20.0. running mean: -20.314919972508935, timestamp: 2022-08-19 18:43:30.914385\n",
      "resetting env. episode 527, reward total was -21.0. running mean: -20.321770772783847, timestamp: 2022-08-19 18:43:32.528402\n",
      "resetting env. episode 528, reward total was -21.0. running mean: -20.32855306505601, timestamp: 2022-08-19 18:43:34.662428\n",
      "resetting env. episode 529, reward total was -21.0. running mean: -20.33526753440545, timestamp: 2022-08-19 18:43:36.586450\n",
      "resetting env. episode 530, reward total was -21.0. running mean: -20.341914859061397, timestamp: 2022-08-19 18:43:38.103468\n",
      "resetting env. episode 531, reward total was -19.0. running mean: -20.328495710470783, timestamp: 2022-08-19 18:43:40.188491\n",
      "resetting env. episode 532, reward total was -19.0. running mean: -20.315210753366078, timestamp: 2022-08-19 18:43:42.233515\n",
      "resetting env. episode 533, reward total was -20.0. running mean: -20.312058645832415, timestamp: 2022-08-19 18:43:44.535542\n",
      "resetting env. episode 534, reward total was -20.0. running mean: -20.30893805937409, timestamp: 2022-08-19 18:43:46.618566\n",
      "resetting env. episode 535, reward total was -20.0. running mean: -20.305848678780347, timestamp: 2022-08-19 18:43:48.240586\n",
      "resetting env. episode 536, reward total was -20.0. running mean: -20.302790191992543, timestamp: 2022-08-19 18:43:50.123604\n",
      "resetting env. episode 537, reward total was -21.0. running mean: -20.30976229007262, timestamp: 2022-08-19 18:43:52.357632\n",
      "resetting env. episode 538, reward total was -21.0. running mean: -20.316664667171892, timestamp: 2022-08-19 18:43:54.481654\n",
      "resetting env. episode 539, reward total was -21.0. running mean: -20.323498020500175, timestamp: 2022-08-19 18:43:55.993675\n",
      "resetting env. episode 540, reward total was -21.0. running mean: -20.330263040295172, timestamp: 2022-08-19 18:43:58.027694\n",
      "resetting env. episode 541, reward total was -21.0. running mean: -20.33696040989222, timestamp: 2022-08-19 18:43:59.991722\n",
      "resetting env. episode 542, reward total was -21.0. running mean: -20.343590805793298, timestamp: 2022-08-19 18:44:01.631742\n",
      "resetting env. episode 543, reward total was -21.0. running mean: -20.350154897735365, timestamp: 2022-08-19 18:44:03.497762\n",
      "resetting env. episode 544, reward total was -19.0. running mean: -20.336653348758013, timestamp: 2022-08-19 18:44:05.775785\n",
      "resetting env. episode 545, reward total was -21.0. running mean: -20.34328681527043, timestamp: 2022-08-19 18:44:07.716810\n",
      "resetting env. episode 546, reward total was -21.0. running mean: -20.34985394711773, timestamp: 2022-08-19 18:44:09.539828\n",
      "resetting env. episode 547, reward total was -20.0. running mean: -20.346355407646552, timestamp: 2022-08-19 18:44:12.008860\n",
      "resetting env. episode 548, reward total was -21.0. running mean: -20.35289185357009, timestamp: 2022-08-19 18:44:14.073882\n",
      "resetting env. episode 549, reward total was -20.0. running mean: -20.34936293503439, timestamp: 2022-08-19 18:44:16.540910\n",
      "resetting env. episode 550, reward total was -19.0. running mean: -20.335869305684046, timestamp: 2022-08-19 18:44:19.045937\n",
      "resetting env. episode 551, reward total was -21.0. running mean: -20.342510612627205, timestamp: 2022-08-19 18:44:20.868960\n",
      "resetting env. episode 552, reward total was -21.0. running mean: -20.349085506500934, timestamp: 2022-08-19 18:44:22.905985\n",
      "resetting env. episode 553, reward total was -21.0. running mean: -20.355594651435926, timestamp: 2022-08-19 18:44:25.404012\n",
      "resetting env. episode 554, reward total was -21.0. running mean: -20.362038704921567, timestamp: 2022-08-19 18:44:26.962028\n",
      "resetting env. episode 555, reward total was -20.0. running mean: -20.35841831787235, timestamp: 2022-08-19 18:44:28.986052\n",
      "resetting env. episode 556, reward total was -21.0. running mean: -20.364834134693627, timestamp: 2022-08-19 18:44:30.963074\n",
      "resetting env. episode 557, reward total was -20.0. running mean: -20.36118579334669, timestamp: 2022-08-19 18:44:32.839096\n",
      "resetting env. episode 558, reward total was -20.0. running mean: -20.35757393541322, timestamp: 2022-08-19 18:44:34.469118\n",
      "resetting env. episode 559, reward total was -21.0. running mean: -20.36399819605909, timestamp: 2022-08-19 18:44:36.493142\n",
      "resetting env. episode 560, reward total was -21.0. running mean: -20.3703582140985, timestamp: 2022-08-19 18:44:38.435161\n",
      "resetting env. episode 561, reward total was -21.0. running mean: -20.376654631957514, timestamp: 2022-08-19 18:44:40.288184\n",
      "resetting env. episode 562, reward total was -19.0. running mean: -20.36288808563794, timestamp: 2022-08-19 18:44:42.634212\n",
      "resetting env. episode 563, reward total was -21.0. running mean: -20.369259204781564, timestamp: 2022-08-19 18:44:44.710234\n",
      "resetting env. episode 564, reward total was -20.0. running mean: -20.365566612733748, timestamp: 2022-08-19 18:44:46.945260\n",
      "resetting env. episode 565, reward total was -19.0. running mean: -20.35191094660641, timestamp: 2022-08-19 18:44:49.052283\n",
      "resetting env. episode 566, reward total was -21.0. running mean: -20.358391837140346, timestamp: 2022-08-19 18:44:50.981308\n",
      "resetting env. episode 567, reward total was -21.0. running mean: -20.364807918768943, timestamp: 2022-08-19 18:44:53.277333\n",
      "resetting env. episode 568, reward total was -20.0. running mean: -20.36115983958125, timestamp: 2022-08-19 18:44:55.518358\n",
      "resetting env. episode 569, reward total was -21.0. running mean: -20.36754824118544, timestamp: 2022-08-19 18:44:57.581382\n",
      "resetting env. episode 570, reward total was -21.0. running mean: -20.373872758773587, timestamp: 2022-08-19 18:44:59.354402\n",
      "resetting env. episode 571, reward total was -21.0. running mean: -20.38013403118585, timestamp: 2022-08-19 18:45:01.697429\n",
      "resetting env. episode 572, reward total was -19.0. running mean: -20.366332690873993, timestamp: 2022-08-19 18:45:03.930454\n",
      "resetting env. episode 573, reward total was -20.0. running mean: -20.362669363965253, timestamp: 2022-08-19 18:45:05.488475\n",
      "resetting env. episode 574, reward total was -21.0. running mean: -20.3690426703256, timestamp: 2022-08-19 18:45:07.708499\n",
      "resetting env. episode 575, reward total was -21.0. running mean: -20.375352243622345, timestamp: 2022-08-19 18:45:09.755525\n",
      "resetting env. episode 576, reward total was -21.0. running mean: -20.381598721186123, timestamp: 2022-08-19 18:45:11.563543\n",
      "resetting env. episode 577, reward total was -20.0. running mean: -20.37778273397426, timestamp: 2022-08-19 18:45:14.314575\n",
      "resetting env. episode 578, reward total was -20.0. running mean: -20.374004906634518, timestamp: 2022-08-19 18:45:16.709601\n",
      "resetting env. episode 579, reward total was -21.0. running mean: -20.380264857568175, timestamp: 2022-08-19 18:45:18.412621\n",
      "resetting env. episode 580, reward total was -20.0. running mean: -20.376462208992493, timestamp: 2022-08-19 18:45:20.745647\n",
      "resetting env. episode 581, reward total was -20.0. running mean: -20.372697586902568, timestamp: 2022-08-19 18:45:23.081679\n",
      "resetting env. episode 582, reward total was -20.0. running mean: -20.368970611033543, timestamp: 2022-08-19 18:45:25.146698\n",
      "resetting env. episode 583, reward total was -20.0. running mean: -20.365280904923207, timestamp: 2022-08-19 18:45:27.174724\n",
      "resetting env. episode 584, reward total was -21.0. running mean: -20.371628095873977, timestamp: 2022-08-19 18:45:28.673745\n",
      "resetting env. episode 585, reward total was -21.0. running mean: -20.377911814915237, timestamp: 2022-08-19 18:45:30.599764\n",
      "resetting env. episode 586, reward total was -20.0. running mean: -20.374132696766083, timestamp: 2022-08-19 18:45:32.688794\n",
      "resetting env. episode 587, reward total was -21.0. running mean: -20.38039136979842, timestamp: 2022-08-19 18:45:34.858813\n",
      "resetting env. episode 588, reward total was -21.0. running mean: -20.386587456100436, timestamp: 2022-08-19 18:45:36.344829\n",
      "resetting env. episode 589, reward total was -21.0. running mean: -20.392721581539433, timestamp: 2022-08-19 18:45:38.376852\n",
      "resetting env. episode 590, reward total was -21.0. running mean: -20.39879436572404, timestamp: 2022-08-19 18:45:40.465875\n",
      "resetting env. episode 591, reward total was -21.0. running mean: -20.4048064220668, timestamp: 2022-08-19 18:45:41.907896\n",
      "resetting env. episode 592, reward total was -21.0. running mean: -20.410758357846134, timestamp: 2022-08-19 18:45:44.040919\n",
      "resetting env. episode 593, reward total was -21.0. running mean: -20.416650774267673, timestamp: 2022-08-19 18:45:46.548949\n",
      "resetting env. episode 594, reward total was -19.0. running mean: -20.402484266524997, timestamp: 2022-08-19 18:45:48.639971\n",
      "resetting env. episode 595, reward total was -21.0. running mean: -20.408459423859746, timestamp: 2022-08-19 18:45:50.329991\n",
      "resetting env. episode 596, reward total was -20.0. running mean: -20.404374829621148, timestamp: 2022-08-19 18:45:52.411017\n",
      "resetting env. episode 597, reward total was -21.0. running mean: -20.410331081324937, timestamp: 2022-08-19 18:45:54.280036\n",
      "resetting env. episode 598, reward total was -20.0. running mean: -20.406227770511688, timestamp: 2022-08-19 18:45:56.389065\n",
      "resetting env. episode 599, reward total was -21.0. running mean: -20.412165492806572, timestamp: 2022-08-19 18:45:58.313083\n",
      "resetting env. episode 600, reward total was -19.0. running mean: -20.398043837878507, timestamp: 2022-08-19 18:46:00.648111\n",
      "resetting env. episode 601, reward total was -21.0. running mean: -20.404063399499723, timestamp: 2022-08-19 18:46:02.408132\n",
      "resetting env. episode 602, reward total was -21.0. running mean: -20.410022765504728, timestamp: 2022-08-19 18:46:04.194154\n",
      "resetting env. episode 603, reward total was -20.0. running mean: -20.40592253784968, timestamp: 2022-08-19 18:46:06.185178\n",
      "resetting env. episode 604, reward total was -19.0. running mean: -20.391863312471184, timestamp: 2022-08-19 18:46:08.262203\n",
      "resetting env. episode 605, reward total was -17.0. running mean: -20.357944679346474, timestamp: 2022-08-19 18:46:10.896231\n",
      "resetting env. episode 606, reward total was -21.0. running mean: -20.36436523255301, timestamp: 2022-08-19 18:46:12.740255\n",
      "resetting env. episode 607, reward total was -20.0. running mean: -20.360721580227477, timestamp: 2022-08-19 18:46:15.194282\n",
      "resetting env. episode 608, reward total was -20.0. running mean: -20.3571143644252, timestamp: 2022-08-19 18:46:17.228303\n",
      "resetting env. episode 609, reward total was -21.0. running mean: -20.36354322078095, timestamp: 2022-08-19 18:46:19.079325\n",
      "resetting env. episode 610, reward total was -21.0. running mean: -20.36990778857314, timestamp: 2022-08-19 18:46:21.364350\n",
      "resetting env. episode 611, reward total was -20.0. running mean: -20.36620871068741, timestamp: 2022-08-19 18:46:23.278377\n",
      "resetting env. episode 612, reward total was -21.0. running mean: -20.372546623580536, timestamp: 2022-08-19 18:46:24.829395\n",
      "resetting env. episode 613, reward total was -21.0. running mean: -20.37882115734473, timestamp: 2022-08-19 18:46:26.557412\n",
      "resetting env. episode 614, reward total was -20.0. running mean: -20.375032945771284, timestamp: 2022-08-19 18:46:28.522436\n",
      "resetting env. episode 615, reward total was -21.0. running mean: -20.381282616313573, timestamp: 2022-08-19 18:46:30.147452\n",
      "resetting env. episode 616, reward total was -21.0. running mean: -20.387469790150437, timestamp: 2022-08-19 18:46:32.373479\n",
      "resetting env. episode 617, reward total was -20.0. running mean: -20.38359509224893, timestamp: 2022-08-19 18:46:34.322501\n",
      "resetting env. episode 618, reward total was -20.0. running mean: -20.379759141326442, timestamp: 2022-08-19 18:46:36.342528\n",
      "resetting env. episode 619, reward total was -21.0. running mean: -20.38596154991318, timestamp: 2022-08-19 18:46:38.578553\n",
      "resetting env. episode 620, reward total was -21.0. running mean: -20.39210193441405, timestamp: 2022-08-19 18:46:40.475572\n",
      "resetting env. episode 621, reward total was -21.0. running mean: -20.39818091506991, timestamp: 2022-08-19 18:46:42.399596\n",
      "resetting env. episode 622, reward total was -19.0. running mean: -20.384199105919212, timestamp: 2022-08-19 18:46:44.495621\n",
      "resetting env. episode 623, reward total was -21.0. running mean: -20.39035711486002, timestamp: 2022-08-19 18:46:46.458643\n",
      "resetting env. episode 624, reward total was -20.0. running mean: -20.38645354371142, timestamp: 2022-08-19 18:46:48.790669\n",
      "resetting env. episode 625, reward total was -20.0. running mean: -20.382589008274305, timestamp: 2022-08-19 18:46:50.775695\n",
      "resetting env. episode 626, reward total was -21.0. running mean: -20.388763118191562, timestamp: 2022-08-19 18:46:52.613717\n",
      "resetting env. episode 627, reward total was -21.0. running mean: -20.394875487009646, timestamp: 2022-08-19 18:46:54.562739\n",
      "resetting env. episode 628, reward total was -21.0. running mean: -20.40092673213955, timestamp: 2022-08-19 18:46:56.312760\n",
      "resetting env. episode 629, reward total was -19.0. running mean: -20.386917464818154, timestamp: 2022-08-19 18:46:58.754791\n",
      "resetting env. episode 630, reward total was -21.0. running mean: -20.393048290169972, timestamp: 2022-08-19 18:47:00.663806\n",
      "resetting env. episode 631, reward total was -21.0. running mean: -20.399117807268272, timestamp: 2022-08-19 18:47:02.899833\n",
      "resetting env. episode 632, reward total was -20.0. running mean: -20.395126629195587, timestamp: 2022-08-19 18:47:05.115859\n",
      "resetting env. episode 633, reward total was -21.0. running mean: -20.401175362903633, timestamp: 2022-08-19 18:47:06.723880\n",
      "resetting env. episode 634, reward total was -21.0. running mean: -20.407163609274598, timestamp: 2022-08-19 18:47:08.373899\n",
      "resetting env. episode 635, reward total was -20.0. running mean: -20.40309197318185, timestamp: 2022-08-19 18:47:10.504920\n",
      "resetting env. episode 636, reward total was -21.0. running mean: -20.409061053450035, timestamp: 2022-08-19 18:47:12.521950\n",
      "resetting env. episode 637, reward total was -17.0. running mean: -20.374970442915536, timestamp: 2022-08-19 18:47:14.758973\n",
      "resetting env. episode 638, reward total was -21.0. running mean: -20.38122073848638, timestamp: 2022-08-19 18:47:16.617993\n",
      "resetting env. episode 639, reward total was -20.0. running mean: -20.377408531101516, timestamp: 2022-08-19 18:47:18.662019\n",
      "resetting env. episode 640, reward total was -21.0. running mean: -20.383634445790502, timestamp: 2022-08-19 18:47:20.645038\n",
      "resetting env. episode 641, reward total was -21.0. running mean: -20.389798101332598, timestamp: 2022-08-19 18:47:22.210059\n",
      "resetting env. episode 642, reward total was -21.0. running mean: -20.395900120319272, timestamp: 2022-08-19 18:47:24.333082\n",
      "resetting env. episode 643, reward total was -18.0. running mean: -20.37194111911608, timestamp: 2022-08-19 18:47:26.848111\n",
      "resetting env. episode 644, reward total was -21.0. running mean: -20.37822170792492, timestamp: 2022-08-19 18:47:28.651135\n",
      "resetting env. episode 645, reward total was -21.0. running mean: -20.38443949084567, timestamp: 2022-08-19 18:47:30.308160\n",
      "resetting env. episode 646, reward total was -21.0. running mean: -20.39059509593721, timestamp: 2022-08-19 18:47:32.319174\n",
      "resetting env. episode 647, reward total was -20.0. running mean: -20.38668914497784, timestamp: 2022-08-19 18:47:34.209196\n",
      "resetting env. episode 648, reward total was -21.0. running mean: -20.392822253528063, timestamp: 2022-08-19 18:47:35.898218\n",
      "resetting env. episode 649, reward total was -21.0. running mean: -20.398894030992782, timestamp: 2022-08-19 18:47:37.942242\n",
      "resetting env. episode 650, reward total was -20.0. running mean: -20.394905090682855, timestamp: 2022-08-19 18:47:40.006265\n",
      "resetting env. episode 651, reward total was -21.0. running mean: -20.400956039776027, timestamp: 2022-08-19 18:47:42.145292\n",
      "resetting env. episode 652, reward total was -20.0. running mean: -20.396946479378265, timestamp: 2022-08-19 18:47:44.256319\n",
      "resetting env. episode 653, reward total was -19.0. running mean: -20.382977014584483, timestamp: 2022-08-19 18:47:46.382337\n",
      "resetting env. episode 654, reward total was -21.0. running mean: -20.38914724443864, timestamp: 2022-08-19 18:47:47.994357\n",
      "resetting env. episode 655, reward total was -20.0. running mean: -20.385255771994252, timestamp: 2022-08-19 18:47:50.213390\n",
      "resetting env. episode 656, reward total was -21.0. running mean: -20.39140321427431, timestamp: 2022-08-19 18:47:52.242408\n",
      "resetting env. episode 657, reward total was -20.0. running mean: -20.387489182131564, timestamp: 2022-08-19 18:47:54.330435\n",
      "resetting env. episode 658, reward total was -21.0. running mean: -20.39361429031025, timestamp: 2022-08-19 18:47:56.677456\n",
      "resetting env. episode 659, reward total was -21.0. running mean: -20.399678147407148, timestamp: 2022-08-19 18:47:58.601481\n",
      "resetting env. episode 660, reward total was -21.0. running mean: -20.405681365933077, timestamp: 2022-08-19 18:48:00.950507\n",
      "resetting env. episode 661, reward total was -21.0. running mean: -20.411624552273747, timestamp: 2022-08-19 18:48:02.907529\n",
      "resetting env. episode 662, reward total was -21.0. running mean: -20.41750830675101, timestamp: 2022-08-19 18:48:04.700548\n",
      "resetting env. episode 663, reward total was -21.0. running mean: -20.4233332236835, timestamp: 2022-08-19 18:48:06.470570\n",
      "resetting env. episode 664, reward total was -21.0. running mean: -20.429099891446665, timestamp: 2022-08-19 18:48:08.929598\n",
      "resetting env. episode 665, reward total was -20.0. running mean: -20.424808892532198, timestamp: 2022-08-19 18:48:11.118624\n",
      "resetting env. episode 666, reward total was -18.0. running mean: -20.400560803606876, timestamp: 2022-08-19 18:48:13.630652\n",
      "resetting env. episode 667, reward total was -21.0. running mean: -20.406555195570807, timestamp: 2022-08-19 18:48:15.362675\n",
      "resetting env. episode 668, reward total was -21.0. running mean: -20.4124896436151, timestamp: 2022-08-19 18:48:17.612697\n",
      "resetting env. episode 669, reward total was -20.0. running mean: -20.408364747178947, timestamp: 2022-08-19 18:48:19.793724\n",
      "resetting env. episode 670, reward total was -20.0. running mean: -20.404281099707156, timestamp: 2022-08-19 18:48:22.553752\n",
      "resetting env. episode 671, reward total was -19.0. running mean: -20.390238288710083, timestamp: 2022-08-19 18:48:24.639778\n",
      "resetting env. episode 672, reward total was -19.0. running mean: -20.376335905822984, timestamp: 2022-08-19 18:48:26.993807\n",
      "resetting env. episode 673, reward total was -21.0. running mean: -20.382572546764756, timestamp: 2022-08-19 18:48:28.839829\n",
      "resetting env. episode 674, reward total was -19.0. running mean: -20.36874682129711, timestamp: 2022-08-19 18:48:31.197853\n",
      "resetting env. episode 675, reward total was -20.0. running mean: -20.365059353084135, timestamp: 2022-08-19 18:48:33.401880\n",
      "resetting env. episode 676, reward total was -20.0. running mean: -20.361408759553292, timestamp: 2022-08-19 18:48:35.761908\n",
      "resetting env. episode 677, reward total was -21.0. running mean: -20.36779467195776, timestamp: 2022-08-19 18:48:37.507929\n",
      "resetting env. episode 678, reward total was -20.0. running mean: -20.364116725238183, timestamp: 2022-08-19 18:48:39.961956\n",
      "resetting env. episode 679, reward total was -20.0. running mean: -20.3604755579858, timestamp: 2022-08-19 18:48:41.871978\n",
      "resetting env. episode 680, reward total was -21.0. running mean: -20.366870802405945, timestamp: 2022-08-19 18:48:44.477005\n",
      "resetting env. episode 681, reward total was -20.0. running mean: -20.363202094381883, timestamp: 2022-08-19 18:48:46.820036\n",
      "resetting env. episode 682, reward total was -20.0. running mean: -20.359570073438064, timestamp: 2022-08-19 18:48:48.976058\n",
      "resetting env. episode 683, reward total was -20.0. running mean: -20.35597437270368, timestamp: 2022-08-19 18:48:51.217087\n",
      "resetting env. episode 684, reward total was -20.0. running mean: -20.352414628976643, timestamp: 2022-08-19 18:48:53.151107\n",
      "resetting env. episode 685, reward total was -20.0. running mean: -20.348890482686876, timestamp: 2022-08-19 18:48:54.985127\n",
      "resetting env. episode 686, reward total was -21.0. running mean: -20.355401577860007, timestamp: 2022-08-19 18:48:56.673149\n",
      "resetting env. episode 687, reward total was -19.0. running mean: -20.34184756208141, timestamp: 2022-08-19 18:48:58.674169\n",
      "resetting env. episode 688, reward total was -21.0. running mean: -20.348429086460595, timestamp: 2022-08-19 18:49:00.313191\n",
      "resetting env. episode 689, reward total was -19.0. running mean: -20.33494479559599, timestamp: 2022-08-19 18:49:03.134223\n",
      "resetting env. episode 690, reward total was -21.0. running mean: -20.34159534764003, timestamp: 2022-08-19 18:49:06.884263\n",
      "resetting env. episode 691, reward total was -21.0. running mean: -20.34817939416363, timestamp: 2022-08-19 18:49:09.664296\n",
      "resetting env. episode 692, reward total was -19.0. running mean: -20.334697600221993, timestamp: 2022-08-19 18:49:12.096325\n",
      "resetting env. episode 693, reward total was -21.0. running mean: -20.341350624219775, timestamp: 2022-08-19 18:49:13.798346\n",
      "resetting env. episode 694, reward total was -21.0. running mean: -20.347937117977576, timestamp: 2022-08-19 18:49:16.116372\n",
      "resetting env. episode 695, reward total was -20.0. running mean: -20.3444577467978, timestamp: 2022-08-19 18:49:18.154392\n",
      "resetting env. episode 696, reward total was -21.0. running mean: -20.351013169329825, timestamp: 2022-08-19 18:49:20.049414\n",
      "resetting env. episode 697, reward total was -21.0. running mean: -20.357503037636526, timestamp: 2022-08-19 18:49:22.017440\n",
      "resetting env. episode 698, reward total was -21.0. running mean: -20.36392800726016, timestamp: 2022-08-19 18:49:24.131467\n",
      "resetting env. episode 699, reward total was -21.0. running mean: -20.37028872718756, timestamp: 2022-08-19 18:49:26.255487\n",
      "resetting env. episode 700, reward total was -21.0. running mean: -20.376585839915684, timestamp: 2022-08-19 18:49:27.936507\n",
      "resetting env. episode 701, reward total was -21.0. running mean: -20.382819981516526, timestamp: 2022-08-19 18:49:29.828528\n",
      "resetting env. episode 702, reward total was -21.0. running mean: -20.38899178170136, timestamp: 2022-08-19 18:49:31.424546\n",
      "resetting env. episode 703, reward total was -21.0. running mean: -20.395101863884346, timestamp: 2022-08-19 18:49:33.279569\n",
      "resetting env. episode 704, reward total was -20.0. running mean: -20.3911508452455, timestamp: 2022-08-19 18:49:35.408591\n",
      "resetting env. episode 705, reward total was -20.0. running mean: -20.387239336793044, timestamp: 2022-08-19 18:49:37.554619\n",
      "resetting env. episode 706, reward total was -21.0. running mean: -20.393366943425114, timestamp: 2022-08-19 18:49:39.190634\n",
      "resetting env. episode 707, reward total was -20.0. running mean: -20.38943327399086, timestamp: 2022-08-19 18:49:41.307659\n",
      "resetting env. episode 708, reward total was -20.0. running mean: -20.38553894125095, timestamp: 2022-08-19 18:49:43.302686\n",
      "resetting env. episode 709, reward total was -18.0. running mean: -20.36168355183844, timestamp: 2022-08-19 18:49:45.444712\n",
      "resetting env. episode 710, reward total was -21.0. running mean: -20.368066716320055, timestamp: 2022-08-19 18:49:47.241729\n",
      "resetting env. episode 711, reward total was -21.0. running mean: -20.374386049156854, timestamp: 2022-08-19 18:49:48.893749\n",
      "resetting env. episode 712, reward total was -19.0. running mean: -20.360642188665288, timestamp: 2022-08-19 18:49:50.971772\n",
      "resetting env. episode 713, reward total was -21.0. running mean: -20.367035766778635, timestamp: 2022-08-19 18:49:52.752794\n",
      "resetting env. episode 714, reward total was -21.0. running mean: -20.37336540911085, timestamp: 2022-08-19 18:49:54.379813\n",
      "resetting env. episode 715, reward total was -21.0. running mean: -20.37963175501974, timestamp: 2022-08-19 18:49:56.460837\n",
      "resetting env. episode 716, reward total was -21.0. running mean: -20.385835437469545, timestamp: 2022-08-19 18:49:58.375861\n",
      "resetting env. episode 717, reward total was -21.0. running mean: -20.39197708309485, timestamp: 2022-08-19 18:50:00.056877\n",
      "resetting env. episode 718, reward total was -20.0. running mean: -20.3880573122639, timestamp: 2022-08-19 18:50:02.513904\n",
      "resetting env. episode 719, reward total was -20.0. running mean: -20.38417673914126, timestamp: 2022-08-19 18:50:04.601927\n",
      "resetting env. episode 720, reward total was -20.0. running mean: -20.380334971749846, timestamp: 2022-08-19 18:50:07.063955\n",
      "resetting env. episode 721, reward total was -20.0. running mean: -20.376531622032346, timestamp: 2022-08-19 18:50:09.386983\n",
      "resetting env. episode 722, reward total was -21.0. running mean: -20.382766305812023, timestamp: 2022-08-19 18:50:12.042014\n",
      "resetting env. episode 723, reward total was -20.0. running mean: -20.3789386427539, timestamp: 2022-08-19 18:50:13.967037\n",
      "resetting env. episode 724, reward total was -20.0. running mean: -20.375149256326363, timestamp: 2022-08-19 18:50:16.286061\n",
      "resetting env. episode 725, reward total was -20.0. running mean: -20.3713977637631, timestamp: 2022-08-19 18:50:18.367087\n",
      "resetting env. episode 726, reward total was -21.0. running mean: -20.37768378612547, timestamp: 2022-08-19 18:50:20.052109\n",
      "resetting env. episode 727, reward total was -21.0. running mean: -20.383906948264215, timestamp: 2022-08-19 18:50:21.962127\n",
      "resetting env. episode 728, reward total was -21.0. running mean: -20.390067878781572, timestamp: 2022-08-19 18:50:23.736149\n",
      "resetting env. episode 729, reward total was -21.0. running mean: -20.39616719999376, timestamp: 2022-08-19 18:50:25.246165\n",
      "resetting env. episode 730, reward total was -21.0. running mean: -20.40220552799382, timestamp: 2022-08-19 18:50:27.316188\n",
      "resetting env. episode 731, reward total was -21.0. running mean: -20.408183472713883, timestamp: 2022-08-19 18:50:29.333212\n",
      "resetting env. episode 732, reward total was -21.0. running mean: -20.414101637986747, timestamp: 2022-08-19 18:50:31.655238\n",
      "resetting env. episode 733, reward total was -21.0. running mean: -20.41996062160688, timestamp: 2022-08-19 18:50:33.247262\n",
      "resetting env. episode 734, reward total was -20.0. running mean: -20.41576101539081, timestamp: 2022-08-19 18:50:35.226280\n",
      "resetting env. episode 735, reward total was -20.0. running mean: -20.4116034052369, timestamp: 2022-08-19 18:50:37.319303\n",
      "resetting env. episode 736, reward total was -20.0. running mean: -20.40748737118453, timestamp: 2022-08-19 18:50:39.314327\n",
      "resetting env. episode 737, reward total was -20.0. running mean: -20.403412497472683, timestamp: 2022-08-19 18:50:41.525353\n",
      "resetting env. episode 738, reward total was -21.0. running mean: -20.409378372497958, timestamp: 2022-08-19 18:50:43.720377\n",
      "resetting env. episode 739, reward total was -21.0. running mean: -20.41528458877298, timestamp: 2022-08-19 18:50:45.829405\n",
      "resetting env. episode 740, reward total was -17.0. running mean: -20.381131742885252, timestamp: 2022-08-19 18:50:48.370430\n",
      "resetting env. episode 741, reward total was -20.0. running mean: -20.3773204254564, timestamp: 2022-08-19 18:50:50.650457\n",
      "resetting env. episode 742, reward total was -21.0. running mean: -20.383547221201837, timestamp: 2022-08-19 18:50:52.391476\n",
      "resetting env. episode 743, reward total was -21.0. running mean: -20.38971174898982, timestamp: 2022-08-19 18:50:54.822505\n",
      "resetting env. episode 744, reward total was -21.0. running mean: -20.395814631499924, timestamp: 2022-08-19 18:50:56.695526\n",
      "resetting env. episode 745, reward total was -20.0. running mean: -20.391856485184924, timestamp: 2022-08-19 18:50:58.496545\n",
      "resetting env. episode 746, reward total was -20.0. running mean: -20.387937920333073, timestamp: 2022-08-19 18:51:00.797572\n",
      "resetting env. episode 747, reward total was -21.0. running mean: -20.39405854112974, timestamp: 2022-08-19 18:51:03.657605\n",
      "resetting env. episode 748, reward total was -21.0. running mean: -20.400117955718443, timestamp: 2022-08-19 18:51:05.381625\n",
      "resetting env. episode 749, reward total was -21.0. running mean: -20.40611677616126, timestamp: 2022-08-19 18:51:07.142647\n",
      "resetting env. episode 750, reward total was -21.0. running mean: -20.412055608399648, timestamp: 2022-08-19 18:51:08.793665\n",
      "resetting env. episode 751, reward total was -21.0. running mean: -20.417935052315652, timestamp: 2022-08-19 18:51:10.837687\n",
      "resetting env. episode 752, reward total was -21.0. running mean: -20.423755701792498, timestamp: 2022-08-19 18:51:12.695708\n",
      "resetting env. episode 753, reward total was -19.0. running mean: -20.409518144774573, timestamp: 2022-08-19 18:51:15.474740\n",
      "resetting env. episode 754, reward total was -20.0. running mean: -20.405422963326828, timestamp: 2022-08-19 18:51:17.451765\n",
      "resetting env. episode 755, reward total was -20.0. running mean: -20.40136873369356, timestamp: 2022-08-19 18:51:19.199781\n",
      "resetting env. episode 756, reward total was -21.0. running mean: -20.407355046356624, timestamp: 2022-08-19 18:51:21.256811\n",
      "resetting env. episode 757, reward total was -21.0. running mean: -20.41328149589306, timestamp: 2022-08-19 18:51:23.618832\n",
      "resetting env. episode 758, reward total was -20.0. running mean: -20.409148680934127, timestamp: 2022-08-19 18:51:25.471855\n",
      "resetting env. episode 759, reward total was -19.0. running mean: -20.395057194124785, timestamp: 2022-08-19 18:51:27.247876\n",
      "resetting env. episode 760, reward total was -19.0. running mean: -20.381106622183538, timestamp: 2022-08-19 18:51:29.047896\n",
      "resetting env. episode 761, reward total was -19.0. running mean: -20.367295555961704, timestamp: 2022-08-19 18:51:31.640924\n",
      "resetting env. episode 762, reward total was -20.0. running mean: -20.363622600402085, timestamp: 2022-08-19 18:51:33.661950\n",
      "resetting env. episode 763, reward total was -21.0. running mean: -20.369986374398064, timestamp: 2022-08-19 18:51:35.828971\n",
      "resetting env. episode 764, reward total was -20.0. running mean: -20.36628651065408, timestamp: 2022-08-19 18:51:38.216000\n",
      "resetting env. episode 765, reward total was -21.0. running mean: -20.37262364554754, timestamp: 2022-08-19 18:51:39.822021\n",
      "resetting env. episode 766, reward total was -21.0. running mean: -20.378897409092065, timestamp: 2022-08-19 18:51:41.883041\n",
      "resetting env. episode 767, reward total was -20.0. running mean: -20.375108435001145, timestamp: 2022-08-19 18:51:44.242070\n",
      "resetting env. episode 768, reward total was -21.0. running mean: -20.381357350651136, timestamp: 2022-08-19 18:51:45.894090\n",
      "resetting env. episode 769, reward total was -21.0. running mean: -20.387543777144625, timestamp: 2022-08-19 18:51:48.034111\n",
      "resetting env. episode 770, reward total was -21.0. running mean: -20.39366833937318, timestamp: 2022-08-19 18:51:49.891134\n",
      "resetting env. episode 771, reward total was -21.0. running mean: -20.399731655979448, timestamp: 2022-08-19 18:51:51.640152\n",
      "resetting env. episode 772, reward total was -20.0. running mean: -20.39573433941965, timestamp: 2022-08-19 18:51:54.058181\n",
      "resetting env. episode 773, reward total was -20.0. running mean: -20.391776996025452, timestamp: 2022-08-19 18:51:56.401208\n",
      "resetting env. episode 774, reward total was -21.0. running mean: -20.397859226065197, timestamp: 2022-08-19 18:51:57.720221\n",
      "resetting env. episode 775, reward total was -19.0. running mean: -20.383880633804548, timestamp: 2022-08-19 18:51:59.965249\n",
      "resetting env. episode 776, reward total was -21.0. running mean: -20.390041827466504, timestamp: 2022-08-19 18:52:01.610265\n",
      "resetting env. episode 777, reward total was -20.0. running mean: -20.38614140919184, timestamp: 2022-08-19 18:52:03.277286\n",
      "resetting env. episode 778, reward total was -20.0. running mean: -20.38227999509992, timestamp: 2022-08-19 18:52:05.312311\n",
      "resetting env. episode 779, reward total was -21.0. running mean: -20.388457195148924, timestamp: 2022-08-19 18:52:07.083330\n",
      "resetting env. episode 780, reward total was -21.0. running mean: -20.394572623197433, timestamp: 2022-08-19 18:52:09.418356\n",
      "resetting env. episode 781, reward total was -21.0. running mean: -20.40062689696546, timestamp: 2022-08-19 18:52:11.380381\n",
      "resetting env. episode 782, reward total was -21.0. running mean: -20.406620627995807, timestamp: 2022-08-19 18:52:12.876393\n",
      "resetting env. episode 783, reward total was -19.0. running mean: -20.39255442171585, timestamp: 2022-08-19 18:52:15.171420\n",
      "resetting env. episode 784, reward total was -21.0. running mean: -20.39862887749869, timestamp: 2022-08-19 18:52:17.343444\n",
      "resetting env. episode 785, reward total was -20.0. running mean: -20.394642588723702, timestamp: 2022-08-19 18:52:19.584473\n",
      "resetting env. episode 786, reward total was -20.0. running mean: -20.390696162836463, timestamp: 2022-08-19 18:52:21.523493\n",
      "resetting env. episode 787, reward total was -21.0. running mean: -20.396789201208097, timestamp: 2022-08-19 18:52:23.502515\n",
      "resetting env. episode 788, reward total was -21.0. running mean: -20.402821309196018, timestamp: 2022-08-19 18:52:25.458536\n",
      "resetting env. episode 789, reward total was -21.0. running mean: -20.40879309610406, timestamp: 2022-08-19 18:52:27.218559\n",
      "resetting env. episode 790, reward total was -20.0. running mean: -20.404705165143017, timestamp: 2022-08-19 18:52:29.357581\n",
      "resetting env. episode 791, reward total was -21.0. running mean: -20.41065811349159, timestamp: 2022-08-19 18:52:32.109613\n",
      "resetting env. episode 792, reward total was -21.0. running mean: -20.416551532356674, timestamp: 2022-08-19 18:52:34.052638\n",
      "resetting env. episode 793, reward total was -20.0. running mean: -20.412386017033107, timestamp: 2022-08-19 18:52:36.535666\n",
      "resetting env. episode 794, reward total was -19.0. running mean: -20.398262156862778, timestamp: 2022-08-19 18:52:39.780701\n",
      "resetting env. episode 795, reward total was -21.0. running mean: -20.40427953529415, timestamp: 2022-08-19 18:52:41.388720\n",
      "resetting env. episode 796, reward total was -19.0. running mean: -20.390236739941212, timestamp: 2022-08-19 18:52:43.823747\n",
      "resetting env. episode 797, reward total was -21.0. running mean: -20.3963343725418, timestamp: 2022-08-19 18:52:45.994777\n",
      "resetting env. episode 798, reward total was -20.0. running mean: -20.39237102881638, timestamp: 2022-08-19 18:52:48.124794\n",
      "resetting env. episode 799, reward total was -21.0. running mean: -20.398447318528216, timestamp: 2022-08-19 18:52:50.007821\n",
      "resetting env. episode 800, reward total was -21.0. running mean: -20.404462845342934, timestamp: 2022-08-19 18:52:51.742836\n",
      "resetting env. episode 801, reward total was -21.0. running mean: -20.410418216889504, timestamp: 2022-08-19 18:52:53.661857\n",
      "resetting env. episode 802, reward total was -21.0. running mean: -20.41631403472061, timestamp: 2022-08-19 18:52:55.584878\n",
      "resetting env. episode 803, reward total was -20.0. running mean: -20.412150894373404, timestamp: 2022-08-19 18:52:57.688905\n",
      "resetting env. episode 804, reward total was -18.0. running mean: -20.388029385429668, timestamp: 2022-08-19 18:53:00.119933\n",
      "resetting env. episode 805, reward total was -20.0. running mean: -20.38414909157537, timestamp: 2022-08-19 18:53:01.839949\n",
      "resetting env. episode 806, reward total was -21.0. running mean: -20.390307600659618, timestamp: 2022-08-19 18:53:04.067977\n",
      "resetting env. episode 807, reward total was -21.0. running mean: -20.396404524653022, timestamp: 2022-08-19 18:53:06.189000\n",
      "resetting env. episode 808, reward total was -21.0. running mean: -20.402440479406494, timestamp: 2022-08-19 18:53:08.307026\n",
      "resetting env. episode 809, reward total was -21.0. running mean: -20.40841607461243, timestamp: 2022-08-19 18:53:10.375049\n",
      "resetting env. episode 810, reward total was -20.0. running mean: -20.404331913866304, timestamp: 2022-08-19 18:53:12.787074\n",
      "resetting env. episode 811, reward total was -20.0. running mean: -20.40028859472764, timestamp: 2022-08-19 18:53:14.732100\n",
      "resetting env. episode 812, reward total was -20.0. running mean: -20.396285708780365, timestamp: 2022-08-19 18:53:16.607119\n",
      "resetting env. episode 813, reward total was -20.0. running mean: -20.392322851692562, timestamp: 2022-08-19 18:53:18.488140\n",
      "resetting env. episode 814, reward total was -21.0. running mean: -20.39839962317564, timestamp: 2022-08-19 18:53:19.971159\n",
      "resetting env. episode 815, reward total was -21.0. running mean: -20.404415626943884, timestamp: 2022-08-19 18:53:21.797177\n",
      "resetting env. episode 816, reward total was -21.0. running mean: -20.410371470674445, timestamp: 2022-08-19 18:53:23.832197\n",
      "resetting env. episode 817, reward total was -20.0. running mean: -20.4062677559677, timestamp: 2022-08-19 18:53:25.727220\n",
      "resetting env. episode 818, reward total was -21.0. running mean: -20.412205078408025, timestamp: 2022-08-19 18:53:27.764245\n",
      "resetting env. episode 819, reward total was -20.0. running mean: -20.408083027623945, timestamp: 2022-08-19 18:53:29.810270\n",
      "resetting env. episode 820, reward total was -20.0. running mean: -20.404002197347705, timestamp: 2022-08-19 18:53:31.952289\n",
      "resetting env. episode 821, reward total was -21.0. running mean: -20.40996217537423, timestamp: 2022-08-19 18:53:34.060314\n",
      "resetting env. episode 822, reward total was -21.0. running mean: -20.41586255362049, timestamp: 2022-08-19 18:53:36.448340\n",
      "resetting env. episode 823, reward total was -21.0. running mean: -20.421703928084284, timestamp: 2022-08-19 18:53:38.118362\n",
      "resetting env. episode 824, reward total was -21.0. running mean: -20.427486888803443, timestamp: 2022-08-19 18:53:39.932379\n",
      "resetting env. episode 825, reward total was -19.0. running mean: -20.41321201991541, timestamp: 2022-08-19 18:53:42.083407\n",
      "resetting env. episode 826, reward total was -20.0. running mean: -20.409079899716254, timestamp: 2022-08-19 18:53:44.187429\n",
      "resetting env. episode 827, reward total was -21.0. running mean: -20.41498910071909, timestamp: 2022-08-19 18:53:45.846449\n",
      "resetting env. episode 828, reward total was -20.0. running mean: -20.4108392097119, timestamp: 2022-08-19 18:53:48.052476\n",
      "resetting env. episode 829, reward total was -21.0. running mean: -20.41673081761478, timestamp: 2022-08-19 18:53:49.842492\n",
      "resetting env. episode 830, reward total was -21.0. running mean: -20.422563509438632, timestamp: 2022-08-19 18:53:51.534514\n",
      "resetting env. episode 831, reward total was -21.0. running mean: -20.428337874344248, timestamp: 2022-08-19 18:53:53.347531\n",
      "resetting env. episode 832, reward total was -20.0. running mean: -20.424054495600803, timestamp: 2022-08-19 18:53:56.075564\n",
      "resetting env. episode 833, reward total was -19.0. running mean: -20.409813950644796, timestamp: 2022-08-19 18:53:58.438590\n",
      "resetting env. episode 834, reward total was -21.0. running mean: -20.415715811138348, timestamp: 2022-08-19 18:54:00.322612\n",
      "resetting env. episode 835, reward total was -20.0. running mean: -20.411558653026965, timestamp: 2022-08-19 18:54:02.515636\n",
      "resetting env. episode 836, reward total was -20.0. running mean: -20.407443066496693, timestamp: 2022-08-19 18:54:04.727659\n",
      "resetting env. episode 837, reward total was -19.0. running mean: -20.393368635831727, timestamp: 2022-08-19 18:54:06.738685\n",
      "resetting env. episode 838, reward total was -21.0. running mean: -20.39943494947341, timestamp: 2022-08-19 18:54:08.435702\n",
      "resetting env. episode 839, reward total was -21.0. running mean: -20.405440599978675, timestamp: 2022-08-19 18:54:10.171721\n",
      "resetting env. episode 840, reward total was -20.0. running mean: -20.401386193978887, timestamp: 2022-08-19 18:54:12.421748\n",
      "resetting env. episode 841, reward total was -21.0. running mean: -20.4073723320391, timestamp: 2022-08-19 18:54:14.165776\n",
      "resetting env. episode 842, reward total was -20.0. running mean: -20.403298608718707, timestamp: 2022-08-19 18:54:16.270794\n",
      "resetting env. episode 843, reward total was -19.0. running mean: -20.38926562263152, timestamp: 2022-08-19 18:54:18.396818\n",
      "resetting env. episode 844, reward total was -21.0. running mean: -20.395372966405205, timestamp: 2022-08-19 18:54:20.021836\n",
      "resetting env. episode 845, reward total was -20.0. running mean: -20.39141923674115, timestamp: 2022-08-19 18:54:21.944858\n",
      "resetting env. episode 846, reward total was -17.0. running mean: -20.35750504437374, timestamp: 2022-08-19 18:54:24.453885\n",
      "resetting env. episode 847, reward total was -20.0. running mean: -20.353929993930002, timestamp: 2022-08-19 18:54:26.521905\n",
      "resetting env. episode 848, reward total was -21.0. running mean: -20.360390693990702, timestamp: 2022-08-19 18:54:28.179924\n",
      "resetting env. episode 849, reward total was -21.0. running mean: -20.366786787050795, timestamp: 2022-08-19 18:54:30.059949\n",
      "resetting env. episode 850, reward total was -20.0. running mean: -20.363118919180287, timestamp: 2022-08-19 18:54:32.138971\n",
      "resetting env. episode 851, reward total was -21.0. running mean: -20.369487729988485, timestamp: 2022-08-19 18:54:34.039992\n",
      "resetting env. episode 852, reward total was -21.0. running mean: -20.3757928526886, timestamp: 2022-08-19 18:54:36.721022\n",
      "resetting env. episode 853, reward total was -21.0. running mean: -20.382034924161715, timestamp: 2022-08-19 18:54:39.060048\n",
      "resetting env. episode 854, reward total was -21.0. running mean: -20.3882145749201, timestamp: 2022-08-19 18:54:40.972072\n",
      "resetting env. episode 855, reward total was -21.0. running mean: -20.3943324291709, timestamp: 2022-08-19 18:54:42.473087\n",
      "resetting env. episode 856, reward total was -20.0. running mean: -20.390389104879187, timestamp: 2022-08-19 18:54:45.422122\n",
      "resetting env. episode 857, reward total was -21.0. running mean: -20.396485213830395, timestamp: 2022-08-19 18:54:47.095140\n",
      "resetting env. episode 858, reward total was -20.0. running mean: -20.39252036169209, timestamp: 2022-08-19 18:54:49.078160\n",
      "resetting env. episode 859, reward total was -18.0. running mean: -20.368595158075166, timestamp: 2022-08-19 18:54:51.410190\n",
      "resetting env. episode 860, reward total was -21.0. running mean: -20.374909206494415, timestamp: 2022-08-19 18:54:53.601209\n",
      "resetting env. episode 861, reward total was -21.0. running mean: -20.38116011442947, timestamp: 2022-08-19 18:54:55.233232\n",
      "resetting env. episode 862, reward total was -21.0. running mean: -20.387348513285175, timestamp: 2022-08-19 18:54:56.944249\n",
      "resetting env. episode 863, reward total was -21.0. running mean: -20.393475028152324, timestamp: 2022-08-19 18:54:58.683271\n",
      "resetting env. episode 864, reward total was -20.0. running mean: -20.3895402778708, timestamp: 2022-08-19 18:55:01.056296\n",
      "resetting env. episode 865, reward total was -21.0. running mean: -20.395644875092092, timestamp: 2022-08-19 18:55:02.575314\n",
      "resetting env. episode 866, reward total was -20.0. running mean: -20.39168842634117, timestamp: 2022-08-19 18:55:04.878337\n",
      "resetting env. episode 867, reward total was -21.0. running mean: -20.39777154207776, timestamp: 2022-08-19 18:55:06.825361\n",
      "resetting env. episode 868, reward total was -21.0. running mean: -20.403793826656983, timestamp: 2022-08-19 18:55:09.028383\n",
      "resetting env. episode 869, reward total was -20.0. running mean: -20.399755888390413, timestamp: 2022-08-19 18:55:10.659402\n",
      "resetting env. episode 870, reward total was -20.0. running mean: -20.395758329506506, timestamp: 2022-08-19 18:55:12.645423\n",
      "resetting env. episode 871, reward total was -20.0. running mean: -20.39180074621144, timestamp: 2022-08-19 18:55:14.638449\n",
      "resetting env. episode 872, reward total was -20.0. running mean: -20.387882738749326, timestamp: 2022-08-19 18:55:17.015472\n",
      "resetting env. episode 873, reward total was -21.0. running mean: -20.394003911361832, timestamp: 2022-08-19 18:55:18.945495\n",
      "resetting env. episode 874, reward total was -20.0. running mean: -20.390063872248213, timestamp: 2022-08-19 18:55:20.543511\n",
      "resetting env. episode 875, reward total was -19.0. running mean: -20.37616323352573, timestamp: 2022-08-19 18:55:22.865539\n",
      "resetting env. episode 876, reward total was -21.0. running mean: -20.382401601190473, timestamp: 2022-08-19 18:55:25.250565\n",
      "resetting env. episode 877, reward total was -21.0. running mean: -20.38857758517857, timestamp: 2022-08-19 18:55:27.161588\n",
      "resetting env. episode 878, reward total was -21.0. running mean: -20.394691809326787, timestamp: 2022-08-19 18:55:28.979608\n",
      "resetting env. episode 879, reward total was -21.0. running mean: -20.40074489123352, timestamp: 2022-08-19 18:55:30.854628\n",
      "resetting env. episode 880, reward total was -21.0. running mean: -20.406737442321184, timestamp: 2022-08-19 18:55:33.181652\n",
      "resetting env. episode 881, reward total was -20.0. running mean: -20.402670067897972, timestamp: 2022-08-19 18:55:35.169680\n",
      "resetting env. episode 882, reward total was -21.0. running mean: -20.408643367218993, timestamp: 2022-08-19 18:55:37.541702\n",
      "resetting env. episode 883, reward total was -21.0. running mean: -20.414556933546802, timestamp: 2022-08-19 18:55:39.445727\n",
      "resetting env. episode 884, reward total was -21.0. running mean: -20.420411364211333, timestamp: 2022-08-19 18:55:41.037742\n",
      "resetting env. episode 885, reward total was -20.0. running mean: -20.41620725056922, timestamp: 2022-08-19 18:55:43.295767\n",
      "resetting env. episode 886, reward total was -20.0. running mean: -20.412045178063526, timestamp: 2022-08-19 18:55:45.297797\n",
      "resetting env. episode 887, reward total was -21.0. running mean: -20.41792472628289, timestamp: 2022-08-19 18:55:47.172814\n",
      "resetting env. episode 888, reward total was -20.0. running mean: -20.41374547902006, timestamp: 2022-08-19 18:55:49.514838\n",
      "resetting env. episode 889, reward total was -18.0. running mean: -20.38960802422986, timestamp: 2022-08-19 18:55:51.481859\n",
      "resetting env. episode 890, reward total was -21.0. running mean: -20.395711943987564, timestamp: 2022-08-19 18:55:53.438879\n",
      "resetting env. episode 891, reward total was -20.0. running mean: -20.391754824547686, timestamp: 2022-08-19 18:55:55.744911\n",
      "resetting env. episode 892, reward total was -18.0. running mean: -20.367837276302208, timestamp: 2022-08-19 18:55:58.796940\n",
      "resetting env. episode 893, reward total was -21.0. running mean: -20.374158903539186, timestamp: 2022-08-19 18:56:00.701963\n",
      "resetting env. episode 894, reward total was -21.0. running mean: -20.380417314503795, timestamp: 2022-08-19 18:56:02.797986\n",
      "resetting env. episode 895, reward total was -20.0. running mean: -20.376613141358757, timestamp: 2022-08-19 18:56:05.210012\n",
      "resetting env. episode 896, reward total was -21.0. running mean: -20.38284700994517, timestamp: 2022-08-19 18:56:06.956032\n",
      "resetting env. episode 897, reward total was -20.0. running mean: -20.379018539845717, timestamp: 2022-08-19 18:56:09.074054\n",
      "resetting env. episode 898, reward total was -20.0. running mean: -20.37522835444726, timestamp: 2022-08-19 18:56:11.378083\n",
      "resetting env. episode 899, reward total was -21.0. running mean: -20.38147607090279, timestamp: 2022-08-19 18:56:13.724110\n",
      "resetting env. episode 900, reward total was -20.0. running mean: -20.37766131019376, timestamp: 2022-08-19 18:56:16.085133\n",
      "resetting env. episode 901, reward total was -21.0. running mean: -20.383884697091823, timestamp: 2022-08-19 18:56:18.956165\n",
      "resetting env. episode 902, reward total was -20.0. running mean: -20.380045850120904, timestamp: 2022-08-19 18:56:21.292192\n",
      "resetting env. episode 903, reward total was -21.0. running mean: -20.386245391619696, timestamp: 2022-08-19 18:56:23.354213\n",
      "resetting env. episode 904, reward total was -21.0. running mean: -20.3923829377035, timestamp: 2022-08-19 18:56:24.986235\n",
      "resetting env. episode 905, reward total was -20.0. running mean: -20.38845910832646, timestamp: 2022-08-19 18:56:27.230261\n",
      "resetting env. episode 906, reward total was -20.0. running mean: -20.384574517243195, timestamp: 2022-08-19 18:56:29.447282\n",
      "resetting env. episode 907, reward total was -20.0. running mean: -20.38072877207076, timestamp: 2022-08-19 18:56:31.718313\n",
      "resetting env. episode 908, reward total was -20.0. running mean: -20.376921484350053, timestamp: 2022-08-19 18:56:33.955334\n",
      "resetting env. episode 909, reward total was -21.0. running mean: -20.383152269506553, timestamp: 2022-08-19 18:56:36.005353\n",
      "resetting env. episode 910, reward total was -20.0. running mean: -20.379320746811487, timestamp: 2022-08-19 18:56:38.328380\n",
      "resetting env. episode 911, reward total was -19.0. running mean: -20.365527539343372, timestamp: 2022-08-19 18:56:40.377405\n",
      "resetting env. episode 912, reward total was -20.0. running mean: -20.361872263949937, timestamp: 2022-08-19 18:56:42.512427\n",
      "resetting env. episode 913, reward total was -18.0. running mean: -20.338253541310436, timestamp: 2022-08-19 18:56:44.722455\n",
      "resetting env. episode 914, reward total was -20.0. running mean: -20.33487100589733, timestamp: 2022-08-19 18:56:46.910475\n",
      "resetting env. episode 915, reward total was -21.0. running mean: -20.341522295838356, timestamp: 2022-08-19 18:56:48.681497\n",
      "resetting env. episode 916, reward total was -21.0. running mean: -20.348107072879973, timestamp: 2022-08-19 18:56:50.388518\n",
      "resetting env. episode 917, reward total was -20.0. running mean: -20.344626002151173, timestamp: 2022-08-19 18:56:52.637544\n",
      "resetting env. episode 918, reward total was -21.0. running mean: -20.351179742129663, timestamp: 2022-08-19 18:56:54.665571\n",
      "resetting env. episode 919, reward total was -18.0. running mean: -20.327667944708367, timestamp: 2022-08-19 18:56:57.085591\n",
      "resetting env. episode 920, reward total was -21.0. running mean: -20.334391265261285, timestamp: 2022-08-19 18:56:58.566607\n",
      "resetting env. episode 921, reward total was -20.0. running mean: -20.33104735260867, timestamp: 2022-08-19 18:57:00.869632\n",
      "resetting env. episode 922, reward total was -20.0. running mean: -20.327736879082583, timestamp: 2022-08-19 18:57:02.785651\n",
      "resetting env. episode 923, reward total was -20.0. running mean: -20.324459510291756, timestamp: 2022-08-19 18:57:05.213678\n",
      "resetting env. episode 924, reward total was -20.0. running mean: -20.32121491518884, timestamp: 2022-08-19 18:57:07.129700\n",
      "resetting env. episode 925, reward total was -19.0. running mean: -20.308002766036953, timestamp: 2022-08-19 18:57:08.990722\n",
      "resetting env. episode 926, reward total was -21.0. running mean: -20.314922738376584, timestamp: 2022-08-19 18:57:10.885741\n",
      "resetting env. episode 927, reward total was -20.0. running mean: -20.31177351099282, timestamp: 2022-08-19 18:57:13.233768\n",
      "resetting env. episode 928, reward total was -19.0. running mean: -20.298655775882892, timestamp: 2022-08-19 18:57:15.719795\n",
      "resetting env. episode 929, reward total was -21.0. running mean: -20.305669218124063, timestamp: 2022-08-19 18:57:17.947821\n",
      "resetting env. episode 930, reward total was -21.0. running mean: -20.31261252594282, timestamp: 2022-08-19 18:57:19.757842\n",
      "resetting env. episode 931, reward total was -21.0. running mean: -20.319486400683395, timestamp: 2022-08-19 18:57:21.344859\n",
      "resetting env. episode 932, reward total was -21.0. running mean: -20.32629153667656, timestamp: 2022-08-19 18:57:22.947878\n",
      "resetting env. episode 933, reward total was -21.0. running mean: -20.333028621309797, timestamp: 2022-08-19 18:57:24.937897\n",
      "resetting env. episode 934, reward total was -20.0. running mean: -20.329698335096698, timestamp: 2022-08-19 18:57:27.253924\n",
      "resetting env. episode 935, reward total was -20.0. running mean: -20.32640135174573, timestamp: 2022-08-19 18:57:29.467949\n",
      "resetting env. episode 936, reward total was -19.0. running mean: -20.313137338228273, timestamp: 2022-08-19 18:57:32.370979\n",
      "resetting env. episode 937, reward total was -20.0. running mean: -20.31000596484599, timestamp: 2022-08-19 18:57:34.241002\n",
      "resetting env. episode 938, reward total was -19.0. running mean: -20.29690590519753, timestamp: 2022-08-19 18:57:37.207041\n",
      "resetting env. episode 939, reward total was -19.0. running mean: -20.283936846145554, timestamp: 2022-08-19 18:57:39.035054\n",
      "resetting env. episode 940, reward total was -21.0. running mean: -20.2910974776841, timestamp: 2022-08-19 18:57:41.126076\n",
      "resetting env. episode 941, reward total was -21.0. running mean: -20.29818650290726, timestamp: 2022-08-19 18:57:43.590104\n",
      "resetting env. episode 942, reward total was -20.0. running mean: -20.295204637878186, timestamp: 2022-08-19 18:57:46.306135\n",
      "resetting env. episode 943, reward total was -20.0. running mean: -20.292252591499402, timestamp: 2022-08-19 18:57:48.635162\n",
      "resetting env. episode 944, reward total was -18.0. running mean: -20.26933006558441, timestamp: 2022-08-19 18:57:50.883185\n",
      "resetting env. episode 945, reward total was -21.0. running mean: -20.276636764928565, timestamp: 2022-08-19 18:57:52.376204\n",
      "resetting env. episode 946, reward total was -21.0. running mean: -20.28387039727928, timestamp: 2022-08-19 18:57:54.966233\n",
      "resetting env. episode 947, reward total was -21.0. running mean: -20.291031693306486, timestamp: 2022-08-19 18:57:57.144256\n",
      "resetting env. episode 948, reward total was -21.0. running mean: -20.298121376373423, timestamp: 2022-08-19 18:57:58.778273\n",
      "resetting env. episode 949, reward total was -21.0. running mean: -20.30514016260969, timestamp: 2022-08-19 18:58:00.438292\n",
      "resetting env. episode 950, reward total was -20.0. running mean: -20.30208876098359, timestamp: 2022-08-19 18:58:02.343312\n",
      "resetting env. episode 951, reward total was -20.0. running mean: -20.299067873373755, timestamp: 2022-08-19 18:58:04.233333\n",
      "resetting env. episode 952, reward total was -19.0. running mean: -20.28607719464002, timestamp: 2022-08-19 18:58:06.506364\n",
      "resetting env. episode 953, reward total was -21.0. running mean: -20.293216422693618, timestamp: 2022-08-19 18:58:08.407381\n",
      "resetting env. episode 954, reward total was -20.0. running mean: -20.29028425846668, timestamp: 2022-08-19 18:58:10.044414\n",
      "resetting env. episode 955, reward total was -21.0. running mean: -20.297381415882015, timestamp: 2022-08-19 18:58:11.773423\n",
      "resetting env. episode 956, reward total was -20.0. running mean: -20.294407601723194, timestamp: 2022-08-19 18:58:13.543441\n",
      "resetting env. episode 957, reward total was -20.0. running mean: -20.29146352570596, timestamp: 2022-08-19 18:58:15.162459\n",
      "resetting env. episode 958, reward total was -21.0. running mean: -20.298548890448902, timestamp: 2022-08-19 18:58:17.205483\n",
      "resetting env. episode 959, reward total was -21.0. running mean: -20.305563401544415, timestamp: 2022-08-19 18:58:19.164503\n",
      "resetting env. episode 960, reward total was -21.0. running mean: -20.31250776752897, timestamp: 2022-08-19 18:58:21.490526\n",
      "resetting env. episode 961, reward total was -20.0. running mean: -20.30938268985368, timestamp: 2022-08-19 18:58:23.156549\n",
      "resetting env. episode 962, reward total was -21.0. running mean: -20.316288862955144, timestamp: 2022-08-19 18:58:25.307573\n",
      "resetting env. episode 963, reward total was -19.0. running mean: -20.303125974325592, timestamp: 2022-08-19 18:58:27.555598\n",
      "resetting env. episode 964, reward total was -21.0. running mean: -20.310094714582338, timestamp: 2022-08-19 18:58:29.684619\n",
      "resetting env. episode 965, reward total was -19.0. running mean: -20.296993767436515, timestamp: 2022-08-19 18:58:32.008649\n",
      "resetting env. episode 966, reward total was -21.0. running mean: -20.30402382976215, timestamp: 2022-08-19 18:58:33.900670\n",
      "resetting env. episode 967, reward total was -21.0. running mean: -20.31098359146453, timestamp: 2022-08-19 18:58:35.955691\n",
      "resetting env. episode 968, reward total was -21.0. running mean: -20.317873755549886, timestamp: 2022-08-19 18:58:38.108715\n",
      "resetting env. episode 969, reward total was -21.0. running mean: -20.324695017994387, timestamp: 2022-08-19 18:58:40.182739\n",
      "resetting env. episode 970, reward total was -20.0. running mean: -20.32144806781444, timestamp: 2022-08-19 18:58:42.422765\n",
      "resetting env. episode 971, reward total was -21.0. running mean: -20.328233587136296, timestamp: 2022-08-19 18:58:44.328786\n",
      "resetting env. episode 972, reward total was -21.0. running mean: -20.334951251264933, timestamp: 2022-08-19 18:58:46.011803\n",
      "resetting env. episode 973, reward total was -21.0. running mean: -20.341601738752285, timestamp: 2022-08-19 18:58:48.046827\n",
      "resetting env. episode 974, reward total was -21.0. running mean: -20.348185721364764, timestamp: 2022-08-19 18:58:50.246851\n",
      "resetting env. episode 975, reward total was -21.0. running mean: -20.354703864151116, timestamp: 2022-08-19 18:58:52.900887\n",
      "resetting env. episode 976, reward total was -20.0. running mean: -20.351156825509605, timestamp: 2022-08-19 18:58:55.237908\n",
      "resetting env. episode 977, reward total was -20.0. running mean: -20.34764525725451, timestamp: 2022-08-19 18:58:57.432937\n",
      "resetting env. episode 978, reward total was -21.0. running mean: -20.354168804681965, timestamp: 2022-08-19 18:58:59.383958\n",
      "resetting env. episode 979, reward total was -19.0. running mean: -20.340627116635147, timestamp: 2022-08-19 18:59:01.309978\n",
      "resetting env. episode 980, reward total was -21.0. running mean: -20.347220845468797, timestamp: 2022-08-19 18:59:03.075996\n",
      "resetting env. episode 981, reward total was -19.0. running mean: -20.33374863701411, timestamp: 2022-08-19 18:59:05.034022\n",
      "resetting env. episode 982, reward total was -20.0. running mean: -20.330411150643968, timestamp: 2022-08-19 18:59:06.684038\n",
      "resetting env. episode 983, reward total was -21.0. running mean: -20.33710703913753, timestamp: 2022-08-19 18:59:08.732060\n",
      "resetting env. episode 984, reward total was -21.0. running mean: -20.343735968746152, timestamp: 2022-08-19 18:59:10.636083\n",
      "resetting env. episode 985, reward total was -21.0. running mean: -20.35029860905869, timestamp: 2022-08-19 18:59:12.866111\n",
      "resetting env. episode 986, reward total was -20.0. running mean: -20.346795622968102, timestamp: 2022-08-19 18:59:14.660130\n",
      "resetting env. episode 987, reward total was -21.0. running mean: -20.353327666738423, timestamp: 2022-08-19 18:59:16.700151\n",
      "resetting env. episode 988, reward total was -21.0. running mean: -20.359794390071038, timestamp: 2022-08-19 18:59:18.635175\n",
      "resetting env. episode 989, reward total was -20.0. running mean: -20.356196446170326, timestamp: 2022-08-19 18:59:20.806201\n",
      "resetting env. episode 990, reward total was -21.0. running mean: -20.362634481708625, timestamp: 2022-08-19 18:59:22.692222\n",
      "resetting env. episode 991, reward total was -20.0. running mean: -20.35900813689154, timestamp: 2022-08-19 18:59:24.559241\n",
      "resetting env. episode 992, reward total was -21.0. running mean: -20.365418055522625, timestamp: 2022-08-19 18:59:26.820266\n",
      "resetting env. episode 993, reward total was -20.0. running mean: -20.361763874967398, timestamp: 2022-08-19 18:59:28.807290\n",
      "resetting env. episode 994, reward total was -20.0. running mean: -20.358146236217724, timestamp: 2022-08-19 18:59:31.515322\n",
      "resetting env. episode 995, reward total was -21.0. running mean: -20.364564773855548, timestamp: 2022-08-19 18:59:33.311347\n",
      "resetting env. episode 996, reward total was -19.0. running mean: -20.350919126116995, timestamp: 2022-08-19 18:59:35.491367\n",
      "resetting env. episode 997, reward total was -21.0. running mean: -20.357409934855827, timestamp: 2022-08-19 18:59:37.064386\n",
      "resetting env. episode 998, reward total was -20.0. running mean: -20.35383583550727, timestamp: 2022-08-19 18:59:38.971409\n",
      "resetting env. episode 999, reward total was -18.0. running mean: -20.330297477152197, timestamp: 2022-08-19 18:59:41.201431\n",
      "resetting env. episode 1000, reward total was -18.0. running mean: -20.306994502380675, timestamp: 2022-08-19 18:59:43.739459\n",
      "resetting env. episode 1001, reward total was -20.0. running mean: -20.30392455735687, timestamp: 2022-08-19 18:59:45.539483\n",
      "resetting env. episode 1002, reward total was -21.0. running mean: -20.310885311783302, timestamp: 2022-08-19 18:59:47.786507\n",
      "resetting env. episode 1003, reward total was -19.0. running mean: -20.29777645866547, timestamp: 2022-08-19 18:59:49.749529\n",
      "resetting env. episode 1004, reward total was -21.0. running mean: -20.304798694078816, timestamp: 2022-08-19 18:59:52.013554\n",
      "resetting env. episode 1005, reward total was -19.0. running mean: -20.29175070713803, timestamp: 2022-08-19 18:59:54.047577\n",
      "resetting env. episode 1006, reward total was -20.0. running mean: -20.288833200066648, timestamp: 2022-08-19 18:59:55.738600\n",
      "resetting env. episode 1007, reward total was -21.0. running mean: -20.295944868065984, timestamp: 2022-08-19 18:59:57.574622\n",
      "resetting env. episode 1008, reward total was -21.0. running mean: -20.302985419385326, timestamp: 2022-08-19 18:59:59.516643\n",
      "resetting env. episode 1009, reward total was -21.0. running mean: -20.309955565191473, timestamp: 2022-08-19 19:00:01.424662\n",
      "resetting env. episode 1010, reward total was -20.0. running mean: -20.30685600953956, timestamp: 2022-08-19 19:00:03.711688\n",
      "resetting env. episode 1011, reward total was -21.0. running mean: -20.313787449444163, timestamp: 2022-08-19 19:00:06.099718\n",
      "resetting env. episode 1012, reward total was -20.0. running mean: -20.31064957494972, timestamp: 2022-08-19 19:00:08.274740\n",
      "resetting env. episode 1013, reward total was -21.0. running mean: -20.317543079200224, timestamp: 2022-08-19 19:00:10.111767\n",
      "resetting env. episode 1014, reward total was -20.0. running mean: -20.314367648408222, timestamp: 2022-08-19 19:00:12.317790\n",
      "resetting env. episode 1015, reward total was -21.0. running mean: -20.32122397192414, timestamp: 2022-08-19 19:00:14.336810\n",
      "resetting env. episode 1016, reward total was -21.0. running mean: -20.3280117322049, timestamp: 2022-08-19 19:00:15.924831\n",
      "resetting env. episode 1017, reward total was -20.0. running mean: -20.32473161488285, timestamp: 2022-08-19 19:00:17.685848\n",
      "resetting env. episode 1018, reward total was -21.0. running mean: -20.331484298734022, timestamp: 2022-08-19 19:00:19.529873\n",
      "resetting env. episode 1019, reward total was -21.0. running mean: -20.338169455746684, timestamp: 2022-08-19 19:00:20.934891\n",
      "resetting env. episode 1020, reward total was -21.0. running mean: -20.344787761189217, timestamp: 2022-08-19 19:00:23.134911\n",
      "resetting env. episode 1021, reward total was -19.0. running mean: -20.331339883577325, timestamp: 2022-08-19 19:00:25.478939\n",
      "resetting env. episode 1022, reward total was -21.0. running mean: -20.33802648474155, timestamp: 2022-08-19 19:00:27.556961\n",
      "resetting env. episode 1023, reward total was -21.0. running mean: -20.344646219894138, timestamp: 2022-08-19 19:00:29.111981\n",
      "resetting env. episode 1024, reward total was -21.0. running mean: -20.3511997576952, timestamp: 2022-08-19 19:00:30.918001\n",
      "resetting env. episode 1025, reward total was -20.0. running mean: -20.347687760118244, timestamp: 2022-08-19 19:00:33.131029\n",
      "resetting env. episode 1026, reward total was -21.0. running mean: -20.354210882517062, timestamp: 2022-08-19 19:00:34.840046\n",
      "resetting env. episode 1027, reward total was -21.0. running mean: -20.36066877369189, timestamp: 2022-08-19 19:00:36.928071\n",
      "resetting env. episode 1028, reward total was -21.0. running mean: -20.367062085954974, timestamp: 2022-08-19 19:00:38.648088\n",
      "resetting env. episode 1029, reward total was -20.0. running mean: -20.36339146509542, timestamp: 2022-08-19 19:00:40.890120\n",
      "resetting env. episode 1030, reward total was -18.0. running mean: -20.339757550444467, timestamp: 2022-08-19 19:00:43.222141\n",
      "resetting env. episode 1031, reward total was -21.0. running mean: -20.34635997494002, timestamp: 2022-08-19 19:00:45.242169\n",
      "resetting env. episode 1032, reward total was -21.0. running mean: -20.35289637519062, timestamp: 2022-08-19 19:00:47.022188\n",
      "resetting env. episode 1033, reward total was -19.0. running mean: -20.339367411438715, timestamp: 2022-08-19 19:00:49.160214\n",
      "resetting env. episode 1034, reward total was -20.0. running mean: -20.335973737324327, timestamp: 2022-08-19 19:00:50.921230\n",
      "resetting env. episode 1035, reward total was -21.0. running mean: -20.342613999951084, timestamp: 2022-08-19 19:00:52.716252\n",
      "resetting env. episode 1036, reward total was -21.0. running mean: -20.349187859951574, timestamp: 2022-08-19 19:00:54.113270\n",
      "resetting env. episode 1037, reward total was -20.0. running mean: -20.34569598135206, timestamp: 2022-08-19 19:00:56.209292\n",
      "resetting env. episode 1038, reward total was -19.0. running mean: -20.332239021538538, timestamp: 2022-08-19 19:00:58.322315\n",
      "resetting env. episode 1039, reward total was -21.0. running mean: -20.33891663132315, timestamp: 2022-08-19 19:01:00.548342\n",
      "resetting env. episode 1040, reward total was -20.0. running mean: -20.335527465009918, timestamp: 2022-08-19 19:01:02.333360\n",
      "resetting env. episode 1041, reward total was -20.0. running mean: -20.332172190359817, timestamp: 2022-08-19 19:01:04.795391\n",
      "resetting env. episode 1042, reward total was -20.0. running mean: -20.328850468456217, timestamp: 2022-08-19 19:01:06.622414\n",
      "resetting env. episode 1043, reward total was -21.0. running mean: -20.335561963771656, timestamp: 2022-08-19 19:01:08.657434\n",
      "resetting env. episode 1044, reward total was -21.0. running mean: -20.342206344133942, timestamp: 2022-08-19 19:01:11.109463\n",
      "resetting env. episode 1045, reward total was -21.0. running mean: -20.348784280692602, timestamp: 2022-08-19 19:01:12.934486\n",
      "resetting env. episode 1046, reward total was -20.0. running mean: -20.345296437885676, timestamp: 2022-08-19 19:01:15.702517\n",
      "resetting env. episode 1047, reward total was -20.0. running mean: -20.341843473506817, timestamp: 2022-08-19 19:01:17.819544\n",
      "resetting env. episode 1048, reward total was -21.0. running mean: -20.34842503877175, timestamp: 2022-08-19 19:01:19.371563\n",
      "resetting env. episode 1049, reward total was -21.0. running mean: -20.354940788384035, timestamp: 2022-08-19 19:01:21.257580\n",
      "resetting env. episode 1050, reward total was -19.0. running mean: -20.341391380500195, timestamp: 2022-08-19 19:01:24.083610\n",
      "resetting env. episode 1051, reward total was -21.0. running mean: -20.347977466695195, timestamp: 2022-08-19 19:01:25.758642\n",
      "resetting env. episode 1052, reward total was -21.0. running mean: -20.354497692028243, timestamp: 2022-08-19 19:01:27.494650\n",
      "resetting env. episode 1053, reward total was -21.0. running mean: -20.36095271510796, timestamp: 2022-08-19 19:01:29.416675\n",
      "resetting env. episode 1054, reward total was -21.0. running mean: -20.36734318795688, timestamp: 2022-08-19 19:01:31.179697\n",
      "resetting env. episode 1055, reward total was -21.0. running mean: -20.373669756077312, timestamp: 2022-08-19 19:01:32.799716\n",
      "resetting env. episode 1056, reward total was -21.0. running mean: -20.37993305851654, timestamp: 2022-08-19 19:01:36.050751\n",
      "resetting env. episode 1057, reward total was -21.0. running mean: -20.386133727931373, timestamp: 2022-08-19 19:01:38.422781\n",
      "resetting env. episode 1058, reward total was -19.0. running mean: -20.37227239065206, timestamp: 2022-08-19 19:01:40.996809\n",
      "resetting env. episode 1059, reward total was -21.0. running mean: -20.378549666745542, timestamp: 2022-08-19 19:01:43.146838\n",
      "resetting env. episode 1060, reward total was -21.0. running mean: -20.384764170078085, timestamp: 2022-08-19 19:01:44.809853\n",
      "resetting env. episode 1061, reward total was -20.0. running mean: -20.380916528377305, timestamp: 2022-08-19 19:01:47.046879\n",
      "resetting env. episode 1062, reward total was -21.0. running mean: -20.387107363093534, timestamp: 2022-08-19 19:01:48.550897\n",
      "resetting env. episode 1063, reward total was -17.0. running mean: -20.3532362894626, timestamp: 2022-08-19 19:01:51.100926\n",
      "resetting env. episode 1064, reward total was -21.0. running mean: -20.359703926567974, timestamp: 2022-08-19 19:01:53.265950\n",
      "resetting env. episode 1065, reward total was -21.0. running mean: -20.366106887302294, timestamp: 2022-08-19 19:01:55.413978\n",
      "resetting env. episode 1066, reward total was -20.0. running mean: -20.362445818429272, timestamp: 2022-08-19 19:01:57.534002\n",
      "resetting env. episode 1067, reward total was -20.0. running mean: -20.358821360244978, timestamp: 2022-08-19 19:01:59.238020\n",
      "resetting env. episode 1068, reward total was -18.0. running mean: -20.335233146642526, timestamp: 2022-08-19 19:02:01.530045\n",
      "resetting env. episode 1069, reward total was -20.0. running mean: -20.3318808151761, timestamp: 2022-08-19 19:02:03.690071\n",
      "resetting env. episode 1070, reward total was -20.0. running mean: -20.32856200702434, timestamp: 2022-08-19 19:02:05.899097\n",
      "resetting env. episode 1071, reward total was -21.0. running mean: -20.335276386954096, timestamp: 2022-08-19 19:02:07.842119\n",
      "resetting env. episode 1072, reward total was -20.0. running mean: -20.331923623084553, timestamp: 2022-08-19 19:02:09.405141\n",
      "resetting env. episode 1073, reward total was -20.0. running mean: -20.328604386853705, timestamp: 2022-08-19 19:02:11.193160\n",
      "resetting env. episode 1074, reward total was -21.0. running mean: -20.33531834298517, timestamp: 2022-08-19 19:02:13.273186\n",
      "resetting env. episode 1075, reward total was -20.0. running mean: -20.331965159555317, timestamp: 2022-08-19 19:02:15.329208\n",
      "resetting env. episode 1076, reward total was -18.0. running mean: -20.308645507959763, timestamp: 2022-08-19 19:02:17.735236\n",
      "resetting env. episode 1077, reward total was -21.0. running mean: -20.315559052880168, timestamp: 2022-08-19 19:02:19.581255\n",
      "resetting env. episode 1078, reward total was -21.0. running mean: -20.322403462351367, timestamp: 2022-08-19 19:02:21.318277\n",
      "resetting env. episode 1079, reward total was -21.0. running mean: -20.329179427727855, timestamp: 2022-08-19 19:02:23.477304\n",
      "resetting env. episode 1080, reward total was -21.0. running mean: -20.335887633450575, timestamp: 2022-08-19 19:02:25.255322\n",
      "resetting env. episode 1081, reward total was -21.0. running mean: -20.34252875711607, timestamp: 2022-08-19 19:02:27.190343\n",
      "resetting env. episode 1082, reward total was -19.0. running mean: -20.32910346954491, timestamp: 2022-08-19 19:02:29.441372\n",
      "resetting env. episode 1083, reward total was -20.0. running mean: -20.32581243484946, timestamp: 2022-08-19 19:02:31.433393\n",
      "resetting env. episode 1084, reward total was -21.0. running mean: -20.332554310500967, timestamp: 2022-08-19 19:02:32.952414\n",
      "resetting env. episode 1085, reward total was -21.0. running mean: -20.33922876739596, timestamp: 2022-08-19 19:02:34.397430\n",
      "resetting env. episode 1086, reward total was -20.0. running mean: -20.335836479721998, timestamp: 2022-08-19 19:02:36.998459\n",
      "resetting env. episode 1087, reward total was -21.0. running mean: -20.342478114924777, timestamp: 2022-08-19 19:02:39.361484\n",
      "resetting env. episode 1088, reward total was -21.0. running mean: -20.34905333377553, timestamp: 2022-08-19 19:02:41.631510\n",
      "resetting env. episode 1089, reward total was -21.0. running mean: -20.355562800437774, timestamp: 2022-08-19 19:02:43.505536\n",
      "resetting env. episode 1090, reward total was -21.0. running mean: -20.362007172433398, timestamp: 2022-08-19 19:02:45.853561\n",
      "resetting env. episode 1091, reward total was -21.0. running mean: -20.368387100709064, timestamp: 2022-08-19 19:02:47.376581\n",
      "resetting env. episode 1092, reward total was -20.0. running mean: -20.364703229701973, timestamp: 2022-08-19 19:02:49.808605\n",
      "resetting env. episode 1093, reward total was -21.0. running mean: -20.371056197404954, timestamp: 2022-08-19 19:02:52.128636\n",
      "resetting env. episode 1094, reward total was -19.0. running mean: -20.357345635430907, timestamp: 2022-08-19 19:02:54.274660\n",
      "resetting env. episode 1095, reward total was -21.0. running mean: -20.363772179076598, timestamp: 2022-08-19 19:02:55.673675\n",
      "resetting env. episode 1096, reward total was -19.0. running mean: -20.350134457285833, timestamp: 2022-08-19 19:02:57.888700\n",
      "resetting env. episode 1097, reward total was -19.0. running mean: -20.336633112712974, timestamp: 2022-08-19 19:03:00.150727\n",
      "resetting env. episode 1098, reward total was -19.0. running mean: -20.323266781585847, timestamp: 2022-08-19 19:03:02.492753\n",
      "resetting env. episode 1099, reward total was -21.0. running mean: -20.33003411376999, timestamp: 2022-08-19 19:03:04.482777\n",
      "resetting env. episode 1100, reward total was -20.0. running mean: -20.326733772632288, timestamp: 2022-08-19 19:03:06.422801\n",
      "resetting env. episode 1101, reward total was -20.0. running mean: -20.323466434905963, timestamp: 2022-08-19 19:03:08.522827\n",
      "resetting env. episode 1102, reward total was -21.0. running mean: -20.330231770556903, timestamp: 2022-08-19 19:03:10.284843\n",
      "resetting env. episode 1103, reward total was -21.0. running mean: -20.336929452851336, timestamp: 2022-08-19 19:03:12.275866\n",
      "resetting env. episode 1104, reward total was -21.0. running mean: -20.343560158322823, timestamp: 2022-08-19 19:03:14.342892\n",
      "resetting env. episode 1105, reward total was -21.0. running mean: -20.350124556739594, timestamp: 2022-08-19 19:03:16.270913\n",
      "resetting env. episode 1106, reward total was -20.0. running mean: -20.3466233111722, timestamp: 2022-08-19 19:03:18.214935\n",
      "resetting env. episode 1107, reward total was -19.0. running mean: -20.333157078060477, timestamp: 2022-08-19 19:03:20.527962\n",
      "resetting env. episode 1108, reward total was -21.0. running mean: -20.339825507279873, timestamp: 2022-08-19 19:03:22.178983\n",
      "resetting env. episode 1109, reward total was -20.0. running mean: -20.336427252207073, timestamp: 2022-08-19 19:03:23.977006\n",
      "resetting env. episode 1110, reward total was -20.0. running mean: -20.333062979685003, timestamp: 2022-08-19 19:03:26.438029\n",
      "resetting env. episode 1111, reward total was -19.0. running mean: -20.319732349888156, timestamp: 2022-08-19 19:03:29.107066\n",
      "resetting env. episode 1112, reward total was -21.0. running mean: -20.326535026389276, timestamp: 2022-08-19 19:03:30.941086\n",
      "resetting env. episode 1113, reward total was -17.0. running mean: -20.293269676125384, timestamp: 2022-08-19 19:03:33.289111\n",
      "resetting env. episode 1114, reward total was -18.0. running mean: -20.270336979364128, timestamp: 2022-08-19 19:03:35.886142\n",
      "resetting env. episode 1115, reward total was -21.0. running mean: -20.277633609570486, timestamp: 2022-08-19 19:03:38.109166\n",
      "resetting env. episode 1116, reward total was -20.0. running mean: -20.27485727347478, timestamp: 2022-08-19 19:03:39.859186\n",
      "resetting env. episode 1117, reward total was -21.0. running mean: -20.282108700740032, timestamp: 2022-08-19 19:03:41.923210\n",
      "resetting env. episode 1118, reward total was -21.0. running mean: -20.289287613732633, timestamp: 2022-08-19 19:03:44.064237\n",
      "resetting env. episode 1119, reward total was -21.0. running mean: -20.296394737595307, timestamp: 2022-08-19 19:03:46.051260\n",
      "resetting env. episode 1120, reward total was -21.0. running mean: -20.303430790219355, timestamp: 2022-08-19 19:03:48.310286\n",
      "resetting env. episode 1121, reward total was -21.0. running mean: -20.310396482317163, timestamp: 2022-08-19 19:03:50.090304\n",
      "resetting env. episode 1122, reward total was -19.0. running mean: -20.297292517493993, timestamp: 2022-08-19 19:03:52.334333\n",
      "resetting env. episode 1123, reward total was -20.0. running mean: -20.294319592319052, timestamp: 2022-08-19 19:03:54.438360\n",
      "resetting env. episode 1124, reward total was -19.0. running mean: -20.281376396395864, timestamp: 2022-08-19 19:03:56.683382\n",
      "resetting env. episode 1125, reward total was -18.0. running mean: -20.258562632431904, timestamp: 2022-08-19 19:03:58.908408\n",
      "resetting env. episode 1126, reward total was -21.0. running mean: -20.265977006107587, timestamp: 2022-08-19 19:04:01.229436\n",
      "resetting env. episode 1127, reward total was -20.0. running mean: -20.26331723604651, timestamp: 2022-08-19 19:04:03.655465\n",
      "resetting env. episode 1128, reward total was -21.0. running mean: -20.270684063686048, timestamp: 2022-08-19 19:04:05.697489\n",
      "resetting env. episode 1129, reward total was -21.0. running mean: -20.277977223049188, timestamp: 2022-08-19 19:04:07.849511\n",
      "resetting env. episode 1130, reward total was -18.0. running mean: -20.255197450818695, timestamp: 2022-08-19 19:04:10.553542\n",
      "resetting env. episode 1131, reward total was -19.0. running mean: -20.24264547631051, timestamp: 2022-08-19 19:04:12.598567\n",
      "resetting env. episode 1132, reward total was -19.0. running mean: -20.230219021547406, timestamp: 2022-08-19 19:04:14.657591\n",
      "resetting env. episode 1133, reward total was -21.0. running mean: -20.237916831331933, timestamp: 2022-08-19 19:04:16.709620\n",
      "resetting env. episode 1134, reward total was -21.0. running mean: -20.245537663018613, timestamp: 2022-08-19 19:04:18.497636\n",
      "resetting env. episode 1135, reward total was -19.0. running mean: -20.233082286388427, timestamp: 2022-08-19 19:04:20.763665\n",
      "resetting env. episode 1136, reward total was -21.0. running mean: -20.240751463524543, timestamp: 2022-08-19 19:04:22.697684\n",
      "resetting env. episode 1137, reward total was -21.0. running mean: -20.248343948889296, timestamp: 2022-08-19 19:04:24.667709\n",
      "resetting env. episode 1138, reward total was -21.0. running mean: -20.255860509400403, timestamp: 2022-08-19 19:04:26.629730\n",
      "resetting env. episode 1139, reward total was -21.0. running mean: -20.2633019043064, timestamp: 2022-08-19 19:04:28.702757\n",
      "resetting env. episode 1140, reward total was -19.0. running mean: -20.250668885263337, timestamp: 2022-08-19 19:04:30.807778\n",
      "resetting env. episode 1141, reward total was -21.0. running mean: -20.258162196410705, timestamp: 2022-08-19 19:04:32.520800\n",
      "resetting env. episode 1142, reward total was -18.0. running mean: -20.235580574446598, timestamp: 2022-08-19 19:04:34.715825\n",
      "resetting env. episode 1143, reward total was -20.0. running mean: -20.23322476870213, timestamp: 2022-08-19 19:04:36.272840\n",
      "resetting env. episode 1144, reward total was -21.0. running mean: -20.24089252101511, timestamp: 2022-08-19 19:04:38.303867\n",
      "resetting env. episode 1145, reward total was -21.0. running mean: -20.24848359580496, timestamp: 2022-08-19 19:04:40.222891\n",
      "resetting env. episode 1146, reward total was -20.0. running mean: -20.24599875984691, timestamp: 2022-08-19 19:04:42.012909\n",
      "resetting env. episode 1147, reward total was -20.0. running mean: -20.24353877224844, timestamp: 2022-08-19 19:04:44.214933\n",
      "resetting env. episode 1148, reward total was -21.0. running mean: -20.251103384525955, timestamp: 2022-08-19 19:04:46.132955\n",
      "resetting env. episode 1149, reward total was -21.0. running mean: -20.258592350680697, timestamp: 2022-08-19 19:04:48.081980\n",
      "resetting env. episode 1150, reward total was -19.0. running mean: -20.246006427173892, timestamp: 2022-08-19 19:04:50.375004\n",
      "resetting env. episode 1151, reward total was -21.0. running mean: -20.253546362902153, timestamp: 2022-08-19 19:04:51.939023\n",
      "resetting env. episode 1152, reward total was -20.0. running mean: -20.25101089927313, timestamp: 2022-08-19 19:04:53.946056\n",
      "resetting env. episode 1153, reward total was -21.0. running mean: -20.258500790280397, timestamp: 2022-08-19 19:04:55.555065\n",
      "resetting env. episode 1154, reward total was -20.0. running mean: -20.255915782377592, timestamp: 2022-08-19 19:04:58.366098\n",
      "resetting env. episode 1155, reward total was -17.0. running mean: -20.22335662455382, timestamp: 2022-08-19 19:05:01.431133\n",
      "resetting env. episode 1156, reward total was -20.0. running mean: -20.22112305830828, timestamp: 2022-08-19 19:05:03.176154\n",
      "resetting env. episode 1157, reward total was -20.0. running mean: -20.218911827725197, timestamp: 2022-08-19 19:05:04.939176\n",
      "resetting env. episode 1158, reward total was -21.0. running mean: -20.226722709447944, timestamp: 2022-08-19 19:05:06.668193\n",
      "resetting env. episode 1159, reward total was -21.0. running mean: -20.234455482353464, timestamp: 2022-08-19 19:05:08.444215\n",
      "resetting env. episode 1160, reward total was -19.0. running mean: -20.22211092752993, timestamp: 2022-08-19 19:05:10.852242\n",
      "resetting env. episode 1161, reward total was -21.0. running mean: -20.22988981825463, timestamp: 2022-08-19 19:05:12.260263\n",
      "resetting env. episode 1162, reward total was -20.0. running mean: -20.227590920072082, timestamp: 2022-08-19 19:05:14.470283\n",
      "resetting env. episode 1163, reward total was -20.0. running mean: -20.22531501087136, timestamp: 2022-08-19 19:05:16.464309\n",
      "resetting env. episode 1164, reward total was -18.0. running mean: -20.203061860762645, timestamp: 2022-08-19 19:05:18.960337\n",
      "resetting env. episode 1165, reward total was -21.0. running mean: -20.21103124215502, timestamp: 2022-08-19 19:05:20.381353\n",
      "resetting env. episode 1166, reward total was -21.0. running mean: -20.21892092973347, timestamp: 2022-08-19 19:05:22.497378\n",
      "resetting env. episode 1167, reward total was -19.0. running mean: -20.20673172043614, timestamp: 2022-08-19 19:05:24.903406\n",
      "resetting env. episode 1168, reward total was -21.0. running mean: -20.21466440323178, timestamp: 2022-08-19 19:05:26.830427\n",
      "resetting env. episode 1169, reward total was -21.0. running mean: -20.222517759199462, timestamp: 2022-08-19 19:05:28.947452\n",
      "resetting env. episode 1170, reward total was -21.0. running mean: -20.23029258160747, timestamp: 2022-08-19 19:05:30.392468\n",
      "resetting env. episode 1171, reward total was -20.0. running mean: -20.227989655791394, timestamp: 2022-08-19 19:05:32.431496\n",
      "resetting env. episode 1172, reward total was -21.0. running mean: -20.23570975923348, timestamp: 2022-08-19 19:05:34.735519\n",
      "resetting env. episode 1173, reward total was -21.0. running mean: -20.243352661641147, timestamp: 2022-08-19 19:05:37.286550\n",
      "resetting env. episode 1174, reward total was -19.0. running mean: -20.230919135024738, timestamp: 2022-08-19 19:05:39.734579\n",
      "resetting env. episode 1175, reward total was -19.0. running mean: -20.21860994367449, timestamp: 2022-08-19 19:05:41.865603\n",
      "resetting env. episode 1176, reward total was -20.0. running mean: -20.216423844237745, timestamp: 2022-08-19 19:05:43.417623\n",
      "resetting env. episode 1177, reward total was -20.0. running mean: -20.214259605795366, timestamp: 2022-08-19 19:05:45.173639\n",
      "resetting env. episode 1178, reward total was -19.0. running mean: -20.202117009737414, timestamp: 2022-08-19 19:05:47.842672\n",
      "resetting env. episode 1179, reward total was -20.0. running mean: -20.20009583964004, timestamp: 2022-08-19 19:05:50.350701\n",
      "resetting env. episode 1180, reward total was -21.0. running mean: -20.20809488124364, timestamp: 2022-08-19 19:05:52.064721\n",
      "resetting env. episode 1181, reward total was -21.0. running mean: -20.216013932431203, timestamp: 2022-08-19 19:05:54.237746\n",
      "resetting env. episode 1182, reward total was -21.0. running mean: -20.22385379310689, timestamp: 2022-08-19 19:05:56.165766\n",
      "resetting env. episode 1183, reward total was -21.0. running mean: -20.23161525517582, timestamp: 2022-08-19 19:05:57.972787\n",
      "resetting env. episode 1184, reward total was -21.0. running mean: -20.239299102624063, timestamp: 2022-08-19 19:06:00.360816\n",
      "resetting env. episode 1185, reward total was -21.0. running mean: -20.246906111597823, timestamp: 2022-08-19 19:06:01.912835\n",
      "resetting env. episode 1186, reward total was -17.0. running mean: -20.21443705048185, timestamp: 2022-08-19 19:06:04.327860\n",
      "resetting env. episode 1187, reward total was -20.0. running mean: -20.21229267997703, timestamp: 2022-08-19 19:06:06.239886\n",
      "resetting env. episode 1188, reward total was -21.0. running mean: -20.22016975317726, timestamp: 2022-08-19 19:06:08.101903\n",
      "resetting env. episode 1189, reward total was -20.0. running mean: -20.217968055645485, timestamp: 2022-08-19 19:06:10.108930\n",
      "resetting env. episode 1190, reward total was -20.0. running mean: -20.21578837508903, timestamp: 2022-08-19 19:06:12.498954\n",
      "resetting env. episode 1191, reward total was -21.0. running mean: -20.22363049133814, timestamp: 2022-08-19 19:06:14.112978\n",
      "resetting env. episode 1192, reward total was -21.0. running mean: -20.23139418642476, timestamp: 2022-08-19 19:06:16.055995\n",
      "resetting env. episode 1193, reward total was -21.0. running mean: -20.239080244560515, timestamp: 2022-08-19 19:06:17.540012\n",
      "resetting env. episode 1194, reward total was -21.0. running mean: -20.24668944211491, timestamp: 2022-08-19 19:06:19.588037\n",
      "resetting env. episode 1195, reward total was -21.0. running mean: -20.25422254769376, timestamp: 2022-08-19 19:06:22.074064\n",
      "resetting env. episode 1196, reward total was -18.0. running mean: -20.23168032221682, timestamp: 2022-08-19 19:06:24.807096\n",
      "resetting env. episode 1197, reward total was -19.0. running mean: -20.219363518994655, timestamp: 2022-08-19 19:06:27.510128\n",
      "resetting env. episode 1198, reward total was -21.0. running mean: -20.22716988380471, timestamp: 2022-08-19 19:06:29.478150\n",
      "resetting env. episode 1199, reward total was -21.0. running mean: -20.234898184966664, timestamp: 2022-08-19 19:06:31.512174\n",
      "resetting env. episode 1200, reward total was -21.0. running mean: -20.242549203116997, timestamp: 2022-08-19 19:06:33.312195\n",
      "resetting env. episode 1201, reward total was -18.0. running mean: -20.220123711085826, timestamp: 2022-08-19 19:06:35.458223\n",
      "resetting env. episode 1202, reward total was -20.0. running mean: -20.217922473974966, timestamp: 2022-08-19 19:06:37.457240\n",
      "resetting env. episode 1203, reward total was -20.0. running mean: -20.215743249235214, timestamp: 2022-08-19 19:06:39.743271\n",
      "resetting env. episode 1204, reward total was -20.0. running mean: -20.21358581674286, timestamp: 2022-08-19 19:06:41.898292\n",
      "resetting env. episode 1205, reward total was -19.0. running mean: -20.201449958575434, timestamp: 2022-08-19 19:06:44.250319\n",
      "resetting env. episode 1206, reward total was -21.0. running mean: -20.20943545898968, timestamp: 2022-08-19 19:06:45.820339\n",
      "resetting env. episode 1207, reward total was -21.0. running mean: -20.217341104399786, timestamp: 2022-08-19 19:06:47.523358\n",
      "resetting env. episode 1208, reward total was -21.0. running mean: -20.22516769335579, timestamp: 2022-08-19 19:06:49.447383\n",
      "resetting env. episode 1209, reward total was -20.0. running mean: -20.222916016422232, timestamp: 2022-08-19 19:06:51.109397\n",
      "resetting env. episode 1210, reward total was -20.0. running mean: -20.22068685625801, timestamp: 2022-08-19 19:06:52.963419\n",
      "resetting env. episode 1211, reward total was -21.0. running mean: -20.22847998769543, timestamp: 2022-08-19 19:06:54.867442\n",
      "resetting env. episode 1212, reward total was -19.0. running mean: -20.216195187818478, timestamp: 2022-08-19 19:06:57.318470\n",
      "resetting env. episode 1213, reward total was -21.0. running mean: -20.224033235940293, timestamp: 2022-08-19 19:07:00.104502\n",
      "resetting env. episode 1214, reward total was -19.0. running mean: -20.211792903580893, timestamp: 2022-08-19 19:07:02.233529\n",
      "resetting env. episode 1215, reward total was -21.0. running mean: -20.219674974545086, timestamp: 2022-08-19 19:07:04.471553\n",
      "resetting env. episode 1216, reward total was -21.0. running mean: -20.227478224799636, timestamp: 2022-08-19 19:07:06.168570\n",
      "resetting env. episode 1217, reward total was -21.0. running mean: -20.23520344255164, timestamp: 2022-08-19 19:07:08.301599\n",
      "resetting env. episode 1218, reward total was -20.0. running mean: -20.232851408126123, timestamp: 2022-08-19 19:07:10.315619\n",
      "resetting env. episode 1219, reward total was -20.0. running mean: -20.23052289404486, timestamp: 2022-08-19 19:07:12.306643\n",
      "resetting env. episode 1220, reward total was -18.0. running mean: -20.20821766510441, timestamp: 2022-08-19 19:07:14.794671\n",
      "resetting env. episode 1221, reward total was -20.0. running mean: -20.206135488453366, timestamp: 2022-08-19 19:07:16.715693\n",
      "resetting env. episode 1222, reward total was -21.0. running mean: -20.214074133568833, timestamp: 2022-08-19 19:07:18.727718\n",
      "resetting env. episode 1223, reward total was -21.0. running mean: -20.221933392233144, timestamp: 2022-08-19 19:07:21.412747\n",
      "resetting env. episode 1224, reward total was -19.0. running mean: -20.209714058310812, timestamp: 2022-08-19 19:07:23.997778\n",
      "resetting env. episode 1225, reward total was -20.0. running mean: -20.2076169177277, timestamp: 2022-08-19 19:07:26.196803\n",
      "resetting env. episode 1226, reward total was -21.0. running mean: -20.215540748550424, timestamp: 2022-08-19 19:07:28.153824\n",
      "resetting env. episode 1227, reward total was -21.0. running mean: -20.22338534106492, timestamp: 2022-08-19 19:07:29.767846\n",
      "resetting env. episode 1228, reward total was -19.0. running mean: -20.21115148765427, timestamp: 2022-08-19 19:07:32.161871\n",
      "resetting env. episode 1229, reward total was -20.0. running mean: -20.209039972777727, timestamp: 2022-08-19 19:07:34.477896\n",
      "resetting env. episode 1230, reward total was -21.0. running mean: -20.216949573049952, timestamp: 2022-08-19 19:07:36.318918\n",
      "resetting env. episode 1231, reward total was -21.0. running mean: -20.224780077319455, timestamp: 2022-08-19 19:07:38.566945\n",
      "resetting env. episode 1232, reward total was -21.0. running mean: -20.232532276546262, timestamp: 2022-08-19 19:07:40.754970\n",
      "resetting env. episode 1233, reward total was -21.0. running mean: -20.2402069537808, timestamp: 2022-08-19 19:07:42.226985\n",
      "resetting env. episode 1234, reward total was -20.0. running mean: -20.23780488424299, timestamp: 2022-08-19 19:07:43.985005\n",
      "resetting env. episode 1235, reward total was -20.0. running mean: -20.23542683540056, timestamp: 2022-08-19 19:07:46.170035\n",
      "resetting env. episode 1236, reward total was -21.0. running mean: -20.243072567046553, timestamp: 2022-08-19 19:07:48.544058\n",
      "resetting env. episode 1237, reward total was -21.0. running mean: -20.250641841376087, timestamp: 2022-08-19 19:07:50.240086\n",
      "resetting env. episode 1238, reward total was -20.0. running mean: -20.248135422962324, timestamp: 2022-08-19 19:07:52.295103\n",
      "resetting env. episode 1239, reward total was -21.0. running mean: -20.255654068732703, timestamp: 2022-08-19 19:07:53.968125\n",
      "resetting env. episode 1240, reward total was -21.0. running mean: -20.26309752804538, timestamp: 2022-08-19 19:07:55.916144\n",
      "resetting env. episode 1241, reward total was -21.0. running mean: -20.270466552764926, timestamp: 2022-08-19 19:07:57.979170\n",
      "resetting env. episode 1242, reward total was -18.0. running mean: -20.247761887237278, timestamp: 2022-08-19 19:08:00.321193\n",
      "resetting env. episode 1243, reward total was -21.0. running mean: -20.255284268364907, timestamp: 2022-08-19 19:08:02.224217\n",
      "resetting env. episode 1244, reward total was -20.0. running mean: -20.252731425681258, timestamp: 2022-08-19 19:08:04.214238\n",
      "resetting env. episode 1245, reward total was -20.0. running mean: -20.250204111424445, timestamp: 2022-08-19 19:08:06.709269\n",
      "resetting env. episode 1246, reward total was -21.0. running mean: -20.257702070310202, timestamp: 2022-08-19 19:08:08.815292\n",
      "resetting env. episode 1247, reward total was -20.0. running mean: -20.2551250496071, timestamp: 2022-08-19 19:08:10.583312\n",
      "resetting env. episode 1248, reward total was -21.0. running mean: -20.262573799111028, timestamp: 2022-08-19 19:08:12.534335\n",
      "resetting env. episode 1249, reward total was -21.0. running mean: -20.26994806111992, timestamp: 2022-08-19 19:08:14.284354\n",
      "resetting env. episode 1250, reward total was -19.0. running mean: -20.257248580508723, timestamp: 2022-08-19 19:08:16.211376\n",
      "resetting env. episode 1251, reward total was -19.0. running mean: -20.244676094703635, timestamp: 2022-08-19 19:08:19.016413\n",
      "resetting env. episode 1252, reward total was -21.0. running mean: -20.2522293337566, timestamp: 2022-08-19 19:08:20.855433\n",
      "resetting env. episode 1253, reward total was -19.0. running mean: -20.239707040419034, timestamp: 2022-08-19 19:08:23.102456\n",
      "resetting env. episode 1254, reward total was -17.0. running mean: -20.207309970014844, timestamp: 2022-08-19 19:08:26.400496\n",
      "resetting env. episode 1255, reward total was -21.0. running mean: -20.215236870314698, timestamp: 2022-08-19 19:08:28.708519\n",
      "resetting env. episode 1256, reward total was -21.0. running mean: -20.223084501611552, timestamp: 2022-08-19 19:08:30.949545\n",
      "resetting env. episode 1257, reward total was -21.0. running mean: -20.23085365659544, timestamp: 2022-08-19 19:08:33.127569\n",
      "resetting env. episode 1258, reward total was -21.0. running mean: -20.238545120029485, timestamp: 2022-08-19 19:08:34.807595\n",
      "resetting env. episode 1259, reward total was -20.0. running mean: -20.23615966882919, timestamp: 2022-08-19 19:08:36.914617\n",
      "resetting env. episode 1260, reward total was -21.0. running mean: -20.243798072140898, timestamp: 2022-08-19 19:08:38.735633\n",
      "resetting env. episode 1261, reward total was -20.0. running mean: -20.241360091419487, timestamp: 2022-08-19 19:08:40.850662\n",
      "resetting env. episode 1262, reward total was -19.0. running mean: -20.228946490505294, timestamp: 2022-08-19 19:08:43.627691\n",
      "resetting env. episode 1263, reward total was -19.0. running mean: -20.21665702560024, timestamp: 2022-08-19 19:08:46.041718\n",
      "resetting env. episode 1264, reward total was -21.0. running mean: -20.224490455344238, timestamp: 2022-08-19 19:08:47.960741\n",
      "resetting env. episode 1265, reward total was -21.0. running mean: -20.232245550790797, timestamp: 2022-08-19 19:08:50.325766\n",
      "resetting env. episode 1266, reward total was -20.0. running mean: -20.22992309528289, timestamp: 2022-08-19 19:08:52.526793\n",
      "resetting env. episode 1267, reward total was -21.0. running mean: -20.23762386433006, timestamp: 2022-08-19 19:08:54.454812\n",
      "resetting env. episode 1268, reward total was -20.0. running mean: -20.23524762568676, timestamp: 2022-08-19 19:08:56.884843\n",
      "resetting env. episode 1269, reward total was -21.0. running mean: -20.242895149429895, timestamp: 2022-08-19 19:08:58.563863\n",
      "resetting env. episode 1270, reward total was -21.0. running mean: -20.250466197935598, timestamp: 2022-08-19 19:09:00.165879\n",
      "resetting env. episode 1271, reward total was -21.0. running mean: -20.25796153595624, timestamp: 2022-08-19 19:09:01.922899\n",
      "resetting env. episode 1272, reward total was -21.0. running mean: -20.265381920596678, timestamp: 2022-08-19 19:09:04.146924\n",
      "resetting env. episode 1273, reward total was -16.0. running mean: -20.22272810139071, timestamp: 2022-08-19 19:09:06.546952\n",
      "resetting env. episode 1274, reward total was -21.0. running mean: -20.230500820376804, timestamp: 2022-08-19 19:09:08.658976\n",
      "resetting env. episode 1275, reward total was -21.0. running mean: -20.238195812173036, timestamp: 2022-08-19 19:09:10.382997\n",
      "resetting env. episode 1276, reward total was -21.0. running mean: -20.245813854051306, timestamp: 2022-08-19 19:09:12.433019\n",
      "resetting env. episode 1277, reward total was -20.0. running mean: -20.24335571551079, timestamp: 2022-08-19 19:09:14.729044\n",
      "resetting env. episode 1278, reward total was -21.0. running mean: -20.250922158355685, timestamp: 2022-08-19 19:09:16.799070\n",
      "resetting env. episode 1279, reward total was -19.0. running mean: -20.23841293677213, timestamp: 2022-08-19 19:09:19.167095\n",
      "resetting env. episode 1280, reward total was -21.0. running mean: -20.246028807404407, timestamp: 2022-08-19 19:09:21.445120\n",
      "resetting env. episode 1281, reward total was -20.0. running mean: -20.243568519330363, timestamp: 2022-08-19 19:09:23.623146\n",
      "resetting env. episode 1282, reward total was -20.0. running mean: -20.24113283413706, timestamp: 2022-08-19 19:09:25.230164\n",
      "resetting env. episode 1283, reward total was -20.0. running mean: -20.238721505795688, timestamp: 2022-08-19 19:09:27.380190\n",
      "resetting env. episode 1284, reward total was -20.0. running mean: -20.23633429073773, timestamp: 2022-08-19 19:09:29.957218\n",
      "resetting env. episode 1285, reward total was -21.0. running mean: -20.243970947830352, timestamp: 2022-08-19 19:09:31.619239\n",
      "resetting env. episode 1286, reward total was -21.0. running mean: -20.251531238352047, timestamp: 2022-08-19 19:09:33.635269\n",
      "resetting env. episode 1287, reward total was -21.0. running mean: -20.259015925968527, timestamp: 2022-08-19 19:09:35.951288\n",
      "resetting env. episode 1288, reward total was -20.0. running mean: -20.25642576670884, timestamp: 2022-08-19 19:09:37.758306\n",
      "resetting env. episode 1289, reward total was -19.0. running mean: -20.243861509041754, timestamp: 2022-08-19 19:09:40.006335\n",
      "resetting env. episode 1290, reward total was -21.0. running mean: -20.251422893951336, timestamp: 2022-08-19 19:09:42.269358\n",
      "resetting env. episode 1291, reward total was -18.0. running mean: -20.228908665011822, timestamp: 2022-08-19 19:09:44.720389\n",
      "resetting env. episode 1292, reward total was -20.0. running mean: -20.226619578361703, timestamp: 2022-08-19 19:09:46.710411\n",
      "resetting env. episode 1293, reward total was -20.0. running mean: -20.224353382578084, timestamp: 2022-08-19 19:09:48.581432\n",
      "resetting env. episode 1294, reward total was -18.0. running mean: -20.202109848752304, timestamp: 2022-08-19 19:09:51.580465\n",
      "resetting env. episode 1295, reward total was -21.0. running mean: -20.21008875026478, timestamp: 2022-08-19 19:09:53.098486\n",
      "resetting env. episode 1296, reward total was -20.0. running mean: -20.20798786276213, timestamp: 2022-08-19 19:09:54.876505\n",
      "resetting env. episode 1297, reward total was -21.0. running mean: -20.21590798413451, timestamp: 2022-08-19 19:09:56.677525\n",
      "resetting env. episode 1298, reward total was -21.0. running mean: -20.223748904293167, timestamp: 2022-08-19 19:09:59.342557\n",
      "resetting env. episode 1299, reward total was -20.0. running mean: -20.221511415250234, timestamp: 2022-08-19 19:10:01.397581\n",
      "resetting env. episode 1300, reward total was -20.0. running mean: -20.21929630109773, timestamp: 2022-08-19 19:10:03.212601\n",
      "resetting env. episode 1301, reward total was -19.0. running mean: -20.207103338086757, timestamp: 2022-08-19 19:10:05.659625\n",
      "resetting env. episode 1302, reward total was -20.0. running mean: -20.205032304705888, timestamp: 2022-08-19 19:10:07.651651\n",
      "resetting env. episode 1303, reward total was -20.0. running mean: -20.20298198165883, timestamp: 2022-08-19 19:10:09.417671\n",
      "resetting env. episode 1304, reward total was -20.0. running mean: -20.200952161842242, timestamp: 2022-08-19 19:10:11.396690\n",
      "resetting env. episode 1305, reward total was -20.0. running mean: -20.19894264022382, timestamp: 2022-08-19 19:10:13.408713\n",
      "resetting env. episode 1306, reward total was -19.0. running mean: -20.18695321382158, timestamp: 2022-08-19 19:10:15.593740\n",
      "resetting env. episode 1307, reward total was -21.0. running mean: -20.195083681683368, timestamp: 2022-08-19 19:10:17.892766\n",
      "resetting env. episode 1308, reward total was -21.0. running mean: -20.203132844866534, timestamp: 2022-08-19 19:10:19.504782\n",
      "resetting env. episode 1309, reward total was -21.0. running mean: -20.21110151641787, timestamp: 2022-08-19 19:10:21.522806\n",
      "resetting env. episode 1310, reward total was -21.0. running mean: -20.218990501253693, timestamp: 2022-08-19 19:10:23.503827\n",
      "resetting env. episode 1311, reward total was -21.0. running mean: -20.226800596241155, timestamp: 2022-08-19 19:10:25.413851\n",
      "resetting env. episode 1312, reward total was -19.0. running mean: -20.214532590278743, timestamp: 2022-08-19 19:10:27.373872\n",
      "resetting env. episode 1313, reward total was -20.0. running mean: -20.212387264375955, timestamp: 2022-08-19 19:10:29.518897\n",
      "resetting env. episode 1314, reward total was -21.0. running mean: -20.220263391732196, timestamp: 2022-08-19 19:10:31.763921\n",
      "resetting env. episode 1315, reward total was -20.0. running mean: -20.21806075781487, timestamp: 2022-08-19 19:10:33.828949\n",
      "resetting env. episode 1316, reward total was -18.0. running mean: -20.19588015023672, timestamp: 2022-08-19 19:10:36.442975\n",
      "resetting env. episode 1317, reward total was -20.0. running mean: -20.193921348734353, timestamp: 2022-08-19 19:10:38.919003\n",
      "resetting env. episode 1318, reward total was -20.0. running mean: -20.19198213524701, timestamp: 2022-08-19 19:10:40.709022\n",
      "resetting env. episode 1319, reward total was -21.0. running mean: -20.20006231389454, timestamp: 2022-08-19 19:10:42.496043\n",
      "resetting env. episode 1320, reward total was -19.0. running mean: -20.188061690755596, timestamp: 2022-08-19 19:10:44.868068\n",
      "resetting env. episode 1321, reward total was -19.0. running mean: -20.176181073848042, timestamp: 2022-08-19 19:10:47.133095\n",
      "resetting env. episode 1322, reward total was -21.0. running mean: -20.18441926310956, timestamp: 2022-08-19 19:10:49.290122\n",
      "resetting env. episode 1323, reward total was -21.0. running mean: -20.192575070478465, timestamp: 2022-08-19 19:10:51.212140\n",
      "resetting env. episode 1324, reward total was -21.0. running mean: -20.20064931977368, timestamp: 2022-08-19 19:10:53.800172\n",
      "resetting env. episode 1325, reward total was -18.0. running mean: -20.178642826575945, timestamp: 2022-08-19 19:10:56.097202\n",
      "resetting env. episode 1326, reward total was -20.0. running mean: -20.176856398310186, timestamp: 2022-08-19 19:10:57.971217\n",
      "resetting env. episode 1327, reward total was -20.0. running mean: -20.175087834327083, timestamp: 2022-08-19 19:10:59.994243\n",
      "resetting env. episode 1328, reward total was -21.0. running mean: -20.183336955983812, timestamp: 2022-08-19 19:11:02.126267\n",
      "resetting env. episode 1329, reward total was -20.0. running mean: -20.181503586423972, timestamp: 2022-08-19 19:11:04.126286\n",
      "resetting env. episode 1330, reward total was -21.0. running mean: -20.189688550559733, timestamp: 2022-08-19 19:11:06.715315\n",
      "resetting env. episode 1331, reward total was -21.0. running mean: -20.197791665054137, timestamp: 2022-08-19 19:11:08.234332\n",
      "resetting env. episode 1332, reward total was -21.0. running mean: -20.205813748403596, timestamp: 2022-08-19 19:11:10.546359\n",
      "resetting env. episode 1333, reward total was -18.0. running mean: -20.183755610919558, timestamp: 2022-08-19 19:11:12.727383\n",
      "resetting env. episode 1334, reward total was -18.0. running mean: -20.16191805481036, timestamp: 2022-08-19 19:11:15.347413\n",
      "resetting env. episode 1335, reward total was -21.0. running mean: -20.170298874262258, timestamp: 2022-08-19 19:11:17.124437\n",
      "resetting env. episode 1336, reward total was -20.0. running mean: -20.168595885519636, timestamp: 2022-08-19 19:11:18.801453\n",
      "resetting env. episode 1337, reward total was -20.0. running mean: -20.166909926664438, timestamp: 2022-08-19 19:11:20.961482\n",
      "resetting env. episode 1338, reward total was -20.0. running mean: -20.165240827397792, timestamp: 2022-08-19 19:11:23.028502\n",
      "resetting env. episode 1339, reward total was -20.0. running mean: -20.163588419123812, timestamp: 2022-08-19 19:11:25.881533\n",
      "resetting env. episode 1340, reward total was -19.0. running mean: -20.151952534932576, timestamp: 2022-08-19 19:11:28.398561\n",
      "resetting env. episode 1341, reward total was -19.0. running mean: -20.14043300958325, timestamp: 2022-08-19 19:11:31.019593\n",
      "resetting env. episode 1342, reward total was -21.0. running mean: -20.14902867948742, timestamp: 2022-08-19 19:11:33.316617\n",
      "resetting env. episode 1343, reward total was -20.0. running mean: -20.147538392692542, timestamp: 2022-08-19 19:11:35.327642\n",
      "resetting env. episode 1344, reward total was -21.0. running mean: -20.156063008765617, timestamp: 2022-08-19 19:11:37.167663\n",
      "resetting env. episode 1345, reward total was -19.0. running mean: -20.144502378677963, timestamp: 2022-08-19 19:11:39.441688\n",
      "resetting env. episode 1346, reward total was -21.0. running mean: -20.153057354891185, timestamp: 2022-08-19 19:11:41.703714\n",
      "resetting env. episode 1347, reward total was -19.0. running mean: -20.141526781342275, timestamp: 2022-08-19 19:11:43.930737\n",
      "resetting env. episode 1348, reward total was -21.0. running mean: -20.150111513528852, timestamp: 2022-08-19 19:11:45.752757\n",
      "resetting env. episode 1349, reward total was -19.0. running mean: -20.138610398393563, timestamp: 2022-08-19 19:11:47.957784\n",
      "resetting env. episode 1350, reward total was -21.0. running mean: -20.14722429440963, timestamp: 2022-08-19 19:11:50.143809\n",
      "resetting env. episode 1351, reward total was -21.0. running mean: -20.155752051465534, timestamp: 2022-08-19 19:11:52.324834\n",
      "resetting env. episode 1352, reward total was -21.0. running mean: -20.16419453095088, timestamp: 2022-08-19 19:11:54.491856\n",
      "resetting env. episode 1353, reward total was -20.0. running mean: -20.16255258564137, timestamp: 2022-08-19 19:11:56.595885\n",
      "resetting env. episode 1354, reward total was -21.0. running mean: -20.170927059784958, timestamp: 2022-08-19 19:11:58.872903\n",
      "resetting env. episode 1355, reward total was -21.0. running mean: -20.17921778918711, timestamp: 2022-08-19 19:12:01.312934\n",
      "resetting env. episode 1356, reward total was -21.0. running mean: -20.18742561129524, timestamp: 2022-08-19 19:12:03.623963\n",
      "resetting env. episode 1357, reward total was -21.0. running mean: -20.19555135518229, timestamp: 2022-08-19 19:12:05.463982\n",
      "resetting env. episode 1358, reward total was -20.0. running mean: -20.193595841630465, timestamp: 2022-08-19 19:12:07.616005\n",
      "resetting env. episode 1359, reward total was -20.0. running mean: -20.19165988321416, timestamp: 2022-08-19 19:12:09.866029\n",
      "resetting env. episode 1360, reward total was -21.0. running mean: -20.19974328438202, timestamp: 2022-08-19 19:12:11.981052\n",
      "resetting env. episode 1361, reward total was -21.0. running mean: -20.2077458515382, timestamp: 2022-08-19 19:12:14.044076\n",
      "resetting env. episode 1362, reward total was -20.0. running mean: -20.205668393022815, timestamp: 2022-08-19 19:12:16.446102\n",
      "resetting env. episode 1363, reward total was -20.0. running mean: -20.203611709092588, timestamp: 2022-08-19 19:12:18.635128\n",
      "resetting env. episode 1364, reward total was -20.0. running mean: -20.20157559200166, timestamp: 2022-08-19 19:12:20.847155\n",
      "resetting env. episode 1365, reward total was -19.0. running mean: -20.189559836081646, timestamp: 2022-08-19 19:12:22.856174\n",
      "resetting env. episode 1366, reward total was -21.0. running mean: -20.19766423772083, timestamp: 2022-08-19 19:12:25.096200\n",
      "resetting env. episode 1367, reward total was -21.0. running mean: -20.205687595343623, timestamp: 2022-08-19 19:12:27.056221\n",
      "resetting env. episode 1368, reward total was -21.0. running mean: -20.21363071939019, timestamp: 2022-08-19 19:12:28.782244\n",
      "resetting env. episode 1369, reward total was -21.0. running mean: -20.221494412196286, timestamp: 2022-08-19 19:12:30.598260\n",
      "resetting env. episode 1370, reward total was -21.0. running mean: -20.229279468074324, timestamp: 2022-08-19 19:12:32.672284\n",
      "resetting env. episode 1371, reward total was -21.0. running mean: -20.23698667339358, timestamp: 2022-08-19 19:12:34.535309\n",
      "resetting env. episode 1372, reward total was -20.0. running mean: -20.234616806659645, timestamp: 2022-08-19 19:12:36.828332\n",
      "resetting env. episode 1373, reward total was -20.0. running mean: -20.232270638593047, timestamp: 2022-08-19 19:12:38.663355\n",
      "resetting env. episode 1374, reward total was -21.0. running mean: -20.239947932207116, timestamp: 2022-08-19 19:12:40.786378\n",
      "resetting env. episode 1375, reward total was -19.0. running mean: -20.227548452885046, timestamp: 2022-08-19 19:12:42.727399\n",
      "resetting env. episode 1376, reward total was -20.0. running mean: -20.225272968356194, timestamp: 2022-08-19 19:12:45.235427\n",
      "resetting env. episode 1377, reward total was -21.0. running mean: -20.233020238672633, timestamp: 2022-08-19 19:12:46.955447\n",
      "resetting env. episode 1378, reward total was -17.0. running mean: -20.20069003628591, timestamp: 2022-08-19 19:12:49.257472\n",
      "resetting env. episode 1379, reward total was -20.0. running mean: -20.198683135923048, timestamp: 2022-08-19 19:12:51.663497\n",
      "resetting env. episode 1380, reward total was -19.0. running mean: -20.186696304563817, timestamp: 2022-08-19 19:12:53.726520\n",
      "resetting env. episode 1381, reward total was -21.0. running mean: -20.19482934151818, timestamp: 2022-08-19 19:12:55.957546\n",
      "resetting env. episode 1382, reward total was -21.0. running mean: -20.202881048103, timestamp: 2022-08-19 19:12:57.983568\n",
      "resetting env. episode 1383, reward total was -20.0. running mean: -20.200852237621966, timestamp: 2022-08-19 19:13:00.504596\n",
      "resetting env. episode 1384, reward total was -20.0. running mean: -20.198843715245744, timestamp: 2022-08-19 19:13:02.596622\n",
      "resetting env. episode 1385, reward total was -21.0. running mean: -20.206855278093286, timestamp: 2022-08-19 19:13:05.202651\n",
      "resetting env. episode 1386, reward total was -21.0. running mean: -20.214786725312354, timestamp: 2022-08-19 19:13:07.025670\n",
      "resetting env. episode 1387, reward total was -21.0. running mean: -20.22263885805923, timestamp: 2022-08-19 19:13:09.059692\n",
      "resetting env. episode 1388, reward total was -21.0. running mean: -20.23041246947864, timestamp: 2022-08-19 19:13:11.267721\n",
      "resetting env. episode 1389, reward total was -20.0. running mean: -20.228108344783852, timestamp: 2022-08-19 19:13:13.986748\n",
      "resetting env. episode 1390, reward total was -21.0. running mean: -20.235827261336013, timestamp: 2022-08-19 19:13:16.182771\n",
      "resetting env. episode 1391, reward total was -21.0. running mean: -20.243468988722654, timestamp: 2022-08-19 19:13:17.966793\n",
      "resetting env. episode 1392, reward total was -18.0. running mean: -20.221034298835427, timestamp: 2022-08-19 19:13:20.470823\n",
      "resetting env. episode 1393, reward total was -20.0. running mean: -20.21882395584707, timestamp: 2022-08-19 19:13:22.322840\n",
      "resetting env. episode 1394, reward total was -21.0. running mean: -20.2266357162886, timestamp: 2022-08-19 19:13:24.421864\n",
      "resetting env. episode 1395, reward total was -19.0. running mean: -20.214369359125715, timestamp: 2022-08-19 19:13:26.570892\n",
      "resetting env. episode 1396, reward total was -19.0. running mean: -20.20222566553446, timestamp: 2022-08-19 19:13:29.136919\n",
      "resetting env. episode 1397, reward total was -20.0. running mean: -20.200203408879116, timestamp: 2022-08-19 19:13:31.130941\n",
      "resetting env. episode 1398, reward total was -20.0. running mean: -20.198201374790322, timestamp: 2022-08-19 19:13:33.427965\n",
      "resetting env. episode 1399, reward total was -19.0. running mean: -20.18621936104242, timestamp: 2022-08-19 19:13:35.814993\n",
      "resetting env. episode 1400, reward total was -21.0. running mean: -20.194357167431995, timestamp: 2022-08-19 19:13:37.700011\n",
      "resetting env. episode 1401, reward total was -21.0. running mean: -20.202413595757676, timestamp: 2022-08-19 19:13:39.528033\n",
      "resetting env. episode 1402, reward total was -18.0. running mean: -20.1803894598001, timestamp: 2022-08-19 19:13:42.103062\n",
      "resetting env. episode 1403, reward total was -19.0. running mean: -20.1685855652021, timestamp: 2022-08-19 19:13:44.369088\n",
      "resetting env. episode 1404, reward total was -20.0. running mean: -20.16689970955008, timestamp: 2022-08-19 19:13:46.858115\n",
      "resetting env. episode 1405, reward total was -20.0. running mean: -20.16523071245458, timestamp: 2022-08-19 19:13:49.079144\n",
      "resetting env. episode 1406, reward total was -21.0. running mean: -20.173578405330034, timestamp: 2022-08-19 19:13:50.932161\n",
      "resetting env. episode 1407, reward total was -20.0. running mean: -20.17184262127673, timestamp: 2022-08-19 19:13:53.032184\n",
      "resetting env. episode 1408, reward total was -21.0. running mean: -20.180124195063964, timestamp: 2022-08-19 19:13:55.560211\n",
      "resetting env. episode 1409, reward total was -21.0. running mean: -20.188322953113325, timestamp: 2022-08-19 19:13:57.387232\n",
      "resetting env. episode 1410, reward total was -21.0. running mean: -20.19643972358219, timestamp: 2022-08-19 19:13:59.231251\n",
      "resetting env. episode 1411, reward total was -16.0. running mean: -20.15447532634637, timestamp: 2022-08-19 19:14:01.987283\n",
      "resetting env. episode 1412, reward total was -21.0. running mean: -20.162930573082907, timestamp: 2022-08-19 19:14:04.017310\n",
      "resetting env. episode 1413, reward total was -18.0. running mean: -20.141301267352077, timestamp: 2022-08-19 19:14:06.188330\n",
      "resetting env. episode 1414, reward total was -20.0. running mean: -20.139888254678556, timestamp: 2022-08-19 19:14:08.012352\n",
      "resetting env. episode 1415, reward total was -21.0. running mean: -20.14848937213177, timestamp: 2022-08-19 19:14:09.959374\n",
      "resetting env. episode 1416, reward total was -21.0. running mean: -20.157004478410453, timestamp: 2022-08-19 19:14:11.744393\n",
      "resetting env. episode 1417, reward total was -21.0. running mean: -20.16543443362635, timestamp: 2022-08-19 19:14:13.654415\n",
      "resetting env. episode 1418, reward total was -21.0. running mean: -20.173780089290087, timestamp: 2022-08-19 19:14:15.692438\n",
      "resetting env. episode 1419, reward total was -21.0. running mean: -20.182042288397188, timestamp: 2022-08-19 19:14:18.148463\n",
      "resetting env. episode 1420, reward total was -20.0. running mean: -20.180221865513214, timestamp: 2022-08-19 19:14:20.546488\n",
      "resetting env. episode 1421, reward total was -21.0. running mean: -20.188419646858083, timestamp: 2022-08-19 19:14:22.470512\n",
      "resetting env. episode 1422, reward total was -20.0. running mean: -20.186535450389503, timestamp: 2022-08-19 19:14:24.660535\n",
      "resetting env. episode 1423, reward total was -20.0. running mean: -20.184670095885608, timestamp: 2022-08-19 19:14:26.203552\n",
      "resetting env. episode 1424, reward total was -18.0. running mean: -20.16282339492675, timestamp: 2022-08-19 19:14:29.065588\n",
      "resetting env. episode 1425, reward total was -21.0. running mean: -20.171195160977483, timestamp: 2022-08-19 19:14:31.492610\n",
      "resetting env. episode 1426, reward total was -21.0. running mean: -20.17948320936771, timestamp: 2022-08-19 19:14:33.550637\n",
      "resetting env. episode 1427, reward total was -20.0. running mean: -20.17768837727403, timestamp: 2022-08-19 19:14:35.921658\n",
      "resetting env. episode 1428, reward total was -21.0. running mean: -20.18591149350129, timestamp: 2022-08-19 19:14:38.303687\n",
      "resetting env. episode 1429, reward total was -20.0. running mean: -20.184052378566278, timestamp: 2022-08-19 19:14:40.282710\n",
      "resetting env. episode 1430, reward total was -20.0. running mean: -20.182211854780615, timestamp: 2022-08-19 19:14:42.224729\n",
      "resetting env. episode 1431, reward total was -21.0. running mean: -20.19038973623281, timestamp: 2022-08-19 19:14:44.191751\n",
      "resetting env. episode 1432, reward total was -19.0. running mean: -20.178485838870483, timestamp: 2022-08-19 19:14:46.645780\n",
      "resetting env. episode 1433, reward total was -21.0. running mean: -20.186700980481778, timestamp: 2022-08-19 19:14:48.677806\n",
      "resetting env. episode 1434, reward total was -20.0. running mean: -20.18483397067696, timestamp: 2022-08-19 19:14:51.519833\n",
      "resetting env. episode 1435, reward total was -21.0. running mean: -20.19298563097019, timestamp: 2022-08-19 19:14:53.849859\n",
      "resetting env. episode 1436, reward total was -20.0. running mean: -20.191055774660484, timestamp: 2022-08-19 19:14:56.150886\n",
      "resetting env. episode 1437, reward total was -21.0. running mean: -20.19914521691388, timestamp: 2022-08-19 19:14:57.712903\n",
      "resetting env. episode 1438, reward total was -20.0. running mean: -20.19715376474474, timestamp: 2022-08-19 19:14:59.902928\n",
      "resetting env. episode 1439, reward total was -20.0. running mean: -20.19518222709729, timestamp: 2022-08-19 19:15:02.178953\n",
      "resetting env. episode 1440, reward total was -21.0. running mean: -20.203230404826318, timestamp: 2022-08-19 19:15:04.178974\n",
      "resetting env. episode 1441, reward total was -20.0. running mean: -20.201198100778054, timestamp: 2022-08-19 19:15:06.405001\n",
      "resetting env. episode 1442, reward total was -21.0. running mean: -20.209186119770273, timestamp: 2022-08-19 19:15:08.085020\n",
      "resetting env. episode 1443, reward total was -21.0. running mean: -20.21709425857257, timestamp: 2022-08-19 19:15:10.585049\n",
      "resetting env. episode 1444, reward total was -18.0. running mean: -20.19492331598684, timestamp: 2022-08-19 19:15:13.153078\n",
      "resetting env. episode 1445, reward total was -21.0. running mean: -20.202974082826973, timestamp: 2022-08-19 19:15:15.215098\n",
      "resetting env. episode 1446, reward total was -20.0. running mean: -20.200944341998703, timestamp: 2022-08-19 19:15:17.615125\n",
      "resetting env. episode 1447, reward total was -18.0. running mean: -20.178934898578717, timestamp: 2022-08-19 19:15:20.294157\n",
      "resetting env. episode 1448, reward total was -21.0. running mean: -20.18714554959293, timestamp: 2022-08-19 19:15:22.209177\n",
      "resetting env. episode 1449, reward total was -20.0. running mean: -20.185274094097, timestamp: 2022-08-19 19:15:24.183200\n",
      "resetting env. episode 1450, reward total was -21.0. running mean: -20.19342135315603, timestamp: 2022-08-19 19:15:26.224225\n",
      "resetting env. episode 1451, reward total was -21.0. running mean: -20.20148713962447, timestamp: 2022-08-19 19:15:28.129251\n",
      "resetting env. episode 1452, reward total was -20.0. running mean: -20.199472268228224, timestamp: 2022-08-19 19:15:30.297268\n",
      "resetting env. episode 1453, reward total was -20.0. running mean: -20.19747754554594, timestamp: 2022-08-19 19:15:32.425293\n",
      "resetting env. episode 1454, reward total was -20.0. running mean: -20.19550277009048, timestamp: 2022-08-19 19:15:34.711320\n",
      "resetting env. episode 1455, reward total was -21.0. running mean: -20.203547742389578, timestamp: 2022-08-19 19:15:36.393338\n",
      "resetting env. episode 1456, reward total was -20.0. running mean: -20.201512264965682, timestamp: 2022-08-19 19:15:38.993368\n",
      "resetting env. episode 1457, reward total was -20.0. running mean: -20.199497142316023, timestamp: 2022-08-19 19:15:40.937390\n",
      "resetting env. episode 1458, reward total was -20.0. running mean: -20.19750217089286, timestamp: 2022-08-19 19:15:42.935415\n",
      "resetting env. episode 1459, reward total was -18.0. running mean: -20.17552714918393, timestamp: 2022-08-19 19:15:45.800446\n",
      "resetting env. episode 1460, reward total was -21.0. running mean: -20.18377187769209, timestamp: 2022-08-19 19:15:47.783466\n",
      "resetting env. episode 1461, reward total was -20.0. running mean: -20.18193415891517, timestamp: 2022-08-19 19:15:50.014495\n",
      "resetting env. episode 1462, reward total was -20.0. running mean: -20.180114817326018, timestamp: 2022-08-19 19:15:52.287520\n",
      "resetting env. episode 1463, reward total was -20.0. running mean: -20.178313669152757, timestamp: 2022-08-19 19:15:54.277542\n",
      "resetting env. episode 1464, reward total was -21.0. running mean: -20.18653053246123, timestamp: 2022-08-19 19:15:55.861559\n",
      "resetting env. episode 1465, reward total was -21.0. running mean: -20.194665227136618, timestamp: 2022-08-19 19:15:57.792580\n",
      "resetting env. episode 1466, reward total was -20.0. running mean: -20.19271857486525, timestamp: 2022-08-19 19:15:59.955605\n",
      "resetting env. episode 1467, reward total was -19.0. running mean: -20.1807913891166, timestamp: 2022-08-19 19:16:02.011631\n",
      "resetting env. episode 1468, reward total was -21.0. running mean: -20.188983475225434, timestamp: 2022-08-19 19:16:03.839653\n",
      "resetting env. episode 1469, reward total was -21.0. running mean: -20.19709364047318, timestamp: 2022-08-19 19:16:05.709670\n",
      "resetting env. episode 1470, reward total was -21.0. running mean: -20.20512270406845, timestamp: 2022-08-19 19:16:07.435691\n",
      "resetting env. episode 1471, reward total was -21.0. running mean: -20.213071477027768, timestamp: 2022-08-19 19:16:09.451712\n",
      "resetting env. episode 1472, reward total was -20.0. running mean: -20.21094076225749, timestamp: 2022-08-19 19:16:12.229748\n",
      "resetting env. episode 1473, reward total was -21.0. running mean: -20.218831354634915, timestamp: 2022-08-19 19:16:14.387769\n",
      "resetting env. episode 1474, reward total was -20.0. running mean: -20.216643041088567, timestamp: 2022-08-19 19:16:16.400796\n",
      "resetting env. episode 1475, reward total was -19.0. running mean: -20.20447661067768, timestamp: 2022-08-19 19:16:18.781821\n",
      "resetting env. episode 1476, reward total was -19.0. running mean: -20.192431844570905, timestamp: 2022-08-19 19:16:21.117848\n",
      "resetting env. episode 1477, reward total was -19.0. running mean: -20.180507526125197, timestamp: 2022-08-19 19:16:23.729876\n",
      "resetting env. episode 1478, reward total was -20.0. running mean: -20.178702450863945, timestamp: 2022-08-19 19:16:26.572909\n",
      "resetting env. episode 1479, reward total was -19.0. running mean: -20.166915426355306, timestamp: 2022-08-19 19:16:29.433942\n",
      "resetting env. episode 1480, reward total was -18.0. running mean: -20.145246272091754, timestamp: 2022-08-19 19:16:32.473977\n",
      "resetting env. episode 1481, reward total was -20.0. running mean: -20.143793809370834, timestamp: 2022-08-19 19:16:35.081007\n",
      "resetting env. episode 1482, reward total was -21.0. running mean: -20.152355871277127, timestamp: 2022-08-19 19:16:37.507035\n",
      "resetting env. episode 1483, reward total was -19.0. running mean: -20.140832312564356, timestamp: 2022-08-19 19:16:39.482057\n",
      "resetting env. episode 1484, reward total was -20.0. running mean: -20.13942398943871, timestamp: 2022-08-19 19:16:41.837085\n",
      "resetting env. episode 1485, reward total was -21.0. running mean: -20.148029749544325, timestamp: 2022-08-19 19:16:43.847110\n",
      "resetting env. episode 1486, reward total was -21.0. running mean: -20.156549452048882, timestamp: 2022-08-19 19:16:45.701131\n",
      "resetting env. episode 1487, reward total was -21.0. running mean: -20.164983957528392, timestamp: 2022-08-19 19:16:47.775153\n",
      "resetting env. episode 1488, reward total was -21.0. running mean: -20.173334117953107, timestamp: 2022-08-19 19:16:49.492173\n",
      "resetting env. episode 1489, reward total was -20.0. running mean: -20.171600776773577, timestamp: 2022-08-19 19:16:51.704198\n",
      "resetting env. episode 1490, reward total was -21.0. running mean: -20.17988476900584, timestamp: 2022-08-19 19:16:53.502219\n",
      "resetting env. episode 1491, reward total was -21.0. running mean: -20.188085921315785, timestamp: 2022-08-19 19:16:55.587245\n",
      "resetting env. episode 1492, reward total was -21.0. running mean: -20.196205062102628, timestamp: 2022-08-19 19:16:57.843268\n",
      "resetting env. episode 1493, reward total was -18.0. running mean: -20.1742430114816, timestamp: 2022-08-19 19:17:00.154296\n",
      "resetting env. episode 1494, reward total was -20.0. running mean: -20.172500581366783, timestamp: 2022-08-19 19:17:02.860327\n",
      "resetting env. episode 1495, reward total was -20.0. running mean: -20.170775575553115, timestamp: 2022-08-19 19:17:05.139352\n",
      "resetting env. episode 1496, reward total was -17.0. running mean: -20.139067819797585, timestamp: 2022-08-19 19:17:07.851383\n",
      "resetting env. episode 1497, reward total was -19.0. running mean: -20.12767714159961, timestamp: 2022-08-19 19:17:10.005408\n",
      "resetting env. episode 1498, reward total was -15.0. running mean: -20.07640037018361, timestamp: 2022-08-19 19:17:12.928442\n",
      "resetting env. episode 1499, reward total was -20.0. running mean: -20.075636366481774, timestamp: 2022-08-19 19:17:14.692465\n",
      "resetting env. episode 1500, reward total was -20.0. running mean: -20.074880002816954, timestamp: 2022-08-19 19:17:17.153490\n",
      "resetting env. episode 1501, reward total was -20.0. running mean: -20.074131202788784, timestamp: 2022-08-19 19:17:19.093515\n",
      "resetting env. episode 1502, reward total was -20.0. running mean: -20.073389890760897, timestamp: 2022-08-19 19:17:20.995536\n",
      "resetting env. episode 1503, reward total was -21.0. running mean: -20.08265599185329, timestamp: 2022-08-19 19:17:23.052559\n",
      "resetting env. episode 1504, reward total was -19.0. running mean: -20.07182943193476, timestamp: 2022-08-19 19:17:25.176583\n",
      "resetting env. episode 1505, reward total was -21.0. running mean: -20.081111137615412, timestamp: 2022-08-19 19:17:27.735615\n",
      "resetting env. episode 1506, reward total was -21.0. running mean: -20.09030002623926, timestamp: 2022-08-19 19:17:29.831638\n",
      "resetting env. episode 1507, reward total was -20.0. running mean: -20.089397025976865, timestamp: 2022-08-19 19:17:31.581659\n",
      "resetting env. episode 1508, reward total was -19.0. running mean: -20.078503055717096, timestamp: 2022-08-19 19:17:34.015687\n",
      "resetting env. episode 1509, reward total was -20.0. running mean: -20.077718025159925, timestamp: 2022-08-19 19:17:36.005711\n",
      "resetting env. episode 1510, reward total was -17.0. running mean: -20.046940844908328, timestamp: 2022-08-19 19:17:38.491738\n",
      "resetting env. episode 1511, reward total was -19.0. running mean: -20.036471436459244, timestamp: 2022-08-19 19:17:40.669765\n",
      "resetting env. episode 1512, reward total was -19.0. running mean: -20.026106722094653, timestamp: 2022-08-19 19:17:42.846789\n",
      "resetting env. episode 1513, reward total was -19.0. running mean: -20.015845654873708, timestamp: 2022-08-19 19:17:45.110817\n",
      "resetting env. episode 1514, reward total was -21.0. running mean: -20.02568719832497, timestamp: 2022-08-19 19:17:46.727838\n",
      "resetting env. episode 1515, reward total was -21.0. running mean: -20.03543032634172, timestamp: 2022-08-19 19:17:48.875859\n",
      "resetting env. episode 1516, reward total was -19.0. running mean: -20.025076023078306, timestamp: 2022-08-19 19:17:51.013885\n",
      "resetting env. episode 1517, reward total was -21.0. running mean: -20.034825262847523, timestamp: 2022-08-19 19:17:53.432914\n",
      "resetting env. episode 1518, reward total was -20.0. running mean: -20.034477010219046, timestamp: 2022-08-19 19:17:56.026943\n",
      "resetting env. episode 1519, reward total was -21.0. running mean: -20.044132240116856, timestamp: 2022-08-19 19:17:57.430959\n",
      "resetting env. episode 1520, reward total was -19.0. running mean: -20.03369091771569, timestamp: 2022-08-19 19:17:59.901987\n",
      "resetting env. episode 1521, reward total was -21.0. running mean: -20.043354008538532, timestamp: 2022-08-19 19:18:02.063015\n",
      "resetting env. episode 1522, reward total was -21.0. running mean: -20.05292046845315, timestamp: 2022-08-19 19:18:03.790034\n",
      "resetting env. episode 1523, reward total was -20.0. running mean: -20.052391263768616, timestamp: 2022-08-19 19:18:06.412065\n",
      "resetting env. episode 1524, reward total was -20.0. running mean: -20.05186735113093, timestamp: 2022-08-19 19:18:08.366089\n",
      "resetting env. episode 1525, reward total was -21.0. running mean: -20.061348677619623, timestamp: 2022-08-19 19:18:09.937102\n",
      "resetting env. episode 1526, reward total was -21.0. running mean: -20.07073519084343, timestamp: 2022-08-19 19:18:12.194129\n",
      "resetting env. episode 1527, reward total was -19.0. running mean: -20.060027838934996, timestamp: 2022-08-19 19:18:14.174157\n",
      "resetting env. episode 1528, reward total was -21.0. running mean: -20.06942756054565, timestamp: 2022-08-19 19:18:15.884172\n",
      "resetting env. episode 1529, reward total was -21.0. running mean: -20.078733284940192, timestamp: 2022-08-19 19:18:17.633196\n",
      "resetting env. episode 1530, reward total was -20.0. running mean: -20.07794595209079, timestamp: 2022-08-19 19:18:21.234235\n",
      "resetting env. episode 1531, reward total was -20.0. running mean: -20.07716649256988, timestamp: 2022-08-19 19:18:22.994261\n",
      "resetting env. episode 1532, reward total was -21.0. running mean: -20.08639482764418, timestamp: 2022-08-19 19:18:25.041281\n",
      "resetting env. episode 1533, reward total was -20.0. running mean: -20.085530879367738, timestamp: 2022-08-19 19:18:27.222308\n",
      "resetting env. episode 1534, reward total was -20.0. running mean: -20.08467557057406, timestamp: 2022-08-19 19:18:29.279329\n",
      "resetting env. episode 1535, reward total was -21.0. running mean: -20.09382881486832, timestamp: 2022-08-19 19:18:30.872347\n",
      "resetting env. episode 1536, reward total was -21.0. running mean: -20.102890526719637, timestamp: 2022-08-19 19:18:33.079373\n",
      "resetting env. episode 1537, reward total was -19.0. running mean: -20.09186162145244, timestamp: 2022-08-19 19:18:35.198398\n",
      "resetting env. episode 1538, reward total was -21.0. running mean: -20.100943005237916, timestamp: 2022-08-19 19:18:37.605432\n",
      "resetting env. episode 1539, reward total was -21.0. running mean: -20.109933575185536, timestamp: 2022-08-19 19:18:39.820453\n",
      "resetting env. episode 1540, reward total was -17.0. running mean: -20.078834239433682, timestamp: 2022-08-19 19:18:42.908490\n",
      "resetting env. episode 1541, reward total was -19.0. running mean: -20.068045897039347, timestamp: 2022-08-19 19:18:45.176517\n",
      "resetting env. episode 1542, reward total was -20.0. running mean: -20.067365438068954, timestamp: 2022-08-19 19:18:47.597546\n",
      "resetting env. episode 1543, reward total was -21.0. running mean: -20.076691783688265, timestamp: 2022-08-19 19:18:49.343564\n",
      "resetting env. episode 1544, reward total was -20.0. running mean: -20.07592486585138, timestamp: 2022-08-19 19:18:51.506588\n",
      "resetting env. episode 1545, reward total was -19.0. running mean: -20.065165617192868, timestamp: 2022-08-19 19:18:53.968618\n",
      "resetting env. episode 1546, reward total was -20.0. running mean: -20.06451396102094, timestamp: 2022-08-19 19:18:56.350649\n",
      "resetting env. episode 1547, reward total was -21.0. running mean: -20.07386882141073, timestamp: 2022-08-19 19:18:58.658679\n",
      "resetting env. episode 1548, reward total was -21.0. running mean: -20.083130133196622, timestamp: 2022-08-19 19:19:00.801748\n",
      "resetting env. episode 1549, reward total was -19.0. running mean: -20.072298831864657, timestamp: 2022-08-19 19:19:02.592772\n",
      "resetting env. episode 1550, reward total was -21.0. running mean: -20.081575843546013, timestamp: 2022-08-19 19:19:04.558791\n",
      "resetting env. episode 1551, reward total was -19.0. running mean: -20.070760085110553, timestamp: 2022-08-19 19:19:07.628826\n",
      "resetting env. episode 1552, reward total was -20.0. running mean: -20.070052484259445, timestamp: 2022-08-19 19:19:09.500847\n",
      "resetting env. episode 1553, reward total was -20.0. running mean: -20.06935195941685, timestamp: 2022-08-19 19:19:11.799875\n",
      "resetting env. episode 1554, reward total was -20.0. running mean: -20.06865843982268, timestamp: 2022-08-19 19:19:14.353905\n",
      "resetting env. episode 1555, reward total was -20.0. running mean: -20.067971855424453, timestamp: 2022-08-19 19:19:16.933936\n",
      "resetting env. episode 1556, reward total was -21.0. running mean: -20.07729213687021, timestamp: 2022-08-19 19:19:18.999961\n",
      "resetting env. episode 1557, reward total was -21.0. running mean: -20.086519215501507, timestamp: 2022-08-19 19:19:21.118986\n",
      "resetting env. episode 1558, reward total was -19.0. running mean: -20.075654023346495, timestamp: 2022-08-19 19:19:23.042006\n",
      "resetting env. episode 1559, reward total was -18.0. running mean: -20.05489748311303, timestamp: 2022-08-19 19:19:25.325032\n",
      "resetting env. episode 1560, reward total was -20.0. running mean: -20.0543485082819, timestamp: 2022-08-19 19:19:27.540057\n",
      "resetting env. episode 1561, reward total was -21.0. running mean: -20.063805023199084, timestamp: 2022-08-19 19:19:29.629083\n",
      "resetting env. episode 1562, reward total was -21.0. running mean: -20.073166972967094, timestamp: 2022-08-19 19:19:31.565108\n",
      "resetting env. episode 1563, reward total was -21.0. running mean: -20.082435303237425, timestamp: 2022-08-19 19:19:33.509131\n",
      "resetting env. episode 1564, reward total was -21.0. running mean: -20.09161095020505, timestamp: 2022-08-19 19:19:35.737153\n",
      "resetting env. episode 1565, reward total was -21.0. running mean: -20.100694840703003, timestamp: 2022-08-19 19:19:37.756178\n",
      "resetting env. episode 1566, reward total was -20.0. running mean: -20.09968789229597, timestamp: 2022-08-19 19:19:40.388208\n",
      "resetting env. episode 1567, reward total was -19.0. running mean: -20.088691013373012, timestamp: 2022-08-19 19:19:43.052240\n",
      "resetting env. episode 1568, reward total was -18.0. running mean: -20.067804103239283, timestamp: 2022-08-19 19:19:45.440269\n",
      "resetting env. episode 1569, reward total was -20.0. running mean: -20.06712606220689, timestamp: 2022-08-19 19:19:47.743294\n",
      "resetting env. episode 1570, reward total was -21.0. running mean: -20.07645480158482, timestamp: 2022-08-19 19:19:49.250313\n",
      "resetting env. episode 1571, reward total was -19.0. running mean: -20.065690253568974, timestamp: 2022-08-19 19:19:52.077349\n",
      "resetting env. episode 1572, reward total was -18.0. running mean: -20.045033351033283, timestamp: 2022-08-19 19:19:54.497376\n",
      "resetting env. episode 1573, reward total was -21.0. running mean: -20.05458301752295, timestamp: 2022-08-19 19:19:56.285397\n",
      "resetting env. episode 1574, reward total was -21.0. running mean: -20.064037187347722, timestamp: 2022-08-19 19:19:58.283418\n",
      "resetting env. episode 1575, reward total was -19.0. running mean: -20.053396815474247, timestamp: 2022-08-19 19:20:01.002451\n",
      "resetting env. episode 1576, reward total was -21.0. running mean: -20.062862847319504, timestamp: 2022-08-19 19:20:03.268476\n",
      "resetting env. episode 1577, reward total was -18.0. running mean: -20.04223421884631, timestamp: 2022-08-19 19:20:05.703509\n",
      "resetting env. episode 1578, reward total was -18.0. running mean: -20.021811876657846, timestamp: 2022-08-19 19:20:07.889530\n",
      "resetting env. episode 1579, reward total was -21.0. running mean: -20.03159375789127, timestamp: 2022-08-19 19:20:09.766554\n",
      "resetting env. episode 1580, reward total was -20.0. running mean: -20.031277820312354, timestamp: 2022-08-19 19:20:12.435584\n",
      "resetting env. episode 1581, reward total was -21.0. running mean: -20.04096504210923, timestamp: 2022-08-19 19:20:14.651609\n",
      "resetting env. episode 1582, reward total was -21.0. running mean: -20.05055539168814, timestamp: 2022-08-19 19:20:17.042637\n",
      "resetting env. episode 1583, reward total was -18.0. running mean: -20.03004983777126, timestamp: 2022-08-19 19:20:19.916672\n",
      "resetting env. episode 1584, reward total was -21.0. running mean: -20.03974933939355, timestamp: 2022-08-19 19:20:22.278700\n",
      "resetting env. episode 1585, reward total was -20.0. running mean: -20.03935184599961, timestamp: 2022-08-19 19:20:24.378723\n",
      "resetting env. episode 1586, reward total was -21.0. running mean: -20.048958327539616, timestamp: 2022-08-19 19:20:26.087744\n",
      "resetting env. episode 1587, reward total was -21.0. running mean: -20.05846874426422, timestamp: 2022-08-19 19:20:28.388770\n",
      "resetting env. episode 1588, reward total was -21.0. running mean: -20.06788405682158, timestamp: 2022-08-19 19:20:30.791800\n",
      "resetting env. episode 1589, reward total was -21.0. running mean: -20.077205216253365, timestamp: 2022-08-19 19:20:33.261827\n",
      "resetting env. episode 1590, reward total was -21.0. running mean: -20.08643316409083, timestamp: 2022-08-19 19:20:35.318851\n",
      "resetting env. episode 1591, reward total was -21.0. running mean: -20.095568832449924, timestamp: 2022-08-19 19:20:37.808881\n",
      "resetting env. episode 1592, reward total was -21.0. running mean: -20.104613144125427, timestamp: 2022-08-19 19:20:40.277920\n",
      "resetting env. episode 1593, reward total was -20.0. running mean: -20.10356701268417, timestamp: 2022-08-19 19:20:42.494936\n",
      "resetting env. episode 1594, reward total was -20.0. running mean: -20.102531342557327, timestamp: 2022-08-19 19:20:44.335959\n",
      "resetting env. episode 1595, reward total was -21.0. running mean: -20.111506029131753, timestamp: 2022-08-19 19:20:46.267980\n",
      "resetting env. episode 1596, reward total was -21.0. running mean: -20.120390968840436, timestamp: 2022-08-19 19:20:48.552006\n",
      "resetting env. episode 1597, reward total was -20.0. running mean: -20.11918705915203, timestamp: 2022-08-19 19:20:51.058035\n",
      "resetting env. episode 1598, reward total was -20.0. running mean: -20.117995188560506, timestamp: 2022-08-19 19:20:53.467068\n",
      "resetting env. episode 1599, reward total was -21.0. running mean: -20.1268152366749, timestamp: 2022-08-19 19:20:54.914083\n",
      "resetting env. episode 1600, reward total was -21.0. running mean: -20.135547084308154, timestamp: 2022-08-19 19:20:57.277107\n",
      "resetting env. episode 1601, reward total was -21.0. running mean: -20.144191613465072, timestamp: 2022-08-19 19:20:59.163130\n",
      "resetting env. episode 1602, reward total was -20.0. running mean: -20.14274969733042, timestamp: 2022-08-19 19:21:01.049159\n",
      "resetting env. episode 1603, reward total was -21.0. running mean: -20.151322200357114, timestamp: 2022-08-19 19:21:02.462171\n",
      "resetting env. episode 1604, reward total was -21.0. running mean: -20.159808978353546, timestamp: 2022-08-19 19:21:04.728197\n",
      "resetting env. episode 1605, reward total was -20.0. running mean: -20.15821088857001, timestamp: 2022-08-19 19:21:06.875220\n",
      "resetting env. episode 1606, reward total was -18.0. running mean: -20.13662877968431, timestamp: 2022-08-19 19:21:09.705255\n",
      "resetting env. episode 1607, reward total was -21.0. running mean: -20.14526249188747, timestamp: 2022-08-19 19:21:12.337286\n",
      "resetting env. episode 1608, reward total was -21.0. running mean: -20.153809866968594, timestamp: 2022-08-19 19:21:14.443313\n",
      "resetting env. episode 1609, reward total was -20.0. running mean: -20.152271768298906, timestamp: 2022-08-19 19:21:16.753336\n",
      "resetting env. episode 1610, reward total was -21.0. running mean: -20.160749050615916, timestamp: 2022-08-19 19:21:19.323367\n",
      "resetting env. episode 1611, reward total was -21.0. running mean: -20.169141560109757, timestamp: 2022-08-19 19:21:21.428393\n",
      "resetting env. episode 1612, reward total was -20.0. running mean: -20.16745014450866, timestamp: 2022-08-19 19:21:23.454422\n",
      "resetting env. episode 1613, reward total was -21.0. running mean: -20.175775643063574, timestamp: 2022-08-19 19:21:25.452437\n",
      "resetting env. episode 1614, reward total was -20.0. running mean: -20.17401788663294, timestamp: 2022-08-19 19:21:27.623463\n",
      "resetting env. episode 1615, reward total was -20.0. running mean: -20.172277707766607, timestamp: 2022-08-19 19:21:30.194494\n",
      "resetting env. episode 1616, reward total was -19.0. running mean: -20.160554930688942, timestamp: 2022-08-19 19:21:33.077528\n",
      "resetting env. episode 1617, reward total was -20.0. running mean: -20.15894938138205, timestamp: 2022-08-19 19:21:35.475557\n",
      "resetting env. episode 1618, reward total was -20.0. running mean: -20.15735988756823, timestamp: 2022-08-19 19:21:37.549579\n",
      "resetting env. episode 1619, reward total was -21.0. running mean: -20.165786288692548, timestamp: 2022-08-19 19:21:39.598604\n",
      "resetting env. episode 1620, reward total was -21.0. running mean: -20.174128425805623, timestamp: 2022-08-19 19:21:41.697628\n",
      "resetting env. episode 1621, reward total was -18.0. running mean: -20.152387141547567, timestamp: 2022-08-19 19:21:44.145660\n",
      "resetting env. episode 1622, reward total was -20.0. running mean: -20.150863270132092, timestamp: 2022-08-19 19:21:46.632686\n",
      "resetting env. episode 1623, reward total was -21.0. running mean: -20.159354637430773, timestamp: 2022-08-19 19:21:48.958712\n",
      "resetting env. episode 1624, reward total was -21.0. running mean: -20.167761091056466, timestamp: 2022-08-19 19:21:51.201739\n",
      "resetting env. episode 1625, reward total was -20.0. running mean: -20.1660834801459, timestamp: 2022-08-19 19:21:53.745769\n",
      "resetting env. episode 1626, reward total was -21.0. running mean: -20.174422645344443, timestamp: 2022-08-19 19:21:55.964795\n",
      "resetting env. episode 1627, reward total was -21.0. running mean: -20.182678418890998, timestamp: 2022-08-19 19:21:57.896819\n",
      "resetting env. episode 1628, reward total was -21.0. running mean: -20.19085163470209, timestamp: 2022-08-19 19:22:00.823852\n",
      "resetting env. episode 1629, reward total was -19.0. running mean: -20.17894311835507, timestamp: 2022-08-19 19:22:03.334881\n",
      "resetting env. episode 1630, reward total was -18.0. running mean: -20.157153687171515, timestamp: 2022-08-19 19:22:06.317915\n",
      "resetting env. episode 1631, reward total was -21.0. running mean: -20.1655821502998, timestamp: 2022-08-19 19:22:08.751944\n",
      "resetting env. episode 1632, reward total was -21.0. running mean: -20.173926328796803, timestamp: 2022-08-19 19:22:11.051973\n",
      "resetting env. episode 1633, reward total was -20.0. running mean: -20.172187065508833, timestamp: 2022-08-19 19:22:12.741991\n",
      "resetting env. episode 1634, reward total was -21.0. running mean: -20.180465194853745, timestamp: 2022-08-19 19:22:14.745016\n",
      "resetting env. episode 1635, reward total was -21.0. running mean: -20.188660542905208, timestamp: 2022-08-19 19:22:16.781039\n",
      "resetting env. episode 1636, reward total was -19.0. running mean: -20.176773937476156, timestamp: 2022-08-19 19:22:19.365072\n",
      "resetting env. episode 1637, reward total was -19.0. running mean: -20.165006198101395, timestamp: 2022-08-19 19:22:22.581108\n",
      "resetting env. episode 1638, reward total was -21.0. running mean: -20.173356136120383, timestamp: 2022-08-19 19:22:24.986134\n",
      "resetting env. episode 1639, reward total was -21.0. running mean: -20.181622574759178, timestamp: 2022-08-19 19:22:26.896160\n",
      "resetting env. episode 1640, reward total was -20.0. running mean: -20.179806349011585, timestamp: 2022-08-19 19:22:29.326187\n",
      "resetting env. episode 1641, reward total was -21.0. running mean: -20.18800828552147, timestamp: 2022-08-19 19:22:30.894204\n",
      "resetting env. episode 1642, reward total was -21.0. running mean: -20.196128202666255, timestamp: 2022-08-19 19:22:33.044228\n",
      "resetting env. episode 1643, reward total was -19.0. running mean: -20.184166920639594, timestamp: 2022-08-19 19:22:35.900265\n",
      "resetting env. episode 1644, reward total was -19.0. running mean: -20.1723252514332, timestamp: 2022-08-19 19:22:38.170289\n",
      "resetting env. episode 1645, reward total was -21.0. running mean: -20.18060199891887, timestamp: 2022-08-19 19:22:40.530316\n",
      "resetting env. episode 1646, reward total was -20.0. running mean: -20.17879597892968, timestamp: 2022-08-19 19:22:43.185348\n",
      "resetting env. episode 1647, reward total was -21.0. running mean: -20.187008019140386, timestamp: 2022-08-19 19:22:45.167370\n",
      "resetting env. episode 1648, reward total was -21.0. running mean: -20.19513793894898, timestamp: 2022-08-19 19:22:47.347397\n",
      "resetting env. episode 1649, reward total was -21.0. running mean: -20.20318655955949, timestamp: 2022-08-19 19:22:49.628426\n",
      "resetting env. episode 1650, reward total was -21.0. running mean: -20.211154693963895, timestamp: 2022-08-19 19:22:51.669448\n",
      "resetting env. episode 1651, reward total was -15.0. running mean: -20.159043147024253, timestamp: 2022-08-19 19:22:54.596482\n",
      "resetting env. episode 1652, reward total was -21.0. running mean: -20.16745271555401, timestamp: 2022-08-19 19:22:57.016519\n",
      "resetting env. episode 1653, reward total was -19.0. running mean: -20.15577818839847, timestamp: 2022-08-19 19:22:59.546544\n",
      "resetting env. episode 1654, reward total was -20.0. running mean: -20.154220406514487, timestamp: 2022-08-19 19:23:02.139572\n",
      "resetting env. episode 1655, reward total was -21.0. running mean: -20.162678202449342, timestamp: 2022-08-19 19:23:04.154592\n",
      "resetting env. episode 1656, reward total was -21.0. running mean: -20.17105142042485, timestamp: 2022-08-19 19:23:06.569621\n",
      "resetting env. episode 1657, reward total was -19.0. running mean: -20.159340906220603, timestamp: 2022-08-19 19:23:08.710653\n",
      "resetting env. episode 1658, reward total was -18.0. running mean: -20.137747497158397, timestamp: 2022-08-19 19:23:11.166675\n",
      "resetting env. episode 1659, reward total was -20.0. running mean: -20.136370022186814, timestamp: 2022-08-19 19:23:13.269704\n",
      "resetting env. episode 1660, reward total was -21.0. running mean: -20.145006321964946, timestamp: 2022-08-19 19:23:15.865731\n",
      "resetting env. episode 1661, reward total was -21.0. running mean: -20.153556258745297, timestamp: 2022-08-19 19:23:17.614755\n",
      "resetting env. episode 1662, reward total was -21.0. running mean: -20.162020696157846, timestamp: 2022-08-19 19:23:19.736775\n",
      "resetting env. episode 1663, reward total was -19.0. running mean: -20.15040048919627, timestamp: 2022-08-19 19:23:22.033802\n",
      "resetting env. episode 1664, reward total was -18.0. running mean: -20.128896484304306, timestamp: 2022-08-19 19:23:24.372831\n",
      "resetting env. episode 1665, reward total was -21.0. running mean: -20.137607519461262, timestamp: 2022-08-19 19:23:26.184853\n",
      "resetting env. episode 1666, reward total was -21.0. running mean: -20.14623144426665, timestamp: 2022-08-19 19:23:27.944871\n",
      "resetting env. episode 1667, reward total was -19.0. running mean: -20.134769129823987, timestamp: 2022-08-19 19:23:30.523902\n",
      "resetting env. episode 1668, reward total was -20.0. running mean: -20.133421438525748, timestamp: 2022-08-19 19:23:32.724930\n",
      "resetting env. episode 1669, reward total was -20.0. running mean: -20.132087224140488, timestamp: 2022-08-19 19:23:34.877952\n",
      "resetting env. episode 1670, reward total was -20.0. running mean: -20.130766351899084, timestamp: 2022-08-19 19:23:37.203978\n",
      "resetting env. episode 1671, reward total was -19.0. running mean: -20.119458688380092, timestamp: 2022-08-19 19:23:39.428005\n",
      "resetting env. episode 1672, reward total was -20.0. running mean: -20.11826410149629, timestamp: 2022-08-19 19:23:41.501030\n",
      "resetting env. episode 1673, reward total was -21.0. running mean: -20.127081460481328, timestamp: 2022-08-19 19:23:43.947058\n",
      "resetting env. episode 1674, reward total was -21.0. running mean: -20.135810645876514, timestamp: 2022-08-19 19:23:45.758082\n",
      "resetting env. episode 1675, reward total was -21.0. running mean: -20.14445253941775, timestamp: 2022-08-19 19:23:47.957108\n",
      "resetting env. episode 1676, reward total was -21.0. running mean: -20.153008014023573, timestamp: 2022-08-19 19:23:50.075134\n",
      "resetting env. episode 1677, reward total was -21.0. running mean: -20.161477933883337, timestamp: 2022-08-19 19:23:51.492146\n",
      "resetting env. episode 1678, reward total was -21.0. running mean: -20.169863154544505, timestamp: 2022-08-19 19:23:53.390171\n",
      "resetting env. episode 1679, reward total was -21.0. running mean: -20.17816452299906, timestamp: 2022-08-19 19:23:55.698199\n",
      "resetting env. episode 1680, reward total was -21.0. running mean: -20.18638287776907, timestamp: 2022-08-19 19:23:57.581219\n",
      "resetting env. episode 1681, reward total was -21.0. running mean: -20.19451904899138, timestamp: 2022-08-19 19:23:59.431239\n",
      "resetting env. episode 1682, reward total was -20.0. running mean: -20.192573858501465, timestamp: 2022-08-19 19:24:01.661265\n",
      "resetting env. episode 1683, reward total was -21.0. running mean: -20.20064811991645, timestamp: 2022-08-19 19:24:03.690290\n",
      "resetting env. episode 1684, reward total was -21.0. running mean: -20.20864163871729, timestamp: 2022-08-19 19:24:06.093319\n",
      "resetting env. episode 1685, reward total was -21.0. running mean: -20.21655522233012, timestamp: 2022-08-19 19:24:08.758349\n",
      "resetting env. episode 1686, reward total was -20.0. running mean: -20.214389670106815, timestamp: 2022-08-19 19:24:10.923376\n",
      "resetting env. episode 1687, reward total was -21.0. running mean: -20.22224577340575, timestamp: 2022-08-19 19:24:13.227401\n",
      "resetting env. episode 1688, reward total was -19.0. running mean: -20.21002331567169, timestamp: 2022-08-19 19:24:15.140425\n",
      "resetting env. episode 1689, reward total was -21.0. running mean: -20.217923082514975, timestamp: 2022-08-19 19:24:17.413453\n",
      "resetting env. episode 1690, reward total was -21.0. running mean: -20.225743851689828, timestamp: 2022-08-19 19:24:19.388471\n",
      "resetting env. episode 1691, reward total was -20.0. running mean: -20.223486413172928, timestamp: 2022-08-19 19:24:21.542502\n",
      "resetting env. episode 1692, reward total was -21.0. running mean: -20.2312515490412, timestamp: 2022-08-19 19:24:23.143519\n",
      "resetting env. episode 1693, reward total was -20.0. running mean: -20.228939033550787, timestamp: 2022-08-19 19:24:25.412547\n",
      "resetting env. episode 1694, reward total was -21.0. running mean: -20.23664964321528, timestamp: 2022-08-19 19:24:28.004574\n",
      "resetting env. episode 1695, reward total was -20.0. running mean: -20.234283146783127, timestamp: 2022-08-19 19:24:30.466603\n",
      "resetting env. episode 1696, reward total was -20.0. running mean: -20.231940315315295, timestamp: 2022-08-19 19:24:33.251636\n",
      "resetting env. episode 1697, reward total was -21.0. running mean: -20.23962091216214, timestamp: 2022-08-19 19:24:35.889666\n",
      "resetting env. episode 1698, reward total was -20.0. running mean: -20.237224703040518, timestamp: 2022-08-19 19:24:38.550708\n",
      "resetting env. episode 1699, reward total was -21.0. running mean: -20.244852456010115, timestamp: 2022-08-19 19:24:40.507725\n",
      "resetting env. episode 1700, reward total was -21.0. running mean: -20.252403931450015, timestamp: 2022-08-19 19:24:42.661744\n",
      "resetting env. episode 1701, reward total was -20.0. running mean: -20.249879892135514, timestamp: 2022-08-19 19:24:45.047773\n",
      "resetting env. episode 1702, reward total was -21.0. running mean: -20.25738109321416, timestamp: 2022-08-19 19:24:47.769805\n",
      "resetting env. episode 1703, reward total was -20.0. running mean: -20.25480728228202, timestamp: 2022-08-19 19:24:49.975831\n",
      "resetting env. episode 1704, reward total was -20.0. running mean: -20.252259209459197, timestamp: 2022-08-19 19:24:52.809863\n",
      "resetting env. episode 1705, reward total was -21.0. running mean: -20.259736617364606, timestamp: 2022-08-19 19:24:54.853888\n",
      "resetting env. episode 1706, reward total was -20.0. running mean: -20.25713925119096, timestamp: 2022-08-19 19:24:56.799915\n",
      "resetting env. episode 1707, reward total was -21.0. running mean: -20.26456785867905, timestamp: 2022-08-19 19:24:58.768932\n",
      "resetting env. episode 1708, reward total was -21.0. running mean: -20.27192218009226, timestamp: 2022-08-19 19:25:00.648953\n",
      "resetting env. episode 1709, reward total was -21.0. running mean: -20.27920295829134, timestamp: 2022-08-19 19:25:02.603979\n",
      "resetting env. episode 1710, reward total was -20.0. running mean: -20.276410928708426, timestamp: 2022-08-19 19:25:05.414010\n",
      "resetting env. episode 1711, reward total was -18.0. running mean: -20.25364681942134, timestamp: 2022-08-19 19:25:08.328045\n",
      "resetting env. episode 1712, reward total was -21.0. running mean: -20.261110351227128, timestamp: 2022-08-19 19:25:11.102075\n",
      "resetting env. episode 1713, reward total was -18.0. running mean: -20.238499247714856, timestamp: 2022-08-19 19:25:14.112111\n",
      "resetting env. episode 1714, reward total was -20.0. running mean: -20.236114255237705, timestamp: 2022-08-19 19:25:16.324135\n",
      "resetting env. episode 1715, reward total was -21.0. running mean: -20.24375311268533, timestamp: 2022-08-19 19:25:18.722167\n",
      "resetting env. episode 1716, reward total was -19.0. running mean: -20.231315581558476, timestamp: 2022-08-19 19:25:21.200192\n",
      "resetting env. episode 1717, reward total was -21.0. running mean: -20.239002425742893, timestamp: 2022-08-19 19:25:23.758222\n",
      "resetting env. episode 1718, reward total was -21.0. running mean: -20.246612401485464, timestamp: 2022-08-19 19:25:26.091250\n",
      "resetting env. episode 1719, reward total was -21.0. running mean: -20.25414627747061, timestamp: 2022-08-19 19:25:27.769271\n",
      "resetting env. episode 1720, reward total was -20.0. running mean: -20.251604814695902, timestamp: 2022-08-19 19:25:30.419300\n",
      "resetting env. episode 1721, reward total was -20.0. running mean: -20.249088766548944, timestamp: 2022-08-19 19:25:32.518322\n",
      "resetting env. episode 1722, reward total was -20.0. running mean: -20.246597878883453, timestamp: 2022-08-19 19:25:34.978353\n",
      "resetting env. episode 1723, reward total was -21.0. running mean: -20.25413190009462, timestamp: 2022-08-19 19:25:36.890373\n",
      "resetting env. episode 1724, reward total was -21.0. running mean: -20.261590581093675, timestamp: 2022-08-19 19:25:39.165403\n",
      "resetting env. episode 1725, reward total was -19.0. running mean: -20.24897467528274, timestamp: 2022-08-19 19:25:41.483431\n",
      "resetting env. episode 1726, reward total was -20.0. running mean: -20.24648492852991, timestamp: 2022-08-19 19:25:43.308453\n",
      "resetting env. episode 1727, reward total was -21.0. running mean: -20.25402007924461, timestamp: 2022-08-19 19:25:45.422476\n",
      "resetting env. episode 1728, reward total was -21.0. running mean: -20.261479878452167, timestamp: 2022-08-19 19:25:47.837506\n",
      "resetting env. episode 1729, reward total was -20.0. running mean: -20.258865079667643, timestamp: 2022-08-19 19:25:50.109527\n",
      "resetting env. episode 1730, reward total was -19.0. running mean: -20.246276428870967, timestamp: 2022-08-19 19:25:52.468554\n",
      "resetting env. episode 1731, reward total was -21.0. running mean: -20.253813664582257, timestamp: 2022-08-19 19:25:54.273579\n",
      "resetting env. episode 1732, reward total was -19.0. running mean: -20.241275527936434, timestamp: 2022-08-19 19:25:56.706604\n",
      "resetting env. episode 1733, reward total was -19.0. running mean: -20.22886277265707, timestamp: 2022-08-19 19:25:58.940630\n",
      "resetting env. episode 1734, reward total was -19.0. running mean: -20.2165741449305, timestamp: 2022-08-19 19:26:01.297657\n",
      "resetting env. episode 1735, reward total was -20.0. running mean: -20.214408403481194, timestamp: 2022-08-19 19:26:03.279680\n",
      "resetting env. episode 1736, reward total was -21.0. running mean: -20.22226431944638, timestamp: 2022-08-19 19:26:05.344708\n",
      "resetting env. episode 1737, reward total was -21.0. running mean: -20.23004167625192, timestamp: 2022-08-19 19:26:06.804720\n",
      "resetting env. episode 1738, reward total was -20.0. running mean: -20.2277412594894, timestamp: 2022-08-19 19:26:09.289755\n",
      "resetting env. episode 1739, reward total was -21.0. running mean: -20.235463846894504, timestamp: 2022-08-19 19:26:11.951787\n",
      "resetting env. episode 1740, reward total was -21.0. running mean: -20.243109208425558, timestamp: 2022-08-19 19:26:14.015803\n",
      "resetting env. episode 1741, reward total was -21.0. running mean: -20.2506781163413, timestamp: 2022-08-19 19:26:16.470832\n",
      "resetting env. episode 1742, reward total was -21.0. running mean: -20.258171335177888, timestamp: 2022-08-19 19:26:18.544858\n",
      "resetting env. episode 1743, reward total was -21.0. running mean: -20.26558962182611, timestamp: 2022-08-19 19:26:20.982886\n",
      "resetting env. episode 1744, reward total was -20.0. running mean: -20.262933725607848, timestamp: 2022-08-19 19:26:23.300913\n",
      "resetting env. episode 1745, reward total was -21.0. running mean: -20.27030438835177, timestamp: 2022-08-19 19:26:25.232936\n",
      "resetting env. episode 1746, reward total was -21.0. running mean: -20.277601344468255, timestamp: 2022-08-19 19:26:27.350959\n",
      "resetting env. episode 1747, reward total was -21.0. running mean: -20.284825331023573, timestamp: 2022-08-19 19:26:29.492984\n",
      "resetting env. episode 1748, reward total was -20.0. running mean: -20.281977077713336, timestamp: 2022-08-19 19:26:31.916013\n",
      "resetting env. episode 1749, reward total was -19.0. running mean: -20.269157306936204, timestamp: 2022-08-19 19:26:34.845046\n",
      "resetting env. episode 1750, reward total was -21.0. running mean: -20.276465733866843, timestamp: 2022-08-19 19:26:36.927070\n",
      "resetting env. episode 1751, reward total was -20.0. running mean: -20.273701076528173, timestamp: 2022-08-19 19:26:38.920095\n",
      "resetting env. episode 1752, reward total was -20.0. running mean: -20.27096406576289, timestamp: 2022-08-19 19:26:40.698113\n",
      "resetting env. episode 1753, reward total was -20.0. running mean: -20.26825442510526, timestamp: 2022-08-19 19:26:42.733136\n",
      "resetting env. episode 1754, reward total was -21.0. running mean: -20.275571880854205, timestamp: 2022-08-19 19:26:45.696173\n",
      "resetting env. episode 1755, reward total was -20.0. running mean: -20.27281616204566, timestamp: 2022-08-19 19:26:48.042202\n",
      "resetting env. episode 1756, reward total was -20.0. running mean: -20.270088000425204, timestamp: 2022-08-19 19:26:49.971226\n",
      "resetting env. episode 1757, reward total was -19.0. running mean: -20.257387120420955, timestamp: 2022-08-19 19:26:52.547251\n",
      "resetting env. episode 1758, reward total was -21.0. running mean: -20.264813249216747, timestamp: 2022-08-19 19:26:54.953284\n",
      "resetting env. episode 1759, reward total was -20.0. running mean: -20.262165116724578, timestamp: 2022-08-19 19:26:57.362308\n",
      "resetting env. episode 1760, reward total was -21.0. running mean: -20.269543465557334, timestamp: 2022-08-19 19:26:59.508331\n",
      "resetting env. episode 1761, reward total was -20.0. running mean: -20.26684803090176, timestamp: 2022-08-19 19:27:01.397351\n",
      "resetting env. episode 1762, reward total was -21.0. running mean: -20.27417955059274, timestamp: 2022-08-19 19:27:03.311374\n",
      "resetting env. episode 1763, reward total was -18.0. running mean: -20.251437755086812, timestamp: 2022-08-19 19:27:05.707406\n",
      "resetting env. episode 1764, reward total was -18.0. running mean: -20.228923377535942, timestamp: 2022-08-19 19:27:08.066430\n",
      "resetting env. episode 1765, reward total was -21.0. running mean: -20.236634143760583, timestamp: 2022-08-19 19:27:09.959453\n",
      "resetting env. episode 1766, reward total was -19.0. running mean: -20.224267802322977, timestamp: 2022-08-19 19:27:12.407481\n",
      "resetting env. episode 1767, reward total was -21.0. running mean: -20.23202512429975, timestamp: 2022-08-19 19:27:14.307501\n",
      "resetting env. episode 1768, reward total was -20.0. running mean: -20.22970487305675, timestamp: 2022-08-19 19:27:17.094533\n",
      "resetting env. episode 1769, reward total was -19.0. running mean: -20.217407824326184, timestamp: 2022-08-19 19:27:19.671564\n",
      "resetting env. episode 1770, reward total was -19.0. running mean: -20.20523374608292, timestamp: 2022-08-19 19:27:22.335592\n",
      "resetting env. episode 1771, reward total was -21.0. running mean: -20.21318140862209, timestamp: 2022-08-19 19:27:24.791623\n",
      "resetting env. episode 1772, reward total was -21.0. running mean: -20.22104959453587, timestamp: 2022-08-19 19:27:27.131649\n",
      "resetting env. episode 1773, reward total was -20.0. running mean: -20.21883909859051, timestamp: 2022-08-19 19:27:29.399678\n",
      "resetting env. episode 1774, reward total was -21.0. running mean: -20.226650707604605, timestamp: 2022-08-19 19:27:31.386701\n",
      "resetting env. episode 1775, reward total was -20.0. running mean: -20.224384200528558, timestamp: 2022-08-19 19:27:33.098721\n",
      "resetting env. episode 1776, reward total was -18.0. running mean: -20.202140358523273, timestamp: 2022-08-19 19:27:35.834748\n",
      "resetting env. episode 1777, reward total was -20.0. running mean: -20.20011895493804, timestamp: 2022-08-19 19:27:38.002777\n",
      "resetting env. episode 1778, reward total was -21.0. running mean: -20.20811776538866, timestamp: 2022-08-19 19:27:40.733805\n",
      "resetting env. episode 1779, reward total was -21.0. running mean: -20.216036587734774, timestamp: 2022-08-19 19:27:42.835830\n",
      "resetting env. episode 1780, reward total was -20.0. running mean: -20.213876221857426, timestamp: 2022-08-19 19:27:45.099855\n",
      "resetting env. episode 1781, reward total was -21.0. running mean: -20.221737459638852, timestamp: 2022-08-19 19:27:47.283881\n",
      "resetting env. episode 1782, reward total was -18.0. running mean: -20.19952008504246, timestamp: 2022-08-19 19:27:49.760910\n",
      "resetting env. episode 1783, reward total was -19.0. running mean: -20.187524884192037, timestamp: 2022-08-19 19:27:51.910935\n",
      "resetting env. episode 1784, reward total was -20.0. running mean: -20.185649635350117, timestamp: 2022-08-19 19:27:53.883959\n",
      "resetting env. episode 1785, reward total was -21.0. running mean: -20.193793138996618, timestamp: 2022-08-19 19:27:56.537988\n",
      "resetting env. episode 1786, reward total was -20.0. running mean: -20.19185520760665, timestamp: 2022-08-19 19:27:59.160017\n",
      "resetting env. episode 1787, reward total was -20.0. running mean: -20.189936655530584, timestamp: 2022-08-19 19:28:01.417047\n",
      "resetting env. episode 1788, reward total was -21.0. running mean: -20.19803728897528, timestamp: 2022-08-19 19:28:03.286067\n",
      "resetting env. episode 1789, reward total was -20.0. running mean: -20.196056916085524, timestamp: 2022-08-19 19:28:05.639099\n",
      "resetting env. episode 1790, reward total was -21.0. running mean: -20.20409634692467, timestamp: 2022-08-19 19:28:07.216112\n",
      "resetting env. episode 1791, reward total was -21.0. running mean: -20.21205538345542, timestamp: 2022-08-19 19:28:09.670140\n",
      "resetting env. episode 1792, reward total was -21.0. running mean: -20.21993482962087, timestamp: 2022-08-19 19:28:11.895164\n",
      "resetting env. episode 1793, reward total was -21.0. running mean: -20.22773548132466, timestamp: 2022-08-19 19:28:13.877186\n",
      "resetting env. episode 1794, reward total was -20.0. running mean: -20.225458126511413, timestamp: 2022-08-19 19:28:16.835220\n",
      "resetting env. episode 1795, reward total was -20.0. running mean: -20.223203545246296, timestamp: 2022-08-19 19:28:19.303252\n",
      "resetting env. episode 1796, reward total was -21.0. running mean: -20.230971509793832, timestamp: 2022-08-19 19:28:21.521798\n",
      "resetting env. episode 1797, reward total was -21.0. running mean: -20.238661794695894, timestamp: 2022-08-19 19:28:23.135821\n",
      "resetting env. episode 1798, reward total was -21.0. running mean: -20.246275176748934, timestamp: 2022-08-19 19:28:25.322845\n",
      "resetting env. episode 1799, reward total was -20.0. running mean: -20.243812424981446, timestamp: 2022-08-19 19:28:27.463866\n",
      "resetting env. episode 1800, reward total was -20.0. running mean: -20.241374300731632, timestamp: 2022-08-19 19:28:29.755892\n",
      "resetting env. episode 1801, reward total was -21.0. running mean: -20.248960557724317, timestamp: 2022-08-19 19:28:31.550913\n",
      "resetting env. episode 1802, reward total was -20.0. running mean: -20.246470952147074, timestamp: 2022-08-19 19:28:33.495941\n",
      "resetting env. episode 1803, reward total was -21.0. running mean: -20.254006242625604, timestamp: 2022-08-19 19:28:35.792971\n",
      "resetting env. episode 1804, reward total was -18.0. running mean: -20.231466180199348, timestamp: 2022-08-19 19:28:37.947986\n",
      "resetting env. episode 1805, reward total was -21.0. running mean: -20.239151518397357, timestamp: 2022-08-19 19:28:40.174014\n",
      "resetting env. episode 1806, reward total was -20.0. running mean: -20.236760003213384, timestamp: 2022-08-19 19:28:42.351036\n",
      "resetting env. episode 1807, reward total was -21.0. running mean: -20.24439240318125, timestamp: 2022-08-19 19:28:44.554061\n",
      "resetting env. episode 1808, reward total was -19.0. running mean: -20.23194847914944, timestamp: 2022-08-19 19:28:47.304094\n",
      "resetting env. episode 1809, reward total was -19.0. running mean: -20.219628994357947, timestamp: 2022-08-19 19:28:50.360128\n",
      "resetting env. episode 1810, reward total was -21.0. running mean: -20.22743270441437, timestamp: 2022-08-19 19:28:53.035157\n",
      "resetting env. episode 1811, reward total was -21.0. running mean: -20.235158377370226, timestamp: 2022-08-19 19:28:55.664188\n",
      "resetting env. episode 1812, reward total was -20.0. running mean: -20.232806793596524, timestamp: 2022-08-19 19:28:57.749214\n",
      "resetting env. episode 1813, reward total was -21.0. running mean: -20.24047872566056, timestamp: 2022-08-19 19:29:00.329242\n",
      "resetting env. episode 1814, reward total was -19.0. running mean: -20.228073938403956, timestamp: 2022-08-19 19:29:03.133273\n",
      "resetting env. episode 1815, reward total was -21.0. running mean: -20.235793199019916, timestamp: 2022-08-19 19:29:04.660292\n",
      "resetting env. episode 1816, reward total was -19.0. running mean: -20.223435267029718, timestamp: 2022-08-19 19:29:07.044317\n",
      "resetting env. episode 1817, reward total was -21.0. running mean: -20.23120091435942, timestamp: 2022-08-19 19:29:09.291345\n",
      "resetting env. episode 1818, reward total was -21.0. running mean: -20.238888905215827, timestamp: 2022-08-19 19:29:11.411370\n",
      "resetting env. episode 1819, reward total was -19.0. running mean: -20.22650001616367, timestamp: 2022-08-19 19:29:13.537392\n",
      "resetting env. episode 1820, reward total was -21.0. running mean: -20.23423501600203, timestamp: 2022-08-19 19:29:16.228422\n",
      "resetting env. episode 1821, reward total was -19.0. running mean: -20.221892665842013, timestamp: 2022-08-19 19:29:18.338447\n",
      "resetting env. episode 1822, reward total was -20.0. running mean: -20.21967373918359, timestamp: 2022-08-19 19:29:19.975468\n",
      "resetting env. episode 1823, reward total was -20.0. running mean: -20.217477001791753, timestamp: 2022-08-19 19:29:23.398506\n",
      "resetting env. episode 1824, reward total was -20.0. running mean: -20.215302231773833, timestamp: 2022-08-19 19:29:25.252529\n",
      "resetting env. episode 1825, reward total was -20.0. running mean: -20.213149209456095, timestamp: 2022-08-19 19:29:27.696558\n",
      "resetting env. episode 1826, reward total was -21.0. running mean: -20.221017717361534, timestamp: 2022-08-19 19:29:30.359584\n",
      "resetting env. episode 1827, reward total was -19.0. running mean: -20.20880754018792, timestamp: 2022-08-19 19:29:32.597610\n",
      "resetting env. episode 1828, reward total was -19.0. running mean: -20.196719464786042, timestamp: 2022-08-19 19:29:35.581647\n",
      "resetting env. episode 1829, reward total was -20.0. running mean: -20.19475227013818, timestamp: 2022-08-19 19:29:37.856671\n",
      "resetting env. episode 1830, reward total was -21.0. running mean: -20.2028047474368, timestamp: 2022-08-19 19:29:39.703689\n",
      "resetting env. episode 1831, reward total was -19.0. running mean: -20.190776699962434, timestamp: 2022-08-19 19:29:41.843718\n",
      "resetting env. episode 1832, reward total was -21.0. running mean: -20.19886893296281, timestamp: 2022-08-19 19:29:43.714738\n",
      "resetting env. episode 1833, reward total was -20.0. running mean: -20.19688024363318, timestamp: 2022-08-19 19:29:46.249766\n",
      "resetting env. episode 1834, reward total was -21.0. running mean: -20.20491144119685, timestamp: 2022-08-19 19:29:48.332797\n",
      "resetting env. episode 1835, reward total was -20.0. running mean: -20.202862326784878, timestamp: 2022-08-19 19:29:50.492816\n",
      "resetting env. episode 1836, reward total was -21.0. running mean: -20.21083370351703, timestamp: 2022-08-19 19:29:52.818842\n",
      "resetting env. episode 1837, reward total was -21.0. running mean: -20.21872536648186, timestamp: 2022-08-19 19:29:54.634863\n",
      "resetting env. episode 1838, reward total was -19.0. running mean: -20.206538112817043, timestamp: 2022-08-19 19:29:57.398891\n",
      "resetting env. episode 1839, reward total was -21.0. running mean: -20.214472731688872, timestamp: 2022-08-19 19:29:59.136912\n",
      "resetting env. episode 1840, reward total was -21.0. running mean: -20.222328004371985, timestamp: 2022-08-19 19:30:01.045932\n",
      "resetting env. episode 1841, reward total was -20.0. running mean: -20.220104724328262, timestamp: 2022-08-19 19:30:03.116961\n",
      "resetting env. episode 1842, reward total was -20.0. running mean: -20.21790367708498, timestamp: 2022-08-19 19:30:05.425984\n",
      "resetting env. episode 1843, reward total was -21.0. running mean: -20.22572464031413, timestamp: 2022-08-19 19:30:07.942014\n",
      "resetting env. episode 1844, reward total was -21.0. running mean: -20.23346739391099, timestamp: 2022-08-19 19:30:10.377038\n",
      "resetting env. episode 1845, reward total was -19.0. running mean: -20.22113271997188, timestamp: 2022-08-19 19:30:12.899070\n",
      "resetting env. episode 1846, reward total was -21.0. running mean: -20.22892139277216, timestamp: 2022-08-19 19:30:14.876096\n",
      "resetting env. episode 1847, reward total was -20.0. running mean: -20.22663217884444, timestamp: 2022-08-19 19:30:16.820115\n",
      "resetting env. episode 1848, reward total was -18.0. running mean: -20.204365857055997, timestamp: 2022-08-19 19:30:19.334141\n",
      "resetting env. episode 1849, reward total was -19.0. running mean: -20.19232219848544, timestamp: 2022-08-19 19:30:22.142173\n",
      "resetting env. episode 1850, reward total was -21.0. running mean: -20.200398976500583, timestamp: 2022-08-19 19:30:24.424198\n",
      "resetting env. episode 1851, reward total was -20.0. running mean: -20.198394986735575, timestamp: 2022-08-19 19:30:26.808274\n",
      "resetting env. episode 1852, reward total was -18.0. running mean: -20.17641103686822, timestamp: 2022-08-19 19:30:29.538306\n",
      "resetting env. episode 1853, reward total was -20.0. running mean: -20.174646926499538, timestamp: 2022-08-19 19:30:31.945336\n",
      "resetting env. episode 1854, reward total was -20.0. running mean: -20.17290045723454, timestamp: 2022-08-19 19:30:34.558364\n",
      "resetting env. episode 1855, reward total was -18.0. running mean: -20.151171452662194, timestamp: 2022-08-19 19:30:36.950391\n",
      "resetting env. episode 1856, reward total was -21.0. running mean: -20.159659738135574, timestamp: 2022-08-19 19:30:38.875420\n",
      "resetting env. episode 1857, reward total was -21.0. running mean: -20.168063140754217, timestamp: 2022-08-19 19:30:40.813436\n",
      "resetting env. episode 1858, reward total was -19.0. running mean: -20.156382509346678, timestamp: 2022-08-19 19:30:43.272471\n",
      "resetting env. episode 1859, reward total was -19.0. running mean: -20.144818684253213, timestamp: 2022-08-19 19:30:46.102495\n",
      "resetting env. episode 1860, reward total was -19.0. running mean: -20.13337049741068, timestamp: 2022-08-19 19:30:48.148515\n",
      "resetting env. episode 1861, reward total was -21.0. running mean: -20.142036792436574, timestamp: 2022-08-19 19:30:50.464542\n",
      "resetting env. episode 1862, reward total was -21.0. running mean: -20.150616424512208, timestamp: 2022-08-19 19:30:52.563566\n",
      "resetting env. episode 1863, reward total was -20.0. running mean: -20.149110260267086, timestamp: 2022-08-19 19:30:54.758591\n",
      "resetting env. episode 1864, reward total was -20.0. running mean: -20.147619157664415, timestamp: 2022-08-19 19:30:57.393621\n",
      "resetting env. episode 1865, reward total was -17.0. running mean: -20.11614296608777, timestamp: 2022-08-19 19:31:00.086652\n",
      "resetting env. episode 1866, reward total was -21.0. running mean: -20.124981536426894, timestamp: 2022-08-19 19:31:02.328679\n",
      "resetting env. episode 1867, reward total was -17.0. running mean: -20.09373172106263, timestamp: 2022-08-19 19:31:05.713716\n",
      "resetting env. episode 1868, reward total was -21.0. running mean: -20.102794403852002, timestamp: 2022-08-19 19:31:08.275746\n",
      "resetting env. episode 1869, reward total was -20.0. running mean: -20.10176645981348, timestamp: 2022-08-19 19:31:10.494768\n",
      "resetting env. episode 1870, reward total was -21.0. running mean: -20.110748795215343, timestamp: 2022-08-19 19:31:12.110785\n",
      "resetting env. episode 1871, reward total was -20.0. running mean: -20.10964130726319, timestamp: 2022-08-19 19:31:14.715821\n",
      "resetting env. episode 1872, reward total was -21.0. running mean: -20.118544894190556, timestamp: 2022-08-19 19:31:17.031842\n",
      "resetting env. episode 1873, reward total was -21.0. running mean: -20.12735944524865, timestamp: 2022-08-19 19:31:20.403883\n",
      "resetting env. episode 1874, reward total was -20.0. running mean: -20.126085850796162, timestamp: 2022-08-19 19:31:23.116913\n",
      "resetting env. episode 1875, reward total was -21.0. running mean: -20.134824992288202, timestamp: 2022-08-19 19:31:25.720942\n",
      "resetting env. episode 1876, reward total was -21.0. running mean: -20.14347674236532, timestamp: 2022-08-19 19:31:27.510975\n",
      "resetting env. episode 1877, reward total was -19.0. running mean: -20.132041974941668, timestamp: 2022-08-19 19:31:30.484997\n",
      "resetting env. episode 1878, reward total was -21.0. running mean: -20.14072155519225, timestamp: 2022-08-19 19:31:32.747024\n",
      "resetting env. episode 1879, reward total was -17.0. running mean: -20.109314339640328, timestamp: 2022-08-19 19:31:35.437052\n",
      "resetting env. episode 1880, reward total was -20.0. running mean: -20.108221196243925, timestamp: 2022-08-19 19:31:37.712075\n",
      "resetting env. episode 1881, reward total was -19.0. running mean: -20.097138984281486, timestamp: 2022-08-19 19:31:40.230104\n",
      "resetting env. episode 1882, reward total was -21.0. running mean: -20.10616759443867, timestamp: 2022-08-19 19:31:42.268127\n",
      "resetting env. episode 1883, reward total was -21.0. running mean: -20.115105918494283, timestamp: 2022-08-19 19:31:44.056157\n",
      "resetting env. episode 1884, reward total was -20.0. running mean: -20.113954859309338, timestamp: 2022-08-19 19:31:46.107172\n",
      "resetting env. episode 1885, reward total was -20.0. running mean: -20.112815310716243, timestamp: 2022-08-19 19:31:49.350208\n",
      "resetting env. episode 1886, reward total was -18.0. running mean: -20.09168715760908, timestamp: 2022-08-19 19:31:51.621236\n",
      "resetting env. episode 1887, reward total was -19.0. running mean: -20.08077028603299, timestamp: 2022-08-19 19:31:53.605258\n",
      "resetting env. episode 1888, reward total was -21.0. running mean: -20.08996258317266, timestamp: 2022-08-19 19:31:55.644279\n",
      "resetting env. episode 1889, reward total was -21.0. running mean: -20.099062957340934, timestamp: 2022-08-19 19:31:58.149309\n",
      "resetting env. episode 1890, reward total was -21.0. running mean: -20.108072327767523, timestamp: 2022-08-19 19:32:00.026328\n",
      "resetting env. episode 1891, reward total was -20.0. running mean: -20.106991604489846, timestamp: 2022-08-19 19:32:02.932363\n",
      "resetting env. episode 1892, reward total was -20.0. running mean: -20.105921688444948, timestamp: 2022-08-19 19:32:05.641391\n",
      "resetting env. episode 1893, reward total was -21.0. running mean: -20.1148624715605, timestamp: 2022-08-19 19:32:07.612414\n",
      "resetting env. episode 1894, reward total was -21.0. running mean: -20.123713846844897, timestamp: 2022-08-19 19:32:09.338434\n",
      "resetting env. episode 1895, reward total was -20.0. running mean: -20.122476708376446, timestamp: 2022-08-19 19:32:11.623462\n",
      "resetting env. episode 1896, reward total was -21.0. running mean: -20.131251941292682, timestamp: 2022-08-19 19:32:13.564482\n",
      "resetting env. episode 1897, reward total was -21.0. running mean: -20.139939421879756, timestamp: 2022-08-19 19:32:15.396503\n",
      "resetting env. episode 1898, reward total was -21.0. running mean: -20.14854002766096, timestamp: 2022-08-19 19:32:17.855533\n",
      "resetting env. episode 1899, reward total was -20.0. running mean: -20.14705462738435, timestamp: 2022-08-19 19:32:20.582564\n",
      "resetting env. episode 1900, reward total was -21.0. running mean: -20.155584081110508, timestamp: 2022-08-19 19:32:23.080590\n",
      "resetting env. episode 1901, reward total was -19.0. running mean: -20.144028240299402, timestamp: 2022-08-19 19:32:25.208617\n",
      "resetting env. episode 1902, reward total was -21.0. running mean: -20.152587957896408, timestamp: 2022-08-19 19:32:27.577642\n",
      "resetting env. episode 1903, reward total was -19.0. running mean: -20.141062078317447, timestamp: 2022-08-19 19:32:30.399674\n",
      "resetting env. episode 1904, reward total was -19.0. running mean: -20.129651457534273, timestamp: 2022-08-19 19:32:32.793702\n",
      "resetting env. episode 1905, reward total was -19.0. running mean: -20.11835494295893, timestamp: 2022-08-19 19:32:35.008726\n",
      "resetting env. episode 1906, reward total was -20.0. running mean: -20.11717139352934, timestamp: 2022-08-19 19:32:36.982752\n",
      "resetting env. episode 1907, reward total was -21.0. running mean: -20.125999679594045, timestamp: 2022-08-19 19:32:39.672791\n",
      "resetting env. episode 1908, reward total was -20.0. running mean: -20.124739682798104, timestamp: 2022-08-19 19:32:41.827807\n",
      "resetting env. episode 1909, reward total was -21.0. running mean: -20.133492285970124, timestamp: 2022-08-19 19:32:43.845830\n",
      "resetting env. episode 1910, reward total was -20.0. running mean: -20.132157363110423, timestamp: 2022-08-19 19:32:46.888863\n",
      "resetting env. episode 1911, reward total was -19.0. running mean: -20.12083578947932, timestamp: 2022-08-19 19:32:48.958888\n",
      "resetting env. episode 1912, reward total was -21.0. running mean: -20.129627431584527, timestamp: 2022-08-19 19:32:50.516904\n",
      "resetting env. episode 1913, reward total was -21.0. running mean: -20.138331157268684, timestamp: 2022-08-19 19:32:52.642928\n",
      "resetting env. episode 1914, reward total was -21.0. running mean: -20.146947845695998, timestamp: 2022-08-19 19:32:54.419949\n",
      "resetting env. episode 1915, reward total was -21.0. running mean: -20.155478367239038, timestamp: 2022-08-19 19:32:56.515976\n",
      "resetting env. episode 1916, reward total was -20.0. running mean: -20.153923583566648, timestamp: 2022-08-19 19:32:58.735001\n",
      "resetting env. episode 1917, reward total was -20.0. running mean: -20.15238434773098, timestamp: 2022-08-19 19:33:00.918552\n",
      "resetting env. episode 1918, reward total was -21.0. running mean: -20.16086050425367, timestamp: 2022-08-19 19:33:03.084578\n",
      "resetting env. episode 1919, reward total was -21.0. running mean: -20.169251899211133, timestamp: 2022-08-19 19:33:04.983600\n",
      "resetting env. episode 1920, reward total was -20.0. running mean: -20.16755938021902, timestamp: 2022-08-19 19:33:06.973622\n",
      "resetting env. episode 1921, reward total was -21.0. running mean: -20.175883786416833, timestamp: 2022-08-19 19:33:09.158646\n",
      "resetting env. episode 1922, reward total was -20.0. running mean: -20.174124948552663, timestamp: 2022-08-19 19:33:11.444676\n",
      "resetting env. episode 1923, reward total was -21.0. running mean: -20.182383699067138, timestamp: 2022-08-19 19:33:13.880699\n",
      "resetting env. episode 1924, reward total was -19.0. running mean: -20.170559862076466, timestamp: 2022-08-19 19:33:16.134728\n",
      "resetting env. episode 1925, reward total was -20.0. running mean: -20.1688542634557, timestamp: 2022-08-19 19:33:18.634759\n",
      "resetting env. episode 1926, reward total was -18.0. running mean: -20.147165720821143, timestamp: 2022-08-19 19:33:21.238786\n",
      "resetting env. episode 1927, reward total was -20.0. running mean: -20.14569406361293, timestamp: 2022-08-19 19:33:24.038819\n",
      "resetting env. episode 1928, reward total was -20.0. running mean: -20.144237122976797, timestamp: 2022-08-19 19:33:26.506851\n",
      "resetting env. episode 1929, reward total was -20.0. running mean: -20.14279475174703, timestamp: 2022-08-19 19:33:28.873874\n",
      "resetting env. episode 1930, reward total was -20.0. running mean: -20.14136680422956, timestamp: 2022-08-19 19:33:31.434905\n",
      "resetting env. episode 1931, reward total was -20.0. running mean: -20.139953136187263, timestamp: 2022-08-19 19:33:33.619452\n",
      "resetting env. episode 1932, reward total was -21.0. running mean: -20.14855360482539, timestamp: 2022-08-19 19:33:35.801478\n",
      "resetting env. episode 1933, reward total was -21.0. running mean: -20.15706806877714, timestamp: 2022-08-19 19:33:38.228508\n",
      "resetting env. episode 1934, reward total was -20.0. running mean: -20.155497388089366, timestamp: 2022-08-19 19:33:40.464534\n",
      "resetting env. episode 1935, reward total was -21.0. running mean: -20.163942414208474, timestamp: 2022-08-19 19:33:42.321553\n",
      "resetting env. episode 1936, reward total was -20.0. running mean: -20.16230299006639, timestamp: 2022-08-19 19:33:44.331576\n",
      "resetting env. episode 1937, reward total was -20.0. running mean: -20.160679960165726, timestamp: 2022-08-19 19:33:47.054610\n",
      "resetting env. episode 1938, reward total was -21.0. running mean: -20.16907316056407, timestamp: 2022-08-19 19:33:49.588638\n",
      "resetting env. episode 1939, reward total was -20.0. running mean: -20.16738242895843, timestamp: 2022-08-19 19:33:52.315672\n",
      "resetting env. episode 1940, reward total was -18.0. running mean: -20.145708604668844, timestamp: 2022-08-19 19:33:55.706709\n",
      "resetting env. episode 1941, reward total was -19.0. running mean: -20.134251518622158, timestamp: 2022-08-19 19:33:58.353740\n",
      "resetting env. episode 1942, reward total was -21.0. running mean: -20.142909003435935, timestamp: 2022-08-19 19:34:00.665767\n",
      "resetting env. episode 1943, reward total was -20.0. running mean: -20.141479913401575, timestamp: 2022-08-19 19:34:02.680790\n",
      "resetting env. episode 1944, reward total was -20.0. running mean: -20.140065114267557, timestamp: 2022-08-19 19:34:04.854815\n",
      "resetting env. episode 1945, reward total was -21.0. running mean: -20.14866446312488, timestamp: 2022-08-19 19:34:06.646837\n",
      "resetting env. episode 1946, reward total was -21.0. running mean: -20.157177818493633, timestamp: 2022-08-19 19:34:08.762859\n",
      "resetting env. episode 1947, reward total was -21.0. running mean: -20.165606040308695, timestamp: 2022-08-19 19:34:11.298893\n",
      "resetting env. episode 1948, reward total was -21.0. running mean: -20.173949979905608, timestamp: 2022-08-19 19:34:13.567919\n",
      "resetting env. episode 1949, reward total was -20.0. running mean: -20.17221048010655, timestamp: 2022-08-19 19:34:16.035943\n",
      "resetting env. episode 1950, reward total was -20.0. running mean: -20.170488375305485, timestamp: 2022-08-19 19:34:18.407973\n",
      "resetting env. episode 1951, reward total was -20.0. running mean: -20.16878349155243, timestamp: 2022-08-19 19:34:21.192006\n",
      "resetting env. episode 1952, reward total was -18.0. running mean: -20.147095656636903, timestamp: 2022-08-19 19:34:24.512043\n",
      "resetting env. episode 1953, reward total was -21.0. running mean: -20.155624700070536, timestamp: 2022-08-19 19:34:26.805070\n",
      "resetting env. episode 1954, reward total was -21.0. running mean: -20.16406845306983, timestamp: 2022-08-19 19:34:29.089097\n",
      "resetting env. episode 1955, reward total was -20.0. running mean: -20.162427768539132, timestamp: 2022-08-19 19:34:31.307123\n",
      "resetting env. episode 1956, reward total was -21.0. running mean: -20.170803490853743, timestamp: 2022-08-19 19:34:33.437147\n",
      "resetting env. episode 1957, reward total was -20.0. running mean: -20.169095455945204, timestamp: 2022-08-19 19:34:36.029180\n",
      "resetting env. episode 1958, reward total was -21.0. running mean: -20.17740450138575, timestamp: 2022-08-19 19:34:37.508195\n",
      "resetting env. episode 1959, reward total was -21.0. running mean: -20.185630456371896, timestamp: 2022-08-19 19:34:39.598223\n",
      "resetting env. episode 1960, reward total was -20.0. running mean: -20.183774151808176, timestamp: 2022-08-19 19:34:41.585243\n",
      "resetting env. episode 1961, reward total was -20.0. running mean: -20.181936410290092, timestamp: 2022-08-19 19:34:44.716280\n",
      "resetting env. episode 1962, reward total was -20.0. running mean: -20.180117046187192, timestamp: 2022-08-19 19:34:46.981305\n",
      "resetting env. episode 1963, reward total was -21.0. running mean: -20.18831587572532, timestamp: 2022-08-19 19:34:49.002332\n",
      "resetting env. episode 1964, reward total was -18.0. running mean: -20.166432716968064, timestamp: 2022-08-19 19:34:51.705370\n",
      "resetting env. episode 1965, reward total was -21.0. running mean: -20.174768389798384, timestamp: 2022-08-19 19:34:53.888389\n",
      "resetting env. episode 1966, reward total was -20.0. running mean: -20.1730207059004, timestamp: 2022-08-19 19:34:55.913416\n",
      "resetting env. episode 1967, reward total was -21.0. running mean: -20.181290498841395, timestamp: 2022-08-19 19:34:57.880438\n",
      "resetting env. episode 1968, reward total was -20.0. running mean: -20.17947759385298, timestamp: 2022-08-19 19:35:00.577471\n",
      "resetting env. episode 1969, reward total was -20.0. running mean: -20.177682817914448, timestamp: 2022-08-19 19:35:02.931492\n",
      "resetting env. episode 1970, reward total was -19.0. running mean: -20.165905989735304, timestamp: 2022-08-19 19:35:05.729525\n",
      "resetting env. episode 1971, reward total was -21.0. running mean: -20.174246929837953, timestamp: 2022-08-19 19:35:07.936553\n",
      "resetting env. episode 1972, reward total was -21.0. running mean: -20.182504460539572, timestamp: 2022-08-19 19:35:10.428581\n",
      "resetting env. episode 1973, reward total was -19.0. running mean: -20.170679415934178, timestamp: 2022-08-19 19:35:12.775610\n",
      "resetting env. episode 1974, reward total was -21.0. running mean: -20.178972621774836, timestamp: 2022-08-19 19:35:15.187638\n",
      "resetting env. episode 1975, reward total was -21.0. running mean: -20.18718289555709, timestamp: 2022-08-19 19:35:17.076660\n",
      "resetting env. episode 1976, reward total was -21.0. running mean: -20.19531106660152, timestamp: 2022-08-19 19:35:18.897687\n",
      "resetting env. episode 1977, reward total was -20.0. running mean: -20.193357955935504, timestamp: 2022-08-19 19:35:21.116709\n",
      "resetting env. episode 1978, reward total was -21.0. running mean: -20.20142437637615, timestamp: 2022-08-19 19:35:22.869730\n",
      "resetting env. episode 1979, reward total was -20.0. running mean: -20.199410132612385, timestamp: 2022-08-19 19:35:24.895753\n",
      "resetting env. episode 1980, reward total was -20.0. running mean: -20.19741603128626, timestamp: 2022-08-19 19:35:26.959774\n",
      "resetting env. episode 1981, reward total was -17.0. running mean: -20.1654418709734, timestamp: 2022-08-19 19:35:30.014812\n",
      "resetting env. episode 1982, reward total was -19.0. running mean: -20.153787452263668, timestamp: 2022-08-19 19:35:32.127358\n",
      "resetting env. episode 1983, reward total was -21.0. running mean: -20.162249577741033, timestamp: 2022-08-19 19:35:34.673385\n",
      "resetting env. episode 1984, reward total was -21.0. running mean: -20.170627081963623, timestamp: 2022-08-19 19:35:36.767417\n",
      "resetting env. episode 1985, reward total was -20.0. running mean: -20.168920811143987, timestamp: 2022-08-19 19:35:39.672444\n",
      "resetting env. episode 1986, reward total was -19.0. running mean: -20.15723160303255, timestamp: 2022-08-19 19:35:42.043473\n",
      "resetting env. episode 1987, reward total was -21.0. running mean: -20.165659287002224, timestamp: 2022-08-19 19:35:44.294502\n",
      "resetting env. episode 1988, reward total was -21.0. running mean: -20.174002694132202, timestamp: 2022-08-19 19:35:46.629526\n",
      "resetting env. episode 1989, reward total was -20.0. running mean: -20.17226266719088, timestamp: 2022-08-19 19:35:48.873551\n",
      "resetting env. episode 1990, reward total was -21.0. running mean: -20.18054004051897, timestamp: 2022-08-19 19:35:51.177578\n",
      "resetting env. episode 1991, reward total was -20.0. running mean: -20.17873464011378, timestamp: 2022-08-19 19:35:53.529607\n",
      "resetting env. episode 1992, reward total was -18.0. running mean: -20.156947293712644, timestamp: 2022-08-19 19:35:55.984635\n",
      "resetting env. episode 1993, reward total was -21.0. running mean: -20.165377820775518, timestamp: 2022-08-19 19:35:58.016661\n",
      "resetting env. episode 1994, reward total was -20.0. running mean: -20.16372404256776, timestamp: 2022-08-19 19:36:00.236684\n",
      "resetting env. episode 1995, reward total was -19.0. running mean: -20.152086802142083, timestamp: 2022-08-19 19:36:02.426713\n",
      "resetting env. episode 1996, reward total was -19.0. running mean: -20.140565934120662, timestamp: 2022-08-19 19:36:04.767737\n",
      "resetting env. episode 1997, reward total was -21.0. running mean: -20.149160274779454, timestamp: 2022-08-19 19:36:06.794762\n",
      "resetting env. episode 1998, reward total was -20.0. running mean: -20.14766867203166, timestamp: 2022-08-19 19:36:08.858785\n",
      "resetting env. episode 1999, reward total was -21.0. running mean: -20.156191985311345, timestamp: 2022-08-19 19:36:11.302815\n",
      "resetting env. episode 2000, reward total was -21.0. running mean: -20.164630065458233, timestamp: 2022-08-19 19:36:13.503840\n",
      "resetting env. episode 2001, reward total was -21.0. running mean: -20.17298376480365, timestamp: 2022-08-19 19:36:15.526864\n",
      "resetting env. episode 2002, reward total was -21.0. running mean: -20.181253927155613, timestamp: 2022-08-19 19:36:17.347887\n",
      "resetting env. episode 2003, reward total was -18.0. running mean: -20.159441387884055, timestamp: 2022-08-19 19:36:19.687911\n",
      "resetting env. episode 2004, reward total was -21.0. running mean: -20.167846974005215, timestamp: 2022-08-19 19:36:22.148941\n",
      "resetting env. episode 2005, reward total was -20.0. running mean: -20.166168504265162, timestamp: 2022-08-19 19:36:24.767972\n",
      "resetting env. episode 2006, reward total was -21.0. running mean: -20.17450681922251, timestamp: 2022-08-19 19:36:26.746997\n",
      "resetting env. episode 2007, reward total was -21.0. running mean: -20.182761751030288, timestamp: 2022-08-19 19:36:29.115027\n",
      "resetting env. episode 2008, reward total was -20.0. running mean: -20.180934133519983, timestamp: 2022-08-19 19:36:31.852056\n",
      "resetting env. episode 2009, reward total was -20.0. running mean: -20.179124792184783, timestamp: 2022-08-19 19:36:34.814094\n",
      "resetting env. episode 2010, reward total was -20.0. running mean: -20.177333544262936, timestamp: 2022-08-19 19:36:37.344119\n",
      "resetting env. episode 2011, reward total was -21.0. running mean: -20.185560208820306, timestamp: 2022-08-19 19:36:39.547149\n",
      "resetting env. episode 2012, reward total was -17.0. running mean: -20.153704606732106, timestamp: 2022-08-19 19:36:42.005175\n",
      "resetting env. episode 2013, reward total was -20.0. running mean: -20.152167560664783, timestamp: 2022-08-19 19:36:44.466206\n",
      "resetting env. episode 2014, reward total was -21.0. running mean: -20.160645885058134, timestamp: 2022-08-19 19:36:46.453229\n",
      "resetting env. episode 2015, reward total was -20.0. running mean: -20.159039426207553, timestamp: 2022-08-19 19:36:48.475254\n",
      "resetting env. episode 2016, reward total was -21.0. running mean: -20.167449031945477, timestamp: 2022-08-19 19:36:50.999281\n",
      "resetting env. episode 2017, reward total was -21.0. running mean: -20.175774541626023, timestamp: 2022-08-19 19:36:53.123309\n",
      "resetting env. episode 2018, reward total was -20.0. running mean: -20.174016796209763, timestamp: 2022-08-19 19:36:55.506335\n",
      "resetting env. episode 2019, reward total was -19.0. running mean: -20.162276628247668, timestamp: 2022-08-19 19:36:58.230366\n",
      "resetting env. episode 2020, reward total was -21.0. running mean: -20.170653861965192, timestamp: 2022-08-19 19:37:00.217389\n",
      "resetting env. episode 2021, reward total was -19.0. running mean: -20.15894732334554, timestamp: 2022-08-19 19:37:02.580417\n",
      "resetting env. episode 2022, reward total was -20.0. running mean: -20.157357850112085, timestamp: 2022-08-19 19:37:04.938447\n",
      "resetting env. episode 2023, reward total was -20.0. running mean: -20.155784271610962, timestamp: 2022-08-19 19:37:07.496478\n",
      "resetting env. episode 2024, reward total was -20.0. running mean: -20.15422642889485, timestamp: 2022-08-19 19:37:09.184496\n",
      "resetting env. episode 2025, reward total was -20.0. running mean: -20.1526841646059, timestamp: 2022-08-19 19:37:11.150524\n",
      "resetting env. episode 2026, reward total was -18.0. running mean: -20.13115732295984, timestamp: 2022-08-19 19:37:13.941554\n",
      "resetting env. episode 2027, reward total was -21.0. running mean: -20.13984574973024, timestamp: 2022-08-19 19:37:16.059579\n",
      "resetting env. episode 2028, reward total was -21.0. running mean: -20.14844729223294, timestamp: 2022-08-19 19:37:18.082604\n",
      "resetting env. episode 2029, reward total was -19.0. running mean: -20.13696281931061, timestamp: 2022-08-19 19:37:20.394630\n",
      "resetting env. episode 2030, reward total was -21.0. running mean: -20.145593191117506, timestamp: 2022-08-19 19:37:22.502655\n",
      "resetting env. episode 2031, reward total was -20.0. running mean: -20.144137259206328, timestamp: 2022-08-19 19:37:24.572678\n",
      "resetting env. episode 2032, reward total was -17.0. running mean: -20.112695886614265, timestamp: 2022-08-19 19:37:27.552714\n",
      "resetting env. episode 2033, reward total was -21.0. running mean: -20.121568927748122, timestamp: 2022-08-19 19:37:29.373738\n",
      "resetting env. episode 2034, reward total was -21.0. running mean: -20.13035323847064, timestamp: 2022-08-19 19:37:31.513759\n",
      "resetting env. episode 2035, reward total was -20.0. running mean: -20.129049706085933, timestamp: 2022-08-19 19:37:33.495784\n",
      "resetting env. episode 2036, reward total was -21.0. running mean: -20.137759209025074, timestamp: 2022-08-19 19:37:36.344817\n",
      "resetting env. episode 2037, reward total was -18.0. running mean: -20.116381616934824, timestamp: 2022-08-19 19:37:38.943847\n",
      "resetting env. episode 2038, reward total was -20.0. running mean: -20.115217800765475, timestamp: 2022-08-19 19:37:40.535867\n",
      "resetting env. episode 2039, reward total was -20.0. running mean: -20.11406562275782, timestamp: 2022-08-19 19:37:42.694893\n",
      "resetting env. episode 2040, reward total was -19.0. running mean: -20.102924966530242, timestamp: 2022-08-19 19:37:45.522924\n",
      "resetting env. episode 2041, reward total was -19.0. running mean: -20.09189571686494, timestamp: 2022-08-19 19:37:47.760952\n",
      "resetting env. episode 2042, reward total was -18.0. running mean: -20.07097675969629, timestamp: 2022-08-19 19:37:50.720510\n",
      "resetting env. episode 2043, reward total was -21.0. running mean: -20.08026699209933, timestamp: 2022-08-19 19:37:52.923536\n",
      "resetting env. episode 2044, reward total was -21.0. running mean: -20.089464322178337, timestamp: 2022-08-19 19:37:55.343565\n",
      "resetting env. episode 2045, reward total was -21.0. running mean: -20.098569678956554, timestamp: 2022-08-19 19:37:57.903594\n",
      "resetting env. episode 2046, reward total was -17.0. running mean: -20.06758398216699, timestamp: 2022-08-19 19:38:00.528624\n",
      "resetting env. episode 2047, reward total was -16.0. running mean: -20.02690814234532, timestamp: 2022-08-19 19:38:03.012654\n",
      "resetting env. episode 2048, reward total was -20.0. running mean: -20.026639060921866, timestamp: 2022-08-19 19:38:05.663685\n",
      "resetting env. episode 2049, reward total was -20.0. running mean: -20.026372670312647, timestamp: 2022-08-19 19:38:07.897711\n",
      "resetting env. episode 2050, reward total was -18.0. running mean: -20.00610894360952, timestamp: 2022-08-19 19:38:10.276739\n",
      "resetting env. episode 2051, reward total was -21.0. running mean: -20.016047854173426, timestamp: 2022-08-19 19:38:12.870771\n",
      "resetting env. episode 2052, reward total was -20.0. running mean: -20.015887375631692, timestamp: 2022-08-19 19:38:15.324801\n",
      "resetting env. episode 2053, reward total was -20.0. running mean: -20.015728501875376, timestamp: 2022-08-19 19:38:17.430823\n",
      "resetting env. episode 2054, reward total was -21.0. running mean: -20.025571216856623, timestamp: 2022-08-19 19:38:19.905853\n",
      "resetting env. episode 2055, reward total was -20.0. running mean: -20.025315504688056, timestamp: 2022-08-19 19:38:22.176879\n",
      "resetting env. episode 2056, reward total was -20.0. running mean: -20.025062349641175, timestamp: 2022-08-19 19:38:24.562906\n",
      "resetting env. episode 2057, reward total was -20.0. running mean: -20.024811726144762, timestamp: 2022-08-19 19:38:26.995937\n",
      "resetting env. episode 2058, reward total was -19.0. running mean: -20.014563608883314, timestamp: 2022-08-19 19:38:29.489968\n",
      "resetting env. episode 2059, reward total was -19.0. running mean: -20.00441797279448, timestamp: 2022-08-19 19:38:32.427002\n",
      "resetting env. episode 2060, reward total was -20.0. running mean: -20.004373793066534, timestamp: 2022-08-19 19:38:34.959029\n",
      "resetting env. episode 2061, reward total was -21.0. running mean: -20.01433005513587, timestamp: 2022-08-19 19:38:37.171059\n",
      "resetting env. episode 2062, reward total was -20.0. running mean: -20.014186754584507, timestamp: 2022-08-19 19:38:39.289084\n",
      "resetting env. episode 2063, reward total was -20.0. running mean: -20.01404488703866, timestamp: 2022-08-19 19:38:41.376108\n",
      "resetting env. episode 2064, reward total was -20.0. running mean: -20.013904438168275, timestamp: 2022-08-19 19:38:44.043139\n",
      "resetting env. episode 2065, reward total was -20.0. running mean: -20.013765393786592, timestamp: 2022-08-19 19:38:46.114161\n",
      "resetting env. episode 2066, reward total was -20.0. running mean: -20.013627739848726, timestamp: 2022-08-19 19:38:48.932195\n",
      "resetting env. episode 2067, reward total was -21.0. running mean: -20.023491462450238, timestamp: 2022-08-19 19:38:51.029220\n",
      "resetting env. episode 2068, reward total was -20.0. running mean: -20.023256547825735, timestamp: 2022-08-19 19:38:53.898778\n",
      "resetting env. episode 2069, reward total was -20.0. running mean: -20.02302398234748, timestamp: 2022-08-19 19:38:57.261815\n",
      "resetting env. episode 2070, reward total was -20.0. running mean: -20.022793742524, timestamp: 2022-08-19 19:38:59.173838\n",
      "resetting env. episode 2071, reward total was -19.0. running mean: -20.012565805098763, timestamp: 2022-08-19 19:39:01.937871\n",
      "resetting env. episode 2072, reward total was -21.0. running mean: -20.022440147047774, timestamp: 2022-08-19 19:39:04.126897\n",
      "resetting env. episode 2073, reward total was -21.0. running mean: -20.032215745577297, timestamp: 2022-08-19 19:39:06.528926\n",
      "resetting env. episode 2074, reward total was -20.0. running mean: -20.031893588121523, timestamp: 2022-08-19 19:39:09.667962\n",
      "resetting env. episode 2075, reward total was -21.0. running mean: -20.041574652240307, timestamp: 2022-08-19 19:39:11.632985\n",
      "resetting env. episode 2076, reward total was -21.0. running mean: -20.051158905717905, timestamp: 2022-08-19 19:39:14.144544\n",
      "resetting env. episode 2077, reward total was -20.0. running mean: -20.050647316660726, timestamp: 2022-08-19 19:39:16.400570\n",
      "resetting env. episode 2078, reward total was -19.0. running mean: -20.040140843494118, timestamp: 2022-08-19 19:39:18.702597\n",
      "resetting env. episode 2079, reward total was -19.0. running mean: -20.029739435059177, timestamp: 2022-08-19 19:39:21.356627\n",
      "resetting env. episode 2080, reward total was -21.0. running mean: -20.039442040708586, timestamp: 2022-08-19 19:39:23.234649\n",
      "resetting env. episode 2081, reward total was -20.0. running mean: -20.0390476203015, timestamp: 2022-08-19 19:39:25.235673\n",
      "resetting env. episode 2082, reward total was -19.0. running mean: -20.028657144098485, timestamp: 2022-08-19 19:39:28.057704\n",
      "resetting env. episode 2083, reward total was -20.0. running mean: -20.0283705726575, timestamp: 2022-08-19 19:39:30.386730\n",
      "resetting env. episode 2084, reward total was -19.0. running mean: -20.018086866930926, timestamp: 2022-08-19 19:39:32.951764\n",
      "resetting env. episode 2085, reward total was -21.0. running mean: -20.027905998261616, timestamp: 2022-08-19 19:39:34.861787\n",
      "resetting env. episode 2086, reward total was -20.0. running mean: -20.027626938279, timestamp: 2022-08-19 19:39:37.230811\n",
      "resetting env. episode 2087, reward total was -20.0. running mean: -20.027350668896208, timestamp: 2022-08-19 19:39:39.898842\n",
      "resetting env. episode 2088, reward total was -20.0. running mean: -20.027077162207245, timestamp: 2022-08-19 19:39:41.985866\n",
      "resetting env. episode 2089, reward total was -21.0. running mean: -20.036806390585173, timestamp: 2022-08-19 19:39:44.127895\n",
      "resetting env. episode 2090, reward total was -20.0. running mean: -20.03643832667932, timestamp: 2022-08-19 19:39:46.125914\n",
      "resetting env. episode 2091, reward total was -21.0. running mean: -20.046073943412527, timestamp: 2022-08-19 19:39:48.231938\n",
      "resetting env. episode 2092, reward total was -20.0. running mean: -20.0456132039784, timestamp: 2022-08-19 19:39:50.244966\n",
      "resetting env. episode 2093, reward total was -20.0. running mean: -20.04515707193862, timestamp: 2022-08-19 19:39:52.899996\n",
      "resetting env. episode 2094, reward total was -21.0. running mean: -20.05470550121923, timestamp: 2022-08-19 19:39:54.732018\n",
      "resetting env. episode 2095, reward total was -18.0. running mean: -20.034158446207037, timestamp: 2022-08-19 19:39:57.252047\n",
      "resetting env. episode 2096, reward total was -19.0. running mean: -20.02381686174497, timestamp: 2022-08-19 19:39:59.826079\n",
      "resetting env. episode 2097, reward total was -21.0. running mean: -20.03357869312752, timestamp: 2022-08-19 19:40:01.863104\n",
      "resetting env. episode 2098, reward total was -21.0. running mean: -20.043242906196244, timestamp: 2022-08-19 19:40:03.665122\n",
      "resetting env. episode 2099, reward total was -20.0. running mean: -20.04281047713428, timestamp: 2022-08-19 19:40:06.813157\n",
      "resetting env. episode 2100, reward total was -20.0. running mean: -20.042382372362937, timestamp: 2022-08-19 19:40:09.175184\n",
      "resetting env. episode 2101, reward total was -21.0. running mean: -20.05195854863931, timestamp: 2022-08-19 19:40:11.678216\n",
      "resetting env. episode 2102, reward total was -19.0. running mean: -20.041438963152917, timestamp: 2022-08-19 19:40:14.545248\n",
      "resetting env. episode 2103, reward total was -21.0. running mean: -20.05102457352139, timestamp: 2022-08-19 19:40:16.642275\n",
      "resetting env. episode 2104, reward total was -20.0. running mean: -20.050514327786175, timestamp: 2022-08-19 19:40:19.089300\n",
      "resetting env. episode 2105, reward total was -19.0. running mean: -20.040009184508314, timestamp: 2022-08-19 19:40:21.764332\n",
      "resetting env. episode 2106, reward total was -19.0. running mean: -20.029609092663232, timestamp: 2022-08-19 19:40:24.528365\n",
      "resetting env. episode 2107, reward total was -20.0. running mean: -20.0293130017366, timestamp: 2022-08-19 19:40:26.700391\n",
      "resetting env. episode 2108, reward total was -20.0. running mean: -20.029019871719232, timestamp: 2022-08-19 19:40:28.936415\n",
      "resetting env. episode 2109, reward total was -20.0. running mean: -20.02872967300204, timestamp: 2022-08-19 19:40:30.971442\n",
      "resetting env. episode 2110, reward total was -20.0. running mean: -20.028442376272018, timestamp: 2022-08-19 19:40:33.803473\n",
      "resetting env. episode 2111, reward total was -21.0. running mean: -20.038157952509298, timestamp: 2022-08-19 19:40:35.791497\n",
      "resetting env. episode 2112, reward total was -19.0. running mean: -20.027776372984206, timestamp: 2022-08-19 19:40:38.052522\n",
      "resetting env. episode 2113, reward total was -19.0. running mean: -20.017498609254364, timestamp: 2022-08-19 19:40:40.829556\n",
      "resetting env. episode 2114, reward total was -21.0. running mean: -20.02732362316182, timestamp: 2022-08-19 19:40:43.561589\n",
      "resetting env. episode 2115, reward total was -20.0. running mean: -20.027050386930203, timestamp: 2022-08-19 19:40:46.017615\n",
      "resetting env. episode 2116, reward total was -21.0. running mean: -20.036779883060902, timestamp: 2022-08-19 19:40:48.109645\n",
      "resetting env. episode 2117, reward total was -20.0. running mean: -20.036412084230292, timestamp: 2022-08-19 19:40:50.809671\n",
      "resetting env. episode 2118, reward total was -21.0. running mean: -20.04604796338799, timestamp: 2022-08-19 19:40:53.022697\n",
      "resetting env. episode 2119, reward total was -20.0. running mean: -20.04558748375411, timestamp: 2022-08-19 19:40:55.136721\n",
      "resetting env. episode 2120, reward total was -21.0. running mean: -20.05513160891657, timestamp: 2022-08-19 19:40:57.610750\n",
      "resetting env. episode 2121, reward total was -19.0. running mean: -20.04458029282741, timestamp: 2022-08-19 19:40:59.603776\n",
      "resetting env. episode 2122, reward total was -20.0. running mean: -20.044134489899132, timestamp: 2022-08-19 19:41:01.632800\n",
      "resetting env. episode 2123, reward total was -19.0. running mean: -20.033693145000143, timestamp: 2022-08-19 19:41:04.165829\n",
      "resetting env. episode 2124, reward total was -21.0. running mean: -20.043356213550144, timestamp: 2022-08-19 19:41:06.583857\n",
      "resetting env. episode 2125, reward total was -18.0. running mean: -20.022922651414643, timestamp: 2022-08-19 19:41:09.242888\n",
      "resetting env. episode 2126, reward total was -19.0. running mean: -20.012693424900498, timestamp: 2022-08-19 19:41:12.807930\n",
      "resetting env. episode 2127, reward total was -21.0. running mean: -20.022566490651492, timestamp: 2022-08-19 19:41:15.072958\n",
      "resetting env. episode 2128, reward total was -20.0. running mean: -20.022340825744976, timestamp: 2022-08-19 19:41:18.680000\n",
      "resetting env. episode 2129, reward total was -20.0. running mean: -20.022117417487525, timestamp: 2022-08-19 19:41:21.541034\n",
      "resetting env. episode 2130, reward total was -21.0. running mean: -20.03189624331265, timestamp: 2022-08-19 19:41:23.321642\n",
      "resetting env. episode 2131, reward total was -20.0. running mean: -20.031577280879524, timestamp: 2022-08-19 19:41:25.950912\n",
      "resetting env. episode 2132, reward total was -21.0. running mean: -20.04126150807073, timestamp: 2022-08-19 19:41:27.937265\n",
      "resetting env. episode 2133, reward total was -20.0. running mean: -20.04084889299002, timestamp: 2022-08-19 19:41:30.208131\n",
      "resetting env. episode 2134, reward total was -19.0. running mean: -20.030440404060123, timestamp: 2022-08-19 19:41:35.784591\n",
      "resetting env. episode 2135, reward total was -21.0. running mean: -20.040136000019523, timestamp: 2022-08-19 19:41:39.259632\n",
      "resetting env. episode 2136, reward total was -19.0. running mean: -20.029734640019328, timestamp: 2022-08-19 19:41:41.874663\n",
      "resetting env. episode 2137, reward total was -21.0. running mean: -20.039437293619134, timestamp: 2022-08-19 19:41:43.745684\n",
      "resetting env. episode 2138, reward total was -20.0. running mean: -20.03904292068294, timestamp: 2022-08-19 19:41:45.813706\n",
      "resetting env. episode 2139, reward total was -20.0. running mean: -20.03865249147611, timestamp: 2022-08-19 19:41:47.894732\n",
      "resetting env. episode 2140, reward total was -21.0. running mean: -20.04826596656135, timestamp: 2022-08-19 19:41:49.947756\n",
      "resetting env. episode 2141, reward total was -20.0. running mean: -20.047783306895735, timestamp: 2022-08-19 19:41:52.109782\n",
      "resetting env. episode 2142, reward total was -19.0. running mean: -20.037305473826777, timestamp: 2022-08-19 19:41:54.694811\n",
      "resetting env. episode 2143, reward total was -20.0. running mean: -20.036932419088508, timestamp: 2022-08-19 19:41:56.513831\n",
      "resetting env. episode 2144, reward total was -21.0. running mean: -20.046563094897625, timestamp: 2022-08-19 19:41:58.921860\n",
      "resetting env. episode 2145, reward total was -20.0. running mean: -20.046097463948648, timestamp: 2022-08-19 19:42:01.110884\n",
      "resetting env. episode 2146, reward total was -19.0. running mean: -20.035636489309162, timestamp: 2022-08-19 19:42:03.432914\n",
      "resetting env. episode 2147, reward total was -21.0. running mean: -20.04528012441607, timestamp: 2022-08-19 19:42:05.140935\n",
      "resetting env. episode 2148, reward total was -19.0. running mean: -20.03482732317191, timestamp: 2022-08-19 19:42:07.564965\n",
      "resetting env. episode 2149, reward total was -18.0. running mean: -20.014479049940192, timestamp: 2022-08-19 19:42:10.330994\n",
      "resetting env. episode 2150, reward total was -20.0. running mean: -20.01433425944079, timestamp: 2022-08-19 19:42:12.374016\n",
      "resetting env. episode 2151, reward total was -17.0. running mean: -19.984190916846384, timestamp: 2022-08-19 19:42:15.534057\n",
      "resetting env. episode 2152, reward total was -21.0. running mean: -19.994349007677922, timestamp: 2022-08-19 19:42:17.387073\n",
      "resetting env. episode 2153, reward total was -18.0. running mean: -19.97440551760114, timestamp: 2022-08-19 19:42:20.879116\n",
      "resetting env. episode 2154, reward total was -19.0. running mean: -19.96466146242513, timestamp: 2022-08-19 19:42:23.172141\n",
      "resetting env. episode 2155, reward total was -21.0. running mean: -19.97501484780088, timestamp: 2022-08-19 19:42:25.596172\n",
      "resetting env. episode 2156, reward total was -21.0. running mean: -19.985264699322872, timestamp: 2022-08-19 19:42:28.058199\n",
      "resetting env. episode 2157, reward total was -20.0. running mean: -19.985412052329643, timestamp: 2022-08-19 19:42:30.266226\n",
      "resetting env. episode 2158, reward total was -21.0. running mean: -19.995557931806346, timestamp: 2022-08-19 19:42:32.634255\n",
      "resetting env. episode 2159, reward total was -21.0. running mean: -20.005602352488282, timestamp: 2022-08-19 19:42:34.962277\n",
      "resetting env. episode 2160, reward total was -18.0. running mean: -19.985546328963398, timestamp: 2022-08-19 19:42:37.666308\n",
      "resetting env. episode 2161, reward total was -21.0. running mean: -19.995690865673765, timestamp: 2022-08-19 19:42:39.870334\n",
      "resetting env. episode 2162, reward total was -19.0. running mean: -19.98573395701703, timestamp: 2022-08-19 19:42:42.897369\n",
      "resetting env. episode 2163, reward total was -21.0. running mean: -19.99587661744686, timestamp: 2022-08-19 19:42:45.023394\n",
      "resetting env. episode 2164, reward total was -20.0. running mean: -19.99591785127239, timestamp: 2022-08-19 19:42:47.757427\n",
      "resetting env. episode 2165, reward total was -21.0. running mean: -20.005958672759668, timestamp: 2022-08-19 19:42:49.677448\n",
      "resetting env. episode 2166, reward total was -20.0. running mean: -20.00589908603207, timestamp: 2022-08-19 19:42:52.268479\n",
      "resetting env. episode 2167, reward total was -20.0. running mean: -20.00584009517175, timestamp: 2022-08-19 19:42:54.388504\n",
      "resetting env. episode 2168, reward total was -21.0. running mean: -20.01578169422003, timestamp: 2022-08-19 19:42:57.080534\n",
      "resetting env. episode 2169, reward total was -18.0. running mean: -19.99562387727783, timestamp: 2022-08-19 19:42:59.750566\n",
      "resetting env. episode 2170, reward total was -20.0. running mean: -19.99566763850505, timestamp: 2022-08-19 19:43:02.211121\n",
      "resetting env. episode 2171, reward total was -20.0. running mean: -19.99571096212, timestamp: 2022-08-19 19:43:04.902153\n",
      "resetting env. episode 2172, reward total was -19.0. running mean: -19.985753852498803, timestamp: 2022-08-19 19:43:07.631184\n",
      "resetting env. episode 2173, reward total was -21.0. running mean: -19.995896313973816, timestamp: 2022-08-19 19:43:09.666210\n",
      "resetting env. episode 2174, reward total was -21.0. running mean: -20.005937350834078, timestamp: 2022-08-19 19:43:11.534230\n",
      "resetting env. episode 2175, reward total was -20.0. running mean: -20.005877977325735, timestamp: 2022-08-19 19:43:13.825255\n",
      "resetting env. episode 2176, reward total was -21.0. running mean: -20.015819197552478, timestamp: 2022-08-19 19:43:15.965285\n",
      "resetting env. episode 2177, reward total was -20.0. running mean: -20.015661005576952, timestamp: 2022-08-19 19:43:17.653300\n",
      "resetting env. episode 2178, reward total was -19.0. running mean: -20.005504395521182, timestamp: 2022-08-19 19:43:20.302331\n",
      "resetting env. episode 2179, reward total was -21.0. running mean: -20.01544935156597, timestamp: 2022-08-19 19:43:22.500357\n",
      "resetting env. episode 2180, reward total was -21.0. running mean: -20.02529485805031, timestamp: 2022-08-19 19:43:24.648382\n",
      "resetting env. episode 2181, reward total was -18.0. running mean: -20.005041909469806, timestamp: 2022-08-19 19:43:27.021409\n",
      "resetting env. episode 2182, reward total was -20.0. running mean: -20.004991490375108, timestamp: 2022-08-19 19:43:29.007436\n",
      "resetting env. episode 2183, reward total was -19.0. running mean: -19.99494157547136, timestamp: 2022-08-19 19:43:31.410463\n",
      "resetting env. episode 2184, reward total was -21.0. running mean: -20.004992159716647, timestamp: 2022-08-19 19:43:33.436487\n",
      "resetting env. episode 2185, reward total was -21.0. running mean: -20.01494223811948, timestamp: 2022-08-19 19:43:35.835519\n",
      "resetting env. episode 2186, reward total was -21.0. running mean: -20.024792815738287, timestamp: 2022-08-19 19:43:38.347540\n",
      "resetting env. episode 2187, reward total was -20.0. running mean: -20.024544887580902, timestamp: 2022-08-19 19:43:40.641567\n",
      "resetting env. episode 2188, reward total was -21.0. running mean: -20.034299438705094, timestamp: 2022-08-19 19:43:43.481602\n",
      "resetting env. episode 2189, reward total was -20.0. running mean: -20.033956444318044, timestamp: 2022-08-19 19:43:45.765626\n",
      "resetting env. episode 2190, reward total was -19.0. running mean: -20.023616879874865, timestamp: 2022-08-19 19:43:48.261657\n",
      "resetting env. episode 2191, reward total was -20.0. running mean: -20.023380711076115, timestamp: 2022-08-19 19:43:50.639687\n",
      "resetting env. episode 2192, reward total was -21.0. running mean: -20.033146903965353, timestamp: 2022-08-19 19:43:53.581719\n",
      "resetting env. episode 2193, reward total was -21.0. running mean: -20.0428154349257, timestamp: 2022-08-19 19:43:55.849748\n",
      "resetting env. episode 2194, reward total was -21.0. running mean: -20.052387280576443, timestamp: 2022-08-19 19:43:57.968769\n",
      "resetting env. episode 2195, reward total was -21.0. running mean: -20.06186340777068, timestamp: 2022-08-19 19:44:00.876803\n",
      "resetting env. episode 2196, reward total was -21.0. running mean: -20.071244773692975, timestamp: 2022-08-19 19:44:03.279832\n",
      "resetting env. episode 2197, reward total was -18.0. running mean: -20.050532325956045, timestamp: 2022-08-19 19:44:06.735918\n",
      "resetting env. episode 2198, reward total was -21.0. running mean: -20.060027002696486, timestamp: 2022-08-19 19:44:08.947943\n",
      "resetting env. episode 2199, reward total was -17.0. running mean: -20.029426732669524, timestamp: 2022-08-19 19:44:12.361984\n",
      "resetting env. episode 2200, reward total was -21.0. running mean: -20.039132465342828, timestamp: 2022-08-19 19:44:14.580008\n",
      "resetting env. episode 2201, reward total was -21.0. running mean: -20.0487411406894, timestamp: 2022-08-19 19:44:17.214039\n",
      "resetting env. episode 2202, reward total was -21.0. running mean: -20.05825372928251, timestamp: 2022-08-19 19:44:19.660066\n",
      "resetting env. episode 2203, reward total was -20.0. running mean: -20.057671191989684, timestamp: 2022-08-19 19:44:22.147097\n",
      "resetting env. episode 2204, reward total was -20.0. running mean: -20.057094480069786, timestamp: 2022-08-19 19:44:24.404129\n",
      "resetting env. episode 2205, reward total was -20.0. running mean: -20.056523535269086, timestamp: 2022-08-19 19:44:27.732160\n",
      "resetting env. episode 2206, reward total was -20.0. running mean: -20.055958299916394, timestamp: 2022-08-19 19:44:29.721183\n",
      "resetting env. episode 2207, reward total was -18.0. running mean: -20.03539871691723, timestamp: 2022-08-19 19:44:32.286212\n",
      "resetting env. episode 2208, reward total was -20.0. running mean: -20.035044729748055, timestamp: 2022-08-19 19:44:34.368235\n",
      "resetting env. episode 2209, reward total was -21.0. running mean: -20.044694282450575, timestamp: 2022-08-19 19:44:37.105267\n",
      "resetting env. episode 2210, reward total was -19.0. running mean: -20.03424733962607, timestamp: 2022-08-19 19:44:39.470293\n",
      "resetting env. episode 2211, reward total was -20.0. running mean: -20.033904866229808, timestamp: 2022-08-19 19:44:41.627322\n",
      "resetting env. episode 2212, reward total was -19.0. running mean: -20.023565817567512, timestamp: 2022-08-19 19:44:43.389339\n",
      "resetting env. episode 2213, reward total was -20.0. running mean: -20.023330159391836, timestamp: 2022-08-19 19:44:45.768368\n",
      "resetting env. episode 2214, reward total was -19.0. running mean: -20.01309685779792, timestamp: 2022-08-19 19:44:49.066407\n",
      "resetting env. episode 2215, reward total was -21.0. running mean: -20.02296588921994, timestamp: 2022-08-19 19:44:50.993431\n",
      "resetting env. episode 2216, reward total was -21.0. running mean: -20.032736230327743, timestamp: 2022-08-19 19:44:53.926461\n",
      "resetting env. episode 2217, reward total was -20.0. running mean: -20.032408868024465, timestamp: 2022-08-19 19:44:56.000490\n",
      "resetting env. episode 2218, reward total was -21.0. running mean: -20.042084779344222, timestamp: 2022-08-19 19:44:57.677504\n",
      "resetting env. episode 2219, reward total was -20.0. running mean: -20.04166393155078, timestamp: 2022-08-19 19:45:00.480537\n",
      "resetting env. episode 2220, reward total was -20.0. running mean: -20.04124729223527, timestamp: 2022-08-19 19:45:02.954564\n",
      "resetting env. episode 2221, reward total was -21.0. running mean: -20.050834819312918, timestamp: 2022-08-19 19:45:05.239591\n",
      "resetting env. episode 2222, reward total was -20.0. running mean: -20.05032647111979, timestamp: 2022-08-19 19:45:07.248622\n",
      "resetting env. episode 2223, reward total was -20.0. running mean: -20.04982320640859, timestamp: 2022-08-19 19:45:09.178638\n",
      "resetting env. episode 2224, reward total was -21.0. running mean: -20.059324974344506, timestamp: 2022-08-19 19:45:11.677667\n",
      "resetting env. episode 2225, reward total was -20.0. running mean: -20.05873172460106, timestamp: 2022-08-19 19:45:14.227696\n",
      "resetting env. episode 2226, reward total was -21.0. running mean: -20.06814440735505, timestamp: 2022-08-19 19:45:16.284719\n",
      "resetting env. episode 2227, reward total was -17.0. running mean: -20.037462963281502, timestamp: 2022-08-19 19:45:18.932748\n",
      "resetting env. episode 2228, reward total was -17.0. running mean: -20.00708833364869, timestamp: 2022-08-19 19:45:21.827783\n",
      "resetting env. episode 2229, reward total was -21.0. running mean: -20.017017450312203, timestamp: 2022-08-19 19:45:24.095810\n",
      "resetting env. episode 2230, reward total was -21.0. running mean: -20.026847275809082, timestamp: 2022-08-19 19:45:26.524835\n",
      "resetting env. episode 2231, reward total was -21.0. running mean: -20.036578803050993, timestamp: 2022-08-19 19:45:28.717863\n",
      "resetting env. episode 2232, reward total was -20.0. running mean: -20.036213015020483, timestamp: 2022-08-19 19:45:31.056891\n",
      "resetting env. episode 2233, reward total was -20.0. running mean: -20.03585088487028, timestamp: 2022-08-19 19:45:33.653918\n",
      "resetting env. episode 2234, reward total was -21.0. running mean: -20.045492376021578, timestamp: 2022-08-19 19:45:35.942947\n",
      "resetting env. episode 2235, reward total was -21.0. running mean: -20.055037452261363, timestamp: 2022-08-19 19:45:38.154021\n",
      "resetting env. episode 2236, reward total was -21.0. running mean: -20.06448707773875, timestamp: 2022-08-19 19:45:40.675052\n",
      "resetting env. episode 2237, reward total was -19.0. running mean: -20.053842206961363, timestamp: 2022-08-19 19:45:43.204084\n",
      "resetting env. episode 2238, reward total was -20.0. running mean: -20.05330378489175, timestamp: 2022-08-19 19:45:45.597107\n",
      "resetting env. episode 2239, reward total was -20.0. running mean: -20.052770747042832, timestamp: 2022-08-19 19:45:48.004136\n",
      "resetting env. episode 2240, reward total was -21.0. running mean: -20.062243039572405, timestamp: 2022-08-19 19:45:50.841166\n",
      "resetting env. episode 2241, reward total was -19.0. running mean: -20.05162060917668, timestamp: 2022-08-19 19:45:53.277198\n",
      "resetting env. episode 2242, reward total was -21.0. running mean: -20.061104403084915, timestamp: 2022-08-19 19:45:55.509224\n",
      "resetting env. episode 2243, reward total was -21.0. running mean: -20.070493359054066, timestamp: 2022-08-19 19:45:58.691257\n",
      "resetting env. episode 2244, reward total was -19.0. running mean: -20.059788425463527, timestamp: 2022-08-19 19:46:01.135285\n",
      "resetting env. episode 2245, reward total was -21.0. running mean: -20.069190541208894, timestamp: 2022-08-19 19:46:03.433316\n",
      "resetting env. episode 2246, reward total was -19.0. running mean: -20.058498635796806, timestamp: 2022-08-19 19:46:06.285343\n",
      "resetting env. episode 2247, reward total was -20.0. running mean: -20.057913649438838, timestamp: 2022-08-19 19:46:08.720371\n",
      "resetting env. episode 2248, reward total was -20.0. running mean: -20.057334512944447, timestamp: 2022-08-19 19:46:10.892395\n",
      "resetting env. episode 2249, reward total was -21.0. running mean: -20.066761167815002, timestamp: 2022-08-19 19:46:13.194421\n",
      "resetting env. episode 2250, reward total was -21.0. running mean: -20.076093556136854, timestamp: 2022-08-19 19:46:15.276444\n",
      "resetting env. episode 2251, reward total was -19.0. running mean: -20.065332620575486, timestamp: 2022-08-19 19:46:17.556473\n",
      "resetting env. episode 2252, reward total was -21.0. running mean: -20.07467929436973, timestamp: 2022-08-19 19:46:19.987502\n",
      "resetting env. episode 2253, reward total was -19.0. running mean: -20.063932501426034, timestamp: 2022-08-19 19:46:22.712533\n",
      "resetting env. episode 2254, reward total was -20.0. running mean: -20.063293176411772, timestamp: 2022-08-19 19:46:24.998560\n",
      "resetting env. episode 2255, reward total was -20.0. running mean: -20.062660244647653, timestamp: 2022-08-19 19:46:27.183584\n",
      "resetting env. episode 2256, reward total was -21.0. running mean: -20.072033642201177, timestamp: 2022-08-19 19:46:29.029602\n",
      "resetting env. episode 2257, reward total was -21.0. running mean: -20.081313305779165, timestamp: 2022-08-19 19:46:31.144626\n",
      "resetting env. episode 2258, reward total was -20.0. running mean: -20.080500172721372, timestamp: 2022-08-19 19:46:33.389653\n",
      "resetting env. episode 2259, reward total was -19.0. running mean: -20.06969517099416, timestamp: 2022-08-19 19:46:36.168689\n",
      "resetting env. episode 2260, reward total was -19.0. running mean: -20.058998219284216, timestamp: 2022-08-19 19:46:39.082719\n",
      "resetting env. episode 2261, reward total was -19.0. running mean: -20.048408237091376, timestamp: 2022-08-19 19:46:41.762751\n",
      "resetting env. episode 2262, reward total was -17.0. running mean: -20.017924154720465, timestamp: 2022-08-19 19:46:44.538781\n",
      "resetting env. episode 2263, reward total was -19.0. running mean: -20.007744913173262, timestamp: 2022-08-19 19:46:46.925809\n",
      "resetting env. episode 2264, reward total was -21.0. running mean: -20.01766746404153, timestamp: 2022-08-19 19:46:49.663839\n",
      "resetting env. episode 2265, reward total was -21.0. running mean: -20.027490789401114, timestamp: 2022-08-19 19:46:51.876868\n",
      "resetting env. episode 2266, reward total was -20.0. running mean: -20.0272158815071, timestamp: 2022-08-19 19:46:54.165890\n",
      "resetting env. episode 2267, reward total was -20.0. running mean: -20.026943722692028, timestamp: 2022-08-19 19:46:56.713919\n",
      "resetting env. episode 2268, reward total was -20.0. running mean: -20.026674285465106, timestamp: 2022-08-19 19:46:58.404938\n",
      "resetting env. episode 2269, reward total was -20.0. running mean: -20.026407542610453, timestamp: 2022-08-19 19:47:01.335973\n",
      "resetting env. episode 2270, reward total was -21.0. running mean: -20.03614346718435, timestamp: 2022-08-19 19:47:04.021001\n",
      "resetting env. episode 2271, reward total was -21.0. running mean: -20.045782032512506, timestamp: 2022-08-19 19:47:06.248030\n",
      "resetting env. episode 2272, reward total was -19.0. running mean: -20.035324212187383, timestamp: 2022-08-19 19:47:09.201061\n",
      "resetting env. episode 2273, reward total was -21.0. running mean: -20.04497097006551, timestamp: 2022-08-19 19:47:11.576089\n",
      "resetting env. episode 2274, reward total was -21.0. running mean: -20.054521260364854, timestamp: 2022-08-19 19:47:13.666115\n",
      "resetting env. episode 2275, reward total was -19.0. running mean: -20.043976047761205, timestamp: 2022-08-19 19:47:16.464143\n",
      "resetting env. episode 2276, reward total was -19.0. running mean: -20.033536287283596, timestamp: 2022-08-19 19:47:19.069173\n",
      "resetting env. episode 2277, reward total was -21.0. running mean: -20.043200924410762, timestamp: 2022-08-19 19:47:21.070198\n",
      "resetting env. episode 2278, reward total was -21.0. running mean: -20.052768915166656, timestamp: 2022-08-19 19:47:23.006220\n",
      "resetting env. episode 2279, reward total was -20.0. running mean: -20.05224122601499, timestamp: 2022-08-19 19:47:25.194245\n",
      "resetting env. episode 2280, reward total was -20.0. running mean: -20.05171881375484, timestamp: 2022-08-19 19:47:27.176265\n",
      "resetting env. episode 2281, reward total was -17.0. running mean: -20.02120162561729, timestamp: 2022-08-19 19:47:30.199304\n",
      "resetting env. episode 2282, reward total was -19.0. running mean: -20.01098960936112, timestamp: 2022-08-19 19:47:32.841335\n",
      "resetting env. episode 2283, reward total was -21.0. running mean: -20.020879713267508, timestamp: 2022-08-19 19:47:34.852355\n",
      "resetting env. episode 2284, reward total was -21.0. running mean: -20.030670916134834, timestamp: 2022-08-19 19:47:37.459387\n",
      "resetting env. episode 2285, reward total was -21.0. running mean: -20.040364206973486, timestamp: 2022-08-19 19:47:39.862410\n",
      "resetting env. episode 2286, reward total was -19.0. running mean: -20.029960564903753, timestamp: 2022-08-19 19:47:42.408438\n",
      "resetting env. episode 2287, reward total was -21.0. running mean: -20.039660959254718, timestamp: 2022-08-19 19:47:45.113471\n",
      "resetting env. episode 2288, reward total was -19.0. running mean: -20.02926434966217, timestamp: 2022-08-19 19:47:47.731499\n",
      "resetting env. episode 2289, reward total was -20.0. running mean: -20.02897170616555, timestamp: 2022-08-19 19:47:50.958535\n",
      "resetting env. episode 2290, reward total was -21.0. running mean: -20.038681989103896, timestamp: 2022-08-19 19:47:53.152559\n",
      "resetting env. episode 2291, reward total was -21.0. running mean: -20.048295169212857, timestamp: 2022-08-19 19:47:55.272583\n",
      "resetting env. episode 2292, reward total was -20.0. running mean: -20.047812217520725, timestamp: 2022-08-19 19:47:57.654610\n",
      "resetting env. episode 2293, reward total was -20.0. running mean: -20.047334095345516, timestamp: 2022-08-19 19:48:00.495642\n",
      "resetting env. episode 2294, reward total was -21.0. running mean: -20.056860754392062, timestamp: 2022-08-19 19:48:02.279663\n",
      "resetting env. episode 2295, reward total was -21.0. running mean: -20.06629214684814, timestamp: 2022-08-19 19:48:04.344687\n",
      "resetting env. episode 2296, reward total was -21.0. running mean: -20.07562922537966, timestamp: 2022-08-19 19:48:06.866717\n",
      "resetting env. episode 2297, reward total was -20.0. running mean: -20.074872933125864, timestamp: 2022-08-19 19:48:09.307742\n",
      "resetting env. episode 2298, reward total was -20.0. running mean: -20.074124203794604, timestamp: 2022-08-19 19:48:11.613768\n",
      "resetting env. episode 2299, reward total was -21.0. running mean: -20.08338296175666, timestamp: 2022-08-19 19:48:14.186800\n",
      "resetting env. episode 2300, reward total was -20.0. running mean: -20.082549132139093, timestamp: 2022-08-19 19:48:16.488823\n",
      "resetting env. episode 2301, reward total was -21.0. running mean: -20.0917236408177, timestamp: 2022-08-19 19:48:18.758849\n",
      "resetting env. episode 2302, reward total was -20.0. running mean: -20.090806404409523, timestamp: 2022-08-19 19:48:20.805872\n",
      "resetting env. episode 2303, reward total was -21.0. running mean: -20.099898340365428, timestamp: 2022-08-19 19:48:23.232900\n",
      "resetting env. episode 2304, reward total was -19.0. running mean: -20.088899356961775, timestamp: 2022-08-19 19:48:26.674940\n",
      "resetting env. episode 2305, reward total was -19.0. running mean: -20.07801036339216, timestamp: 2022-08-19 19:48:28.990966\n",
      "resetting env. episode 2306, reward total was -21.0. running mean: -20.08723025975824, timestamp: 2022-08-19 19:48:31.240993\n",
      "resetting env. episode 2307, reward total was -20.0. running mean: -20.086357957160658, timestamp: 2022-08-19 19:48:33.288013\n",
      "resetting env. episode 2308, reward total was -21.0. running mean: -20.095494377589052, timestamp: 2022-08-19 19:48:35.152038\n",
      "resetting env. episode 2309, reward total was -20.0. running mean: -20.09453943381316, timestamp: 2022-08-19 19:48:37.243062\n",
      "resetting env. episode 2310, reward total was -21.0. running mean: -20.10359403947503, timestamp: 2022-08-19 19:48:39.489084\n",
      "resetting env. episode 2311, reward total was -19.0. running mean: -20.092558099080282, timestamp: 2022-08-19 19:48:42.320643\n",
      "resetting env. episode 2312, reward total was -19.0. running mean: -20.08163251808948, timestamp: 2022-08-19 19:48:45.134675\n",
      "resetting env. episode 2313, reward total was -21.0. running mean: -20.090816192908587, timestamp: 2022-08-19 19:48:47.368698\n",
      "resetting env. episode 2314, reward total was -21.0. running mean: -20.099908030979503, timestamp: 2022-08-19 19:48:49.582726\n",
      "resetting env. episode 2315, reward total was -21.0. running mean: -20.108908950669708, timestamp: 2022-08-19 19:48:52.094752\n",
      "resetting env. episode 2316, reward total was -20.0. running mean: -20.10781986116301, timestamp: 2022-08-19 19:48:54.443779\n",
      "resetting env. episode 2317, reward total was -20.0. running mean: -20.10674166255138, timestamp: 2022-08-19 19:48:56.317808\n",
      "resetting env. episode 2318, reward total was -20.0. running mean: -20.105674245925865, timestamp: 2022-08-19 19:48:58.438828\n",
      "resetting env. episode 2319, reward total was -21.0. running mean: -20.114617503466608, timestamp: 2022-08-19 19:49:00.755850\n",
      "resetting env. episode 2320, reward total was -18.0. running mean: -20.093471328431942, timestamp: 2022-08-19 19:49:03.527880\n",
      "resetting env. episode 2321, reward total was -16.0. running mean: -20.052536615147623, timestamp: 2022-08-19 19:49:06.325914\n",
      "resetting env. episode 2322, reward total was -21.0. running mean: -20.062011248996146, timestamp: 2022-08-19 19:49:08.450462\n",
      "resetting env. episode 2323, reward total was -19.0. running mean: -20.051391136506187, timestamp: 2022-08-19 19:49:11.206490\n",
      "resetting env. episode 2324, reward total was -21.0. running mean: -20.060877225141127, timestamp: 2022-08-19 19:49:13.627520\n",
      "resetting env. episode 2325, reward total was -21.0. running mean: -20.070268452889717, timestamp: 2022-08-19 19:49:15.818544\n",
      "resetting env. episode 2326, reward total was -21.0. running mean: -20.07956576836082, timestamp: 2022-08-19 19:49:18.110572\n",
      "resetting env. episode 2327, reward total was -20.0. running mean: -20.07877011067721, timestamp: 2022-08-19 19:49:21.468610\n",
      "resetting env. episode 2328, reward total was -19.0. running mean: -20.067982409570437, timestamp: 2022-08-19 19:49:24.382640\n",
      "resetting env. episode 2329, reward total was -21.0. running mean: -20.077302585474733, timestamp: 2022-08-19 19:49:26.987669\n",
      "resetting env. episode 2330, reward total was -21.0. running mean: -20.086529559619986, timestamp: 2022-08-19 19:49:29.871702\n",
      "resetting env. episode 2331, reward total was -21.0. running mean: -20.09566426402379, timestamp: 2022-08-19 19:49:31.870728\n",
      "resetting env. episode 2332, reward total was -19.0. running mean: -20.08470762138355, timestamp: 2022-08-19 19:49:34.419755\n",
      "resetting env. episode 2333, reward total was -21.0. running mean: -20.093860545169715, timestamp: 2022-08-19 19:49:36.986784\n",
      "resetting env. episode 2334, reward total was -19.0. running mean: -20.08292193971802, timestamp: 2022-08-19 19:49:39.320810\n",
      "resetting env. episode 2335, reward total was -20.0. running mean: -20.082092720320837, timestamp: 2022-08-19 19:49:41.914843\n",
      "resetting env. episode 2336, reward total was -20.0. running mean: -20.08127179311763, timestamp: 2022-08-19 19:49:43.869865\n",
      "resetting env. episode 2337, reward total was -21.0. running mean: -20.090459075186455, timestamp: 2022-08-19 19:49:45.736886\n",
      "resetting env. episode 2338, reward total was -21.0. running mean: -20.09955448443459, timestamp: 2022-08-19 19:49:47.418906\n",
      "resetting env. episode 2339, reward total was -20.0. running mean: -20.098558939590244, timestamp: 2022-08-19 19:49:49.706930\n",
      "resetting env. episode 2340, reward total was -21.0. running mean: -20.107573350194343, timestamp: 2022-08-19 19:49:52.007955\n",
      "resetting env. episode 2341, reward total was -20.0. running mean: -20.106497616692398, timestamp: 2022-08-19 19:49:54.125984\n",
      "resetting env. episode 2342, reward total was -20.0. running mean: -20.10543264052547, timestamp: 2022-08-19 19:49:56.204009\n",
      "resetting env. episode 2343, reward total was -21.0. running mean: -20.114378314120216, timestamp: 2022-08-19 19:49:57.984025\n",
      "resetting env. episode 2344, reward total was -20.0. running mean: -20.113234530979014, timestamp: 2022-08-19 19:50:00.274052\n",
      "resetting env. episode 2345, reward total was -19.0. running mean: -20.102102185669224, timestamp: 2022-08-19 19:50:03.023602\n",
      "resetting env. episode 2346, reward total was -21.0. running mean: -20.111081163812532, timestamp: 2022-08-19 19:50:05.086626\n",
      "resetting env. episode 2347, reward total was -21.0. running mean: -20.119970352174406, timestamp: 2022-08-19 19:50:07.287655\n",
      "resetting env. episode 2348, reward total was -21.0. running mean: -20.12877064865266, timestamp: 2022-08-19 19:50:09.489679\n",
      "resetting env. episode 2349, reward total was -20.0. running mean: -20.127482942166136, timestamp: 2022-08-19 19:50:11.829706\n",
      "resetting env. episode 2350, reward total was -20.0. running mean: -20.126208112744475, timestamp: 2022-08-19 19:50:14.854738\n",
      "resetting env. episode 2351, reward total was -20.0. running mean: -20.12494603161703, timestamp: 2022-08-19 19:50:16.687759\n",
      "resetting env. episode 2352, reward total was -18.0. running mean: -20.10369657130086, timestamp: 2022-08-19 19:50:19.046787\n",
      "resetting env. episode 2353, reward total was -21.0. running mean: -20.11265960558785, timestamp: 2022-08-19 19:50:20.960809\n",
      "resetting env. episode 2354, reward total was -17.0. running mean: -20.081533009531974, timestamp: 2022-08-19 19:50:23.990844\n",
      "resetting env. episode 2355, reward total was -21.0. running mean: -20.090717679436654, timestamp: 2022-08-19 19:50:26.115872\n",
      "resetting env. episode 2356, reward total was -20.0. running mean: -20.089810502642287, timestamp: 2022-08-19 19:50:28.501895\n",
      "resetting env. episode 2357, reward total was -20.0. running mean: -20.088912397615864, timestamp: 2022-08-19 19:50:31.258930\n",
      "resetting env. episode 2358, reward total was -20.0. running mean: -20.088023273639706, timestamp: 2022-08-19 19:50:34.176962\n",
      "resetting env. episode 2359, reward total was -21.0. running mean: -20.09714304090331, timestamp: 2022-08-19 19:50:36.678992\n",
      "resetting env. episode 2360, reward total was -21.0. running mean: -20.106171610494275, timestamp: 2022-08-19 19:50:39.465022\n",
      "resetting env. episode 2361, reward total was -19.0. running mean: -20.095109894389335, timestamp: 2022-08-19 19:50:42.376058\n",
      "resetting env. episode 2362, reward total was -19.0. running mean: -20.084158795445443, timestamp: 2022-08-19 19:50:44.684084\n",
      "resetting env. episode 2363, reward total was -21.0. running mean: -20.09331720749099, timestamp: 2022-08-19 19:50:46.358106\n",
      "resetting env. episode 2364, reward total was -19.0. running mean: -20.08238403541608, timestamp: 2022-08-19 19:50:48.913135\n",
      "resetting env. episode 2365, reward total was -20.0. running mean: -20.08156019506192, timestamp: 2022-08-19 19:50:51.511166\n",
      "resetting env. episode 2366, reward total was -20.0. running mean: -20.080744593111298, timestamp: 2022-08-19 19:50:53.560187\n",
      "resetting env. episode 2367, reward total was -20.0. running mean: -20.079937147180186, timestamp: 2022-08-19 19:50:55.875213\n",
      "resetting env. episode 2368, reward total was -20.0. running mean: -20.079137775708382, timestamp: 2022-08-19 19:50:58.142242\n",
      "resetting env. episode 2369, reward total was -17.0. running mean: -20.0483463979513, timestamp: 2022-08-19 19:51:00.755271\n",
      "resetting env. episode 2370, reward total was -19.0. running mean: -20.037862933971788, timestamp: 2022-08-19 19:51:03.600302\n",
      "resetting env. episode 2371, reward total was -20.0. running mean: -20.03748430463207, timestamp: 2022-08-19 19:51:05.756334\n",
      "resetting env. episode 2372, reward total was -21.0. running mean: -20.047109461585748, timestamp: 2022-08-19 19:51:07.862356\n",
      "resetting env. episode 2373, reward total was -21.0. running mean: -20.056638366969892, timestamp: 2022-08-19 19:51:10.528385\n",
      "resetting env. episode 2374, reward total was -21.0. running mean: -20.066071983300194, timestamp: 2022-08-19 19:51:12.685413\n",
      "resetting env. episode 2375, reward total was -21.0. running mean: -20.075411263467192, timestamp: 2022-08-19 19:51:15.321441\n",
      "resetting env. episode 2376, reward total was -21.0. running mean: -20.08465715083252, timestamp: 2022-08-19 19:51:16.969463\n",
      "resetting env. episode 2377, reward total was -20.0. running mean: -20.083810579324194, timestamp: 2022-08-19 19:51:19.528493\n",
      "resetting env. episode 2378, reward total was -21.0. running mean: -20.092972473530953, timestamp: 2022-08-19 19:51:22.379526\n",
      "resetting env. episode 2379, reward total was -20.0. running mean: -20.09204274879564, timestamp: 2022-08-19 19:51:24.212545\n",
      "resetting env. episode 2380, reward total was -21.0. running mean: -20.101122321307685, timestamp: 2022-08-19 19:51:26.046566\n",
      "resetting env. episode 2381, reward total was -21.0. running mean: -20.11011109809461, timestamp: 2022-08-19 19:51:28.516595\n",
      "resetting env. episode 2382, reward total was -21.0. running mean: -20.119009987113664, timestamp: 2022-08-19 19:51:31.424632\n",
      "resetting env. episode 2383, reward total was -20.0. running mean: -20.117819887242526, timestamp: 2022-08-19 19:51:33.970662\n",
      "resetting env. episode 2384, reward total was -21.0. running mean: -20.1266416883701, timestamp: 2022-08-19 19:51:36.104688\n",
      "resetting env. episode 2385, reward total was -20.0. running mean: -20.125375271486398, timestamp: 2022-08-19 19:51:38.811716\n",
      "resetting env. episode 2386, reward total was -19.0. running mean: -20.114121518771533, timestamp: 2022-08-19 19:51:41.507748\n",
      "resetting env. episode 2387, reward total was -19.0. running mean: -20.10298030358382, timestamp: 2022-08-19 19:51:43.819293\n",
      "resetting env. episode 2388, reward total was -21.0. running mean: -20.111950500547984, timestamp: 2022-08-19 19:51:45.658323\n",
      "resetting env. episode 2389, reward total was -19.0. running mean: -20.100830995542506, timestamp: 2022-08-19 19:51:48.262347\n",
      "resetting env. episode 2390, reward total was -18.0. running mean: -20.07982268558708, timestamp: 2022-08-19 19:51:50.685376\n",
      "resetting env. episode 2391, reward total was -21.0. running mean: -20.08902445873121, timestamp: 2022-08-19 19:51:52.938406\n",
      "resetting env. episode 2392, reward total was -21.0. running mean: -20.098134214143897, timestamp: 2022-08-19 19:51:55.330430\n",
      "resetting env. episode 2393, reward total was -21.0. running mean: -20.10715287200246, timestamp: 2022-08-19 19:51:57.527456\n",
      "resetting env. episode 2394, reward total was -19.0. running mean: -20.096081343282435, timestamp: 2022-08-19 19:52:00.001482\n",
      "resetting env. episode 2395, reward total was -20.0. running mean: -20.09512052984961, timestamp: 2022-08-19 19:52:02.697515\n",
      "resetting env. episode 2396, reward total was -18.0. running mean: -20.074169324551114, timestamp: 2022-08-19 19:52:05.301549\n",
      "resetting env. episode 2397, reward total was -19.0. running mean: -20.063427631305604, timestamp: 2022-08-19 19:52:08.078578\n",
      "resetting env. episode 2398, reward total was -20.0. running mean: -20.062793354992547, timestamp: 2022-08-19 19:52:10.990612\n",
      "resetting env. episode 2399, reward total was -20.0. running mean: -20.06216542144262, timestamp: 2022-08-19 19:52:12.972636\n",
      "resetting env. episode 2400, reward total was -20.0. running mean: -20.061543767228194, timestamp: 2022-08-19 19:52:15.133660\n",
      "resetting env. episode 2401, reward total was -21.0. running mean: -20.07092832955591, timestamp: 2022-08-19 19:52:17.215686\n",
      "resetting env. episode 2402, reward total was -19.0. running mean: -20.060219046260354, timestamp: 2022-08-19 19:52:19.341713\n",
      "resetting env. episode 2403, reward total was -19.0. running mean: -20.04961685579775, timestamp: 2022-08-19 19:52:21.741739\n",
      "resetting env. episode 2404, reward total was -18.0. running mean: -20.02912068723977, timestamp: 2022-08-19 19:52:24.823787\n",
      "resetting env. episode 2405, reward total was -21.0. running mean: -20.038829480367376, timestamp: 2022-08-19 19:52:26.809800\n",
      "resetting env. episode 2406, reward total was -19.0. running mean: -20.028441185563704, timestamp: 2022-08-19 19:52:29.347832\n",
      "resetting env. episode 2407, reward total was -19.0. running mean: -20.018156773708068, timestamp: 2022-08-19 19:52:31.864860\n",
      "resetting env. episode 2408, reward total was -21.0. running mean: -20.02797520597099, timestamp: 2022-08-19 19:52:34.322887\n",
      "resetting env. episode 2409, reward total was -21.0. running mean: -20.03769545391128, timestamp: 2022-08-19 19:52:36.741916\n",
      "resetting env. episode 2410, reward total was -19.0. running mean: -20.027318499372168, timestamp: 2022-08-19 19:52:39.323944\n",
      "resetting env. episode 2411, reward total was -21.0. running mean: -20.037045314378446, timestamp: 2022-08-19 19:52:41.655979\n",
      "resetting env. episode 2412, reward total was -21.0. running mean: -20.046674861234663, timestamp: 2022-08-19 19:52:44.086003\n",
      "resetting env. episode 2413, reward total was -21.0. running mean: -20.05620811262232, timestamp: 2022-08-19 19:52:46.212031\n",
      "resetting env. episode 2414, reward total was -21.0. running mean: -20.065646031496097, timestamp: 2022-08-19 19:52:48.570057\n",
      "resetting env. episode 2415, reward total was -20.0. running mean: -20.064989571181137, timestamp: 2022-08-19 19:52:50.566085\n",
      "resetting env. episode 2416, reward total was -20.0. running mean: -20.064339675469324, timestamp: 2022-08-19 19:52:52.555106\n",
      "resetting env. episode 2417, reward total was -21.0. running mean: -20.073696278714632, timestamp: 2022-08-19 19:52:54.433124\n",
      "resetting env. episode 2418, reward total was -18.0. running mean: -20.052959315927485, timestamp: 2022-08-19 19:52:57.344159\n",
      "resetting env. episode 2419, reward total was -20.0. running mean: -20.05242972276821, timestamp: 2022-08-19 19:52:59.643191\n",
      "resetting env. episode 2420, reward total was -20.0. running mean: -20.051905425540525, timestamp: 2022-08-19 19:53:01.730210\n",
      "resetting env. episode 2421, reward total was -21.0. running mean: -20.06138637128512, timestamp: 2022-08-19 19:53:04.115239\n",
      "resetting env. episode 2422, reward total was -21.0. running mean: -20.07077250757227, timestamp: 2022-08-19 19:53:06.418267\n",
      "resetting env. episode 2423, reward total was -19.0. running mean: -20.060064782496546, timestamp: 2022-08-19 19:53:08.591294\n",
      "resetting env. episode 2424, reward total was -20.0. running mean: -20.05946413467158, timestamp: 2022-08-19 19:53:11.945333\n",
      "resetting env. episode 2425, reward total was -20.0. running mean: -20.058869493324863, timestamp: 2022-08-19 19:53:13.635362\n",
      "resetting env. episode 2426, reward total was -21.0. running mean: -20.068280798391616, timestamp: 2022-08-19 19:53:15.742376\n",
      "resetting env. episode 2427, reward total was -20.0. running mean: -20.067597990407698, timestamp: 2022-08-19 19:53:17.924404\n",
      "resetting env. episode 2428, reward total was -21.0. running mean: -20.076922010503623, timestamp: 2022-08-19 19:53:20.042426\n",
      "resetting env. episode 2429, reward total was -20.0. running mean: -20.076152790398584, timestamp: 2022-08-19 19:53:21.628448\n",
      "resetting env. episode 2430, reward total was -21.0. running mean: -20.0853912624946, timestamp: 2022-08-19 19:53:23.790470\n",
      "resetting env. episode 2431, reward total was -21.0. running mean: -20.094537349869654, timestamp: 2022-08-19 19:53:25.668497\n",
      "resetting env. episode 2432, reward total was -20.0. running mean: -20.093591976370956, timestamp: 2022-08-19 19:53:27.825523\n",
      "resetting env. episode 2433, reward total was -20.0. running mean: -20.092656056607247, timestamp: 2022-08-19 19:53:30.715554\n",
      "resetting env. episode 2434, reward total was -19.0. running mean: -20.081729496041174, timestamp: 2022-08-19 19:53:33.049583\n",
      "resetting env. episode 2435, reward total was -19.0. running mean: -20.070912201080763, timestamp: 2022-08-19 19:53:35.237611\n",
      "resetting env. episode 2436, reward total was -21.0. running mean: -20.080203079069957, timestamp: 2022-08-19 19:53:37.229630\n",
      "resetting env. episode 2437, reward total was -21.0. running mean: -20.089401048279257, timestamp: 2022-08-19 19:53:39.442176\n",
      "resetting env. episode 2438, reward total was -21.0. running mean: -20.098507037796466, timestamp: 2022-08-19 19:53:41.331203\n",
      "resetting env. episode 2439, reward total was -19.0. running mean: -20.087521967418503, timestamp: 2022-08-19 19:53:43.649229\n",
      "resetting env. episode 2440, reward total was -21.0. running mean: -20.09664674774432, timestamp: 2022-08-19 19:53:45.722250\n",
      "resetting env. episode 2441, reward total was -20.0. running mean: -20.095680280266876, timestamp: 2022-08-19 19:53:47.652276\n",
      "resetting env. episode 2442, reward total was -20.0. running mean: -20.094723477464207, timestamp: 2022-08-19 19:53:50.198304\n",
      "resetting env. episode 2443, reward total was -20.0. running mean: -20.093776242689565, timestamp: 2022-08-19 19:53:52.489334\n",
      "resetting env. episode 2444, reward total was -21.0. running mean: -20.10283848026267, timestamp: 2022-08-19 19:53:54.402357\n",
      "resetting env. episode 2445, reward total was -18.0. running mean: -20.081810095460042, timestamp: 2022-08-19 19:53:57.459388\n",
      "resetting env. episode 2446, reward total was -21.0. running mean: -20.090991994505444, timestamp: 2022-08-19 19:53:59.894421\n",
      "resetting env. episode 2447, reward total was -21.0. running mean: -20.10008207456039, timestamp: 2022-08-19 19:54:02.259984\n",
      "resetting env. episode 2448, reward total was -20.0. running mean: -20.099081253814784, timestamp: 2022-08-19 19:54:04.122995\n",
      "resetting env. episode 2449, reward total was -21.0. running mean: -20.108090441276637, timestamp: 2022-08-19 19:54:06.043021\n",
      "resetting env. episode 2450, reward total was -20.0. running mean: -20.10700953686387, timestamp: 2022-08-19 19:54:08.584047\n",
      "resetting env. episode 2451, reward total was -20.0. running mean: -20.10593944149523, timestamp: 2022-08-19 19:54:10.860079\n",
      "resetting env. episode 2452, reward total was -18.0. running mean: -20.08488004708028, timestamp: 2022-08-19 19:54:13.385107\n",
      "resetting env. episode 2453, reward total was -18.0. running mean: -20.064031246609478, timestamp: 2022-08-19 19:54:15.994142\n",
      "resetting env. episode 2454, reward total was -19.0. running mean: -20.053390934143383, timestamp: 2022-08-19 19:54:18.429165\n",
      "resetting env. episode 2455, reward total was -20.0. running mean: -20.05285702480195, timestamp: 2022-08-19 19:54:20.601190\n",
      "resetting env. episode 2456, reward total was -20.0. running mean: -20.05232845455393, timestamp: 2022-08-19 19:54:23.481747\n",
      "resetting env. episode 2457, reward total was -19.0. running mean: -20.04180517000839, timestamp: 2022-08-19 19:54:26.010780\n",
      "resetting env. episode 2458, reward total was -18.0. running mean: -20.021387118308308, timestamp: 2022-08-19 19:54:28.521806\n",
      "resetting env. episode 2459, reward total was -21.0. running mean: -20.031173247125224, timestamp: 2022-08-19 19:54:30.708836\n",
      "resetting env. episode 2460, reward total was -21.0. running mean: -20.040861514653972, timestamp: 2022-08-19 19:54:33.082862\n",
      "resetting env. episode 2461, reward total was -21.0. running mean: -20.050452899507434, timestamp: 2022-08-19 19:54:35.604891\n",
      "resetting env. episode 2462, reward total was -21.0. running mean: -20.05994837051236, timestamp: 2022-08-19 19:54:38.254921\n",
      "resetting env. episode 2463, reward total was -18.0. running mean: -20.039348886807236, timestamp: 2022-08-19 19:54:40.820952\n",
      "resetting env. episode 2464, reward total was -20.0. running mean: -20.038955397939162, timestamp: 2022-08-19 19:54:43.260982\n",
      "resetting env. episode 2465, reward total was -21.0. running mean: -20.04856584395977, timestamp: 2022-08-19 19:54:46.206015\n",
      "resetting env. episode 2466, reward total was -20.0. running mean: -20.048080185520174, timestamp: 2022-08-19 19:54:47.949038\n",
      "resetting env. episode 2467, reward total was -19.0. running mean: -20.037599383664972, timestamp: 2022-08-19 19:54:50.098065\n",
      "resetting env. episode 2468, reward total was -19.0. running mean: -20.027223389828322, timestamp: 2022-08-19 19:54:52.447089\n",
      "resetting env. episode 2469, reward total was -18.0. running mean: -20.00695115593004, timestamp: 2022-08-19 19:54:55.095120\n",
      "resetting env. episode 2470, reward total was -21.0. running mean: -20.01688164437074, timestamp: 2022-08-19 19:54:56.959141\n",
      "resetting env. episode 2471, reward total was -18.0. running mean: -19.996712827927034, timestamp: 2022-08-19 19:54:59.944178\n",
      "resetting env. episode 2472, reward total was -21.0. running mean: -20.006745699647766, timestamp: 2022-08-19 19:55:02.121204\n",
      "resetting env. episode 2473, reward total was -20.0. running mean: -20.006678242651287, timestamp: 2022-08-19 19:55:04.941237\n",
      "resetting env. episode 2474, reward total was -20.0. running mean: -20.00661146022477, timestamp: 2022-08-19 19:55:07.814272\n",
      "resetting env. episode 2475, reward total was -21.0. running mean: -20.016545345622525, timestamp: 2022-08-19 19:55:10.000299\n",
      "resetting env. episode 2476, reward total was -19.0. running mean: -20.0063798921663, timestamp: 2022-08-19 19:55:12.133321\n",
      "resetting env. episode 2477, reward total was -16.0. running mean: -19.966316093244636, timestamp: 2022-08-19 19:55:14.813355\n",
      "resetting env. episode 2478, reward total was -20.0. running mean: -19.96665293231219, timestamp: 2022-08-19 19:55:17.434388\n",
      "resetting env. episode 2479, reward total was -19.0. running mean: -19.95698640298907, timestamp: 2022-08-19 19:55:20.820424\n",
      "resetting env. episode 2480, reward total was -17.0. running mean: -19.927416538959182, timestamp: 2022-08-19 19:55:23.831461\n",
      "resetting env. episode 2481, reward total was -21.0. running mean: -19.93814237356959, timestamp: 2022-08-19 19:55:26.229488\n",
      "resetting env. episode 2482, reward total was -19.0. running mean: -19.928760949833897, timestamp: 2022-08-19 19:55:29.151522\n",
      "resetting env. episode 2483, reward total was -21.0. running mean: -19.93947334033556, timestamp: 2022-08-19 19:55:31.614551\n",
      "resetting env. episode 2484, reward total was -19.0. running mean: -19.930078606932206, timestamp: 2022-08-19 19:55:34.197586\n",
      "resetting env. episode 2485, reward total was -20.0. running mean: -19.930777820862883, timestamp: 2022-08-19 19:55:36.350607\n",
      "resetting env. episode 2486, reward total was -21.0. running mean: -19.941470042654256, timestamp: 2022-08-19 19:55:38.872636\n",
      "resetting env. episode 2487, reward total was -21.0. running mean: -19.952055342227712, timestamp: 2022-08-19 19:55:41.273667\n",
      "resetting env. episode 2488, reward total was -19.0. running mean: -19.942534788805435, timestamp: 2022-08-19 19:55:43.777694\n",
      "resetting env. episode 2489, reward total was -21.0. running mean: -19.95310944091738, timestamp: 2022-08-19 19:55:45.892722\n",
      "resetting env. episode 2490, reward total was -20.0. running mean: -19.953578346508205, timestamp: 2022-08-19 19:55:48.163747\n",
      "resetting env. episode 2491, reward total was -20.0. running mean: -19.95404256304312, timestamp: 2022-08-19 19:55:50.712778\n",
      "resetting env. episode 2492, reward total was -20.0. running mean: -19.95450213741269, timestamp: 2022-08-19 19:55:52.953803\n",
      "resetting env. episode 2493, reward total was -20.0. running mean: -19.95495711603856, timestamp: 2022-08-19 19:55:55.991840\n",
      "resetting env. episode 2494, reward total was -17.0. running mean: -19.925407544878176, timestamp: 2022-08-19 19:55:59.014875\n",
      "resetting env. episode 2495, reward total was -20.0. running mean: -19.926153469429394, timestamp: 2022-08-19 19:56:01.152903\n",
      "resetting env. episode 2496, reward total was -18.0. running mean: -19.9068919347351, timestamp: 2022-08-19 19:56:03.575932\n",
      "resetting env. episode 2497, reward total was -19.0. running mean: -19.89782301538775, timestamp: 2022-08-19 19:56:05.745953\n",
      "resetting env. episode 2498, reward total was -20.0. running mean: -19.898844785233873, timestamp: 2022-08-19 19:56:08.094987\n",
      "resetting env. episode 2499, reward total was -20.0. running mean: -19.899856337381532, timestamp: 2022-08-19 19:56:10.515010\n",
      "resetting env. episode 2500, reward total was -21.0. running mean: -19.910857774007717, timestamp: 2022-08-19 19:56:13.233041\n",
      "resetting env. episode 2501, reward total was -19.0. running mean: -19.90174919626764, timestamp: 2022-08-19 19:56:15.662069\n",
      "resetting env. episode 2502, reward total was -18.0. running mean: -19.882731704304963, timestamp: 2022-08-19 19:56:18.123099\n",
      "resetting env. episode 2503, reward total was -20.0. running mean: -19.88390438726191, timestamp: 2022-08-19 19:56:20.193124\n",
      "resetting env. episode 2504, reward total was -18.0. running mean: -19.86506534338929, timestamp: 2022-08-19 19:56:23.043158\n",
      "resetting env. episode 2505, reward total was -21.0. running mean: -19.876414689955396, timestamp: 2022-08-19 19:56:25.792192\n",
      "resetting env. episode 2506, reward total was -21.0. running mean: -19.887650543055845, timestamp: 2022-08-19 19:56:28.457222\n",
      "resetting env. episode 2507, reward total was -20.0. running mean: -19.888774037625286, timestamp: 2022-08-19 19:56:30.998252\n",
      "resetting env. episode 2508, reward total was -20.0. running mean: -19.88988629724903, timestamp: 2022-08-19 19:56:33.476284\n",
      "resetting env. episode 2509, reward total was -21.0. running mean: -19.90098743427654, timestamp: 2022-08-19 19:56:35.554308\n",
      "resetting env. episode 2510, reward total was -19.0. running mean: -19.891977559933775, timestamp: 2022-08-19 19:56:38.233336\n",
      "resetting env. episode 2511, reward total was -21.0. running mean: -19.903057784334436, timestamp: 2022-08-19 19:56:40.138360\n",
      "resetting env. episode 2512, reward total was -21.0. running mean: -19.91402720649109, timestamp: 2022-08-19 19:56:42.351385\n",
      "resetting env. episode 2513, reward total was -21.0. running mean: -19.92488693442618, timestamp: 2022-08-19 19:56:44.767415\n",
      "resetting env. episode 2514, reward total was -19.0. running mean: -19.915638065081918, timestamp: 2022-08-19 19:56:47.038441\n",
      "resetting env. episode 2515, reward total was -18.0. running mean: -19.896481684431098, timestamp: 2022-08-19 19:56:49.535473\n",
      "resetting env. episode 2516, reward total was -21.0. running mean: -19.90751686758679, timestamp: 2022-08-19 19:56:52.188502\n",
      "resetting env. episode 2517, reward total was -20.0. running mean: -19.90844169891092, timestamp: 2022-08-19 19:56:54.546530\n",
      "resetting env. episode 2518, reward total was -20.0. running mean: -19.90935728192181, timestamp: 2022-08-19 19:56:56.814566\n",
      "resetting env. episode 2519, reward total was -19.0. running mean: -19.900263709102592, timestamp: 2022-08-19 19:56:59.581590\n",
      "resetting env. episode 2520, reward total was -21.0. running mean: -19.911261072011566, timestamp: 2022-08-19 19:57:02.471623\n",
      "resetting env. episode 2521, reward total was -21.0. running mean: -19.92214846129145, timestamp: 2022-08-19 19:57:05.003654\n",
      "resetting env. episode 2522, reward total was -20.0. running mean: -19.922926976678536, timestamp: 2022-08-19 19:57:07.931688\n",
      "resetting env. episode 2523, reward total was -19.0. running mean: -19.91369770691175, timestamp: 2022-08-19 19:57:10.479718\n",
      "resetting env. episode 2524, reward total was -18.0. running mean: -19.894560729842635, timestamp: 2022-08-19 19:57:12.952746\n",
      "resetting env. episode 2525, reward total was -21.0. running mean: -19.90561512254421, timestamp: 2022-08-19 19:57:14.608768\n",
      "resetting env. episode 2526, reward total was -20.0. running mean: -19.906558971318766, timestamp: 2022-08-19 19:57:16.550791\n",
      "resetting env. episode 2527, reward total was -20.0. running mean: -19.907493381605576, timestamp: 2022-08-19 19:57:18.759815\n",
      "resetting env. episode 2528, reward total was -19.0. running mean: -19.89841844778952, timestamp: 2022-08-19 19:57:21.718851\n",
      "resetting env. episode 2529, reward total was -20.0. running mean: -19.899434263311626, timestamp: 2022-08-19 19:57:23.791878\n",
      "resetting env. episode 2530, reward total was -20.0. running mean: -19.900439920678508, timestamp: 2022-08-19 19:57:26.113903\n",
      "resetting env. episode 2531, reward total was -21.0. running mean: -19.911435521471724, timestamp: 2022-08-19 19:57:28.099926\n",
      "resetting env. episode 2532, reward total was -20.0. running mean: -19.912321166257005, timestamp: 2022-08-19 19:57:30.352953\n",
      "resetting env. episode 2533, reward total was -20.0. running mean: -19.913197954594434, timestamp: 2022-08-19 19:57:32.674983\n",
      "resetting env. episode 2534, reward total was -21.0. running mean: -19.92406597504849, timestamp: 2022-08-19 19:57:34.428003\n",
      "resetting env. episode 2535, reward total was -21.0. running mean: -19.934825315298003, timestamp: 2022-08-19 19:57:36.853029\n",
      "resetting env. episode 2536, reward total was -21.0. running mean: -19.945477062145024, timestamp: 2022-08-19 19:57:39.286062\n",
      "resetting env. episode 2537, reward total was -21.0. running mean: -19.956022291523574, timestamp: 2022-08-19 19:57:42.057094\n",
      "resetting env. episode 2538, reward total was -20.0. running mean: -19.95646206860834, timestamp: 2022-08-19 19:57:44.752122\n",
      "resetting env. episode 2539, reward total was -19.0. running mean: -19.946897447922257, timestamp: 2022-08-19 19:57:47.073150\n",
      "resetting env. episode 2540, reward total was -21.0. running mean: -19.957428473443034, timestamp: 2022-08-19 19:57:49.461176\n",
      "resetting env. episode 2541, reward total was -21.0. running mean: -19.967854188708603, timestamp: 2022-08-19 19:57:52.199210\n",
      "resetting env. episode 2542, reward total was -20.0. running mean: -19.968175646821518, timestamp: 2022-08-19 19:57:54.938242\n",
      "resetting env. episode 2543, reward total was -21.0. running mean: -19.978493890353302, timestamp: 2022-08-19 19:57:57.027267\n",
      "resetting env. episode 2544, reward total was -19.0. running mean: -19.96870895144977, timestamp: 2022-08-19 19:57:59.786301\n",
      "resetting env. episode 2545, reward total was -19.0. running mean: -19.959021861935273, timestamp: 2022-08-19 19:58:02.536336\n",
      "resetting env. episode 2546, reward total was -21.0. running mean: -19.96943164331592, timestamp: 2022-08-19 19:58:04.425358\n",
      "resetting env. episode 2547, reward total was -20.0. running mean: -19.96973732688276, timestamp: 2022-08-19 19:58:06.919384\n",
      "resetting env. episode 2548, reward total was -21.0. running mean: -19.980039953613936, timestamp: 2022-08-19 19:58:09.656419\n",
      "resetting env. episode 2549, reward total was -21.0. running mean: -19.990239554077796, timestamp: 2022-08-19 19:58:12.050447\n",
      "resetting env. episode 2550, reward total was -21.0. running mean: -20.000337158537018, timestamp: 2022-08-19 19:58:13.897468\n",
      "resetting env. episode 2551, reward total was -19.0. running mean: -19.99033378695165, timestamp: 2022-08-19 19:58:16.421499\n",
      "resetting env. episode 2552, reward total was -20.0. running mean: -19.99043044908213, timestamp: 2022-08-19 19:58:19.162529\n",
      "resetting env. episode 2553, reward total was -21.0. running mean: -20.00052614459131, timestamp: 2022-08-19 19:58:21.490555\n",
      "resetting env. episode 2554, reward total was -20.0. running mean: -20.000520883145395, timestamp: 2022-08-19 19:58:23.608580\n",
      "resetting env. episode 2555, reward total was -20.0. running mean: -20.00051567431394, timestamp: 2022-08-19 19:58:25.789609\n",
      "resetting env. episode 2556, reward total was -20.0. running mean: -20.000510517570802, timestamp: 2022-08-19 19:58:28.345639\n",
      "resetting env. episode 2557, reward total was -19.0. running mean: -19.990505412395095, timestamp: 2022-08-19 19:58:31.090668\n",
      "resetting env. episode 2558, reward total was -20.0. running mean: -19.99060035827114, timestamp: 2022-08-19 19:58:33.806699\n",
      "resetting env. episode 2559, reward total was -21.0. running mean: -20.00069435468843, timestamp: 2022-08-19 19:58:36.327729\n",
      "resetting env. episode 2560, reward total was -21.0. running mean: -20.010687411141546, timestamp: 2022-08-19 19:58:38.599757\n",
      "resetting env. episode 2561, reward total was -20.0. running mean: -20.01058053703013, timestamp: 2022-08-19 19:58:40.835784\n",
      "resetting env. episode 2562, reward total was -21.0. running mean: -20.020474731659828, timestamp: 2022-08-19 19:58:42.868808\n",
      "resetting env. episode 2563, reward total was -20.0. running mean: -20.02026998434323, timestamp: 2022-08-19 19:58:45.520839\n",
      "resetting env. episode 2564, reward total was -19.0. running mean: -20.010067284499797, timestamp: 2022-08-19 19:58:48.078869\n",
      "resetting env. episode 2565, reward total was -20.0. running mean: -20.0099666116548, timestamp: 2022-08-19 19:58:50.740899\n",
      "resetting env. episode 2566, reward total was -19.0. running mean: -19.999866945538255, timestamp: 2022-08-19 19:58:53.193927\n",
      "resetting env. episode 2567, reward total was -20.0. running mean: -19.99986827608287, timestamp: 2022-08-19 19:58:55.156954\n",
      "resetting env. episode 2568, reward total was -20.0. running mean: -19.999869593322043, timestamp: 2022-08-19 19:58:57.647981\n",
      "resetting env. episode 2569, reward total was -21.0. running mean: -20.009870897388822, timestamp: 2022-08-19 19:59:00.413010\n",
      "resetting env. episode 2570, reward total was -21.0. running mean: -20.019772188414933, timestamp: 2022-08-19 19:59:02.676039\n",
      "resetting env. episode 2571, reward total was -21.0. running mean: -20.029574466530786, timestamp: 2022-08-19 19:59:04.889062\n",
      "resetting env. episode 2572, reward total was -19.0. running mean: -20.01927872186548, timestamp: 2022-08-19 19:59:07.035088\n",
      "resetting env. episode 2573, reward total was -21.0. running mean: -20.029085934646826, timestamp: 2022-08-19 19:59:09.978124\n",
      "resetting env. episode 2574, reward total was -20.0. running mean: -20.02879507530036, timestamp: 2022-08-19 19:59:12.563158\n",
      "resetting env. episode 2575, reward total was -21.0. running mean: -20.038507124547355, timestamp: 2022-08-19 19:59:14.744177\n",
      "resetting env. episode 2576, reward total was -21.0. running mean: -20.04812205330188, timestamp: 2022-08-19 19:59:17.189207\n",
      "resetting env. episode 2577, reward total was -21.0. running mean: -20.057640832768865, timestamp: 2022-08-19 19:59:19.278234\n",
      "resetting env. episode 2578, reward total was -21.0. running mean: -20.067064424441178, timestamp: 2022-08-19 19:59:21.380260\n",
      "resetting env. episode 2579, reward total was -20.0. running mean: -20.066393780196766, timestamp: 2022-08-19 19:59:24.181287\n",
      "resetting env. episode 2580, reward total was -21.0. running mean: -20.0757298423948, timestamp: 2022-08-19 19:59:27.400329\n",
      "resetting env. episode 2581, reward total was -21.0. running mean: -20.084972543970853, timestamp: 2022-08-19 19:59:30.341362\n",
      "resetting env. episode 2582, reward total was -18.0. running mean: -20.064122818531143, timestamp: 2022-08-19 19:59:33.348398\n",
      "resetting env. episode 2583, reward total was -19.0. running mean: -20.053481590345832, timestamp: 2022-08-19 19:59:36.085427\n",
      "resetting env. episode 2584, reward total was -21.0. running mean: -20.062946774442374, timestamp: 2022-08-19 19:59:37.985453\n",
      "resetting env. episode 2585, reward total was -21.0. running mean: -20.07231730669795, timestamp: 2022-08-19 19:59:40.700482\n",
      "resetting env. episode 2586, reward total was -20.0. running mean: -20.07159413363097, timestamp: 2022-08-19 19:59:43.108509\n",
      "resetting env. episode 2587, reward total was -19.0. running mean: -20.060878192294663, timestamp: 2022-08-19 19:59:45.817541\n",
      "resetting env. episode 2588, reward total was -21.0. running mean: -20.070269410371715, timestamp: 2022-08-19 19:59:48.104569\n",
      "resetting env. episode 2589, reward total was -19.0. running mean: -20.059566716267998, timestamp: 2022-08-19 19:59:50.129594\n",
      "resetting env. episode 2590, reward total was -19.0. running mean: -20.04897104910532, timestamp: 2022-08-19 19:59:52.850625\n",
      "resetting env. episode 2591, reward total was -19.0. running mean: -20.038481338614268, timestamp: 2022-08-19 19:59:55.417655\n",
      "resetting env. episode 2592, reward total was -21.0. running mean: -20.048096525228125, timestamp: 2022-08-19 19:59:57.486681\n",
      "resetting env. episode 2593, reward total was -19.0. running mean: -20.037615559975844, timestamp: 2022-08-19 19:59:59.963706\n",
      "resetting env. episode 2594, reward total was -20.0. running mean: -20.037239404376084, timestamp: 2022-08-19 20:00:02.745740\n",
      "resetting env. episode 2595, reward total was -20.0. running mean: -20.036867010332323, timestamp: 2022-08-19 20:00:04.847764\n",
      "resetting env. episode 2596, reward total was -20.0. running mean: -20.036498340229, timestamp: 2022-08-19 20:00:07.428798\n",
      "resetting env. episode 2597, reward total was -21.0. running mean: -20.046133356826708, timestamp: 2022-08-19 20:00:09.430817\n",
      "resetting env. episode 2598, reward total was -21.0. running mean: -20.055672023258442, timestamp: 2022-08-19 20:00:11.665846\n",
      "resetting env. episode 2599, reward total was -20.0. running mean: -20.055115303025858, timestamp: 2022-08-19 20:00:13.683867\n",
      "resetting env. episode 2600, reward total was -21.0. running mean: -20.0645641499956, timestamp: 2022-08-19 20:00:15.664889\n",
      "resetting env. episode 2601, reward total was -21.0. running mean: -20.073918508495645, timestamp: 2022-08-19 20:00:18.650926\n",
      "resetting env. episode 2602, reward total was -21.0. running mean: -20.08317932341069, timestamp: 2022-08-19 20:00:21.043955\n",
      "resetting env. episode 2603, reward total was -20.0. running mean: -20.08234753017658, timestamp: 2022-08-19 20:00:23.541508\n",
      "resetting env. episode 2604, reward total was -20.0. running mean: -20.081524054874812, timestamp: 2022-08-19 20:00:26.255544\n",
      "resetting env. episode 2605, reward total was -21.0. running mean: -20.090708814326064, timestamp: 2022-08-19 20:00:28.791092\n",
      "resetting env. episode 2606, reward total was -18.0. running mean: -20.069801726182803, timestamp: 2022-08-19 20:00:31.699126\n",
      "resetting env. episode 2607, reward total was -19.0. running mean: -20.059103708920976, timestamp: 2022-08-19 20:00:34.384157\n",
      "resetting env. episode 2608, reward total was -21.0. running mean: -20.068512671831765, timestamp: 2022-08-19 20:00:36.335178\n",
      "resetting env. episode 2609, reward total was -21.0. running mean: -20.077827545113447, timestamp: 2022-08-19 20:00:38.365204\n",
      "resetting env. episode 2610, reward total was -19.0. running mean: -20.067049269662313, timestamp: 2022-08-19 20:00:41.045233\n",
      "resetting env. episode 2611, reward total was -20.0. running mean: -20.06637877696569, timestamp: 2022-08-19 20:00:43.276260\n",
      "resetting env. episode 2612, reward total was -20.0. running mean: -20.06571498919603, timestamp: 2022-08-19 20:00:45.467288\n",
      "resetting env. episode 2613, reward total was -21.0. running mean: -20.075057839304073, timestamp: 2022-08-19 20:00:47.315309\n",
      "resetting env. episode 2614, reward total was -21.0. running mean: -20.084307260911032, timestamp: 2022-08-19 20:00:49.103326\n",
      "resetting env. episode 2615, reward total was -19.0. running mean: -20.073464188301923, timestamp: 2022-08-19 20:00:51.455355\n",
      "resetting env. episode 2616, reward total was -20.0. running mean: -20.072729546418902, timestamp: 2022-08-19 20:00:54.278388\n",
      "resetting env. episode 2617, reward total was -21.0. running mean: -20.082002250954712, timestamp: 2022-08-19 20:00:56.624412\n",
      "resetting env. episode 2618, reward total was -20.0. running mean: -20.081182228445165, timestamp: 2022-08-19 20:00:58.834442\n",
      "resetting env. episode 2619, reward total was -20.0. running mean: -20.080370406160714, timestamp: 2022-08-19 20:01:00.515460\n",
      "resetting env. episode 2620, reward total was -20.0. running mean: -20.079566702099108, timestamp: 2022-08-19 20:01:02.853486\n",
      "resetting env. episode 2621, reward total was -21.0. running mean: -20.088771035078118, timestamp: 2022-08-19 20:01:05.053514\n",
      "resetting env. episode 2622, reward total was -18.0. running mean: -20.067883324727337, timestamp: 2022-08-19 20:01:07.538544\n",
      "resetting env. episode 2623, reward total was -19.0. running mean: -20.057204491480064, timestamp: 2022-08-19 20:01:10.642578\n",
      "resetting env. episode 2624, reward total was -16.0. running mean: -20.016632446565264, timestamp: 2022-08-19 20:01:13.284607\n",
      "resetting env. episode 2625, reward total was -21.0. running mean: -20.026466122099613, timestamp: 2022-08-19 20:01:15.538635\n",
      "resetting env. episode 2626, reward total was -21.0. running mean: -20.03620146087862, timestamp: 2022-08-19 20:01:17.878661\n",
      "resetting env. episode 2627, reward total was -18.0. running mean: -20.015839446269833, timestamp: 2022-08-19 20:01:20.244688\n",
      "resetting env. episode 2628, reward total was -20.0. running mean: -20.015681051807135, timestamp: 2022-08-19 20:01:22.517720\n",
      "resetting env. episode 2629, reward total was -20.0. running mean: -20.015524241289064, timestamp: 2022-08-19 20:01:24.320738\n",
      "resetting env. episode 2630, reward total was -21.0. running mean: -20.025368998876175, timestamp: 2022-08-19 20:01:26.717766\n",
      "resetting env. episode 2631, reward total was -20.0. running mean: -20.02511530888741, timestamp: 2022-08-19 20:01:28.813790\n",
      "resetting env. episode 2632, reward total was -21.0. running mean: -20.034864155798537, timestamp: 2022-08-19 20:01:30.855811\n",
      "resetting env. episode 2633, reward total was -21.0. running mean: -20.04451551424055, timestamp: 2022-08-19 20:01:33.091840\n",
      "resetting env. episode 2634, reward total was -16.0. running mean: -20.004070359098147, timestamp: 2022-08-19 20:01:36.060873\n",
      "resetting env. episode 2635, reward total was -19.0. running mean: -19.994029655507166, timestamp: 2022-08-19 20:01:38.396899\n",
      "resetting env. episode 2636, reward total was -19.0. running mean: -19.984089358952097, timestamp: 2022-08-19 20:01:41.530935\n",
      "resetting env. episode 2637, reward total was -21.0. running mean: -19.994248465362578, timestamp: 2022-08-19 20:01:44.080973\n",
      "resetting env. episode 2638, reward total was -21.0. running mean: -20.004305980708953, timestamp: 2022-08-19 20:01:46.259990\n",
      "resetting env. episode 2639, reward total was -21.0. running mean: -20.014262920901864, timestamp: 2022-08-19 20:01:48.489016\n",
      "resetting env. episode 2640, reward total was -19.0. running mean: -20.004120291692846, timestamp: 2022-08-19 20:01:52.117057\n",
      "resetting env. episode 2641, reward total was -21.0. running mean: -20.01407908877592, timestamp: 2022-08-19 20:01:54.706097\n",
      "resetting env. episode 2642, reward total was -21.0. running mean: -20.02393829788816, timestamp: 2022-08-19 20:01:56.630112\n",
      "resetting env. episode 2643, reward total was -20.0. running mean: -20.02369891490928, timestamp: 2022-08-19 20:01:59.155139\n",
      "resetting env. episode 2644, reward total was -18.0. running mean: -20.003461925760185, timestamp: 2022-08-19 20:02:01.659170\n",
      "resetting env. episode 2645, reward total was -20.0. running mean: -20.003427306502584, timestamp: 2022-08-19 20:02:04.160199\n",
      "resetting env. episode 2646, reward total was -19.0. running mean: -19.99339303343756, timestamp: 2022-08-19 20:02:06.797230\n",
      "resetting env. episode 2647, reward total was -19.0. running mean: -19.983459103103186, timestamp: 2022-08-19 20:02:09.670262\n",
      "resetting env. episode 2648, reward total was -21.0. running mean: -19.993624512072156, timestamp: 2022-08-19 20:02:12.384293\n",
      "resetting env. episode 2649, reward total was -20.0. running mean: -19.993688266951434, timestamp: 2022-08-19 20:02:14.397840\n",
      "resetting env. episode 2650, reward total was -21.0. running mean: -20.00375138428192, timestamp: 2022-08-19 20:02:17.197871\n",
      "resetting env. episode 2651, reward total was -21.0. running mean: -20.0137138704391, timestamp: 2022-08-19 20:02:18.920893\n",
      "resetting env. episode 2652, reward total was -20.0. running mean: -20.01357673173471, timestamp: 2022-08-19 20:02:21.245919\n",
      "resetting env. episode 2653, reward total was -21.0. running mean: -20.02344096441736, timestamp: 2022-08-19 20:02:23.811948\n",
      "resetting env. episode 2654, reward total was -19.0. running mean: -20.013206554773188, timestamp: 2022-08-19 20:02:26.422979\n",
      "resetting env. episode 2655, reward total was -17.0. running mean: -19.98307448922546, timestamp: 2022-08-19 20:02:29.483015\n",
      "resetting env. episode 2656, reward total was -20.0. running mean: -19.983243744333205, timestamp: 2022-08-19 20:02:31.633038\n",
      "resetting env. episode 2657, reward total was -21.0. running mean: -19.993411306889872, timestamp: 2022-08-19 20:02:33.805064\n",
      "resetting env. episode 2658, reward total was -20.0. running mean: -19.993477193820972, timestamp: 2022-08-19 20:02:36.005092\n",
      "resetting env. episode 2659, reward total was -21.0. running mean: -20.003542421882763, timestamp: 2022-08-19 20:02:38.277114\n",
      "resetting env. episode 2660, reward total was -21.0. running mean: -20.013506997663935, timestamp: 2022-08-19 20:02:40.977144\n",
      "resetting env. episode 2661, reward total was -21.0. running mean: -20.023371927687297, timestamp: 2022-08-19 20:02:43.129169\n",
      "resetting env. episode 2662, reward total was -21.0. running mean: -20.033138208410424, timestamp: 2022-08-19 20:02:45.772204\n",
      "resetting env. episode 2663, reward total was -21.0. running mean: -20.04280682632632, timestamp: 2022-08-19 20:02:47.874224\n",
      "resetting env. episode 2664, reward total was -19.0. running mean: -20.032378758063057, timestamp: 2022-08-19 20:02:50.872258\n",
      "resetting env. episode 2665, reward total was -19.0. running mean: -20.02205497048243, timestamp: 2022-08-19 20:02:53.351288\n",
      "resetting env. episode 2666, reward total was -21.0. running mean: -20.031834420777606, timestamp: 2022-08-19 20:02:55.437314\n",
      "resetting env. episode 2667, reward total was -19.0. running mean: -20.02151607656983, timestamp: 2022-08-19 20:02:57.553338\n",
      "resetting env. episode 2668, reward total was -17.0. running mean: -19.991300915804135, timestamp: 2022-08-19 20:03:00.117367\n",
      "resetting env. episode 2669, reward total was -21.0. running mean: -20.001387906646094, timestamp: 2022-08-19 20:03:02.566392\n",
      "resetting env. episode 2670, reward total was -20.0. running mean: -20.001374027579633, timestamp: 2022-08-19 20:03:04.671416\n",
      "resetting env. episode 2671, reward total was -20.0. running mean: -20.001360287303836, timestamp: 2022-08-19 20:03:08.100459\n",
      "resetting env. episode 2672, reward total was -21.0. running mean: -20.011346684430798, timestamp: 2022-08-19 20:03:10.238487\n",
      "resetting env. episode 2673, reward total was -21.0. running mean: -20.02123321758649, timestamp: 2022-08-19 20:03:12.725510\n",
      "resetting env. episode 2674, reward total was -21.0. running mean: -20.031020885410626, timestamp: 2022-08-19 20:03:15.190542\n",
      "resetting env. episode 2675, reward total was -19.0. running mean: -20.020710676556522, timestamp: 2022-08-19 20:03:17.350567\n",
      "resetting env. episode 2676, reward total was -20.0. running mean: -20.020503569790957, timestamp: 2022-08-19 20:03:19.655590\n",
      "resetting env. episode 2677, reward total was -21.0. running mean: -20.03029853409305, timestamp: 2022-08-19 20:03:22.223622\n",
      "resetting env. episode 2678, reward total was -21.0. running mean: -20.03999554875212, timestamp: 2022-08-19 20:03:24.570645\n",
      "resetting env. episode 2679, reward total was -21.0. running mean: -20.0495955932646, timestamp: 2022-08-19 20:03:26.824672\n",
      "resetting env. episode 2680, reward total was -18.0. running mean: -20.029099637331953, timestamp: 2022-08-19 20:03:29.669703\n",
      "resetting env. episode 2681, reward total was -18.0. running mean: -20.008808640958634, timestamp: 2022-08-19 20:03:32.357737\n",
      "resetting env. episode 2682, reward total was -21.0. running mean: -20.01872055454905, timestamp: 2022-08-19 20:03:34.941766\n",
      "resetting env. episode 2683, reward total was -20.0. running mean: -20.018533349003558, timestamp: 2022-08-19 20:03:36.946791\n",
      "resetting env. episode 2684, reward total was -20.0. running mean: -20.01834801551352, timestamp: 2022-08-19 20:03:38.766812\n",
      "resetting env. episode 2685, reward total was -18.0. running mean: -19.998164535358384, timestamp: 2022-08-19 20:03:41.195837\n",
      "resetting env. episode 2686, reward total was -17.0. running mean: -19.9681828900048, timestamp: 2022-08-19 20:03:44.118872\n",
      "resetting env. episode 2687, reward total was -20.0. running mean: -19.968501061104753, timestamp: 2022-08-19 20:03:46.706904\n",
      "resetting env. episode 2688, reward total was -19.0. running mean: -19.958816050493706, timestamp: 2022-08-19 20:03:48.905931\n",
      "resetting env. episode 2689, reward total was -21.0. running mean: -19.96922788998877, timestamp: 2022-08-19 20:03:51.655963\n",
      "resetting env. episode 2690, reward total was -19.0. running mean: -19.95953561108888, timestamp: 2022-08-19 20:03:54.139986\n",
      "resetting env. episode 2691, reward total was -18.0. running mean: -19.93994025497799, timestamp: 2022-08-19 20:03:56.967019\n",
      "resetting env. episode 2692, reward total was -19.0. running mean: -19.930540852428212, timestamp: 2022-08-19 20:03:59.235044\n",
      "resetting env. episode 2693, reward total was -21.0. running mean: -19.94123544390393, timestamp: 2022-08-19 20:04:01.455071\n",
      "resetting env. episode 2694, reward total was -16.0. running mean: -19.90182308946489, timestamp: 2022-08-19 20:04:04.181102\n",
      "resetting env. episode 2695, reward total was -21.0. running mean: -19.912804858570244, timestamp: 2022-08-19 20:04:06.532131\n",
      "resetting env. episode 2696, reward total was -21.0. running mean: -19.923676809984542, timestamp: 2022-08-19 20:04:08.920156\n",
      "resetting env. episode 2697, reward total was -15.0. running mean: -19.874440041884696, timestamp: 2022-08-19 20:04:12.359194\n",
      "resetting env. episode 2698, reward total was -21.0. running mean: -19.88569564146585, timestamp: 2022-08-19 20:04:15.282229\n",
      "resetting env. episode 2699, reward total was -21.0. running mean: -19.896838685051193, timestamp: 2022-08-19 20:04:17.296250\n",
      "resetting env. episode 2700, reward total was -20.0. running mean: -19.89787029820068, timestamp: 2022-08-19 20:04:19.516275\n",
      "resetting env. episode 2701, reward total was -19.0. running mean: -19.888891595218674, timestamp: 2022-08-19 20:04:22.526312\n",
      "resetting env. episode 2702, reward total was -21.0. running mean: -19.90000267926649, timestamp: 2022-08-19 20:04:25.175341\n",
      "resetting env. episode 2703, reward total was -19.0. running mean: -19.891002652473826, timestamp: 2022-08-19 20:04:27.888371\n",
      "resetting env. episode 2704, reward total was -21.0. running mean: -19.902092625949088, timestamp: 2022-08-19 20:04:30.190397\n",
      "resetting env. episode 2705, reward total was -21.0. running mean: -19.9130716996896, timestamp: 2022-08-19 20:04:32.381424\n",
      "resetting env. episode 2706, reward total was -20.0. running mean: -19.9139409826927, timestamp: 2022-08-19 20:04:34.671453\n",
      "resetting env. episode 2707, reward total was -21.0. running mean: -19.924801572865775, timestamp: 2022-08-19 20:04:37.074478\n",
      "resetting env. episode 2708, reward total was -21.0. running mean: -19.93555355713712, timestamp: 2022-08-19 20:04:39.448505\n",
      "resetting env. episode 2709, reward total was -17.0. running mean: -19.90619802156575, timestamp: 2022-08-19 20:04:42.136534\n",
      "resetting env. episode 2710, reward total was -21.0. running mean: -19.917136041350094, timestamp: 2022-08-19 20:04:44.625561\n",
      "resetting env. episode 2711, reward total was -14.0. running mean: -19.857964680936593, timestamp: 2022-08-19 20:04:47.852598\n",
      "resetting env. episode 2712, reward total was -19.0. running mean: -19.849385034127227, timestamp: 2022-08-19 20:04:50.170625\n",
      "resetting env. episode 2713, reward total was -21.0. running mean: -19.860891183785956, timestamp: 2022-08-19 20:04:52.349650\n",
      "resetting env. episode 2714, reward total was -21.0. running mean: -19.872282271948098, timestamp: 2022-08-19 20:04:56.152693\n",
      "resetting env. episode 2715, reward total was -19.0. running mean: -19.863559449228617, timestamp: 2022-08-19 20:04:58.336721\n",
      "resetting env. episode 2716, reward total was -19.0. running mean: -19.85492385473633, timestamp: 2022-08-19 20:05:00.771748\n",
      "resetting env. episode 2717, reward total was -19.0. running mean: -19.846374616188967, timestamp: 2022-08-19 20:05:03.191774\n",
      "resetting env. episode 2718, reward total was -21.0. running mean: -19.85791087002708, timestamp: 2022-08-19 20:05:05.698800\n",
      "resetting env. episode 2719, reward total was -18.0. running mean: -19.839331761326807, timestamp: 2022-08-19 20:05:08.317831\n",
      "resetting env. episode 2720, reward total was -21.0. running mean: -19.85093844371354, timestamp: 2022-08-19 20:05:11.205863\n",
      "resetting env. episode 2721, reward total was -20.0. running mean: -19.852429059276407, timestamp: 2022-08-19 20:05:13.382888\n",
      "resetting env. episode 2722, reward total was -20.0. running mean: -19.85390476868364, timestamp: 2022-08-19 20:05:16.505927\n",
      "resetting env. episode 2723, reward total was -20.0. running mean: -19.855365720996804, timestamp: 2022-08-19 20:05:19.053960\n",
      "resetting env. episode 2724, reward total was -21.0. running mean: -19.86681206378684, timestamp: 2022-08-19 20:05:21.329980\n",
      "resetting env. episode 2725, reward total was -21.0. running mean: -19.87814394314897, timestamp: 2022-08-19 20:05:23.343004\n",
      "resetting env. episode 2726, reward total was -20.0. running mean: -19.87936250371748, timestamp: 2022-08-19 20:05:25.750032\n",
      "resetting env. episode 2727, reward total was -20.0. running mean: -19.880568878680304, timestamp: 2022-08-19 20:05:28.254058\n",
      "resetting env. episode 2728, reward total was -21.0. running mean: -19.891763189893503, timestamp: 2022-08-19 20:05:30.369086\n",
      "resetting env. episode 2729, reward total was -21.0. running mean: -19.902845557994567, timestamp: 2022-08-19 20:05:33.503119\n",
      "resetting env. episode 2730, reward total was -19.0. running mean: -19.893817102414623, timestamp: 2022-08-19 20:05:36.222148\n",
      "resetting env. episode 2731, reward total was -21.0. running mean: -19.904878931390478, timestamp: 2022-08-19 20:05:38.248174\n",
      "resetting env. episode 2732, reward total was -19.0. running mean: -19.895830142076573, timestamp: 2022-08-19 20:05:41.271206\n",
      "resetting env. episode 2733, reward total was -20.0. running mean: -19.896871840655805, timestamp: 2022-08-19 20:05:43.822233\n",
      "resetting env. episode 2734, reward total was -20.0. running mean: -19.897903122249247, timestamp: 2022-08-19 20:05:46.284265\n",
      "resetting env. episode 2735, reward total was -21.0. running mean: -19.908924091026755, timestamp: 2022-08-19 20:05:49.157298\n",
      "resetting env. episode 2736, reward total was -21.0. running mean: -19.919834850116487, timestamp: 2022-08-19 20:05:51.882326\n",
      "resetting env. episode 2737, reward total was -21.0. running mean: -19.93063650161532, timestamp: 2022-08-19 20:05:54.213355\n",
      "resetting env. episode 2738, reward total was -21.0. running mean: -19.94133013659917, timestamp: 2022-08-19 20:05:56.014375\n",
      "resetting env. episode 2739, reward total was -19.0. running mean: -19.931916835233178, timestamp: 2022-08-19 20:05:59.154408\n",
      "resetting env. episode 2740, reward total was -20.0. running mean: -19.932597666880845, timestamp: 2022-08-19 20:06:01.693436\n",
      "resetting env. episode 2741, reward total was -21.0. running mean: -19.943271690212036, timestamp: 2022-08-19 20:06:03.831463\n",
      "resetting env. episode 2742, reward total was -19.0. running mean: -19.933838973309918, timestamp: 2022-08-19 20:06:06.480491\n",
      "resetting env. episode 2743, reward total was -21.0. running mean: -19.94450058357682, timestamp: 2022-08-19 20:06:08.359515\n",
      "resetting env. episode 2744, reward total was -20.0. running mean: -19.945055577741048, timestamp: 2022-08-19 20:06:11.046546\n",
      "resetting env. episode 2745, reward total was -20.0. running mean: -19.945605021963637, timestamp: 2022-08-19 20:06:13.814575\n",
      "resetting env. episode 2746, reward total was -21.0. running mean: -19.956148971744, timestamp: 2022-08-19 20:06:15.993602\n",
      "resetting env. episode 2747, reward total was -18.0. running mean: -19.93658748202656, timestamp: 2022-08-19 20:06:18.151626\n",
      "resetting env. episode 2748, reward total was -19.0. running mean: -19.927221607206295, timestamp: 2022-08-19 20:06:20.695654\n",
      "resetting env. episode 2749, reward total was -19.0. running mean: -19.917949391134233, timestamp: 2022-08-19 20:06:23.007681\n",
      "resetting env. episode 2750, reward total was -18.0. running mean: -19.89876989722289, timestamp: 2022-08-19 20:06:25.605711\n",
      "resetting env. episode 2751, reward total was -18.0. running mean: -19.879782198250663, timestamp: 2022-08-19 20:06:28.642745\n",
      "resetting env. episode 2752, reward total was -21.0. running mean: -19.890984376268158, timestamp: 2022-08-19 20:06:30.828772\n",
      "resetting env. episode 2753, reward total was -20.0. running mean: -19.892074532505475, timestamp: 2022-08-19 20:06:33.037797\n",
      "resetting env. episode 2754, reward total was -19.0. running mean: -19.883153787180422, timestamp: 2022-08-19 20:06:35.637825\n",
      "resetting env. episode 2755, reward total was -21.0. running mean: -19.89432224930862, timestamp: 2022-08-19 20:06:38.162856\n",
      "resetting env. episode 2756, reward total was -17.0. running mean: -19.865379026815535, timestamp: 2022-08-19 20:06:41.604895\n",
      "resetting env. episode 2757, reward total was -21.0. running mean: -19.87672523654738, timestamp: 2022-08-19 20:06:44.444932\n",
      "resetting env. episode 2758, reward total was -21.0. running mean: -19.887957984181906, timestamp: 2022-08-19 20:06:46.324950\n",
      "resetting env. episode 2759, reward total was -20.0. running mean: -19.889078404340086, timestamp: 2022-08-19 20:06:48.475972\n",
      "resetting env. episode 2760, reward total was -20.0. running mean: -19.890187620296686, timestamp: 2022-08-19 20:06:51.353005\n",
      "resetting env. episode 2761, reward total was -20.0. running mean: -19.891285744093718, timestamp: 2022-08-19 20:06:54.015037\n",
      "resetting env. episode 2762, reward total was -20.0. running mean: -19.89237288665278, timestamp: 2022-08-19 20:06:56.841071\n",
      "resetting env. episode 2763, reward total was -20.0. running mean: -19.89344915778625, timestamp: 2022-08-19 20:06:58.928092\n",
      "resetting env. episode 2764, reward total was -21.0. running mean: -19.90451466620839, timestamp: 2022-08-19 20:07:01.040121\n",
      "resetting env. episode 2765, reward total was -20.0. running mean: -19.905469519546305, timestamp: 2022-08-19 20:07:03.237145\n",
      "resetting env. episode 2766, reward total was -21.0. running mean: -19.91641482435084, timestamp: 2022-08-19 20:07:05.156166\n",
      "resetting env. episode 2767, reward total was -20.0. running mean: -19.917250676107333, timestamp: 2022-08-19 20:07:07.643198\n",
      "resetting env. episode 2768, reward total was -20.0. running mean: -19.91807816934626, timestamp: 2022-08-19 20:07:09.999224\n",
      "resetting env. episode 2769, reward total was -21.0. running mean: -19.928897387652796, timestamp: 2022-08-19 20:07:12.083251\n",
      "resetting env. episode 2770, reward total was -19.0. running mean: -19.91960841377627, timestamp: 2022-08-19 20:07:14.598276\n",
      "resetting env. episode 2771, reward total was -20.0. running mean: -19.920412329638506, timestamp: 2022-08-19 20:07:17.189305\n",
      "resetting env. episode 2772, reward total was -21.0. running mean: -19.93120820634212, timestamp: 2022-08-19 20:07:19.338333\n",
      "resetting env. episode 2773, reward total was -21.0. running mean: -19.9418961242787, timestamp: 2022-08-19 20:07:21.244352\n",
      "resetting env. episode 2774, reward total was -21.0. running mean: -19.952477163035912, timestamp: 2022-08-19 20:07:23.609379\n",
      "resetting env. episode 2775, reward total was -21.0. running mean: -19.962952391405555, timestamp: 2022-08-19 20:07:25.730404\n",
      "resetting env. episode 2776, reward total was -20.0. running mean: -19.9633228674915, timestamp: 2022-08-19 20:07:28.253434\n",
      "resetting env. episode 2777, reward total was -20.0. running mean: -19.963689638816582, timestamp: 2022-08-19 20:07:31.092467\n",
      "resetting env. episode 2778, reward total was -20.0. running mean: -19.964052742428414, timestamp: 2022-08-19 20:07:33.069490\n",
      "resetting env. episode 2779, reward total was -16.0. running mean: -19.92441221500413, timestamp: 2022-08-19 20:07:36.648532\n",
      "resetting env. episode 2780, reward total was -19.0. running mean: -19.91516809285409, timestamp: 2022-08-19 20:07:39.209560\n",
      "resetting env. episode 2781, reward total was -21.0. running mean: -19.92601641192555, timestamp: 2022-08-19 20:07:41.341587\n",
      "resetting env. episode 2782, reward total was -21.0. running mean: -19.936756247806294, timestamp: 2022-08-19 20:07:44.293620\n",
      "resetting env. episode 2783, reward total was -20.0. running mean: -19.93738868532823, timestamp: 2022-08-19 20:07:46.812652\n",
      "resetting env. episode 2784, reward total was -21.0. running mean: -19.948014798474947, timestamp: 2022-08-19 20:07:49.188676\n",
      "resetting env. episode 2785, reward total was -21.0. running mean: -19.958534650490197, timestamp: 2022-08-19 20:07:51.620705\n",
      "resetting env. episode 2786, reward total was -21.0. running mean: -19.968949303985294, timestamp: 2022-08-19 20:07:54.039735\n",
      "resetting env. episode 2787, reward total was -19.0. running mean: -19.959259810945444, timestamp: 2022-08-19 20:07:57.078770\n",
      "resetting env. episode 2788, reward total was -19.0. running mean: -19.94966721283599, timestamp: 2022-08-19 20:07:59.620801\n",
      "resetting env. episode 2789, reward total was -18.0. running mean: -19.93017054070763, timestamp: 2022-08-19 20:08:02.172831\n",
      "resetting env. episode 2790, reward total was -21.0. running mean: -19.940868835300552, timestamp: 2022-08-19 20:08:04.422853\n",
      "resetting env. episode 2791, reward total was -21.0. running mean: -19.951460146947547, timestamp: 2022-08-19 20:08:07.122888\n",
      "resetting env. episode 2792, reward total was -18.0. running mean: -19.931945545478072, timestamp: 2022-08-19 20:08:10.252923\n",
      "resetting env. episode 2793, reward total was -18.0. running mean: -19.91262609002329, timestamp: 2022-08-19 20:08:12.901954\n",
      "resetting env. episode 2794, reward total was -21.0. running mean: -19.92349982912306, timestamp: 2022-08-19 20:08:15.038980\n",
      "resetting env. episode 2795, reward total was -21.0. running mean: -19.93426483083183, timestamp: 2022-08-19 20:08:17.397005\n",
      "resetting env. episode 2796, reward total was -20.0. running mean: -19.93492218252351, timestamp: 2022-08-19 20:08:19.655033\n",
      "resetting env. episode 2797, reward total was -19.0. running mean: -19.92557296069828, timestamp: 2022-08-19 20:08:22.734068\n",
      "resetting env. episode 2798, reward total was -20.0. running mean: -19.926317231091296, timestamp: 2022-08-19 20:08:25.334102\n",
      "resetting env. episode 2799, reward total was -18.0. running mean: -19.907054058780382, timestamp: 2022-08-19 20:08:28.187133\n",
      "resetting env. episode 2800, reward total was -20.0. running mean: -19.907983518192577, timestamp: 2022-08-19 20:08:30.721162\n",
      "resetting env. episode 2801, reward total was -21.0. running mean: -19.91890368301065, timestamp: 2022-08-19 20:08:33.310194\n",
      "resetting env. episode 2802, reward total was -18.0. running mean: -19.899714646180545, timestamp: 2022-08-19 20:08:35.914226\n",
      "resetting env. episode 2803, reward total was -21.0. running mean: -19.91071749971874, timestamp: 2022-08-19 20:08:37.863249\n",
      "resetting env. episode 2804, reward total was -21.0. running mean: -19.921610324721552, timestamp: 2022-08-19 20:08:39.867271\n",
      "resetting env. episode 2805, reward total was -21.0. running mean: -19.932394221474336, timestamp: 2022-08-19 20:08:42.157299\n",
      "resetting env. episode 2806, reward total was -20.0. running mean: -19.933070279259592, timestamp: 2022-08-19 20:08:44.567326\n",
      "resetting env. episode 2807, reward total was -19.0. running mean: -19.923739576466996, timestamp: 2022-08-19 20:08:46.624350\n",
      "resetting env. episode 2808, reward total was -21.0. running mean: -19.934502180702328, timestamp: 2022-08-19 20:08:48.873377\n",
      "resetting env. episode 2809, reward total was -17.0. running mean: -19.905157158895307, timestamp: 2022-08-19 20:08:52.206413\n",
      "resetting env. episode 2810, reward total was -20.0. running mean: -19.906105587306353, timestamp: 2022-08-19 20:08:54.860443\n",
      "resetting env. episode 2811, reward total was -21.0. running mean: -19.91704453143329, timestamp: 2022-08-19 20:08:57.049472\n",
      "resetting env. episode 2812, reward total was -19.0. running mean: -19.90787408611896, timestamp: 2022-08-19 20:08:59.275500\n",
      "resetting env. episode 2813, reward total was -21.0. running mean: -19.91879534525777, timestamp: 2022-08-19 20:09:01.539527\n",
      "resetting env. episode 2814, reward total was -21.0. running mean: -19.92960739180519, timestamp: 2022-08-19 20:09:03.515547\n",
      "resetting env. episode 2815, reward total was -19.0. running mean: -19.92031131788714, timestamp: 2022-08-19 20:09:06.370582\n",
      "resetting env. episode 2816, reward total was -17.0. running mean: -19.89110820470827, timestamp: 2022-08-19 20:09:09.038614\n",
      "resetting env. episode 2817, reward total was -20.0. running mean: -19.892197122661187, timestamp: 2022-08-19 20:09:11.366640\n",
      "resetting env. episode 2818, reward total was -19.0. running mean: -19.883275151434578, timestamp: 2022-08-19 20:09:14.208673\n",
      "resetting env. episode 2819, reward total was -21.0. running mean: -19.894442399920234, timestamp: 2022-08-19 20:09:16.780705\n",
      "resetting env. episode 2820, reward total was -21.0. running mean: -19.905497975921033, timestamp: 2022-08-19 20:09:19.284733\n",
      "resetting env. episode 2821, reward total was -21.0. running mean: -19.916442996161823, timestamp: 2022-08-19 20:09:22.473770\n",
      "resetting env. episode 2822, reward total was -21.0. running mean: -19.927278566200204, timestamp: 2022-08-19 20:09:25.054804\n",
      "resetting env. episode 2823, reward total was -20.0. running mean: -19.9280057805382, timestamp: 2022-08-19 20:09:27.733834\n",
      "resetting env. episode 2824, reward total was -19.0. running mean: -19.91872572273282, timestamp: 2022-08-19 20:09:29.644858\n",
      "resetting env. episode 2825, reward total was -20.0. running mean: -19.91953846550549, timestamp: 2022-08-19 20:09:32.245889\n",
      "resetting env. episode 2826, reward total was -20.0. running mean: -19.920343080850433, timestamp: 2022-08-19 20:09:34.509913\n",
      "resetting env. episode 2827, reward total was -19.0. running mean: -19.911139650041928, timestamp: 2022-08-19 20:09:37.410947\n",
      "resetting env. episode 2828, reward total was -20.0. running mean: -19.912028253541507, timestamp: 2022-08-19 20:09:39.648976\n",
      "resetting env. episode 2829, reward total was -18.0. running mean: -19.892907971006093, timestamp: 2022-08-19 20:09:42.699009\n",
      "resetting env. episode 2830, reward total was -21.0. running mean: -19.90397889129603, timestamp: 2022-08-19 20:09:44.859034\n",
      "resetting env. episode 2831, reward total was -19.0. running mean: -19.894939102383074, timestamp: 2022-08-19 20:09:47.346062\n",
      "resetting env. episode 2832, reward total was -20.0. running mean: -19.895989711359242, timestamp: 2022-08-19 20:09:50.004097\n",
      "resetting env. episode 2833, reward total was -19.0. running mean: -19.88702981424565, timestamp: 2022-08-19 20:09:52.797128\n",
      "resetting env. episode 2834, reward total was -20.0. running mean: -19.888159516103194, timestamp: 2022-08-19 20:09:55.167159\n",
      "resetting env. episode 2835, reward total was -19.0. running mean: -19.87927792094216, timestamp: 2022-08-19 20:09:57.769189\n",
      "resetting env. episode 2836, reward total was -20.0. running mean: -19.880485141732738, timestamp: 2022-08-19 20:10:00.385221\n",
      "resetting env. episode 2837, reward total was -20.0. running mean: -19.88168029031541, timestamp: 2022-08-19 20:10:03.434255\n",
      "resetting env. episode 2838, reward total was -20.0. running mean: -19.882863487412255, timestamp: 2022-08-19 20:10:06.409289\n",
      "resetting env. episode 2839, reward total was -20.0. running mean: -19.884034852538132, timestamp: 2022-08-19 20:10:08.584317\n",
      "resetting env. episode 2840, reward total was -20.0. running mean: -19.885194504012752, timestamp: 2022-08-19 20:10:10.679338\n",
      "resetting env. episode 2841, reward total was -17.0. running mean: -19.856342558972624, timestamp: 2022-08-19 20:10:13.052366\n",
      "resetting env. episode 2842, reward total was -19.0. running mean: -19.8477791333829, timestamp: 2022-08-19 20:10:15.697398\n",
      "resetting env. episode 2843, reward total was -20.0. running mean: -19.84930134204907, timestamp: 2022-08-19 20:10:18.395431\n",
      "resetting env. episode 2844, reward total was -21.0. running mean: -19.86080832862858, timestamp: 2022-08-19 20:10:20.731457\n",
      "resetting env. episode 2845, reward total was -18.0. running mean: -19.842200245342294, timestamp: 2022-08-19 20:10:23.351489\n",
      "resetting env. episode 2846, reward total was -21.0. running mean: -19.853778242888872, timestamp: 2022-08-19 20:10:25.793519\n",
      "resetting env. episode 2847, reward total was -20.0. running mean: -19.85524046045998, timestamp: 2022-08-19 20:10:28.370548\n",
      "resetting env. episode 2848, reward total was -21.0. running mean: -19.86668805585538, timestamp: 2022-08-19 20:10:30.584578\n",
      "resetting env. episode 2849, reward total was -18.0. running mean: -19.848021175296825, timestamp: 2022-08-19 20:10:33.187609\n",
      "resetting env. episode 2850, reward total was -20.0. running mean: -19.849540963543856, timestamp: 2022-08-19 20:10:35.667632\n",
      "resetting env. episode 2851, reward total was -20.0. running mean: -19.851045553908417, timestamp: 2022-08-19 20:10:37.990662\n",
      "resetting env. episode 2852, reward total was -17.0. running mean: -19.822535098369336, timestamp: 2022-08-19 20:10:40.865744\n",
      "resetting env. episode 2853, reward total was -21.0. running mean: -19.834309747385642, timestamp: 2022-08-19 20:10:42.415762\n",
      "resetting env. episode 2854, reward total was -21.0. running mean: -19.845966649911787, timestamp: 2022-08-19 20:10:44.520791\n",
      "resetting env. episode 2855, reward total was -21.0. running mean: -19.85750698341267, timestamp: 2022-08-19 20:10:46.708814\n",
      "resetting env. episode 2856, reward total was -20.0. running mean: -19.85893191357854, timestamp: 2022-08-19 20:10:49.662850\n",
      "resetting env. episode 2857, reward total was -20.0. running mean: -19.860342594442756, timestamp: 2022-08-19 20:10:52.069876\n",
      "resetting env. episode 2858, reward total was -19.0. running mean: -19.85173916849833, timestamp: 2022-08-19 20:10:54.638908\n",
      "resetting env. episode 2859, reward total was -20.0. running mean: -19.853221776813346, timestamp: 2022-08-19 20:10:56.756935\n",
      "resetting env. episode 2860, reward total was -20.0. running mean: -19.854689559045212, timestamp: 2022-08-19 20:10:59.130958\n",
      "resetting env. episode 2861, reward total was -21.0. running mean: -19.86614266345476, timestamp: 2022-08-19 20:11:00.986982\n",
      "resetting env. episode 2862, reward total was -21.0. running mean: -19.877481236820213, timestamp: 2022-08-19 20:11:03.010008\n",
      "resetting env. episode 2863, reward total was -19.0. running mean: -19.86870642445201, timestamp: 2022-08-19 20:11:05.670044\n",
      "resetting env. episode 2864, reward total was -20.0. running mean: -19.87001936020749, timestamp: 2022-08-19 20:11:08.075070\n",
      "resetting env. episode 2865, reward total was -20.0. running mean: -19.871319166605414, timestamp: 2022-08-19 20:11:10.276094\n",
      "resetting env. episode 2866, reward total was -21.0. running mean: -19.88260597493936, timestamp: 2022-08-19 20:11:12.552124\n",
      "resetting env. episode 2867, reward total was -21.0. running mean: -19.893779915189967, timestamp: 2022-08-19 20:11:14.951155\n",
      "resetting env. episode 2868, reward total was -21.0. running mean: -19.90484211603807, timestamp: 2022-08-19 20:11:17.868188\n",
      "resetting env. episode 2869, reward total was -20.0. running mean: -19.905793694877687, timestamp: 2022-08-19 20:11:19.999214\n",
      "resetting env. episode 2870, reward total was -18.0. running mean: -19.88673575792891, timestamp: 2022-08-19 20:11:22.880245\n",
      "resetting env. episode 2871, reward total was -20.0. running mean: -19.88786840034962, timestamp: 2022-08-19 20:11:25.832284\n",
      "resetting env. episode 2872, reward total was -19.0. running mean: -19.878989716346126, timestamp: 2022-08-19 20:11:28.698315\n",
      "resetting env. episode 2873, reward total was -20.0. running mean: -19.880199819182664, timestamp: 2022-08-19 20:11:30.896343\n",
      "resetting env. episode 2874, reward total was -19.0. running mean: -19.87139782099084, timestamp: 2022-08-19 20:11:33.350369\n",
      "resetting env. episode 2875, reward total was -20.0. running mean: -19.87268384278093, timestamp: 2022-08-19 20:11:35.411394\n",
      "resetting env. episode 2876, reward total was -20.0. running mean: -19.87395700435312, timestamp: 2022-08-19 20:11:38.086429\n",
      "resetting env. episode 2877, reward total was -21.0. running mean: -19.885217434309588, timestamp: 2022-08-19 20:11:40.339453\n",
      "resetting env. episode 2878, reward total was -20.0. running mean: -19.886365259966492, timestamp: 2022-08-19 20:11:42.305476\n",
      "resetting env. episode 2879, reward total was -21.0. running mean: -19.897501607366827, timestamp: 2022-08-19 20:11:44.802504\n",
      "resetting env. episode 2880, reward total was -18.0. running mean: -19.87852659129316, timestamp: 2022-08-19 20:11:48.492548\n",
      "resetting env. episode 2881, reward total was -21.0. running mean: -19.88974132538023, timestamp: 2022-08-19 20:11:50.379572\n",
      "resetting env. episode 2882, reward total was -21.0. running mean: -19.900843912126426, timestamp: 2022-08-19 20:11:52.955601\n",
      "resetting env. episode 2883, reward total was -20.0. running mean: -19.90183547300516, timestamp: 2022-08-19 20:11:55.175157\n",
      "resetting env. episode 2884, reward total was -20.0. running mean: -19.90281711827511, timestamp: 2022-08-19 20:11:57.666178\n",
      "resetting env. episode 2885, reward total was -21.0. running mean: -19.91378894709236, timestamp: 2022-08-19 20:12:00.833217\n",
      "resetting env. episode 2886, reward total was -21.0. running mean: -19.92465105762144, timestamp: 2022-08-19 20:12:02.973240\n",
      "resetting env. episode 2887, reward total was -21.0. running mean: -19.935404547045227, timestamp: 2022-08-19 20:12:05.622275\n",
      "resetting env. episode 2888, reward total was -19.0. running mean: -19.926050501574775, timestamp: 2022-08-19 20:12:08.479306\n",
      "resetting env. episode 2889, reward total was -21.0. running mean: -19.93678999655903, timestamp: 2022-08-19 20:12:10.158330\n",
      "resetting env. episode 2890, reward total was -21.0. running mean: -19.94742209659344, timestamp: 2022-08-19 20:12:11.817347\n",
      "resetting env. episode 2891, reward total was -20.0. running mean: -19.947947875627502, timestamp: 2022-08-19 20:12:14.354378\n",
      "resetting env. episode 2892, reward total was -20.0. running mean: -19.948468396871228, timestamp: 2022-08-19 20:12:17.159409\n",
      "resetting env. episode 2893, reward total was -21.0. running mean: -19.958983712902516, timestamp: 2022-08-19 20:12:19.604441\n",
      "resetting env. episode 2894, reward total was -21.0. running mean: -19.96939387577349, timestamp: 2022-08-19 20:12:22.665472\n",
      "resetting env. episode 2895, reward total was -21.0. running mean: -19.979699937015756, timestamp: 2022-08-19 20:12:25.110502\n",
      "resetting env. episode 2896, reward total was -19.0. running mean: -19.9699029376456, timestamp: 2022-08-19 20:12:27.673533\n",
      "resetting env. episode 2897, reward total was -20.0. running mean: -19.97020390826914, timestamp: 2022-08-19 20:12:29.905560\n",
      "resetting env. episode 2898, reward total was -21.0. running mean: -19.98050186918645, timestamp: 2022-08-19 20:12:31.893584\n",
      "resetting env. episode 2899, reward total was -20.0. running mean: -19.980696850494585, timestamp: 2022-08-19 20:12:34.270613\n",
      "resetting env. episode 2900, reward total was -20.0. running mean: -19.98088988198964, timestamp: 2022-08-19 20:12:36.831640\n",
      "resetting env. episode 2901, reward total was -21.0. running mean: -19.991080983169745, timestamp: 2022-08-19 20:12:39.009665\n",
      "resetting env. episode 2902, reward total was -20.0. running mean: -19.99117017333805, timestamp: 2022-08-19 20:12:41.774701\n",
      "resetting env. episode 2903, reward total was -21.0. running mean: -20.001258471604668, timestamp: 2022-08-19 20:12:44.224730\n",
      "resetting env. episode 2904, reward total was -21.0. running mean: -20.011245886888624, timestamp: 2022-08-19 20:12:46.776766\n",
      "resetting env. episode 2905, reward total was -21.0. running mean: -20.021133428019738, timestamp: 2022-08-19 20:12:49.557791\n",
      "resetting env. episode 2906, reward total was -21.0. running mean: -20.03092209373954, timestamp: 2022-08-19 20:12:51.660820\n",
      "resetting env. episode 2907, reward total was -19.0. running mean: -20.020612872802147, timestamp: 2022-08-19 20:12:54.866854\n",
      "resetting env. episode 2908, reward total was -17.0. running mean: -19.99040674407413, timestamp: 2022-08-19 20:12:57.975890\n",
      "resetting env. episode 2909, reward total was -21.0. running mean: -20.00050267663339, timestamp: 2022-08-19 20:13:00.627926\n",
      "resetting env. episode 2910, reward total was -21.0. running mean: -20.010497649867055, timestamp: 2022-08-19 20:13:02.950949\n",
      "resetting env. episode 2911, reward total was -21.0. running mean: -20.020392673368384, timestamp: 2022-08-19 20:13:05.309977\n",
      "resetting env. episode 2912, reward total was -20.0. running mean: -20.020188746634698, timestamp: 2022-08-19 20:13:07.558004\n",
      "resetting env. episode 2913, reward total was -21.0. running mean: -20.029986859168353, timestamp: 2022-08-19 20:13:10.152034\n",
      "resetting env. episode 2914, reward total was -21.0. running mean: -20.03968699057667, timestamp: 2022-08-19 20:13:12.160059\n",
      "resetting env. episode 2915, reward total was -19.0. running mean: -20.029290120670904, timestamp: 2022-08-19 20:13:15.257093\n",
      "resetting env. episode 2916, reward total was -21.0. running mean: -20.038997219464196, timestamp: 2022-08-19 20:13:18.010127\n",
      "resetting env. episode 2917, reward total was -21.0. running mean: -20.048607247269555, timestamp: 2022-08-19 20:13:20.289152\n",
      "resetting env. episode 2918, reward total was -20.0. running mean: -20.048121174796858, timestamp: 2022-08-19 20:13:22.526180\n",
      "resetting env. episode 2919, reward total was -20.0. running mean: -20.047639963048887, timestamp: 2022-08-19 20:13:24.743206\n",
      "resetting env. episode 2920, reward total was -16.0. running mean: -20.0071635634184, timestamp: 2022-08-19 20:13:28.085245\n",
      "resetting env. episode 2921, reward total was -19.0. running mean: -19.997091927784215, timestamp: 2022-08-19 20:13:30.783277\n",
      "resetting env. episode 2922, reward total was -20.0. running mean: -19.997121008506372, timestamp: 2022-08-19 20:13:33.266307\n",
      "resetting env. episode 2923, reward total was -19.0. running mean: -19.98714979842131, timestamp: 2022-08-19 20:13:35.850340\n",
      "resetting env. episode 2924, reward total was -20.0. running mean: -19.987278300437097, timestamp: 2022-08-19 20:13:38.761371\n",
      "resetting env. episode 2925, reward total was -21.0. running mean: -19.99740551743273, timestamp: 2022-08-19 20:13:41.297401\n",
      "resetting env. episode 2926, reward total was -20.0. running mean: -19.9974314622584, timestamp: 2022-08-19 20:13:43.863435\n",
      "resetting env. episode 2927, reward total was -21.0. running mean: -20.00745714763582, timestamp: 2022-08-19 20:13:46.403461\n",
      "resetting env. episode 2928, reward total was -20.0. running mean: -20.00738257615946, timestamp: 2022-08-19 20:13:49.264496\n",
      "resetting env. episode 2929, reward total was -20.0. running mean: -20.007308750397865, timestamp: 2022-08-19 20:13:52.037528\n",
      "resetting env. episode 2930, reward total was -19.0. running mean: -19.99723566289389, timestamp: 2022-08-19 20:13:54.703558\n",
      "resetting env. episode 2931, reward total was -19.0. running mean: -19.98726330626495, timestamp: 2022-08-19 20:13:57.536597\n",
      "resetting env. episode 2932, reward total was -17.0. running mean: -19.9573906732023, timestamp: 2022-08-19 20:14:00.055625\n",
      "resetting env. episode 2933, reward total was -20.0. running mean: -19.957816766470277, timestamp: 2022-08-19 20:14:01.944644\n",
      "resetting env. episode 2934, reward total was -21.0. running mean: -19.968238598805574, timestamp: 2022-08-19 20:14:04.161672\n",
      "resetting env. episode 2935, reward total was -20.0. running mean: -19.968556212817518, timestamp: 2022-08-19 20:14:06.880703\n",
      "resetting env. episode 2936, reward total was -21.0. running mean: -19.978870650689345, timestamp: 2022-08-19 20:14:09.115729\n",
      "resetting env. episode 2937, reward total was -21.0. running mean: -19.989081944182452, timestamp: 2022-08-19 20:14:11.384758\n",
      "resetting env. episode 2938, reward total was -17.0. running mean: -19.959191124740627, timestamp: 2022-08-19 20:14:14.207792\n",
      "resetting env. episode 2939, reward total was -18.0. running mean: -19.93959921349322, timestamp: 2022-08-19 20:14:17.158827\n",
      "resetting env. episode 2940, reward total was -20.0. running mean: -19.94020322135829, timestamp: 2022-08-19 20:14:19.924855\n",
      "resetting env. episode 2941, reward total was -19.0. running mean: -19.930801189144706, timestamp: 2022-08-19 20:14:21.788878\n",
      "resetting env. episode 2942, reward total was -20.0. running mean: -19.93149317725326, timestamp: 2022-08-19 20:14:24.582912\n",
      "resetting env. episode 2943, reward total was -21.0. running mean: -19.942178245480726, timestamp: 2022-08-19 20:14:26.850939\n",
      "resetting env. episode 2944, reward total was -20.0. running mean: -19.94275646302592, timestamp: 2022-08-19 20:14:29.107969\n",
      "resetting env. episode 2945, reward total was -18.0. running mean: -19.92332889839566, timestamp: 2022-08-19 20:14:31.968002\n",
      "resetting env. episode 2946, reward total was -20.0. running mean: -19.9240956094117, timestamp: 2022-08-19 20:14:34.383549\n",
      "resetting env. episode 2947, reward total was -21.0. running mean: -19.934854653317586, timestamp: 2022-08-19 20:14:37.156584\n",
      "resetting env. episode 2948, reward total was -20.0. running mean: -19.93550610678441, timestamp: 2022-08-19 20:14:39.319613\n",
      "resetting env. episode 2949, reward total was -21.0. running mean: -19.946151045716565, timestamp: 2022-08-19 20:14:41.530637\n",
      "resetting env. episode 2950, reward total was -19.0. running mean: -19.9366895352594, timestamp: 2022-08-19 20:14:43.710659\n",
      "resetting env. episode 2951, reward total was -20.0. running mean: -19.937322639906807, timestamp: 2022-08-19 20:14:46.287693\n",
      "resetting env. episode 2952, reward total was -18.0. running mean: -19.91794941350774, timestamp: 2022-08-19 20:14:49.731733\n",
      "resetting env. episode 2953, reward total was -21.0. running mean: -19.928769919372662, timestamp: 2022-08-19 20:14:51.815755\n",
      "resetting env. episode 2954, reward total was -21.0. running mean: -19.939482220178938, timestamp: 2022-08-19 20:14:54.460788\n",
      "resetting env. episode 2955, reward total was -21.0. running mean: -19.95008739797715, timestamp: 2022-08-19 20:14:57.079821\n",
      "resetting env. episode 2956, reward total was -18.0. running mean: -19.930586523997377, timestamp: 2022-08-19 20:14:59.667847\n",
      "resetting env. episode 2957, reward total was -21.0. running mean: -19.941280658757403, timestamp: 2022-08-19 20:15:02.082401\n",
      "resetting env. episode 2958, reward total was -21.0. running mean: -19.95186785216983, timestamp: 2022-08-19 20:15:04.555435\n",
      "resetting env. episode 2959, reward total was -19.0. running mean: -19.942349173648132, timestamp: 2022-08-19 20:15:07.303463\n",
      "resetting env. episode 2960, reward total was -21.0. running mean: -19.95292568191165, timestamp: 2022-08-19 20:15:10.011494\n",
      "resetting env. episode 2961, reward total was -18.0. running mean: -19.933396425092536, timestamp: 2022-08-19 20:15:12.513528\n",
      "resetting env. episode 2962, reward total was -21.0. running mean: -19.94406246084161, timestamp: 2022-08-19 20:15:14.850551\n",
      "resetting env. episode 2963, reward total was -21.0. running mean: -19.954621836233194, timestamp: 2022-08-19 20:15:17.081579\n",
      "resetting env. episode 2964, reward total was -17.0. running mean: -19.925075617870863, timestamp: 2022-08-19 20:15:20.332616\n",
      "resetting env. episode 2965, reward total was -21.0. running mean: -19.935824861692154, timestamp: 2022-08-19 20:15:22.223638\n",
      "resetting env. episode 2966, reward total was -21.0. running mean: -19.946466613075234, timestamp: 2022-08-19 20:15:24.072658\n",
      "resetting env. episode 2967, reward total was -20.0. running mean: -19.947001946944482, timestamp: 2022-08-19 20:15:26.423688\n",
      "resetting env. episode 2968, reward total was -20.0. running mean: -19.947531927475037, timestamp: 2022-08-19 20:15:29.041716\n",
      "resetting env. episode 2969, reward total was -20.0. running mean: -19.948056608200286, timestamp: 2022-08-19 20:15:32.148754\n",
      "resetting env. episode 2970, reward total was -21.0. running mean: -19.958576042118285, timestamp: 2022-08-19 20:15:34.758783\n",
      "resetting env. episode 2971, reward total was -21.0. running mean: -19.968990281697103, timestamp: 2022-08-19 20:15:37.541822\n",
      "resetting env. episode 2972, reward total was -19.0. running mean: -19.959300378880133, timestamp: 2022-08-19 20:15:40.062849\n",
      "resetting env. episode 2973, reward total was -20.0. running mean: -19.95970737509133, timestamp: 2022-08-19 20:15:42.407874\n",
      "resetting env. episode 2974, reward total was -18.0. running mean: -19.940110301340418, timestamp: 2022-08-19 20:15:45.225907\n",
      "resetting env. episode 2975, reward total was -18.0. running mean: -19.920709198327014, timestamp: 2022-08-19 20:15:49.260954\n",
      "resetting env. episode 2976, reward total was -21.0. running mean: -19.931502106343743, timestamp: 2022-08-19 20:15:52.008986\n",
      "resetting env. episode 2977, reward total was -21.0. running mean: -19.942187085280306, timestamp: 2022-08-19 20:15:54.391015\n",
      "resetting env. episode 2978, reward total was -20.0. running mean: -19.942765214427503, timestamp: 2022-08-19 20:15:56.884044\n",
      "resetting env. episode 2979, reward total was -21.0. running mean: -19.953337562283227, timestamp: 2022-08-19 20:15:59.424072\n",
      "resetting env. episode 2980, reward total was -20.0. running mean: -19.953804186660395, timestamp: 2022-08-19 20:16:01.759099\n",
      "resetting env. episode 2981, reward total was -17.0. running mean: -19.924266144793794, timestamp: 2022-08-19 20:16:04.442131\n",
      "resetting env. episode 2982, reward total was -18.0. running mean: -19.905023483345857, timestamp: 2022-08-19 20:16:06.832162\n",
      "resetting env. episode 2983, reward total was -20.0. running mean: -19.9059732485124, timestamp: 2022-08-19 20:16:09.261187\n",
      "resetting env. episode 2984, reward total was -19.0. running mean: -19.896913516027276, timestamp: 2022-08-19 20:16:11.563218\n",
      "resetting env. episode 2985, reward total was -18.0. running mean: -19.877944380867003, timestamp: 2022-08-19 20:16:15.011255\n",
      "resetting env. episode 2986, reward total was -21.0. running mean: -19.889164937058332, timestamp: 2022-08-19 20:16:17.390282\n",
      "resetting env. episode 2987, reward total was -21.0. running mean: -19.90027328768775, timestamp: 2022-08-19 20:16:20.381318\n",
      "resetting env. episode 2988, reward total was -20.0. running mean: -19.90127055481087, timestamp: 2022-08-19 20:16:23.300352\n",
      "resetting env. episode 2989, reward total was -18.0. running mean: -19.88225784926276, timestamp: 2022-08-19 20:16:26.673394\n",
      "resetting env. episode 2990, reward total was -21.0. running mean: -19.893435270770134, timestamp: 2022-08-19 20:16:29.434422\n",
      "resetting env. episode 2991, reward total was -21.0. running mean: -19.904500918062432, timestamp: 2022-08-19 20:16:31.789455\n",
      "resetting env. episode 2992, reward total was -20.0. running mean: -19.905455908881805, timestamp: 2022-08-19 20:16:34.152478\n",
      "resetting env. episode 2993, reward total was -20.0. running mean: -19.906401349792986, timestamp: 2022-08-19 20:16:36.577506\n",
      "resetting env. episode 2994, reward total was -17.0. running mean: -19.877337336295057, timestamp: 2022-08-19 20:16:39.494541\n",
      "resetting env. episode 2995, reward total was -20.0. running mean: -19.878563962932105, timestamp: 2022-08-19 20:16:41.880568\n",
      "resetting env. episode 2996, reward total was -21.0. running mean: -19.889778323302785, timestamp: 2022-08-19 20:16:43.987594\n",
      "resetting env. episode 2997, reward total was -19.0. running mean: -19.880880540069757, timestamp: 2022-08-19 20:16:47.408635\n",
      "resetting env. episode 2998, reward total was -21.0. running mean: -19.89207173466906, timestamp: 2022-08-19 20:16:49.359657\n",
      "resetting env. episode 2999, reward total was -19.0. running mean: -19.88315101732237, timestamp: 2022-08-19 20:16:51.929686\n",
      "resetting env. episode 3000, reward total was -16.0. running mean: -19.844319507149144, timestamp: 2022-08-19 20:16:55.413726\n",
      "resetting env. episode 3001, reward total was -21.0. running mean: -19.855876312077655, timestamp: 2022-08-19 20:16:57.321750\n",
      "resetting env. episode 3002, reward total was -16.0. running mean: -19.81731754895688, timestamp: 2022-08-19 20:17:00.344787\n",
      "resetting env. episode 3003, reward total was -21.0. running mean: -19.82914437346731, timestamp: 2022-08-19 20:17:02.566811\n",
      "resetting env. episode 3004, reward total was -20.0. running mean: -19.830852929732636, timestamp: 2022-08-19 20:17:05.107844\n",
      "resetting env. episode 3005, reward total was -21.0. running mean: -19.84254440043531, timestamp: 2022-08-19 20:17:07.881876\n",
      "resetting env. episode 3006, reward total was -21.0. running mean: -19.85411895643096, timestamp: 2022-08-19 20:17:09.728896\n",
      "resetting env. episode 3007, reward total was -20.0. running mean: -19.85557776686665, timestamp: 2022-08-19 20:17:12.264923\n",
      "resetting env. episode 3008, reward total was -15.0. running mean: -19.80702198919798, timestamp: 2022-08-19 20:17:15.246960\n",
      "resetting env. episode 3009, reward total was -21.0. running mean: -19.818951769306, timestamp: 2022-08-19 20:17:17.367983\n",
      "resetting env. episode 3010, reward total was -21.0. running mean: -19.830762251612942, timestamp: 2022-08-19 20:17:19.759011\n",
      "resetting env. episode 3011, reward total was -18.0. running mean: -19.812454629096813, timestamp: 2022-08-19 20:17:22.276043\n",
      "resetting env. episode 3012, reward total was -20.0. running mean: -19.814330082805842, timestamp: 2022-08-19 20:17:24.014064\n",
      "resetting env. episode 3013, reward total was -19.0. running mean: -19.806186781977786, timestamp: 2022-08-19 20:17:26.864095\n",
      "resetting env. episode 3014, reward total was -21.0. running mean: -19.81812491415801, timestamp: 2022-08-19 20:17:29.294125\n",
      "resetting env. episode 3015, reward total was -19.0. running mean: -19.80994366501643, timestamp: 2022-08-19 20:17:32.013155\n",
      "resetting env. episode 3016, reward total was -18.0. running mean: -19.791844228366266, timestamp: 2022-08-19 20:17:34.519184\n",
      "resetting env. episode 3017, reward total was -19.0. running mean: -19.783925786082605, timestamp: 2022-08-19 20:17:37.121215\n",
      "resetting env. episode 3018, reward total was -18.0. running mean: -19.766086528221777, timestamp: 2022-08-19 20:17:40.187251\n",
      "resetting env. episode 3019, reward total was -21.0. running mean: -19.77842566293956, timestamp: 2022-08-19 20:17:42.314274\n",
      "resetting env. episode 3020, reward total was -21.0. running mean: -19.790641406310165, timestamp: 2022-08-19 20:17:44.574298\n",
      "resetting env. episode 3021, reward total was -21.0. running mean: -19.802734992247064, timestamp: 2022-08-19 20:17:46.879330\n",
      "resetting env. episode 3022, reward total was -17.0. running mean: -19.774707642324596, timestamp: 2022-08-19 20:17:49.893361\n",
      "resetting env. episode 3023, reward total was -20.0. running mean: -19.776960565901348, timestamp: 2022-08-19 20:17:52.338389\n",
      "resetting env. episode 3024, reward total was -19.0. running mean: -19.769190960242337, timestamp: 2022-08-19 20:17:55.106422\n",
      "resetting env. episode 3025, reward total was -21.0. running mean: -19.781499050639916, timestamp: 2022-08-19 20:17:57.440449\n",
      "resetting env. episode 3026, reward total was -21.0. running mean: -19.79368406013352, timestamp: 2022-08-19 20:17:59.639477\n",
      "resetting env. episode 3027, reward total was -20.0. running mean: -19.79574721953218, timestamp: 2022-08-19 20:18:01.833499\n",
      "resetting env. episode 3028, reward total was -20.0. running mean: -19.797789747336857, timestamp: 2022-08-19 20:18:04.331534\n",
      "resetting env. episode 3029, reward total was -19.0. running mean: -19.78981184986349, timestamp: 2022-08-19 20:18:07.321563\n",
      "resetting env. episode 3030, reward total was -21.0. running mean: -19.801913731364856, timestamp: 2022-08-19 20:18:10.064596\n",
      "resetting env. episode 3031, reward total was -20.0. running mean: -19.803894594051208, timestamp: 2022-08-19 20:18:12.776626\n",
      "resetting env. episode 3032, reward total was -19.0. running mean: -19.795855648110695, timestamp: 2022-08-19 20:18:15.440657\n",
      "resetting env. episode 3033, reward total was -18.0. running mean: -19.777897091629587, timestamp: 2022-08-19 20:18:18.713696\n",
      "resetting env. episode 3034, reward total was -21.0. running mean: -19.79011812071329, timestamp: 2022-08-19 20:18:21.246725\n",
      "resetting env. episode 3035, reward total was -21.0. running mean: -19.80221693950616, timestamp: 2022-08-19 20:18:23.627752\n",
      "resetting env. episode 3036, reward total was -18.0. running mean: -19.784194770111096, timestamp: 2022-08-19 20:18:26.356788\n",
      "resetting env. episode 3037, reward total was -20.0. running mean: -19.786352822409984, timestamp: 2022-08-19 20:18:29.080817\n",
      "resetting env. episode 3038, reward total was -20.0. running mean: -19.788489294185883, timestamp: 2022-08-19 20:18:31.611846\n",
      "resetting env. episode 3039, reward total was -21.0. running mean: -19.800604401244026, timestamp: 2022-08-19 20:18:34.134878\n",
      "resetting env. episode 3040, reward total was -20.0. running mean: -19.802598357231584, timestamp: 2022-08-19 20:18:36.393901\n",
      "resetting env. episode 3041, reward total was -21.0. running mean: -19.81457237365927, timestamp: 2022-08-19 20:18:39.029932\n",
      "resetting env. episode 3042, reward total was -20.0. running mean: -19.816426649922676, timestamp: 2022-08-19 20:18:41.589961\n",
      "resetting env. episode 3043, reward total was -19.0. running mean: -19.80826238342345, timestamp: 2022-08-19 20:18:44.073989\n",
      "resetting env. episode 3044, reward total was -21.0. running mean: -19.820179759589216, timestamp: 2022-08-19 20:18:46.888544\n",
      "resetting env. episode 3045, reward total was -21.0. running mean: -19.831977961993324, timestamp: 2022-08-19 20:18:49.324100\n",
      "resetting env. episode 3046, reward total was -18.0. running mean: -19.81365818237339, timestamp: 2022-08-19 20:18:52.015134\n",
      "resetting env. episode 3047, reward total was -20.0. running mean: -19.815521600549655, timestamp: 2022-08-19 20:18:54.318159\n",
      "resetting env. episode 3048, reward total was -21.0. running mean: -19.82736638454416, timestamp: 2022-08-19 20:18:56.928188\n",
      "resetting env. episode 3049, reward total was -20.0. running mean: -19.829092720698718, timestamp: 2022-08-19 20:18:59.228269\n",
      "resetting env. episode 3050, reward total was -20.0. running mean: -19.83080179349173, timestamp: 2022-08-19 20:19:02.143298\n",
      "resetting env. episode 3051, reward total was -21.0. running mean: -19.842493775556814, timestamp: 2022-08-19 20:19:04.373324\n",
      "resetting env. episode 3052, reward total was -18.0. running mean: -19.824068837801246, timestamp: 2022-08-19 20:19:07.101357\n",
      "resetting env. episode 3053, reward total was -20.0. running mean: -19.82582814942323, timestamp: 2022-08-19 20:19:10.051390\n",
      "resetting env. episode 3054, reward total was -20.0. running mean: -19.827569867928997, timestamp: 2022-08-19 20:19:12.371416\n",
      "resetting env. episode 3055, reward total was -20.0. running mean: -19.829294169249707, timestamp: 2022-08-19 20:19:13.947435\n",
      "resetting env. episode 3056, reward total was -20.0. running mean: -19.83100122755721, timestamp: 2022-08-19 20:19:16.415463\n",
      "resetting env. episode 3057, reward total was -21.0. running mean: -19.842691215281636, timestamp: 2022-08-19 20:19:19.176495\n",
      "resetting env. episode 3058, reward total was -20.0. running mean: -19.84426430312882, timestamp: 2022-08-19 20:19:22.080529\n",
      "resetting env. episode 3059, reward total was -21.0. running mean: -19.855821660097533, timestamp: 2022-08-19 20:19:25.038565\n",
      "resetting env. episode 3060, reward total was -21.0. running mean: -19.867263443496558, timestamp: 2022-08-19 20:19:27.730594\n",
      "resetting env. episode 3061, reward total was -19.0. running mean: -19.858590809061592, timestamp: 2022-08-19 20:19:29.929618\n",
      "resetting env. episode 3062, reward total was -20.0. running mean: -19.860004900970974, timestamp: 2022-08-19 20:19:32.687650\n",
      "resetting env. episode 3063, reward total was -18.0. running mean: -19.841404851961265, timestamp: 2022-08-19 20:19:35.197678\n",
      "resetting env. episode 3064, reward total was -19.0. running mean: -19.832990803441653, timestamp: 2022-08-19 20:19:37.856709\n",
      "resetting env. episode 3065, reward total was -20.0. running mean: -19.834660895407236, timestamp: 2022-08-19 20:19:40.263740\n",
      "resetting env. episode 3066, reward total was -21.0. running mean: -19.846314286453165, timestamp: 2022-08-19 20:19:42.896767\n",
      "resetting env. episode 3067, reward total was -21.0. running mean: -19.857851143588633, timestamp: 2022-08-19 20:19:45.518798\n",
      "resetting env. episode 3068, reward total was -21.0. running mean: -19.869272632152747, timestamp: 2022-08-19 20:19:47.927829\n",
      "resetting env. episode 3069, reward total was -21.0. running mean: -19.88057990583122, timestamp: 2022-08-19 20:19:50.201855\n",
      "resetting env. episode 3070, reward total was -20.0. running mean: -19.881774106772905, timestamp: 2022-08-19 20:19:52.849883\n",
      "resetting env. episode 3071, reward total was -20.0. running mean: -19.882956365705176, timestamp: 2022-08-19 20:19:55.668915\n",
      "resetting env. episode 3072, reward total was -21.0. running mean: -19.894126802048124, timestamp: 2022-08-19 20:19:58.369946\n",
      "resetting env. episode 3073, reward total was -19.0. running mean: -19.885185534027645, timestamp: 2022-08-19 20:20:01.444981\n",
      "resetting env. episode 3074, reward total was -20.0. running mean: -19.886333678687368, timestamp: 2022-08-19 20:20:04.994023\n",
      "resetting env. episode 3075, reward total was -20.0. running mean: -19.887470341900492, timestamp: 2022-08-19 20:20:07.808055\n",
      "resetting env. episode 3076, reward total was -17.0. running mean: -19.85859563848149, timestamp: 2022-08-19 20:20:10.488084\n",
      "resetting env. episode 3077, reward total was -21.0. running mean: -19.870009682096676, timestamp: 2022-08-19 20:20:12.309106\n",
      "resetting env. episode 3078, reward total was -18.0. running mean: -19.851309585275708, timestamp: 2022-08-19 20:20:15.222141\n",
      "resetting env. episode 3079, reward total was -18.0. running mean: -19.83279648942295, timestamp: 2022-08-19 20:20:18.523175\n",
      "resetting env. episode 3080, reward total was -21.0. running mean: -19.844468524528722, timestamp: 2022-08-19 20:20:21.254208\n",
      "resetting env. episode 3081, reward total was -20.0. running mean: -19.846023839283433, timestamp: 2022-08-19 20:20:23.793238\n",
      "resetting env. episode 3082, reward total was -19.0. running mean: -19.8375636008906, timestamp: 2022-08-19 20:20:26.452269\n",
      "resetting env. episode 3083, reward total was -20.0. running mean: -19.839187964881695, timestamp: 2022-08-19 20:20:28.980300\n",
      "resetting env. episode 3084, reward total was -21.0. running mean: -19.85079608523288, timestamp: 2022-08-19 20:20:31.058323\n",
      "resetting env. episode 3085, reward total was -20.0. running mean: -19.85228812438055, timestamp: 2022-08-19 20:20:34.032356\n",
      "resetting env. episode 3086, reward total was -20.0. running mean: -19.853765243136742, timestamp: 2022-08-19 20:20:36.083381\n",
      "resetting env. episode 3087, reward total was -21.0. running mean: -19.865227590705373, timestamp: 2022-08-19 20:20:38.268403\n",
      "resetting env. episode 3088, reward total was -20.0. running mean: -19.866575314798318, timestamp: 2022-08-19 20:20:40.890433\n",
      "resetting env. episode 3089, reward total was -19.0. running mean: -19.857909561650334, timestamp: 2022-08-19 20:20:43.319462\n",
      "resetting env. episode 3090, reward total was -18.0. running mean: -19.839330466033832, timestamp: 2022-08-19 20:20:46.515500\n",
      "resetting env. episode 3091, reward total was -21.0. running mean: -19.850937161373494, timestamp: 2022-08-19 20:20:49.621534\n",
      "resetting env. episode 3092, reward total was -21.0. running mean: -19.86242778975976, timestamp: 2022-08-19 20:20:52.384567\n",
      "resetting env. episode 3093, reward total was -20.0. running mean: -19.863803511862162, timestamp: 2022-08-19 20:20:54.987597\n",
      "resetting env. episode 3094, reward total was -21.0. running mean: -19.87516547674354, timestamp: 2022-08-19 20:20:58.072634\n",
      "resetting env. episode 3095, reward total was -20.0. running mean: -19.876413821976104, timestamp: 2022-08-19 20:21:01.256668\n",
      "resetting env. episode 3096, reward total was -20.0. running mean: -19.877649683756342, timestamp: 2022-08-19 20:21:04.052700\n",
      "resetting env. episode 3097, reward total was -20.0. running mean: -19.878873186918778, timestamp: 2022-08-19 20:21:06.480727\n",
      "resetting env. episode 3098, reward total was -21.0. running mean: -19.89008445504959, timestamp: 2022-08-19 20:21:08.804754\n",
      "resetting env. episode 3099, reward total was -17.0. running mean: -19.861183610499094, timestamp: 2022-08-19 20:21:11.603786\n",
      "resetting env. episode 3100, reward total was -20.0. running mean: -19.8625717743941, timestamp: 2022-08-19 20:21:13.714809\n",
      "resetting env. episode 3101, reward total was -20.0. running mean: -19.86394605665016, timestamp: 2022-08-19 20:21:16.143839\n",
      "resetting env. episode 3102, reward total was -19.0. running mean: -19.85530659608366, timestamp: 2022-08-19 20:21:19.231875\n",
      "resetting env. episode 3103, reward total was -18.0. running mean: -19.836753530122824, timestamp: 2022-08-19 20:21:21.963905\n",
      "resetting env. episode 3104, reward total was -21.0. running mean: -19.848385994821598, timestamp: 2022-08-19 20:21:24.410933\n",
      "resetting env. episode 3105, reward total was -21.0. running mean: -19.859902134873384, timestamp: 2022-08-19 20:21:26.646962\n",
      "resetting env. episode 3106, reward total was -20.0. running mean: -19.86130311352465, timestamp: 2022-08-19 20:21:29.103989\n",
      "resetting env. episode 3107, reward total was -21.0. running mean: -19.872690082389404, timestamp: 2022-08-19 20:21:31.622021\n",
      "resetting env. episode 3108, reward total was -20.0. running mean: -19.87396318156551, timestamp: 2022-08-19 20:21:34.137042\n",
      "resetting env. episode 3109, reward total was -21.0. running mean: -19.885223549749856, timestamp: 2022-08-19 20:21:36.278068\n",
      "resetting env. episode 3110, reward total was -20.0. running mean: -19.886371314252358, timestamp: 2022-08-19 20:21:38.834095\n",
      "resetting env. episode 3111, reward total was -21.0. running mean: -19.897507601109837, timestamp: 2022-08-19 20:21:41.574127\n",
      "resetting env. episode 3112, reward total was -21.0. running mean: -19.90853252509874, timestamp: 2022-08-19 20:21:44.086159\n",
      "resetting env. episode 3113, reward total was -21.0. running mean: -19.919447199847752, timestamp: 2022-08-19 20:21:46.625185\n",
      "resetting env. episode 3114, reward total was -19.0. running mean: -19.910252727849276, timestamp: 2022-08-19 20:21:49.026212\n",
      "resetting env. episode 3115, reward total was -21.0. running mean: -19.921150200570782, timestamp: 2022-08-19 20:21:51.532242\n",
      "resetting env. episode 3116, reward total was -19.0. running mean: -19.911938698565077, timestamp: 2022-08-19 20:21:54.487274\n",
      "resetting env. episode 3117, reward total was -21.0. running mean: -19.922819311579428, timestamp: 2022-08-19 20:21:56.713301\n",
      "resetting env. episode 3118, reward total was -19.0. running mean: -19.913591118463636, timestamp: 2022-08-19 20:21:59.095331\n",
      "resetting env. episode 3119, reward total was -19.0. running mean: -19.904455207279, timestamp: 2022-08-19 20:22:01.486355\n",
      "resetting env. episode 3120, reward total was -20.0. running mean: -19.905410655206207, timestamp: 2022-08-19 20:22:03.805380\n",
      "resetting env. episode 3121, reward total was -21.0. running mean: -19.916356548654147, timestamp: 2022-08-19 20:22:06.434410\n",
      "resetting env. episode 3122, reward total was -16.0. running mean: -19.877192983167603, timestamp: 2022-08-19 20:22:09.370446\n",
      "resetting env. episode 3123, reward total was -19.0. running mean: -19.86842105333593, timestamp: 2022-08-19 20:22:11.391469\n",
      "resetting env. episode 3124, reward total was -19.0. running mean: -19.859736842802572, timestamp: 2022-08-19 20:22:14.056499\n",
      "resetting env. episode 3125, reward total was -20.0. running mean: -19.861139474374546, timestamp: 2022-08-19 20:22:16.330525\n",
      "resetting env. episode 3126, reward total was -21.0. running mean: -19.8725280796308, timestamp: 2022-08-19 20:22:18.535551\n",
      "resetting env. episode 3127, reward total was -19.0. running mean: -19.863802798834495, timestamp: 2022-08-19 20:22:21.938589\n",
      "resetting env. episode 3128, reward total was -19.0. running mean: -19.85516477084615, timestamp: 2022-08-19 20:22:24.543619\n",
      "resetting env. episode 3129, reward total was -21.0. running mean: -19.86661312313769, timestamp: 2022-08-19 20:22:26.830646\n",
      "resetting env. episode 3130, reward total was -20.0. running mean: -19.86794699190631, timestamp: 2022-08-19 20:22:29.167670\n",
      "resetting env. episode 3131, reward total was -17.0. running mean: -19.83926752198725, timestamp: 2022-08-19 20:22:31.992703\n",
      "resetting env. episode 3132, reward total was -19.0. running mean: -19.83087484676738, timestamp: 2022-08-19 20:22:34.535732\n",
      "resetting env. episode 3133, reward total was -20.0. running mean: -19.832566098299704, timestamp: 2022-08-19 20:22:36.682757\n",
      "resetting env. episode 3134, reward total was -21.0. running mean: -19.844240437316707, timestamp: 2022-08-19 20:22:39.459308\n",
      "resetting env. episode 3135, reward total was -16.0. running mean: -19.80579803294354, timestamp: 2022-08-19 20:22:42.814347\n",
      "resetting env. episode 3136, reward total was -19.0. running mean: -19.797740052614106, timestamp: 2022-08-19 20:22:45.187372\n",
      "resetting env. episode 3137, reward total was -21.0. running mean: -19.809762652087965, timestamp: 2022-08-19 20:22:47.579404\n",
      "resetting env. episode 3138, reward total was -20.0. running mean: -19.811665025567084, timestamp: 2022-08-19 20:22:49.745428\n",
      "resetting env. episode 3139, reward total was -20.0. running mean: -19.813548375311413, timestamp: 2022-08-19 20:22:52.767459\n",
      "resetting env. episode 3140, reward total was -18.0. running mean: -19.7954128915583, timestamp: 2022-08-19 20:22:55.672493\n",
      "resetting env. episode 3141, reward total was -18.0. running mean: -19.777458762642716, timestamp: 2022-08-19 20:22:58.680527\n",
      "resetting env. episode 3142, reward total was -19.0. running mean: -19.76968417501629, timestamp: 2022-08-19 20:23:00.944555\n",
      "resetting env. episode 3143, reward total was -21.0. running mean: -19.78198733326613, timestamp: 2022-08-19 20:23:03.134577\n",
      "resetting env. episode 3144, reward total was -20.0. running mean: -19.784167459933467, timestamp: 2022-08-19 20:23:05.919612\n",
      "resetting env. episode 3145, reward total was -20.0. running mean: -19.78632578533413, timestamp: 2022-08-19 20:23:08.717640\n",
      "resetting env. episode 3146, reward total was -20.0. running mean: -19.78846252748079, timestamp: 2022-08-19 20:23:11.331670\n",
      "resetting env. episode 3147, reward total was -18.0. running mean: -19.770577902205982, timestamp: 2022-08-19 20:23:14.319703\n",
      "resetting env. episode 3148, reward total was -18.0. running mean: -19.752872123183923, timestamp: 2022-08-19 20:23:17.873746\n",
      "resetting env. episode 3149, reward total was -19.0. running mean: -19.745343401952084, timestamp: 2022-08-19 20:23:20.203772\n",
      "resetting env. episode 3150, reward total was -19.0. running mean: -19.737889967932563, timestamp: 2022-08-19 20:23:22.951801\n",
      "resetting env. episode 3151, reward total was -21.0. running mean: -19.75051106825324, timestamp: 2022-08-19 20:23:25.894833\n",
      "resetting env. episode 3152, reward total was -21.0. running mean: -19.76300595757071, timestamp: 2022-08-19 20:23:28.539865\n",
      "resetting env. episode 3153, reward total was -20.0. running mean: -19.765375897995, timestamp: 2022-08-19 20:23:31.087894\n",
      "resetting env. episode 3154, reward total was -20.0. running mean: -19.76772213901505, timestamp: 2022-08-19 20:23:33.880460\n",
      "resetting env. episode 3155, reward total was -20.0. running mean: -19.770044917624897, timestamp: 2022-08-19 20:23:36.607489\n",
      "resetting env. episode 3156, reward total was -19.0. running mean: -19.76234446844865, timestamp: 2022-08-19 20:23:39.136516\n",
      "resetting env. episode 3157, reward total was -21.0. running mean: -19.774721023764165, timestamp: 2022-08-19 20:23:41.351546\n",
      "resetting env. episode 3158, reward total was -21.0. running mean: -19.786973813526526, timestamp: 2022-08-19 20:23:43.272566\n",
      "resetting env. episode 3159, reward total was -21.0. running mean: -19.799104075391263, timestamp: 2022-08-19 20:23:45.688593\n",
      "resetting env. episode 3160, reward total was -19.0. running mean: -19.791113034637352, timestamp: 2022-08-19 20:23:48.025150\n",
      "resetting env. episode 3161, reward total was -19.0. running mean: -19.78320190429098, timestamp: 2022-08-19 20:23:50.588177\n",
      "resetting env. episode 3162, reward total was -21.0. running mean: -19.79536988524807, timestamp: 2022-08-19 20:23:53.199207\n",
      "resetting env. episode 3163, reward total was -18.0. running mean: -19.77741618639559, timestamp: 2022-08-19 20:23:56.659249\n",
      "resetting env. episode 3164, reward total was -19.0. running mean: -19.769642024531635, timestamp: 2022-08-19 20:23:59.209280\n",
      "resetting env. episode 3165, reward total was -19.0. running mean: -19.761945604286318, timestamp: 2022-08-19 20:24:02.258311\n",
      "resetting env. episode 3166, reward total was -21.0. running mean: -19.774326148243457, timestamp: 2022-08-19 20:24:04.716341\n",
      "resetting env. episode 3167, reward total was -19.0. running mean: -19.766582886761025, timestamp: 2022-08-19 20:24:07.682897\n",
      "resetting env. episode 3168, reward total was -21.0. running mean: -19.778917057893416, timestamp: 2022-08-19 20:24:09.933924\n",
      "resetting env. episode 3169, reward total was -21.0. running mean: -19.79112788731448, timestamp: 2022-08-19 20:24:11.814948\n",
      "resetting env. episode 3170, reward total was -21.0. running mean: -19.803216608441335, timestamp: 2022-08-19 20:24:14.074973\n",
      "resetting env. episode 3171, reward total was -17.0. running mean: -19.775184442356924, timestamp: 2022-08-19 20:24:16.992006\n",
      "resetting env. episode 3172, reward total was -18.0. running mean: -19.757432597933356, timestamp: 2022-08-19 20:24:19.634039\n",
      "resetting env. episode 3173, reward total was -19.0. running mean: -19.74985827195402, timestamp: 2022-08-19 20:24:21.935066\n",
      "resetting env. episode 3174, reward total was -19.0. running mean: -19.742359689234483, timestamp: 2022-08-19 20:24:24.653097\n",
      "resetting env. episode 3175, reward total was -19.0. running mean: -19.73493609234214, timestamp: 2022-08-19 20:24:26.925119\n",
      "resetting env. episode 3176, reward total was -20.0. running mean: -19.737586731418716, timestamp: 2022-08-19 20:24:29.614679\n",
      "resetting env. episode 3177, reward total was -20.0. running mean: -19.74021086410453, timestamp: 2022-08-19 20:24:31.813708\n",
      "resetting env. episode 3178, reward total was -20.0. running mean: -19.742808755463482, timestamp: 2022-08-19 20:24:34.394734\n",
      "resetting env. episode 3179, reward total was -20.0. running mean: -19.745380667908847, timestamp: 2022-08-19 20:24:37.251769\n",
      "resetting env. episode 3180, reward total was -21.0. running mean: -19.75792686122976, timestamp: 2022-08-19 20:24:39.849799\n",
      "resetting env. episode 3181, reward total was -21.0. running mean: -19.770347592617462, timestamp: 2022-08-19 20:24:42.280825\n",
      "resetting env. episode 3182, reward total was -21.0. running mean: -19.782644116691287, timestamp: 2022-08-19 20:24:44.681379\n",
      "resetting env. episode 3183, reward total was -18.0. running mean: -19.764817675524373, timestamp: 2022-08-19 20:24:47.531412\n",
      "resetting env. episode 3184, reward total was -20.0. running mean: -19.767169498769128, timestamp: 2022-08-19 20:24:50.022441\n",
      "resetting env. episode 3185, reward total was -20.0. running mean: -19.769497803781437, timestamp: 2022-08-19 20:24:52.578469\n",
      "resetting env. episode 3186, reward total was -21.0. running mean: -19.781802825743625, timestamp: 2022-08-19 20:24:54.815500\n",
      "resetting env. episode 3187, reward total was -21.0. running mean: -19.79398479748619, timestamp: 2022-08-19 20:24:56.727520\n",
      "resetting env. episode 3188, reward total was -19.0. running mean: -19.78604494951133, timestamp: 2022-08-19 20:25:00.275557\n",
      "resetting env. episode 3189, reward total was -17.0. running mean: -19.758184500016217, timestamp: 2022-08-19 20:25:03.251594\n",
      "resetting env. episode 3190, reward total was -21.0. running mean: -19.770602655016056, timestamp: 2022-08-19 20:25:06.308629\n",
      "resetting env. episode 3191, reward total was -21.0. running mean: -19.782896628465895, timestamp: 2022-08-19 20:25:09.158664\n",
      "resetting env. episode 3192, reward total was -18.0. running mean: -19.765067662181234, timestamp: 2022-08-19 20:25:12.133696\n",
      "resetting env. episode 3193, reward total was -20.0. running mean: -19.76741698555942, timestamp: 2022-08-19 20:25:14.428723\n",
      "resetting env. episode 3194, reward total was -20.0. running mean: -19.769742815703825, timestamp: 2022-08-19 20:25:16.647749\n",
      "resetting env. episode 3195, reward total was -20.0. running mean: -19.772045387546786, timestamp: 2022-08-19 20:25:18.905775\n",
      "resetting env. episode 3196, reward total was -18.0. running mean: -19.754324933671317, timestamp: 2022-08-19 20:25:21.342806\n",
      "resetting env. episode 3197, reward total was -20.0. running mean: -19.7567816843346, timestamp: 2022-08-19 20:25:23.730831\n",
      "resetting env. episode 3198, reward total was -21.0. running mean: -19.769213867491256, timestamp: 2022-08-19 20:25:26.275862\n",
      "resetting env. episode 3199, reward total was -20.0. running mean: -19.771521728816342, timestamp: 2022-08-19 20:25:28.844895\n",
      "resetting env. episode 3200, reward total was -19.0. running mean: -19.76380651152818, timestamp: 2022-08-19 20:25:32.232931\n",
      "resetting env. episode 3201, reward total was -20.0. running mean: -19.766168446412898, timestamp: 2022-08-19 20:25:35.025964\n",
      "resetting env. episode 3202, reward total was -21.0. running mean: -19.77850676194877, timestamp: 2022-08-19 20:25:37.339990\n",
      "resetting env. episode 3203, reward total was -20.0. running mean: -19.78072169432928, timestamp: 2022-08-19 20:25:39.304019\n",
      "resetting env. episode 3204, reward total was -18.0. running mean: -19.762914477385987, timestamp: 2022-08-19 20:25:41.809043\n",
      "resetting env. episode 3205, reward total was -21.0. running mean: -19.77528533261213, timestamp: 2022-08-19 20:25:43.972072\n",
      "resetting env. episode 3206, reward total was -21.0. running mean: -19.787532479286007, timestamp: 2022-08-19 20:25:46.019096\n",
      "resetting env. episode 3207, reward total was -20.0. running mean: -19.789657154493145, timestamp: 2022-08-19 20:25:48.486126\n",
      "resetting env. episode 3208, reward total was -17.0. running mean: -19.761760582948217, timestamp: 2022-08-19 20:25:51.895165\n",
      "resetting env. episode 3209, reward total was -21.0. running mean: -19.774142977118736, timestamp: 2022-08-19 20:25:53.919185\n",
      "resetting env. episode 3210, reward total was -21.0. running mean: -19.78640154734755, timestamp: 2022-08-19 20:25:56.564215\n",
      "resetting env. episode 3211, reward total was -19.0. running mean: -19.778537531874075, timestamp: 2022-08-19 20:25:59.451777\n",
      "resetting env. episode 3212, reward total was -19.0. running mean: -19.770752156555336, timestamp: 2022-08-19 20:26:01.853807\n",
      "resetting env. episode 3213, reward total was -20.0. running mean: -19.77304463498978, timestamp: 2022-08-19 20:26:04.358834\n",
      "resetting env. episode 3214, reward total was -18.0. running mean: -19.755314188639883, timestamp: 2022-08-19 20:26:07.398871\n",
      "resetting env. episode 3215, reward total was -20.0. running mean: -19.757761046753483, timestamp: 2022-08-19 20:26:09.437894\n",
      "resetting env. episode 3216, reward total was -20.0. running mean: -19.76018343628595, timestamp: 2022-08-19 20:26:12.439929\n",
      "resetting env. episode 3217, reward total was -19.0. running mean: -19.75258160192309, timestamp: 2022-08-19 20:26:14.920956\n",
      "resetting env. episode 3218, reward total was -21.0. running mean: -19.76505578590386, timestamp: 2022-08-19 20:26:17.478990\n",
      "resetting env. episode 3219, reward total was -21.0. running mean: -19.777405228044824, timestamp: 2022-08-19 20:26:20.138022\n",
      "resetting env. episode 3220, reward total was -21.0. running mean: -19.789631175764377, timestamp: 2022-08-19 20:26:22.607045\n",
      "resetting env. episode 3221, reward total was -20.0. running mean: -19.79173486400673, timestamp: 2022-08-19 20:26:25.402079\n",
      "resetting env. episode 3222, reward total was -21.0. running mean: -19.803817515366664, timestamp: 2022-08-19 20:26:28.045110\n",
      "resetting env. episode 3223, reward total was -20.0. running mean: -19.805779340212997, timestamp: 2022-08-19 20:26:30.471142\n",
      "resetting env. episode 3224, reward total was -20.0. running mean: -19.807721546810868, timestamp: 2022-08-19 20:26:32.576163\n",
      "resetting env. episode 3225, reward total was -16.0. running mean: -19.769644331342757, timestamp: 2022-08-19 20:26:35.432197\n",
      "resetting env. episode 3226, reward total was -20.0. running mean: -19.771947888029327, timestamp: 2022-08-19 20:26:37.975228\n",
      "resetting env. episode 3227, reward total was -21.0. running mean: -19.784228409149033, timestamp: 2022-08-19 20:26:39.986253\n",
      "resetting env. episode 3228, reward total was -19.0. running mean: -19.776386125057545, timestamp: 2022-08-19 20:26:42.546281\n",
      "resetting env. episode 3229, reward total was -21.0. running mean: -19.78862226380697, timestamp: 2022-08-19 20:26:44.950308\n",
      "resetting env. episode 3230, reward total was -19.0. running mean: -19.780736041168904, timestamp: 2022-08-19 20:26:47.611339\n",
      "resetting env. episode 3231, reward total was -21.0. running mean: -19.792928680757214, timestamp: 2022-08-19 20:26:50.035369\n",
      "resetting env. episode 3232, reward total was -20.0. running mean: -19.79499939394964, timestamp: 2022-08-19 20:26:52.554402\n",
      "resetting env. episode 3233, reward total was -19.0. running mean: -19.787049400010147, timestamp: 2022-08-19 20:26:55.541433\n",
      "resetting env. episode 3234, reward total was -21.0. running mean: -19.799178906010045, timestamp: 2022-08-19 20:26:58.586468\n",
      "resetting env. episode 3235, reward total was -18.0. running mean: -19.781187116949944, timestamp: 2022-08-19 20:27:01.680508\n",
      "resetting env. episode 3236, reward total was -20.0. running mean: -19.783375245780444, timestamp: 2022-08-19 20:27:03.911534\n",
      "resetting env. episode 3237, reward total was -21.0. running mean: -19.79554149332264, timestamp: 2022-08-19 20:27:06.291558\n",
      "resetting env. episode 3238, reward total was -20.0. running mean: -19.797586078389415, timestamp: 2022-08-19 20:27:08.936595\n",
      "resetting env. episode 3239, reward total was -21.0. running mean: -19.80961021760552, timestamp: 2022-08-19 20:27:11.045615\n",
      "resetting env. episode 3240, reward total was -14.0. running mean: -19.751514115429465, timestamp: 2022-08-19 20:27:14.573659\n",
      "resetting env. episode 3241, reward total was -21.0. running mean: -19.76399897427517, timestamp: 2022-08-19 20:27:16.763686\n",
      "resetting env. episode 3242, reward total was -18.0. running mean: -19.74635898453242, timestamp: 2022-08-19 20:27:19.731719\n",
      "resetting env. episode 3243, reward total was -19.0. running mean: -19.7388953946871, timestamp: 2022-08-19 20:27:22.968757\n",
      "resetting env. episode 3244, reward total was -20.0. running mean: -19.741506440740228, timestamp: 2022-08-19 20:27:25.595791\n",
      "resetting env. episode 3245, reward total was -20.0. running mean: -19.744091376332825, timestamp: 2022-08-19 20:27:28.273819\n",
      "resetting env. episode 3246, reward total was -21.0. running mean: -19.756650462569496, timestamp: 2022-08-19 20:27:31.021852\n",
      "resetting env. episode 3247, reward total was -20.0. running mean: -19.7590839579438, timestamp: 2022-08-19 20:27:33.542885\n",
      "resetting env. episode 3248, reward total was -20.0. running mean: -19.761493118364363, timestamp: 2022-08-19 20:27:36.175912\n",
      "resetting env. episode 3249, reward total was -18.0. running mean: -19.74387818718072, timestamp: 2022-08-19 20:27:38.799944\n",
      "resetting env. episode 3250, reward total was -21.0. running mean: -19.756439405308914, timestamp: 2022-08-19 20:27:41.452974\n",
      "resetting env. episode 3251, reward total was -21.0. running mean: -19.768875011255826, timestamp: 2022-08-19 20:27:44.169009\n",
      "resetting env. episode 3252, reward total was -19.0. running mean: -19.76118626114327, timestamp: 2022-08-19 20:27:47.366045\n",
      "resetting env. episode 3253, reward total was -20.0. running mean: -19.763574398531837, timestamp: 2022-08-19 20:27:49.681073\n",
      "resetting env. episode 3254, reward total was -21.0. running mean: -19.77593865454652, timestamp: 2022-08-19 20:27:52.479110\n",
      "resetting env. episode 3255, reward total was -18.0. running mean: -19.758179268001054, timestamp: 2022-08-19 20:27:55.375140\n",
      "resetting env. episode 3256, reward total was -21.0. running mean: -19.770597475321043, timestamp: 2022-08-19 20:27:57.763167\n",
      "resetting env. episode 3257, reward total was -19.0. running mean: -19.762891500567836, timestamp: 2022-08-19 20:28:00.582201\n",
      "resetting env. episode 3258, reward total was -20.0. running mean: -19.765262585562155, timestamp: 2022-08-19 20:28:03.760240\n",
      "resetting env. episode 3259, reward total was -20.0. running mean: -19.767609959706533, timestamp: 2022-08-19 20:28:05.988265\n",
      "resetting env. episode 3260, reward total was -19.0. running mean: -19.75993386010947, timestamp: 2022-08-19 20:28:08.287290\n",
      "resetting env. episode 3261, reward total was -20.0. running mean: -19.762334521508375, timestamp: 2022-08-19 20:28:10.698322\n",
      "resetting env. episode 3262, reward total was -21.0. running mean: -19.77471117629329, timestamp: 2022-08-19 20:28:12.777344\n",
      "resetting env. episode 3263, reward total was -19.0. running mean: -19.76696406453036, timestamp: 2022-08-19 20:28:15.936382\n",
      "resetting env. episode 3264, reward total was -21.0. running mean: -19.779294423885055, timestamp: 2022-08-19 20:28:19.124420\n",
      "resetting env. episode 3265, reward total was -21.0. running mean: -19.791501479646204, timestamp: 2022-08-19 20:28:21.244445\n",
      "resetting env. episode 3266, reward total was -20.0. running mean: -19.793586464849742, timestamp: 2022-08-19 20:28:23.536471\n",
      "resetting env. episode 3267, reward total was -21.0. running mean: -19.805650600201247, timestamp: 2022-08-19 20:28:26.643510\n",
      "resetting env. episode 3268, reward total was -21.0. running mean: -19.817594094199237, timestamp: 2022-08-19 20:28:29.073541\n",
      "resetting env. episode 3269, reward total was -20.0. running mean: -19.819418153257242, timestamp: 2022-08-19 20:28:31.495565\n",
      "resetting env. episode 3270, reward total was -19.0. running mean: -19.811223971724672, timestamp: 2022-08-19 20:28:34.160596\n",
      "resetting env. episode 3271, reward total was -19.0. running mean: -19.803111732007427, timestamp: 2022-08-19 20:28:36.676626\n",
      "resetting env. episode 3272, reward total was -19.0. running mean: -19.795080614687354, timestamp: 2022-08-19 20:28:39.498665\n",
      "resetting env. episode 3273, reward total was -19.0. running mean: -19.78712980854048, timestamp: 2022-08-19 20:28:41.963690\n",
      "resetting env. episode 3274, reward total was -18.0. running mean: -19.769258510455074, timestamp: 2022-08-19 20:28:45.054256\n",
      "resetting env. episode 3275, reward total was -21.0. running mean: -19.781565925350524, timestamp: 2022-08-19 20:28:47.479282\n",
      "resetting env. episode 3276, reward total was -20.0. running mean: -19.78375026609702, timestamp: 2022-08-19 20:28:49.919314\n",
      "resetting env. episode 3277, reward total was -20.0. running mean: -19.78591276343605, timestamp: 2022-08-19 20:28:52.209337\n",
      "resetting env. episode 3278, reward total was -18.0. running mean: -19.76805363580169, timestamp: 2022-08-19 20:28:55.264378\n",
      "resetting env. episode 3279, reward total was -20.0. running mean: -19.77037309944367, timestamp: 2022-08-19 20:28:57.838405\n",
      "resetting env. episode 3280, reward total was -20.0. running mean: -19.772669368449233, timestamp: 2022-08-19 20:29:00.711437\n",
      "resetting env. episode 3281, reward total was -18.0. running mean: -19.754942674764738, timestamp: 2022-08-19 20:29:03.773475\n",
      "resetting env. episode 3282, reward total was -19.0. running mean: -19.74739324801709, timestamp: 2022-08-19 20:29:07.038515\n",
      "resetting env. episode 3283, reward total was -19.0. running mean: -19.73991931553692, timestamp: 2022-08-19 20:29:10.160553\n",
      "resetting env. episode 3284, reward total was -21.0. running mean: -19.75252012238155, timestamp: 2022-08-19 20:29:13.003106\n",
      "resetting env. episode 3285, reward total was -21.0. running mean: -19.764994921157736, timestamp: 2022-08-19 20:29:15.477136\n",
      "resetting env. episode 3286, reward total was -19.0. running mean: -19.75734497194616, timestamp: 2022-08-19 20:29:17.636163\n",
      "resetting env. episode 3287, reward total was -20.0. running mean: -19.7597715222267, timestamp: 2022-08-19 20:29:19.839187\n",
      "resetting env. episode 3288, reward total was -20.0. running mean: -19.762173807004434, timestamp: 2022-08-19 20:29:22.644219\n",
      "resetting env. episode 3289, reward total was -20.0. running mean: -19.76455206893439, timestamp: 2022-08-19 20:29:25.503252\n",
      "resetting env. episode 3290, reward total was -20.0. running mean: -19.766906548245043, timestamp: 2022-08-19 20:29:27.889282\n",
      "resetting env. episode 3291, reward total was -18.0. running mean: -19.74923748276259, timestamp: 2022-08-19 20:29:30.378313\n",
      "resetting env. episode 3292, reward total was -20.0. running mean: -19.751745107934966, timestamp: 2022-08-19 20:29:33.144344\n",
      "resetting env. episode 3293, reward total was -19.0. running mean: -19.744227656855617, timestamp: 2022-08-19 20:29:35.158367\n",
      "resetting env. episode 3294, reward total was -17.0. running mean: -19.716785380287064, timestamp: 2022-08-19 20:29:39.472418\n",
      "resetting env. episode 3295, reward total was -20.0. running mean: -19.719617526484193, timestamp: 2022-08-19 20:29:42.308451\n",
      "resetting env. episode 3296, reward total was -20.0. running mean: -19.72242135121935, timestamp: 2022-08-19 20:29:44.780480\n",
      "resetting env. episode 3297, reward total was -21.0. running mean: -19.735197137707157, timestamp: 2022-08-19 20:29:47.303509\n",
      "resetting env. episode 3298, reward total was -21.0. running mean: -19.747845166330087, timestamp: 2022-08-19 20:29:50.171542\n",
      "resetting env. episode 3299, reward total was -21.0. running mean: -19.760366714666787, timestamp: 2022-08-19 20:29:52.743577\n",
      "resetting env. episode 3300, reward total was -21.0. running mean: -19.77276304752012, timestamp: 2022-08-19 20:29:55.458605\n",
      "resetting env. episode 3301, reward total was -21.0. running mean: -19.78503541704492, timestamp: 2022-08-19 20:29:59.144652\n",
      "resetting env. episode 3302, reward total was -20.0. running mean: -19.78718506287447, timestamp: 2022-08-19 20:30:02.036685\n",
      "resetting env. episode 3303, reward total was -20.0. running mean: -19.789313212245727, timestamp: 2022-08-19 20:30:03.793707\n",
      "resetting env. episode 3304, reward total was -21.0. running mean: -19.801420080123272, timestamp: 2022-08-19 20:30:06.594738\n",
      "resetting env. episode 3305, reward total was -21.0. running mean: -19.81340587932204, timestamp: 2022-08-19 20:30:09.243768\n",
      "resetting env. episode 3306, reward total was -18.0. running mean: -19.795271820528818, timestamp: 2022-08-19 20:30:11.816801\n",
      "resetting env. episode 3307, reward total was -21.0. running mean: -19.80731910232353, timestamp: 2022-08-19 20:30:14.483832\n",
      "resetting env. episode 3308, reward total was -20.0. running mean: -19.80924591130029, timestamp: 2022-08-19 20:30:16.709859\n",
      "resetting env. episode 3309, reward total was -18.0. running mean: -19.791153452187288, timestamp: 2022-08-19 20:30:19.559894\n",
      "resetting env. episode 3310, reward total was -21.0. running mean: -19.803241917665417, timestamp: 2022-08-19 20:30:21.847916\n",
      "resetting env. episode 3311, reward total was -21.0. running mean: -19.815209498488763, timestamp: 2022-08-19 20:30:24.591950\n",
      "resetting env. episode 3312, reward total was -17.0. running mean: -19.787057403503876, timestamp: 2022-08-19 20:30:27.361982\n",
      "resetting env. episode 3313, reward total was -19.0. running mean: -19.779186829468838, timestamp: 2022-08-19 20:30:30.052015\n",
      "resetting env. episode 3314, reward total was -20.0. running mean: -19.781394961174147, timestamp: 2022-08-19 20:30:32.849047\n",
      "resetting env. episode 3315, reward total was -21.0. running mean: -19.793581011562406, timestamp: 2022-08-19 20:30:35.431080\n",
      "resetting env. episode 3316, reward total was -20.0. running mean: -19.79564520144678, timestamp: 2022-08-19 20:30:37.523102\n",
      "resetting env. episode 3317, reward total was -20.0. running mean: -19.797688749432314, timestamp: 2022-08-19 20:30:39.907134\n",
      "resetting env. episode 3318, reward total was -19.0. running mean: -19.78971186193799, timestamp: 2022-08-19 20:30:42.067155\n",
      "resetting env. episode 3319, reward total was -21.0. running mean: -19.801814743318612, timestamp: 2022-08-19 20:30:44.303186\n",
      "resetting env. episode 3320, reward total was -19.0. running mean: -19.79379659588543, timestamp: 2022-08-19 20:30:47.064213\n",
      "resetting env. episode 3321, reward total was -21.0. running mean: -19.805858629926576, timestamp: 2022-08-19 20:30:49.270241\n",
      "resetting env. episode 3322, reward total was -19.0. running mean: -19.797800043627312, timestamp: 2022-08-19 20:30:51.734273\n",
      "resetting env. episode 3323, reward total was -21.0. running mean: -19.80982204319104, timestamp: 2022-08-19 20:30:54.157299\n",
      "resetting env. episode 3324, reward total was -21.0. running mean: -19.821723822759132, timestamp: 2022-08-19 20:30:56.864329\n",
      "resetting env. episode 3325, reward total was -18.0. running mean: -19.80350658453154, timestamp: 2022-08-19 20:30:59.339358\n",
      "resetting env. episode 3326, reward total was -20.0. running mean: -19.805471518686225, timestamp: 2022-08-19 20:31:01.746388\n",
      "resetting env. episode 3327, reward total was -21.0. running mean: -19.817416803499363, timestamp: 2022-08-19 20:31:04.457419\n",
      "resetting env. episode 3328, reward total was -20.0. running mean: -19.819242635464366, timestamp: 2022-08-19 20:31:06.980448\n",
      "resetting env. episode 3329, reward total was -20.0. running mean: -19.82105020910972, timestamp: 2022-08-19 20:31:09.608479\n",
      "resetting env. episode 3330, reward total was -19.0. running mean: -19.812839707018625, timestamp: 2022-08-19 20:31:12.785515\n",
      "resetting env. episode 3331, reward total was -17.0. running mean: -19.78471130994844, timestamp: 2022-08-19 20:31:15.905553\n",
      "resetting env. episode 3332, reward total was -19.0. running mean: -19.77686419684896, timestamp: 2022-08-19 20:31:18.298579\n",
      "resetting env. episode 3333, reward total was -19.0. running mean: -19.76909555488047, timestamp: 2022-08-19 20:31:20.873609\n",
      "resetting env. episode 3334, reward total was -18.0. running mean: -19.751404599331664, timestamp: 2022-08-19 20:31:23.372642\n",
      "resetting env. episode 3335, reward total was -18.0. running mean: -19.733890553338348, timestamp: 2022-08-19 20:31:26.304674\n",
      "resetting env. episode 3336, reward total was -19.0. running mean: -19.726551647804964, timestamp: 2022-08-19 20:31:28.710703\n",
      "resetting env. episode 3337, reward total was -20.0. running mean: -19.729286131326912, timestamp: 2022-08-19 20:31:31.539736\n",
      "resetting env. episode 3338, reward total was -21.0. running mean: -19.741993270013644, timestamp: 2022-08-19 20:31:33.744760\n",
      "resetting env. episode 3339, reward total was -20.0. running mean: -19.744573337313508, timestamp: 2022-08-19 20:31:36.125789\n",
      "resetting env. episode 3340, reward total was -20.0. running mean: -19.74712760394037, timestamp: 2022-08-19 20:31:39.410355\n",
      "resetting env. episode 3341, reward total was -21.0. running mean: -19.759656327900966, timestamp: 2022-08-19 20:31:41.622380\n",
      "resetting env. episode 3342, reward total was -19.0. running mean: -19.752059764621958, timestamp: 2022-08-19 20:31:44.272417\n",
      "resetting env. episode 3343, reward total was -21.0. running mean: -19.764539166975737, timestamp: 2022-08-19 20:31:46.954446\n",
      "resetting env. episode 3344, reward total was -18.0. running mean: -19.74689377530598, timestamp: 2022-08-19 20:31:50.024478\n",
      "resetting env. episode 3345, reward total was -18.0. running mean: -19.72942483755292, timestamp: 2022-08-19 20:31:52.997514\n",
      "resetting env. episode 3346, reward total was -21.0. running mean: -19.74213058917739, timestamp: 2022-08-19 20:31:55.450543\n",
      "resetting env. episode 3347, reward total was -19.0. running mean: -19.734709283285618, timestamp: 2022-08-19 20:31:58.110577\n",
      "resetting env. episode 3348, reward total was -20.0. running mean: -19.73736219045276, timestamp: 2022-08-19 20:32:00.752134\n",
      "resetting env. episode 3349, reward total was -18.0. running mean: -19.71998856854823, timestamp: 2022-08-19 20:32:03.607167\n",
      "resetting env. episode 3350, reward total was -20.0. running mean: -19.72278868286275, timestamp: 2022-08-19 20:32:06.713204\n",
      "resetting env. episode 3351, reward total was -20.0. running mean: -19.72556079603412, timestamp: 2022-08-19 20:32:09.586236\n",
      "resetting env. episode 3352, reward total was -18.0. running mean: -19.70830518807378, timestamp: 2022-08-19 20:32:11.887264\n",
      "resetting env. episode 3353, reward total was -21.0. running mean: -19.72122213619304, timestamp: 2022-08-19 20:32:15.038299\n",
      "resetting env. episode 3354, reward total was -20.0. running mean: -19.72400991483111, timestamp: 2022-08-19 20:32:17.926332\n",
      "resetting env. episode 3355, reward total was -17.0. running mean: -19.696769815682803, timestamp: 2022-08-19 20:32:21.028367\n",
      "resetting env. episode 3356, reward total was -20.0. running mean: -19.699802117525973, timestamp: 2022-08-19 20:32:23.641402\n",
      "resetting env. episode 3357, reward total was -20.0. running mean: -19.70280409635071, timestamp: 2022-08-19 20:32:25.977428\n",
      "resetting env. episode 3358, reward total was -19.0. running mean: -19.695776055387206, timestamp: 2022-08-19 20:32:29.453468\n",
      "resetting env. episode 3359, reward total was -17.0. running mean: -19.668818294833336, timestamp: 2022-08-19 20:32:32.097498\n",
      "resetting env. episode 3360, reward total was -17.0. running mean: -19.642130111885006, timestamp: 2022-08-19 20:32:35.382539\n",
      "resetting env. episode 3361, reward total was -19.0. running mean: -19.635708810766157, timestamp: 2022-08-19 20:32:39.252583\n",
      "resetting env. episode 3362, reward total was -20.0. running mean: -19.639351722658496, timestamp: 2022-08-19 20:32:41.963615\n",
      "resetting env. episode 3363, reward total was -21.0. running mean: -19.65295820543191, timestamp: 2022-08-19 20:32:44.824172\n",
      "resetting env. episode 3364, reward total was -19.0. running mean: -19.646428623377595, timestamp: 2022-08-19 20:32:47.172200\n",
      "resetting env. episode 3365, reward total was -20.0. running mean: -19.649964337143818, timestamp: 2022-08-19 20:32:49.997233\n",
      "resetting env. episode 3366, reward total was -19.0. running mean: -19.64346469377238, timestamp: 2022-08-19 20:32:52.721265\n",
      "resetting env. episode 3367, reward total was -19.0. running mean: -19.637030046834656, timestamp: 2022-08-19 20:32:55.189292\n",
      "resetting env. episode 3368, reward total was -18.0. running mean: -19.62065974636631, timestamp: 2022-08-19 20:32:57.753324\n",
      "resetting env. episode 3369, reward total was -19.0. running mean: -19.614453148902648, timestamp: 2022-08-19 20:33:00.367353\n",
      "resetting env. episode 3370, reward total was -19.0. running mean: -19.608308617413623, timestamp: 2022-08-19 20:33:03.008914\n",
      "resetting env. episode 3371, reward total was -21.0. running mean: -19.622225531239486, timestamp: 2022-08-19 20:33:05.565942\n",
      "resetting env. episode 3372, reward total was -19.0. running mean: -19.616003275927092, timestamp: 2022-08-19 20:33:08.136972\n",
      "resetting env. episode 3373, reward total was -18.0. running mean: -19.599843243167822, timestamp: 2022-08-19 20:33:11.067005\n",
      "resetting env. episode 3374, reward total was -19.0. running mean: -19.593844810736144, timestamp: 2022-08-19 20:33:13.594037\n",
      "resetting env. episode 3375, reward total was -17.0. running mean: -19.567906362628783, timestamp: 2022-08-19 20:33:16.266070\n",
      "resetting env. episode 3376, reward total was -19.0. running mean: -19.562227299002497, timestamp: 2022-08-19 20:33:18.890098\n",
      "resetting env. episode 3377, reward total was -21.0. running mean: -19.576605026012473, timestamp: 2022-08-19 20:33:21.029124\n",
      "resetting env. episode 3378, reward total was -21.0. running mean: -19.590838975752348, timestamp: 2022-08-19 20:33:22.922143\n",
      "resetting env. episode 3379, reward total was -21.0. running mean: -19.604930585994826, timestamp: 2022-08-19 20:33:25.272173\n",
      "resetting env. episode 3380, reward total was -19.0. running mean: -19.59888128013488, timestamp: 2022-08-19 20:33:28.157204\n",
      "resetting env. episode 3381, reward total was -21.0. running mean: -19.61289246733353, timestamp: 2022-08-19 20:33:30.628239\n",
      "resetting env. episode 3382, reward total was -20.0. running mean: -19.616763542660195, timestamp: 2022-08-19 20:33:33.550269\n",
      "resetting env. episode 3383, reward total was -20.0. running mean: -19.620595907233593, timestamp: 2022-08-19 20:33:35.953297\n",
      "resetting env. episode 3384, reward total was -18.0. running mean: -19.604389948161256, timestamp: 2022-08-19 20:33:38.563854\n",
      "resetting env. episode 3385, reward total was -19.0. running mean: -19.598346048679645, timestamp: 2022-08-19 20:33:40.823879\n",
      "resetting env. episode 3386, reward total was -21.0. running mean: -19.61236258819285, timestamp: 2022-08-19 20:33:42.729902\n",
      "resetting env. episode 3387, reward total was -19.0. running mean: -19.606238962310922, timestamp: 2022-08-19 20:33:45.282930\n",
      "resetting env. episode 3388, reward total was -21.0. running mean: -19.620176572687814, timestamp: 2022-08-19 20:33:47.253955\n",
      "resetting env. episode 3389, reward total was -20.0. running mean: -19.623974806960934, timestamp: 2022-08-19 20:33:50.093984\n",
      "resetting env. episode 3390, reward total was -21.0. running mean: -19.637735058891327, timestamp: 2022-08-19 20:33:53.120018\n",
      "resetting env. episode 3391, reward total was -20.0. running mean: -19.64135770830241, timestamp: 2022-08-19 20:33:56.066057\n",
      "resetting env. episode 3392, reward total was -21.0. running mean: -19.654944131219388, timestamp: 2022-08-19 20:33:57.982079\n",
      "resetting env. episode 3393, reward total was -19.0. running mean: -19.648394689907196, timestamp: 2022-08-19 20:34:00.691108\n",
      "resetting env. episode 3394, reward total was -15.0. running mean: -19.601910743008123, timestamp: 2022-08-19 20:34:04.308153\n",
      "resetting env. episode 3395, reward total was -17.0. running mean: -19.575891635578042, timestamp: 2022-08-19 20:34:07.243185\n",
      "resetting env. episode 3396, reward total was -18.0. running mean: -19.56013271922226, timestamp: 2022-08-19 20:34:09.729216\n",
      "resetting env. episode 3397, reward total was -20.0. running mean: -19.564531392030037, timestamp: 2022-08-19 20:34:12.771250\n",
      "resetting env. episode 3398, reward total was -19.0. running mean: -19.558886078109737, timestamp: 2022-08-19 20:34:16.136287\n",
      "resetting env. episode 3399, reward total was -20.0. running mean: -19.56329721732864, timestamp: 2022-08-19 20:34:18.662318\n",
      "resetting env. episode 3400, reward total was -21.0. running mean: -19.577664245155354, timestamp: 2022-08-19 20:34:21.060344\n",
      "resetting env. episode 3401, reward total was -18.0. running mean: -19.5618876027038, timestamp: 2022-08-19 20:34:23.510374\n",
      "resetting env. episode 3402, reward total was -18.0. running mean: -19.54626872667676, timestamp: 2022-08-19 20:34:26.632409\n",
      "resetting env. episode 3403, reward total was -21.0. running mean: -19.560806039409993, timestamp: 2022-08-19 20:34:29.275442\n",
      "resetting env. episode 3404, reward total was -21.0. running mean: -19.575197979015893, timestamp: 2022-08-19 20:34:31.606468\n",
      "resetting env. episode 3405, reward total was -20.0. running mean: -19.579445999225733, timestamp: 2022-08-19 20:34:34.003495\n",
      "resetting env. episode 3406, reward total was -18.0. running mean: -19.563651539233476, timestamp: 2022-08-19 20:34:37.263535\n",
      "resetting env. episode 3407, reward total was -16.0. running mean: -19.528015023841142, timestamp: 2022-08-19 20:34:40.920576\n",
      "resetting env. episode 3408, reward total was -19.0. running mean: -19.522734873602733, timestamp: 2022-08-19 20:34:43.991614\n",
      "resetting env. episode 3409, reward total was -19.0. running mean: -19.51750752486671, timestamp: 2022-08-19 20:34:46.813644\n",
      "resetting env. episode 3410, reward total was -20.0. running mean: -19.52233244961804, timestamp: 2022-08-19 20:34:49.709676\n",
      "resetting env. episode 3411, reward total was -21.0. running mean: -19.537109125121862, timestamp: 2022-08-19 20:34:52.380708\n",
      "resetting env. episode 3412, reward total was -20.0. running mean: -19.541738033870644, timestamp: 2022-08-19 20:34:54.563734\n",
      "resetting env. episode 3413, reward total was -21.0. running mean: -19.556320653531937, timestamp: 2022-08-19 20:34:56.631756\n",
      "resetting env. episode 3414, reward total was -20.0. running mean: -19.560757446996618, timestamp: 2022-08-19 20:34:59.290789\n",
      "resetting env. episode 3415, reward total was -18.0. running mean: -19.54514987252665, timestamp: 2022-08-19 20:35:02.632826\n",
      "resetting env. episode 3416, reward total was -20.0. running mean: -19.549698373801384, timestamp: 2022-08-19 20:35:05.336858\n",
      "resetting env. episode 3417, reward total was -19.0. running mean: -19.54420139006337, timestamp: 2022-08-19 20:35:07.706886\n",
      "resetting env. episode 3418, reward total was -21.0. running mean: -19.558759376162737, timestamp: 2022-08-19 20:35:10.360920\n",
      "resetting env. episode 3419, reward total was -20.0. running mean: -19.56317178240111, timestamp: 2022-08-19 20:35:12.970948\n",
      "resetting env. episode 3420, reward total was -21.0. running mean: -19.5775400645771, timestamp: 2022-08-19 20:35:15.651976\n",
      "resetting env. episode 3421, reward total was -20.0. running mean: -19.581764663931327, timestamp: 2022-08-19 20:35:18.471010\n",
      "resetting env. episode 3422, reward total was -19.0. running mean: -19.575947017292016, timestamp: 2022-08-19 20:35:20.726037\n",
      "resetting env. episode 3423, reward total was -18.0. running mean: -19.560187547119096, timestamp: 2022-08-19 20:35:23.753071\n",
      "resetting env. episode 3424, reward total was -19.0. running mean: -19.554585671647907, timestamp: 2022-08-19 20:35:26.617104\n",
      "resetting env. episode 3425, reward total was -20.0. running mean: -19.559039814931428, timestamp: 2022-08-19 20:35:29.816142\n",
      "resetting env. episode 3426, reward total was -19.0. running mean: -19.553449416782115, timestamp: 2022-08-19 20:35:32.393175\n",
      "resetting env. episode 3427, reward total was -20.0. running mean: -19.557914922614295, timestamp: 2022-08-19 20:35:34.557198\n",
      "resetting env. episode 3428, reward total was -21.0. running mean: -19.57233577338815, timestamp: 2022-08-19 20:35:38.434240\n",
      "resetting env. episode 3429, reward total was -21.0. running mean: -19.58661241565427, timestamp: 2022-08-19 20:35:40.603265\n",
      "resetting env. episode 3430, reward total was -19.0. running mean: -19.58074629149773, timestamp: 2022-08-19 20:35:43.971303\n",
      "resetting env. episode 3431, reward total was -20.0. running mean: -19.58493882858275, timestamp: 2022-08-19 20:35:46.897338\n",
      "resetting env. episode 3432, reward total was -17.0. running mean: -19.559089440296923, timestamp: 2022-08-19 20:35:50.099900\n",
      "resetting env. episode 3433, reward total was -18.0. running mean: -19.543498545893954, timestamp: 2022-08-19 20:35:52.750933\n",
      "resetting env. episode 3434, reward total was -20.0. running mean: -19.548063560435015, timestamp: 2022-08-19 20:35:55.053957\n",
      "resetting env. episode 3435, reward total was -20.0. running mean: -19.552582924830663, timestamp: 2022-08-19 20:35:57.862987\n",
      "resetting env. episode 3436, reward total was -21.0. running mean: -19.567057095582356, timestamp: 2022-08-19 20:36:00.413020\n",
      "resetting env. episode 3437, reward total was -20.0. running mean: -19.571386524626533, timestamp: 2022-08-19 20:36:02.727048\n",
      "resetting env. episode 3438, reward total was -21.0. running mean: -19.58567265938027, timestamp: 2022-08-19 20:36:05.695079\n",
      "resetting env. episode 3439, reward total was -16.0. running mean: -19.549815932786466, timestamp: 2022-08-19 20:36:08.990119\n",
      "resetting env. episode 3440, reward total was -21.0. running mean: -19.5643177734586, timestamp: 2022-08-19 20:36:11.687147\n",
      "resetting env. episode 3441, reward total was -18.0. running mean: -19.548674595724016, timestamp: 2022-08-19 20:36:14.233180\n",
      "resetting env. episode 3442, reward total was -20.0. running mean: -19.553187849766775, timestamp: 2022-08-19 20:36:16.704209\n",
      "resetting env. episode 3443, reward total was -20.0. running mean: -19.557655971269106, timestamp: 2022-08-19 20:36:18.911232\n",
      "resetting env. episode 3444, reward total was -15.0. running mean: -19.512079411556414, timestamp: 2022-08-19 20:36:21.822267\n",
      "resetting env. episode 3445, reward total was -19.0. running mean: -19.50695861744085, timestamp: 2022-08-19 20:36:24.725299\n",
      "resetting env. episode 3446, reward total was -20.0. running mean: -19.511889031266442, timestamp: 2022-08-19 20:36:27.571331\n",
      "resetting env. episode 3447, reward total was -19.0. running mean: -19.50677014095378, timestamp: 2022-08-19 20:36:30.745368\n",
      "resetting env. episode 3448, reward total was -21.0. running mean: -19.521702439544242, timestamp: 2022-08-19 20:36:33.421400\n",
      "resetting env. episode 3449, reward total was -20.0. running mean: -19.526485415148798, timestamp: 2022-08-19 20:36:35.767437\n",
      "resetting env. episode 3450, reward total was -20.0. running mean: -19.53122056099731, timestamp: 2022-08-19 20:36:38.388456\n",
      "resetting env. episode 3451, reward total was -19.0. running mean: -19.525908355387337, timestamp: 2022-08-19 20:36:41.534491\n",
      "resetting env. episode 3452, reward total was -20.0. running mean: -19.53064927183346, timestamp: 2022-08-19 20:36:43.924523\n",
      "resetting env. episode 3453, reward total was -21.0. running mean: -19.545342779115128, timestamp: 2022-08-19 20:36:45.990545\n",
      "resetting env. episode 3454, reward total was -21.0. running mean: -19.559889351323978, timestamp: 2022-08-19 20:36:48.109567\n",
      "resetting env. episode 3455, reward total was -20.0. running mean: -19.56429045781074, timestamp: 2022-08-19 20:36:51.389606\n",
      "resetting env. episode 3456, reward total was -18.0. running mean: -19.54864755323263, timestamp: 2022-08-19 20:36:54.936645\n",
      "resetting env. episode 3457, reward total was -19.0. running mean: -19.543161077700304, timestamp: 2022-08-19 20:36:57.523674\n",
      "resetting env. episode 3458, reward total was -21.0. running mean: -19.557729466923302, timestamp: 2022-08-19 20:37:00.238227\n",
      "resetting env. episode 3459, reward total was -20.0. running mean: -19.562152172254066, timestamp: 2022-08-19 20:37:03.117261\n",
      "resetting env. episode 3460, reward total was -18.0. running mean: -19.546530650531526, timestamp: 2022-08-19 20:37:05.591288\n",
      "resetting env. episode 3461, reward total was -20.0. running mean: -19.55106534402621, timestamp: 2022-08-19 20:37:08.180319\n",
      "resetting env. episode 3462, reward total was -21.0. running mean: -19.565554690585948, timestamp: 2022-08-19 20:37:11.023351\n",
      "resetting env. episode 3463, reward total was -18.0. running mean: -19.549899143680086, timestamp: 2022-08-19 20:37:14.077388\n",
      "resetting env. episode 3464, reward total was -20.0. running mean: -19.554400152243286, timestamp: 2022-08-19 20:37:16.270412\n",
      "resetting env. episode 3465, reward total was -20.0. running mean: -19.558856150720853, timestamp: 2022-08-19 20:37:18.941444\n",
      "resetting env. episode 3466, reward total was -21.0. running mean: -19.573267589213646, timestamp: 2022-08-19 20:37:21.258468\n",
      "resetting env. episode 3467, reward total was -21.0. running mean: -19.58753491332151, timestamp: 2022-08-19 20:37:23.758500\n",
      "resetting env. episode 3468, reward total was -20.0. running mean: -19.591659564188294, timestamp: 2022-08-19 20:37:25.880520\n",
      "resetting env. episode 3469, reward total was -20.0. running mean: -19.59574296854641, timestamp: 2022-08-19 20:37:28.909558\n",
      "resetting env. episode 3470, reward total was -19.0. running mean: -19.589785538860948, timestamp: 2022-08-19 20:37:32.146591\n",
      "resetting env. episode 3471, reward total was -18.0. running mean: -19.57388768347234, timestamp: 2022-08-19 20:37:35.182626\n",
      "resetting env. episode 3472, reward total was -19.0. running mean: -19.568148806637616, timestamp: 2022-08-19 20:37:38.416665\n",
      "resetting env. episode 3473, reward total was -21.0. running mean: -19.58246731857124, timestamp: 2022-08-19 20:37:41.929704\n",
      "resetting env. episode 3474, reward total was -17.0. running mean: -19.55664264538553, timestamp: 2022-08-19 20:37:45.311743\n",
      "resetting env. episode 3475, reward total was -20.0. running mean: -19.561076218931674, timestamp: 2022-08-19 20:37:48.734783\n",
      "resetting env. episode 3476, reward total was -20.0. running mean: -19.565465456742356, timestamp: 2022-08-19 20:37:51.011808\n",
      "resetting env. episode 3477, reward total was -19.0. running mean: -19.559810802174933, timestamp: 2022-08-19 20:37:53.916842\n",
      "resetting env. episode 3478, reward total was -21.0. running mean: -19.574212694153186, timestamp: 2022-08-19 20:37:56.477871\n",
      "resetting env. episode 3479, reward total was -19.0. running mean: -19.568470567211655, timestamp: 2022-08-19 20:37:58.904900\n",
      "resetting env. episode 3480, reward total was -21.0. running mean: -19.582785861539538, timestamp: 2022-08-19 20:38:01.413926\n",
      "resetting env. episode 3481, reward total was -21.0. running mean: -19.596958002924143, timestamp: 2022-08-19 20:38:03.772953\n",
      "resetting env. episode 3482, reward total was -18.0. running mean: -19.5809884228949, timestamp: 2022-08-19 20:38:06.620987\n",
      "resetting env. episode 3483, reward total was -18.0. running mean: -19.56517853866595, timestamp: 2022-08-19 20:38:09.329020\n",
      "resetting env. episode 3484, reward total was -21.0. running mean: -19.579526753279293, timestamp: 2022-08-19 20:38:11.631042\n",
      "resetting env. episode 3485, reward total was -18.0. running mean: -19.563731485746498, timestamp: 2022-08-19 20:38:14.713086\n",
      "resetting env. episode 3486, reward total was -20.0. running mean: -19.568094170889033, timestamp: 2022-08-19 20:38:17.101107\n",
      "resetting env. episode 3487, reward total was -20.0. running mean: -19.572413229180142, timestamp: 2022-08-19 20:38:20.334145\n",
      "resetting env. episode 3488, reward total was -20.0. running mean: -19.57668909688834, timestamp: 2022-08-19 20:38:23.659184\n",
      "resetting env. episode 3489, reward total was -18.0. running mean: -19.560922205919457, timestamp: 2022-08-19 20:38:26.085211\n",
      "resetting env. episode 3490, reward total was -19.0. running mean: -19.555312983860265, timestamp: 2022-08-19 20:38:29.144241\n",
      "resetting env. episode 3491, reward total was -20.0. running mean: -19.55975985402166, timestamp: 2022-08-19 20:38:31.876274\n",
      "resetting env. episode 3492, reward total was -21.0. running mean: -19.574162255481443, timestamp: 2022-08-19 20:38:34.242301\n",
      "resetting env. episode 3493, reward total was -17.0. running mean: -19.548420632926632, timestamp: 2022-08-19 20:38:37.227336\n",
      "resetting env. episode 3494, reward total was -21.0. running mean: -19.562936426597368, timestamp: 2022-08-19 20:38:39.570363\n",
      "resetting env. episode 3495, reward total was -21.0. running mean: -19.577307062331396, timestamp: 2022-08-19 20:38:41.648385\n",
      "resetting env. episode 3496, reward total was -21.0. running mean: -19.591533991708083, timestamp: 2022-08-19 20:38:44.387416\n",
      "resetting env. episode 3497, reward total was -21.0. running mean: -19.605618651791, timestamp: 2022-08-19 20:38:46.389441\n",
      "resetting env. episode 3498, reward total was -20.0. running mean: -19.60956246527309, timestamp: 2022-08-19 20:38:48.862465\n",
      "resetting env. episode 3499, reward total was -21.0. running mean: -19.62346684062036, timestamp: 2022-08-19 20:38:51.774503\n",
      "resetting env. episode 3500, reward total was -19.0. running mean: -19.617232172214155, timestamp: 2022-08-19 20:38:54.087525\n",
      "resetting env. episode 3501, reward total was -19.0. running mean: -19.611059850492015, timestamp: 2022-08-19 20:38:57.462567\n",
      "resetting env. episode 3502, reward total was -19.0. running mean: -19.604949251987097, timestamp: 2022-08-19 20:39:00.265597\n",
      "resetting env. episode 3503, reward total was -20.0. running mean: -19.608899759467224, timestamp: 2022-08-19 20:39:01.879613\n",
      "resetting env. episode 3504, reward total was -21.0. running mean: -19.622810761872554, timestamp: 2022-08-19 20:39:05.530655\n",
      "resetting env. episode 3505, reward total was -21.0. running mean: -19.63658265425383, timestamp: 2022-08-19 20:39:07.835683\n",
      "resetting env. episode 3506, reward total was -20.0. running mean: -19.64021682771129, timestamp: 2022-08-19 20:39:10.334711\n",
      "resetting env. episode 3507, reward total was -20.0. running mean: -19.643814659434174, timestamp: 2022-08-19 20:39:13.103741\n",
      "resetting env. episode 3508, reward total was -20.0. running mean: -19.64737651283983, timestamp: 2022-08-19 20:39:15.668770\n",
      "resetting env. episode 3509, reward total was -20.0. running mean: -19.65090274771143, timestamp: 2022-08-19 20:39:18.478801\n",
      "resetting env. episode 3510, reward total was -20.0. running mean: -19.654393720234317, timestamp: 2022-08-19 20:39:21.238835\n",
      "resetting env. episode 3511, reward total was -21.0. running mean: -19.667849783031976, timestamp: 2022-08-19 20:39:23.214856\n",
      "resetting env. episode 3512, reward total was -19.0. running mean: -19.661171285201657, timestamp: 2022-08-19 20:39:25.532882\n",
      "resetting env. episode 3513, reward total was -20.0. running mean: -19.66455957234964, timestamp: 2022-08-19 20:39:28.168913\n",
      "resetting env. episode 3514, reward total was -20.0. running mean: -19.667913976626142, timestamp: 2022-08-19 20:39:31.706951\n",
      "resetting env. episode 3515, reward total was -21.0. running mean: -19.681234836859883, timestamp: 2022-08-19 20:39:34.717986\n",
      "resetting env. episode 3516, reward total was -20.0. running mean: -19.684422488491283, timestamp: 2022-08-19 20:39:38.026022\n",
      "resetting env. episode 3517, reward total was -21.0. running mean: -19.69757826360637, timestamp: 2022-08-19 20:39:41.122058\n",
      "resetting env. episode 3518, reward total was -17.0. running mean: -19.67060248097031, timestamp: 2022-08-19 20:39:44.068092\n",
      "resetting env. episode 3519, reward total was -19.0. running mean: -19.663896456160607, timestamp: 2022-08-19 20:39:47.337127\n",
      "resetting env. episode 3520, reward total was -18.0. running mean: -19.647257491599, timestamp: 2022-08-19 20:39:50.744167\n",
      "resetting env. episode 3521, reward total was -19.0. running mean: -19.64078491668301, timestamp: 2022-08-19 20:39:53.420199\n",
      "resetting env. episode 3522, reward total was -21.0. running mean: -19.65437706751618, timestamp: 2022-08-19 20:39:56.410233\n",
      "resetting env. episode 3523, reward total was -18.0. running mean: -19.637833296841016, timestamp: 2022-08-19 20:39:59.000265\n",
      "resetting env. episode 3524, reward total was -20.0. running mean: -19.641454963872604, timestamp: 2022-08-19 20:40:01.989296\n",
      "resetting env. episode 3525, reward total was -21.0. running mean: -19.65504041423388, timestamp: 2022-08-19 20:40:05.253331\n",
      "resetting env. episode 3526, reward total was -21.0. running mean: -19.668490010091542, timestamp: 2022-08-19 20:40:07.778360\n",
      "resetting env. episode 3527, reward total was -21.0. running mean: -19.681805109990627, timestamp: 2022-08-19 20:40:10.824394\n",
      "resetting env. episode 3528, reward total was -20.0. running mean: -19.68498705889072, timestamp: 2022-08-19 20:40:13.930429\n",
      "resetting env. episode 3529, reward total was -20.0. running mean: -19.688137188301813, timestamp: 2022-08-19 20:40:15.863452\n",
      "resetting env. episode 3530, reward total was -19.0. running mean: -19.681255816418794, timestamp: 2022-08-19 20:40:18.683481\n",
      "resetting env. episode 3531, reward total was -20.0. running mean: -19.684443258254607, timestamp: 2022-08-19 20:40:21.466513\n",
      "resetting env. episode 3532, reward total was -19.0. running mean: -19.677598825672064, timestamp: 2022-08-19 20:40:24.082545\n",
      "resetting env. episode 3533, reward total was -21.0. running mean: -19.690822837415343, timestamp: 2022-08-19 20:40:26.344570\n",
      "resetting env. episode 3534, reward total was -20.0. running mean: -19.69391460904119, timestamp: 2022-08-19 20:40:28.395595\n",
      "resetting env. episode 3535, reward total was -19.0. running mean: -19.68697546295078, timestamp: 2022-08-19 20:40:30.736620\n",
      "resetting env. episode 3536, reward total was -19.0. running mean: -19.680105708321275, timestamp: 2022-08-19 20:40:33.610653\n",
      "resetting env. episode 3537, reward total was -21.0. running mean: -19.693304651238062, timestamp: 2022-08-19 20:40:36.413686\n",
      "resetting env. episode 3538, reward total was -20.0. running mean: -19.69637160472568, timestamp: 2022-08-19 20:40:39.415720\n",
      "resetting env. episode 3539, reward total was -19.0. running mean: -19.689407888678424, timestamp: 2022-08-19 20:40:42.241748\n",
      "resetting env. episode 3540, reward total was -19.0. running mean: -19.68251380979164, timestamp: 2022-08-19 20:40:45.542787\n",
      "resetting env. episode 3541, reward total was -21.0. running mean: -19.695688671693723, timestamp: 2022-08-19 20:40:48.165819\n",
      "resetting env. episode 3542, reward total was -20.0. running mean: -19.698731784976786, timestamp: 2022-08-19 20:40:50.471842\n",
      "resetting env. episode 3543, reward total was -21.0. running mean: -19.71174446712702, timestamp: 2022-08-19 20:40:53.218874\n",
      "resetting env. episode 3544, reward total was -19.0. running mean: -19.70462702245575, timestamp: 2022-08-19 20:40:56.216910\n",
      "resetting env. episode 3545, reward total was -17.0. running mean: -19.677580752231194, timestamp: 2022-08-19 20:40:59.344947\n",
      "resetting env. episode 3546, reward total was -20.0. running mean: -19.680804944708882, timestamp: 2022-08-19 20:41:01.583972\n",
      "resetting env. episode 3547, reward total was -21.0. running mean: -19.693996895261794, timestamp: 2022-08-19 20:41:03.716999\n",
      "resetting env. episode 3548, reward total was -21.0. running mean: -19.70705692630918, timestamp: 2022-08-19 20:41:06.238026\n",
      "resetting env. episode 3549, reward total was -21.0. running mean: -19.719986357046086, timestamp: 2022-08-19 20:41:08.881055\n",
      "resetting env. episode 3550, reward total was -20.0. running mean: -19.722786493475624, timestamp: 2022-08-19 20:41:11.226082\n",
      "resetting env. episode 3551, reward total was -20.0. running mean: -19.725558628540867, timestamp: 2022-08-19 20:41:13.976114\n",
      "resetting env. episode 3552, reward total was -21.0. running mean: -19.73830304225546, timestamp: 2022-08-19 20:41:16.572145\n",
      "resetting env. episode 3553, reward total was -19.0. running mean: -19.730920011832907, timestamp: 2022-08-19 20:41:19.703180\n",
      "resetting env. episode 3554, reward total was -20.0. running mean: -19.733610811714577, timestamp: 2022-08-19 20:41:22.493214\n",
      "resetting env. episode 3555, reward total was -19.0. running mean: -19.726274703597433, timestamp: 2022-08-19 20:41:25.545247\n",
      "resetting env. episode 3556, reward total was -17.0. running mean: -19.69901195656146, timestamp: 2022-08-19 20:41:28.127275\n",
      "resetting env. episode 3557, reward total was -20.0. running mean: -19.702021836995844, timestamp: 2022-08-19 20:41:30.696305\n",
      "resetting env. episode 3558, reward total was -20.0. running mean: -19.705001618625886, timestamp: 2022-08-19 20:41:33.201339\n",
      "resetting env. episode 3559, reward total was -21.0. running mean: -19.717951602439626, timestamp: 2022-08-19 20:41:35.326359\n",
      "resetting env. episode 3560, reward total was -21.0. running mean: -19.730772086415232, timestamp: 2022-08-19 20:41:37.697386\n",
      "resetting env. episode 3561, reward total was -20.0. running mean: -19.73346436555108, timestamp: 2022-08-19 20:41:40.192414\n",
      "resetting env. episode 3562, reward total was -18.0. running mean: -19.716129721895566, timestamp: 2022-08-19 20:41:43.214451\n",
      "resetting env. episode 3563, reward total was -19.0. running mean: -19.708968424676613, timestamp: 2022-08-19 20:41:45.384475\n",
      "resetting env. episode 3564, reward total was -19.0. running mean: -19.701878740429848, timestamp: 2022-08-19 20:41:48.556513\n",
      "resetting env. episode 3565, reward total was -19.0. running mean: -19.69485995302555, timestamp: 2022-08-19 20:41:51.796549\n",
      "resetting env. episode 3566, reward total was -21.0. running mean: -19.707911353495295, timestamp: 2022-08-19 20:41:54.725584\n",
      "resetting env. episode 3567, reward total was -19.0. running mean: -19.70083223996034, timestamp: 2022-08-19 20:41:58.852632\n",
      "resetting env. episode 3568, reward total was -21.0. running mean: -19.713823917560738, timestamp: 2022-08-19 20:42:01.270659\n",
      "resetting env. episode 3569, reward total was -21.0. running mean: -19.72668567838513, timestamp: 2022-08-19 20:42:03.855687\n",
      "resetting env. episode 3570, reward total was -18.0. running mean: -19.70941882160128, timestamp: 2022-08-19 20:42:06.859245\n",
      "resetting env. episode 3571, reward total was -20.0. running mean: -19.712324633385265, timestamp: 2022-08-19 20:42:09.276273\n",
      "resetting env. episode 3572, reward total was -21.0. running mean: -19.725201387051413, timestamp: 2022-08-19 20:42:11.470302\n",
      "resetting env. episode 3573, reward total was -19.0. running mean: -19.7179493731809, timestamp: 2022-08-19 20:42:13.759329\n",
      "resetting env. episode 3574, reward total was -19.0. running mean: -19.710769879449092, timestamp: 2022-08-19 20:42:16.558358\n",
      "resetting env. episode 3575, reward total was -19.0. running mean: -19.703662180654604, timestamp: 2022-08-19 20:42:19.564401\n",
      "resetting env. episode 3576, reward total was -21.0. running mean: -19.716625558848058, timestamp: 2022-08-19 20:42:22.213424\n",
      "resetting env. episode 3577, reward total was -19.0. running mean: -19.709459303259578, timestamp: 2022-08-19 20:42:25.101458\n",
      "resetting env. episode 3578, reward total was -20.0. running mean: -19.712364710226982, timestamp: 2022-08-19 20:42:27.534486\n",
      "resetting env. episode 3579, reward total was -19.0. running mean: -19.705241063124713, timestamp: 2022-08-19 20:42:29.881513\n",
      "resetting env. episode 3580, reward total was -19.0. running mean: -19.698188652493467, timestamp: 2022-08-19 20:42:33.043548\n",
      "resetting env. episode 3581, reward total was -21.0. running mean: -19.711206765968534, timestamp: 2022-08-19 20:42:35.836583\n",
      "resetting env. episode 3582, reward total was -19.0. running mean: -19.70409469830885, timestamp: 2022-08-19 20:42:38.567613\n",
      "resetting env. episode 3583, reward total was -19.0. running mean: -19.697053751325765, timestamp: 2022-08-19 20:42:41.976176\n",
      "resetting env. episode 3584, reward total was -20.0. running mean: -19.700083213812505, timestamp: 2022-08-19 20:42:44.442204\n",
      "resetting env. episode 3585, reward total was -21.0. running mean: -19.71308238167438, timestamp: 2022-08-19 20:42:46.375228\n",
      "resetting env. episode 3586, reward total was -21.0. running mean: -19.725951557857638, timestamp: 2022-08-19 20:42:49.388263\n",
      "resetting env. episode 3587, reward total was -18.0. running mean: -19.70869204227906, timestamp: 2022-08-19 20:42:52.823304\n",
      "resetting env. episode 3588, reward total was -17.0. running mean: -19.681605121856272, timestamp: 2022-08-19 20:42:56.545345\n",
      "resetting env. episode 3589, reward total was -21.0. running mean: -19.69478907063771, timestamp: 2022-08-19 20:42:59.345378\n",
      "resetting env. episode 3590, reward total was -20.0. running mean: -19.697841179931334, timestamp: 2022-08-19 20:43:01.920934\n",
      "resetting env. episode 3591, reward total was -21.0. running mean: -19.71086276813202, timestamp: 2022-08-19 20:43:04.255961\n",
      "resetting env. episode 3592, reward total was -19.0. running mean: -19.7037541404507, timestamp: 2022-08-19 20:43:06.342989\n",
      "resetting env. episode 3593, reward total was -21.0. running mean: -19.716716599046194, timestamp: 2022-08-19 20:43:08.931018\n",
      "resetting env. episode 3594, reward total was -19.0. running mean: -19.709549433055734, timestamp: 2022-08-19 20:43:11.985053\n",
      "resetting env. episode 3595, reward total was -18.0. running mean: -19.692453938725176, timestamp: 2022-08-19 20:43:14.976086\n",
      "resetting env. episode 3596, reward total was -21.0. running mean: -19.705529399337927, timestamp: 2022-08-19 20:43:17.469115\n",
      "resetting env. episode 3597, reward total was -21.0. running mean: -19.718474105344548, timestamp: 2022-08-19 20:43:20.349147\n",
      "resetting env. episode 3598, reward total was -19.0. running mean: -19.711289364291105, timestamp: 2022-08-19 20:43:23.729188\n",
      "resetting env. episode 3599, reward total was -20.0. running mean: -19.714176470648194, timestamp: 2022-08-19 20:43:26.352222\n",
      "resetting env. episode 3600, reward total was -18.0. running mean: -19.69703470594171, timestamp: 2022-08-19 20:43:29.156252\n",
      "resetting env. episode 3601, reward total was -20.0. running mean: -19.700064358882294, timestamp: 2022-08-19 20:43:32.418292\n",
      "resetting env. episode 3602, reward total was -19.0. running mean: -19.693063715293473, timestamp: 2022-08-19 20:43:34.442316\n",
      "resetting env. episode 3603, reward total was -19.0. running mean: -19.68613307814054, timestamp: 2022-08-19 20:43:37.105347\n",
      "resetting env. episode 3604, reward total was -21.0. running mean: -19.699271747359134, timestamp: 2022-08-19 20:43:40.147384\n",
      "resetting env. episode 3605, reward total was -19.0. running mean: -19.692279029885544, timestamp: 2022-08-19 20:43:43.448419\n",
      "resetting env. episode 3606, reward total was -20.0. running mean: -19.695356239586687, timestamp: 2022-08-19 20:43:46.226452\n",
      "resetting env. episode 3607, reward total was -18.0. running mean: -19.67840267719082, timestamp: 2022-08-19 20:43:49.126485\n",
      "resetting env. episode 3608, reward total was -20.0. running mean: -19.681618650418912, timestamp: 2022-08-19 20:43:51.826518\n",
      "resetting env. episode 3609, reward total was -17.0. running mean: -19.654802463914724, timestamp: 2022-08-19 20:43:54.551596\n",
      "resetting env. episode 3610, reward total was -19.0. running mean: -19.64825443927558, timestamp: 2022-08-19 20:43:57.898633\n",
      "resetting env. episode 3611, reward total was -17.0. running mean: -19.621771894882826, timestamp: 2022-08-19 20:44:01.812680\n",
      "resetting env. episode 3612, reward total was -21.0. running mean: -19.635554175933997, timestamp: 2022-08-19 20:44:04.336711\n",
      "resetting env. episode 3613, reward total was -18.0. running mean: -19.619198634174655, timestamp: 2022-08-19 20:44:06.928740\n",
      "resetting env. episode 3614, reward total was -20.0. running mean: -19.62300664783291, timestamp: 2022-08-19 20:44:09.425769\n",
      "resetting env. episode 3615, reward total was -18.0. running mean: -19.60677658135458, timestamp: 2022-08-19 20:44:12.569807\n",
      "resetting env. episode 3616, reward total was -21.0. running mean: -19.620708815541036, timestamp: 2022-08-19 20:44:15.278362\n",
      "resetting env. episode 3617, reward total was -21.0. running mean: -19.634501727385626, timestamp: 2022-08-19 20:44:18.307923\n",
      "resetting env. episode 3618, reward total was -17.0. running mean: -19.60815671011177, timestamp: 2022-08-19 20:44:21.070954\n",
      "resetting env. episode 3619, reward total was -21.0. running mean: -19.622075143010655, timestamp: 2022-08-19 20:44:23.982990\n",
      "resetting env. episode 3620, reward total was -18.0. running mean: -19.605854391580547, timestamp: 2022-08-19 20:44:26.828021\n",
      "resetting env. episode 3621, reward total was -19.0. running mean: -19.59979584766474, timestamp: 2022-08-19 20:44:29.320053\n",
      "resetting env. episode 3622, reward total was -21.0. running mean: -19.613797889188096, timestamp: 2022-08-19 20:44:31.996089\n",
      "resetting env. episode 3623, reward total was -21.0. running mean: -19.627659910296217, timestamp: 2022-08-19 20:44:34.233109\n",
      "resetting env. episode 3624, reward total was -17.0. running mean: -19.601383311193256, timestamp: 2022-08-19 20:44:37.455151\n",
      "resetting env. episode 3625, reward total was -21.0. running mean: -19.615369478081323, timestamp: 2022-08-19 20:44:39.875174\n",
      "resetting env. episode 3626, reward total was -21.0. running mean: -19.62921578330051, timestamp: 2022-08-19 20:44:42.476207\n",
      "resetting env. episode 3627, reward total was -19.0. running mean: -19.622923625467504, timestamp: 2022-08-19 20:44:45.162240\n",
      "resetting env. episode 3628, reward total was -19.0. running mean: -19.616694389212828, timestamp: 2022-08-19 20:44:47.408273\n",
      "resetting env. episode 3629, reward total was -19.0. running mean: -19.610527445320702, timestamp: 2022-08-19 20:44:49.888292\n",
      "resetting env. episode 3630, reward total was -20.0. running mean: -19.614422170867496, timestamp: 2022-08-19 20:44:53.020329\n",
      "resetting env. episode 3631, reward total was -17.0. running mean: -19.588277949158822, timestamp: 2022-08-19 20:44:55.807363\n",
      "resetting env. episode 3632, reward total was -20.0. running mean: -19.592395169667235, timestamp: 2022-08-19 20:44:57.864388\n",
      "resetting env. episode 3633, reward total was -21.0. running mean: -19.60647121797056, timestamp: 2022-08-19 20:45:00.274417\n",
      "resetting env. episode 3634, reward total was -21.0. running mean: -19.620406505790857, timestamp: 2022-08-19 20:45:03.420453\n",
      "resetting env. episode 3635, reward total was -19.0. running mean: -19.61420244073295, timestamp: 2022-08-19 20:45:06.882492\n",
      "resetting env. episode 3636, reward total was -19.0. running mean: -19.60806041632562, timestamp: 2022-08-19 20:45:10.646536\n",
      "resetting env. episode 3637, reward total was -19.0. running mean: -19.601979812162366, timestamp: 2022-08-19 20:45:13.916576\n",
      "resetting env. episode 3638, reward total was -20.0. running mean: -19.60596001404074, timestamp: 2022-08-19 20:45:17.050611\n",
      "resetting env. episode 3639, reward total was -18.0. running mean: -19.58990041390033, timestamp: 2022-08-19 20:45:20.356652\n",
      "resetting env. episode 3640, reward total was -19.0. running mean: -19.584001409761328, timestamp: 2022-08-19 20:45:22.997679\n",
      "resetting env. episode 3641, reward total was -21.0. running mean: -19.598161395663716, timestamp: 2022-08-19 20:45:25.063703\n",
      "resetting env. episode 3642, reward total was -20.0. running mean: -19.60217978170708, timestamp: 2022-08-19 20:45:27.630735\n",
      "resetting env. episode 3643, reward total was -21.0. running mean: -19.61615798389001, timestamp: 2022-08-19 20:45:30.208766\n",
      "resetting env. episode 3644, reward total was -19.0. running mean: -19.60999640405111, timestamp: 2022-08-19 20:45:33.279802\n",
      "resetting env. episode 3645, reward total was -17.0. running mean: -19.5838964400106, timestamp: 2022-08-19 20:45:35.762828\n",
      "resetting env. episode 3646, reward total was -18.0. running mean: -19.568057475610495, timestamp: 2022-08-19 20:45:38.725389\n",
      "resetting env. episode 3647, reward total was -21.0. running mean: -19.582376900854392, timestamp: 2022-08-19 20:45:41.940427\n",
      "resetting env. episode 3648, reward total was -20.0. running mean: -19.586553131845847, timestamp: 2022-08-19 20:45:44.745461\n",
      "resetting env. episode 3649, reward total was -17.0. running mean: -19.56068760052739, timestamp: 2022-08-19 20:45:47.596491\n",
      "resetting env. episode 3650, reward total was -18.0. running mean: -19.545080724522116, timestamp: 2022-08-19 20:45:50.502526\n",
      "resetting env. episode 3651, reward total was -20.0. running mean: -19.549629917276892, timestamp: 2022-08-19 20:45:53.318563\n",
      "resetting env. episode 3652, reward total was -20.0. running mean: -19.55413361810412, timestamp: 2022-08-19 20:45:56.240601\n",
      "resetting env. episode 3653, reward total was -21.0. running mean: -19.56859228192308, timestamp: 2022-08-19 20:45:58.345617\n",
      "resetting env. episode 3654, reward total was -18.0. running mean: -19.55290635910385, timestamp: 2022-08-19 20:46:01.621660\n",
      "resetting env. episode 3655, reward total was -20.0. running mean: -19.55737729551281, timestamp: 2022-08-19 20:46:04.079687\n",
      "resetting env. episode 3656, reward total was -17.0. running mean: -19.531803522557684, timestamp: 2022-08-19 20:46:06.951719\n",
      "resetting env. episode 3657, reward total was -21.0. running mean: -19.54648548733211, timestamp: 2022-08-19 20:46:08.994747\n",
      "resetting env. episode 3658, reward total was -20.0. running mean: -19.551020632458787, timestamp: 2022-08-19 20:46:11.731776\n",
      "resetting env. episode 3659, reward total was -19.0. running mean: -19.5455104261342, timestamp: 2022-08-19 20:46:14.599812\n",
      "resetting env. episode 3660, reward total was -20.0. running mean: -19.550055321872858, timestamp: 2022-08-19 20:46:17.174362\n",
      "resetting env. episode 3661, reward total was -19.0. running mean: -19.54455476865413, timestamp: 2022-08-19 20:46:20.100399\n",
      "resetting env. episode 3662, reward total was -20.0. running mean: -19.549109220967587, timestamp: 2022-08-19 20:46:23.276437\n",
      "resetting env. episode 3663, reward total was -20.0. running mean: -19.55361812875791, timestamp: 2022-08-19 20:46:26.096470\n",
      "resetting env. episode 3664, reward total was -20.0. running mean: -19.55808194747033, timestamp: 2022-08-19 20:46:28.987501\n",
      "resetting env. episode 3665, reward total was -19.0. running mean: -19.55250112799563, timestamp: 2022-08-19 20:46:32.055536\n",
      "resetting env. episode 3666, reward total was -21.0. running mean: -19.566976116715676, timestamp: 2022-08-19 20:46:34.240565\n",
      "resetting env. episode 3667, reward total was -19.0. running mean: -19.56130635554852, timestamp: 2022-08-19 20:46:37.080596\n",
      "resetting env. episode 3668, reward total was -21.0. running mean: -19.575693291993037, timestamp: 2022-08-19 20:46:39.682625\n",
      "resetting env. episode 3669, reward total was -19.0. running mean: -19.569936359073107, timestamp: 2022-08-19 20:46:42.476666\n",
      "resetting env. episode 3670, reward total was -19.0. running mean: -19.56423699548238, timestamp: 2022-08-19 20:46:45.553694\n",
      "resetting env. episode 3671, reward total was -19.0. running mean: -19.558594625527554, timestamp: 2022-08-19 20:46:48.260730\n",
      "resetting env. episode 3672, reward total was -20.0. running mean: -19.56300867927228, timestamp: 2022-08-19 20:46:50.963762\n",
      "resetting env. episode 3673, reward total was -21.0. running mean: -19.57737859247956, timestamp: 2022-08-19 20:46:54.042797\n",
      "resetting env. episode 3674, reward total was -20.0. running mean: -19.58160480655476, timestamp: 2022-08-19 20:46:56.657825\n",
      "resetting env. episode 3675, reward total was -21.0. running mean: -19.595788758489213, timestamp: 2022-08-19 20:47:00.407871\n",
      "resetting env. episode 3676, reward total was -18.0. running mean: -19.57983087090432, timestamp: 2022-08-19 20:47:02.868901\n",
      "resetting env. episode 3677, reward total was -19.0. running mean: -19.574032562195278, timestamp: 2022-08-19 20:47:05.821936\n",
      "resetting env. episode 3678, reward total was -20.0. running mean: -19.578292236573326, timestamp: 2022-08-19 20:47:09.022970\n",
      "resetting env. episode 3679, reward total was -21.0. running mean: -19.592509314207593, timestamp: 2022-08-19 20:47:11.678000\n",
      "resetting env. episode 3680, reward total was -20.0. running mean: -19.596584221065516, timestamp: 2022-08-19 20:47:14.779036\n",
      "resetting env. episode 3681, reward total was -19.0. running mean: -19.590618378854863, timestamp: 2022-08-19 20:47:17.730073\n",
      "resetting env. episode 3682, reward total was -21.0. running mean: -19.604712195066316, timestamp: 2022-08-19 20:47:21.159111\n",
      "resetting env. episode 3683, reward total was -19.0. running mean: -19.598665073115654, timestamp: 2022-08-19 20:47:24.806156\n",
      "resetting env. episode 3684, reward total was -19.0. running mean: -19.5926784223845, timestamp: 2022-08-19 20:47:27.034183\n",
      "resetting env. episode 3685, reward total was -21.0. running mean: -19.606751638160652, timestamp: 2022-08-19 20:47:29.710214\n",
      "resetting env. episode 3686, reward total was -19.0. running mean: -19.600684121779047, timestamp: 2022-08-19 20:47:32.268240\n",
      "resetting env. episode 3687, reward total was -21.0. running mean: -19.614677280561256, timestamp: 2022-08-19 20:47:34.454269\n",
      "resetting env. episode 3688, reward total was -19.0. running mean: -19.608530507755646, timestamp: 2022-08-19 20:47:37.413827\n",
      "resetting env. episode 3689, reward total was -20.0. running mean: -19.61244520267809, timestamp: 2022-08-19 20:47:39.930856\n",
      "resetting env. episode 3690, reward total was -20.0. running mean: -19.616320750651308, timestamp: 2022-08-19 20:47:42.623888\n",
      "resetting env. episode 3691, reward total was -21.0. running mean: -19.630157543144797, timestamp: 2022-08-19 20:47:45.604924\n",
      "resetting env. episode 3692, reward total was -21.0. running mean: -19.64385596771335, timestamp: 2022-08-19 20:47:48.019950\n",
      "resetting env. episode 3693, reward total was -18.0. running mean: -19.627417408036216, timestamp: 2022-08-19 20:47:51.049987\n",
      "resetting env. episode 3694, reward total was -18.0. running mean: -19.611143233955854, timestamp: 2022-08-19 20:47:53.814018\n",
      "resetting env. episode 3695, reward total was -18.0. running mean: -19.595031801616294, timestamp: 2022-08-19 20:47:56.895063\n",
      "resetting env. episode 3696, reward total was -20.0. running mean: -19.59908148360013, timestamp: 2022-08-19 20:47:59.894091\n",
      "resetting env. episode 3697, reward total was -21.0. running mean: -19.61309066876413, timestamp: 2022-08-19 20:48:02.402122\n",
      "resetting env. episode 3698, reward total was -20.0. running mean: -19.616959762076487, timestamp: 2022-08-19 20:48:05.454155\n",
      "resetting env. episode 3699, reward total was -20.0. running mean: -19.62079016445572, timestamp: 2022-08-19 20:48:08.284188\n",
      "resetting env. episode 3700, reward total was -21.0. running mean: -19.634582262811165, timestamp: 2022-08-19 20:48:11.067219\n",
      "resetting env. episode 3701, reward total was -21.0. running mean: -19.648236440183055, timestamp: 2022-08-19 20:48:13.700254\n",
      "resetting env. episode 3702, reward total was -19.0. running mean: -19.641754075781225, timestamp: 2022-08-19 20:48:16.028281\n",
      "resetting env. episode 3703, reward total was -21.0. running mean: -19.655336535023412, timestamp: 2022-08-19 20:48:18.954311\n",
      "resetting env. episode 3704, reward total was -20.0. running mean: -19.65878316967318, timestamp: 2022-08-19 20:48:21.159336\n",
      "resetting env. episode 3705, reward total was -20.0. running mean: -19.662195337976446, timestamp: 2022-08-19 20:48:23.332362\n",
      "resetting env. episode 3706, reward total was -21.0. running mean: -19.67557338459668, timestamp: 2022-08-19 20:48:25.888392\n",
      "resetting env. episode 3707, reward total was -20.0. running mean: -19.678817650750712, timestamp: 2022-08-19 20:48:27.993420\n",
      "resetting env. episode 3708, reward total was -20.0. running mean: -19.682029474243205, timestamp: 2022-08-19 20:48:32.153466\n",
      "resetting env. episode 3709, reward total was -19.0. running mean: -19.675209179500772, timestamp: 2022-08-19 20:48:35.403504\n",
      "resetting env. episode 3710, reward total was -20.0. running mean: -19.678457087705763, timestamp: 2022-08-19 20:48:38.185533\n",
      "resetting env. episode 3711, reward total was -19.0. running mean: -19.671672516828707, timestamp: 2022-08-19 20:48:40.830570\n",
      "resetting env. episode 3712, reward total was -19.0. running mean: -19.66495579166042, timestamp: 2022-08-19 20:48:44.422607\n",
      "resetting env. episode 3713, reward total was -20.0. running mean: -19.668306233743817, timestamp: 2022-08-19 20:48:46.712635\n",
      "resetting env. episode 3714, reward total was -19.0. running mean: -19.66162317140638, timestamp: 2022-08-19 20:48:49.741672\n",
      "resetting env. episode 3715, reward total was -21.0. running mean: -19.675006939692317, timestamp: 2022-08-19 20:48:52.736704\n",
      "resetting env. episode 3716, reward total was -21.0. running mean: -19.688256870295394, timestamp: 2022-08-19 20:48:55.654738\n",
      "resetting env. episode 3717, reward total was -19.0. running mean: -19.68137430159244, timestamp: 2022-08-19 20:48:58.811774\n",
      "resetting env. episode 3718, reward total was -20.0. running mean: -19.684560558576518, timestamp: 2022-08-19 20:49:01.362806\n",
      "resetting env. episode 3719, reward total was -21.0. running mean: -19.697714952990754, timestamp: 2022-08-19 20:49:04.467839\n",
      "resetting env. episode 3720, reward total was -21.0. running mean: -19.710737803460848, timestamp: 2022-08-19 20:49:06.793866\n",
      "resetting env. episode 3721, reward total was -21.0. running mean: -19.72363042542624, timestamp: 2022-08-19 20:49:09.360899\n",
      "resetting env. episode 3722, reward total was -19.0. running mean: -19.71639412117198, timestamp: 2022-08-19 20:49:11.541921\n",
      "resetting env. episode 3723, reward total was -21.0. running mean: -19.72923017996026, timestamp: 2022-08-19 20:49:13.770951\n",
      "resetting env. episode 3724, reward total was -18.0. running mean: -19.711937878160658, timestamp: 2022-08-19 20:49:17.088990\n",
      "resetting env. episode 3725, reward total was -20.0. running mean: -19.71481849937905, timestamp: 2022-08-19 20:49:19.743018\n",
      "resetting env. episode 3726, reward total was -19.0. running mean: -19.70767031438526, timestamp: 2022-08-19 20:49:22.344046\n",
      "resetting env. episode 3727, reward total was -21.0. running mean: -19.72059361124141, timestamp: 2022-08-19 20:49:24.254070\n",
      "resetting env. episode 3728, reward total was -19.0. running mean: -19.713387675128995, timestamp: 2022-08-19 20:49:27.667110\n",
      "resetting env. episode 3729, reward total was -21.0. running mean: -19.726253798377705, timestamp: 2022-08-19 20:49:30.202141\n",
      "resetting env. episode 3730, reward total was -19.0. running mean: -19.718991260393928, timestamp: 2022-08-19 20:49:33.065170\n",
      "resetting env. episode 3731, reward total was -21.0. running mean: -19.73180134778999, timestamp: 2022-08-19 20:49:35.102197\n",
      "resetting env. episode 3732, reward total was -20.0. running mean: -19.73448333431209, timestamp: 2022-08-19 20:49:38.010230\n",
      "resetting env. episode 3733, reward total was -19.0. running mean: -19.72713850096897, timestamp: 2022-08-19 20:49:42.581282\n",
      "resetting env. episode 3734, reward total was -19.0. running mean: -19.719867115959282, timestamp: 2022-08-19 20:49:46.355328\n",
      "resetting env. episode 3735, reward total was -20.0. running mean: -19.722668444799687, timestamp: 2022-08-19 20:49:49.338361\n",
      "resetting env. episode 3736, reward total was -19.0. running mean: -19.71544176035169, timestamp: 2022-08-19 20:49:51.878392\n",
      "resetting env. episode 3737, reward total was -21.0. running mean: -19.728287342748175, timestamp: 2022-08-19 20:49:54.175419\n",
      "resetting env. episode 3738, reward total was -19.0. running mean: -19.721004469320693, timestamp: 2022-08-19 20:49:56.683447\n",
      "resetting env. episode 3739, reward total was -17.0. running mean: -19.693794424627487, timestamp: 2022-08-19 20:49:59.660481\n",
      "resetting env. episode 3740, reward total was -21.0. running mean: -19.706856480381212, timestamp: 2022-08-19 20:50:02.013030\n",
      "resetting env. episode 3741, reward total was -20.0. running mean: -19.7097879155774, timestamp: 2022-08-19 20:50:05.586600\n",
      "resetting env. episode 3742, reward total was -20.0. running mean: -19.712690036421627, timestamp: 2022-08-19 20:50:08.860636\n",
      "resetting env. episode 3743, reward total was -19.0. running mean: -19.70556313605741, timestamp: 2022-08-19 20:50:12.500678\n",
      "resetting env. episode 3744, reward total was -21.0. running mean: -19.718507504696838, timestamp: 2022-08-19 20:50:15.495711\n",
      "resetting env. episode 3745, reward total was -16.0. running mean: -19.68132242964987, timestamp: 2022-08-19 20:50:18.865750\n",
      "resetting env. episode 3746, reward total was -20.0. running mean: -19.684509205353372, timestamp: 2022-08-19 20:50:21.744784\n",
      "resetting env. episode 3747, reward total was -21.0. running mean: -19.69766411329984, timestamp: 2022-08-19 20:50:24.618818\n",
      "resetting env. episode 3748, reward total was -18.0. running mean: -19.68068747216684, timestamp: 2022-08-19 20:50:27.153848\n",
      "resetting env. episode 3749, reward total was -18.0. running mean: -19.66388059744517, timestamp: 2022-08-19 20:50:30.048880\n",
      "resetting env. episode 3750, reward total was -21.0. running mean: -19.67724179147072, timestamp: 2022-08-19 20:50:33.258915\n",
      "resetting env. episode 3751, reward total was -19.0. running mean: -19.670469373556013, timestamp: 2022-08-19 20:50:36.010950\n",
      "resetting env. episode 3752, reward total was -20.0. running mean: -19.67376467982045, timestamp: 2022-08-19 20:50:38.962982\n",
      "resetting env. episode 3753, reward total was -17.0. running mean: -19.647027033022248, timestamp: 2022-08-19 20:50:42.121019\n",
      "resetting env. episode 3754, reward total was -20.0. running mean: -19.650556762692023, timestamp: 2022-08-19 20:50:45.127058\n",
      "resetting env. episode 3755, reward total was -18.0. running mean: -19.6340511950651, timestamp: 2022-08-19 20:50:48.864095\n",
      "resetting env. episode 3756, reward total was -19.0. running mean: -19.62771068311445, timestamp: 2022-08-19 20:50:51.476126\n",
      "resetting env. episode 3757, reward total was -18.0. running mean: -19.611433576283307, timestamp: 2022-08-19 20:50:54.248161\n",
      "resetting env. episode 3758, reward total was -21.0. running mean: -19.625319240520476, timestamp: 2022-08-19 20:50:56.538183\n",
      "resetting env. episode 3759, reward total was -20.0. running mean: -19.62906604811527, timestamp: 2022-08-19 20:50:59.302221\n",
      "resetting env. episode 3760, reward total was -17.0. running mean: -19.602775387634118, timestamp: 2022-08-19 20:51:02.618256\n",
      "resetting env. episode 3761, reward total was -21.0. running mean: -19.61674763375778, timestamp: 2022-08-19 20:51:05.189283\n",
      "resetting env. episode 3762, reward total was -18.0. running mean: -19.6005801574202, timestamp: 2022-08-19 20:51:07.931314\n",
      "resetting env. episode 3763, reward total was -20.0. running mean: -19.604574355845998, timestamp: 2022-08-19 20:51:11.275355\n",
      "resetting env. episode 3764, reward total was -19.0. running mean: -19.598528612287538, timestamp: 2022-08-19 20:51:13.934383\n",
      "resetting env. episode 3765, reward total was -19.0. running mean: -19.592543326164662, timestamp: 2022-08-19 20:51:16.961419\n",
      "resetting env. episode 3766, reward total was -18.0. running mean: -19.576617892903016, timestamp: 2022-08-19 20:51:20.190459\n",
      "resetting env. episode 3767, reward total was -20.0. running mean: -19.580851713973985, timestamp: 2022-08-19 20:51:22.782485\n",
      "resetting env. episode 3768, reward total was -20.0. running mean: -19.585043196834246, timestamp: 2022-08-19 20:51:24.833510\n",
      "resetting env. episode 3769, reward total was -21.0. running mean: -19.599192764865904, timestamp: 2022-08-19 20:51:27.446542\n",
      "resetting env. episode 3770, reward total was -16.0. running mean: -19.563200837217245, timestamp: 2022-08-19 20:51:30.504574\n",
      "resetting env. episode 3771, reward total was -15.0. running mean: -19.51756882884507, timestamp: 2022-08-19 20:51:33.561610\n",
      "resetting env. episode 3772, reward total was -18.0. running mean: -19.50239314055662, timestamp: 2022-08-19 20:51:36.807175\n",
      "resetting env. episode 3773, reward total was -19.0. running mean: -19.497369209151056, timestamp: 2022-08-19 20:51:39.456210\n",
      "resetting env. episode 3774, reward total was -21.0. running mean: -19.512395517059545, timestamp: 2022-08-19 20:51:42.516241\n",
      "resetting env. episode 3775, reward total was -21.0. running mean: -19.527271561888952, timestamp: 2022-08-19 20:51:45.677278\n",
      "resetting env. episode 3776, reward total was -21.0. running mean: -19.54199884627006, timestamp: 2022-08-19 20:51:47.716299\n",
      "resetting env. episode 3777, reward total was -19.0. running mean: -19.536578857807363, timestamp: 2022-08-19 20:51:51.433343\n",
      "resetting env. episode 3778, reward total was -19.0. running mean: -19.531213069229292, timestamp: 2022-08-19 20:51:54.206373\n",
      "resetting env. episode 3779, reward total was -20.0. running mean: -19.535900938536997, timestamp: 2022-08-19 20:51:56.592401\n",
      "resetting env. episode 3780, reward total was -17.0. running mean: -19.51054192915163, timestamp: 2022-08-19 20:51:59.182432\n",
      "resetting env. episode 3781, reward total was -21.0. running mean: -19.525436509860114, timestamp: 2022-08-19 20:52:01.455464\n",
      "resetting env. episode 3782, reward total was -19.0. running mean: -19.520182144761513, timestamp: 2022-08-19 20:52:04.060488\n",
      "resetting env. episode 3783, reward total was -20.0. running mean: -19.524980323313898, timestamp: 2022-08-19 20:52:06.193514\n",
      "resetting env. episode 3784, reward total was -19.0. running mean: -19.51973052008076, timestamp: 2022-08-19 20:52:08.752540\n",
      "resetting env. episode 3785, reward total was -19.0. running mean: -19.514533214879954, timestamp: 2022-08-19 20:52:11.427582\n",
      "resetting env. episode 3786, reward total was -20.0. running mean: -19.519387882731152, timestamp: 2022-08-19 20:52:13.979648\n",
      "resetting env. episode 3787, reward total was -21.0. running mean: -19.534194003903842, timestamp: 2022-08-19 20:52:16.775683\n",
      "resetting env. episode 3788, reward total was -19.0. running mean: -19.528852063864804, timestamp: 2022-08-19 20:52:19.363714\n",
      "resetting env. episode 3789, reward total was -20.0. running mean: -19.533563543226155, timestamp: 2022-08-19 20:52:22.385748\n",
      "resetting env. episode 3790, reward total was -20.0. running mean: -19.538227907793893, timestamp: 2022-08-19 20:52:25.155778\n",
      "resetting env. episode 3791, reward total was -20.0. running mean: -19.542845628715952, timestamp: 2022-08-19 20:52:28.159812\n",
      "resetting env. episode 3792, reward total was -17.0. running mean: -19.517417172428793, timestamp: 2022-08-19 20:52:31.786853\n",
      "resetting env. episode 3793, reward total was -19.0. running mean: -19.512243000704505, timestamp: 2022-08-19 20:52:34.372883\n",
      "resetting env. episode 3794, reward total was -18.0. running mean: -19.497120570697458, timestamp: 2022-08-19 20:52:37.119917\n",
      "resetting env. episode 3795, reward total was -19.0. running mean: -19.492149364990485, timestamp: 2022-08-19 20:52:40.339953\n",
      "resetting env. episode 3796, reward total was -20.0. running mean: -19.49722787134058, timestamp: 2022-08-19 20:52:43.133983\n",
      "resetting env. episode 3797, reward total was -19.0. running mean: -19.492255592627178, timestamp: 2022-08-19 20:52:45.902018\n",
      "resetting env. episode 3798, reward total was -20.0. running mean: -19.497333036700905, timestamp: 2022-08-19 20:52:48.271043\n",
      "resetting env. episode 3799, reward total was -17.0. running mean: -19.472359706333897, timestamp: 2022-08-19 20:52:52.276089\n",
      "resetting env. episode 3800, reward total was -19.0. running mean: -19.467636109270558, timestamp: 2022-08-19 20:52:54.957117\n",
      "resetting env. episode 3801, reward total was -19.0. running mean: -19.462959748177852, timestamp: 2022-08-19 20:52:57.361146\n",
      "resetting env. episode 3802, reward total was -21.0. running mean: -19.478330150696074, timestamp: 2022-08-19 20:53:00.083179\n",
      "resetting env. episode 3803, reward total was -21.0. running mean: -19.493546849189112, timestamp: 2022-08-19 20:53:03.233214\n",
      "resetting env. episode 3804, reward total was -20.0. running mean: -19.49861138069722, timestamp: 2022-08-19 20:53:05.831242\n",
      "resetting env. episode 3805, reward total was -21.0. running mean: -19.513625266890248, timestamp: 2022-08-19 20:53:08.830276\n",
      "resetting env. episode 3806, reward total was -21.0. running mean: -19.528489014221346, timestamp: 2022-08-19 20:53:11.284307\n",
      "resetting env. episode 3807, reward total was -16.0. running mean: -19.49320412407913, timestamp: 2022-08-19 20:53:14.831348\n",
      "resetting env. episode 3808, reward total was -19.0. running mean: -19.488272082838343, timestamp: 2022-08-19 20:53:17.527378\n",
      "resetting env. episode 3809, reward total was -20.0. running mean: -19.493389362009957, timestamp: 2022-08-19 20:53:20.046408\n",
      "resetting env. episode 3810, reward total was -18.0. running mean: -19.478455468389857, timestamp: 2022-08-19 20:53:22.203431\n",
      "resetting env. episode 3811, reward total was -19.0. running mean: -19.47367091370596, timestamp: 2022-08-19 20:53:24.960462\n",
      "resetting env. episode 3812, reward total was -19.0. running mean: -19.4689342045689, timestamp: 2022-08-19 20:53:28.112503\n",
      "resetting env. episode 3813, reward total was -14.0. running mean: -19.414244862523212, timestamp: 2022-08-19 20:53:31.708537\n",
      "resetting env. episode 3814, reward total was -17.0. running mean: -19.39010241389798, timestamp: 2022-08-19 20:53:34.899575\n",
      "resetting env. episode 3815, reward total was -19.0. running mean: -19.386201389759, timestamp: 2022-08-19 20:53:37.538607\n",
      "resetting env. episode 3816, reward total was -21.0. running mean: -19.402339375861413, timestamp: 2022-08-19 20:53:39.859630\n",
      "resetting env. episode 3817, reward total was -20.0. running mean: -19.4083159821028, timestamp: 2022-08-19 20:53:42.924666\n",
      "resetting env. episode 3818, reward total was -19.0. running mean: -19.404232822281774, timestamp: 2022-08-19 20:53:46.314706\n",
      "resetting env. episode 3819, reward total was -21.0. running mean: -19.420190494058957, timestamp: 2022-08-19 20:53:48.671733\n",
      "resetting env. episode 3820, reward total was -20.0. running mean: -19.425988589118365, timestamp: 2022-08-19 20:53:52.421772\n",
      "resetting env. episode 3821, reward total was -20.0. running mean: -19.43172870322718, timestamp: 2022-08-19 20:53:55.076804\n",
      "resetting env. episode 3822, reward total was -21.0. running mean: -19.447411416194907, timestamp: 2022-08-19 20:53:57.598836\n",
      "resetting env. episode 3823, reward total was -20.0. running mean: -19.452937302032957, timestamp: 2022-08-19 20:54:00.453864\n",
      "resetting env. episode 3824, reward total was -21.0. running mean: -19.468407929012628, timestamp: 2022-08-19 20:54:02.779895\n",
      "resetting env. episode 3825, reward total was -18.0. running mean: -19.4537238497225, timestamp: 2022-08-19 20:54:05.885933\n",
      "resetting env. episode 3826, reward total was -20.0. running mean: -19.459186611225274, timestamp: 2022-08-19 20:54:09.110964\n",
      "resetting env. episode 3827, reward total was -21.0. running mean: -19.474594745113023, timestamp: 2022-08-19 20:54:11.707993\n",
      "resetting env. episode 3828, reward total was -21.0. running mean: -19.489848797661892, timestamp: 2022-08-19 20:54:14.215024\n",
      "resetting env. episode 3829, reward total was -19.0. running mean: -19.484950309685274, timestamp: 2022-08-19 20:54:17.594066\n",
      "resetting env. episode 3830, reward total was -20.0. running mean: -19.49010080658842, timestamp: 2022-08-19 20:54:21.290102\n",
      "resetting env. episode 3831, reward total was -21.0. running mean: -19.505199798522536, timestamp: 2022-08-19 20:54:23.453127\n",
      "resetting env. episode 3832, reward total was -20.0. running mean: -19.51014780053731, timestamp: 2022-08-19 20:54:26.216160\n",
      "resetting env. episode 3833, reward total was -19.0. running mean: -19.50504632253194, timestamp: 2022-08-19 20:54:28.982190\n",
      "resetting env. episode 3834, reward total was -18.0. running mean: -19.48999585930662, timestamp: 2022-08-19 20:54:32.069227\n",
      "resetting env. episode 3835, reward total was -20.0. running mean: -19.495095900713554, timestamp: 2022-08-19 20:54:34.915262\n",
      "resetting env. episode 3836, reward total was -19.0. running mean: -19.49014494170642, timestamp: 2022-08-19 20:54:38.076295\n",
      "resetting env. episode 3837, reward total was -18.0. running mean: -19.475243492289355, timestamp: 2022-08-19 20:54:41.419331\n",
      "resetting env. episode 3838, reward total was -21.0. running mean: -19.490491057366462, timestamp: 2022-08-19 20:54:44.379890\n",
      "resetting env. episode 3839, reward total was -21.0. running mean: -19.505586146792798, timestamp: 2022-08-19 20:54:46.917919\n",
      "resetting env. episode 3840, reward total was -21.0. running mean: -19.52053028532487, timestamp: 2022-08-19 20:54:49.264945\n",
      "resetting env. episode 3841, reward total was -20.0. running mean: -19.52532498247162, timestamp: 2022-08-19 20:54:52.227977\n",
      "resetting env. episode 3842, reward total was -18.0. running mean: -19.510071732646903, timestamp: 2022-08-19 20:54:55.113011\n",
      "resetting env. episode 3843, reward total was -17.0. running mean: -19.484971015320436, timestamp: 2022-08-19 20:54:58.577051\n",
      "resetting env. episode 3844, reward total was -19.0. running mean: -19.480121305167234, timestamp: 2022-08-19 20:55:01.243081\n",
      "resetting env. episode 3845, reward total was -18.0. running mean: -19.46532009211556, timestamp: 2022-08-19 20:55:04.521120\n",
      "resetting env. episode 3846, reward total was -21.0. running mean: -19.480666891194407, timestamp: 2022-08-19 20:55:07.683156\n",
      "resetting env. episode 3847, reward total was -19.0. running mean: -19.475860222282463, timestamp: 2022-08-19 20:55:10.580187\n",
      "resetting env. episode 3848, reward total was -20.0. running mean: -19.481101620059636, timestamp: 2022-08-19 20:55:13.039214\n",
      "resetting env. episode 3849, reward total was -18.0. running mean: -19.46629060385904, timestamp: 2022-08-19 20:55:16.754255\n",
      "resetting env. episode 3850, reward total was -18.0. running mean: -19.45162769782045, timestamp: 2022-08-19 20:55:19.570287\n",
      "resetting env. episode 3851, reward total was -21.0. running mean: -19.467111420842244, timestamp: 2022-08-19 20:55:22.332318\n",
      "resetting env. episode 3852, reward total was -19.0. running mean: -19.462440306633823, timestamp: 2022-08-19 20:55:25.363361\n",
      "resetting env. episode 3853, reward total was -20.0. running mean: -19.467815903567484, timestamp: 2022-08-19 20:55:27.417377\n",
      "resetting env. episode 3854, reward total was -21.0. running mean: -19.48313774453181, timestamp: 2022-08-19 20:55:29.916406\n",
      "resetting env. episode 3855, reward total was -19.0. running mean: -19.478306367086493, timestamp: 2022-08-19 20:55:33.124442\n",
      "resetting env. episode 3856, reward total was -21.0. running mean: -19.49352330341563, timestamp: 2022-08-19 20:55:35.227468\n",
      "resetting env. episode 3857, reward total was -21.0. running mean: -19.508588070381474, timestamp: 2022-08-19 20:55:37.335492\n",
      "resetting env. episode 3858, reward total was -21.0. running mean: -19.52350218967766, timestamp: 2022-08-19 20:55:39.970525\n",
      "resetting env. episode 3859, reward total was -17.0. running mean: -19.498267167780885, timestamp: 2022-08-19 20:55:43.314557\n",
      "resetting env. episode 3860, reward total was -19.0. running mean: -19.493284496103076, timestamp: 2022-08-19 20:55:46.290590\n",
      "resetting env. episode 3861, reward total was -21.0. running mean: -19.508351651142046, timestamp: 2022-08-19 20:55:49.255626\n",
      "resetting env. episode 3862, reward total was -21.0. running mean: -19.523268134630626, timestamp: 2022-08-19 20:55:51.817656\n",
      "resetting env. episode 3863, reward total was -19.0. running mean: -19.51803545328432, timestamp: 2022-08-19 20:55:55.232695\n",
      "resetting env. episode 3864, reward total was -19.0. running mean: -19.512855098751476, timestamp: 2022-08-19 20:55:57.735722\n",
      "resetting env. episode 3865, reward total was -19.0. running mean: -19.507726547763962, timestamp: 2022-08-19 20:56:00.622754\n",
      "resetting env. episode 3866, reward total was -19.0. running mean: -19.502649282286324, timestamp: 2022-08-19 20:56:03.128783\n",
      "resetting env. episode 3867, reward total was -21.0. running mean: -19.517622789463463, timestamp: 2022-08-19 20:56:05.366806\n",
      "resetting env. episode 3868, reward total was -21.0. running mean: -19.53244656156883, timestamp: 2022-08-19 20:56:07.140828\n",
      "resetting env. episode 3869, reward total was -19.0. running mean: -19.527122095953143, timestamp: 2022-08-19 20:56:09.690859\n",
      "resetting env. episode 3870, reward total was -19.0. running mean: -19.52185087499361, timestamp: 2022-08-19 20:56:12.880893\n",
      "resetting env. episode 3871, reward total was -21.0. running mean: -19.536632366243676, timestamp: 2022-08-19 20:56:15.585923\n",
      "resetting env. episode 3872, reward total was -19.0. running mean: -19.53126604258124, timestamp: 2022-08-19 20:56:18.360953\n",
      "resetting env. episode 3873, reward total was -21.0. running mean: -19.545953382155428, timestamp: 2022-08-19 20:56:20.839983\n",
      "resetting env. episode 3874, reward total was -17.0. running mean: -19.520493848333874, timestamp: 2022-08-19 20:56:24.162018\n",
      "resetting env. episode 3875, reward total was -20.0. running mean: -19.525288909850534, timestamp: 2022-08-19 20:56:27.257051\n",
      "resetting env. episode 3876, reward total was -20.0. running mean: -19.53003602075203, timestamp: 2022-08-19 20:56:30.136607\n",
      "resetting env. episode 3877, reward total was -15.0. running mean: -19.484735660544505, timestamp: 2022-08-19 20:56:33.161642\n",
      "resetting env. episode 3878, reward total was -21.0. running mean: -19.49988830393906, timestamp: 2022-08-19 20:56:36.257679\n",
      "resetting env. episode 3879, reward total was -18.0. running mean: -19.48488942089967, timestamp: 2022-08-19 20:56:39.836719\n",
      "resetting env. episode 3880, reward total was -20.0. running mean: -19.490040526690674, timestamp: 2022-08-19 20:56:43.162752\n",
      "resetting env. episode 3881, reward total was -21.0. running mean: -19.505140121423768, timestamp: 2022-08-19 20:56:45.852788\n",
      "resetting env. episode 3882, reward total was -20.0. running mean: -19.51008872020953, timestamp: 2022-08-19 20:56:48.397813\n",
      "resetting env. episode 3883, reward total was -21.0. running mean: -19.524987833007437, timestamp: 2022-08-19 20:56:51.647851\n",
      "resetting env. episode 3884, reward total was -19.0. running mean: -19.519737954677364, timestamp: 2022-08-19 20:56:55.520894\n",
      "resetting env. episode 3885, reward total was -19.0. running mean: -19.514540575130592, timestamp: 2022-08-19 20:56:57.712918\n",
      "resetting env. episode 3886, reward total was -19.0. running mean: -19.50939516937929, timestamp: 2022-08-19 20:57:00.610951\n",
      "resetting env. episode 3887, reward total was -21.0. running mean: -19.524301217685498, timestamp: 2022-08-19 20:57:04.216993\n",
      "resetting env. episode 3888, reward total was -19.0. running mean: -19.519058205508642, timestamp: 2022-08-19 20:57:06.843019\n",
      "resetting env. episode 3889, reward total was -18.0. running mean: -19.503867623453555, timestamp: 2022-08-19 20:57:09.759052\n",
      "resetting env. episode 3890, reward total was -19.0. running mean: -19.49882894721902, timestamp: 2022-08-19 20:57:13.263090\n",
      "resetting env. episode 3891, reward total was -19.0. running mean: -19.493840657746834, timestamp: 2022-08-19 20:57:16.227125\n",
      "resetting env. episode 3892, reward total was -19.0. running mean: -19.488902251169367, timestamp: 2022-08-19 20:57:19.710166\n",
      "resetting env. episode 3893, reward total was -19.0. running mean: -19.484013228657673, timestamp: 2022-08-19 20:57:22.508198\n",
      "resetting env. episode 3894, reward total was -20.0. running mean: -19.489173096371097, timestamp: 2022-08-19 20:57:25.530232\n",
      "resetting env. episode 3895, reward total was -19.0. running mean: -19.484281365407387, timestamp: 2022-08-19 20:57:28.919271\n",
      "resetting env. episode 3896, reward total was -20.0. running mean: -19.489438551753313, timestamp: 2022-08-19 20:57:31.779301\n",
      "resetting env. episode 3897, reward total was -19.0. running mean: -19.484544166235782, timestamp: 2022-08-19 20:57:34.649333\n",
      "resetting env. episode 3898, reward total was -20.0. running mean: -19.489698724573422, timestamp: 2022-08-19 20:57:37.478365\n",
      "resetting env. episode 3899, reward total was -19.0. running mean: -19.48480173732769, timestamp: 2022-08-19 20:57:40.715402\n",
      "resetting env. episode 3900, reward total was -21.0. running mean: -19.499953719954412, timestamp: 2022-08-19 20:57:43.148429\n",
      "resetting env. episode 3901, reward total was -20.0. running mean: -19.50495418275487, timestamp: 2022-08-19 20:57:45.667461\n",
      "resetting env. episode 3902, reward total was -19.0. running mean: -19.499904640927323, timestamp: 2022-08-19 20:57:49.042499\n",
      "resetting env. episode 3903, reward total was -21.0. running mean: -19.51490559451805, timestamp: 2022-08-19 20:57:51.447523\n",
      "resetting env. episode 3904, reward total was -20.0. running mean: -19.51975653857287, timestamp: 2022-08-19 20:57:54.147556\n",
      "resetting env. episode 3905, reward total was -19.0. running mean: -19.514558973187142, timestamp: 2022-08-19 20:57:56.765587\n",
      "resetting env. episode 3906, reward total was -20.0. running mean: -19.51941338345527, timestamp: 2022-08-19 20:57:59.370617\n",
      "resetting env. episode 3907, reward total was -20.0. running mean: -19.524219249620717, timestamp: 2022-08-19 20:58:02.039645\n",
      "resetting env. episode 3908, reward total was -21.0. running mean: -19.538977057124512, timestamp: 2022-08-19 20:58:04.487675\n",
      "resetting env. episode 3909, reward total was -19.0. running mean: -19.533587286553267, timestamp: 2022-08-19 20:58:07.404708\n",
      "resetting env. episode 3910, reward total was -20.0. running mean: -19.538251413687732, timestamp: 2022-08-19 20:58:11.009746\n",
      "resetting env. episode 3911, reward total was -17.0. running mean: -19.512868899550856, timestamp: 2022-08-19 20:58:13.956781\n",
      "resetting env. episode 3912, reward total was -21.0. running mean: -19.527740210555347, timestamp: 2022-08-19 20:58:16.136809\n",
      "resetting env. episode 3913, reward total was -21.0. running mean: -19.542462808449795, timestamp: 2022-08-19 20:58:19.048842\n",
      "resetting env. episode 3914, reward total was -20.0. running mean: -19.547038180365295, timestamp: 2022-08-19 20:58:21.954875\n",
      "resetting env. episode 3915, reward total was -20.0. running mean: -19.551567798561642, timestamp: 2022-08-19 20:58:24.472905\n",
      "resetting env. episode 3916, reward total was -19.0. running mean: -19.546052120576025, timestamp: 2022-08-19 20:58:27.644937\n",
      "resetting env. episode 3917, reward total was -20.0. running mean: -19.550591599370264, timestamp: 2022-08-19 20:58:30.336965\n",
      "resetting env. episode 3918, reward total was -21.0. running mean: -19.565085683376562, timestamp: 2022-08-19 20:58:32.863998\n",
      "resetting env. episode 3919, reward total was -19.0. running mean: -19.559434826542798, timestamp: 2022-08-19 20:58:35.899032\n",
      "resetting env. episode 3920, reward total was -19.0. running mean: -19.553840478277372, timestamp: 2022-08-19 20:58:39.000067\n",
      "resetting env. episode 3921, reward total was -20.0. running mean: -19.5583020734946, timestamp: 2022-08-19 20:58:41.728099\n",
      "resetting env. episode 3922, reward total was -21.0. running mean: -19.572719052759652, timestamp: 2022-08-19 20:58:44.245127\n",
      "resetting env. episode 3923, reward total was -19.0. running mean: -19.566991862232058, timestamp: 2022-08-19 20:58:48.009170\n",
      "resetting env. episode 3924, reward total was -21.0. running mean: -19.581321943609737, timestamp: 2022-08-19 20:58:50.579204\n",
      "resetting env. episode 3925, reward total was -21.0. running mean: -19.59550872417364, timestamp: 2022-08-19 20:58:52.824226\n",
      "resetting env. episode 3926, reward total was -21.0. running mean: -19.609553636931906, timestamp: 2022-08-19 20:58:55.510257\n",
      "resetting env. episode 3927, reward total was -20.0. running mean: -19.613458100562585, timestamp: 2022-08-19 20:58:58.883302\n",
      "resetting env. episode 3928, reward total was -18.0. running mean: -19.59732351955696, timestamp: 2022-08-19 20:59:01.787332\n",
      "resetting env. episode 3929, reward total was -20.0. running mean: -19.601350284361388, timestamp: 2022-08-19 20:59:05.291371\n",
      "resetting env. episode 3930, reward total was -20.0. running mean: -19.605336781517774, timestamp: 2022-08-19 20:59:09.200413\n",
      "resetting env. episode 3931, reward total was -19.0. running mean: -19.599283413702597, timestamp: 2022-08-19 20:59:12.669454\n",
      "resetting env. episode 3932, reward total was -19.0. running mean: -19.593290579565572, timestamp: 2022-08-19 20:59:15.585488\n",
      "resetting env. episode 3933, reward total was -21.0. running mean: -19.60735767376992, timestamp: 2022-08-19 20:59:18.813050\n",
      "resetting env. episode 3934, reward total was -20.0. running mean: -19.611284097032218, timestamp: 2022-08-19 20:59:21.549082\n",
      "resetting env. episode 3935, reward total was -18.0. running mean: -19.595171256061896, timestamp: 2022-08-19 20:59:25.018120\n",
      "resetting env. episode 3936, reward total was -18.0. running mean: -19.579219543501278, timestamp: 2022-08-19 20:59:28.465161\n",
      "resetting env. episode 3937, reward total was -17.0. running mean: -19.55342734806627, timestamp: 2022-08-19 20:59:31.284193\n",
      "resetting env. episode 3938, reward total was -19.0. running mean: -19.547893074585605, timestamp: 2022-08-19 20:59:34.573231\n",
      "resetting env. episode 3939, reward total was -20.0. running mean: -19.552414143839748, timestamp: 2022-08-19 20:59:37.969270\n",
      "resetting env. episode 3940, reward total was -21.0. running mean: -19.56689000240135, timestamp: 2022-08-19 20:59:41.487310\n",
      "resetting env. episode 3941, reward total was -17.0. running mean: -19.54122110237734, timestamp: 2022-08-19 20:59:44.375345\n",
      "resetting env. episode 3942, reward total was -21.0. running mean: -19.555808891353568, timestamp: 2022-08-19 20:59:47.602380\n",
      "resetting env. episode 3943, reward total was -17.0. running mean: -19.530250802440033, timestamp: 2022-08-19 20:59:50.161413\n",
      "resetting env. episode 3944, reward total was -19.0. running mean: -19.524948294415633, timestamp: 2022-08-19 20:59:52.807443\n",
      "resetting env. episode 3945, reward total was -19.0. running mean: -19.51969881147148, timestamp: 2022-08-19 20:59:56.372483\n",
      "resetting env. episode 3946, reward total was -19.0. running mean: -19.514501823356763, timestamp: 2022-08-19 20:59:58.941512\n",
      "resetting env. episode 3947, reward total was -21.0. running mean: -19.529356805123196, timestamp: 2022-08-19 21:00:01.320541\n",
      "resetting env. episode 3948, reward total was -20.0. running mean: -19.534063237071965, timestamp: 2022-08-19 21:00:04.210576\n",
      "resetting env. episode 3949, reward total was -21.0. running mean: -19.548722604701247, timestamp: 2022-08-19 21:00:06.618601\n",
      "resetting env. episode 3950, reward total was -21.0. running mean: -19.563235378654234, timestamp: 2022-08-19 21:00:09.463634\n",
      "resetting env. episode 3951, reward total was -21.0. running mean: -19.57760302486769, timestamp: 2022-08-19 21:00:12.328674\n",
      "resetting env. episode 3952, reward total was -20.0. running mean: -19.581826994619014, timestamp: 2022-08-19 21:00:14.899696\n",
      "resetting env. episode 3953, reward total was -20.0. running mean: -19.586008724672823, timestamp: 2022-08-19 21:00:17.315724\n",
      "resetting env. episode 3954, reward total was -20.0. running mean: -19.590148637426093, timestamp: 2022-08-19 21:00:19.903756\n",
      "resetting env. episode 3955, reward total was -18.0. running mean: -19.574247151051832, timestamp: 2022-08-19 21:00:23.490797\n",
      "resetting env. episode 3956, reward total was -21.0. running mean: -19.588504679541316, timestamp: 2022-08-19 21:00:26.291832\n",
      "resetting env. episode 3957, reward total was -18.0. running mean: -19.5726196327459, timestamp: 2022-08-19 21:00:29.634871\n",
      "resetting env. episode 3958, reward total was -21.0. running mean: -19.586893436418443, timestamp: 2022-08-19 21:00:31.644892\n",
      "resetting env. episode 3959, reward total was -21.0. running mean: -19.60102450205426, timestamp: 2022-08-19 21:00:34.682929\n",
      "resetting env. episode 3960, reward total was -20.0. running mean: -19.605014257033716, timestamp: 2022-08-19 21:00:37.405960\n",
      "resetting env. episode 3961, reward total was -21.0. running mean: -19.61896411446338, timestamp: 2022-08-19 21:00:40.827000\n",
      "resetting env. episode 3962, reward total was -20.0. running mean: -19.622774473318746, timestamp: 2022-08-19 21:00:43.364027\n",
      "resetting env. episode 3963, reward total was -21.0. running mean: -19.636546728585557, timestamp: 2022-08-19 21:00:46.415064\n",
      "resetting env. episode 3964, reward total was -16.0. running mean: -19.600181261299703, timestamp: 2022-08-19 21:00:49.831103\n",
      "resetting env. episode 3965, reward total was -21.0. running mean: -19.614179448686706, timestamp: 2022-08-19 21:00:53.027141\n",
      "resetting env. episode 3966, reward total was -21.0. running mean: -19.62803765419984, timestamp: 2022-08-19 21:00:56.058176\n",
      "resetting env. episode 3967, reward total was -21.0. running mean: -19.64175727765784, timestamp: 2022-08-19 21:00:58.751208\n",
      "resetting env. episode 3968, reward total was -19.0. running mean: -19.635339704881265, timestamp: 2022-08-19 21:01:02.310249\n",
      "resetting env. episode 3969, reward total was -21.0. running mean: -19.648986307832452, timestamp: 2022-08-19 21:01:04.949278\n",
      "resetting env. episode 3970, reward total was -20.0. running mean: -19.652496444754128, timestamp: 2022-08-19 21:01:08.094323\n",
      "resetting env. episode 3971, reward total was -19.0. running mean: -19.64597148030659, timestamp: 2022-08-19 21:01:11.376878\n",
      "resetting env. episode 3972, reward total was -21.0. running mean: -19.659511765503524, timestamp: 2022-08-19 21:01:14.094911\n",
      "resetting env. episode 3973, reward total was -21.0. running mean: -19.67291664784849, timestamp: 2022-08-19 21:01:16.819940\n",
      "resetting env. episode 3974, reward total was -18.0. running mean: -19.656187481370004, timestamp: 2022-08-19 21:01:19.928979\n",
      "resetting env. episode 3975, reward total was -21.0. running mean: -19.669625606556306, timestamp: 2022-08-19 21:01:22.728010\n",
      "resetting env. episode 3976, reward total was -19.0. running mean: -19.662929350490742, timestamp: 2022-08-19 21:01:25.611042\n",
      "resetting env. episode 3977, reward total was -19.0. running mean: -19.656300056985835, timestamp: 2022-08-19 21:01:28.640078\n",
      "resetting env. episode 3978, reward total was -21.0. running mean: -19.669737056415975, timestamp: 2022-08-19 21:01:32.165119\n",
      "resetting env. episode 3979, reward total was -19.0. running mean: -19.663039685851817, timestamp: 2022-08-19 21:01:34.748149\n",
      "resetting env. episode 3980, reward total was -19.0. running mean: -19.656409288993302, timestamp: 2022-08-19 21:01:38.445191\n",
      "resetting env. episode 3981, reward total was -18.0. running mean: -19.63984519610337, timestamp: 2022-08-19 21:01:41.545232\n",
      "resetting env. episode 3982, reward total was -20.0. running mean: -19.643446744142334, timestamp: 2022-08-19 21:01:44.268260\n",
      "resetting env. episode 3983, reward total was -20.0. running mean: -19.64701227670091, timestamp: 2022-08-19 21:01:47.117292\n",
      "resetting env. episode 3984, reward total was -21.0. running mean: -19.6605421539339, timestamp: 2022-08-19 21:01:49.423321\n",
      "resetting env. episode 3985, reward total was -19.0. running mean: -19.653936732394563, timestamp: 2022-08-19 21:01:52.243355\n",
      "resetting env. episode 3986, reward total was -21.0. running mean: -19.667397365070617, timestamp: 2022-08-19 21:01:54.481376\n",
      "resetting env. episode 3987, reward total was -19.0. running mean: -19.66072339141991, timestamp: 2022-08-19 21:01:57.901417\n",
      "resetting env. episode 3988, reward total was -21.0. running mean: -19.67411615750571, timestamp: 2022-08-19 21:02:00.630450\n",
      "resetting env. episode 3989, reward total was -20.0. running mean: -19.677374995930652, timestamp: 2022-08-19 21:02:03.182478\n",
      "resetting env. episode 3990, reward total was -21.0. running mean: -19.690601245971347, timestamp: 2022-08-19 21:02:05.760507\n",
      "resetting env. episode 3991, reward total was -20.0. running mean: -19.693695233511633, timestamp: 2022-08-19 21:02:08.258537\n",
      "resetting env. episode 3992, reward total was -19.0. running mean: -19.68675828117652, timestamp: 2022-08-19 21:02:12.281585\n",
      "resetting env. episode 3993, reward total was -17.0. running mean: -19.659890698364755, timestamp: 2022-08-19 21:02:15.776625\n",
      "resetting env. episode 3994, reward total was -18.0. running mean: -19.643291791381106, timestamp: 2022-08-19 21:02:19.313667\n",
      "resetting env. episode 3995, reward total was -19.0. running mean: -19.636858873467297, timestamp: 2022-08-19 21:02:22.110701\n",
      "resetting env. episode 3996, reward total was -20.0. running mean: -19.64049028473262, timestamp: 2022-08-19 21:02:24.225723\n",
      "resetting env. episode 3997, reward total was -21.0. running mean: -19.654085381885295, timestamp: 2022-08-19 21:02:27.068761\n",
      "resetting env. episode 3998, reward total was -19.0. running mean: -19.647544528066444, timestamp: 2022-08-19 21:02:29.634788\n",
      "resetting env. episode 3999, reward total was -20.0. running mean: -19.651069082785778, timestamp: 2022-08-19 21:02:32.022815\n",
      "resetting env. episode 4000, reward total was -21.0. running mean: -19.66455839195792, timestamp: 2022-08-19 21:02:35.385854\n",
      "resetting env. episode 4001, reward total was -19.0. running mean: -19.657912808038343, timestamp: 2022-08-19 21:02:38.571890\n",
      "resetting env. episode 4002, reward total was -20.0. running mean: -19.66133367995796, timestamp: 2022-08-19 21:02:41.078919\n",
      "resetting env. episode 4003, reward total was -20.0. running mean: -19.66472034315838, timestamp: 2022-08-19 21:02:44.038952\n",
      "resetting env. episode 4004, reward total was -20.0. running mean: -19.668073139726793, timestamp: 2022-08-19 21:02:46.659984\n",
      "resetting env. episode 4005, reward total was -19.0. running mean: -19.661392408329526, timestamp: 2022-08-19 21:02:49.223017\n",
      "resetting env. episode 4006, reward total was -18.0. running mean: -19.64477848424623, timestamp: 2022-08-19 21:02:52.127048\n",
      "resetting env. episode 4007, reward total was -19.0. running mean: -19.63833069940377, timestamp: 2022-08-19 21:02:54.906081\n",
      "resetting env. episode 4008, reward total was -20.0. running mean: -19.641947392409733, timestamp: 2022-08-19 21:02:57.914116\n",
      "resetting env. episode 4009, reward total was -19.0. running mean: -19.635527918485636, timestamp: 2022-08-19 21:03:01.296156\n",
      "resetting env. episode 4010, reward total was -20.0. running mean: -19.639172639300778, timestamp: 2022-08-19 21:03:03.230177\n",
      "resetting env. episode 4011, reward total was -19.0. running mean: -19.632780912907773, timestamp: 2022-08-19 21:03:05.914210\n",
      "resetting env. episode 4012, reward total was -21.0. running mean: -19.646453103778697, timestamp: 2022-08-19 21:03:08.548243\n",
      "resetting env. episode 4013, reward total was -19.0. running mean: -19.63998857274091, timestamp: 2022-08-19 21:03:10.831265\n",
      "resetting env. episode 4014, reward total was -18.0. running mean: -19.623588687013502, timestamp: 2022-08-19 21:03:14.108303\n",
      "resetting env. episode 4015, reward total was -20.0. running mean: -19.627352800143367, timestamp: 2022-08-19 21:03:17.141341\n",
      "resetting env. episode 4016, reward total was -20.0. running mean: -19.631079272141932, timestamp: 2022-08-19 21:03:20.830916\n",
      "resetting env. episode 4017, reward total was -20.0. running mean: -19.63476847942051, timestamp: 2022-08-19 21:03:23.850945\n",
      "resetting env. episode 4018, reward total was -18.0. running mean: -19.618420794626307, timestamp: 2022-08-19 21:03:26.655977\n",
      "resetting env. episode 4019, reward total was -20.0. running mean: -19.622236586680042, timestamp: 2022-08-19 21:03:29.627014\n",
      "resetting env. episode 4020, reward total was -17.0. running mean: -19.59601422081324, timestamp: 2022-08-19 21:03:32.145042\n",
      "resetting env. episode 4021, reward total was -21.0. running mean: -19.61005407860511, timestamp: 2022-08-19 21:03:35.628085\n",
      "resetting env. episode 4022, reward total was -21.0. running mean: -19.62395353781906, timestamp: 2022-08-19 21:03:39.190651\n",
      "resetting env. episode 4023, reward total was -17.0. running mean: -19.59771400244087, timestamp: 2022-08-19 21:03:41.996684\n",
      "resetting env. episode 4024, reward total was -20.0. running mean: -19.601736862416463, timestamp: 2022-08-19 21:03:44.661715\n",
      "resetting env. episode 4025, reward total was -20.0. running mean: -19.605719493792297, timestamp: 2022-08-19 21:03:47.390745\n",
      "resetting env. episode 4026, reward total was -20.0. running mean: -19.609662298854374, timestamp: 2022-08-19 21:03:49.355770\n",
      "resetting env. episode 4027, reward total was -20.0. running mean: -19.61356567586583, timestamp: 2022-08-19 21:03:52.229804\n",
      "resetting env. episode 4028, reward total was -20.0. running mean: -19.617430019107168, timestamp: 2022-08-19 21:03:56.271373\n",
      "resetting env. episode 4029, reward total was -20.0. running mean: -19.621255718916096, timestamp: 2022-08-19 21:03:59.486407\n",
      "resetting env. episode 4030, reward total was -21.0. running mean: -19.635043161726937, timestamp: 2022-08-19 21:04:02.373440\n",
      "resetting env. episode 4031, reward total was -17.0. running mean: -19.60869273010967, timestamp: 2022-08-19 21:04:06.082488\n",
      "resetting env. episode 4032, reward total was -20.0. running mean: -19.612605802808574, timestamp: 2022-08-19 21:04:08.556515\n",
      "resetting env. episode 4033, reward total was -19.0. running mean: -19.60647974478049, timestamp: 2022-08-19 21:04:11.703550\n",
      "resetting env. episode 4034, reward total was -21.0. running mean: -19.620414947332687, timestamp: 2022-08-19 21:04:14.493581\n",
      "resetting env. episode 4035, reward total was -18.0. running mean: -19.60421079785936, timestamp: 2022-08-19 21:04:17.371616\n",
      "resetting env. episode 4036, reward total was -21.0. running mean: -19.618168689880765, timestamp: 2022-08-19 21:04:20.210649\n",
      "resetting env. episode 4037, reward total was -20.0. running mean: -19.621987002981957, timestamp: 2022-08-19 21:04:23.300684\n",
      "resetting env. episode 4038, reward total was -19.0. running mean: -19.61576713295214, timestamp: 2022-08-19 21:04:27.082729\n",
      "resetting env. episode 4039, reward total was -21.0. running mean: -19.629609461622618, timestamp: 2022-08-19 21:04:29.889761\n",
      "resetting env. episode 4040, reward total was -20.0. running mean: -19.63331336700639, timestamp: 2022-08-19 21:04:32.911797\n",
      "resetting env. episode 4041, reward total was -21.0. running mean: -19.64698023333633, timestamp: 2022-08-19 21:04:35.587830\n",
      "resetting env. episode 4042, reward total was -20.0. running mean: -19.650510431002964, timestamp: 2022-08-19 21:04:38.500860\n",
      "resetting env. episode 4043, reward total was -17.0. running mean: -19.624005326692934, timestamp: 2022-08-19 21:04:41.301892\n",
      "resetting env. episode 4044, reward total was -20.0. running mean: -19.627765273426004, timestamp: 2022-08-19 21:04:44.249927\n",
      "resetting env. episode 4045, reward total was -17.0. running mean: -19.601487620691746, timestamp: 2022-08-19 21:04:47.830971\n",
      "resetting env. episode 4046, reward total was -19.0. running mean: -19.59547274448483, timestamp: 2022-08-19 21:04:50.885005\n",
      "resetting env. episode 4047, reward total was -20.0. running mean: -19.59951801703998, timestamp: 2022-08-19 21:04:54.333045\n",
      "resetting env. episode 4048, reward total was -18.0. running mean: -19.58352283686958, timestamp: 2022-08-19 21:04:57.474080\n",
      "resetting env. episode 4049, reward total was -20.0. running mean: -19.587687608500882, timestamp: 2022-08-19 21:05:00.075115\n",
      "resetting env. episode 4050, reward total was -20.0. running mean: -19.591810732415873, timestamp: 2022-08-19 21:05:02.724140\n",
      "resetting env. episode 4051, reward total was -14.0. running mean: -19.535892625091716, timestamp: 2022-08-19 21:05:06.469188\n",
      "resetting env. episode 4052, reward total was -19.0. running mean: -19.5305336988408, timestamp: 2022-08-19 21:05:09.692223\n",
      "resetting env. episode 4053, reward total was -19.0. running mean: -19.525228361852392, timestamp: 2022-08-19 21:05:12.786259\n",
      "resetting env. episode 4054, reward total was -18.0. running mean: -19.50997607823387, timestamp: 2022-08-19 21:05:15.780292\n",
      "resetting env. episode 4055, reward total was -18.0. running mean: -19.49487631745153, timestamp: 2022-08-19 21:05:19.162334\n",
      "resetting env. episode 4056, reward total was -18.0. running mean: -19.479927554277015, timestamp: 2022-08-19 21:05:22.358371\n",
      "resetting env. episode 4057, reward total was -21.0. running mean: -19.495128278734246, timestamp: 2022-08-19 21:05:24.858399\n",
      "resetting env. episode 4058, reward total was -20.0. running mean: -19.5001769959469, timestamp: 2022-08-19 21:05:27.983435\n",
      "resetting env. episode 4059, reward total was -18.0. running mean: -19.485175225987433, timestamp: 2022-08-19 21:05:30.936469\n",
      "resetting env. episode 4060, reward total was -18.0. running mean: -19.470323473727557, timestamp: 2022-08-19 21:05:34.022028\n",
      "resetting env. episode 4061, reward total was -19.0. running mean: -19.465620238990283, timestamp: 2022-08-19 21:05:36.653059\n",
      "resetting env. episode 4062, reward total was -18.0. running mean: -19.45096403660038, timestamp: 2022-08-19 21:05:40.989110\n",
      "resetting env. episode 4063, reward total was -21.0. running mean: -19.466454396234376, timestamp: 2022-08-19 21:05:43.480139\n",
      "resetting env. episode 4064, reward total was -21.0. running mean: -19.481789852272033, timestamp: 2022-08-19 21:05:45.818165\n",
      "resetting env. episode 4065, reward total was -19.0. running mean: -19.476971953749313, timestamp: 2022-08-19 21:05:48.859200\n",
      "resetting env. episode 4066, reward total was -17.0. running mean: -19.45220223421182, timestamp: 2022-08-19 21:05:52.225242\n",
      "resetting env. episode 4067, reward total was -21.0. running mean: -19.467680211869705, timestamp: 2022-08-19 21:05:55.258278\n",
      "resetting env. episode 4068, reward total was -20.0. running mean: -19.47300340975101, timestamp: 2022-08-19 21:05:58.465315\n",
      "resetting env. episode 4069, reward total was -18.0. running mean: -19.458273375653498, timestamp: 2022-08-19 21:06:01.019343\n",
      "resetting env. episode 4070, reward total was -21.0. running mean: -19.47369064189696, timestamp: 2022-08-19 21:06:03.531371\n",
      "resetting env. episode 4071, reward total was -18.0. running mean: -19.45895373547799, timestamp: 2022-08-19 21:06:06.302406\n",
      "resetting env. episode 4072, reward total was -20.0. running mean: -19.46436419812321, timestamp: 2022-08-19 21:06:09.624446\n",
      "resetting env. episode 4073, reward total was -20.0. running mean: -19.469720556141976, timestamp: 2022-08-19 21:06:11.961471\n",
      "resetting env. episode 4074, reward total was -21.0. running mean: -19.48502335058056, timestamp: 2022-08-19 21:06:14.832553\n",
      "resetting env. episode 4075, reward total was -20.0. running mean: -19.49017311707475, timestamp: 2022-08-19 21:06:18.108586\n",
      "resetting env. episode 4076, reward total was -18.0. running mean: -19.475271385904, timestamp: 2022-08-19 21:06:21.179622\n",
      "resetting env. episode 4077, reward total was -19.0. running mean: -19.470518672044964, timestamp: 2022-08-19 21:06:25.126671\n",
      "resetting env. episode 4078, reward total was -19.0. running mean: -19.465813485324514, timestamp: 2022-08-19 21:06:27.603695\n",
      "resetting env. episode 4079, reward total was -20.0. running mean: -19.471155350471268, timestamp: 2022-08-19 21:06:30.431732\n",
      "resetting env. episode 4080, reward total was -18.0. running mean: -19.456443796966553, timestamp: 2022-08-19 21:06:33.897768\n",
      "resetting env. episode 4081, reward total was -20.0. running mean: -19.461879358996885, timestamp: 2022-08-19 21:06:36.298799\n",
      "resetting env. episode 4082, reward total was -20.0. running mean: -19.467260565406917, timestamp: 2022-08-19 21:06:39.755839\n",
      "resetting env. episode 4083, reward total was -19.0. running mean: -19.46258795975285, timestamp: 2022-08-19 21:06:43.217879\n",
      "resetting env. episode 4084, reward total was -20.0. running mean: -19.46796208015532, timestamp: 2022-08-19 21:06:46.107910\n",
      "resetting env. episode 4085, reward total was -21.0. running mean: -19.483282459353767, timestamp: 2022-08-19 21:06:48.755943\n",
      "resetting env. episode 4086, reward total was -19.0. running mean: -19.47844963476023, timestamp: 2022-08-19 21:06:51.506973\n",
      "resetting env. episode 4087, reward total was -21.0. running mean: -19.49366513841263, timestamp: 2022-08-19 21:06:53.767999\n",
      "resetting env. episode 4088, reward total was -21.0. running mean: -19.508728487028506, timestamp: 2022-08-19 21:06:57.393040\n",
      "resetting env. episode 4089, reward total was -20.0. running mean: -19.51364120215822, timestamp: 2022-08-19 21:07:00.029598\n",
      "resetting env. episode 4090, reward total was -19.0. running mean: -19.508504790136637, timestamp: 2022-08-19 21:07:03.477640\n",
      "resetting env. episode 4091, reward total was -21.0. running mean: -19.523419742235273, timestamp: 2022-08-19 21:07:06.555674\n",
      "resetting env. episode 4092, reward total was -20.0. running mean: -19.52818554481292, timestamp: 2022-08-19 21:07:09.831713\n",
      "resetting env. episode 4093, reward total was -21.0. running mean: -19.542903689364792, timestamp: 2022-08-19 21:07:13.111749\n",
      "resetting env. episode 4094, reward total was -17.0. running mean: -19.517474652471144, timestamp: 2022-08-19 21:07:16.397788\n",
      "resetting env. episode 4095, reward total was -19.0. running mean: -19.512299905946435, timestamp: 2022-08-19 21:07:18.853818\n",
      "resetting env. episode 4096, reward total was -17.0. running mean: -19.487176906886972, timestamp: 2022-08-19 21:07:23.228866\n",
      "resetting env. episode 4097, reward total was -20.0. running mean: -19.492305137818104, timestamp: 2022-08-19 21:07:25.996899\n",
      "resetting env. episode 4098, reward total was -18.0. running mean: -19.47738208643992, timestamp: 2022-08-19 21:07:30.345947\n",
      "resetting env. episode 4099, reward total was -19.0. running mean: -19.472608265575523, timestamp: 2022-08-19 21:07:33.345980\n",
      "resetting env. episode 4100, reward total was -17.0. running mean: -19.44788218291977, timestamp: 2022-08-19 21:07:36.370015\n",
      "resetting env. episode 4101, reward total was -19.0. running mean: -19.443403361090574, timestamp: 2022-08-19 21:07:39.746054\n",
      "resetting env. episode 4102, reward total was -20.0. running mean: -19.448969327479666, timestamp: 2022-08-19 21:07:42.511090\n",
      "resetting env. episode 4103, reward total was -19.0. running mean: -19.44447963420487, timestamp: 2022-08-19 21:07:45.301120\n",
      "resetting env. episode 4104, reward total was -19.0. running mean: -19.440034837862825, timestamp: 2022-08-19 21:07:48.739160\n",
      "resetting env. episode 4105, reward total was -21.0. running mean: -19.455634489484197, timestamp: 2022-08-19 21:07:52.000195\n",
      "resetting env. episode 4106, reward total was -19.0. running mean: -19.451078144589356, timestamp: 2022-08-19 21:07:54.700229\n",
      "resetting env. episode 4107, reward total was -19.0. running mean: -19.446567363143465, timestamp: 2022-08-19 21:07:57.865265\n",
      "resetting env. episode 4108, reward total was -20.0. running mean: -19.45210168951203, timestamp: 2022-08-19 21:08:00.819295\n",
      "resetting env. episode 4109, reward total was -20.0. running mean: -19.45758067261691, timestamp: 2022-08-19 21:08:04.683343\n",
      "resetting env. episode 4110, reward total was -18.0. running mean: -19.44300486589074, timestamp: 2022-08-19 21:08:07.781376\n",
      "resetting env. episode 4111, reward total was -20.0. running mean: -19.44857481723183, timestamp: 2022-08-19 21:08:11.199417\n",
      "resetting env. episode 4112, reward total was -19.0. running mean: -19.444089069059512, timestamp: 2022-08-19 21:08:13.558443\n",
      "resetting env. episode 4113, reward total was -21.0. running mean: -19.459648178368916, timestamp: 2022-08-19 21:08:16.485476\n",
      "resetting env. episode 4114, reward total was -19.0. running mean: -19.455051696585226, timestamp: 2022-08-19 21:08:19.177508\n",
      "resetting env. episode 4115, reward total was -18.0. running mean: -19.440501179619375, timestamp: 2022-08-19 21:08:22.213544\n",
      "resetting env. episode 4116, reward total was -19.0. running mean: -19.436096167823184, timestamp: 2022-08-19 21:08:26.182589\n",
      "resetting env. episode 4117, reward total was -19.0. running mean: -19.431735206144953, timestamp: 2022-08-19 21:08:28.930146\n",
      "resetting env. episode 4118, reward total was -20.0. running mean: -19.437417854083503, timestamp: 2022-08-19 21:08:31.953180\n",
      "resetting env. episode 4119, reward total was -19.0. running mean: -19.43304367554267, timestamp: 2022-08-19 21:08:35.320221\n",
      "resetting env. episode 4120, reward total was -20.0. running mean: -19.438713238787244, timestamp: 2022-08-19 21:08:38.239255\n",
      "resetting env. episode 4121, reward total was -21.0. running mean: -19.45432610639937, timestamp: 2022-08-19 21:08:40.746284\n",
      "resetting env. episode 4122, reward total was -21.0. running mean: -19.469782845335377, timestamp: 2022-08-19 21:08:43.802321\n",
      "resetting env. episode 4123, reward total was -19.0. running mean: -19.465085016882025, timestamp: 2022-08-19 21:08:47.969366\n",
      "resetting env. episode 4124, reward total was -21.0. running mean: -19.480434166713206, timestamp: 2022-08-19 21:08:50.457396\n",
      "resetting env. episode 4125, reward total was -18.0. running mean: -19.465629825046072, timestamp: 2022-08-19 21:08:53.523428\n",
      "resetting env. episode 4126, reward total was -21.0. running mean: -19.480973526795612, timestamp: 2022-08-19 21:08:56.074460\n",
      "resetting env. episode 4127, reward total was -20.0. running mean: -19.486163791527655, timestamp: 2022-08-19 21:08:58.902490\n",
      "resetting env. episode 4128, reward total was -19.0. running mean: -19.48130215361238, timestamp: 2022-08-19 21:09:02.577531\n",
      "resetting env. episode 4129, reward total was -20.0. running mean: -19.486489132076255, timestamp: 2022-08-19 21:09:05.296564\n",
      "resetting env. episode 4130, reward total was -21.0. running mean: -19.501624240755493, timestamp: 2022-08-19 21:09:07.389590\n",
      "resetting env. episode 4131, reward total was -19.0. running mean: -19.49660799834794, timestamp: 2022-08-19 21:09:10.763628\n",
      "resetting env. episode 4132, reward total was -20.0. running mean: -19.50164191836446, timestamp: 2022-08-19 21:09:13.307178\n",
      "resetting env. episode 4133, reward total was -17.0. running mean: -19.476625499180816, timestamp: 2022-08-19 21:09:16.409212\n",
      "resetting env. episode 4134, reward total was -20.0. running mean: -19.481859244189007, timestamp: 2022-08-19 21:09:18.590248\n",
      "resetting env. episode 4135, reward total was -20.0. running mean: -19.487040651747115, timestamp: 2022-08-19 21:09:21.610270\n",
      "resetting env. episode 4136, reward total was -21.0. running mean: -19.502170245229646, timestamp: 2022-08-19 21:09:24.230302\n",
      "resetting env. episode 4137, reward total was -20.0. running mean: -19.507148542777347, timestamp: 2022-08-19 21:09:26.363327\n",
      "resetting env. episode 4138, reward total was -20.0. running mean: -19.512077057349572, timestamp: 2022-08-19 21:09:28.873363\n",
      "resetting env. episode 4139, reward total was -20.0. running mean: -19.516956286776075, timestamp: 2022-08-19 21:09:32.038391\n",
      "resetting env. episode 4140, reward total was -19.0. running mean: -19.511786723908315, timestamp: 2022-08-19 21:09:34.939423\n",
      "resetting env. episode 4141, reward total was -20.0. running mean: -19.51666885666923, timestamp: 2022-08-19 21:09:38.380464\n",
      "resetting env. episode 4142, reward total was -19.0. running mean: -19.51150216810254, timestamp: 2022-08-19 21:09:41.898503\n",
      "resetting env. episode 4143, reward total was -19.0. running mean: -19.506387146421513, timestamp: 2022-08-19 21:09:45.116539\n",
      "resetting env. episode 4144, reward total was -19.0. running mean: -19.5013232749573, timestamp: 2022-08-19 21:09:47.371565\n",
      "resetting env. episode 4145, reward total was -16.0. running mean: -19.466310042207727, timestamp: 2022-08-19 21:09:50.576605\n",
      "resetting env. episode 4146, reward total was -20.0. running mean: -19.47164694178565, timestamp: 2022-08-19 21:09:53.524636\n",
      "resetting env. episode 4147, reward total was -19.0. running mean: -19.466930472367796, timestamp: 2022-08-19 21:09:55.949662\n",
      "resetting env. episode 4148, reward total was -18.0. running mean: -19.452261167644117, timestamp: 2022-08-19 21:09:58.739694\n",
      "resetting env. episode 4149, reward total was -19.0. running mean: -19.44773855596768, timestamp: 2022-08-19 21:10:01.746729\n",
      "resetting env. episode 4150, reward total was -20.0. running mean: -19.453261170408002, timestamp: 2022-08-19 21:10:04.207756\n",
      "resetting env. episode 4151, reward total was -17.0. running mean: -19.428728558703924, timestamp: 2022-08-19 21:10:07.351794\n",
      "resetting env. episode 4152, reward total was -17.0. running mean: -19.404441273116888, timestamp: 2022-08-19 21:10:11.349364\n",
      "resetting env. episode 4153, reward total was -19.0. running mean: -19.40039686038572, timestamp: 2022-08-19 21:10:14.329397\n",
      "resetting env. episode 4154, reward total was -20.0. running mean: -19.40639289178186, timestamp: 2022-08-19 21:10:17.228430\n",
      "resetting env. episode 4155, reward total was -20.0. running mean: -19.41232896286404, timestamp: 2022-08-19 21:10:20.411470\n",
      "resetting env. episode 4156, reward total was -20.0. running mean: -19.4182056732354, timestamp: 2022-08-19 21:10:23.210499\n",
      "resetting env. episode 4157, reward total was -20.0. running mean: -19.424023616503042, timestamp: 2022-08-19 21:10:25.909533\n",
      "resetting env. episode 4158, reward total was -20.0. running mean: -19.429783380338012, timestamp: 2022-08-19 21:10:28.947566\n",
      "resetting env. episode 4159, reward total was -19.0. running mean: -19.425485546534635, timestamp: 2022-08-19 21:10:31.690597\n",
      "resetting env. episode 4160, reward total was -20.0. running mean: -19.43123069106929, timestamp: 2022-08-19 21:10:34.781631\n",
      "resetting env. episode 4161, reward total was -20.0. running mean: -19.436918384158595, timestamp: 2022-08-19 21:10:37.668666\n",
      "resetting env. episode 4162, reward total was -20.0. running mean: -19.442549200317007, timestamp: 2022-08-19 21:10:41.144703\n",
      "resetting env. episode 4163, reward total was -21.0. running mean: -19.45812370831384, timestamp: 2022-08-19 21:10:44.196740\n",
      "resetting env. episode 4164, reward total was -20.0. running mean: -19.4635424712307, timestamp: 2022-08-19 21:10:47.854306\n",
      "resetting env. episode 4165, reward total was -19.0. running mean: -19.458907046518394, timestamp: 2022-08-19 21:10:50.284333\n",
      "resetting env. episode 4166, reward total was -19.0. running mean: -19.45431797605321, timestamp: 2022-08-19 21:10:53.094368\n",
      "resetting env. episode 4167, reward total was -19.0. running mean: -19.44977479629268, timestamp: 2022-08-19 21:10:56.691406\n",
      "resetting env. episode 4168, reward total was -19.0. running mean: -19.445277048329753, timestamp: 2022-08-19 21:11:00.114448\n",
      "resetting env. episode 4169, reward total was -19.0. running mean: -19.440824277846456, timestamp: 2022-08-19 21:11:03.678487\n",
      "resetting env. episode 4170, reward total was -19.0. running mean: -19.436416035067992, timestamp: 2022-08-19 21:11:06.034512\n",
      "resetting env. episode 4171, reward total was -18.0. running mean: -19.42205187471731, timestamp: 2022-08-19 21:11:09.077549\n",
      "resetting env. episode 4172, reward total was -20.0. running mean: -19.427831355970138, timestamp: 2022-08-19 21:11:12.243594\n",
      "resetting env. episode 4173, reward total was -20.0. running mean: -19.433553042410434, timestamp: 2022-08-19 21:11:14.440611\n",
      "resetting env. episode 4174, reward total was -21.0. running mean: -19.44921751198633, timestamp: 2022-08-19 21:11:17.315639\n",
      "resetting env. episode 4175, reward total was -21.0. running mean: -19.46472533686647, timestamp: 2022-08-19 21:11:19.642666\n",
      "resetting env. episode 4176, reward total was -21.0. running mean: -19.480078083497805, timestamp: 2022-08-19 21:11:22.078696\n",
      "resetting env. episode 4177, reward total was -18.0. running mean: -19.465277302662827, timestamp: 2022-08-19 21:11:25.179727\n",
      "resetting env. episode 4178, reward total was -19.0. running mean: -19.4606245296362, timestamp: 2022-08-19 21:11:27.819761\n",
      "resetting env. episode 4179, reward total was -18.0. running mean: -19.446018284339836, timestamp: 2022-08-19 21:11:30.335789\n",
      "resetting env. episode 4180, reward total was -20.0. running mean: -19.451558101496435, timestamp: 2022-08-19 21:11:33.409821\n",
      "resetting env. episode 4181, reward total was -21.0. running mean: -19.46704252048147, timestamp: 2022-08-19 21:11:37.023906\n",
      "resetting env. episode 4182, reward total was -21.0. running mean: -19.482372095276656, timestamp: 2022-08-19 21:11:40.044939\n",
      "resetting env. episode 4183, reward total was -19.0. running mean: -19.47754837432389, timestamp: 2022-08-19 21:11:43.310977\n",
      "resetting env. episode 4184, reward total was -20.0. running mean: -19.48277289058065, timestamp: 2022-08-19 21:11:45.406001\n",
      "resetting env. episode 4185, reward total was -18.0. running mean: -19.467945161674844, timestamp: 2022-08-19 21:11:48.045032\n",
      "resetting env. episode 4186, reward total was -18.0. running mean: -19.453265710058094, timestamp: 2022-08-19 21:11:50.966598\n",
      "resetting env. episode 4187, reward total was -19.0. running mean: -19.448733052957515, timestamp: 2022-08-19 21:11:53.654627\n",
      "resetting env. episode 4188, reward total was -16.0. running mean: -19.41424572242794, timestamp: 2022-08-19 21:11:56.821661\n",
      "resetting env. episode 4189, reward total was -19.0. running mean: -19.41010326520366, timestamp: 2022-08-19 21:12:00.121704\n",
      "resetting env. episode 4190, reward total was -20.0. running mean: -19.416002232551623, timestamp: 2022-08-19 21:12:02.855731\n",
      "resetting env. episode 4191, reward total was -18.0. running mean: -19.401842210226107, timestamp: 2022-08-19 21:12:05.579761\n",
      "resetting env. episode 4192, reward total was -18.0. running mean: -19.387823788123846, timestamp: 2022-08-19 21:12:08.309790\n",
      "resetting env. episode 4193, reward total was -19.0. running mean: -19.383945550242608, timestamp: 2022-08-19 21:12:11.103822\n",
      "resetting env. episode 4194, reward total was -20.0. running mean: -19.39010609474018, timestamp: 2022-08-19 21:12:14.088859\n",
      "resetting env. episode 4195, reward total was -21.0. running mean: -19.40620503379278, timestamp: 2022-08-19 21:12:16.639885\n",
      "resetting env. episode 4196, reward total was -20.0. running mean: -19.412142983454853, timestamp: 2022-08-19 21:12:18.785912\n",
      "resetting env. episode 4197, reward total was -19.0. running mean: -19.408021553620305, timestamp: 2022-08-19 21:12:21.227939\n",
      "resetting env. episode 4198, reward total was -19.0. running mean: -19.403941338084103, timestamp: 2022-08-19 21:12:24.157971\n",
      "resetting env. episode 4199, reward total was -21.0. running mean: -19.41990192470326, timestamp: 2022-08-19 21:12:26.986002\n",
      "resetting env. episode 4200, reward total was -21.0. running mean: -19.43570290545623, timestamp: 2022-08-19 21:12:29.884035\n",
      "resetting env. episode 4201, reward total was -20.0. running mean: -19.441345876401666, timestamp: 2022-08-19 21:12:32.430075\n",
      "resetting env. episode 4202, reward total was -21.0. running mean: -19.45693241763765, timestamp: 2022-08-19 21:12:34.744089\n",
      "resetting env. episode 4203, reward total was -20.0. running mean: -19.46236309346127, timestamp: 2022-08-19 21:12:37.580122\n",
      "resetting env. episode 4204, reward total was -20.0. running mean: -19.46773946252666, timestamp: 2022-08-19 21:12:39.890151\n",
      "resetting env. episode 4205, reward total was -19.0. running mean: -19.463062067901394, timestamp: 2022-08-19 21:12:42.961183\n",
      "resetting env. episode 4206, reward total was -18.0. running mean: -19.44843144722238, timestamp: 2022-08-19 21:12:45.943220\n",
      "resetting env. episode 4207, reward total was -19.0. running mean: -19.443947132750157, timestamp: 2022-08-19 21:12:48.650246\n",
      "resetting env. episode 4208, reward total was -19.0. running mean: -19.439507661422656, timestamp: 2022-08-19 21:12:52.365290\n",
      "resetting env. episode 4209, reward total was -19.0. running mean: -19.43511258480843, timestamp: 2022-08-19 21:12:55.965331\n",
      "resetting env. episode 4210, reward total was -20.0. running mean: -19.440761458960345, timestamp: 2022-08-19 21:12:58.662361\n",
      "resetting env. episode 4211, reward total was -21.0. running mean: -19.456353844370742, timestamp: 2022-08-19 21:13:01.238388\n",
      "resetting env. episode 4212, reward total was -18.0. running mean: -19.441790305927036, timestamp: 2022-08-19 21:13:03.958422\n",
      "resetting env. episode 4213, reward total was -19.0. running mean: -19.437372402867766, timestamp: 2022-08-19 21:13:07.619468\n",
      "resetting env. episode 4214, reward total was -17.0. running mean: -19.412998678839088, timestamp: 2022-08-19 21:13:11.254501\n",
      "resetting env. episode 4215, reward total was -20.0. running mean: -19.418868692050697, timestamp: 2022-08-19 21:13:14.454538\n",
      "resetting env. episode 4216, reward total was -20.0. running mean: -19.424680005130188, timestamp: 2022-08-19 21:13:16.764564\n",
      "resetting env. episode 4217, reward total was -20.0. running mean: -19.430433205078884, timestamp: 2022-08-19 21:13:19.924601\n",
      "resetting env. episode 4218, reward total was -18.0. running mean: -19.416128873028097, timestamp: 2022-08-19 21:13:22.894633\n",
      "resetting env. episode 4219, reward total was -20.0. running mean: -19.421967584297814, timestamp: 2022-08-19 21:13:25.470662\n",
      "resetting env. episode 4220, reward total was -19.0. running mean: -19.41774790845484, timestamp: 2022-08-19 21:13:29.023701\n",
      "resetting env. episode 4221, reward total was -20.0. running mean: -19.42357042937029, timestamp: 2022-08-19 21:13:31.938734\n",
      "resetting env. episode 4222, reward total was -19.0. running mean: -19.419334725076588, timestamp: 2022-08-19 21:13:35.373776\n",
      "resetting env. episode 4223, reward total was -21.0. running mean: -19.435141377825822, timestamp: 2022-08-19 21:13:38.566821\n",
      "resetting env. episode 4224, reward total was -21.0. running mean: -19.450789964047566, timestamp: 2022-08-19 21:13:42.366850\n",
      "resetting env. episode 4225, reward total was -21.0. running mean: -19.46628206440709, timestamp: 2022-08-19 21:13:44.039868\n",
      "resetting env. episode 4226, reward total was -17.0. running mean: -19.441619243763018, timestamp: 2022-08-19 21:13:47.403906\n",
      "resetting env. episode 4227, reward total was -19.0. running mean: -19.43720305132539, timestamp: 2022-08-19 21:13:50.411943\n",
      "resetting env. episode 4228, reward total was -20.0. running mean: -19.442831020812136, timestamp: 2022-08-19 21:13:53.057968\n",
      "resetting env. episode 4229, reward total was -19.0. running mean: -19.438402710604016, timestamp: 2022-08-19 21:13:55.745000\n",
      "resetting env. episode 4230, reward total was -17.0. running mean: -19.41401868349798, timestamp: 2022-08-19 21:13:59.118036\n",
      "resetting env. episode 4231, reward total was -21.0. running mean: -19.429878496663, timestamp: 2022-08-19 21:14:02.235071\n",
      "resetting env. episode 4232, reward total was -17.0. running mean: -19.405579711696372, timestamp: 2022-08-19 21:14:05.746114\n",
      "resetting env. episode 4233, reward total was -21.0. running mean: -19.42152391457941, timestamp: 2022-08-19 21:14:08.706144\n",
      "resetting env. episode 4234, reward total was -20.0. running mean: -19.427308675433615, timestamp: 2022-08-19 21:14:11.603179\n",
      "resetting env. episode 4235, reward total was -20.0. running mean: -19.433035588679278, timestamp: 2022-08-19 21:14:14.418211\n",
      "resetting env. episode 4236, reward total was -18.0. running mean: -19.418705232792483, timestamp: 2022-08-19 21:14:17.804246\n",
      "resetting env. episode 4237, reward total was -21.0. running mean: -19.434518180464558, timestamp: 2022-08-19 21:14:20.847280\n",
      "resetting env. episode 4238, reward total was -20.0. running mean: -19.44017299865991, timestamp: 2022-08-19 21:14:23.410309\n",
      "resetting env. episode 4239, reward total was -19.0. running mean: -19.435771268673314, timestamp: 2022-08-19 21:14:26.203343\n",
      "resetting env. episode 4240, reward total was -20.0. running mean: -19.44141355598658, timestamp: 2022-08-19 21:14:29.017372\n",
      "resetting env. episode 4241, reward total was -19.0. running mean: -19.436999420426712, timestamp: 2022-08-19 21:14:32.564417\n",
      "resetting env. episode 4242, reward total was -20.0. running mean: -19.442629426222446, timestamp: 2022-08-19 21:14:35.196446\n",
      "resetting env. episode 4243, reward total was -20.0. running mean: -19.44820313196022, timestamp: 2022-08-19 21:14:38.343479\n",
      "resetting env. episode 4244, reward total was -19.0. running mean: -19.44372110064062, timestamp: 2022-08-19 21:14:41.060507\n",
      "resetting env. episode 4245, reward total was -21.0. running mean: -19.459283889634214, timestamp: 2022-08-19 21:14:43.887544\n",
      "resetting env. episode 4246, reward total was -20.0. running mean: -19.464691050737873, timestamp: 2022-08-19 21:14:47.045576\n",
      "resetting env. episode 4247, reward total was -19.0. running mean: -19.460044140230494, timestamp: 2022-08-19 21:14:49.741609\n",
      "resetting env. episode 4248, reward total was -20.0. running mean: -19.46544369882819, timestamp: 2022-08-19 21:14:52.565638\n",
      "resetting env. episode 4249, reward total was -17.0. running mean: -19.440789261839907, timestamp: 2022-08-19 21:14:56.170678\n",
      "resetting env. episode 4250, reward total was -20.0. running mean: -19.446381369221506, timestamp: 2022-08-19 21:14:58.234702\n",
      "resetting env. episode 4251, reward total was -19.0. running mean: -19.44191755552929, timestamp: 2022-08-19 21:15:01.208744\n",
      "resetting env. episode 4252, reward total was -20.0. running mean: -19.447498379973997, timestamp: 2022-08-19 21:15:04.137775\n",
      "resetting env. episode 4253, reward total was -20.0. running mean: -19.453023396174256, timestamp: 2022-08-19 21:15:07.086802\n",
      "resetting env. episode 4254, reward total was -21.0. running mean: -19.468493162212514, timestamp: 2022-08-19 21:15:10.150837\n",
      "resetting env. episode 4255, reward total was -16.0. running mean: -19.43380823059039, timestamp: 2022-08-19 21:15:14.171892\n",
      "resetting env. episode 4256, reward total was -18.0. running mean: -19.419470148284486, timestamp: 2022-08-19 21:15:17.217917\n",
      "resetting env. episode 4257, reward total was -19.0. running mean: -19.41527544680164, timestamp: 2022-08-19 21:15:20.002949\n",
      "resetting env. episode 4258, reward total was -18.0. running mean: -19.401122692333622, timestamp: 2022-08-19 21:15:23.526989\n",
      "resetting env. episode 4259, reward total was -17.0. running mean: -19.377111465410287, timestamp: 2022-08-19 21:15:27.475036\n",
      "resetting env. episode 4260, reward total was -21.0. running mean: -19.393340350756183, timestamp: 2022-08-19 21:15:30.429068\n",
      "resetting env. episode 4261, reward total was -21.0. running mean: -19.409406947248623, timestamp: 2022-08-19 21:15:32.766099\n",
      "resetting env. episode 4262, reward total was -20.0. running mean: -19.415312877776135, timestamp: 2022-08-19 21:15:35.415125\n",
      "resetting env. episode 4263, reward total was -17.0. running mean: -19.391159748998376, timestamp: 2022-08-19 21:15:38.591161\n",
      "resetting env. episode 4264, reward total was -20.0. running mean: -19.397248151508393, timestamp: 2022-08-19 21:15:40.879188\n",
      "resetting env. episode 4265, reward total was -20.0. running mean: -19.40327566999331, timestamp: 2022-08-19 21:15:43.382217\n",
      "resetting env. episode 4266, reward total was -19.0. running mean: -19.399242913293378, timestamp: 2022-08-19 21:15:46.373250\n",
      "resetting env. episode 4267, reward total was -21.0. running mean: -19.415250484160445, timestamp: 2022-08-19 21:15:49.668289\n",
      "resetting env. episode 4268, reward total was -21.0. running mean: -19.431097979318842, timestamp: 2022-08-19 21:15:52.022316\n",
      "resetting env. episode 4269, reward total was -17.0. running mean: -19.406786999525654, timestamp: 2022-08-19 21:15:55.053349\n",
      "resetting env. episode 4270, reward total was -20.0. running mean: -19.412719129530398, timestamp: 2022-08-19 21:15:57.542379\n",
      "resetting env. episode 4271, reward total was -19.0. running mean: -19.408591938235094, timestamp: 2022-08-19 21:16:01.631427\n",
      "resetting env. episode 4272, reward total was -20.0. running mean: -19.41450601885274, timestamp: 2022-08-19 21:16:05.104467\n",
      "resetting env. episode 4273, reward total was -21.0. running mean: -19.430360958664213, timestamp: 2022-08-19 21:16:08.449505\n",
      "resetting env. episode 4274, reward total was -17.0. running mean: -19.40605734907757, timestamp: 2022-08-19 21:16:12.276548\n",
      "resetting env. episode 4275, reward total was -20.0. running mean: -19.411996775586793, timestamp: 2022-08-19 21:16:15.854591\n",
      "resetting env. episode 4276, reward total was -19.0. running mean: -19.407876807830927, timestamp: 2022-08-19 21:16:18.135615\n",
      "resetting env. episode 4277, reward total was -19.0. running mean: -19.40379803975262, timestamp: 2022-08-19 21:16:21.289651\n",
      "resetting env. episode 4278, reward total was -21.0. running mean: -19.419760059355095, timestamp: 2022-08-19 21:16:24.031681\n",
      "resetting env. episode 4279, reward total was -20.0. running mean: -19.425562458761544, timestamp: 2022-08-19 21:16:26.798716\n",
      "resetting env. episode 4280, reward total was -18.0. running mean: -19.411306834173928, timestamp: 2022-08-19 21:16:29.314744\n",
      "resetting env. episode 4281, reward total was -19.0. running mean: -19.40719376583219, timestamp: 2022-08-19 21:16:32.105776\n",
      "resetting env. episode 4282, reward total was -21.0. running mean: -19.42312182817387, timestamp: 2022-08-19 21:16:35.495815\n",
      "resetting env. episode 4283, reward total was -21.0. running mean: -19.43889060989213, timestamp: 2022-08-19 21:16:38.097844\n",
      "resetting env. episode 4284, reward total was -19.0. running mean: -19.43450170379321, timestamp: 2022-08-19 21:16:40.593875\n",
      "resetting env. episode 4285, reward total was -21.0. running mean: -19.450156686755278, timestamp: 2022-08-19 21:16:43.195905\n",
      "resetting env. episode 4286, reward total was -20.0. running mean: -19.455655119887723, timestamp: 2022-08-19 21:16:46.252938\n",
      "resetting env. episode 4287, reward total was -17.0. running mean: -19.431098568688846, timestamp: 2022-08-19 21:16:50.125508\n",
      "resetting env. episode 4288, reward total was -20.0. running mean: -19.436787583001955, timestamp: 2022-08-19 21:16:53.145544\n",
      "resetting env. episode 4289, reward total was -20.0. running mean: -19.442419707171936, timestamp: 2022-08-19 21:16:55.772573\n",
      "resetting env. episode 4290, reward total was -21.0. running mean: -19.45799551010022, timestamp: 2022-08-19 21:16:58.621606\n",
      "resetting env. episode 4291, reward total was -18.0. running mean: -19.443415554999216, timestamp: 2022-08-19 21:17:01.771646\n",
      "resetting env. episode 4292, reward total was -16.0. running mean: -19.408981399449225, timestamp: 2022-08-19 21:17:05.397683\n",
      "resetting env. episode 4293, reward total was -20.0. running mean: -19.414891585454733, timestamp: 2022-08-19 21:17:08.818725\n",
      "resetting env. episode 4294, reward total was -20.0. running mean: -19.420742669600184, timestamp: 2022-08-19 21:17:11.439756\n",
      "resetting env. episode 4295, reward total was -20.0. running mean: -19.42653524290418, timestamp: 2022-08-19 21:17:13.975784\n",
      "resetting env. episode 4296, reward total was -20.0. running mean: -19.432269890475137, timestamp: 2022-08-19 21:17:16.987818\n",
      "resetting env. episode 4297, reward total was -20.0. running mean: -19.437947191570384, timestamp: 2022-08-19 21:17:19.879853\n",
      "resetting env. episode 4298, reward total was -21.0. running mean: -19.453567719654682, timestamp: 2022-08-19 21:17:22.610888\n",
      "resetting env. episode 4299, reward total was -20.0. running mean: -19.459032042458134, timestamp: 2022-08-19 21:17:25.448919\n",
      "resetting env. episode 4300, reward total was -21.0. running mean: -19.474441722033554, timestamp: 2022-08-19 21:17:27.798943\n",
      "resetting env. episode 4301, reward total was -20.0. running mean: -19.479697304813218, timestamp: 2022-08-19 21:17:30.779499\n",
      "resetting env. episode 4302, reward total was -19.0. running mean: -19.474900331765088, timestamp: 2022-08-19 21:17:33.837536\n",
      "resetting env. episode 4303, reward total was -17.0. running mean: -19.45015132844744, timestamp: 2022-08-19 21:17:37.692581\n",
      "resetting env. episode 4304, reward total was -21.0. running mean: -19.465649815162966, timestamp: 2022-08-19 21:17:40.737621\n",
      "resetting env. episode 4305, reward total was -19.0. running mean: -19.460993317011337, timestamp: 2022-08-19 21:17:44.214657\n",
      "resetting env. episode 4306, reward total was -20.0. running mean: -19.466383383841222, timestamp: 2022-08-19 21:17:46.825686\n",
      "resetting env. episode 4307, reward total was -19.0. running mean: -19.46171955000281, timestamp: 2022-08-19 21:17:49.721718\n",
      "resetting env. episode 4308, reward total was -19.0. running mean: -19.457102354502783, timestamp: 2022-08-19 21:17:52.874758\n",
      "resetting env. episode 4309, reward total was -19.0. running mean: -19.452531330957758, timestamp: 2022-08-19 21:17:55.832791\n",
      "resetting env. episode 4310, reward total was -21.0. running mean: -19.468006017648182, timestamp: 2022-08-19 21:17:58.262819\n",
      "resetting env. episode 4311, reward total was -21.0. running mean: -19.483325957471703, timestamp: 2022-08-19 21:18:01.657859\n",
      "resetting env. episode 4312, reward total was -19.0. running mean: -19.478492697896986, timestamp: 2022-08-19 21:18:04.919897\n",
      "resetting env. episode 4313, reward total was -21.0. running mean: -19.493707770918018, timestamp: 2022-08-19 21:18:07.607928\n",
      "resetting env. episode 4314, reward total was -17.0. running mean: -19.46877069320884, timestamp: 2022-08-19 21:18:10.759963\n",
      "resetting env. episode 4315, reward total was -21.0. running mean: -19.48408298627675, timestamp: 2022-08-19 21:18:13.503996\n",
      "resetting env. episode 4316, reward total was -21.0. running mean: -19.499242156413985, timestamp: 2022-08-19 21:18:16.531034\n",
      "resetting env. episode 4317, reward total was -20.0. running mean: -19.504249734849843, timestamp: 2022-08-19 21:18:19.653069\n",
      "resetting env. episode 4318, reward total was -18.0. running mean: -19.489207237501343, timestamp: 2022-08-19 21:18:23.593114\n",
      "resetting env. episode 4319, reward total was -21.0. running mean: -19.504315165126332, timestamp: 2022-08-19 21:18:26.522147\n",
      "resetting env. episode 4320, reward total was -21.0. running mean: -19.51927201347507, timestamp: 2022-08-19 21:18:29.591181\n",
      "resetting env. episode 4321, reward total was -19.0. running mean: -19.51407929334032, timestamp: 2022-08-19 21:18:33.086230\n",
      "resetting env. episode 4322, reward total was -18.0. running mean: -19.498938500406915, timestamp: 2022-08-19 21:18:35.862254\n",
      "resetting env. episode 4323, reward total was -21.0. running mean: -19.513949115402845, timestamp: 2022-08-19 21:18:38.394283\n",
      "resetting env. episode 4324, reward total was -18.0. running mean: -19.498809624248818, timestamp: 2022-08-19 21:18:40.999315\n",
      "resetting env. episode 4325, reward total was -19.0. running mean: -19.49382152800633, timestamp: 2022-08-19 21:18:44.513356\n",
      "resetting env. episode 4326, reward total was -19.0. running mean: -19.488883312726266, timestamp: 2022-08-19 21:18:47.933398\n",
      "resetting env. episode 4327, reward total was -20.0. running mean: -19.493994479599003, timestamp: 2022-08-19 21:18:50.607430\n",
      "resetting env. episode 4328, reward total was -17.0. running mean: -19.469054534803014, timestamp: 2022-08-19 21:18:54.190468\n",
      "resetting env. episode 4329, reward total was -19.0. running mean: -19.464363989454984, timestamp: 2022-08-19 21:18:57.615507\n",
      "resetting env. episode 4330, reward total was -19.0. running mean: -19.459720349560435, timestamp: 2022-08-19 21:19:00.910547\n",
      "resetting env. episode 4331, reward total was -19.0. running mean: -19.45512314606483, timestamp: 2022-08-19 21:19:04.505590\n",
      "resetting env. episode 4332, reward total was -19.0. running mean: -19.450571914604186, timestamp: 2022-08-19 21:19:07.577626\n",
      "resetting env. episode 4333, reward total was -20.0. running mean: -19.456066195458142, timestamp: 2022-08-19 21:19:09.581645\n",
      "resetting env. episode 4334, reward total was -17.0. running mean: -19.43150553350356, timestamp: 2022-08-19 21:19:12.309680\n",
      "resetting env. episode 4335, reward total was -20.0. running mean: -19.437190478168525, timestamp: 2022-08-19 21:19:15.490716\n",
      "resetting env. episode 4336, reward total was -18.0. running mean: -19.422818573386838, timestamp: 2022-08-19 21:19:18.574752\n",
      "resetting env. episode 4337, reward total was -19.0. running mean: -19.41859038765297, timestamp: 2022-08-19 21:19:21.881789\n",
      "resetting env. episode 4338, reward total was -20.0. running mean: -19.42440448377644, timestamp: 2022-08-19 21:19:24.732822\n",
      "resetting env. episode 4339, reward total was -19.0. running mean: -19.420160438938677, timestamp: 2022-08-19 21:19:27.409852\n",
      "resetting env. episode 4340, reward total was -18.0. running mean: -19.40595883454929, timestamp: 2022-08-19 21:19:31.027895\n",
      "resetting env. episode 4341, reward total was -20.0. running mean: -19.411899246203795, timestamp: 2022-08-19 21:19:33.977933\n",
      "resetting env. episode 4342, reward total was -20.0. running mean: -19.417780253741757, timestamp: 2022-08-19 21:19:36.676961\n",
      "resetting env. episode 4343, reward total was -20.0. running mean: -19.42360245120434, timestamp: 2022-08-19 21:19:39.399991\n",
      "resetting env. episode 4344, reward total was -19.0. running mean: -19.419366426692296, timestamp: 2022-08-19 21:19:42.542028\n",
      "resetting env. episode 4345, reward total was -19.0. running mean: -19.415172762425374, timestamp: 2022-08-19 21:19:45.816078\n",
      "resetting env. episode 4346, reward total was -19.0. running mean: -19.411021034801124, timestamp: 2022-08-19 21:19:48.977105\n",
      "resetting env. episode 4347, reward total was -20.0. running mean: -19.41691082445311, timestamp: 2022-08-19 21:19:52.128143\n",
      "resetting env. episode 4348, reward total was -21.0. running mean: -19.432741716208582, timestamp: 2022-08-19 21:19:54.908173\n",
      "resetting env. episode 4349, reward total was -20.0. running mean: -19.438414299046496, timestamp: 2022-08-19 21:19:57.629204\n",
      "resetting env. episode 4350, reward total was -18.0. running mean: -19.42403015605603, timestamp: 2022-08-19 21:20:00.623237\n",
      "resetting env. episode 4351, reward total was -19.0. running mean: -19.41978985449547, timestamp: 2022-08-19 21:20:04.159280\n",
      "resetting env. episode 4352, reward total was -21.0. running mean: -19.435591955950514, timestamp: 2022-08-19 21:20:06.720308\n",
      "resetting env. episode 4353, reward total was -18.0. running mean: -19.421236036391008, timestamp: 2022-08-19 21:20:10.241352\n",
      "resetting env. episode 4354, reward total was -21.0. running mean: -19.4370236760271, timestamp: 2022-08-19 21:20:13.213384\n",
      "resetting env. episode 4355, reward total was -21.0. running mean: -19.45265343926683, timestamp: 2022-08-19 21:20:15.351411\n",
      "resetting env. episode 4356, reward total was -19.0. running mean: -19.44812690487416, timestamp: 2022-08-19 21:20:17.825439\n",
      "resetting env. episode 4357, reward total was -21.0. running mean: -19.463645635825422, timestamp: 2022-08-19 21:20:20.397467\n",
      "resetting env. episode 4358, reward total was -18.0. running mean: -19.44900917946717, timestamp: 2022-08-19 21:20:23.388505\n",
      "resetting env. episode 4359, reward total was -21.0. running mean: -19.464519087672496, timestamp: 2022-08-19 21:20:26.862544\n",
      "resetting env. episode 4360, reward total was -20.0. running mean: -19.46987389679577, timestamp: 2022-08-19 21:20:29.629105\n",
      "resetting env. episode 4361, reward total was -20.0. running mean: -19.475175157827813, timestamp: 2022-08-19 21:20:32.632137\n",
      "resetting env. episode 4362, reward total was -17.0. running mean: -19.450423406249538, timestamp: 2022-08-19 21:20:35.963175\n",
      "resetting env. episode 4363, reward total was -20.0. running mean: -19.45591917218704, timestamp: 2022-08-19 21:20:39.039736\n",
      "resetting env. episode 4364, reward total was -21.0. running mean: -19.47135998046517, timestamp: 2022-08-19 21:20:41.889771\n",
      "resetting env. episode 4365, reward total was -17.0. running mean: -19.44664638066052, timestamp: 2022-08-19 21:20:45.985816\n",
      "resetting env. episode 4366, reward total was -19.0. running mean: -19.442179916853917, timestamp: 2022-08-19 21:20:48.685850\n",
      "resetting env. episode 4367, reward total was -21.0. running mean: -19.45775811768538, timestamp: 2022-08-19 21:20:51.238877\n",
      "resetting env. episode 4368, reward total was -20.0. running mean: -19.463180536508524, timestamp: 2022-08-19 21:20:54.416916\n",
      "resetting env. episode 4369, reward total was -21.0. running mean: -19.47854873114344, timestamp: 2022-08-19 21:20:57.758954\n",
      "resetting env. episode 4370, reward total was -20.0. running mean: -19.483763243832005, timestamp: 2022-08-19 21:21:00.776511\n",
      "resetting env. episode 4371, reward total was -20.0. running mean: -19.488925611393682, timestamp: 2022-08-19 21:21:03.995548\n",
      "resetting env. episode 4372, reward total was -19.0. running mean: -19.48403635527975, timestamp: 2022-08-19 21:21:06.939582\n",
      "resetting env. episode 4373, reward total was -18.0. running mean: -19.469195991726952, timestamp: 2022-08-19 21:21:10.332146\n",
      "resetting env. episode 4374, reward total was -18.0. running mean: -19.454504031809684, timestamp: 2022-08-19 21:21:13.529187\n",
      "resetting env. episode 4375, reward total was -21.0. running mean: -19.469958991491588, timestamp: 2022-08-19 21:21:16.865222\n",
      "resetting env. episode 4376, reward total was -20.0. running mean: -19.475259401576672, timestamp: 2022-08-19 21:21:20.188261\n",
      "resetting env. episode 4377, reward total was -20.0. running mean: -19.480506807560904, timestamp: 2022-08-19 21:21:23.080297\n",
      "resetting env. episode 4378, reward total was -20.0. running mean: -19.485701739485293, timestamp: 2022-08-19 21:21:26.057331\n",
      "resetting env. episode 4379, reward total was -20.0. running mean: -19.49084472209044, timestamp: 2022-08-19 21:21:30.018374\n",
      "resetting env. episode 4380, reward total was -20.0. running mean: -19.495936274869536, timestamp: 2022-08-19 21:21:33.217410\n",
      "resetting env. episode 4381, reward total was -21.0. running mean: -19.510976912120842, timestamp: 2022-08-19 21:21:36.002448\n",
      "resetting env. episode 4382, reward total was -19.0. running mean: -19.505867142999634, timestamp: 2022-08-19 21:21:38.689473\n",
      "resetting env. episode 4383, reward total was -20.0. running mean: -19.510808471569636, timestamp: 2022-08-19 21:21:41.445510\n",
      "resetting env. episode 4384, reward total was -20.0. running mean: -19.51570038685394, timestamp: 2022-08-19 21:21:44.447542\n",
      "resetting env. episode 4385, reward total was -19.0. running mean: -19.5105433829854, timestamp: 2022-08-19 21:21:48.472593\n",
      "resetting env. episode 4386, reward total was -20.0. running mean: -19.515437949155544, timestamp: 2022-08-19 21:21:50.698614\n",
      "resetting env. episode 4387, reward total was -17.0. running mean: -19.49028356966399, timestamp: 2022-08-19 21:21:53.974653\n",
      "resetting env. episode 4388, reward total was -20.0. running mean: -19.495380733967348, timestamp: 2022-08-19 21:21:56.981687\n",
      "resetting env. episode 4389, reward total was -19.0. running mean: -19.490426926627677, timestamp: 2022-08-19 21:21:59.974724\n",
      "resetting env. episode 4390, reward total was -19.0. running mean: -19.4855226573614, timestamp: 2022-08-19 21:22:03.350760\n",
      "resetting env. episode 4391, reward total was -21.0. running mean: -19.500667430787786, timestamp: 2022-08-19 21:22:07.636811\n",
      "resetting env. episode 4392, reward total was -20.0. running mean: -19.50566075647991, timestamp: 2022-08-19 21:22:10.439842\n",
      "resetting env. episode 4393, reward total was -17.0. running mean: -19.480604148915113, timestamp: 2022-08-19 21:22:13.363881\n",
      "resetting env. episode 4394, reward total was -20.0. running mean: -19.48579810742596, timestamp: 2022-08-19 21:22:15.796906\n",
      "resetting env. episode 4395, reward total was -20.0. running mean: -19.4909401263517, timestamp: 2022-08-19 21:22:19.054944\n",
      "resetting env. episode 4396, reward total was -20.0. running mean: -19.496030725088183, timestamp: 2022-08-19 21:22:22.711990\n",
      "resetting env. episode 4397, reward total was -21.0. running mean: -19.511070417837303, timestamp: 2022-08-19 21:22:25.656024\n",
      "resetting env. episode 4398, reward total was -19.0. running mean: -19.50595971365893, timestamp: 2022-08-19 21:22:28.396051\n",
      "resetting env. episode 4399, reward total was -20.0. running mean: -19.510900116522343, timestamp: 2022-08-19 21:22:31.130085\n",
      "resetting env. episode 4400, reward total was -16.0. running mean: -19.47579111535712, timestamp: 2022-08-19 21:22:34.080117\n",
      "resetting env. episode 4401, reward total was -18.0. running mean: -19.461033204203545, timestamp: 2022-08-19 21:22:37.140676\n",
      "resetting env. episode 4402, reward total was -20.0. running mean: -19.46642287216151, timestamp: 2022-08-19 21:22:39.914704\n",
      "resetting env. episode 4403, reward total was -18.0. running mean: -19.451758643439895, timestamp: 2022-08-19 21:22:43.132747\n",
      "resetting env. episode 4404, reward total was -21.0. running mean: -19.467241057005495, timestamp: 2022-08-19 21:22:45.594769\n",
      "resetting env. episode 4405, reward total was -20.0. running mean: -19.472568646435438, timestamp: 2022-08-19 21:22:48.967808\n",
      "resetting env. episode 4406, reward total was -19.0. running mean: -19.467842959971083, timestamp: 2022-08-19 21:22:52.183846\n",
      "resetting env. episode 4407, reward total was -21.0. running mean: -19.483164530371372, timestamp: 2022-08-19 21:22:55.299885\n",
      "resetting env. episode 4408, reward total was -20.0. running mean: -19.488332885067656, timestamp: 2022-08-19 21:22:58.107914\n",
      "resetting env. episode 4409, reward total was -21.0. running mean: -19.50344955621698, timestamp: 2022-08-19 21:23:00.999949\n",
      "resetting env. episode 4410, reward total was -21.0. running mean: -19.518415060654814, timestamp: 2022-08-19 21:23:03.615976\n",
      "resetting env. episode 4411, reward total was -20.0. running mean: -19.523230910048266, timestamp: 2022-08-19 21:23:06.752015\n",
      "resetting env. episode 4412, reward total was -18.0. running mean: -19.507998600947783, timestamp: 2022-08-19 21:23:10.160055\n",
      "resetting env. episode 4413, reward total was -20.0. running mean: -19.512918614938304, timestamp: 2022-08-19 21:23:12.811083\n",
      "resetting env. episode 4414, reward total was -21.0. running mean: -19.52778942878892, timestamp: 2022-08-19 21:23:15.833120\n",
      "resetting env. episode 4415, reward total was -21.0. running mean: -19.54251153450103, timestamp: 2022-08-19 21:23:18.543673\n",
      "resetting env. episode 4416, reward total was -20.0. running mean: -19.54708641915602, timestamp: 2022-08-19 21:23:22.283767\n",
      "resetting env. episode 4417, reward total was -21.0. running mean: -19.56161555496446, timestamp: 2022-08-19 21:23:25.086801\n",
      "resetting env. episode 4418, reward total was -19.0. running mean: -19.55599939941482, timestamp: 2022-08-19 21:23:27.946832\n",
      "resetting env. episode 4419, reward total was -20.0. running mean: -19.56043940542067, timestamp: 2022-08-19 21:23:31.173872\n",
      "resetting env. episode 4420, reward total was -21.0. running mean: -19.574835011366464, timestamp: 2022-08-19 21:23:34.224902\n",
      "resetting env. episode 4421, reward total was -21.0. running mean: -19.5890866612528, timestamp: 2022-08-19 21:23:37.912947\n",
      "resetting env. episode 4422, reward total was -20.0. running mean: -19.59319579464027, timestamp: 2022-08-19 21:23:41.277034\n",
      "resetting env. episode 4423, reward total was -18.0. running mean: -19.577263836693866, timestamp: 2022-08-19 21:23:44.444071\n",
      "resetting env. episode 4424, reward total was -18.0. running mean: -19.561491198326927, timestamp: 2022-08-19 21:23:47.294104\n",
      "resetting env. episode 4425, reward total was -21.0. running mean: -19.575876286343657, timestamp: 2022-08-19 21:23:50.208136\n",
      "resetting env. episode 4426, reward total was -20.0. running mean: -19.58011752348022, timestamp: 2022-08-19 21:23:53.720181\n",
      "resetting env. episode 4427, reward total was -20.0. running mean: -19.584316348245416, timestamp: 2022-08-19 21:23:57.376219\n",
      "resetting env. episode 4428, reward total was -20.0. running mean: -19.58847318476296, timestamp: 2022-08-19 21:24:00.263254\n",
      "resetting env. episode 4429, reward total was -21.0. running mean: -19.60258845291533, timestamp: 2022-08-19 21:24:03.011285\n",
      "resetting env. episode 4430, reward total was -17.0. running mean: -19.57656256838618, timestamp: 2022-08-19 21:24:05.740315\n",
      "resetting env. episode 4431, reward total was -20.0. running mean: -19.580796942702317, timestamp: 2022-08-19 21:24:10.149367\n",
      "resetting env. episode 4432, reward total was -20.0. running mean: -19.584988973275294, timestamp: 2022-08-19 21:24:12.989399\n",
      "resetting env. episode 4433, reward total was -17.0. running mean: -19.559139083542544, timestamp: 2022-08-19 21:24:16.298439\n",
      "resetting env. episode 4434, reward total was -19.0. running mean: -19.55354769270712, timestamp: 2022-08-19 21:24:19.285472\n",
      "resetting env. episode 4435, reward total was -21.0. running mean: -19.56801221578005, timestamp: 2022-08-19 21:24:21.661502\n",
      "resetting env. episode 4436, reward total was -19.0. running mean: -19.562332093622253, timestamp: 2022-08-19 21:24:24.635532\n",
      "resetting env. episode 4437, reward total was -20.0. running mean: -19.56670877268603, timestamp: 2022-08-19 21:24:27.316564\n",
      "resetting env. episode 4438, reward total was -20.0. running mean: -19.57104168495917, timestamp: 2022-08-19 21:24:30.189597\n",
      "resetting env. episode 4439, reward total was -21.0. running mean: -19.585331268109577, timestamp: 2022-08-19 21:24:33.747169\n",
      "resetting env. episode 4440, reward total was -18.0. running mean: -19.569477955428482, timestamp: 2022-08-19 21:24:36.456195\n",
      "resetting env. episode 4441, reward total was -20.0. running mean: -19.573783175874198, timestamp: 2022-08-19 21:24:40.068239\n",
      "resetting env. episode 4442, reward total was -16.0. running mean: -19.538045344115456, timestamp: 2022-08-19 21:24:43.294274\n",
      "resetting env. episode 4443, reward total was -21.0. running mean: -19.552664890674304, timestamp: 2022-08-19 21:24:46.512311\n",
      "resetting env. episode 4444, reward total was -21.0. running mean: -19.567138241767562, timestamp: 2022-08-19 21:24:49.704349\n",
      "resetting env. episode 4445, reward total was -20.0. running mean: -19.571466859349886, timestamp: 2022-08-19 21:24:52.574379\n",
      "resetting env. episode 4446, reward total was -18.0. running mean: -19.555752190756387, timestamp: 2022-08-19 21:24:56.216422\n",
      "resetting env. episode 4447, reward total was -21.0. running mean: -19.570194668848824, timestamp: 2022-08-19 21:24:58.600448\n",
      "resetting env. episode 4448, reward total was -21.0. running mean: -19.584492722160338, timestamp: 2022-08-19 21:25:01.638485\n",
      "resetting env. episode 4449, reward total was -20.0. running mean: -19.588647794938733, timestamp: 2022-08-19 21:25:05.040525\n",
      "resetting env. episode 4450, reward total was -19.0. running mean: -19.582761316989348, timestamp: 2022-08-19 21:25:09.773579\n",
      "resetting env. episode 4451, reward total was -19.0. running mean: -19.576933703819456, timestamp: 2022-08-19 21:25:13.149616\n",
      "resetting env. episode 4452, reward total was -19.0. running mean: -19.571164366781264, timestamp: 2022-08-19 21:25:16.815659\n",
      "resetting env. episode 4453, reward total was -18.0. running mean: -19.55545272311345, timestamp: 2022-08-19 21:25:19.903693\n",
      "resetting env. episode 4454, reward total was -18.0. running mean: -19.539898195882316, timestamp: 2022-08-19 21:25:23.513738\n",
      "resetting env. episode 4455, reward total was -15.0. running mean: -19.49449921392349, timestamp: 2022-08-19 21:25:27.571789\n",
      "resetting env. episode 4456, reward total was -18.0. running mean: -19.479554221784255, timestamp: 2022-08-19 21:25:30.425818\n",
      "resetting env. episode 4457, reward total was -19.0. running mean: -19.474758679566413, timestamp: 2022-08-19 21:25:34.113861\n",
      "resetting env. episode 4458, reward total was -20.0. running mean: -19.48001109277075, timestamp: 2022-08-19 21:25:37.184893\n",
      "resetting env. episode 4459, reward total was -20.0. running mean: -19.48521098184304, timestamp: 2022-08-19 21:25:40.042928\n",
      "resetting env. episode 4460, reward total was -21.0. running mean: -19.50035887202461, timestamp: 2022-08-19 21:25:42.886956\n",
      "resetting env. episode 4461, reward total was -19.0. running mean: -19.495355283304363, timestamp: 2022-08-19 21:25:46.246997\n",
      "resetting env. episode 4462, reward total was -21.0. running mean: -19.51040173047132, timestamp: 2022-08-19 21:25:49.242032\n",
      "resetting env. episode 4463, reward total was -20.0. running mean: -19.515297713166603, timestamp: 2022-08-19 21:25:52.164062\n",
      "resetting env. episode 4464, reward total was -18.0. running mean: -19.500144736034937, timestamp: 2022-08-19 21:25:54.969621\n",
      "resetting env. episode 4465, reward total was -19.0. running mean: -19.495143288674587, timestamp: 2022-08-19 21:25:57.195647\n",
      "resetting env. episode 4466, reward total was -21.0. running mean: -19.51019185578784, timestamp: 2022-08-19 21:26:00.305680\n",
      "resetting env. episode 4467, reward total was -20.0. running mean: -19.515089937229963, timestamp: 2022-08-19 21:26:02.981708\n",
      "resetting env. episode 4468, reward total was -20.0. running mean: -19.51993903785766, timestamp: 2022-08-19 21:26:06.263748\n",
      "resetting env. episode 4469, reward total was -20.0. running mean: -19.524739647479084, timestamp: 2022-08-19 21:26:08.695773\n",
      "resetting env. episode 4470, reward total was -19.0. running mean: -19.519492251004294, timestamp: 2022-08-19 21:26:12.146813\n",
      "resetting env. episode 4471, reward total was -20.0. running mean: -19.52429732849425, timestamp: 2022-08-19 21:26:15.373851\n",
      "resetting env. episode 4472, reward total was -20.0. running mean: -19.529054355209308, timestamp: 2022-08-19 21:26:18.395887\n",
      "resetting env. episode 4473, reward total was -21.0. running mean: -19.543763811657215, timestamp: 2022-08-19 21:26:21.870924\n",
      "resetting env. episode 4474, reward total was -18.0. running mean: -19.52832617354064, timestamp: 2022-08-19 21:26:25.192962\n",
      "resetting env. episode 4475, reward total was -20.0. running mean: -19.533042911805232, timestamp: 2022-08-19 21:26:28.183994\n",
      "resetting env. episode 4476, reward total was -21.0. running mean: -19.54771248268718, timestamp: 2022-08-19 21:26:30.932030\n",
      "resetting env. episode 4477, reward total was -18.0. running mean: -19.53223535786031, timestamp: 2022-08-19 21:26:35.411079\n",
      "resetting env. episode 4478, reward total was -19.0. running mean: -19.526913004281706, timestamp: 2022-08-19 21:26:38.743116\n",
      "resetting env. episode 4479, reward total was -21.0. running mean: -19.54164387423889, timestamp: 2022-08-19 21:26:41.352148\n",
      "resetting env. episode 4480, reward total was -21.0. running mean: -19.556227435496503, timestamp: 2022-08-19 21:26:44.230178\n",
      "resetting env. episode 4481, reward total was -21.0. running mean: -19.570665161141537, timestamp: 2022-08-19 21:26:47.154215\n",
      "resetting env. episode 4482, reward total was -19.0. running mean: -19.564958509530122, timestamp: 2022-08-19 21:26:50.322248\n",
      "resetting env. episode 4483, reward total was -20.0. running mean: -19.56930892443482, timestamp: 2022-08-19 21:26:53.132284\n",
      "resetting env. episode 4484, reward total was -20.0. running mean: -19.573615835190473, timestamp: 2022-08-19 21:26:56.439317\n",
      "resetting env. episode 4485, reward total was -17.0. running mean: -19.54787967683857, timestamp: 2022-08-19 21:26:59.598356\n",
      "resetting env. episode 4486, reward total was -19.0. running mean: -19.542400880070186, timestamp: 2022-08-19 21:27:02.818393\n",
      "resetting env. episode 4487, reward total was -20.0. running mean: -19.546976871269482, timestamp: 2022-08-19 21:27:05.903426\n",
      "resetting env. episode 4488, reward total was -19.0. running mean: -19.54150710255679, timestamp: 2022-08-19 21:27:08.951459\n",
      "resetting env. episode 4489, reward total was -19.0. running mean: -19.536092031531222, timestamp: 2022-08-19 21:27:11.513489\n",
      "resetting env. episode 4490, reward total was -19.0. running mean: -19.53073111121591, timestamp: 2022-08-19 21:27:14.870528\n",
      "resetting env. episode 4491, reward total was -16.0. running mean: -19.49542380010375, timestamp: 2022-08-19 21:27:18.346093\n",
      "resetting env. episode 4492, reward total was -20.0. running mean: -19.50046956210271, timestamp: 2022-08-19 21:27:20.420116\n",
      "resetting env. episode 4493, reward total was -21.0. running mean: -19.515464866481686, timestamp: 2022-08-19 21:27:23.462150\n",
      "resetting env. episode 4494, reward total was -20.0. running mean: -19.520310217816867, timestamp: 2022-08-19 21:27:26.069183\n",
      "resetting env. episode 4495, reward total was -20.0. running mean: -19.525107115638697, timestamp: 2022-08-19 21:27:28.964215\n",
      "resetting env. episode 4496, reward total was -20.0. running mean: -19.529856044482308, timestamp: 2022-08-19 21:27:31.940250\n",
      "resetting env. episode 4497, reward total was -21.0. running mean: -19.544557484037487, timestamp: 2022-08-19 21:27:34.309275\n",
      "resetting env. episode 4498, reward total was -18.0. running mean: -19.529111909197113, timestamp: 2022-08-19 21:27:37.789314\n",
      "resetting env. episode 4499, reward total was -19.0. running mean: -19.52382079010514, timestamp: 2022-08-19 21:27:40.797346\n",
      "resetting env. episode 4500, reward total was -21.0. running mean: -19.53858258220409, timestamp: 2022-08-19 21:27:43.873912\n",
      "resetting env. episode 4501, reward total was -18.0. running mean: -19.52319675638205, timestamp: 2022-08-19 21:27:46.885947\n",
      "resetting env. episode 4502, reward total was -17.0. running mean: -19.49796478881823, timestamp: 2022-08-19 21:27:50.807992\n",
      "resetting env. episode 4503, reward total was -21.0. running mean: -19.51298514093005, timestamp: 2022-08-19 21:27:53.282021\n",
      "resetting env. episode 4504, reward total was -18.0. running mean: -19.497855289520746, timestamp: 2022-08-19 21:27:56.815059\n",
      "resetting env. episode 4505, reward total was -21.0. running mean: -19.51287673662554, timestamp: 2022-08-19 21:27:59.273086\n",
      "resetting env. episode 4506, reward total was -19.0. running mean: -19.507747969259285, timestamp: 2022-08-19 21:28:02.762130\n",
      "resetting env. episode 4507, reward total was -17.0. running mean: -19.482670489566694, timestamp: 2022-08-19 21:28:06.710171\n",
      "resetting env. episode 4508, reward total was -18.0. running mean: -19.467843784671025, timestamp: 2022-08-19 21:28:09.931211\n",
      "resetting env. episode 4509, reward total was -19.0. running mean: -19.463165346824315, timestamp: 2022-08-19 21:28:12.503236\n",
      "resetting env. episode 4510, reward total was -18.0. running mean: -19.448533693356072, timestamp: 2022-08-19 21:28:15.622271\n",
      "resetting env. episode 4511, reward total was -20.0. running mean: -19.45404835642251, timestamp: 2022-08-19 21:28:18.052822\n",
      "resetting env. episode 4512, reward total was -21.0. running mean: -19.469507872858287, timestamp: 2022-08-19 21:28:20.116848\n",
      "resetting env. episode 4513, reward total was -21.0. running mean: -19.484812794129706, timestamp: 2022-08-19 21:28:23.370884\n",
      "resetting env. episode 4514, reward total was -20.0. running mean: -19.489964666188406, timestamp: 2022-08-19 21:28:26.822966\n",
      "resetting env. episode 4515, reward total was -20.0. running mean: -19.49506501952652, timestamp: 2022-08-19 21:28:29.462994\n",
      "resetting env. episode 4516, reward total was -19.0. running mean: -19.490114369331256, timestamp: 2022-08-19 21:28:32.835030\n",
      "resetting env. episode 4517, reward total was -19.0. running mean: -19.485213225637946, timestamp: 2022-08-19 21:28:36.385072\n",
      "resetting env. episode 4518, reward total was -19.0. running mean: -19.480361093381568, timestamp: 2022-08-19 21:28:39.395106\n",
      "resetting env. episode 4519, reward total was -19.0. running mean: -19.47555748244775, timestamp: 2022-08-19 21:28:41.916133\n",
      "resetting env. episode 4520, reward total was -17.0. running mean: -19.450801907623276, timestamp: 2022-08-19 21:28:45.262170\n",
      "resetting env. episode 4521, reward total was -20.0. running mean: -19.456293888547044, timestamp: 2022-08-19 21:28:48.007203\n",
      "resetting env. episode 4522, reward total was -20.0. running mean: -19.461730949661572, timestamp: 2022-08-19 21:28:50.740235\n",
      "resetting env. episode 4523, reward total was -18.0. running mean: -19.447113640164957, timestamp: 2022-08-19 21:28:53.477266\n",
      "resetting env. episode 4524, reward total was -21.0. running mean: -19.46264250376331, timestamp: 2022-08-19 21:28:56.523299\n",
      "resetting env. episode 4525, reward total was -19.0. running mean: -19.458016078725677, timestamp: 2022-08-19 21:28:59.147327\n",
      "resetting env. episode 4526, reward total was -18.0. running mean: -19.44343591793842, timestamp: 2022-08-19 21:29:02.304364\n",
      "resetting env. episode 4527, reward total was -21.0. running mean: -19.459001558759034, timestamp: 2022-08-19 21:29:04.934392\n",
      "resetting env. episode 4528, reward total was -21.0. running mean: -19.474411543171446, timestamp: 2022-08-19 21:29:08.501438\n",
      "resetting env. episode 4529, reward total was -21.0. running mean: -19.489667427739732, timestamp: 2022-08-19 21:29:11.401468\n",
      "resetting env. episode 4530, reward total was -20.0. running mean: -19.494770753462333, timestamp: 2022-08-19 21:29:14.324501\n",
      "resetting env. episode 4531, reward total was -19.0. running mean: -19.48982304592771, timestamp: 2022-08-19 21:29:17.900539\n",
      "resetting env. episode 4532, reward total was -19.0. running mean: -19.484924815468435, timestamp: 2022-08-19 21:29:20.714575\n",
      "resetting env. episode 4533, reward total was -16.0. running mean: -19.45007556731375, timestamp: 2022-08-19 21:29:23.918608\n",
      "resetting env. episode 4534, reward total was -17.0. running mean: -19.425574811640615, timestamp: 2022-08-19 21:29:27.694651\n",
      "resetting env. episode 4535, reward total was -19.0. running mean: -19.42131906352421, timestamp: 2022-08-19 21:29:30.311683\n",
      "resetting env. episode 4536, reward total was -21.0. running mean: -19.437105872888967, timestamp: 2022-08-19 21:29:33.246714\n",
      "resetting env. episode 4537, reward total was -20.0. running mean: -19.442734814160076, timestamp: 2022-08-19 21:29:36.238747\n",
      "resetting env. episode 4538, reward total was -13.0. running mean: -19.378307466018473, timestamp: 2022-08-19 21:29:40.178795\n",
      "resetting env. episode 4539, reward total was -18.0. running mean: -19.364524391358287, timestamp: 2022-08-19 21:29:43.506829\n",
      "resetting env. episode 4540, reward total was -20.0. running mean: -19.370879147444704, timestamp: 2022-08-19 21:29:46.685862\n",
      "resetting env. episode 4541, reward total was -18.0. running mean: -19.357170355970258, timestamp: 2022-08-19 21:29:49.894903\n",
      "resetting env. episode 4542, reward total was -18.0. running mean: -19.343598652410556, timestamp: 2022-08-19 21:29:53.317941\n",
      "resetting env. episode 4543, reward total was -21.0. running mean: -19.360162665886453, timestamp: 2022-08-19 21:29:55.413963\n",
      "resetting env. episode 4544, reward total was -18.0. running mean: -19.346561039227588, timestamp: 2022-08-19 21:29:58.745998\n",
      "resetting env. episode 4545, reward total was -19.0. running mean: -19.343095428835312, timestamp: 2022-08-19 21:30:01.564030\n",
      "resetting env. episode 4546, reward total was -20.0. running mean: -19.34966447454696, timestamp: 2022-08-19 21:30:04.796066\n",
      "resetting env. episode 4547, reward total was -21.0. running mean: -19.36616782980149, timestamp: 2022-08-19 21:30:07.369099\n",
      "resetting env. episode 4548, reward total was -18.0. running mean: -19.352506151503476, timestamp: 2022-08-19 21:30:10.605136\n",
      "resetting env. episode 4549, reward total was -19.0. running mean: -19.348981089988442, timestamp: 2022-08-19 21:30:14.796177\n",
      "resetting env. episode 4550, reward total was -21.0. running mean: -19.36549127908856, timestamp: 2022-08-19 21:30:17.210206\n",
      "resetting env. episode 4551, reward total was -17.0. running mean: -19.341836366297674, timestamp: 2022-08-19 21:30:20.677295\n",
      "resetting env. episode 4552, reward total was -20.0. running mean: -19.348418002634695, timestamp: 2022-08-19 21:30:23.887333\n",
      "resetting env. episode 4553, reward total was -17.0. running mean: -19.32493382260835, timestamp: 2022-08-19 21:30:27.218370\n",
      "resetting env. episode 4554, reward total was -19.0. running mean: -19.321684484382267, timestamp: 2022-08-19 21:30:30.115400\n",
      "resetting env. episode 4555, reward total was -17.0. running mean: -19.298467639538448, timestamp: 2022-08-19 21:30:33.718441\n",
      "resetting env. episode 4556, reward total was -15.0. running mean: -19.255482963143063, timestamp: 2022-08-19 21:30:37.458485\n",
      "resetting env. episode 4557, reward total was -20.0. running mean: -19.262928133511632, timestamp: 2022-08-19 21:30:40.794520\n",
      "resetting env. episode 4558, reward total was -17.0. running mean: -19.24029885217652, timestamp: 2022-08-19 21:30:43.808552\n",
      "resetting env. episode 4559, reward total was -17.0. running mean: -19.217895863654753, timestamp: 2022-08-19 21:30:47.156590\n",
      "resetting env. episode 4560, reward total was -19.0. running mean: -19.21571690501821, timestamp: 2022-08-19 21:30:50.434627\n",
      "resetting env. episode 4561, reward total was -20.0. running mean: -19.223559735968024, timestamp: 2022-08-19 21:30:53.645665\n",
      "resetting env. episode 4562, reward total was -21.0. running mean: -19.241324138608345, timestamp: 2022-08-19 21:30:56.459696\n",
      "resetting env. episode 4563, reward total was -21.0. running mean: -19.25891089722226, timestamp: 2022-08-19 21:30:58.891726\n",
      "resetting env. episode 4564, reward total was -21.0. running mean: -19.27632178825004, timestamp: 2022-08-19 21:31:01.662752\n",
      "resetting env. episode 4565, reward total was -20.0. running mean: -19.28355857036754, timestamp: 2022-08-19 21:31:04.931794\n",
      "resetting env. episode 4566, reward total was -19.0. running mean: -19.280722984663864, timestamp: 2022-08-19 21:31:07.690819\n",
      "resetting env. episode 4567, reward total was -18.0. running mean: -19.267915754817224, timestamp: 2022-08-19 21:31:10.963858\n",
      "resetting env. episode 4568, reward total was -19.0. running mean: -19.265236597269052, timestamp: 2022-08-19 21:31:13.942893\n",
      "resetting env. episode 4569, reward total was -16.0. running mean: -19.23258423129636, timestamp: 2022-08-19 21:31:17.584932\n",
      "resetting env. episode 4570, reward total was -18.0. running mean: -19.220258388983396, timestamp: 2022-08-19 21:31:20.694966\n",
      "resetting env. episode 4571, reward total was -19.0. running mean: -19.218055805093563, timestamp: 2022-08-19 21:31:24.045005\n",
      "resetting env. episode 4572, reward total was -19.0. running mean: -19.21587524704263, timestamp: 2022-08-19 21:31:27.529043\n",
      "resetting env. episode 4573, reward total was -19.0. running mean: -19.213716494572203, timestamp: 2022-08-19 21:31:30.595076\n",
      "resetting env. episode 4574, reward total was -21.0. running mean: -19.23157932962648, timestamp: 2022-08-19 21:31:34.265119\n",
      "resetting env. episode 4575, reward total was -19.0. running mean: -19.229263536330215, timestamp: 2022-08-19 21:31:37.174151\n",
      "resetting env. episode 4576, reward total was -20.0. running mean: -19.236970900966913, timestamp: 2022-08-19 21:31:40.699190\n",
      "resetting env. episode 4577, reward total was -20.0. running mean: -19.244601191957244, timestamp: 2022-08-19 21:31:44.429233\n",
      "resetting env. episode 4578, reward total was -19.0. running mean: -19.242155180037674, timestamp: 2022-08-19 21:31:47.336268\n",
      "resetting env. episode 4579, reward total was -20.0. running mean: -19.249733628237298, timestamp: 2022-08-19 21:31:49.855296\n",
      "resetting env. episode 4580, reward total was -18.0. running mean: -19.237236291954925, timestamp: 2022-08-19 21:31:52.637323\n",
      "resetting env. episode 4581, reward total was -16.0. running mean: -19.204863929035376, timestamp: 2022-08-19 21:31:55.192354\n",
      "resetting env. episode 4582, reward total was -19.0. running mean: -19.202815289745022, timestamp: 2022-08-19 21:31:59.006397\n",
      "resetting env. episode 4583, reward total was -20.0. running mean: -19.21078713684757, timestamp: 2022-08-19 21:32:01.867436\n",
      "resetting env. episode 4584, reward total was -18.0. running mean: -19.198679265479097, timestamp: 2022-08-19 21:32:05.165995\n",
      "resetting env. episode 4585, reward total was -18.0. running mean: -19.186692472824305, timestamp: 2022-08-19 21:32:08.309029\n",
      "resetting env. episode 4586, reward total was -19.0. running mean: -19.184825548096065, timestamp: 2022-08-19 21:32:11.460064\n",
      "resetting env. episode 4587, reward total was -21.0. running mean: -19.202977292615106, timestamp: 2022-08-19 21:32:14.159094\n",
      "resetting env. episode 4588, reward total was -19.0. running mean: -19.200947519688956, timestamp: 2022-08-19 21:32:16.667122\n",
      "resetting env. episode 4589, reward total was -21.0. running mean: -19.218938044492067, timestamp: 2022-08-19 21:32:20.531167\n",
      "resetting env. episode 4590, reward total was -20.0. running mean: -19.226748664047147, timestamp: 2022-08-19 21:32:23.765201\n",
      "resetting env. episode 4591, reward total was -20.0. running mean: -19.234481177406675, timestamp: 2022-08-19 21:32:26.265233\n",
      "resetting env. episode 4592, reward total was -17.0. running mean: -19.21213636563261, timestamp: 2022-08-19 21:32:29.252264\n",
      "resetting env. episode 4593, reward total was -16.0. running mean: -19.180015001976283, timestamp: 2022-08-19 21:32:33.239309\n",
      "resetting env. episode 4594, reward total was -21.0. running mean: -19.19821485195652, timestamp: 2022-08-19 21:32:36.358349\n",
      "resetting env. episode 4595, reward total was -19.0. running mean: -19.19623270343696, timestamp: 2022-08-19 21:32:39.264379\n",
      "resetting env. episode 4596, reward total was -18.0. running mean: -19.184270376402587, timestamp: 2022-08-19 21:32:42.019409\n",
      "resetting env. episode 4597, reward total was -14.0. running mean: -19.13242767263856, timestamp: 2022-08-19 21:32:45.722454\n",
      "resetting env. episode 4598, reward total was -19.0. running mean: -19.131103395912174, timestamp: 2022-08-19 21:32:48.687488\n",
      "resetting env. episode 4599, reward total was -19.0. running mean: -19.129792361953054, timestamp: 2022-08-19 21:32:51.549521\n",
      "resetting env. episode 4600, reward total was -19.0. running mean: -19.128494438333526, timestamp: 2022-08-19 21:32:54.117548\n",
      "resetting env. episode 4601, reward total was -21.0. running mean: -19.147209493950193, timestamp: 2022-08-19 21:32:56.730578\n",
      "resetting env. episode 4602, reward total was -18.0. running mean: -19.13573739901069, timestamp: 2022-08-19 21:33:00.163619\n",
      "resetting env. episode 4603, reward total was -17.0. running mean: -19.114380025020584, timestamp: 2022-08-19 21:33:03.560656\n",
      "resetting env. episode 4604, reward total was -17.0. running mean: -19.09323622477038, timestamp: 2022-08-19 21:33:06.772692\n",
      "resetting env. episode 4605, reward total was -16.0. running mean: -19.062303862522676, timestamp: 2022-08-19 21:33:10.558740\n",
      "resetting env. episode 4606, reward total was -19.0. running mean: -19.06168082389745, timestamp: 2022-08-19 21:33:13.590769\n",
      "resetting env. episode 4607, reward total was -19.0. running mean: -19.061064015658477, timestamp: 2022-08-19 21:33:16.448805\n",
      "resetting env. episode 4608, reward total was -20.0. running mean: -19.07045337550189, timestamp: 2022-08-19 21:33:19.353836\n",
      "resetting env. episode 4609, reward total was -20.0. running mean: -19.07974884174687, timestamp: 2022-08-19 21:33:22.251872\n",
      "resetting env. episode 4610, reward total was -19.0. running mean: -19.0789513533294, timestamp: 2022-08-19 21:33:25.972910\n",
      "resetting env. episode 4611, reward total was -19.0. running mean: -19.07816183979611, timestamp: 2022-08-19 21:33:28.943946\n",
      "resetting env. episode 4612, reward total was -21.0. running mean: -19.09738022139815, timestamp: 2022-08-19 21:33:31.858977\n",
      "resetting env. episode 4613, reward total was -19.0. running mean: -19.09640641918417, timestamp: 2022-08-19 21:33:34.639012\n",
      "resetting env. episode 4614, reward total was -18.0. running mean: -19.085442354992328, timestamp: 2022-08-19 21:33:38.221052\n",
      "resetting env. episode 4615, reward total was -20.0. running mean: -19.094587931442405, timestamp: 2022-08-19 21:33:41.304086\n",
      "resetting env. episode 4616, reward total was -20.0. running mean: -19.10364205212798, timestamp: 2022-08-19 21:33:43.864113\n",
      "resetting env. episode 4617, reward total was -19.0. running mean: -19.102605631606703, timestamp: 2022-08-19 21:33:47.520156\n",
      "resetting env. episode 4618, reward total was -14.0. running mean: -19.05157957529064, timestamp: 2022-08-19 21:33:51.661204\n",
      "resetting env. episode 4619, reward total was -21.0. running mean: -19.071063779537734, timestamp: 2022-08-19 21:33:54.286236\n",
      "resetting env. episode 4620, reward total was -20.0. running mean: -19.080353141742357, timestamp: 2022-08-19 21:33:57.442268\n",
      "resetting env. episode 4621, reward total was -19.0. running mean: -19.079549610324936, timestamp: 2022-08-19 21:34:00.257304\n",
      "resetting env. episode 4622, reward total was -19.0. running mean: -19.078754114221688, timestamp: 2022-08-19 21:34:03.712341\n",
      "resetting env. episode 4623, reward total was -20.0. running mean: -19.08796657307947, timestamp: 2022-08-19 21:34:06.937392\n",
      "resetting env. episode 4624, reward total was -17.0. running mean: -19.067086907348678, timestamp: 2022-08-19 21:34:10.374417\n",
      "resetting env. episode 4625, reward total was -18.0. running mean: -19.05641603827519, timestamp: 2022-08-19 21:34:13.974460\n",
      "resetting env. episode 4626, reward total was -20.0. running mean: -19.065851877892438, timestamp: 2022-08-19 21:34:16.353490\n",
      "resetting env. episode 4627, reward total was -21.0. running mean: -19.085193359113514, timestamp: 2022-08-19 21:34:19.439526\n",
      "resetting env. episode 4628, reward total was -19.0. running mean: -19.084341425522382, timestamp: 2022-08-19 21:34:23.338567\n",
      "resetting env. episode 4629, reward total was -18.0. running mean: -19.07349801126716, timestamp: 2022-08-19 21:34:26.536602\n",
      "resetting env. episode 4630, reward total was -15.0. running mean: -19.032763031154484, timestamp: 2022-08-19 21:34:29.871641\n",
      "resetting env. episode 4631, reward total was -19.0. running mean: -19.032435400842942, timestamp: 2022-08-19 21:34:33.187681\n",
      "resetting env. episode 4632, reward total was -17.0. running mean: -19.012111046834516, timestamp: 2022-08-19 21:34:36.306718\n",
      "resetting env. episode 4633, reward total was -20.0. running mean: -19.021989936366168, timestamp: 2022-08-19 21:34:39.004746\n",
      "resetting env. episode 4634, reward total was -21.0. running mean: -19.041770037002507, timestamp: 2022-08-19 21:34:41.360774\n",
      "resetting env. episode 4635, reward total was -19.0. running mean: -19.04135233663248, timestamp: 2022-08-19 21:34:44.089334\n",
      "resetting env. episode 4636, reward total was -19.0. running mean: -19.04093881326616, timestamp: 2022-08-19 21:34:47.054423\n",
      "resetting env. episode 4637, reward total was -16.0. running mean: -19.010529425133498, timestamp: 2022-08-19 21:34:50.225458\n",
      "resetting env. episode 4638, reward total was -20.0. running mean: -19.020424130882162, timestamp: 2022-08-19 21:34:52.637485\n",
      "resetting env. episode 4639, reward total was -16.0. running mean: -18.99021988957334, timestamp: 2022-08-19 21:34:56.023524\n",
      "resetting env. episode 4640, reward total was -18.0. running mean: -18.980317690677605, timestamp: 2022-08-19 21:34:59.978569\n",
      "resetting env. episode 4641, reward total was -21.0. running mean: -19.00051451377083, timestamp: 2022-08-19 21:35:03.661613\n",
      "resetting env. episode 4642, reward total was -20.0. running mean: -19.010509368633123, timestamp: 2022-08-19 21:35:06.800649\n",
      "resetting env. episode 4643, reward total was -21.0. running mean: -19.030404274946793, timestamp: 2022-08-19 21:35:10.186687\n",
      "resetting env. episode 4644, reward total was -20.0. running mean: -19.040100232197325, timestamp: 2022-08-19 21:35:13.033720\n",
      "resetting env. episode 4645, reward total was -18.0. running mean: -19.02969922987535, timestamp: 2022-08-19 21:35:16.316758\n",
      "resetting env. episode 4646, reward total was -20.0. running mean: -19.039402237576596, timestamp: 2022-08-19 21:35:19.307793\n",
      "resetting env. episode 4647, reward total was -19.0. running mean: -19.03900821520083, timestamp: 2022-08-19 21:35:22.122824\n",
      "resetting env. episode 4648, reward total was -19.0. running mean: -19.038618133048825, timestamp: 2022-08-19 21:35:26.216872\n",
      "resetting env. episode 4649, reward total was -19.0. running mean: -19.038231951718338, timestamp: 2022-08-19 21:35:29.443909\n",
      "resetting env. episode 4650, reward total was -18.0. running mean: -19.027849632201153, timestamp: 2022-08-19 21:35:32.682946\n",
      "resetting env. episode 4651, reward total was -19.0. running mean: -19.027571135879143, timestamp: 2022-08-19 21:35:35.412976\n",
      "resetting env. episode 4652, reward total was -20.0. running mean: -19.03729542452035, timestamp: 2022-08-19 21:35:39.097548\n",
      "resetting env. episode 4653, reward total was -18.0. running mean: -19.02692247027515, timestamp: 2022-08-19 21:35:42.066582\n",
      "resetting env. episode 4654, reward total was -18.0. running mean: -19.016653245572396, timestamp: 2022-08-19 21:35:44.981137\n",
      "resetting env. episode 4655, reward total was -21.0. running mean: -19.036486713116673, timestamp: 2022-08-19 21:35:47.918170\n",
      "resetting env. episode 4656, reward total was -21.0. running mean: -19.05612184598551, timestamp: 2022-08-19 21:35:50.549205\n",
      "resetting env. episode 4657, reward total was -21.0. running mean: -19.075560627525654, timestamp: 2022-08-19 21:35:53.450234\n",
      "resetting env. episode 4658, reward total was -21.0. running mean: -19.094805021250398, timestamp: 2022-08-19 21:35:56.340268\n",
      "resetting env. episode 4659, reward total was -19.0. running mean: -19.093856971037894, timestamp: 2022-08-19 21:35:59.148301\n",
      "resetting env. episode 4660, reward total was -19.0. running mean: -19.092918401327516, timestamp: 2022-08-19 21:36:02.283337\n",
      "resetting env. episode 4661, reward total was -21.0. running mean: -19.111989217314242, timestamp: 2022-08-19 21:36:05.240370\n",
      "resetting env. episode 4662, reward total was -20.0. running mean: -19.1208693251411, timestamp: 2022-08-19 21:36:08.193404\n",
      "resetting env. episode 4663, reward total was -20.0. running mean: -19.12966063188969, timestamp: 2022-08-19 21:36:11.468442\n",
      "resetting env. episode 4664, reward total was -19.0. running mean: -19.128364025570793, timestamp: 2022-08-19 21:36:15.150485\n",
      "resetting env. episode 4665, reward total was -21.0. running mean: -19.147080385315085, timestamp: 2022-08-19 21:36:17.152510\n",
      "resetting env. episode 4666, reward total was -19.0. running mean: -19.145609581461937, timestamp: 2022-08-19 21:36:20.371546\n",
      "resetting env. episode 4667, reward total was -18.0. running mean: -19.134153485647317, timestamp: 2022-08-19 21:36:23.821586\n",
      "resetting env. episode 4668, reward total was -21.0. running mean: -19.152811950790845, timestamp: 2022-08-19 21:36:26.800621\n",
      "resetting env. episode 4669, reward total was -17.0. running mean: -19.13128383128294, timestamp: 2022-08-19 21:36:30.269661\n",
      "resetting env. episode 4670, reward total was -19.0. running mean: -19.12997099297011, timestamp: 2022-08-19 21:36:33.698697\n",
      "resetting env. episode 4671, reward total was -20.0. running mean: -19.13867128304041, timestamp: 2022-08-19 21:36:36.352729\n",
      "resetting env. episode 4672, reward total was -20.0. running mean: -19.147284570210005, timestamp: 2022-08-19 21:36:39.290763\n",
      "resetting env. episode 4673, reward total was -21.0. running mean: -19.165811724507904, timestamp: 2022-08-19 21:36:43.125806\n",
      "resetting env. episode 4674, reward total was -20.0. running mean: -19.174153607262824, timestamp: 2022-08-19 21:36:45.756836\n",
      "resetting env. episode 4675, reward total was -21.0. running mean: -19.192412071190198, timestamp: 2022-08-19 21:36:49.340404\n",
      "resetting env. episode 4676, reward total was -19.0. running mean: -19.190487950478296, timestamp: 2022-08-19 21:36:51.640431\n",
      "resetting env. episode 4677, reward total was -18.0. running mean: -19.178583070973513, timestamp: 2022-08-19 21:36:54.792468\n",
      "resetting env. episode 4678, reward total was -21.0. running mean: -19.196797240263777, timestamp: 2022-08-19 21:36:57.881500\n",
      "resetting env. episode 4679, reward total was -19.0. running mean: -19.19482926786114, timestamp: 2022-08-19 21:37:00.441053\n",
      "resetting env. episode 4680, reward total was -19.0. running mean: -19.192880975182533, timestamp: 2022-08-19 21:37:04.027097\n",
      "resetting env. episode 4681, reward total was -20.0. running mean: -19.200952165430706, timestamp: 2022-08-19 21:37:07.265137\n",
      "resetting env. episode 4682, reward total was -19.0. running mean: -19.1989426437764, timestamp: 2022-08-19 21:37:10.171167\n",
      "resetting env. episode 4683, reward total was -17.0. running mean: -19.17695321733864, timestamp: 2022-08-19 21:37:13.236212\n",
      "resetting env. episode 4684, reward total was -20.0. running mean: -19.185183685165253, timestamp: 2022-08-19 21:37:16.353237\n",
      "resetting env. episode 4685, reward total was -21.0. running mean: -19.2033318483136, timestamp: 2022-08-19 21:37:19.800280\n",
      "resetting env. episode 4686, reward total was -20.0. running mean: -19.21129852983046, timestamp: 2022-08-19 21:37:23.052315\n",
      "resetting env. episode 4687, reward total was -19.0. running mean: -19.209185544532158, timestamp: 2022-08-19 21:37:25.923349\n",
      "resetting env. episode 4688, reward total was -21.0. running mean: -19.227093689086836, timestamp: 2022-08-19 21:37:29.070387\n",
      "resetting env. episode 4689, reward total was -20.0. running mean: -19.234822752195967, timestamp: 2022-08-19 21:37:32.063417\n",
      "resetting env. episode 4690, reward total was -20.0. running mean: -19.242474524674005, timestamp: 2022-08-19 21:37:34.883449\n",
      "resetting env. episode 4691, reward total was -19.0. running mean: -19.240049779427267, timestamp: 2022-08-19 21:37:37.926488\n",
      "resetting env. episode 4692, reward total was -17.0. running mean: -19.217649281632994, timestamp: 2022-08-19 21:37:40.856519\n",
      "resetting env. episode 4693, reward total was -20.0. running mean: -19.225472788816663, timestamp: 2022-08-19 21:37:43.708555\n",
      "resetting env. episode 4694, reward total was -18.0. running mean: -19.213218060928497, timestamp: 2022-08-19 21:37:46.945591\n",
      "resetting env. episode 4695, reward total was -19.0. running mean: -19.211085880319214, timestamp: 2022-08-19 21:37:49.741622\n",
      "resetting env. episode 4696, reward total was -19.0. running mean: -19.20897502151602, timestamp: 2022-08-19 21:37:53.949667\n",
      "resetting env. episode 4697, reward total was -18.0. running mean: -19.19688527130086, timestamp: 2022-08-19 21:37:56.994705\n",
      "resetting env. episode 4698, reward total was -19.0. running mean: -19.194916418587855, timestamp: 2022-08-19 21:37:59.299730\n",
      "resetting env. episode 4699, reward total was -20.0. running mean: -19.202967254401976, timestamp: 2022-08-19 21:38:02.345770\n",
      "resetting env. episode 4700, reward total was -20.0. running mean: -19.210937581857955, timestamp: 2022-08-19 21:38:05.355851\n",
      "resetting env. episode 4701, reward total was -18.0. running mean: -19.198828206039376, timestamp: 2022-08-19 21:38:08.686889\n",
      "resetting env. episode 4702, reward total was -19.0. running mean: -19.196839923978985, timestamp: 2022-08-19 21:38:11.904925\n",
      "resetting env. episode 4703, reward total was -19.0. running mean: -19.194871524739195, timestamp: 2022-08-19 21:38:15.176964\n",
      "resetting env. episode 4704, reward total was -21.0. running mean: -19.212922809491804, timestamp: 2022-08-19 21:38:18.788006\n",
      "resetting env. episode 4705, reward total was -18.0. running mean: -19.200793581396887, timestamp: 2022-08-19 21:38:22.069043\n",
      "resetting env. episode 4706, reward total was -19.0. running mean: -19.19878564558292, timestamp: 2022-08-19 21:38:25.285079\n",
      "resetting env. episode 4707, reward total was -19.0. running mean: -19.196797789127093, timestamp: 2022-08-19 21:38:28.769123\n",
      "resetting env. episode 4708, reward total was -18.0. running mean: -19.184829811235822, timestamp: 2022-08-19 21:38:32.418163\n",
      "resetting env. episode 4709, reward total was -21.0. running mean: -19.202981513123465, timestamp: 2022-08-19 21:38:34.973192\n",
      "resetting env. episode 4710, reward total was -20.0. running mean: -19.21095169799223, timestamp: 2022-08-19 21:38:38.124226\n",
      "resetting env. episode 4711, reward total was -20.0. running mean: -19.218842181012306, timestamp: 2022-08-19 21:38:41.073266\n",
      "resetting env. episode 4712, reward total was -17.0. running mean: -19.196653759202185, timestamp: 2022-08-19 21:38:44.753307\n",
      "resetting env. episode 4713, reward total was -21.0. running mean: -19.214687221610163, timestamp: 2022-08-19 21:38:47.839344\n",
      "resetting env. episode 4714, reward total was -19.0. running mean: -19.21254034939406, timestamp: 2022-08-19 21:38:50.839377\n",
      "resetting env. episode 4715, reward total was -19.0. running mean: -19.210414945900123, timestamp: 2022-08-19 21:38:53.586407\n",
      "resetting env. episode 4716, reward total was -20.0. running mean: -19.21831079644112, timestamp: 2022-08-19 21:38:56.516438\n",
      "resetting env. episode 4717, reward total was -21.0. running mean: -19.23612768847671, timestamp: 2022-08-19 21:38:59.664475\n",
      "resetting env. episode 4718, reward total was -21.0. running mean: -19.253766411591943, timestamp: 2022-08-19 21:39:02.454507\n",
      "resetting env. episode 4719, reward total was -21.0. running mean: -19.271228747476023, timestamp: 2022-08-19 21:39:05.704546\n",
      "resetting env. episode 4720, reward total was -19.0. running mean: -19.268516460001266, timestamp: 2022-08-19 21:39:08.104572\n",
      "resetting env. episode 4721, reward total was -20.0. running mean: -19.27583129540125, timestamp: 2022-08-19 21:39:11.024130\n",
      "resetting env. episode 4722, reward total was -20.0. running mean: -19.283072982447237, timestamp: 2022-08-19 21:39:14.816174\n",
      "resetting env. episode 4723, reward total was -21.0. running mean: -19.300242252622766, timestamp: 2022-08-19 21:39:17.422203\n",
      "resetting env. episode 4724, reward total was -17.0. running mean: -19.27723983009654, timestamp: 2022-08-19 21:39:20.326237\n",
      "resetting env. episode 4725, reward total was -21.0. running mean: -19.294467431795574, timestamp: 2022-08-19 21:39:23.502277\n",
      "resetting env. episode 4726, reward total was -21.0. running mean: -19.31152275747762, timestamp: 2022-08-19 21:39:25.949301\n",
      "resetting env. episode 4727, reward total was -20.0. running mean: -19.318407529902842, timestamp: 2022-08-19 21:39:28.328330\n",
      "resetting env. episode 4728, reward total was -19.0. running mean: -19.315223454603814, timestamp: 2022-08-19 21:39:31.263362\n",
      "resetting env. episode 4729, reward total was -19.0. running mean: -19.312071220057778, timestamp: 2022-08-19 21:39:34.504399\n",
      "resetting env. episode 4730, reward total was -21.0. running mean: -19.3289505078572, timestamp: 2022-08-19 21:39:37.204429\n",
      "resetting env. episode 4731, reward total was -20.0. running mean: -19.33566100277863, timestamp: 2022-08-19 21:39:39.570459\n",
      "resetting env. episode 4732, reward total was -21.0. running mean: -19.352304392750842, timestamp: 2022-08-19 21:39:41.972486\n",
      "resetting env. episode 4733, reward total was -20.0. running mean: -19.35878134882333, timestamp: 2022-08-19 21:39:45.273524\n",
      "resetting env. episode 4734, reward total was -20.0. running mean: -19.3651935353351, timestamp: 2022-08-19 21:39:48.479564\n",
      "resetting env. episode 4735, reward total was -21.0. running mean: -19.381541599981748, timestamp: 2022-08-19 21:39:51.033595\n",
      "resetting env. episode 4736, reward total was -20.0. running mean: -19.38772618398193, timestamp: 2022-08-19 21:39:53.816623\n",
      "resetting env. episode 4737, reward total was -20.0. running mean: -19.39384892214211, timestamp: 2022-08-19 21:39:56.332656\n",
      "resetting env. episode 4738, reward total was -18.0. running mean: -19.37991043292069, timestamp: 2022-08-19 21:39:59.992693\n",
      "resetting env. episode 4739, reward total was -19.0. running mean: -19.37611132859148, timestamp: 2022-08-19 21:40:03.016729\n",
      "resetting env. episode 4740, reward total was -18.0. running mean: -19.362350215305565, timestamp: 2022-08-19 21:40:06.498770\n",
      "resetting env. episode 4741, reward total was -21.0. running mean: -19.37872671315251, timestamp: 2022-08-19 21:40:09.615807\n",
      "resetting env. episode 4742, reward total was -20.0. running mean: -19.384939446020983, timestamp: 2022-08-19 21:40:12.864842\n",
      "resetting env. episode 4743, reward total was -19.0. running mean: -19.381090051560776, timestamp: 2022-08-19 21:40:16.368880\n",
      "resetting env. episode 4744, reward total was -19.0. running mean: -19.37727915104517, timestamp: 2022-08-19 21:40:20.295927\n",
      "resetting env. episode 4745, reward total was -21.0. running mean: -19.39350635953472, timestamp: 2022-08-19 21:40:23.767964\n",
      "resetting env. episode 4746, reward total was -18.0. running mean: -19.37957129593937, timestamp: 2022-08-19 21:40:27.193004\n",
      "resetting env. episode 4747, reward total was -19.0. running mean: -19.37577558297998, timestamp: 2022-08-19 21:40:31.342057\n",
      "resetting env. episode 4748, reward total was -20.0. running mean: -19.38201782715018, timestamp: 2022-08-19 21:40:34.742093\n",
      "resetting env. episode 4749, reward total was -19.0. running mean: -19.37819764887868, timestamp: 2022-08-19 21:40:37.504125\n",
      "resetting env. episode 4750, reward total was -18.0. running mean: -19.364415672389892, timestamp: 2022-08-19 21:40:40.747161\n",
      "resetting env. episode 4751, reward total was -20.0. running mean: -19.370771515665993, timestamp: 2022-08-19 21:40:43.590716\n",
      "resetting env. episode 4752, reward total was -21.0. running mean: -19.387063800509335, timestamp: 2022-08-19 21:40:46.653753\n",
      "resetting env. episode 4753, reward total was -21.0. running mean: -19.40319316250424, timestamp: 2022-08-19 21:40:49.722786\n",
      "resetting env. episode 4754, reward total was -18.0. running mean: -19.3891612308792, timestamp: 2022-08-19 21:40:52.635819\n",
      "resetting env. episode 4755, reward total was -19.0. running mean: -19.38526961857041, timestamp: 2022-08-19 21:40:55.789856\n",
      "resetting env. episode 4756, reward total was -19.0. running mean: -19.381416922384705, timestamp: 2022-08-19 21:40:59.178894\n",
      "resetting env. episode 4757, reward total was -19.0. running mean: -19.377602753160858, timestamp: 2022-08-19 21:41:02.352932\n",
      "resetting env. episode 4758, reward total was -18.0. running mean: -19.36382672562925, timestamp: 2022-08-19 21:41:06.007496\n",
      "resetting env. episode 4759, reward total was -19.0. running mean: -19.360188458372956, timestamp: 2022-08-19 21:41:08.858526\n",
      "resetting env. episode 4760, reward total was -20.0. running mean: -19.366586573789228, timestamp: 2022-08-19 21:41:12.246566\n",
      "resetting env. episode 4761, reward total was -20.0. running mean: -19.372920708051335, timestamp: 2022-08-19 21:41:15.252130\n",
      "resetting env. episode 4762, reward total was -20.0. running mean: -19.379191500970823, timestamp: 2022-08-19 21:41:18.630218\n",
      "resetting env. episode 4763, reward total was -20.0. running mean: -19.385399585961114, timestamp: 2022-08-19 21:41:21.923255\n",
      "resetting env. episode 4764, reward total was -21.0. running mean: -19.401545590101502, timestamp: 2022-08-19 21:41:24.205284\n",
      "resetting env. episode 4765, reward total was -16.0. running mean: -19.367530134200486, timestamp: 2022-08-19 21:41:27.627320\n",
      "resetting env. episode 4766, reward total was -20.0. running mean: -19.37385483285848, timestamp: 2022-08-19 21:41:30.338350\n",
      "resetting env. episode 4767, reward total was -20.0. running mean: -19.380116284529894, timestamp: 2022-08-19 21:41:33.582388\n",
      "resetting env. episode 4768, reward total was -17.0. running mean: -19.356315121684595, timestamp: 2022-08-19 21:41:37.175429\n",
      "resetting env. episode 4769, reward total was -19.0. running mean: -19.35275197046775, timestamp: 2022-08-19 21:41:39.847460\n",
      "resetting env. episode 4770, reward total was -17.0. running mean: -19.329224450763075, timestamp: 2022-08-19 21:41:43.644501\n",
      "resetting env. episode 4771, reward total was -21.0. running mean: -19.345932206255444, timestamp: 2022-08-19 21:41:46.418536\n",
      "resetting env. episode 4772, reward total was -20.0. running mean: -19.35247288419289, timestamp: 2022-08-19 21:41:50.125576\n",
      "resetting env. episode 4773, reward total was -19.0. running mean: -19.34894815535096, timestamp: 2022-08-19 21:41:53.743622\n",
      "resetting env. episode 4774, reward total was -20.0. running mean: -19.35545867379745, timestamp: 2022-08-19 21:41:57.117657\n",
      "resetting env. episode 4775, reward total was -20.0. running mean: -19.361904087059475, timestamp: 2022-08-19 21:42:00.298695\n",
      "resetting env. episode 4776, reward total was -20.0. running mean: -19.36828504618888, timestamp: 2022-08-19 21:42:03.304727\n",
      "resetting env. episode 4777, reward total was -16.0. running mean: -19.33460219572699, timestamp: 2022-08-19 21:42:07.350777\n",
      "resetting env. episode 4778, reward total was -18.0. running mean: -19.32125617376972, timestamp: 2022-08-19 21:42:10.512813\n",
      "resetting env. episode 4779, reward total was -19.0. running mean: -19.31804361203202, timestamp: 2022-08-19 21:42:14.104850\n",
      "resetting env. episode 4780, reward total was -21.0. running mean: -19.3348631759117, timestamp: 2022-08-19 21:42:17.313889\n",
      "resetting env. episode 4781, reward total was -21.0. running mean: -19.351514544152582, timestamp: 2022-08-19 21:42:20.421923\n",
      "resetting env. episode 4782, reward total was -19.0. running mean: -19.347999398711057, timestamp: 2022-08-19 21:42:23.927966\n",
      "resetting env. episode 4783, reward total was -18.0. running mean: -19.334519404723945, timestamp: 2022-08-19 21:42:27.125999\n",
      "resetting env. episode 4784, reward total was -20.0. running mean: -19.341174210676705, timestamp: 2022-08-19 21:42:30.255034\n",
      "resetting env. episode 4785, reward total was -19.0. running mean: -19.337762468569938, timestamp: 2022-08-19 21:42:33.607073\n",
      "resetting env. episode 4786, reward total was -19.0. running mean: -19.33438484388424, timestamp: 2022-08-19 21:42:36.198101\n",
      "resetting env. episode 4787, reward total was -19.0. running mean: -19.3310409954454, timestamp: 2022-08-19 21:42:39.722142\n",
      "resetting env. episode 4788, reward total was -21.0. running mean: -19.347730585490947, timestamp: 2022-08-19 21:42:42.506174\n",
      "resetting env. episode 4789, reward total was -17.0. running mean: -19.32425327963604, timestamp: 2022-08-19 21:42:45.940212\n",
      "resetting env. episode 4790, reward total was -20.0. running mean: -19.331010746839677, timestamp: 2022-08-19 21:42:49.399250\n",
      "resetting env. episode 4791, reward total was -19.0. running mean: -19.327700639371283, timestamp: 2022-08-19 21:42:52.649335\n",
      "resetting env. episode 4792, reward total was -19.0. running mean: -19.32442363297757, timestamp: 2022-08-19 21:42:56.299376\n",
      "resetting env. episode 4793, reward total was -15.0. running mean: -19.281179396647794, timestamp: 2022-08-19 21:43:00.504947\n",
      "resetting env. episode 4794, reward total was -19.0. running mean: -19.278367602681318, timestamp: 2022-08-19 21:43:03.023973\n",
      "resetting env. episode 4795, reward total was -19.0. running mean: -19.275583926654505, timestamp: 2022-08-19 21:43:05.709004\n",
      "resetting env. episode 4796, reward total was -17.0. running mean: -19.25282808738796, timestamp: 2022-08-19 21:43:09.454047\n",
      "resetting env. episode 4797, reward total was -19.0. running mean: -19.250299806514082, timestamp: 2022-08-19 21:43:12.192078\n",
      "resetting env. episode 4798, reward total was -21.0. running mean: -19.267796808448942, timestamp: 2022-08-19 21:43:15.505116\n",
      "resetting env. episode 4799, reward total was -19.0. running mean: -19.265118840364455, timestamp: 2022-08-19 21:43:18.755153\n",
      "resetting env. episode 4800, reward total was -19.0. running mean: -19.26246765196081, timestamp: 2022-08-19 21:43:21.890187\n",
      "resetting env. episode 4801, reward total was -19.0. running mean: -19.259842975441206, timestamp: 2022-08-19 21:43:25.140232\n",
      "resetting env. episode 4802, reward total was -18.0. running mean: -19.247244545686794, timestamp: 2022-08-19 21:43:28.440261\n",
      "resetting env. episode 4803, reward total was -17.0. running mean: -19.224772100229927, timestamp: 2022-08-19 21:43:31.539296\n",
      "resetting env. episode 4804, reward total was -20.0. running mean: -19.232524379227627, timestamp: 2022-08-19 21:43:34.071323\n",
      "resetting env. episode 4805, reward total was -17.0. running mean: -19.210199135435353, timestamp: 2022-08-19 21:43:37.803367\n",
      "resetting env. episode 4806, reward total was -20.0. running mean: -19.218097144081, timestamp: 2022-08-19 21:43:40.290395\n",
      "resetting env. episode 4807, reward total was -20.0. running mean: -19.22591617264019, timestamp: 2022-08-19 21:43:42.767428\n",
      "resetting env. episode 4808, reward total was -20.0. running mean: -19.233657010913788, timestamp: 2022-08-19 21:43:45.544454\n",
      "resetting env. episode 4809, reward total was -21.0. running mean: -19.25132044080465, timestamp: 2022-08-19 21:43:49.244495\n",
      "resetting env. episode 4810, reward total was -19.0. running mean: -19.248807236396605, timestamp: 2022-08-19 21:43:53.125064\n",
      "resetting env. episode 4811, reward total was -19.0. running mean: -19.24631916403264, timestamp: 2022-08-19 21:43:56.453630\n",
      "resetting env. episode 4812, reward total was -21.0. running mean: -19.263855972392317, timestamp: 2022-08-19 21:43:59.798664\n",
      "resetting env. episode 4813, reward total was -19.0. running mean: -19.261217412668394, timestamp: 2022-08-19 21:44:02.807702\n",
      "resetting env. episode 4814, reward total was -18.0. running mean: -19.24860523854171, timestamp: 2022-08-19 21:44:06.506740\n",
      "resetting env. episode 4815, reward total was -20.0. running mean: -19.256119186156294, timestamp: 2022-08-19 21:44:09.876781\n",
      "resetting env. episode 4816, reward total was -17.0. running mean: -19.23355799429473, timestamp: 2022-08-19 21:44:12.922815\n",
      "resetting env. episode 4817, reward total was -18.0. running mean: -19.221222414351782, timestamp: 2022-08-19 21:44:16.239854\n",
      "resetting env. episode 4818, reward total was -19.0. running mean: -19.219010190208266, timestamp: 2022-08-19 21:44:19.760893\n",
      "resetting env. episode 4819, reward total was -20.0. running mean: -19.226820088306184, timestamp: 2022-08-19 21:44:22.722922\n",
      "resetting env. episode 4820, reward total was -21.0. running mean: -19.24455188742312, timestamp: 2022-08-19 21:44:26.256962\n",
      "resetting env. episode 4821, reward total was -19.0. running mean: -19.242106368548892, timestamp: 2022-08-19 21:44:28.740992\n",
      "resetting env. episode 4822, reward total was -18.0. running mean: -19.229685304863402, timestamp: 2022-08-19 21:44:32.014028\n",
      "resetting env. episode 4823, reward total was -17.0. running mean: -19.20738845181477, timestamp: 2022-08-19 21:44:35.331068\n",
      "resetting env. episode 4824, reward total was -20.0. running mean: -19.21531456729662, timestamp: 2022-08-19 21:44:38.254100\n",
      "resetting env. episode 4825, reward total was -19.0. running mean: -19.213161421623656, timestamp: 2022-08-19 21:44:41.379132\n",
      "resetting env. episode 4826, reward total was -21.0. running mean: -19.23102980740742, timestamp: 2022-08-19 21:44:44.879172\n",
      "resetting env. episode 4827, reward total was -20.0. running mean: -19.238719509333347, timestamp: 2022-08-19 21:44:47.662207\n",
      "resetting env. episode 4828, reward total was -21.0. running mean: -19.256332314240012, timestamp: 2022-08-19 21:44:50.482236\n",
      "resetting env. episode 4829, reward total was -21.0. running mean: -19.27376899109761, timestamp: 2022-08-19 21:44:53.618272\n",
      "resetting env. episode 4830, reward total was -20.0. running mean: -19.281031301186633, timestamp: 2022-08-19 21:44:56.767305\n",
      "resetting env. episode 4831, reward total was -21.0. running mean: -19.29822098817477, timestamp: 2022-08-19 21:44:59.393336\n",
      "resetting env. episode 4832, reward total was -20.0. running mean: -19.30523877829302, timestamp: 2022-08-19 21:45:02.267366\n",
      "resetting env. episode 4833, reward total was -21.0. running mean: -19.32218639051009, timestamp: 2022-08-19 21:45:04.944396\n",
      "resetting env. episode 4834, reward total was -21.0. running mean: -19.33896452660499, timestamp: 2022-08-19 21:45:08.117434\n",
      "resetting env. episode 4835, reward total was -19.0. running mean: -19.335574881338943, timestamp: 2022-08-19 21:45:10.758462\n",
      "resetting env. episode 4836, reward total was -19.0. running mean: -19.332219132525555, timestamp: 2022-08-19 21:45:13.657494\n",
      "resetting env. episode 4837, reward total was -21.0. running mean: -19.3488969412003, timestamp: 2022-08-19 21:45:16.454526\n",
      "resetting env. episode 4838, reward total was -20.0. running mean: -19.3554079717883, timestamp: 2022-08-19 21:45:19.431562\n",
      "resetting env. episode 4839, reward total was -18.0. running mean: -19.341853892070414, timestamp: 2022-08-19 21:45:23.574606\n",
      "resetting env. episode 4840, reward total was -17.0. running mean: -19.318435353149713, timestamp: 2022-08-19 21:45:26.783642\n",
      "resetting env. episode 4841, reward total was -18.0. running mean: -19.305250999618217, timestamp: 2022-08-19 21:45:29.631678\n",
      "resetting env. episode 4842, reward total was -21.0. running mean: -19.322198489622036, timestamp: 2022-08-19 21:45:32.610709\n",
      "resetting env. episode 4843, reward total was -21.0. running mean: -19.338976504725817, timestamp: 2022-08-19 21:45:35.398738\n",
      "resetting env. episode 4844, reward total was -20.0. running mean: -19.34558673967856, timestamp: 2022-08-19 21:45:38.044770\n",
      "resetting env. episode 4845, reward total was -19.0. running mean: -19.342130872281775, timestamp: 2022-08-19 21:45:40.807800\n",
      "resetting env. episode 4846, reward total was -19.0. running mean: -19.338709563558957, timestamp: 2022-08-19 21:45:44.270840\n",
      "resetting env. episode 4847, reward total was -20.0. running mean: -19.345322467923367, timestamp: 2022-08-19 21:45:47.385873\n",
      "resetting env. episode 4848, reward total was -21.0. running mean: -19.361869243244133, timestamp: 2022-08-19 21:45:50.556912\n",
      "resetting env. episode 4849, reward total was -19.0. running mean: -19.358250550811693, timestamp: 2022-08-19 21:45:55.238960\n",
      "resetting env. episode 4850, reward total was -19.0. running mean: -19.354668045303576, timestamp: 2022-08-19 21:45:58.504996\n",
      "resetting env. episode 4851, reward total was -17.0. running mean: -19.331121364850542, timestamp: 2022-08-19 21:46:02.199038\n",
      "resetting env. episode 4852, reward total was -20.0. running mean: -19.337810151202035, timestamp: 2022-08-19 21:46:05.070072\n",
      "resetting env. episode 4853, reward total was -20.0. running mean: -19.344432049690013, timestamp: 2022-08-19 21:46:08.154104\n",
      "resetting env. episode 4854, reward total was -20.0. running mean: -19.35098772919311, timestamp: 2022-08-19 21:46:11.234140\n",
      "resetting env. episode 4855, reward total was -21.0. running mean: -19.36747785190118, timestamp: 2022-08-19 21:46:14.914181\n",
      "resetting env. episode 4856, reward total was -19.0. running mean: -19.363803073382172, timestamp: 2022-08-19 21:46:17.954217\n",
      "resetting env. episode 4857, reward total was -20.0. running mean: -19.37016504264835, timestamp: 2022-08-19 21:46:21.063253\n",
      "resetting env. episode 4858, reward total was -21.0. running mean: -19.386463392221867, timestamp: 2022-08-19 21:46:23.901805\n",
      "resetting env. episode 4859, reward total was -20.0. running mean: -19.39259875829965, timestamp: 2022-08-19 21:46:26.534839\n",
      "resetting env. episode 4860, reward total was -19.0. running mean: -19.388672770716653, timestamp: 2022-08-19 21:46:29.166864\n",
      "resetting env. episode 4861, reward total was -18.0. running mean: -19.374786043009486, timestamp: 2022-08-19 21:46:32.522904\n",
      "resetting env. episode 4862, reward total was -20.0. running mean: -19.381038182579392, timestamp: 2022-08-19 21:46:35.014930\n",
      "resetting env. episode 4863, reward total was -20.0. running mean: -19.387227800753596, timestamp: 2022-08-19 21:46:38.259965\n",
      "resetting env. episode 4864, reward total was -19.0. running mean: -19.38335552274606, timestamp: 2022-08-19 21:46:42.486540\n",
      "resetting env. episode 4865, reward total was -19.0. running mean: -19.379521967518603, timestamp: 2022-08-19 21:46:45.645576\n",
      "resetting env. episode 4866, reward total was -20.0. running mean: -19.385726747843417, timestamp: 2022-08-19 21:46:48.702607\n",
      "resetting env. episode 4867, reward total was -21.0. running mean: -19.401869480364983, timestamp: 2022-08-19 21:46:51.344640\n",
      "resetting env. episode 4868, reward total was -18.0. running mean: -19.387850785561334, timestamp: 2022-08-19 21:46:55.349206\n",
      "resetting env. episode 4869, reward total was -17.0. running mean: -19.36397227770572, timestamp: 2022-08-19 21:46:58.776243\n",
      "resetting env. episode 4870, reward total was -18.0. running mean: -19.350332554928663, timestamp: 2022-08-19 21:47:02.428285\n",
      "resetting env. episode 4871, reward total was -18.0. running mean: -19.336829229379376, timestamp: 2022-08-19 21:47:05.854326\n",
      "resetting env. episode 4872, reward total was -21.0. running mean: -19.353460937085583, timestamp: 2022-08-19 21:47:09.430363\n",
      "resetting env. episode 4873, reward total was -17.0. running mean: -19.329926327714727, timestamp: 2022-08-19 21:47:13.056405\n",
      "resetting env. episode 4874, reward total was -19.0. running mean: -19.32662706443758, timestamp: 2022-08-19 21:47:16.217439\n",
      "resetting env. episode 4875, reward total was -21.0. running mean: -19.343360793793206, timestamp: 2022-08-19 21:47:18.888466\n",
      "resetting env. episode 4876, reward total was -20.0. running mean: -19.34992718585527, timestamp: 2022-08-19 21:47:22.797510\n",
      "resetting env. episode 4877, reward total was -18.0. running mean: -19.33642791399672, timestamp: 2022-08-19 21:47:25.606591\n",
      "resetting env. episode 4878, reward total was -20.0. running mean: -19.34306363485675, timestamp: 2022-08-19 21:47:29.494631\n",
      "resetting env. episode 4879, reward total was -16.0. running mean: -19.309632998508185, timestamp: 2022-08-19 21:47:32.524668\n",
      "resetting env. episode 4880, reward total was -19.0. running mean: -19.306536668523105, timestamp: 2022-08-19 21:47:35.260693\n",
      "resetting env. episode 4881, reward total was -18.0. running mean: -19.293471301837872, timestamp: 2022-08-19 21:47:38.270728\n",
      "resetting env. episode 4882, reward total was -19.0. running mean: -19.290536588819496, timestamp: 2022-08-19 21:47:41.858769\n",
      "resetting env. episode 4883, reward total was -19.0. running mean: -19.287631222931303, timestamp: 2022-08-19 21:47:45.012807\n",
      "resetting env. episode 4884, reward total was -17.0. running mean: -19.264754910701992, timestamp: 2022-08-19 21:47:48.451841\n",
      "resetting env. episode 4885, reward total was -19.0. running mean: -19.262107361594975, timestamp: 2022-08-19 21:47:51.828879\n",
      "resetting env. episode 4886, reward total was -20.0. running mean: -19.269486287979024, timestamp: 2022-08-19 21:47:55.545921\n",
      "resetting env. episode 4887, reward total was -15.0. running mean: -19.226791425099233, timestamp: 2022-08-19 21:47:58.861956\n",
      "resetting env. episode 4888, reward total was -19.0. running mean: -19.22452351084824, timestamp: 2022-08-19 21:48:02.961003\n",
      "resetting env. episode 4889, reward total was -21.0. running mean: -19.242278275739757, timestamp: 2022-08-19 21:48:05.641033\n",
      "resetting env. episode 4890, reward total was -19.0. running mean: -19.23985549298236, timestamp: 2022-08-19 21:48:09.084071\n",
      "resetting env. episode 4891, reward total was -19.0. running mean: -19.23745693805254, timestamp: 2022-08-19 21:48:12.117106\n",
      "resetting env. episode 4892, reward total was -19.0. running mean: -19.235082368672014, timestamp: 2022-08-19 21:48:15.619143\n",
      "resetting env. episode 4893, reward total was -17.0. running mean: -19.212731544985296, timestamp: 2022-08-19 21:48:19.013185\n",
      "resetting env. episode 4894, reward total was -19.0. running mean: -19.210604229535445, timestamp: 2022-08-19 21:48:22.018213\n",
      "resetting env. episode 4895, reward total was -19.0. running mean: -19.208498187240092, timestamp: 2022-08-19 21:48:25.359252\n",
      "resetting env. episode 4896, reward total was -20.0. running mean: -19.21641320536769, timestamp: 2022-08-19 21:48:29.156293\n",
      "resetting env. episode 4897, reward total was -21.0. running mean: -19.234249073314015, timestamp: 2022-08-19 21:48:31.445322\n",
      "resetting env. episode 4898, reward total was -19.0. running mean: -19.231906582580876, timestamp: 2022-08-19 21:48:34.426352\n",
      "resetting env. episode 4899, reward total was -19.0. running mean: -19.229587516755068, timestamp: 2022-08-19 21:48:37.115381\n",
      "resetting env. episode 4900, reward total was -20.0. running mean: -19.237291641587515, timestamp: 2022-08-19 21:48:40.288416\n",
      "resetting env. episode 4901, reward total was -19.0. running mean: -19.234918725171642, timestamp: 2022-08-19 21:48:43.786456\n",
      "resetting env. episode 4902, reward total was -18.0. running mean: -19.222569537919924, timestamp: 2022-08-19 21:48:47.302498\n",
      "resetting env. episode 4903, reward total was -17.0. running mean: -19.200343842540725, timestamp: 2022-08-19 21:48:50.370530\n",
      "resetting env. episode 4904, reward total was -21.0. running mean: -19.21834040411532, timestamp: 2022-08-19 21:48:53.389563\n",
      "resetting env. episode 4905, reward total was -20.0. running mean: -19.226157000074167, timestamp: 2022-08-19 21:48:56.649602\n",
      "resetting env. episode 4906, reward total was -19.0. running mean: -19.223895430073426, timestamp: 2022-08-19 21:48:59.625635\n",
      "resetting env. episode 4907, reward total was -20.0. running mean: -19.23165647577269, timestamp: 2022-08-19 21:49:02.385667\n",
      "resetting env. episode 4908, reward total was -21.0. running mean: -19.249339911014964, timestamp: 2022-08-19 21:49:05.299696\n",
      "resetting env. episode 4909, reward total was -16.0. running mean: -19.216846511904816, timestamp: 2022-08-19 21:49:09.644745\n",
      "resetting env. episode 4910, reward total was -19.0. running mean: -19.214678046785767, timestamp: 2022-08-19 21:49:12.787781\n",
      "resetting env. episode 4911, reward total was -20.0. running mean: -19.222531266317908, timestamp: 2022-08-19 21:49:15.752815\n",
      "resetting env. episode 4912, reward total was -21.0. running mean: -19.24030595365473, timestamp: 2022-08-19 21:49:19.354857\n",
      "resetting env. episode 4913, reward total was -19.0. running mean: -19.237902894118182, timestamp: 2022-08-19 21:49:23.022896\n",
      "resetting env. episode 4914, reward total was -20.0. running mean: -19.245523865177, timestamp: 2022-08-19 21:49:25.986930\n",
      "resetting env. episode 4915, reward total was -18.0. running mean: -19.233068626525228, timestamp: 2022-08-19 21:49:28.835962\n",
      "resetting env. episode 4916, reward total was -21.0. running mean: -19.250737940259977, timestamp: 2022-08-19 21:49:32.099000\n",
      "resetting env. episode 4917, reward total was -21.0. running mean: -19.26823056085738, timestamp: 2022-08-19 21:49:35.508041\n",
      "resetting env. episode 4918, reward total was -19.0. running mean: -19.265548255248806, timestamp: 2022-08-19 21:49:38.740072\n",
      "resetting env. episode 4919, reward total was -20.0. running mean: -19.272892772696316, timestamp: 2022-08-19 21:49:42.149113\n",
      "resetting env. episode 4920, reward total was -17.0. running mean: -19.250163844969354, timestamp: 2022-08-19 21:49:45.122143\n",
      "resetting env. episode 4921, reward total was -20.0. running mean: -19.257662206519658, timestamp: 2022-08-19 21:49:48.064699\n",
      "resetting env. episode 4922, reward total was -19.0. running mean: -19.255085584454463, timestamp: 2022-08-19 21:49:51.683744\n",
      "resetting env. episode 4923, reward total was -19.0. running mean: -19.25253472860992, timestamp: 2022-08-19 21:49:54.255768\n",
      "resetting env. episode 4924, reward total was -19.0. running mean: -19.25000938132382, timestamp: 2022-08-19 21:49:58.498817\n",
      "resetting env. episode 4925, reward total was -19.0. running mean: -19.247509287510585, timestamp: 2022-08-19 21:50:02.774393\n",
      "resetting env. episode 4926, reward total was -20.0. running mean: -19.255034194635478, timestamp: 2022-08-19 21:50:06.124430\n",
      "resetting env. episode 4927, reward total was -19.0. running mean: -19.252483852689124, timestamp: 2022-08-19 21:50:10.107474\n",
      "resetting env. episode 4928, reward total was -21.0. running mean: -19.269959014162232, timestamp: 2022-08-19 21:50:12.503502\n",
      "resetting env. episode 4929, reward total was -17.0. running mean: -19.247259424020612, timestamp: 2022-08-19 21:50:16.559550\n",
      "resetting env. episode 4930, reward total was -19.0. running mean: -19.244786829780406, timestamp: 2022-08-19 21:50:20.119108\n",
      "resetting env. episode 4931, reward total was -18.0. running mean: -19.2323389614826, timestamp: 2022-08-19 21:50:23.344145\n",
      "resetting env. episode 4932, reward total was -21.0. running mean: -19.250015571867774, timestamp: 2022-08-19 21:50:26.303180\n",
      "resetting env. episode 4933, reward total was -21.0. running mean: -19.267515416149095, timestamp: 2022-08-19 21:50:28.977206\n",
      "resetting env. episode 4934, reward total was -19.0. running mean: -19.264840261987604, timestamp: 2022-08-19 21:50:32.572249\n",
      "resetting env. episode 4935, reward total was -20.0. running mean: -19.272191859367727, timestamp: 2022-08-19 21:50:35.205279\n",
      "resetting env. episode 4936, reward total was -19.0. running mean: -19.26946994077405, timestamp: 2022-08-19 21:50:38.425314\n",
      "resetting env. episode 4937, reward total was -19.0. running mean: -19.26677524136631, timestamp: 2022-08-19 21:50:41.860353\n",
      "resetting env. episode 4938, reward total was -20.0. running mean: -19.274107488952648, timestamp: 2022-08-19 21:50:44.380381\n",
      "resetting env. episode 4939, reward total was -17.0. running mean: -19.251366414063124, timestamp: 2022-08-19 21:50:48.183426\n",
      "resetting env. episode 4940, reward total was -21.0. running mean: -19.268852749922495, timestamp: 2022-08-19 21:50:51.384464\n",
      "resetting env. episode 4941, reward total was -17.0. running mean: -19.24616422242327, timestamp: 2022-08-19 21:50:54.796501\n",
      "resetting env. episode 4942, reward total was -20.0. running mean: -19.253702580199036, timestamp: 2022-08-19 21:50:57.670543\n",
      "resetting env. episode 4943, reward total was -20.0. running mean: -19.261165554397046, timestamp: 2022-08-19 21:51:00.911572\n",
      "resetting env. episode 4944, reward total was -18.0. running mean: -19.248553898853075, timestamp: 2022-08-19 21:51:04.556614\n",
      "resetting env. episode 4945, reward total was -21.0. running mean: -19.266068359864544, timestamp: 2022-08-19 21:51:07.925650\n",
      "resetting env. episode 4946, reward total was -16.0. running mean: -19.233407676265898, timestamp: 2022-08-19 21:51:11.634696\n",
      "resetting env. episode 4947, reward total was -19.0. running mean: -19.23107359950324, timestamp: 2022-08-19 21:51:14.882732\n",
      "resetting env. episode 4948, reward total was -19.0. running mean: -19.22876286350821, timestamp: 2022-08-19 21:51:18.503772\n",
      "resetting env. episode 4949, reward total was -19.0. running mean: -19.226475234873128, timestamp: 2022-08-19 21:51:21.959813\n",
      "resetting env. episode 4950, reward total was -18.0. running mean: -19.214210482524397, timestamp: 2022-08-19 21:51:25.746852\n",
      "resetting env. episode 4951, reward total was -20.0. running mean: -19.222068377699152, timestamp: 2022-08-19 21:51:28.291882\n",
      "resetting env. episode 4952, reward total was -19.0. running mean: -19.219847693922162, timestamp: 2022-08-19 21:51:31.615923\n",
      "resetting env. episode 4953, reward total was -17.0. running mean: -19.197649216982942, timestamp: 2022-08-19 21:51:35.367964\n",
      "resetting env. episode 4954, reward total was -19.0. running mean: -19.195672724813114, timestamp: 2022-08-19 21:51:38.564533\n",
      "resetting env. episode 4955, reward total was -18.0. running mean: -19.18371599756498, timestamp: 2022-08-19 21:51:41.474572\n",
      "resetting env. episode 4956, reward total was -20.0. running mean: -19.191878837589332, timestamp: 2022-08-19 21:51:44.294599\n",
      "resetting env. episode 4957, reward total was -18.0. running mean: -19.179960049213438, timestamp: 2022-08-19 21:51:48.571649\n",
      "resetting env. episode 4958, reward total was -19.0. running mean: -19.178160448721304, timestamp: 2022-08-19 21:51:51.421681\n",
      "resetting env. episode 4959, reward total was -21.0. running mean: -19.19637884423409, timestamp: 2022-08-19 21:51:55.107724\n",
      "resetting env. episode 4960, reward total was -21.0. running mean: -19.21441505579175, timestamp: 2022-08-19 21:51:57.903753\n",
      "resetting env. episode 4961, reward total was -18.0. running mean: -19.20227090523383, timestamp: 2022-08-19 21:52:01.938801\n",
      "resetting env. episode 4962, reward total was -17.0. running mean: -19.180248196181495, timestamp: 2022-08-19 21:52:05.688847\n",
      "resetting env. episode 4963, reward total was -16.0. running mean: -19.14844571421968, timestamp: 2022-08-19 21:52:09.146881\n",
      "resetting env. episode 4964, reward total was -17.0. running mean: -19.126961257077486, timestamp: 2022-08-19 21:52:12.452924\n",
      "resetting env. episode 4965, reward total was -19.0. running mean: -19.125691644506713, timestamp: 2022-08-19 21:52:15.813961\n",
      "resetting env. episode 4966, reward total was -20.0. running mean: -19.134434728061645, timestamp: 2022-08-19 21:52:18.602989\n",
      "resetting env. episode 4967, reward total was -21.0. running mean: -19.15309038078103, timestamp: 2022-08-19 21:52:21.730029\n",
      "resetting env. episode 4968, reward total was -18.0. running mean: -19.14155947697322, timestamp: 2022-08-19 21:52:24.098054\n",
      "resetting env. episode 4969, reward total was -18.0. running mean: -19.130143882203487, timestamp: 2022-08-19 21:52:27.447092\n",
      "resetting env. episode 4970, reward total was -20.0. running mean: -19.138842443381453, timestamp: 2022-08-19 21:52:30.587129\n",
      "resetting env. episode 4971, reward total was -19.0. running mean: -19.13745401894764, timestamp: 2022-08-19 21:52:34.550174\n",
      "resetting env. episode 4972, reward total was -19.0. running mean: -19.136079478758166, timestamp: 2022-08-19 21:52:37.760211\n",
      "resetting env. episode 4973, reward total was -20.0. running mean: -19.144718683970584, timestamp: 2022-08-19 21:52:40.849244\n",
      "resetting env. episode 4974, reward total was -19.0. running mean: -19.14327149713088, timestamp: 2022-08-19 21:52:43.516277\n",
      "resetting env. episode 4975, reward total was -17.0. running mean: -19.12183878215957, timestamp: 2022-08-19 21:52:46.671312\n",
      "resetting env. episode 4976, reward total was -21.0. running mean: -19.140620394337976, timestamp: 2022-08-19 21:52:50.111350\n",
      "resetting env. episode 4977, reward total was -21.0. running mean: -19.159214190394596, timestamp: 2022-08-19 21:52:53.373387\n",
      "resetting env. episode 4978, reward total was -20.0. running mean: -19.16762204849065, timestamp: 2022-08-19 21:52:56.220945\n",
      "resetting env. episode 4979, reward total was -20.0. running mean: -19.17594582800574, timestamp: 2022-08-19 21:52:59.692981\n",
      "resetting env. episode 4980, reward total was -21.0. running mean: -19.194186369725685, timestamp: 2022-08-19 21:53:02.216009\n",
      "resetting env. episode 4981, reward total was -21.0. running mean: -19.21224450602843, timestamp: 2022-08-19 21:53:05.710052\n",
      "resetting env. episode 4982, reward total was -21.0. running mean: -19.230122060968146, timestamp: 2022-08-19 21:53:08.532082\n",
      "resetting env. episode 4983, reward total was -20.0. running mean: -19.237820840358463, timestamp: 2022-08-19 21:53:11.099110\n",
      "resetting env. episode 4984, reward total was -21.0. running mean: -19.255442631954878, timestamp: 2022-08-19 21:53:14.169145\n",
      "resetting env. episode 4985, reward total was -20.0. running mean: -19.262888205635328, timestamp: 2022-08-19 21:53:17.583186\n",
      "resetting env. episode 4986, reward total was -20.0. running mean: -19.270259323578973, timestamp: 2022-08-19 21:53:20.583217\n",
      "resetting env. episode 4987, reward total was -21.0. running mean: -19.287556730343184, timestamp: 2022-08-19 21:53:24.300260\n",
      "resetting env. episode 4988, reward total was -19.0. running mean: -19.284681163039753, timestamp: 2022-08-19 21:53:27.638300\n",
      "resetting env. episode 4989, reward total was -20.0. running mean: -19.291834351409356, timestamp: 2022-08-19 21:53:30.941340\n",
      "resetting env. episode 4990, reward total was -19.0. running mean: -19.288916007895264, timestamp: 2022-08-19 21:53:33.967371\n",
      "resetting env. episode 4991, reward total was -19.0. running mean: -19.286026847816313, timestamp: 2022-08-19 21:53:37.332411\n",
      "resetting env. episode 4992, reward total was -18.0. running mean: -19.27316657933815, timestamp: 2022-08-19 21:53:40.246445\n",
      "resetting env. episode 4993, reward total was -18.0. running mean: -19.260434913544767, timestamp: 2022-08-19 21:53:43.614484\n",
      "resetting env. episode 4994, reward total was -21.0. running mean: -19.27783056440932, timestamp: 2022-08-19 21:53:46.085508\n",
      "resetting env. episode 4995, reward total was -21.0. running mean: -19.295052258765228, timestamp: 2022-08-19 21:53:49.487546\n",
      "resetting env. episode 4996, reward total was -20.0. running mean: -19.302101736177576, timestamp: 2022-08-19 21:53:52.555586\n",
      "resetting env. episode 4997, reward total was -17.0. running mean: -19.279080718815802, timestamp: 2022-08-19 21:53:56.574632\n",
      "resetting env. episode 4998, reward total was -21.0. running mean: -19.296289911627646, timestamp: 2022-08-19 21:53:59.744667\n",
      "resetting env. episode 4999, reward total was -21.0. running mean: -19.31332701251137, timestamp: 2022-08-19 21:54:02.516225\n",
      "resetting env. episode 5000, reward total was -19.0. running mean: -19.310193742386257, timestamp: 2022-08-19 21:54:06.353268\n",
      "resetting env. episode 5001, reward total was -21.0. running mean: -19.327091804962397, timestamp: 2022-08-19 21:54:09.455301\n",
      "resetting env. episode 5002, reward total was -18.0. running mean: -19.313820886912772, timestamp: 2022-08-19 21:54:13.492349\n",
      "resetting env. episode 5003, reward total was -19.0. running mean: -19.310682678043644, timestamp: 2022-08-19 21:54:17.742397\n",
      "resetting env. episode 5004, reward total was -21.0. running mean: -19.32757585126321, timestamp: 2022-08-19 21:54:20.774431\n",
      "resetting env. episode 5005, reward total was -21.0. running mean: -19.344300092750576, timestamp: 2022-08-19 21:54:23.442983\n",
      "resetting env. episode 5006, reward total was -19.0. running mean: -19.34085709182307, timestamp: 2022-08-19 21:54:26.608027\n",
      "resetting env. episode 5007, reward total was -20.0. running mean: -19.34744852090484, timestamp: 2022-08-19 21:54:29.854579\n",
      "resetting env. episode 5008, reward total was -18.0. running mean: -19.333974035695793, timestamp: 2022-08-19 21:54:33.735623\n",
      "resetting env. episode 5009, reward total was -21.0. running mean: -19.350634295338835, timestamp: 2022-08-19 21:54:36.548655\n",
      "resetting env. episode 5010, reward total was -20.0. running mean: -19.357127952385447, timestamp: 2022-08-19 21:54:39.437688\n",
      "resetting env. episode 5011, reward total was -18.0. running mean: -19.34355667286159, timestamp: 2022-08-19 21:54:42.595725\n",
      "resetting env. episode 5012, reward total was -20.0. running mean: -19.350121106132974, timestamp: 2022-08-19 21:54:45.866285\n",
      "resetting env. episode 5013, reward total was -19.0. running mean: -19.346619895071644, timestamp: 2022-08-19 21:54:48.960322\n",
      "resetting env. episode 5014, reward total was -19.0. running mean: -19.34315369612093, timestamp: 2022-08-19 21:54:52.435360\n",
      "resetting env. episode 5015, reward total was -21.0. running mean: -19.35972215915972, timestamp: 2022-08-19 21:54:55.559397\n",
      "resetting env. episode 5016, reward total was -21.0. running mean: -19.37612493756812, timestamp: 2022-08-19 21:54:58.443438\n",
      "resetting env. episode 5017, reward total was -19.0. running mean: -19.37236368819244, timestamp: 2022-08-19 21:55:02.321474\n",
      "resetting env. episode 5018, reward total was -16.0. running mean: -19.338640051310517, timestamp: 2022-08-19 21:55:05.296511\n",
      "resetting env. episode 5019, reward total was -20.0. running mean: -19.34525365079741, timestamp: 2022-08-19 21:55:08.190539\n",
      "resetting env. episode 5020, reward total was -19.0. running mean: -19.34180111428944, timestamp: 2022-08-19 21:55:12.214585\n",
      "resetting env. episode 5021, reward total was -21.0. running mean: -19.358383103146544, timestamp: 2022-08-19 21:55:15.330140\n",
      "resetting env. episode 5022, reward total was -19.0. running mean: -19.35479927211508, timestamp: 2022-08-19 21:55:18.899182\n",
      "resetting env. episode 5023, reward total was -18.0. running mean: -19.34125127939393, timestamp: 2022-08-19 21:55:21.589216\n",
      "resetting env. episode 5024, reward total was -18.0. running mean: -19.32783876659999, timestamp: 2022-08-19 21:55:24.747252\n",
      "resetting env. episode 5025, reward total was -20.0. running mean: -19.334560378933986, timestamp: 2022-08-19 21:55:27.976290\n",
      "resetting env. episode 5026, reward total was -19.0. running mean: -19.331214775144648, timestamp: 2022-08-19 21:55:31.339325\n",
      "resetting env. episode 5027, reward total was -19.0. running mean: -19.327902627393204, timestamp: 2022-08-19 21:55:34.163357\n",
      "resetting env. episode 5028, reward total was -17.0. running mean: -19.304623601119275, timestamp: 2022-08-19 21:55:38.109405\n",
      "resetting env. episode 5029, reward total was -19.0. running mean: -19.301577365108084, timestamp: 2022-08-19 21:55:41.073437\n",
      "resetting env. episode 5030, reward total was -20.0. running mean: -19.308561591457003, timestamp: 2022-08-19 21:55:44.471472\n",
      "resetting env. episode 5031, reward total was -21.0. running mean: -19.325475975542435, timestamp: 2022-08-19 21:55:47.556026\n",
      "resetting env. episode 5032, reward total was -18.0. running mean: -19.31222121578701, timestamp: 2022-08-19 21:55:50.802068\n",
      "resetting env. episode 5033, reward total was -19.0. running mean: -19.30909900362914, timestamp: 2022-08-19 21:55:54.425108\n",
      "resetting env. episode 5034, reward total was -19.0. running mean: -19.306008013592848, timestamp: 2022-08-19 21:55:58.102148\n",
      "resetting env. episode 5035, reward total was -19.0. running mean: -19.30294793345692, timestamp: 2022-08-19 21:56:02.508198\n",
      "resetting env. episode 5036, reward total was -20.0. running mean: -19.30991845412235, timestamp: 2022-08-19 21:56:05.447231\n",
      "resetting env. episode 5037, reward total was -21.0. running mean: -19.326819269581126, timestamp: 2022-08-19 21:56:08.069264\n",
      "resetting env. episode 5038, reward total was -19.0. running mean: -19.323551076885316, timestamp: 2022-08-19 21:56:11.609305\n",
      "resetting env. episode 5039, reward total was -17.0. running mean: -19.300315566116463, timestamp: 2022-08-19 21:56:14.731340\n",
      "resetting env. episode 5040, reward total was -18.0. running mean: -19.2873124104553, timestamp: 2022-08-19 21:56:19.054389\n",
      "resetting env. episode 5041, reward total was -20.0. running mean: -19.294439286350745, timestamp: 2022-08-19 21:56:22.929954\n",
      "resetting env. episode 5042, reward total was -21.0. running mean: -19.31149489348724, timestamp: 2022-08-19 21:56:25.627984\n",
      "resetting env. episode 5043, reward total was -21.0. running mean: -19.328379944552367, timestamp: 2022-08-19 21:56:28.514019\n",
      "resetting env. episode 5044, reward total was -21.0. running mean: -19.345096145106844, timestamp: 2022-08-19 21:56:32.172057\n",
      "resetting env. episode 5045, reward total was -20.0. running mean: -19.351645183655773, timestamp: 2022-08-19 21:56:35.030090\n",
      "resetting env. episode 5046, reward total was -20.0. running mean: -19.358128731819214, timestamp: 2022-08-19 21:56:37.961123\n",
      "resetting env. episode 5047, reward total was -18.0. running mean: -19.34454744450102, timestamp: 2022-08-19 21:56:41.122173\n",
      "resetting env. episode 5048, reward total was -21.0. running mean: -19.361101970056012, timestamp: 2022-08-19 21:56:43.955191\n",
      "resetting env. episode 5049, reward total was -18.0. running mean: -19.34749095035545, timestamp: 2022-08-19 21:56:46.984229\n",
      "resetting env. episode 5050, reward total was -20.0. running mean: -19.354016040851896, timestamp: 2022-08-19 21:56:51.154274\n",
      "resetting env. episode 5051, reward total was -19.0. running mean: -19.350475880443376, timestamp: 2022-08-19 21:56:54.775320\n",
      "resetting env. episode 5052, reward total was -19.0. running mean: -19.346971121638944, timestamp: 2022-08-19 21:56:58.543360\n",
      "resetting env. episode 5053, reward total was -19.0. running mean: -19.343501410422554, timestamp: 2022-08-19 21:57:01.805398\n",
      "resetting env. episode 5054, reward total was -20.0. running mean: -19.35006639631833, timestamp: 2022-08-19 21:57:04.117422\n",
      "resetting env. episode 5055, reward total was -20.0. running mean: -19.356565732355143, timestamp: 2022-08-19 21:57:07.117462\n",
      "resetting env. episode 5056, reward total was -21.0. running mean: -19.37300007503159, timestamp: 2022-08-19 21:57:10.667504\n",
      "resetting env. episode 5057, reward total was -20.0. running mean: -19.379270074281273, timestamp: 2022-08-19 21:57:13.927056\n",
      "resetting env. episode 5058, reward total was -21.0. running mean: -19.395477373538462, timestamp: 2022-08-19 21:57:17.767100\n",
      "resetting env. episode 5059, reward total was -20.0. running mean: -19.401522599803076, timestamp: 2022-08-19 21:57:20.835139\n",
      "resetting env. episode 5060, reward total was -17.0. running mean: -19.37750737380505, timestamp: 2022-08-19 21:57:24.697181\n",
      "resetting env. episode 5061, reward total was -20.0. running mean: -19.383732300067, timestamp: 2022-08-19 21:57:27.613213\n",
      "resetting env. episode 5062, reward total was -20.0. running mean: -19.389894977066326, timestamp: 2022-08-19 21:57:29.790238\n",
      "resetting env. episode 5063, reward total was -19.0. running mean: -19.385996027295665, timestamp: 2022-08-19 21:57:32.437267\n",
      "resetting env. episode 5064, reward total was -19.0. running mean: -19.38213606702271, timestamp: 2022-08-19 21:57:36.022311\n",
      "resetting env. episode 5065, reward total was -21.0. running mean: -19.398314706352483, timestamp: 2022-08-19 21:57:38.676343\n",
      "resetting env. episode 5066, reward total was -17.0. running mean: -19.37433155928896, timestamp: 2022-08-19 21:57:42.383381\n",
      "resetting env. episode 5067, reward total was -19.0. running mean: -19.370588243696073, timestamp: 2022-08-19 21:57:45.512418\n",
      "resetting env. episode 5068, reward total was -21.0. running mean: -19.38688236125911, timestamp: 2022-08-19 21:57:48.125446\n",
      "resetting env. episode 5069, reward total was -19.0. running mean: -19.383013537646523, timestamp: 2022-08-19 21:57:51.196481\n",
      "resetting env. episode 5070, reward total was -21.0. running mean: -19.399183402270058, timestamp: 2022-08-19 21:57:54.927528\n",
      "resetting env. episode 5071, reward total was -18.0. running mean: -19.385191568247357, timestamp: 2022-08-19 21:57:58.021556\n",
      "resetting env. episode 5072, reward total was -21.0. running mean: -19.401339652564886, timestamp: 2022-08-19 21:58:00.393591\n",
      "resetting env. episode 5073, reward total was -21.0. running mean: -19.41732625603924, timestamp: 2022-08-19 21:58:03.581618\n",
      "resetting env. episode 5074, reward total was -21.0. running mean: -19.433152993478846, timestamp: 2022-08-19 21:58:06.544654\n",
      "resetting env. episode 5075, reward total was -19.0. running mean: -19.428821463544057, timestamp: 2022-08-19 21:58:10.199693\n",
      "resetting env. episode 5076, reward total was -20.0. running mean: -19.434533248908615, timestamp: 2022-08-19 21:58:13.142728\n",
      "resetting env. episode 5077, reward total was -18.0. running mean: -19.42018791641953, timestamp: 2022-08-19 21:58:16.814770\n",
      "resetting env. episode 5078, reward total was -21.0. running mean: -19.435986037255333, timestamp: 2022-08-19 21:58:20.040808\n",
      "resetting env. episode 5079, reward total was -19.0. running mean: -19.43162617688278, timestamp: 2022-08-19 21:58:23.672847\n",
      "resetting env. episode 5080, reward total was -19.0. running mean: -19.427309915113952, timestamp: 2022-08-19 21:58:27.375890\n",
      "resetting env. episode 5081, reward total was -20.0. running mean: -19.43303681596281, timestamp: 2022-08-19 21:58:30.198921\n",
      "resetting env. episode 5082, reward total was -21.0. running mean: -19.448706447803183, timestamp: 2022-08-19 21:58:33.847483\n",
      "resetting env. episode 5083, reward total was -21.0. running mean: -19.46421938332515, timestamp: 2022-08-19 21:58:37.061525\n",
      "resetting env. episode 5084, reward total was -15.0. running mean: -19.419577189491896, timestamp: 2022-08-19 21:58:41.056567\n",
      "resetting env. episode 5085, reward total was -20.0. running mean: -19.425381417596977, timestamp: 2022-08-19 21:58:44.192128\n",
      "resetting env. episode 5086, reward total was -19.0. running mean: -19.42112760342101, timestamp: 2022-08-19 21:58:47.486164\n",
      "resetting env. episode 5087, reward total was -20.0. running mean: -19.4269163273868, timestamp: 2022-08-19 21:58:50.890201\n",
      "resetting env. episode 5088, reward total was -21.0. running mean: -19.44264716411293, timestamp: 2022-08-19 21:58:53.743234\n",
      "resetting env. episode 5089, reward total was -19.0. running mean: -19.438220692471802, timestamp: 2022-08-19 21:58:57.894280\n",
      "resetting env. episode 5090, reward total was -20.0. running mean: -19.443838485547083, timestamp: 2022-08-19 21:59:00.896314\n",
      "resetting env. episode 5091, reward total was -21.0. running mean: -19.459400100691614, timestamp: 2022-08-19 21:59:04.067349\n",
      "resetting env. episode 5092, reward total was -19.0. running mean: -19.4548060996847, timestamp: 2022-08-19 21:59:07.223393\n",
      "resetting env. episode 5093, reward total was -18.0. running mean: -19.44025803868785, timestamp: 2022-08-19 21:59:10.856429\n",
      "resetting env. episode 5094, reward total was -18.0. running mean: -19.425855458300973, timestamp: 2022-08-19 21:59:14.727474\n",
      "resetting env. episode 5095, reward total was -16.0. running mean: -19.391596903717964, timestamp: 2022-08-19 21:59:18.618521\n",
      "resetting env. episode 5096, reward total was -17.0. running mean: -19.367680934680788, timestamp: 2022-08-19 21:59:22.332558\n",
      "resetting env. episode 5097, reward total was -18.0. running mean: -19.35400412533398, timestamp: 2022-08-19 21:59:25.210589\n",
      "resetting env. episode 5098, reward total was -17.0. running mean: -19.330464084080642, timestamp: 2022-08-19 21:59:28.515155\n",
      "resetting env. episode 5099, reward total was -19.0. running mean: -19.327159443239836, timestamp: 2022-08-19 21:59:31.660192\n",
      "resetting env. episode 5100, reward total was -21.0. running mean: -19.343887848807437, timestamp: 2022-08-19 21:59:34.984226\n",
      "resetting env. episode 5101, reward total was -18.0. running mean: -19.330448970319363, timestamp: 2022-08-19 21:59:38.200265\n",
      "resetting env. episode 5102, reward total was -16.0. running mean: -19.29714448061617, timestamp: 2022-08-19 21:59:42.130311\n",
      "resetting env. episode 5103, reward total was -17.0. running mean: -19.27417303581001, timestamp: 2022-08-19 21:59:46.359356\n",
      "resetting env. episode 5104, reward total was -20.0. running mean: -19.281431305451907, timestamp: 2022-08-19 21:59:50.334401\n",
      "resetting env. episode 5105, reward total was -20.0. running mean: -19.288616992397387, timestamp: 2022-08-19 21:59:53.125434\n",
      "resetting env. episode 5106, reward total was -19.0. running mean: -19.285730822473415, timestamp: 2022-08-19 21:59:56.470469\n",
      "resetting env. episode 5107, reward total was -18.0. running mean: -19.27287351424868, timestamp: 2022-08-19 21:59:59.480505\n",
      "resetting env. episode 5108, reward total was -19.0. running mean: -19.270144779106193, timestamp: 2022-08-19 22:00:02.423537\n",
      "resetting env. episode 5109, reward total was -19.0. running mean: -19.267443331315132, timestamp: 2022-08-19 22:00:04.921568\n",
      "resetting env. episode 5110, reward total was -20.0. running mean: -19.27476889800198, timestamp: 2022-08-19 22:00:07.675600\n",
      "resetting env. episode 5111, reward total was -18.0. running mean: -19.26202120902196, timestamp: 2022-08-19 22:00:11.530640\n",
      "resetting env. episode 5112, reward total was -16.0. running mean: -19.22940099693174, timestamp: 2022-08-19 22:00:15.493684\n",
      "resetting env. episode 5113, reward total was -20.0. running mean: -19.237106986962424, timestamp: 2022-08-19 22:00:18.092712\n",
      "resetting env. episode 5114, reward total was -21.0. running mean: -19.2547359170928, timestamp: 2022-08-19 22:00:22.269759\n",
      "resetting env. episode 5115, reward total was -19.0. running mean: -19.252188557921873, timestamp: 2022-08-19 22:00:25.674799\n",
      "resetting env. episode 5116, reward total was -17.0. running mean: -19.229666672342656, timestamp: 2022-08-19 22:00:29.934847\n",
      "resetting env. episode 5117, reward total was -15.0. running mean: -19.18737000561923, timestamp: 2022-08-19 22:00:33.658889\n",
      "resetting env. episode 5118, reward total was -18.0. running mean: -19.175496305563037, timestamp: 2022-08-19 22:00:36.598922\n",
      "resetting env. episode 5119, reward total was -21.0. running mean: -19.19374134250741, timestamp: 2022-08-19 22:00:40.014961\n",
      "resetting env. episode 5120, reward total was -19.0. running mean: -19.191803929082337, timestamp: 2022-08-19 22:00:43.588997\n",
      "resetting env. episode 5121, reward total was -19.0. running mean: -19.189885889791515, timestamp: 2022-08-19 22:00:45.842026\n",
      "resetting env. episode 5122, reward total was -21.0. running mean: -19.2079870308936, timestamp: 2022-08-19 22:00:48.849061\n",
      "resetting env. episode 5123, reward total was -20.0. running mean: -19.215907160584663, timestamp: 2022-08-19 22:00:51.412086\n",
      "resetting env. episode 5124, reward total was -19.0. running mean: -19.213748088978818, timestamp: 2022-08-19 22:00:54.823125\n",
      "resetting env. episode 5125, reward total was -12.0. running mean: -19.14161060808903, timestamp: 2022-08-19 22:00:59.152173\n",
      "resetting env. episode 5126, reward total was -20.0. running mean: -19.15019450200814, timestamp: 2022-08-19 22:01:02.075209\n",
      "resetting env. episode 5127, reward total was -20.0. running mean: -19.158692556988058, timestamp: 2022-08-19 22:01:05.795248\n",
      "resetting env. episode 5128, reward total was -18.0. running mean: -19.147105631418178, timestamp: 2022-08-19 22:01:08.052274\n",
      "resetting env. episode 5129, reward total was -21.0. running mean: -19.165634575103997, timestamp: 2022-08-19 22:01:11.187310\n",
      "resetting env. episode 5130, reward total was -21.0. running mean: -19.18397822935296, timestamp: 2022-08-19 22:01:14.056341\n",
      "resetting env. episode 5131, reward total was -21.0. running mean: -19.20213844705943, timestamp: 2022-08-19 22:01:17.105375\n",
      "resetting env. episode 5132, reward total was -19.0. running mean: -19.200117062588838, timestamp: 2022-08-19 22:01:20.798414\n",
      "resetting env. episode 5133, reward total was -16.0. running mean: -19.168115891962948, timestamp: 2022-08-19 22:01:24.142453\n",
      "resetting env. episode 5134, reward total was -20.0. running mean: -19.17643473304332, timestamp: 2022-08-19 22:01:26.678484\n",
      "resetting env. episode 5135, reward total was -19.0. running mean: -19.174670385712886, timestamp: 2022-08-19 22:01:29.976520\n",
      "resetting env. episode 5136, reward total was -21.0. running mean: -19.19292368185576, timestamp: 2022-08-19 22:01:33.562557\n",
      "resetting env. episode 5137, reward total was -20.0. running mean: -19.2009944450372, timestamp: 2022-08-19 22:01:36.372592\n",
      "resetting env. episode 5138, reward total was -21.0. running mean: -19.218984500586828, timestamp: 2022-08-19 22:01:39.279622\n",
      "resetting env. episode 5139, reward total was -19.0. running mean: -19.216794655580962, timestamp: 2022-08-19 22:01:42.667662\n",
      "resetting env. episode 5140, reward total was -21.0. running mean: -19.234626709025154, timestamp: 2022-08-19 22:01:46.091699\n",
      "resetting env. episode 5141, reward total was -21.0. running mean: -19.252280441934904, timestamp: 2022-08-19 22:01:49.575738\n",
      "resetting env. episode 5142, reward total was -18.0. running mean: -19.239757637515556, timestamp: 2022-08-19 22:01:52.765777\n",
      "resetting env. episode 5143, reward total was -17.0. running mean: -19.2173600611404, timestamp: 2022-08-19 22:01:56.867825\n",
      "resetting env. episode 5144, reward total was -19.0. running mean: -19.215186460528997, timestamp: 2022-08-19 22:02:00.305858\n",
      "resetting env. episode 5145, reward total was -17.0. running mean: -19.19303459592371, timestamp: 2022-08-19 22:02:03.465894\n",
      "resetting env. episode 5146, reward total was -20.0. running mean: -19.201104249964473, timestamp: 2022-08-19 22:02:06.156926\n",
      "resetting env. episode 5147, reward total was -18.0. running mean: -19.18909320746483, timestamp: 2022-08-19 22:02:09.332959\n",
      "resetting env. episode 5148, reward total was -20.0. running mean: -19.19720227539018, timestamp: 2022-08-19 22:02:12.956001\n",
      "resetting env. episode 5149, reward total was -20.0. running mean: -19.205230252636277, timestamp: 2022-08-19 22:02:16.909044\n",
      "resetting env. episode 5150, reward total was -20.0. running mean: -19.213177950109912, timestamp: 2022-08-19 22:02:19.685076\n",
      "resetting env. episode 5151, reward total was -21.0. running mean: -19.231046170608813, timestamp: 2022-08-19 22:02:22.315104\n",
      "resetting env. episode 5152, reward total was -20.0. running mean: -19.238735708902723, timestamp: 2022-08-19 22:02:25.479142\n",
      "resetting env. episode 5153, reward total was -20.0. running mean: -19.246348351813694, timestamp: 2022-08-19 22:02:28.236170\n",
      "resetting env. episode 5154, reward total was -20.0. running mean: -19.253884868295557, timestamp: 2022-08-19 22:02:31.563206\n",
      "resetting env. episode 5155, reward total was -19.0. running mean: -19.251346019612605, timestamp: 2022-08-19 22:02:35.238246\n",
      "resetting env. episode 5156, reward total was -19.0. running mean: -19.24883255941648, timestamp: 2022-08-19 22:02:38.405285\n",
      "resetting env. episode 5157, reward total was -16.0. running mean: -19.216344233822316, timestamp: 2022-08-19 22:02:42.233325\n",
      "resetting env. episode 5158, reward total was -15.0. running mean: -19.17418079148409, timestamp: 2022-08-19 22:02:45.635364\n",
      "resetting env. episode 5159, reward total was -18.0. running mean: -19.16243898356925, timestamp: 2022-08-19 22:02:48.536395\n",
      "resetting env. episode 5160, reward total was -20.0. running mean: -19.170814593733557, timestamp: 2022-08-19 22:02:51.975434\n",
      "resetting env. episode 5161, reward total was -20.0. running mean: -19.17910644779622, timestamp: 2022-08-19 22:02:54.402462\n",
      "resetting env. episode 5162, reward total was -19.0. running mean: -19.17731538331826, timestamp: 2022-08-19 22:02:58.162501\n",
      "resetting env. episode 5163, reward total was -21.0. running mean: -19.195542229485078, timestamp: 2022-08-19 22:03:01.500539\n",
      "resetting env. episode 5164, reward total was -21.0. running mean: -19.21358680719023, timestamp: 2022-08-19 22:03:04.205568\n",
      "resetting env. episode 5165, reward total was -16.0. running mean: -19.181450939118328, timestamp: 2022-08-19 22:03:07.689609\n",
      "resetting env. episode 5166, reward total was -21.0. running mean: -19.199636429727146, timestamp: 2022-08-19 22:03:10.810641\n",
      "resetting env. episode 5167, reward total was -17.0. running mean: -19.177640065429877, timestamp: 2022-08-19 22:03:14.335684\n",
      "resetting env. episode 5168, reward total was -18.0. running mean: -19.16586366477558, timestamp: 2022-08-19 22:03:17.450717\n",
      "resetting env. episode 5169, reward total was -17.0. running mean: -19.144205028127825, timestamp: 2022-08-19 22:03:20.861756\n",
      "resetting env. episode 5170, reward total was -20.0. running mean: -19.152762977846546, timestamp: 2022-08-19 22:03:23.309780\n",
      "resetting env. episode 5171, reward total was -19.0. running mean: -19.15123534806808, timestamp: 2022-08-19 22:03:26.183815\n",
      "resetting env. episode 5172, reward total was -21.0. running mean: -19.1697229945874, timestamp: 2022-08-19 22:03:29.587852\n",
      "resetting env. episode 5173, reward total was -21.0. running mean: -19.188025764641527, timestamp: 2022-08-19 22:03:32.275880\n",
      "resetting env. episode 5174, reward total was -19.0. running mean: -19.186145506995114, timestamp: 2022-08-19 22:03:35.051913\n",
      "resetting env. episode 5175, reward total was -20.0. running mean: -19.194284051925163, timestamp: 2022-08-19 22:03:38.522949\n",
      "resetting env. episode 5176, reward total was -19.0. running mean: -19.19234121140591, timestamp: 2022-08-19 22:03:41.486982\n",
      "resetting env. episode 5177, reward total was -19.0. running mean: -19.190417799291854, timestamp: 2022-08-19 22:03:44.177015\n",
      "resetting env. episode 5178, reward total was -20.0. running mean: -19.198513621298936, timestamp: 2022-08-19 22:03:47.248046\n",
      "resetting env. episode 5179, reward total was -19.0. running mean: -19.19652848508595, timestamp: 2022-08-19 22:03:49.502072\n",
      "resetting env. episode 5180, reward total was -18.0. running mean: -19.18456320023509, timestamp: 2022-08-19 22:03:53.117113\n",
      "resetting env. episode 5181, reward total was -21.0. running mean: -19.20271756823274, timestamp: 2022-08-19 22:03:56.397150\n",
      "resetting env. episode 5182, reward total was -20.0. running mean: -19.21069039255041, timestamp: 2022-08-19 22:03:59.327184\n",
      "resetting env. episode 5183, reward total was -20.0. running mean: -19.218583488624905, timestamp: 2022-08-19 22:04:02.459216\n",
      "resetting env. episode 5184, reward total was -19.0. running mean: -19.216397653738657, timestamp: 2022-08-19 22:04:06.503261\n",
      "resetting env. episode 5185, reward total was -20.0. running mean: -19.22423367720127, timestamp: 2022-08-19 22:04:09.700296\n",
      "resetting env. episode 5186, reward total was -18.0. running mean: -19.211991340429257, timestamp: 2022-08-19 22:04:12.679328\n",
      "resetting env. episode 5187, reward total was -21.0. running mean: -19.229871427024964, timestamp: 2022-08-19 22:04:15.704364\n",
      "resetting env. episode 5188, reward total was -17.0. running mean: -19.207572712754715, timestamp: 2022-08-19 22:04:18.960398\n",
      "resetting env. episode 5189, reward total was -17.0. running mean: -19.185496985627168, timestamp: 2022-08-19 22:04:21.895433\n",
      "resetting env. episode 5190, reward total was -20.0. running mean: -19.193642015770894, timestamp: 2022-08-19 22:04:25.308467\n",
      "resetting env. episode 5191, reward total was -19.0. running mean: -19.191705595613186, timestamp: 2022-08-19 22:04:28.524503\n",
      "resetting env. episode 5192, reward total was -19.0. running mean: -19.189788539657055, timestamp: 2022-08-19 22:04:32.004543\n",
      "resetting env. episode 5193, reward total was -19.0. running mean: -19.187890654260485, timestamp: 2022-08-19 22:04:35.093578\n",
      "resetting env. episode 5194, reward total was -21.0. running mean: -19.20601174771788, timestamp: 2022-08-19 22:04:38.076608\n",
      "resetting env. episode 5195, reward total was -21.0. running mean: -19.223951630240702, timestamp: 2022-08-19 22:04:41.110642\n",
      "resetting env. episode 5196, reward total was -20.0. running mean: -19.231712113938293, timestamp: 2022-08-19 22:04:44.267677\n",
      "resetting env. episode 5197, reward total was -20.0. running mean: -19.23939499279891, timestamp: 2022-08-19 22:04:47.463714\n",
      "resetting env. episode 5198, reward total was -14.0. running mean: -19.18700104287092, timestamp: 2022-08-19 22:04:51.001751\n",
      "resetting env. episode 5199, reward total was -21.0. running mean: -19.205131032442214, timestamp: 2022-08-19 22:04:54.176788\n",
      "resetting env. episode 5200, reward total was -21.0. running mean: -19.22307972211779, timestamp: 2022-08-19 22:04:56.996816\n",
      "resetting env. episode 5201, reward total was -20.0. running mean: -19.230848924896613, timestamp: 2022-08-19 22:04:59.608845\n",
      "resetting env. episode 5202, reward total was -21.0. running mean: -19.248540435647648, timestamp: 2022-08-19 22:05:02.332875\n",
      "resetting env. episode 5203, reward total was -17.0. running mean: -19.226055031291175, timestamp: 2022-08-19 22:05:06.470923\n",
      "resetting env. episode 5204, reward total was -21.0. running mean: -19.243794480978263, timestamp: 2022-08-19 22:05:09.369954\n",
      "resetting env. episode 5205, reward total was -21.0. running mean: -19.26135653616848, timestamp: 2022-08-19 22:05:11.764981\n",
      "resetting env. episode 5206, reward total was -19.0. running mean: -19.258742970806797, timestamp: 2022-08-19 22:05:14.222009\n",
      "resetting env. episode 5207, reward total was -21.0. running mean: -19.276155541098728, timestamp: 2022-08-19 22:05:16.804036\n",
      "resetting env. episode 5208, reward total was -20.0. running mean: -19.283393985687738, timestamp: 2022-08-19 22:05:19.932071\n",
      "resetting env. episode 5209, reward total was -17.0. running mean: -19.26056004583086, timestamp: 2022-08-19 22:05:23.430108\n",
      "resetting env. episode 5210, reward total was -17.0. running mean: -19.237954445372555, timestamp: 2022-08-19 22:05:26.535142\n",
      "resetting env. episode 5211, reward total was -19.0. running mean: -19.23557490091883, timestamp: 2022-08-19 22:05:30.094183\n",
      "resetting env. episode 5212, reward total was -16.0. running mean: -19.203219151909643, timestamp: 2022-08-19 22:05:33.362220\n",
      "resetting env. episode 5213, reward total was -20.0. running mean: -19.211186960390545, timestamp: 2022-08-19 22:05:36.736254\n",
      "resetting env. episode 5214, reward total was -20.0. running mean: -19.21907509078664, timestamp: 2022-08-19 22:05:39.592286\n",
      "resetting env. episode 5215, reward total was -19.0. running mean: -19.216884339878774, timestamp: 2022-08-19 22:05:42.680322\n",
      "resetting env. episode 5216, reward total was -17.0. running mean: -19.194715496479986, timestamp: 2022-08-19 22:05:45.954359\n",
      "resetting env. episode 5217, reward total was -19.0. running mean: -19.192768341515187, timestamp: 2022-08-19 22:05:49.102392\n",
      "resetting env. episode 5218, reward total was -20.0. running mean: -19.200840658100034, timestamp: 2022-08-19 22:05:51.733419\n",
      "resetting env. episode 5219, reward total was -20.0. running mean: -19.208832251519034, timestamp: 2022-08-19 22:05:54.579453\n",
      "resetting env. episode 5220, reward total was -15.0. running mean: -19.166743929003843, timestamp: 2022-08-19 22:05:57.940488\n",
      "resetting env. episode 5221, reward total was -20.0. running mean: -19.175076489713803, timestamp: 2022-08-19 22:06:01.110527\n",
      "resetting env. episode 5222, reward total was -21.0. running mean: -19.193325724816667, timestamp: 2022-08-19 22:06:04.164560\n",
      "resetting env. episode 5223, reward total was -20.0. running mean: -19.2013924675685, timestamp: 2022-08-19 22:06:07.776598\n",
      "resetting env. episode 5224, reward total was -20.0. running mean: -19.209378542892814, timestamp: 2022-08-19 22:06:10.122627\n",
      "resetting env. episode 5225, reward total was -18.0. running mean: -19.197284757463887, timestamp: 2022-08-19 22:06:13.128658\n",
      "resetting env. episode 5226, reward total was -20.0. running mean: -19.205311909889247, timestamp: 2022-08-19 22:06:16.833701\n",
      "resetting env. episode 5227, reward total was -19.0. running mean: -19.203258790790354, timestamp: 2022-08-19 22:06:20.132735\n",
      "resetting env. episode 5228, reward total was -17.0. running mean: -19.181226202882453, timestamp: 2022-08-19 22:06:23.681775\n",
      "resetting env. episode 5229, reward total was -20.0. running mean: -19.189413940853626, timestamp: 2022-08-19 22:06:26.038802\n",
      "resetting env. episode 5230, reward total was -17.0. running mean: -19.167519801445092, timestamp: 2022-08-19 22:06:29.971850\n",
      "resetting env. episode 5231, reward total was -21.0. running mean: -19.185844603430642, timestamp: 2022-08-19 22:06:33.098884\n",
      "resetting env. episode 5232, reward total was -19.0. running mean: -19.183986157396337, timestamp: 2022-08-19 22:06:35.799910\n",
      "resetting env. episode 5233, reward total was -19.0. running mean: -19.182146295822374, timestamp: 2022-08-19 22:06:38.905949\n",
      "resetting env. episode 5234, reward total was -19.0. running mean: -19.18032483286415, timestamp: 2022-08-19 22:06:41.806979\n",
      "resetting env. episode 5235, reward total was -19.0. running mean: -19.17852158453551, timestamp: 2022-08-19 22:06:45.011025\n",
      "resetting env. episode 5236, reward total was -19.0. running mean: -19.176736368690154, timestamp: 2022-08-19 22:06:47.532043\n",
      "resetting env. episode 5237, reward total was -17.0. running mean: -19.154969005003252, timestamp: 2022-08-19 22:06:51.564089\n",
      "resetting env. episode 5238, reward total was -20.0. running mean: -19.16341931495322, timestamp: 2022-08-19 22:06:54.594125\n",
      "resetting env. episode 5239, reward total was -19.0. running mean: -19.16178512180369, timestamp: 2022-08-19 22:06:57.656156\n",
      "resetting env. episode 5240, reward total was -16.0. running mean: -19.130167270585652, timestamp: 2022-08-19 22:07:02.220205\n",
      "resetting env. episode 5241, reward total was -20.0. running mean: -19.138865597879793, timestamp: 2022-08-19 22:07:04.834236\n",
      "resetting env. episode 5242, reward total was -20.0. running mean: -19.147476941900994, timestamp: 2022-08-19 22:07:07.236264\n",
      "resetting env. episode 5243, reward total was -21.0. running mean: -19.166002172481985, timestamp: 2022-08-19 22:07:09.944294\n",
      "resetting env. episode 5244, reward total was -20.0. running mean: -19.174342150757163, timestamp: 2022-08-19 22:07:13.118330\n",
      "resetting env. episode 5245, reward total was -17.0. running mean: -19.152598729249593, timestamp: 2022-08-19 22:07:16.356368\n",
      "resetting env. episode 5246, reward total was -18.0. running mean: -19.141072741957096, timestamp: 2022-08-19 22:07:20.364412\n",
      "resetting env. episode 5247, reward total was -19.0. running mean: -19.139662014537524, timestamp: 2022-08-19 22:07:23.507451\n",
      "resetting env. episode 5248, reward total was -20.0. running mean: -19.148265394392148, timestamp: 2022-08-19 22:07:26.402481\n",
      "resetting env. episode 5249, reward total was -19.0. running mean: -19.146782740448227, timestamp: 2022-08-19 22:07:30.210523\n",
      "resetting env. episode 5250, reward total was -21.0. running mean: -19.165314913043744, timestamp: 2022-08-19 22:07:32.714551\n",
      "resetting env. episode 5251, reward total was -19.0. running mean: -19.163661763913307, timestamp: 2022-08-19 22:07:35.959591\n",
      "resetting env. episode 5252, reward total was -20.0. running mean: -19.172025146274173, timestamp: 2022-08-19 22:07:38.678622\n",
      "resetting env. episode 5253, reward total was -21.0. running mean: -19.190304894811433, timestamp: 2022-08-19 22:07:41.989655\n",
      "resetting env. episode 5254, reward total was -19.0. running mean: -19.18840184586332, timestamp: 2022-08-19 22:07:44.869689\n",
      "resetting env. episode 5255, reward total was -16.0. running mean: -19.156517827404688, timestamp: 2022-08-19 22:07:48.406729\n",
      "resetting env. episode 5256, reward total was -20.0. running mean: -19.16495264913064, timestamp: 2022-08-19 22:07:50.901758\n",
      "resetting env. episode 5257, reward total was -19.0. running mean: -19.163303122639334, timestamp: 2022-08-19 22:07:54.288798\n",
      "resetting env. episode 5258, reward total was -21.0. running mean: -19.18167009141294, timestamp: 2022-08-19 22:07:56.870829\n",
      "resetting env. episode 5259, reward total was -20.0. running mean: -19.18985339049881, timestamp: 2022-08-19 22:08:00.467867\n",
      "resetting env. episode 5260, reward total was -18.0. running mean: -19.17795485659382, timestamp: 2022-08-19 22:08:03.772903\n",
      "resetting env. episode 5261, reward total was -20.0. running mean: -19.18617530802788, timestamp: 2022-08-19 22:08:07.344944\n",
      "resetting env. episode 5262, reward total was -18.0. running mean: -19.174313554947602, timestamp: 2022-08-19 22:08:10.886986\n",
      "resetting env. episode 5263, reward total was -21.0. running mean: -19.192570419398127, timestamp: 2022-08-19 22:08:13.144011\n",
      "resetting env. episode 5264, reward total was -16.0. running mean: -19.160644715204146, timestamp: 2022-08-19 22:08:16.902054\n",
      "resetting env. episode 5265, reward total was -19.0. running mean: -19.159038268052107, timestamp: 2022-08-19 22:08:19.797087\n",
      "resetting env. episode 5266, reward total was -19.0. running mean: -19.15744788537159, timestamp: 2022-08-19 22:08:22.321114\n",
      "resetting env. episode 5267, reward total was -18.0. running mean: -19.14587340651787, timestamp: 2022-08-19 22:08:25.638148\n",
      "resetting env. episode 5268, reward total was -18.0. running mean: -19.134414672452692, timestamp: 2022-08-19 22:08:28.864185\n",
      "resetting env. episode 5269, reward total was -21.0. running mean: -19.153070525728165, timestamp: 2022-08-19 22:08:31.306217\n",
      "resetting env. episode 5270, reward total was -20.0. running mean: -19.161539820470882, timestamp: 2022-08-19 22:08:34.902254\n",
      "resetting env. episode 5271, reward total was -17.0. running mean: -19.139924422266173, timestamp: 2022-08-19 22:08:38.999301\n",
      "resetting env. episode 5272, reward total was -19.0. running mean: -19.138525178043512, timestamp: 2022-08-19 22:08:42.236341\n",
      "resetting env. episode 5273, reward total was -21.0. running mean: -19.157139926263078, timestamp: 2022-08-19 22:08:44.866382\n",
      "resetting env. episode 5274, reward total was -19.0. running mean: -19.155568527000447, timestamp: 2022-08-19 22:08:47.641399\n",
      "resetting env. episode 5275, reward total was -21.0. running mean: -19.174012841730445, timestamp: 2022-08-19 22:08:50.679435\n",
      "resetting env. episode 5276, reward total was -20.0. running mean: -19.18227271331314, timestamp: 2022-08-19 22:08:54.533482\n",
      "resetting env. episode 5277, reward total was -20.0. running mean: -19.190449986180006, timestamp: 2022-08-19 22:08:58.367523\n",
      "resetting env. episode 5278, reward total was -21.0. running mean: -19.208545486318208, timestamp: 2022-08-19 22:09:01.067557\n",
      "resetting env. episode 5279, reward total was -19.0. running mean: -19.206460031455027, timestamp: 2022-08-19 22:09:04.377590\n",
      "resetting env. episode 5280, reward total was -17.0. running mean: -19.184395431140477, timestamp: 2022-08-19 22:09:08.597637\n",
      "resetting env. episode 5281, reward total was -16.0. running mean: -19.15255147682907, timestamp: 2022-08-19 22:09:11.713675\n",
      "resetting env. episode 5282, reward total was -18.0. running mean: -19.14102596206078, timestamp: 2022-08-19 22:09:15.229717\n",
      "resetting env. episode 5283, reward total was -20.0. running mean: -19.149615702440173, timestamp: 2022-08-19 22:09:18.491750\n",
      "resetting env. episode 5284, reward total was -20.0. running mean: -19.15811954541577, timestamp: 2022-08-19 22:09:21.436784\n",
      "resetting env. episode 5285, reward total was -20.0. running mean: -19.16653834996161, timestamp: 2022-08-19 22:09:24.882825\n",
      "resetting env. episode 5286, reward total was -20.0. running mean: -19.174872966461994, timestamp: 2022-08-19 22:09:28.073862\n",
      "resetting env. episode 5287, reward total was -19.0. running mean: -19.173124236797374, timestamp: 2022-08-19 22:09:31.134895\n",
      "resetting env. episode 5288, reward total was -19.0. running mean: -19.1713929944294, timestamp: 2022-08-19 22:09:34.270936\n",
      "resetting env. episode 5289, reward total was -18.0. running mean: -19.159679064485104, timestamp: 2022-08-19 22:09:38.293976\n",
      "resetting env. episode 5290, reward total was -21.0. running mean: -19.178082273840253, timestamp: 2022-08-19 22:09:41.173010\n",
      "resetting env. episode 5291, reward total was -18.0. running mean: -19.16630145110185, timestamp: 2022-08-19 22:09:44.563052\n",
      "resetting env. episode 5292, reward total was -20.0. running mean: -19.174638436590833, timestamp: 2022-08-19 22:09:47.204077\n",
      "resetting env. episode 5293, reward total was -18.0. running mean: -19.162892052224922, timestamp: 2022-08-19 22:09:50.962122\n",
      "resetting env. episode 5294, reward total was -19.0. running mean: -19.161263131702675, timestamp: 2022-08-19 22:09:53.334149\n",
      "resetting env. episode 5295, reward total was -17.0. running mean: -19.13965050038565, timestamp: 2022-08-19 22:09:56.351182\n",
      "resetting env. episode 5296, reward total was -21.0. running mean: -19.15825399538179, timestamp: 2022-08-19 22:09:59.564218\n",
      "resetting env. episode 5297, reward total was -20.0. running mean: -19.166671455427974, timestamp: 2022-08-19 22:10:03.465266\n",
      "resetting env. episode 5298, reward total was -17.0. running mean: -19.145004740873695, timestamp: 2022-08-19 22:10:07.296307\n",
      "resetting env. episode 5299, reward total was -20.0. running mean: -19.153554693464958, timestamp: 2022-08-19 22:10:10.154343\n",
      "resetting env. episode 5300, reward total was -21.0. running mean: -19.17201914653031, timestamp: 2022-08-19 22:10:12.760368\n",
      "resetting env. episode 5301, reward total was -18.0. running mean: -19.160298955065006, timestamp: 2022-08-19 22:10:15.503404\n",
      "resetting env. episode 5302, reward total was -21.0. running mean: -19.178695965514358, timestamp: 2022-08-19 22:10:18.450439\n",
      "resetting env. episode 5303, reward total was -18.0. running mean: -19.166909005859214, timestamp: 2022-08-19 22:10:22.328479\n",
      "resetting env. episode 5304, reward total was -19.0. running mean: -19.165239915800623, timestamp: 2022-08-19 22:10:25.083511\n",
      "resetting env. episode 5305, reward total was -20.0. running mean: -19.173587516642616, timestamp: 2022-08-19 22:10:27.773540\n",
      "resetting env. episode 5306, reward total was -21.0. running mean: -19.19185164147619, timestamp: 2022-08-19 22:10:30.681574\n",
      "resetting env. episode 5307, reward total was -20.0. running mean: -19.199933125061428, timestamp: 2022-08-19 22:10:33.763609\n",
      "resetting env. episode 5308, reward total was -17.0. running mean: -19.177933793810816, timestamp: 2022-08-19 22:10:37.684653\n",
      "resetting env. episode 5309, reward total was -20.0. running mean: -19.186154455872707, timestamp: 2022-08-19 22:10:39.692678\n",
      "resetting env. episode 5310, reward total was -21.0. running mean: -19.20429291131398, timestamp: 2022-08-19 22:10:42.896712\n",
      "resetting env. episode 5311, reward total was -15.0. running mean: -19.16224998220084, timestamp: 2022-08-19 22:10:47.026760\n",
      "resetting env. episode 5312, reward total was -17.0. running mean: -19.140627482378832, timestamp: 2022-08-19 22:10:50.673801\n",
      "resetting env. episode 5313, reward total was -20.0. running mean: -19.149221207555044, timestamp: 2022-08-19 22:10:53.258831\n",
      "resetting env. episode 5314, reward total was -16.0. running mean: -19.117728995479492, timestamp: 2022-08-19 22:10:57.072875\n",
      "resetting env. episode 5315, reward total was -19.0. running mean: -19.1165517055247, timestamp: 2022-08-19 22:11:00.254914\n",
      "resetting env. episode 5316, reward total was -20.0. running mean: -19.125386188469452, timestamp: 2022-08-19 22:11:02.495938\n",
      "resetting env. episode 5317, reward total was -18.0. running mean: -19.11413232658476, timestamp: 2022-08-19 22:11:05.293970\n",
      "resetting env. episode 5318, reward total was -19.0. running mean: -19.112991003318914, timestamp: 2022-08-19 22:11:08.888012\n",
      "resetting env. episode 5319, reward total was -15.0. running mean: -19.071861093285722, timestamp: 2022-08-19 22:11:12.433050\n",
      "resetting env. episode 5320, reward total was -18.0. running mean: -19.061142482352864, timestamp: 2022-08-19 22:11:15.483086\n",
      "resetting env. episode 5321, reward total was -16.0. running mean: -19.030531057529334, timestamp: 2022-08-19 22:11:19.156129\n",
      "resetting env. episode 5322, reward total was -20.0. running mean: -19.04022574695404, timestamp: 2022-08-19 22:11:21.969160\n",
      "resetting env. episode 5323, reward total was -17.0. running mean: -19.0198234894845, timestamp: 2022-08-19 22:11:25.125198\n",
      "resetting env. episode 5324, reward total was -21.0. running mean: -19.03962525458966, timestamp: 2022-08-19 22:11:28.808764\n",
      "resetting env. episode 5325, reward total was -19.0. running mean: -19.039229002043765, timestamp: 2022-08-19 22:11:32.364802\n",
      "resetting env. episode 5326, reward total was -21.0. running mean: -19.05883671202333, timestamp: 2022-08-19 22:11:35.015833\n",
      "resetting env. episode 5327, reward total was -20.0. running mean: -19.068248344903093, timestamp: 2022-08-19 22:11:38.392870\n",
      "resetting env. episode 5328, reward total was -21.0. running mean: -19.087565861454063, timestamp: 2022-08-19 22:11:41.851911\n",
      "resetting env. episode 5329, reward total was -20.0. running mean: -19.096690202839522, timestamp: 2022-08-19 22:11:45.353950\n",
      "resetting env. episode 5330, reward total was -19.0. running mean: -19.095723300811127, timestamp: 2022-08-19 22:11:48.222981\n",
      "resetting env. episode 5331, reward total was -17.0. running mean: -19.07476606780302, timestamp: 2022-08-19 22:11:51.830024\n",
      "resetting env. episode 5332, reward total was -20.0. running mean: -19.084018407124987, timestamp: 2022-08-19 22:11:55.302065\n",
      "resetting env. episode 5333, reward total was -19.0. running mean: -19.08317822305374, timestamp: 2022-08-19 22:11:58.784106\n",
      "resetting env. episode 5334, reward total was -18.0. running mean: -19.0723464408232, timestamp: 2022-08-19 22:12:01.924142\n",
      "resetting env. episode 5335, reward total was -20.0. running mean: -19.081622976414966, timestamp: 2022-08-19 22:12:04.661173\n",
      "resetting env. episode 5336, reward total was -21.0. running mean: -19.100806746650818, timestamp: 2022-08-19 22:12:07.843209\n",
      "resetting env. episode 5337, reward total was -18.0. running mean: -19.08979867918431, timestamp: 2022-08-19 22:12:11.046245\n",
      "resetting env. episode 5338, reward total was -20.0. running mean: -19.098900692392466, timestamp: 2022-08-19 22:12:15.260290\n",
      "resetting env. episode 5339, reward total was -19.0. running mean: -19.097911685468542, timestamp: 2022-08-19 22:12:18.685333\n",
      "resetting env. episode 5340, reward total was -17.0. running mean: -19.07693256861386, timestamp: 2022-08-19 22:12:21.865366\n",
      "resetting env. episode 5341, reward total was -21.0. running mean: -19.096163242927723, timestamp: 2022-08-19 22:12:25.327405\n",
      "resetting env. episode 5342, reward total was -19.0. running mean: -19.095201610498446, timestamp: 2022-08-19 22:12:28.267438\n",
      "resetting env. episode 5343, reward total was -20.0. running mean: -19.104249594393462, timestamp: 2022-08-19 22:12:30.722469\n",
      "resetting env. episode 5344, reward total was -15.0. running mean: -19.063207098449524, timestamp: 2022-08-19 22:12:34.448509\n",
      "resetting env. episode 5345, reward total was -17.0. running mean: -19.04257502746503, timestamp: 2022-08-19 22:12:38.116553\n",
      "resetting env. episode 5346, reward total was -17.0. running mean: -19.022149277190383, timestamp: 2022-08-19 22:12:42.201596\n",
      "resetting env. episode 5347, reward total was -18.0. running mean: -19.01192778441848, timestamp: 2022-08-19 22:12:44.435625\n",
      "resetting env. episode 5348, reward total was -17.0. running mean: -18.991808506574294, timestamp: 2022-08-19 22:12:47.935666\n",
      "resetting env. episode 5349, reward total was -21.0. running mean: -19.011890421508554, timestamp: 2022-08-19 22:12:50.989699\n",
      "resetting env. episode 5350, reward total was -21.0. running mean: -19.031771517293468, timestamp: 2022-08-19 22:12:54.548739\n",
      "resetting env. episode 5351, reward total was -18.0. running mean: -19.021453802120533, timestamp: 2022-08-19 22:12:57.774775\n",
      "resetting env. episode 5352, reward total was -21.0. running mean: -19.041239264099328, timestamp: 2022-08-19 22:13:01.006811\n",
      "resetting env. episode 5353, reward total was -19.0. running mean: -19.040826871458336, timestamp: 2022-08-19 22:13:04.051848\n",
      "resetting env. episode 5354, reward total was -20.0. running mean: -19.05041860274375, timestamp: 2022-08-19 22:13:06.782877\n",
      "resetting env. episode 5355, reward total was -18.0. running mean: -19.039914416716314, timestamp: 2022-08-19 22:13:09.739911\n",
      "resetting env. episode 5356, reward total was -20.0. running mean: -19.04951527254915, timestamp: 2022-08-19 22:13:12.879947\n",
      "resetting env. episode 5357, reward total was -21.0. running mean: -19.06902011982366, timestamp: 2022-08-19 22:13:15.722980\n",
      "resetting env. episode 5358, reward total was -21.0. running mean: -19.088329918625423, timestamp: 2022-08-19 22:13:18.255010\n",
      "resetting env. episode 5359, reward total was -20.0. running mean: -19.097446619439168, timestamp: 2022-08-19 22:13:21.586047\n",
      "resetting env. episode 5360, reward total was -20.0. running mean: -19.106472153244777, timestamp: 2022-08-19 22:13:25.031085\n",
      "resetting env. episode 5361, reward total was -18.0. running mean: -19.095407431712328, timestamp: 2022-08-19 22:13:28.560126\n",
      "resetting env. episode 5362, reward total was -20.0. running mean: -19.104453357395204, timestamp: 2022-08-19 22:13:31.736165\n",
      "resetting env. episode 5363, reward total was -17.0. running mean: -19.083408823821255, timestamp: 2022-08-19 22:13:34.948199\n",
      "resetting env. episode 5364, reward total was -18.0. running mean: -19.072574735583043, timestamp: 2022-08-19 22:13:38.369247\n",
      "resetting env. episode 5365, reward total was -21.0. running mean: -19.091848988227213, timestamp: 2022-08-19 22:13:41.977283\n",
      "resetting env. episode 5366, reward total was -19.0. running mean: -19.090930498344942, timestamp: 2022-08-19 22:13:45.481322\n",
      "resetting env. episode 5367, reward total was -19.0. running mean: -19.090021193361494, timestamp: 2022-08-19 22:13:48.952361\n",
      "resetting env. episode 5368, reward total was -18.0. running mean: -19.079120981427877, timestamp: 2022-08-19 22:13:52.734401\n",
      "resetting env. episode 5369, reward total was -19.0. running mean: -19.0783297716136, timestamp: 2022-08-19 22:13:56.387445\n",
      "resetting env. episode 5370, reward total was -15.0. running mean: -19.03754647389746, timestamp: 2022-08-19 22:13:59.934482\n",
      "resetting env. episode 5371, reward total was -20.0. running mean: -19.047171009158486, timestamp: 2022-08-19 22:14:02.985519\n",
      "resetting env. episode 5372, reward total was -17.0. running mean: -19.0266992990669, timestamp: 2022-08-19 22:14:06.078555\n",
      "resetting env. episode 5373, reward total was -19.0. running mean: -19.026432306076234, timestamp: 2022-08-19 22:14:09.559592\n",
      "resetting env. episode 5374, reward total was -20.0. running mean: -19.03616798301547, timestamp: 2022-08-19 22:14:13.220636\n",
      "resetting env. episode 5375, reward total was -18.0. running mean: -19.025806303185316, timestamp: 2022-08-19 22:14:16.311668\n",
      "resetting env. episode 5376, reward total was -20.0. running mean: -19.035548240153464, timestamp: 2022-08-19 22:14:19.375705\n",
      "resetting env. episode 5377, reward total was -21.0. running mean: -19.05519275775193, timestamp: 2022-08-19 22:14:22.603742\n",
      "resetting env. episode 5378, reward total was -16.0. running mean: -19.02464083017441, timestamp: 2022-08-19 22:14:26.472787\n",
      "resetting env. episode 5379, reward total was -20.0. running mean: -19.034394421872666, timestamp: 2022-08-19 22:14:29.618827\n",
      "resetting env. episode 5380, reward total was -21.0. running mean: -19.054050477653938, timestamp: 2022-08-19 22:14:32.463854\n",
      "resetting env. episode 5381, reward total was -15.0. running mean: -19.013509972877397, timestamp: 2022-08-19 22:14:36.412899\n",
      "resetting env. episode 5382, reward total was -21.0. running mean: -19.033374873148624, timestamp: 2022-08-19 22:14:39.734942\n",
      "resetting env. episode 5383, reward total was -20.0. running mean: -19.043041124417137, timestamp: 2022-08-19 22:14:42.497967\n",
      "resetting env. episode 5384, reward total was -14.0. running mean: -18.992610713172965, timestamp: 2022-08-19 22:14:47.066020\n",
      "resetting env. episode 5385, reward total was -21.0. running mean: -19.012684606041237, timestamp: 2022-08-19 22:14:49.685049\n",
      "resetting env. episode 5386, reward total was -21.0. running mean: -19.032557759980826, timestamp: 2022-08-19 22:14:52.659084\n",
      "resetting env. episode 5387, reward total was -20.0. running mean: -19.042232182381017, timestamp: 2022-08-19 22:14:55.984122\n",
      "resetting env. episode 5388, reward total was -20.0. running mean: -19.051809860557206, timestamp: 2022-08-19 22:14:59.381160\n",
      "resetting env. episode 5389, reward total was -20.0. running mean: -19.061291761951633, timestamp: 2022-08-19 22:15:02.058199\n",
      "resetting env. episode 5390, reward total was -21.0. running mean: -19.080678844332116, timestamp: 2022-08-19 22:15:04.612220\n",
      "resetting env. episode 5391, reward total was -18.0. running mean: -19.069872055888794, timestamp: 2022-08-19 22:15:07.341252\n",
      "resetting env. episode 5392, reward total was -15.0. running mean: -19.029173335329904, timestamp: 2022-08-19 22:15:10.933292\n",
      "resetting env. episode 5393, reward total was -21.0. running mean: -19.048881601976607, timestamp: 2022-08-19 22:15:13.886323\n",
      "resetting env. episode 5394, reward total was -19.0. running mean: -19.048392785956842, timestamp: 2022-08-19 22:15:17.206358\n",
      "resetting env. episode 5395, reward total was -21.0. running mean: -19.067908858097276, timestamp: 2022-08-19 22:15:19.920392\n",
      "resetting env. episode 5396, reward total was -20.0. running mean: -19.077229769516304, timestamp: 2022-08-19 22:15:22.526419\n",
      "resetting env. episode 5397, reward total was -21.0. running mean: -19.096457471821143, timestamp: 2022-08-19 22:15:25.192453\n",
      "resetting env. episode 5398, reward total was -20.0. running mean: -19.10549289710293, timestamp: 2022-08-19 22:15:28.375488\n",
      "resetting env. episode 5399, reward total was -21.0. running mean: -19.1244379681319, timestamp: 2022-08-19 22:15:31.314520\n",
      "resetting env. episode 5400, reward total was -21.0. running mean: -19.143193588450583, timestamp: 2022-08-19 22:15:33.809548\n",
      "resetting env. episode 5401, reward total was -18.0. running mean: -19.131761652566077, timestamp: 2022-08-19 22:15:36.804584\n",
      "resetting env. episode 5402, reward total was -19.0. running mean: -19.130444036040416, timestamp: 2022-08-19 22:15:39.923617\n",
      "resetting env. episode 5403, reward total was -18.0. running mean: -19.11913959568001, timestamp: 2022-08-19 22:15:43.792664\n",
      "resetting env. episode 5404, reward total was -20.0. running mean: -19.12794819972321, timestamp: 2022-08-19 22:15:47.394701\n",
      "resetting env. episode 5405, reward total was -21.0. running mean: -19.14666871772598, timestamp: 2022-08-19 22:15:50.396734\n",
      "resetting env. episode 5406, reward total was -19.0. running mean: -19.14520203054872, timestamp: 2022-08-19 22:15:53.550771\n",
      "resetting env. episode 5407, reward total was -17.0. running mean: -19.123750010243235, timestamp: 2022-08-19 22:15:57.002810\n",
      "resetting env. episode 5408, reward total was -17.0. running mean: -19.102512510140805, timestamp: 2022-08-19 22:16:00.337847\n",
      "resetting env. episode 5409, reward total was -21.0. running mean: -19.121487385039398, timestamp: 2022-08-19 22:16:03.562886\n",
      "resetting env. episode 5410, reward total was -17.0. running mean: -19.100272511189004, timestamp: 2022-08-19 22:16:06.494916\n",
      "resetting env. episode 5411, reward total was -20.0. running mean: -19.109269786077114, timestamp: 2022-08-19 22:16:09.304948\n",
      "resetting env. episode 5412, reward total was -18.0. running mean: -19.098177088216342, timestamp: 2022-08-19 22:16:13.103994\n",
      "resetting env. episode 5413, reward total was -21.0. running mean: -19.11719531733418, timestamp: 2022-08-19 22:16:15.953024\n",
      "resetting env. episode 5414, reward total was -16.0. running mean: -19.086023364160837, timestamp: 2022-08-19 22:16:20.842081\n",
      "resetting env. episode 5415, reward total was -20.0. running mean: -19.09516313051923, timestamp: 2022-08-19 22:16:24.018120\n",
      "resetting env. episode 5416, reward total was -17.0. running mean: -19.074211499214037, timestamp: 2022-08-19 22:16:27.733159\n",
      "resetting env. episode 5417, reward total was -17.0. running mean: -19.0534693842219, timestamp: 2022-08-19 22:16:31.746203\n",
      "resetting env. episode 5418, reward total was -19.0. running mean: -19.05293469037968, timestamp: 2022-08-19 22:16:34.848237\n",
      "resetting env. episode 5419, reward total was -20.0. running mean: -19.06240534347588, timestamp: 2022-08-19 22:16:37.989274\n",
      "resetting env. episode 5420, reward total was -20.0. running mean: -19.07178129004112, timestamp: 2022-08-19 22:16:40.919308\n",
      "resetting env. episode 5421, reward total was -19.0. running mean: -19.071063477140708, timestamp: 2022-08-19 22:16:44.245346\n",
      "resetting env. episode 5422, reward total was -18.0. running mean: -19.0603528423693, timestamp: 2022-08-19 22:16:47.436380\n",
      "resetting env. episode 5423, reward total was -18.0. running mean: -19.049749313945608, timestamp: 2022-08-19 22:16:50.840422\n",
      "resetting env. episode 5424, reward total was -20.0. running mean: -19.05925182080615, timestamp: 2022-08-19 22:16:54.067457\n",
      "resetting env. episode 5425, reward total was -18.0. running mean: -19.04865930259809, timestamp: 2022-08-19 22:16:57.580493\n",
      "resetting env. episode 5426, reward total was -20.0. running mean: -19.05817270957211, timestamp: 2022-08-19 22:17:00.429527\n",
      "resetting env. episode 5427, reward total was -17.0. running mean: -19.037590982476388, timestamp: 2022-08-19 22:17:03.503563\n",
      "resetting env. episode 5428, reward total was -21.0. running mean: -19.057215072651626, timestamp: 2022-08-19 22:17:06.034594\n",
      "resetting env. episode 5429, reward total was -18.0. running mean: -19.04664292192511, timestamp: 2022-08-19 22:17:09.633634\n",
      "resetting env. episode 5430, reward total was -19.0. running mean: -19.046176492705857, timestamp: 2022-08-19 22:17:13.085672\n",
      "resetting env. episode 5431, reward total was -21.0. running mean: -19.0657147277788, timestamp: 2022-08-19 22:17:15.938707\n",
      "resetting env. episode 5432, reward total was -15.0. running mean: -19.02505758050101, timestamp: 2022-08-19 22:17:19.818745\n",
      "resetting env. episode 5433, reward total was -19.0. running mean: -19.024807004696, timestamp: 2022-08-19 22:17:22.233775\n",
      "resetting env. episode 5434, reward total was -19.0. running mean: -19.024558934649043, timestamp: 2022-08-19 22:17:25.865812\n",
      "resetting env. episode 5435, reward total was -20.0. running mean: -19.034313345302554, timestamp: 2022-08-19 22:17:29.374852\n",
      "resetting env. episode 5436, reward total was -19.0. running mean: -19.033970211849528, timestamp: 2022-08-19 22:17:33.248896\n",
      "resetting env. episode 5437, reward total was -19.0. running mean: -19.033630509731033, timestamp: 2022-08-19 22:17:36.227936\n",
      "resetting env. episode 5438, reward total was -18.0. running mean: -19.02329420463372, timestamp: 2022-08-19 22:17:39.984970\n",
      "resetting env. episode 5439, reward total was -17.0. running mean: -19.003061262587387, timestamp: 2022-08-19 22:17:44.234019\n",
      "resetting env. episode 5440, reward total was -21.0. running mean: -19.023030649961512, timestamp: 2022-08-19 22:17:47.310052\n",
      "resetting env. episode 5441, reward total was -20.0. running mean: -19.032800343461897, timestamp: 2022-08-19 22:17:50.455089\n",
      "resetting env. episode 5442, reward total was -20.0. running mean: -19.042472340027278, timestamp: 2022-08-19 22:17:54.186131\n",
      "resetting env. episode 5443, reward total was -20.0. running mean: -19.052047616627004, timestamp: 2022-08-19 22:17:57.873170\n",
      "resetting env. episode 5444, reward total was -20.0. running mean: -19.061527140460733, timestamp: 2022-08-19 22:18:01.560211\n",
      "resetting env. episode 5445, reward total was -19.0. running mean: -19.060911869056127, timestamp: 2022-08-19 22:18:04.415247\n",
      "resetting env. episode 5446, reward total was -19.0. running mean: -19.06030275036557, timestamp: 2022-08-19 22:18:07.902283\n",
      "resetting env. episode 5447, reward total was -18.0. running mean: -19.049699722861913, timestamp: 2022-08-19 22:18:11.109318\n",
      "resetting env. episode 5448, reward total was -20.0. running mean: -19.05920272563329, timestamp: 2022-08-19 22:18:14.236361\n",
      "resetting env. episode 5449, reward total was -21.0. running mean: -19.07861069837696, timestamp: 2022-08-19 22:18:17.826398\n",
      "resetting env. episode 5450, reward total was -21.0. running mean: -19.09782459139319, timestamp: 2022-08-19 22:18:21.534438\n",
      "resetting env. episode 5451, reward total was -19.0. running mean: -19.09684634547926, timestamp: 2022-08-19 22:18:25.532483\n",
      "resetting env. episode 5452, reward total was -19.0. running mean: -19.095877882024467, timestamp: 2022-08-19 22:18:29.118521\n",
      "resetting env. episode 5453, reward total was -17.0. running mean: -19.074919103204223, timestamp: 2022-08-19 22:18:33.317570\n",
      "resetting env. episode 5454, reward total was -19.0. running mean: -19.07416991217218, timestamp: 2022-08-19 22:18:36.742608\n",
      "resetting env. episode 5455, reward total was -20.0. running mean: -19.083428213050457, timestamp: 2022-08-19 22:18:39.534638\n",
      "resetting env. episode 5456, reward total was -17.0. running mean: -19.062593930919952, timestamp: 2022-08-19 22:18:43.009675\n",
      "resetting env. episode 5457, reward total was -20.0. running mean: -19.07196799161075, timestamp: 2022-08-19 22:18:46.396717\n",
      "resetting env. episode 5458, reward total was -20.0. running mean: -19.081248311694644, timestamp: 2022-08-19 22:18:49.315747\n",
      "resetting env. episode 5459, reward total was -17.0. running mean: -19.0604358285777, timestamp: 2022-08-19 22:18:53.370792\n",
      "resetting env. episode 5460, reward total was -17.0. running mean: -19.039831470291922, timestamp: 2022-08-19 22:18:56.861831\n",
      "resetting env. episode 5461, reward total was -16.0. running mean: -19.009433155589004, timestamp: 2022-08-19 22:19:00.648879\n",
      "resetting env. episode 5462, reward total was -19.0. running mean: -19.009338824033115, timestamp: 2022-08-19 22:19:04.644923\n",
      "resetting env. episode 5463, reward total was -20.0. running mean: -19.019245435792783, timestamp: 2022-08-19 22:19:08.124959\n",
      "resetting env. episode 5464, reward total was -19.0. running mean: -19.019052981434857, timestamp: 2022-08-19 22:19:11.763998\n",
      "resetting env. episode 5465, reward total was -19.0. running mean: -19.01886245162051, timestamp: 2022-08-19 22:19:15.978046\n",
      "resetting env. episode 5466, reward total was -20.0. running mean: -19.028673827104303, timestamp: 2022-08-19 22:19:18.720077\n",
      "resetting env. episode 5467, reward total was -18.0. running mean: -19.018387088833258, timestamp: 2022-08-19 22:19:22.254116\n",
      "resetting env. episode 5468, reward total was -19.0. running mean: -19.018203217944926, timestamp: 2022-08-19 22:19:25.888158\n",
      "resetting env. episode 5469, reward total was -19.0. running mean: -19.018021185765477, timestamp: 2022-08-19 22:19:29.223194\n",
      "resetting env. episode 5470, reward total was -21.0. running mean: -19.037840973907823, timestamp: 2022-08-19 22:19:32.808233\n",
      "resetting env. episode 5471, reward total was -19.0. running mean: -19.037462564168745, timestamp: 2022-08-19 22:19:36.778278\n",
      "resetting env. episode 5472, reward total was -17.0. running mean: -19.01708793852706, timestamp: 2022-08-19 22:19:40.465318\n",
      "resetting env. episode 5473, reward total was -16.0. running mean: -18.98691705914179, timestamp: 2022-08-19 22:19:44.431362\n",
      "resetting env. episode 5474, reward total was -17.0. running mean: -18.967047888550372, timestamp: 2022-08-19 22:19:48.944414\n",
      "resetting env. episode 5475, reward total was -19.0. running mean: -18.96737740966487, timestamp: 2022-08-19 22:19:52.752458\n",
      "resetting env. episode 5476, reward total was -20.0. running mean: -18.977703635568222, timestamp: 2022-08-19 22:19:55.693487\n",
      "resetting env. episode 5477, reward total was -20.0. running mean: -18.98792659921254, timestamp: 2022-08-19 22:19:59.049526\n",
      "resetting env. episode 5478, reward total was -19.0. running mean: -18.988047333220415, timestamp: 2022-08-19 22:20:02.331560\n",
      "resetting env. episode 5479, reward total was -21.0. running mean: -19.00816685988821, timestamp: 2022-08-19 22:20:05.334594\n",
      "resetting env. episode 5480, reward total was -19.0. running mean: -19.00808519128933, timestamp: 2022-08-19 22:20:08.109623\n",
      "resetting env. episode 5481, reward total was -20.0. running mean: -19.018004339376436, timestamp: 2022-08-19 22:20:11.410662\n",
      "resetting env. episode 5482, reward total was -19.0. running mean: -19.017824295982674, timestamp: 2022-08-19 22:20:15.065703\n",
      "resetting env. episode 5483, reward total was -17.0. running mean: -18.997646053022848, timestamp: 2022-08-19 22:20:18.515744\n",
      "resetting env. episode 5484, reward total was -15.0. running mean: -18.957669592492618, timestamp: 2022-08-19 22:20:22.058783\n",
      "resetting env. episode 5485, reward total was -19.0. running mean: -18.958092896567692, timestamp: 2022-08-19 22:20:24.859809\n",
      "resetting env. episode 5486, reward total was -20.0. running mean: -18.968511967602016, timestamp: 2022-08-19 22:20:28.775853\n",
      "resetting env. episode 5487, reward total was -20.0. running mean: -18.978826847925994, timestamp: 2022-08-19 22:20:32.055893\n",
      "resetting env. episode 5488, reward total was -17.0. running mean: -18.959038579446737, timestamp: 2022-08-19 22:20:35.168925\n",
      "resetting env. episode 5489, reward total was -18.0. running mean: -18.94944819365227, timestamp: 2022-08-19 22:20:38.323960\n",
      "resetting env. episode 5490, reward total was -19.0. running mean: -18.949953711715747, timestamp: 2022-08-19 22:20:41.875998\n",
      "resetting env. episode 5491, reward total was -20.0. running mean: -18.96045417459859, timestamp: 2022-08-19 22:20:45.529040\n",
      "resetting env. episode 5492, reward total was -19.0. running mean: -18.960849632852604, timestamp: 2022-08-19 22:20:48.976078\n",
      "resetting env. episode 5493, reward total was -20.0. running mean: -18.97124113652408, timestamp: 2022-08-19 22:20:51.972111\n",
      "resetting env. episode 5494, reward total was -19.0. running mean: -18.971528725158837, timestamp: 2022-08-19 22:20:55.497151\n",
      "resetting env. episode 5495, reward total was -19.0. running mean: -18.97181343790725, timestamp: 2022-08-19 22:20:58.989192\n",
      "resetting env. episode 5496, reward total was -21.0. running mean: -18.992095303528178, timestamp: 2022-08-19 22:21:02.412232\n",
      "resetting env. episode 5497, reward total was -14.0. running mean: -18.942174350492895, timestamp: 2022-08-19 22:21:06.071268\n",
      "resetting env. episode 5498, reward total was -21.0. running mean: -18.962752606987966, timestamp: 2022-08-19 22:21:08.852297\n",
      "resetting env. episode 5499, reward total was -19.0. running mean: -18.963125080918086, timestamp: 2022-08-19 22:21:12.568343\n",
      "resetting env. episode 5500, reward total was -18.0. running mean: -18.953493830108904, timestamp: 2022-08-19 22:21:15.574373\n",
      "resetting env. episode 5501, reward total was -19.0. running mean: -18.953958891807815, timestamp: 2022-08-19 22:21:19.331416\n",
      "resetting env. episode 5502, reward total was -15.0. running mean: -18.914419302889737, timestamp: 2022-08-19 22:21:22.371452\n",
      "resetting env. episode 5503, reward total was -17.0. running mean: -18.89527510986084, timestamp: 2022-08-19 22:21:26.058489\n",
      "resetting env. episode 5504, reward total was -20.0. running mean: -18.90632235876223, timestamp: 2022-08-19 22:21:28.672522\n",
      "resetting env. episode 5505, reward total was -19.0. running mean: -18.90725913517461, timestamp: 2022-08-19 22:21:31.612551\n",
      "resetting env. episode 5506, reward total was -17.0. running mean: -18.888186543822865, timestamp: 2022-08-19 22:21:34.611583\n",
      "resetting env. episode 5507, reward total was -18.0. running mean: -18.879304678384635, timestamp: 2022-08-19 22:21:38.662628\n",
      "resetting env. episode 5508, reward total was -20.0. running mean: -18.890511631600788, timestamp: 2022-08-19 22:21:41.616659\n",
      "resetting env. episode 5509, reward total was -19.0. running mean: -18.89160651528478, timestamp: 2022-08-19 22:21:44.600693\n",
      "resetting env. episode 5510, reward total was -20.0. running mean: -18.90269045013193, timestamp: 2022-08-19 22:21:47.893729\n",
      "resetting env. episode 5511, reward total was -19.0. running mean: -18.903663545630614, timestamp: 2022-08-19 22:21:51.233769\n",
      "resetting env. episode 5512, reward total was -18.0. running mean: -18.894626910174306, timestamp: 2022-08-19 22:21:54.552802\n",
      "resetting env. episode 5513, reward total was -20.0. running mean: -18.90568064107256, timestamp: 2022-08-19 22:21:57.697837\n",
      "resetting env. episode 5514, reward total was -21.0. running mean: -18.926623834661836, timestamp: 2022-08-19 22:22:00.669872\n",
      "resetting env. episode 5515, reward total was -21.0. running mean: -18.947357596315218, timestamp: 2022-08-19 22:22:03.792904\n",
      "resetting env. episode 5516, reward total was -21.0. running mean: -18.967884020352066, timestamp: 2022-08-19 22:22:07.693951\n",
      "resetting env. episode 5517, reward total was -20.0. running mean: -18.978205180148546, timestamp: 2022-08-19 22:22:10.424979\n",
      "resetting env. episode 5518, reward total was -21.0. running mean: -18.99842312834706, timestamp: 2022-08-19 22:22:13.550015\n",
      "resetting env. episode 5519, reward total was -17.0. running mean: -18.97843889706359, timestamp: 2022-08-19 22:22:17.026053\n",
      "resetting env. episode 5520, reward total was -19.0. running mean: -18.978654508092955, timestamp: 2022-08-19 22:22:20.784090\n",
      "resetting env. episode 5521, reward total was -20.0. running mean: -18.988867963012023, timestamp: 2022-08-19 22:22:23.817128\n",
      "resetting env. episode 5522, reward total was -19.0. running mean: -18.988979283381905, timestamp: 2022-08-19 22:22:27.302166\n",
      "resetting env. episode 5523, reward total was -18.0. running mean: -18.979089490548084, timestamp: 2022-08-19 22:22:31.376209\n",
      "resetting env. episode 5524, reward total was -20.0. running mean: -18.9892985956426, timestamp: 2022-08-19 22:22:34.415247\n",
      "resetting env. episode 5525, reward total was -21.0. running mean: -19.009405609686176, timestamp: 2022-08-19 22:22:37.466276\n",
      "resetting env. episode 5526, reward total was -18.0. running mean: -18.999311553589315, timestamp: 2022-08-19 22:22:40.875316\n",
      "resetting env. episode 5527, reward total was -20.0. running mean: -19.00931843805342, timestamp: 2022-08-19 22:22:43.460345\n",
      "resetting env. episode 5528, reward total was -19.0. running mean: -19.009225253672888, timestamp: 2022-08-19 22:22:46.033372\n",
      "resetting env. episode 5529, reward total was -19.0. running mean: -19.00913300113616, timestamp: 2022-08-19 22:22:49.013406\n",
      "resetting env. episode 5530, reward total was -19.0. running mean: -19.0090416711248, timestamp: 2022-08-19 22:22:53.317451\n",
      "resetting env. episode 5531, reward total was -19.0. running mean: -19.008951254413553, timestamp: 2022-08-19 22:22:55.895482\n",
      "resetting env. episode 5532, reward total was -19.0. running mean: -19.008861741869417, timestamp: 2022-08-19 22:22:59.273519\n",
      "resetting env. episode 5533, reward total was -20.0. running mean: -19.01877312445072, timestamp: 2022-08-19 22:23:02.719559\n",
      "resetting env. episode 5534, reward total was -18.0. running mean: -19.008585393206214, timestamp: 2022-08-19 22:23:06.011597\n",
      "resetting env. episode 5535, reward total was -18.0. running mean: -18.998499539274153, timestamp: 2022-08-19 22:23:09.251629\n",
      "resetting env. episode 5536, reward total was -18.0. running mean: -18.98851454388141, timestamp: 2022-08-19 22:23:12.813669\n",
      "resetting env. episode 5537, reward total was -19.0. running mean: -18.988629398442598, timestamp: 2022-08-19 22:23:15.803702\n",
      "resetting env. episode 5538, reward total was -13.0. running mean: -18.92874310445817, timestamp: 2022-08-19 22:23:19.817747\n",
      "resetting env. episode 5539, reward total was -20.0. running mean: -18.939455673413587, timestamp: 2022-08-19 22:23:22.732782\n",
      "resetting env. episode 5540, reward total was -19.0. running mean: -18.940061116679452, timestamp: 2022-08-19 22:23:26.057815\n",
      "resetting env. episode 5541, reward total was -21.0. running mean: -18.960660505512656, timestamp: 2022-08-19 22:23:28.911848\n",
      "resetting env. episode 5542, reward total was -19.0. running mean: -18.961053900457532, timestamp: 2022-08-19 22:23:32.659891\n",
      "resetting env. episode 5543, reward total was -20.0. running mean: -18.971443361452955, timestamp: 2022-08-19 22:23:35.523924\n",
      "resetting env. episode 5544, reward total was -17.0. running mean: -18.951728927838428, timestamp: 2022-08-19 22:23:40.105973\n",
      "resetting env. episode 5545, reward total was -17.0. running mean: -18.932211638560045, timestamp: 2022-08-19 22:23:43.561011\n",
      "resetting env. episode 5546, reward total was -18.0. running mean: -18.922889522174444, timestamp: 2022-08-19 22:23:47.371055\n",
      "resetting env. episode 5547, reward total was -19.0. running mean: -18.9236606269527, timestamp: 2022-08-19 22:23:50.157085\n",
      "resetting env. episode 5548, reward total was -19.0. running mean: -18.924424020683173, timestamp: 2022-08-19 22:23:53.095131\n",
      "resetting env. episode 5549, reward total was -15.0. running mean: -18.88517978047634, timestamp: 2022-08-19 22:23:57.004163\n",
      "resetting env. episode 5550, reward total was -21.0. running mean: -18.906327982671577, timestamp: 2022-08-19 22:24:00.549201\n",
      "resetting env. episode 5551, reward total was -21.0. running mean: -18.927264702844862, timestamp: 2022-08-19 22:24:03.602237\n",
      "resetting env. episode 5552, reward total was -16.0. running mean: -18.897992055816413, timestamp: 2022-08-19 22:24:07.139278\n",
      "resetting env. episode 5553, reward total was -21.0. running mean: -18.91901213525825, timestamp: 2022-08-19 22:24:09.660316\n",
      "resetting env. episode 5554, reward total was -18.0. running mean: -18.909822013905668, timestamp: 2022-08-19 22:24:13.922353\n",
      "resetting env. episode 5555, reward total was -19.0. running mean: -18.91072379376661, timestamp: 2022-08-19 22:24:17.335391\n",
      "resetting env. episode 5556, reward total was -13.0. running mean: -18.851616555828944, timestamp: 2022-08-19 22:24:21.545439\n",
      "resetting env. episode 5557, reward total was -20.0. running mean: -18.863100390270652, timestamp: 2022-08-19 22:24:24.569475\n",
      "resetting env. episode 5558, reward total was -21.0. running mean: -18.884469386367947, timestamp: 2022-08-19 22:24:27.487506\n",
      "resetting env. episode 5559, reward total was -21.0. running mean: -18.90562469250427, timestamp: 2022-08-19 22:24:30.288543\n",
      "resetting env. episode 5560, reward total was -20.0. running mean: -18.916568445579227, timestamp: 2022-08-19 22:24:33.235570\n",
      "resetting env. episode 5561, reward total was -19.0. running mean: -18.917402761123437, timestamp: 2022-08-19 22:24:36.743611\n",
      "resetting env. episode 5562, reward total was -17.0. running mean: -18.898228733512205, timestamp: 2022-08-19 22:24:39.934652\n",
      "resetting env. episode 5563, reward total was -21.0. running mean: -18.919246446177084, timestamp: 2022-08-19 22:24:42.717681\n",
      "resetting env. episode 5564, reward total was -15.0. running mean: -18.88005398171531, timestamp: 2022-08-19 22:24:46.686724\n",
      "resetting env. episode 5565, reward total was -18.0. running mean: -18.87125344189816, timestamp: 2022-08-19 22:24:50.454764\n",
      "resetting env. episode 5566, reward total was -18.0. running mean: -18.862540907479175, timestamp: 2022-08-19 22:24:53.693805\n",
      "resetting env. episode 5567, reward total was -19.0. running mean: -18.863915498404385, timestamp: 2022-08-19 22:24:57.335845\n",
      "resetting env. episode 5568, reward total was -19.0. running mean: -18.86527634342034, timestamp: 2022-08-19 22:25:00.308877\n",
      "resetting env. episode 5569, reward total was -19.0. running mean: -18.86662357998614, timestamp: 2022-08-19 22:25:03.820919\n",
      "resetting env. episode 5570, reward total was -18.0. running mean: -18.85795734418628, timestamp: 2022-08-19 22:25:07.495961\n",
      "resetting env. episode 5571, reward total was -20.0. running mean: -18.869377770744414, timestamp: 2022-08-19 22:25:11.332001\n",
      "resetting env. episode 5572, reward total was -19.0. running mean: -18.87068399303697, timestamp: 2022-08-19 22:25:13.796034\n",
      "resetting env. episode 5573, reward total was -19.0. running mean: -18.871977153106602, timestamp: 2022-08-19 22:25:17.535072\n",
      "resetting env. episode 5574, reward total was -19.0. running mean: -18.873257381575538, timestamp: 2022-08-19 22:25:20.878112\n",
      "resetting env. episode 5575, reward total was -18.0. running mean: -18.864524807759782, timestamp: 2022-08-19 22:25:24.746154\n",
      "resetting env. episode 5576, reward total was -19.0. running mean: -18.865879559682185, timestamp: 2022-08-19 22:25:28.287193\n",
      "resetting env. episode 5577, reward total was -21.0. running mean: -18.887220764085363, timestamp: 2022-08-19 22:25:31.688233\n",
      "resetting env. episode 5578, reward total was -18.0. running mean: -18.878348556444507, timestamp: 2022-08-19 22:25:35.178273\n",
      "resetting env. episode 5579, reward total was -18.0. running mean: -18.86956507088006, timestamp: 2022-08-19 22:25:38.508308\n",
      "resetting env. episode 5580, reward total was -19.0. running mean: -18.87086942017126, timestamp: 2022-08-19 22:25:42.553353\n",
      "resetting env. episode 5581, reward total was -18.0. running mean: -18.86216072596955, timestamp: 2022-08-19 22:25:45.160384\n",
      "resetting env. episode 5582, reward total was -20.0. running mean: -18.873539118709854, timestamp: 2022-08-19 22:25:48.470422\n",
      "resetting env. episode 5583, reward total was -19.0. running mean: -18.874803727522757, timestamp: 2022-08-19 22:25:51.070454\n",
      "resetting env. episode 5584, reward total was -21.0. running mean: -18.89605569024753, timestamp: 2022-08-19 22:25:53.553481\n",
      "resetting env. episode 5585, reward total was -19.0. running mean: -18.897095133345054, timestamp: 2022-08-19 22:25:57.212521\n",
      "resetting env. episode 5586, reward total was -16.0. running mean: -18.868124182011602, timestamp: 2022-08-19 22:26:01.242570\n",
      "resetting env. episode 5587, reward total was -19.0. running mean: -18.869442940191487, timestamp: 2022-08-19 22:26:04.269603\n",
      "resetting env. episode 5588, reward total was -20.0. running mean: -18.88074851078957, timestamp: 2022-08-19 22:26:07.489638\n",
      "resetting env. episode 5589, reward total was -21.0. running mean: -18.901941025681673, timestamp: 2022-08-19 22:26:10.264673\n",
      "resetting env. episode 5590, reward total was -18.0. running mean: -18.892921615424857, timestamp: 2022-08-19 22:26:13.313705\n",
      "resetting env. episode 5591, reward total was -17.0. running mean: -18.87399239927061, timestamp: 2022-08-19 22:26:17.062747\n",
      "resetting env. episode 5592, reward total was -17.0. running mean: -18.855252475277904, timestamp: 2022-08-19 22:26:21.243798\n",
      "resetting env. episode 5593, reward total was -19.0. running mean: -18.856699950525126, timestamp: 2022-08-19 22:26:24.956837\n",
      "resetting env. episode 5594, reward total was -14.0. running mean: -18.808132951019875, timestamp: 2022-08-19 22:26:29.444891\n",
      "resetting env. episode 5595, reward total was -20.0. running mean: -18.820051621509677, timestamp: 2022-08-19 22:26:32.762928\n",
      "resetting env. episode 5596, reward total was -19.0. running mean: -18.82185110529458, timestamp: 2022-08-19 22:26:37.537982\n",
      "resetting env. episode 5597, reward total was -19.0. running mean: -18.823632594241637, timestamp: 2022-08-19 22:26:40.808017\n",
      "resetting env. episode 5598, reward total was -20.0. running mean: -18.83539626829922, timestamp: 2022-08-19 22:26:43.747051\n",
      "resetting env. episode 5599, reward total was -21.0. running mean: -18.85704230561623, timestamp: 2022-08-19 22:26:46.748088\n",
      "resetting env. episode 5600, reward total was -19.0. running mean: -18.858471882560067, timestamp: 2022-08-19 22:26:49.639120\n",
      "resetting env. episode 5601, reward total was -19.0. running mean: -18.859887163734466, timestamp: 2022-08-19 22:26:53.169160\n",
      "resetting env. episode 5602, reward total was -20.0. running mean: -18.87128829209712, timestamp: 2022-08-19 22:26:56.739199\n",
      "resetting env. episode 5603, reward total was -17.0. running mean: -18.85257540917615, timestamp: 2022-08-19 22:27:00.684246\n",
      "resetting env. episode 5604, reward total was -17.0. running mean: -18.834049655084392, timestamp: 2022-08-19 22:27:03.625278\n",
      "resetting env. episode 5605, reward total was -21.0. running mean: -18.85570915853355, timestamp: 2022-08-19 22:27:06.897319\n",
      "resetting env. episode 5606, reward total was -21.0. running mean: -18.877152066948216, timestamp: 2022-08-19 22:27:09.950351\n",
      "resetting env. episode 5607, reward total was -20.0. running mean: -18.888380546278732, timestamp: 2022-08-19 22:27:13.064389\n",
      "resetting env. episode 5608, reward total was -20.0. running mean: -18.899496740815945, timestamp: 2022-08-19 22:27:17.082433\n",
      "resetting env. episode 5609, reward total was -17.0. running mean: -18.880501773407786, timestamp: 2022-08-19 22:27:20.610475\n",
      "resetting env. episode 5610, reward total was -17.0. running mean: -18.86169675567371, timestamp: 2022-08-19 22:27:24.377516\n",
      "resetting env. episode 5611, reward total was -19.0. running mean: -18.863079788116973, timestamp: 2022-08-19 22:27:29.008569\n",
      "resetting env. episode 5612, reward total was -18.0. running mean: -18.854448990235802, timestamp: 2022-08-19 22:27:32.408606\n",
      "resetting env. episode 5613, reward total was -17.0. running mean: -18.835904500333445, timestamp: 2022-08-19 22:27:36.867656\n",
      "resetting env. episode 5614, reward total was -21.0. running mean: -18.85754545533011, timestamp: 2022-08-19 22:27:40.246696\n",
      "resetting env. episode 5615, reward total was -18.0. running mean: -18.84897000077681, timestamp: 2022-08-19 22:27:43.471736\n",
      "resetting env. episode 5616, reward total was -17.0. running mean: -18.830480300769043, timestamp: 2022-08-19 22:27:47.174777\n",
      "resetting env. episode 5617, reward total was -17.0. running mean: -18.812175497761356, timestamp: 2022-08-19 22:27:50.840816\n",
      "resetting env. episode 5618, reward total was -18.0. running mean: -18.80405374278374, timestamp: 2022-08-19 22:27:54.076856\n",
      "resetting env. episode 5619, reward total was -20.0. running mean: -18.8160132053559, timestamp: 2022-08-19 22:27:57.689896\n",
      "resetting env. episode 5620, reward total was -17.0. running mean: -18.797853073302342, timestamp: 2022-08-19 22:28:01.266934\n",
      "resetting env. episode 5621, reward total was -20.0. running mean: -18.809874542569318, timestamp: 2022-08-19 22:28:04.673973\n",
      "resetting env. episode 5622, reward total was -19.0. running mean: -18.811775797143625, timestamp: 2022-08-19 22:28:08.003016\n",
      "resetting env. episode 5623, reward total was -21.0. running mean: -18.83365803917219, timestamp: 2022-08-19 22:28:10.711044\n",
      "resetting env. episode 5624, reward total was -19.0. running mean: -18.835321458780466, timestamp: 2022-08-19 22:28:13.780079\n",
      "resetting env. episode 5625, reward total was -19.0. running mean: -18.83696824419266, timestamp: 2022-08-19 22:28:17.367122\n",
      "resetting env. episode 5626, reward total was -18.0. running mean: -18.828598561750734, timestamp: 2022-08-19 22:28:20.427156\n",
      "resetting env. episode 5627, reward total was -21.0. running mean: -18.850312576133227, timestamp: 2022-08-19 22:28:24.243197\n",
      "resetting env. episode 5628, reward total was -20.0. running mean: -18.861809450371894, timestamp: 2022-08-19 22:28:27.644239\n",
      "resetting env. episode 5629, reward total was -20.0. running mean: -18.873191355868173, timestamp: 2022-08-19 22:28:31.658283\n",
      "resetting env. episode 5630, reward total was -18.0. running mean: -18.86445944230949, timestamp: 2022-08-19 22:28:35.372328\n",
      "resetting env. episode 5631, reward total was -19.0. running mean: -18.865814847886394, timestamp: 2022-08-19 22:28:38.658364\n",
      "resetting env. episode 5632, reward total was -21.0. running mean: -18.88715669940753, timestamp: 2022-08-19 22:28:41.147392\n",
      "resetting env. episode 5633, reward total was -19.0. running mean: -18.888285132413458, timestamp: 2022-08-19 22:28:44.802433\n",
      "resetting env. episode 5634, reward total was -19.0. running mean: -18.889402281089325, timestamp: 2022-08-19 22:28:48.279475\n",
      "resetting env. episode 5635, reward total was -17.0. running mean: -18.870508258278434, timestamp: 2022-08-19 22:28:52.517521\n",
      "resetting env. episode 5636, reward total was -16.0. running mean: -18.84180317569565, timestamp: 2022-08-19 22:28:56.447568\n",
      "resetting env. episode 5637, reward total was -21.0. running mean: -18.863385143938693, timestamp: 2022-08-19 22:28:59.353598\n",
      "resetting env. episode 5638, reward total was -21.0. running mean: -18.884751292499306, timestamp: 2022-08-19 22:29:02.841640\n",
      "resetting env. episode 5639, reward total was -17.0. running mean: -18.865903779574314, timestamp: 2022-08-19 22:29:07.198687\n",
      "resetting env. episode 5640, reward total was -19.0. running mean: -18.86724474177857, timestamp: 2022-08-19 22:29:11.250733\n",
      "resetting env. episode 5641, reward total was -17.0. running mean: -18.848572294360785, timestamp: 2022-08-19 22:29:14.517772\n",
      "resetting env. episode 5642, reward total was -18.0. running mean: -18.840086571417178, timestamp: 2022-08-19 22:29:18.954823\n",
      "resetting env. episode 5643, reward total was -19.0. running mean: -18.841685705703007, timestamp: 2022-08-19 22:29:22.954867\n",
      "resetting env. episode 5644, reward total was -18.0. running mean: -18.833268848645975, timestamp: 2022-08-19 22:29:26.865914\n",
      "resetting env. episode 5645, reward total was -18.0. running mean: -18.824936160159513, timestamp: 2022-08-19 22:29:29.950950\n",
      "resetting env. episode 5646, reward total was -18.0. running mean: -18.816686798557917, timestamp: 2022-08-19 22:29:33.937993\n",
      "resetting env. episode 5647, reward total was -17.0. running mean: -18.79851993057234, timestamp: 2022-08-19 22:29:37.905036\n",
      "resetting env. episode 5648, reward total was -17.0. running mean: -18.780534731266616, timestamp: 2022-08-19 22:29:42.145086\n",
      "resetting env. episode 5649, reward total was -17.0. running mean: -18.762729383953953, timestamp: 2022-08-19 22:29:45.271121\n",
      "resetting env. episode 5650, reward total was -21.0. running mean: -18.785102090114414, timestamp: 2022-08-19 22:29:48.703162\n",
      "resetting env. episode 5651, reward total was -16.0. running mean: -18.757251069213268, timestamp: 2022-08-19 22:29:52.434203\n",
      "resetting env. episode 5652, reward total was -18.0. running mean: -18.749678558521136, timestamp: 2022-08-19 22:29:55.841241\n",
      "resetting env. episode 5653, reward total was -16.0. running mean: -18.722181772935926, timestamp: 2022-08-19 22:29:59.082279\n",
      "resetting env. episode 5654, reward total was -19.0. running mean: -18.724959955206568, timestamp: 2022-08-19 22:30:04.016335\n",
      "resetting env. episode 5655, reward total was -19.0. running mean: -18.727710355654505, timestamp: 2022-08-19 22:30:06.949372\n",
      "resetting env. episode 5656, reward total was -21.0. running mean: -18.75043325209796, timestamp: 2022-08-19 22:30:10.078406\n",
      "resetting env. episode 5657, reward total was -17.0. running mean: -18.73292891957698, timestamp: 2022-08-19 22:30:14.080450\n",
      "resetting env. episode 5658, reward total was -18.0. running mean: -18.72559963038121, timestamp: 2022-08-19 22:30:17.943495\n",
      "resetting env. episode 5659, reward total was -19.0. running mean: -18.7283436340774, timestamp: 2022-08-19 22:30:21.535534\n",
      "resetting env. episode 5660, reward total was -19.0. running mean: -18.73106019773663, timestamp: 2022-08-19 22:30:24.893571\n",
      "resetting env. episode 5661, reward total was -20.0. running mean: -18.74374959575926, timestamp: 2022-08-19 22:30:27.730609\n",
      "resetting env. episode 5662, reward total was -19.0. running mean: -18.74631209980167, timestamp: 2022-08-19 22:30:31.309647\n",
      "resetting env. episode 5663, reward total was -19.0. running mean: -18.748848978803654, timestamp: 2022-08-19 22:30:34.774689\n",
      "resetting env. episode 5664, reward total was -19.0. running mean: -18.751360489015617, timestamp: 2022-08-19 22:30:38.371726\n",
      "resetting env. episode 5665, reward total was -18.0. running mean: -18.74384688412546, timestamp: 2022-08-19 22:30:42.605776\n",
      "resetting env. episode 5666, reward total was -20.0. running mean: -18.756408415284206, timestamp: 2022-08-19 22:30:45.692815\n",
      "resetting env. episode 5667, reward total was -19.0. running mean: -18.758844331131364, timestamp: 2022-08-19 22:30:49.041850\n",
      "resetting env. episode 5668, reward total was -21.0. running mean: -18.781255887820052, timestamp: 2022-08-19 22:30:52.263885\n",
      "resetting env. episode 5669, reward total was -18.0. running mean: -18.773443328941852, timestamp: 2022-08-19 22:30:54.861916\n",
      "resetting env. episode 5670, reward total was -20.0. running mean: -18.785708895652434, timestamp: 2022-08-19 22:30:58.693957\n",
      "resetting env. episode 5671, reward total was -19.0. running mean: -18.78785180669591, timestamp: 2022-08-19 22:31:02.516003\n",
      "resetting env. episode 5672, reward total was -20.0. running mean: -18.79997328862895, timestamp: 2022-08-19 22:31:06.437045\n",
      "resetting env. episode 5673, reward total was -17.0. running mean: -18.781973555742663, timestamp: 2022-08-19 22:31:10.262092\n",
      "resetting env. episode 5674, reward total was -19.0. running mean: -18.78415382018524, timestamp: 2022-08-19 22:31:13.522129\n",
      "resetting env. episode 5675, reward total was -21.0. running mean: -18.806312281983388, timestamp: 2022-08-19 22:31:16.487160\n",
      "resetting env. episode 5676, reward total was -17.0. running mean: -18.788249159163556, timestamp: 2022-08-19 22:31:20.020198\n",
      "resetting env. episode 5677, reward total was -21.0. running mean: -18.81036666757192, timestamp: 2022-08-19 22:31:23.331236\n",
      "resetting env. episode 5678, reward total was -19.0. running mean: -18.812263000896202, timestamp: 2022-08-19 22:31:26.800278\n",
      "resetting env. episode 5679, reward total was -19.0. running mean: -18.81414037088724, timestamp: 2022-08-19 22:31:29.874311\n",
      "resetting env. episode 5680, reward total was -20.0. running mean: -18.825998967178368, timestamp: 2022-08-19 22:31:33.187346\n",
      "resetting env. episode 5681, reward total was -20.0. running mean: -18.837738977506582, timestamp: 2022-08-19 22:31:36.499386\n",
      "resetting env. episode 5682, reward total was -18.0. running mean: -18.829361587731515, timestamp: 2022-08-19 22:31:40.259427\n",
      "resetting env. episode 5683, reward total was -14.0. running mean: -18.7810679718542, timestamp: 2022-08-19 22:31:44.252474\n",
      "resetting env. episode 5684, reward total was -18.0. running mean: -18.773257292135657, timestamp: 2022-08-19 22:31:48.208518\n",
      "resetting env. episode 5685, reward total was -19.0. running mean: -18.775524719214303, timestamp: 2022-08-19 22:31:51.665555\n",
      "resetting env. episode 5686, reward total was -18.0. running mean: -18.76776947202216, timestamp: 2022-08-19 22:31:54.785594\n",
      "resetting env. episode 5687, reward total was -21.0. running mean: -18.79009177730194, timestamp: 2022-08-19 22:31:58.429633\n",
      "resetting env. episode 5688, reward total was -19.0. running mean: -18.79219085952892, timestamp: 2022-08-19 22:32:02.246675\n",
      "resetting env. episode 5689, reward total was -19.0. running mean: -18.79426895093363, timestamp: 2022-08-19 22:32:05.989717\n",
      "resetting env. episode 5690, reward total was -18.0. running mean: -18.786326261424293, timestamp: 2022-08-19 22:32:09.192754\n",
      "resetting env. episode 5691, reward total was -19.0. running mean: -18.78846299881005, timestamp: 2022-08-19 22:32:13.209801\n",
      "resetting env. episode 5692, reward total was -20.0. running mean: -18.80057836882195, timestamp: 2022-08-19 22:32:16.996845\n",
      "resetting env. episode 5693, reward total was -18.0. running mean: -18.79257258513373, timestamp: 2022-08-19 22:32:21.320893\n",
      "resetting env. episode 5694, reward total was -19.0. running mean: -18.794646859282395, timestamp: 2022-08-19 22:32:24.801929\n",
      "resetting env. episode 5695, reward total was -18.0. running mean: -18.78670039068957, timestamp: 2022-08-19 22:32:27.916968\n",
      "resetting env. episode 5696, reward total was -19.0. running mean: -18.788833386782677, timestamp: 2022-08-19 22:32:31.615009\n",
      "resetting env. episode 5697, reward total was -20.0. running mean: -18.800945052914848, timestamp: 2022-08-19 22:32:34.113036\n",
      "resetting env. episode 5698, reward total was -18.0. running mean: -18.7929356023857, timestamp: 2022-08-19 22:32:36.985070\n",
      "resetting env. episode 5699, reward total was -19.0. running mean: -18.795006246361844, timestamp: 2022-08-19 22:32:40.325105\n",
      "resetting env. episode 5700, reward total was -20.0. running mean: -18.807056183898226, timestamp: 2022-08-19 22:32:43.874147\n",
      "resetting env. episode 5701, reward total was -18.0. running mean: -18.79898562205924, timestamp: 2022-08-19 22:32:47.235184\n",
      "resetting env. episode 5702, reward total was -17.0. running mean: -18.78099576583865, timestamp: 2022-08-19 22:32:50.855226\n",
      "resetting env. episode 5703, reward total was -21.0. running mean: -18.803185808180263, timestamp: 2022-08-19 22:32:54.250269\n",
      "resetting env. episode 5704, reward total was -16.0. running mean: -18.77515395009846, timestamp: 2022-08-19 22:32:58.567311\n",
      "resetting env. episode 5705, reward total was -21.0. running mean: -18.797402410597478, timestamp: 2022-08-19 22:33:01.648346\n",
      "resetting env. episode 5706, reward total was -21.0. running mean: -18.819428386491502, timestamp: 2022-08-19 22:33:05.132387\n",
      "resetting env. episode 5707, reward total was -19.0. running mean: -18.821234102626587, timestamp: 2022-08-19 22:33:08.491426\n",
      "resetting env. episode 5708, reward total was -19.0. running mean: -18.823021761600323, timestamp: 2022-08-19 22:33:11.420464\n",
      "resetting env. episode 5709, reward total was -20.0. running mean: -18.83479154398432, timestamp: 2022-08-19 22:33:15.519506\n",
      "resetting env. episode 5710, reward total was -17.0. running mean: -18.816443628544476, timestamp: 2022-08-19 22:33:19.099543\n",
      "resetting env. episode 5711, reward total was -19.0. running mean: -18.818279192259034, timestamp: 2022-08-19 22:33:22.114578\n",
      "resetting env. episode 5712, reward total was -19.0. running mean: -18.820096400336446, timestamp: 2022-08-19 22:33:25.518627\n",
      "resetting env. episode 5713, reward total was -21.0. running mean: -18.841895436333083, timestamp: 2022-08-19 22:33:28.965657\n",
      "resetting env. episode 5714, reward total was -19.0. running mean: -18.843476481969752, timestamp: 2022-08-19 22:33:31.648688\n",
      "resetting env. episode 5715, reward total was -21.0. running mean: -18.865041717150056, timestamp: 2022-08-19 22:33:35.723734\n",
      "resetting env. episode 5716, reward total was -20.0. running mean: -18.876391299978554, timestamp: 2022-08-19 22:33:39.638776\n",
      "resetting env. episode 5717, reward total was -17.0. running mean: -18.85762738697877, timestamp: 2022-08-19 22:33:42.495810\n",
      "resetting env. episode 5718, reward total was -20.0. running mean: -18.86905111310898, timestamp: 2022-08-19 22:33:45.966846\n",
      "resetting env. episode 5719, reward total was -20.0. running mean: -18.88036060197789, timestamp: 2022-08-19 22:33:48.872882\n",
      "resetting env. episode 5720, reward total was -19.0. running mean: -18.881556995958114, timestamp: 2022-08-19 22:33:52.075917\n",
      "resetting env. episode 5721, reward total was -16.0. running mean: -18.852741425998534, timestamp: 2022-08-19 22:33:56.079961\n",
      "resetting env. episode 5722, reward total was -20.0. running mean: -18.864214011738547, timestamp: 2022-08-19 22:33:59.315996\n",
      "resetting env. episode 5723, reward total was -19.0. running mean: -18.865571871621164, timestamp: 2022-08-19 22:34:02.901036\n",
      "resetting env. episode 5724, reward total was -20.0. running mean: -18.87691615290495, timestamp: 2022-08-19 22:34:06.423076\n",
      "resetting env. episode 5725, reward total was -18.0. running mean: -18.8681469913759, timestamp: 2022-08-19 22:34:10.308120\n",
      "resetting env. episode 5726, reward total was -18.0. running mean: -18.85946552146214, timestamp: 2022-08-19 22:34:13.414163\n",
      "resetting env. episode 5727, reward total was -21.0. running mean: -18.88087086624752, timestamp: 2022-08-19 22:34:16.591190\n",
      "resetting env. episode 5728, reward total was -19.0. running mean: -18.882062157585047, timestamp: 2022-08-19 22:34:20.418238\n",
      "resetting env. episode 5729, reward total was -13.0. running mean: -18.823241536009196, timestamp: 2022-08-19 22:34:24.916285\n",
      "resetting env. episode 5730, reward total was -19.0. running mean: -18.825009120649106, timestamp: 2022-08-19 22:34:29.254331\n",
      "resetting env. episode 5731, reward total was -20.0. running mean: -18.836759029442614, timestamp: 2022-08-19 22:34:33.070374\n",
      "resetting env. episode 5732, reward total was -17.0. running mean: -18.81839143914819, timestamp: 2022-08-19 22:34:36.997421\n",
      "resetting env. episode 5733, reward total was -18.0. running mean: -18.81020752475671, timestamp: 2022-08-19 22:34:40.336455\n",
      "resetting env. episode 5734, reward total was -18.0. running mean: -18.802105449509142, timestamp: 2022-08-19 22:34:43.376491\n",
      "resetting env. episode 5735, reward total was -20.0. running mean: -18.81408439501405, timestamp: 2022-08-19 22:34:47.342538\n",
      "resetting env. episode 5736, reward total was -21.0. running mean: -18.83594355106391, timestamp: 2022-08-19 22:34:49.579560\n",
      "resetting env. episode 5737, reward total was -19.0. running mean: -18.837584115553273, timestamp: 2022-08-19 22:34:53.245600\n",
      "resetting env. episode 5738, reward total was -17.0. running mean: -18.81920827439774, timestamp: 2022-08-19 22:34:56.991643\n",
      "resetting env. episode 5739, reward total was -18.0. running mean: -18.811016191653763, timestamp: 2022-08-19 22:35:00.852685\n",
      "resetting env. episode 5740, reward total was -21.0. running mean: -18.832906029737227, timestamp: 2022-08-19 22:35:05.614738\n",
      "resetting env. episode 5741, reward total was -21.0. running mean: -18.854576969439854, timestamp: 2022-08-19 22:35:08.679774\n",
      "resetting env. episode 5742, reward total was -16.0. running mean: -18.826031199745454, timestamp: 2022-08-19 22:35:12.565818\n",
      "resetting env. episode 5743, reward total was -20.0. running mean: -18.837770887748, timestamp: 2022-08-19 22:35:15.353849\n",
      "resetting env. episode 5744, reward total was -20.0. running mean: -18.84939317887052, timestamp: 2022-08-19 22:35:18.194883\n",
      "resetting env. episode 5745, reward total was -17.0. running mean: -18.830899247081817, timestamp: 2022-08-19 22:35:21.759919\n",
      "resetting env. episode 5746, reward total was -19.0. running mean: -18.832590254611, timestamp: 2022-08-19 22:35:25.343963\n",
      "resetting env. episode 5747, reward total was -17.0. running mean: -18.81426435206489, timestamp: 2022-08-19 22:35:29.805010\n",
      "resetting env. episode 5748, reward total was -19.0. running mean: -18.81612170854424, timestamp: 2022-08-19 22:35:32.918045\n",
      "resetting env. episode 5749, reward total was -17.0. running mean: -18.7979604914588, timestamp: 2022-08-19 22:35:36.324084\n",
      "resetting env. episode 5750, reward total was -14.0. running mean: -18.74998088654421, timestamp: 2022-08-19 22:35:40.147125\n",
      "resetting env. episode 5751, reward total was -17.0. running mean: -18.73248107767877, timestamp: 2022-08-19 22:35:43.420162\n",
      "resetting env. episode 5752, reward total was -21.0. running mean: -18.755156266901984, timestamp: 2022-08-19 22:35:46.093192\n",
      "resetting env. episode 5753, reward total was -17.0. running mean: -18.737604704232965, timestamp: 2022-08-19 22:35:51.015248\n",
      "resetting env. episode 5754, reward total was -20.0. running mean: -18.750228657190632, timestamp: 2022-08-19 22:35:54.257285\n",
      "resetting env. episode 5755, reward total was -19.0. running mean: -18.752726370618728, timestamp: 2022-08-19 22:35:58.147328\n",
      "resetting env. episode 5756, reward total was -21.0. running mean: -18.77519910691254, timestamp: 2022-08-19 22:36:01.655367\n",
      "resetting env. episode 5757, reward total was -18.0. running mean: -18.767447115843417, timestamp: 2022-08-19 22:36:05.765413\n",
      "resetting env. episode 5758, reward total was -18.0. running mean: -18.759772644684983, timestamp: 2022-08-19 22:36:08.852451\n",
      "resetting env. episode 5759, reward total was -17.0. running mean: -18.742174918238135, timestamp: 2022-08-19 22:36:13.228497\n",
      "resetting env. episode 5760, reward total was -18.0. running mean: -18.734753169055754, timestamp: 2022-08-19 22:36:16.763533\n",
      "resetting env. episode 5761, reward total was -18.0. running mean: -18.727405637365194, timestamp: 2022-08-19 22:36:19.565567\n",
      "resetting env. episode 5762, reward total was -19.0. running mean: -18.730131580991543, timestamp: 2022-08-19 22:36:23.735616\n",
      "resetting env. episode 5763, reward total was -18.0. running mean: -18.722830265181628, timestamp: 2022-08-19 22:36:27.036653\n",
      "resetting env. episode 5764, reward total was -20.0. running mean: -18.73560196252981, timestamp: 2022-08-19 22:36:30.123682\n",
      "resetting env. episode 5765, reward total was -16.0. running mean: -18.70824594290451, timestamp: 2022-08-19 22:36:34.664732\n",
      "resetting env. episode 5766, reward total was -17.0. running mean: -18.691163483475467, timestamp: 2022-08-19 22:36:38.101772\n",
      "resetting env. episode 5767, reward total was -17.0. running mean: -18.674251848640715, timestamp: 2022-08-19 22:36:41.633816\n",
      "resetting env. episode 5768, reward total was -17.0. running mean: -18.65750933015431, timestamp: 2022-08-19 22:36:45.506855\n",
      "resetting env. episode 5769, reward total was -21.0. running mean: -18.680934236852767, timestamp: 2022-08-19 22:36:48.672890\n",
      "resetting env. episode 5770, reward total was -17.0. running mean: -18.664124894484242, timestamp: 2022-08-19 22:36:51.759924\n",
      "resetting env. episode 5771, reward total was -21.0. running mean: -18.687483645539402, timestamp: 2022-08-19 22:36:55.643968\n",
      "resetting env. episode 5772, reward total was -21.0. running mean: -18.710608809084007, timestamp: 2022-08-19 22:36:58.995005\n",
      "resetting env. episode 5773, reward total was -15.0. running mean: -18.673502720993167, timestamp: 2022-08-19 22:37:03.452054\n",
      "resetting env. episode 5774, reward total was -18.0. running mean: -18.666767693783235, timestamp: 2022-08-19 22:37:06.957094\n",
      "resetting env. episode 5775, reward total was -20.0. running mean: -18.6801000168454, timestamp: 2022-08-19 22:37:10.241130\n",
      "resetting env. episode 5776, reward total was -20.0. running mean: -18.693299016676946, timestamp: 2022-08-19 22:37:12.969158\n",
      "resetting env. episode 5777, reward total was -16.0. running mean: -18.666366026510175, timestamp: 2022-08-19 22:37:17.008206\n",
      "resetting env. episode 5778, reward total was -20.0. running mean: -18.679702366245074, timestamp: 2022-08-19 22:37:20.609250\n",
      "resetting env. episode 5779, reward total was -18.0. running mean: -18.672905342582624, timestamp: 2022-08-19 22:37:24.843293\n",
      "resetting env. episode 5780, reward total was -20.0. running mean: -18.686176289156798, timestamp: 2022-08-19 22:37:29.250342\n",
      "resetting env. episode 5781, reward total was -19.0. running mean: -18.689314526265232, timestamp: 2022-08-19 22:37:32.748380\n",
      "resetting env. episode 5782, reward total was -17.0. running mean: -18.672421381002582, timestamp: 2022-08-19 22:37:36.148417\n",
      "resetting env. episode 5783, reward total was -17.0. running mean: -18.655697167192557, timestamp: 2022-08-19 22:37:39.863461\n",
      "resetting env. episode 5784, reward total was -20.0. running mean: -18.66914019552063, timestamp: 2022-08-19 22:37:42.830492\n",
      "resetting env. episode 5785, reward total was -15.0. running mean: -18.632448793565423, timestamp: 2022-08-19 22:37:47.260541\n",
      "resetting env. episode 5786, reward total was -20.0. running mean: -18.64612430562977, timestamp: 2022-08-19 22:37:50.523579\n",
      "resetting env. episode 5787, reward total was -19.0. running mean: -18.649663062573474, timestamp: 2022-08-19 22:37:54.668622\n",
      "resetting env. episode 5788, reward total was -19.0. running mean: -18.65316643194774, timestamp: 2022-08-19 22:37:57.449653\n",
      "resetting env. episode 5789, reward total was -18.0. running mean: -18.64663476762826, timestamp: 2022-08-19 22:38:00.551690\n",
      "resetting env. episode 5790, reward total was -19.0. running mean: -18.650168419951978, timestamp: 2022-08-19 22:38:04.022727\n",
      "resetting env. episode 5791, reward total was -18.0. running mean: -18.643666735752458, timestamp: 2022-08-19 22:38:07.684773\n",
      "resetting env. episode 5792, reward total was -21.0. running mean: -18.667230068394932, timestamp: 2022-08-19 22:38:11.089807\n",
      "resetting env. episode 5793, reward total was -21.0. running mean: -18.690557767710985, timestamp: 2022-08-19 22:38:14.267843\n",
      "resetting env. episode 5794, reward total was -19.0. running mean: -18.693652190033877, timestamp: 2022-08-19 22:38:17.592880\n",
      "resetting env. episode 5795, reward total was -19.0. running mean: -18.69671566813354, timestamp: 2022-08-19 22:38:20.967916\n",
      "resetting env. episode 5796, reward total was -21.0. running mean: -18.719748511452206, timestamp: 2022-08-19 22:38:24.338952\n",
      "resetting env. episode 5797, reward total was -15.0. running mean: -18.68255102633768, timestamp: 2022-08-19 22:38:29.057002\n",
      "resetting env. episode 5798, reward total was -21.0. running mean: -18.705725516074306, timestamp: 2022-08-19 22:38:32.976045\n",
      "resetting env. episode 5799, reward total was -17.0. running mean: -18.688668260913566, timestamp: 2022-08-19 22:38:37.179093\n",
      "resetting env. episode 5800, reward total was -19.0. running mean: -18.691781578304433, timestamp: 2022-08-19 22:38:40.414126\n",
      "resetting env. episode 5801, reward total was -18.0. running mean: -18.68486376252139, timestamp: 2022-08-19 22:38:44.135168\n",
      "resetting env. episode 5802, reward total was -17.0. running mean: -18.668015124896176, timestamp: 2022-08-19 22:38:47.251203\n",
      "resetting env. episode 5803, reward total was -20.0. running mean: -18.681334973647214, timestamp: 2022-08-19 22:38:50.597240\n",
      "resetting env. episode 5804, reward total was -19.0. running mean: -18.684521623910744, timestamp: 2022-08-19 22:38:53.970275\n",
      "resetting env. episode 5805, reward total was -19.0. running mean: -18.68767640767164, timestamp: 2022-08-19 22:38:57.716317\n",
      "resetting env. episode 5806, reward total was -19.0. running mean: -18.69079964359492, timestamp: 2022-08-19 22:39:00.862353\n",
      "resetting env. episode 5807, reward total was -20.0. running mean: -18.703891647158972, timestamp: 2022-08-19 22:39:03.765386\n",
      "resetting env. episode 5808, reward total was -18.0. running mean: -18.696852730687382, timestamp: 2022-08-19 22:39:06.885423\n",
      "resetting env. episode 5809, reward total was -17.0. running mean: -18.67988420338051, timestamp: 2022-08-19 22:39:09.799450\n",
      "resetting env. episode 5810, reward total was -17.0. running mean: -18.663085361346706, timestamp: 2022-08-19 22:39:13.540491\n",
      "resetting env. episode 5811, reward total was -21.0. running mean: -18.686454507733238, timestamp: 2022-08-19 22:39:16.706528\n",
      "resetting env. episode 5812, reward total was -19.0. running mean: -18.689589962655905, timestamp: 2022-08-19 22:39:20.253568\n",
      "resetting env. episode 5813, reward total was -17.0. running mean: -18.672694063029347, timestamp: 2022-08-19 22:39:24.300609\n",
      "resetting env. episode 5814, reward total was -21.0. running mean: -18.695967122399054, timestamp: 2022-08-19 22:39:27.890650\n",
      "resetting env. episode 5815, reward total was -18.0. running mean: -18.689007451175062, timestamp: 2022-08-19 22:39:31.324689\n",
      "resetting env. episode 5816, reward total was -21.0. running mean: -18.71211737666331, timestamp: 2022-08-19 22:39:34.126721\n",
      "resetting env. episode 5817, reward total was -19.0. running mean: -18.71499620289668, timestamp: 2022-08-19 22:39:37.657758\n",
      "resetting env. episode 5818, reward total was -20.0. running mean: -18.72784624086771, timestamp: 2022-08-19 22:39:41.038798\n",
      "resetting env. episode 5819, reward total was -20.0. running mean: -18.74056777845903, timestamp: 2022-08-19 22:39:44.360833\n",
      "resetting env. episode 5820, reward total was -20.0. running mean: -18.75316210067444, timestamp: 2022-08-19 22:39:47.537872\n",
      "resetting env. episode 5821, reward total was -19.0. running mean: -18.755630479667698, timestamp: 2022-08-19 22:39:50.837902\n",
      "resetting env. episode 5822, reward total was -16.0. running mean: -18.728074174871022, timestamp: 2022-08-19 22:39:53.649933\n",
      "resetting env. episode 5823, reward total was -20.0. running mean: -18.74079343312231, timestamp: 2022-08-19 22:39:56.848971\n",
      "resetting env. episode 5824, reward total was -20.0. running mean: -18.753385498791086, timestamp: 2022-08-19 22:40:00.343007\n",
      "resetting env. episode 5825, reward total was -19.0. running mean: -18.755851643803176, timestamp: 2022-08-19 22:40:03.487047\n",
      "resetting env. episode 5826, reward total was -19.0. running mean: -18.758293127365146, timestamp: 2022-08-19 22:40:07.215086\n",
      "resetting env. episode 5827, reward total was -18.0. running mean: -18.750710196091493, timestamp: 2022-08-19 22:40:10.855123\n",
      "resetting env. episode 5828, reward total was -17.0. running mean: -18.73320309413058, timestamp: 2022-08-19 22:40:15.280174\n",
      "resetting env. episode 5829, reward total was -19.0. running mean: -18.735871063189276, timestamp: 2022-08-19 22:40:18.878215\n",
      "resetting env. episode 5830, reward total was -16.0. running mean: -18.70851235255738, timestamp: 2022-08-19 22:40:22.784257\n",
      "resetting env. episode 5831, reward total was -19.0. running mean: -18.71142722903181, timestamp: 2022-08-19 22:40:26.272298\n",
      "resetting env. episode 5832, reward total was -19.0. running mean: -18.71431295674149, timestamp: 2022-08-19 22:40:29.396332\n",
      "resetting env. episode 5833, reward total was -16.0. running mean: -18.687169827174078, timestamp: 2022-08-19 22:40:33.470376\n",
      "resetting env. episode 5834, reward total was -18.0. running mean: -18.680298128902336, timestamp: 2022-08-19 22:40:36.904414\n",
      "resetting env. episode 5835, reward total was -19.0. running mean: -18.683495147613314, timestamp: 2022-08-19 22:40:39.818448\n",
      "resetting env. episode 5836, reward total was -20.0. running mean: -18.69666019613718, timestamp: 2022-08-19 22:40:42.251475\n",
      "resetting env. episode 5837, reward total was -19.0. running mean: -18.69969359417581, timestamp: 2022-08-19 22:40:46.012517\n",
      "resetting env. episode 5838, reward total was -19.0. running mean: -18.702696658234053, timestamp: 2022-08-19 22:40:49.877560\n",
      "resetting env. episode 5839, reward total was -21.0. running mean: -18.725669691651714, timestamp: 2022-08-19 22:40:53.070594\n",
      "resetting env. episode 5840, reward total was -20.0. running mean: -18.738412994735196, timestamp: 2022-08-19 22:40:56.377631\n",
      "resetting env. episode 5841, reward total was -20.0. running mean: -18.751028864787845, timestamp: 2022-08-19 22:40:59.211664\n",
      "resetting env. episode 5842, reward total was -20.0. running mean: -18.763518576139965, timestamp: 2022-08-19 22:41:02.306700\n",
      "resetting env. episode 5843, reward total was -20.0. running mean: -18.775883390378564, timestamp: 2022-08-19 22:41:05.729735\n",
      "resetting env. episode 5844, reward total was -18.0. running mean: -18.768124556474778, timestamp: 2022-08-19 22:41:09.337776\n",
      "resetting env. episode 5845, reward total was -17.0. running mean: -18.750443310910033, timestamp: 2022-08-19 22:41:13.923827\n",
      "resetting env. episode 5846, reward total was -17.0. running mean: -18.732938877800933, timestamp: 2022-08-19 22:41:17.686872\n",
      "resetting env. episode 5847, reward total was -17.0. running mean: -18.715609489022924, timestamp: 2022-08-19 22:41:21.483913\n",
      "resetting env. episode 5848, reward total was -19.0. running mean: -18.718453394132695, timestamp: 2022-08-19 22:41:24.850950\n",
      "resetting env. episode 5849, reward total was -14.0. running mean: -18.67126886019137, timestamp: 2022-08-19 22:41:29.142998\n",
      "resetting env. episode 5850, reward total was -19.0. running mean: -18.674556171589455, timestamp: 2022-08-19 22:41:32.065030\n",
      "resetting env. episode 5851, reward total was -19.0. running mean: -18.67781060987356, timestamp: 2022-08-19 22:41:35.602075\n",
      "resetting env. episode 5852, reward total was -19.0. running mean: -18.681032503774826, timestamp: 2022-08-19 22:41:38.366101\n",
      "resetting env. episode 5853, reward total was -19.0. running mean: -18.68422217873708, timestamp: 2022-08-19 22:41:41.656138\n",
      "resetting env. episode 5854, reward total was -21.0. running mean: -18.707379956949712, timestamp: 2022-08-19 22:41:44.044164\n",
      "resetting env. episode 5855, reward total was -20.0. running mean: -18.720306157380215, timestamp: 2022-08-19 22:41:48.396214\n",
      "resetting env. episode 5856, reward total was -16.0. running mean: -18.69310309580641, timestamp: 2022-08-19 22:41:52.200256\n",
      "resetting env. episode 5857, reward total was -18.0. running mean: -18.686172064848346, timestamp: 2022-08-19 22:41:56.109303\n",
      "resetting env. episode 5858, reward total was -21.0. running mean: -18.709310344199864, timestamp: 2022-08-19 22:41:59.341339\n",
      "resetting env. episode 5859, reward total was -19.0. running mean: -18.712217240757866, timestamp: 2022-08-19 22:42:02.852377\n",
      "resetting env. episode 5860, reward total was -17.0. running mean: -18.695095068350287, timestamp: 2022-08-19 22:42:06.904424\n",
      "resetting env. episode 5861, reward total was -19.0. running mean: -18.698144117666786, timestamp: 2022-08-19 22:42:10.599467\n",
      "resetting env. episode 5862, reward total was -18.0. running mean: -18.691162676490116, timestamp: 2022-08-19 22:42:14.709513\n",
      "resetting env. episode 5863, reward total was -19.0. running mean: -18.694251049725217, timestamp: 2022-08-19 22:42:18.503559\n",
      "resetting env. episode 5864, reward total was -18.0. running mean: -18.687308539227963, timestamp: 2022-08-19 22:42:21.859592\n",
      "resetting env. episode 5865, reward total was -21.0. running mean: -18.710435453835686, timestamp: 2022-08-19 22:42:25.883638\n",
      "resetting env. episode 5866, reward total was -21.0. running mean: -18.73333109929733, timestamp: 2022-08-19 22:42:29.436678\n",
      "resetting env. episode 5867, reward total was -21.0. running mean: -18.75599778830436, timestamp: 2022-08-19 22:42:32.898719\n",
      "resetting env. episode 5868, reward total was -18.0. running mean: -18.748437810421315, timestamp: 2022-08-19 22:42:37.002762\n",
      "resetting env. episode 5869, reward total was -18.0. running mean: -18.740953432317102, timestamp: 2022-08-19 22:42:40.846808\n",
      "resetting env. episode 5870, reward total was -18.0. running mean: -18.733543897993933, timestamp: 2022-08-19 22:42:44.636848\n",
      "resetting env. episode 5871, reward total was -19.0. running mean: -18.736208459013994, timestamp: 2022-08-19 22:42:48.517893\n",
      "resetting env. episode 5872, reward total was -18.0. running mean: -18.728846374423853, timestamp: 2022-08-19 22:42:52.419937\n",
      "resetting env. episode 5873, reward total was -19.0. running mean: -18.731557910679616, timestamp: 2022-08-19 22:42:56.421981\n",
      "resetting env. episode 5874, reward total was -19.0. running mean: -18.73424233157282, timestamp: 2022-08-19 22:43:00.815033\n",
      "resetting env. episode 5875, reward total was -18.0. running mean: -18.726899908257092, timestamp: 2022-08-19 22:43:04.148071\n",
      "resetting env. episode 5876, reward total was -21.0. running mean: -18.74963090917452, timestamp: 2022-08-19 22:43:07.872111\n",
      "resetting env. episode 5877, reward total was -16.0. running mean: -18.722134600082775, timestamp: 2022-08-19 22:43:11.427151\n",
      "resetting env. episode 5878, reward total was -18.0. running mean: -18.714913254081946, timestamp: 2022-08-19 22:43:15.698200\n",
      "resetting env. episode 5879, reward total was -20.0. running mean: -18.727764121541124, timestamp: 2022-08-19 22:43:18.748234\n",
      "resetting env. episode 5880, reward total was -20.0. running mean: -18.74048648032571, timestamp: 2022-08-19 22:43:21.891271\n",
      "resetting env. episode 5881, reward total was -19.0. running mean: -18.743081615522456, timestamp: 2022-08-19 22:43:26.525322\n",
      "resetting env. episode 5882, reward total was -16.0. running mean: -18.715650799367232, timestamp: 2022-08-19 22:43:29.748361\n",
      "resetting env. episode 5883, reward total was -18.0. running mean: -18.708494291373558, timestamp: 2022-08-19 22:43:34.040409\n",
      "resetting env. episode 5884, reward total was -21.0. running mean: -18.731409348459824, timestamp: 2022-08-19 22:43:37.248447\n",
      "resetting env. episode 5885, reward total was -21.0. running mean: -18.754095254975226, timestamp: 2022-08-19 22:43:40.543484\n",
      "resetting env. episode 5886, reward total was -19.0. running mean: -18.756554302425474, timestamp: 2022-08-19 22:43:43.335518\n",
      "resetting env. episode 5887, reward total was -21.0. running mean: -18.77898875940122, timestamp: 2022-08-19 22:43:45.637540\n",
      "resetting env. episode 5888, reward total was -18.0. running mean: -18.771198871807208, timestamp: 2022-08-19 22:43:49.212581\n",
      "resetting env. episode 5889, reward total was -20.0. running mean: -18.783486883089136, timestamp: 2022-08-19 22:43:52.055611\n",
      "resetting env. episode 5890, reward total was -16.0. running mean: -18.755652014258246, timestamp: 2022-08-19 22:43:55.746652\n",
      "resetting env. episode 5891, reward total was -17.0. running mean: -18.738095494115665, timestamp: 2022-08-19 22:43:59.975708\n",
      "resetting env. episode 5892, reward total was -17.0. running mean: -18.72071453917451, timestamp: 2022-08-19 22:44:03.546740\n",
      "resetting env. episode 5893, reward total was -20.0. running mean: -18.733507393782762, timestamp: 2022-08-19 22:44:06.685778\n",
      "resetting env. episode 5894, reward total was -20.0. running mean: -18.746172319844934, timestamp: 2022-08-19 22:44:08.979802\n",
      "resetting env. episode 5895, reward total was -21.0. running mean: -18.768710596646486, timestamp: 2022-08-19 22:44:12.109841\n",
      "resetting env. episode 5896, reward total was -18.0. running mean: -18.76102349068002, timestamp: 2022-08-19 22:44:15.699881\n",
      "resetting env. episode 5897, reward total was -21.0. running mean: -18.783413255773223, timestamp: 2022-08-19 22:44:19.369923\n",
      "resetting env. episode 5898, reward total was -20.0. running mean: -18.79557912321549, timestamp: 2022-08-19 22:44:22.459958\n",
      "resetting env. episode 5899, reward total was -19.0. running mean: -18.797623331983335, timestamp: 2022-08-19 22:44:26.091995\n",
      "resetting env. episode 5900, reward total was -21.0. running mean: -18.819647098663502, timestamp: 2022-08-19 22:44:29.129029\n",
      "resetting env. episode 5901, reward total was -19.0. running mean: -18.821450627676867, timestamp: 2022-08-19 22:44:33.114074\n",
      "resetting env. episode 5902, reward total was -16.0. running mean: -18.7932361214001, timestamp: 2022-08-19 22:44:36.673119\n",
      "resetting env. episode 5903, reward total was -19.0. running mean: -18.795303760186098, timestamp: 2022-08-19 22:44:40.643161\n",
      "resetting env. episode 5904, reward total was -20.0. running mean: -18.807350722584236, timestamp: 2022-08-19 22:44:43.866197\n",
      "resetting env. episode 5905, reward total was -21.0. running mean: -18.829277215358395, timestamp: 2022-08-19 22:44:47.336243\n",
      "resetting env. episode 5906, reward total was -16.0. running mean: -18.80098444320481, timestamp: 2022-08-19 22:44:50.623274\n",
      "resetting env. episode 5907, reward total was -18.0. running mean: -18.792974598772762, timestamp: 2022-08-19 22:44:54.399318\n",
      "resetting env. episode 5908, reward total was -17.0. running mean: -18.775044852785037, timestamp: 2022-08-19 22:44:58.181359\n",
      "resetting env. episode 5909, reward total was -12.0. running mean: -18.707294404257187, timestamp: 2022-08-19 22:45:02.733410\n",
      "resetting env. episode 5910, reward total was -19.0. running mean: -18.710221460214616, timestamp: 2022-08-19 22:45:06.025445\n",
      "resetting env. episode 5911, reward total was -20.0. running mean: -18.72311924561247, timestamp: 2022-08-19 22:45:09.155485\n",
      "resetting env. episode 5912, reward total was -21.0. running mean: -18.745888053156346, timestamp: 2022-08-19 22:45:12.721524\n",
      "resetting env. episode 5913, reward total was -14.0. running mean: -18.69842917262478, timestamp: 2022-08-19 22:45:17.365575\n",
      "resetting env. episode 5914, reward total was -17.0. running mean: -18.681444880898535, timestamp: 2022-08-19 22:45:21.109621\n",
      "resetting env. episode 5915, reward total was -17.0. running mean: -18.664630432089552, timestamp: 2022-08-19 22:45:24.460656\n",
      "resetting env. episode 5916, reward total was -19.0. running mean: -18.66798412776866, timestamp: 2022-08-19 22:45:28.035700\n",
      "resetting env. episode 5917, reward total was -18.0. running mean: -18.66130428649097, timestamp: 2022-08-19 22:45:32.109743\n",
      "resetting env. episode 5918, reward total was -21.0. running mean: -18.684691243626062, timestamp: 2022-08-19 22:45:34.909775\n",
      "resetting env. episode 5919, reward total was -16.0. running mean: -18.657844331189803, timestamp: 2022-08-19 22:45:38.824816\n",
      "resetting env. episode 5920, reward total was -18.0. running mean: -18.651265887877905, timestamp: 2022-08-19 22:45:41.807851\n",
      "resetting env. episode 5921, reward total was -21.0. running mean: -18.674753228999126, timestamp: 2022-08-19 22:45:46.040900\n",
      "resetting env. episode 5922, reward total was -18.0. running mean: -18.668005696709134, timestamp: 2022-08-19 22:45:49.521942\n",
      "resetting env. episode 5923, reward total was -21.0. running mean: -18.691325639742043, timestamp: 2022-08-19 22:45:52.574978\n",
      "resetting env. episode 5924, reward total was -17.0. running mean: -18.674412383344624, timestamp: 2022-08-19 22:45:55.816012\n",
      "resetting env. episode 5925, reward total was -21.0. running mean: -18.69766825951118, timestamp: 2022-08-19 22:45:59.225051\n",
      "resetting env. episode 5926, reward total was -17.0. running mean: -18.680691576916068, timestamp: 2022-08-19 22:46:02.936097\n",
      "resetting env. episode 5927, reward total was -20.0. running mean: -18.693884661146907, timestamp: 2022-08-19 22:46:05.707125\n",
      "resetting env. episode 5928, reward total was -19.0. running mean: -18.69694581453544, timestamp: 2022-08-19 22:46:08.377152\n",
      "resetting env. episode 5929, reward total was -21.0. running mean: -18.719976356390085, timestamp: 2022-08-19 22:46:10.888180\n",
      "resetting env. episode 5930, reward total was -19.0. running mean: -18.722776592826186, timestamp: 2022-08-19 22:46:15.133231\n",
      "resetting env. episode 5931, reward total was -19.0. running mean: -18.725548826897924, timestamp: 2022-08-19 22:46:18.883274\n",
      "resetting env. episode 5932, reward total was -17.0. running mean: -18.70829333862895, timestamp: 2022-08-19 22:46:22.841316\n",
      "resetting env. episode 5933, reward total was -18.0. running mean: -18.70121040524266, timestamp: 2022-08-19 22:46:27.113368\n",
      "resetting env. episode 5934, reward total was -18.0. running mean: -18.69419830119023, timestamp: 2022-08-19 22:46:30.780408\n",
      "resetting env. episode 5935, reward total was -19.0. running mean: -18.69725631817833, timestamp: 2022-08-19 22:46:34.468450\n",
      "resetting env. episode 5936, reward total was -20.0. running mean: -18.710283754996546, timestamp: 2022-08-19 22:46:37.359479\n",
      "resetting env. episode 5937, reward total was -18.0. running mean: -18.70318091744658, timestamp: 2022-08-19 22:46:39.908507\n",
      "resetting env. episode 5938, reward total was -18.0. running mean: -18.696149108272113, timestamp: 2022-08-19 22:46:43.427548\n",
      "resetting env. episode 5939, reward total was -14.0. running mean: -18.649187617189394, timestamp: 2022-08-19 22:46:47.475595\n",
      "resetting env. episode 5940, reward total was -19.0. running mean: -18.652695741017503, timestamp: 2022-08-19 22:46:51.067633\n",
      "resetting env. episode 5941, reward total was -20.0. running mean: -18.666168783607326, timestamp: 2022-08-19 22:46:54.413672\n",
      "resetting env. episode 5942, reward total was -18.0. running mean: -18.65950709577125, timestamp: 2022-08-19 22:46:57.060701\n",
      "resetting env. episode 5943, reward total was -19.0. running mean: -18.66291202481354, timestamp: 2022-08-19 22:47:00.419739\n",
      "resetting env. episode 5944, reward total was -20.0. running mean: -18.676282904565404, timestamp: 2022-08-19 22:47:03.351776\n",
      "resetting env. episode 5945, reward total was -17.0. running mean: -18.65952007551975, timestamp: 2022-08-19 22:47:07.705822\n",
      "resetting env. episode 5946, reward total was -19.0. running mean: -18.662924874764556, timestamp: 2022-08-19 22:47:11.127860\n",
      "resetting env. episode 5947, reward total was -21.0. running mean: -18.68629562601691, timestamp: 2022-08-19 22:47:14.245896\n",
      "resetting env. episode 5948, reward total was -18.0. running mean: -18.679432669756743, timestamp: 2022-08-19 22:47:18.014947\n",
      "resetting env. episode 5949, reward total was -19.0. running mean: -18.682638343059175, timestamp: 2022-08-19 22:47:21.405977\n",
      "resetting env. episode 5950, reward total was -21.0. running mean: -18.705811959628583, timestamp: 2022-08-19 22:47:24.755017\n",
      "resetting env. episode 5951, reward total was -19.0. running mean: -18.708753840032298, timestamp: 2022-08-19 22:47:28.100056\n",
      "resetting env. episode 5952, reward total was -19.0. running mean: -18.711666301631976, timestamp: 2022-08-19 22:47:31.115085\n",
      "resetting env. episode 5953, reward total was -20.0. running mean: -18.724549638615656, timestamp: 2022-08-19 22:47:35.013132\n",
      "resetting env. episode 5954, reward total was -19.0. running mean: -18.7273041422295, timestamp: 2022-08-19 22:47:38.527170\n",
      "resetting env. episode 5955, reward total was -21.0. running mean: -18.750031100807206, timestamp: 2022-08-19 22:47:41.767213\n",
      "resetting env. episode 5956, reward total was -15.0. running mean: -18.712530789799132, timestamp: 2022-08-19 22:47:46.169255\n",
      "resetting env. episode 5957, reward total was -17.0. running mean: -18.695405481901144, timestamp: 2022-08-19 22:47:50.460307\n",
      "resetting env. episode 5958, reward total was -19.0. running mean: -18.698451427082134, timestamp: 2022-08-19 22:47:53.859344\n",
      "resetting env. episode 5959, reward total was -19.0. running mean: -18.701466912811313, timestamp: 2022-08-19 22:47:57.727387\n",
      "resetting env. episode 5960, reward total was -20.0. running mean: -18.714452243683198, timestamp: 2022-08-19 22:48:00.292416\n",
      "resetting env. episode 5961, reward total was -21.0. running mean: -18.737307721246367, timestamp: 2022-08-19 22:48:03.618456\n",
      "resetting env. episode 5962, reward total was -18.0. running mean: -18.729934644033904, timestamp: 2022-08-19 22:48:07.044492\n",
      "resetting env. episode 5963, reward total was -20.0. running mean: -18.742635297593562, timestamp: 2022-08-19 22:48:10.466533\n",
      "resetting env. episode 5964, reward total was -18.0. running mean: -18.735208944617625, timestamp: 2022-08-19 22:48:14.087578\n",
      "resetting env. episode 5965, reward total was -17.0. running mean: -18.71785685517145, timestamp: 2022-08-19 22:48:18.446622\n",
      "resetting env. episode 5966, reward total was -21.0. running mean: -18.740678286619737, timestamp: 2022-08-19 22:48:20.648649\n",
      "resetting env. episode 5967, reward total was -20.0. running mean: -18.75327150375354, timestamp: 2022-08-19 22:48:24.156690\n",
      "resetting env. episode 5968, reward total was -19.0. running mean: -18.755738788716005, timestamp: 2022-08-19 22:48:27.507723\n",
      "resetting env. episode 5969, reward total was -19.0. running mean: -18.758181400828846, timestamp: 2022-08-19 22:48:29.948750\n",
      "resetting env. episode 5970, reward total was -16.0. running mean: -18.730599586820556, timestamp: 2022-08-19 22:48:34.202798\n",
      "resetting env. episode 5971, reward total was -21.0. running mean: -18.753293590952353, timestamp: 2022-08-19 22:48:37.885841\n",
      "resetting env. episode 5972, reward total was -19.0. running mean: -18.75576065504283, timestamp: 2022-08-19 22:48:42.104889\n",
      "resetting env. episode 5973, reward total was -21.0. running mean: -18.778203048492404, timestamp: 2022-08-19 22:48:45.051925\n",
      "resetting env. episode 5974, reward total was -18.0. running mean: -18.77042101800748, timestamp: 2022-08-19 22:48:47.792955\n",
      "resetting env. episode 5975, reward total was -18.0. running mean: -18.762716807827402, timestamp: 2022-08-19 22:48:51.330996\n",
      "resetting env. episode 5976, reward total was -17.0. running mean: -18.74508963974913, timestamp: 2022-08-19 22:48:54.842035\n",
      "resetting env. episode 5977, reward total was -18.0. running mean: -18.73763874335164, timestamp: 2022-08-19 22:48:58.559075\n",
      "resetting env. episode 5978, reward total was -20.0. running mean: -18.75026235591812, timestamp: 2022-08-19 22:49:02.298119\n",
      "resetting env. episode 5979, reward total was -18.0. running mean: -18.74275973235894, timestamp: 2022-08-19 22:49:05.472158\n",
      "resetting env. episode 5980, reward total was -18.0. running mean: -18.73533213503535, timestamp: 2022-08-19 22:49:08.876192\n",
      "resetting env. episode 5981, reward total was -17.0. running mean: -18.717978813684997, timestamp: 2022-08-19 22:49:12.371234\n",
      "resetting env. episode 5982, reward total was -19.0. running mean: -18.72079902554815, timestamp: 2022-08-19 22:49:16.292278\n",
      "resetting env. episode 5983, reward total was -18.0. running mean: -18.71359103529267, timestamp: 2022-08-19 22:49:19.748315\n",
      "resetting env. episode 5984, reward total was -20.0. running mean: -18.726455124939744, timestamp: 2022-08-19 22:49:23.004354\n",
      "resetting env. episode 5985, reward total was -19.0. running mean: -18.729190573690346, timestamp: 2022-08-19 22:49:27.105399\n",
      "resetting env. episode 5986, reward total was -19.0. running mean: -18.731898667953445, timestamp: 2022-08-19 22:49:30.659441\n",
      "resetting env. episode 5987, reward total was -17.0. running mean: -18.71457968127391, timestamp: 2022-08-19 22:49:34.453481\n",
      "resetting env. episode 5988, reward total was -19.0. running mean: -18.717433884461173, timestamp: 2022-08-19 22:49:38.040523\n",
      "resetting env. episode 5989, reward total was -21.0. running mean: -18.74025954561656, timestamp: 2022-08-19 22:49:41.699561\n",
      "resetting env. episode 5990, reward total was -18.0. running mean: -18.732856950160393, timestamp: 2022-08-19 22:49:45.348603\n",
      "resetting env. episode 5991, reward total was -19.0. running mean: -18.73552838065879, timestamp: 2022-08-19 22:49:48.024635\n",
      "resetting env. episode 5992, reward total was -20.0. running mean: -18.7481730968522, timestamp: 2022-08-19 22:49:51.708677\n",
      "resetting env. episode 5993, reward total was -19.0. running mean: -18.75069136588368, timestamp: 2022-08-19 22:49:55.573718\n",
      "resetting env. episode 5994, reward total was -20.0. running mean: -18.76318445222484, timestamp: 2022-08-19 22:49:58.804752\n",
      "resetting env. episode 5995, reward total was -18.0. running mean: -18.755552607702594, timestamp: 2022-08-19 22:50:02.885798\n",
      "resetting env. episode 5996, reward total was -17.0. running mean: -18.73799708162557, timestamp: 2022-08-19 22:50:07.213847\n",
      "resetting env. episode 5997, reward total was -19.0. running mean: -18.740617110809314, timestamp: 2022-08-19 22:50:10.888888\n",
      "resetting env. episode 5998, reward total was -17.0. running mean: -18.72321093970122, timestamp: 2022-08-19 22:50:15.204936\n",
      "resetting env. episode 5999, reward total was -18.0. running mean: -18.71597883030421, timestamp: 2022-08-19 22:50:19.153984\n",
      "resetting env. episode 6000, reward total was -21.0. running mean: -18.738819042001168, timestamp: 2022-08-19 22:50:23.290117\n",
      "resetting env. episode 6001, reward total was -21.0. running mean: -18.761430851581157, timestamp: 2022-08-19 22:50:27.046068\n",
      "resetting env. episode 6002, reward total was -19.0. running mean: -18.763816543065346, timestamp: 2022-08-19 22:50:31.165117\n",
      "resetting env. episode 6003, reward total was -19.0. running mean: -18.766178377634695, timestamp: 2022-08-19 22:50:35.478167\n",
      "resetting env. episode 6004, reward total was -18.0. running mean: -18.75851659385835, timestamp: 2022-08-19 22:50:38.736199\n",
      "resetting env. episode 6005, reward total was -18.0. running mean: -18.750931427919767, timestamp: 2022-08-19 22:50:42.819245\n",
      "resetting env. episode 6006, reward total was -21.0. running mean: -18.77342211364057, timestamp: 2022-08-19 22:50:45.930284\n",
      "resetting env. episode 6007, reward total was -21.0. running mean: -18.795687892504166, timestamp: 2022-08-19 22:50:49.471320\n",
      "resetting env. episode 6008, reward total was -17.0. running mean: -18.777731013579125, timestamp: 2022-08-19 22:50:53.257361\n",
      "resetting env. episode 6009, reward total was -19.0. running mean: -18.779953703443333, timestamp: 2022-08-19 22:50:56.439399\n",
      "resetting env. episode 6010, reward total was -20.0. running mean: -18.7921541664089, timestamp: 2022-08-19 22:50:59.361436\n",
      "resetting env. episode 6011, reward total was -21.0. running mean: -18.81423262474481, timestamp: 2022-08-19 22:51:02.920473\n",
      "resetting env. episode 6012, reward total was -20.0. running mean: -18.826090298497363, timestamp: 2022-08-19 22:51:05.954506\n",
      "resetting env. episode 6013, reward total was -20.0. running mean: -18.837829395512387, timestamp: 2022-08-19 22:51:08.916540\n",
      "resetting env. episode 6014, reward total was -17.0. running mean: -18.819451101557263, timestamp: 2022-08-19 22:51:11.854569\n",
      "resetting env. episode 6015, reward total was -20.0. running mean: -18.831256590541688, timestamp: 2022-08-19 22:51:15.691616\n",
      "resetting env. episode 6016, reward total was -21.0. running mean: -18.852944024636273, timestamp: 2022-08-19 22:51:18.617647\n",
      "resetting env. episode 6017, reward total was -20.0. running mean: -18.86441458438991, timestamp: 2022-08-19 22:51:22.701696\n",
      "resetting env. episode 6018, reward total was -17.0. running mean: -18.845770438546012, timestamp: 2022-08-19 22:51:26.572736\n",
      "resetting env. episode 6019, reward total was -15.0. running mean: -18.80731273416055, timestamp: 2022-08-19 22:51:30.657781\n",
      "resetting env. episode 6020, reward total was -19.0. running mean: -18.809239606818945, timestamp: 2022-08-19 22:51:33.862816\n",
      "resetting env. episode 6021, reward total was -21.0. running mean: -18.831147210750757, timestamp: 2022-08-19 22:51:36.981857\n",
      "resetting env. episode 6022, reward total was -19.0. running mean: -18.83283573864325, timestamp: 2022-08-19 22:51:40.086887\n",
      "resetting env. episode 6023, reward total was -21.0. running mean: -18.85450738125682, timestamp: 2022-08-19 22:51:43.289924\n",
      "resetting env. episode 6024, reward total was -18.0. running mean: -18.84596230744425, timestamp: 2022-08-19 22:51:48.140981\n",
      "resetting env. episode 6025, reward total was -17.0. running mean: -18.827502684369808, timestamp: 2022-08-19 22:51:51.026012\n",
      "resetting env. episode 6026, reward total was -20.0. running mean: -18.83922765752611, timestamp: 2022-08-19 22:51:54.514047\n",
      "resetting env. episode 6027, reward total was -20.0. running mean: -18.850835380950848, timestamp: 2022-08-19 22:51:57.369082\n",
      "resetting env. episode 6028, reward total was -20.0. running mean: -18.862327027141337, timestamp: 2022-08-19 22:52:00.273113\n",
      "resetting env. episode 6029, reward total was -19.0. running mean: -18.863703756869924, timestamp: 2022-08-19 22:52:04.145153\n",
      "resetting env. episode 6030, reward total was -19.0. running mean: -18.865066719301225, timestamp: 2022-08-19 22:52:08.248200\n",
      "resetting env. episode 6031, reward total was -16.0. running mean: -18.836416052108213, timestamp: 2022-08-19 22:52:11.819244\n",
      "resetting env. episode 6032, reward total was -18.0. running mean: -18.82805189158713, timestamp: 2022-08-19 22:52:14.778275\n",
      "resetting env. episode 6033, reward total was -20.0. running mean: -18.839771372671258, timestamp: 2022-08-19 22:52:17.923310\n",
      "resetting env. episode 6034, reward total was -21.0. running mean: -18.861373658944547, timestamp: 2022-08-19 22:52:21.193346\n",
      "resetting env. episode 6035, reward total was -17.0. running mean: -18.842759922355103, timestamp: 2022-08-19 22:52:24.753385\n",
      "resetting env. episode 6036, reward total was -21.0. running mean: -18.864332323131553, timestamp: 2022-08-19 22:52:27.716417\n",
      "resetting env. episode 6037, reward total was -19.0. running mean: -18.86568899990024, timestamp: 2022-08-19 22:52:31.094453\n",
      "resetting env. episode 6038, reward total was -18.0. running mean: -18.857032109901237, timestamp: 2022-08-19 22:52:34.293491\n",
      "resetting env. episode 6039, reward total was -21.0. running mean: -18.878461788802227, timestamp: 2022-08-19 22:52:37.806529\n",
      "resetting env. episode 6040, reward total was -17.0. running mean: -18.859677170914207, timestamp: 2022-08-19 22:52:42.200578\n",
      "resetting env. episode 6041, reward total was -19.0. running mean: -18.861080399205065, timestamp: 2022-08-19 22:52:45.744620\n",
      "resetting env. episode 6042, reward total was -20.0. running mean: -18.872469595213012, timestamp: 2022-08-19 22:52:49.359656\n",
      "resetting env. episode 6043, reward total was -20.0. running mean: -18.88374489926088, timestamp: 2022-08-19 22:52:52.853696\n",
      "resetting env. episode 6044, reward total was -19.0. running mean: -18.884907450268273, timestamp: 2022-08-19 22:52:56.904741\n",
      "resetting env. episode 6045, reward total was -21.0. running mean: -18.90605837576559, timestamp: 2022-08-19 22:52:59.741774\n",
      "resetting env. episode 6046, reward total was -20.0. running mean: -18.916997792007933, timestamp: 2022-08-19 22:53:03.736816\n",
      "resetting env. episode 6047, reward total was -20.0. running mean: -18.927827814087852, timestamp: 2022-08-19 22:53:06.159843\n",
      "resetting env. episode 6048, reward total was -21.0. running mean: -18.948549535946974, timestamp: 2022-08-19 22:53:09.287882\n",
      "resetting env. episode 6049, reward total was -20.0. running mean: -18.959064040587503, timestamp: 2022-08-19 22:53:13.134922\n",
      "resetting env. episode 6050, reward total was -21.0. running mean: -18.97947340018163, timestamp: 2022-08-19 22:53:16.757962\n",
      "resetting env. episode 6051, reward total was -19.0. running mean: -18.979678666179815, timestamp: 2022-08-19 22:53:20.342001\n",
      "resetting env. episode 6052, reward total was -17.0. running mean: -18.95988187951802, timestamp: 2022-08-19 22:53:23.450037\n",
      "resetting env. episode 6053, reward total was -21.0. running mean: -18.98028306072284, timestamp: 2022-08-19 22:53:27.196077\n",
      "resetting env. episode 6054, reward total was -18.0. running mean: -18.970480230115612, timestamp: 2022-08-19 22:53:30.686115\n",
      "resetting env. episode 6055, reward total was -18.0. running mean: -18.960775427814454, timestamp: 2022-08-19 22:53:33.444145\n",
      "resetting env. episode 6056, reward total was -20.0. running mean: -18.971167673536307, timestamp: 2022-08-19 22:53:37.051190\n",
      "resetting env. episode 6057, reward total was -19.0. running mean: -18.971455996800945, timestamp: 2022-08-19 22:53:40.521225\n",
      "resetting env. episode 6058, reward total was -18.0. running mean: -18.961741436832934, timestamp: 2022-08-19 22:53:44.226269\n",
      "resetting env. episode 6059, reward total was -16.0. running mean: -18.932124022464606, timestamp: 2022-08-19 22:53:48.215310\n",
      "resetting env. episode 6060, reward total was -17.0. running mean: -18.91280278223996, timestamp: 2022-08-19 22:53:51.906349\n",
      "resetting env. episode 6061, reward total was -20.0. running mean: -18.92367475441756, timestamp: 2022-08-19 22:53:55.523391\n",
      "resetting env. episode 6062, reward total was -19.0. running mean: -18.924438006873388, timestamp: 2022-08-19 22:53:58.649429\n",
      "resetting env. episode 6063, reward total was -17.0. running mean: -18.905193626804657, timestamp: 2022-08-19 22:54:02.051466\n",
      "resetting env. episode 6064, reward total was -21.0. running mean: -18.92614169053661, timestamp: 2022-08-19 22:54:04.639491\n",
      "resetting env. episode 6065, reward total was -18.0. running mean: -18.916880273631243, timestamp: 2022-08-19 22:54:08.663536\n",
      "resetting env. episode 6066, reward total was -20.0. running mean: -18.92771147089493, timestamp: 2022-08-19 22:54:12.307576\n",
      "resetting env. episode 6067, reward total was -18.0. running mean: -18.91843435618598, timestamp: 2022-08-19 22:54:15.921619\n",
      "resetting env. episode 6068, reward total was -19.0. running mean: -18.919250012624122, timestamp: 2022-08-19 22:54:19.448657\n",
      "resetting env. episode 6069, reward total was -15.0. running mean: -18.880057512497878, timestamp: 2022-08-19 22:54:23.922705\n",
      "resetting env. episode 6070, reward total was -17.0. running mean: -18.8612569373729, timestamp: 2022-08-19 22:54:27.745747\n",
      "resetting env. episode 6071, reward total was -18.0. running mean: -18.852644367999172, timestamp: 2022-08-19 22:54:31.339787\n",
      "resetting env. episode 6072, reward total was -19.0. running mean: -18.85411792431918, timestamp: 2022-08-19 22:54:34.652823\n",
      "resetting env. episode 6073, reward total was -20.0. running mean: -18.865576745075987, timestamp: 2022-08-19 22:54:39.426876\n",
      "resetting env. episode 6074, reward total was -17.0. running mean: -18.846920977625228, timestamp: 2022-08-19 22:54:42.973915\n",
      "resetting env. episode 6075, reward total was -18.0. running mean: -18.838451767848976, timestamp: 2022-08-19 22:54:46.082951\n",
      "resetting env. episode 6076, reward total was -21.0. running mean: -18.860067250170488, timestamp: 2022-08-19 22:54:48.879979\n",
      "resetting env. episode 6077, reward total was -19.0. running mean: -18.861466577668786, timestamp: 2022-08-19 22:54:52.500020\n",
      "resetting env. episode 6078, reward total was -19.0. running mean: -18.8628519118921, timestamp: 2022-08-19 22:54:55.630053\n",
      "resetting env. episode 6079, reward total was -18.0. running mean: -18.85422339277318, timestamp: 2022-08-19 22:54:59.337095\n",
      "resetting env. episode 6080, reward total was -20.0. running mean: -18.865681158845447, timestamp: 2022-08-19 22:55:02.878133\n",
      "resetting env. episode 6081, reward total was -17.0. running mean: -18.847024347256994, timestamp: 2022-08-19 22:55:06.323173\n",
      "resetting env. episode 6082, reward total was -20.0. running mean: -18.858554103784424, timestamp: 2022-08-19 22:55:09.687214\n",
      "resetting env. episode 6083, reward total was -19.0. running mean: -18.85996856274658, timestamp: 2022-08-19 22:55:14.821265\n",
      "resetting env. episode 6084, reward total was -21.0. running mean: -18.881368877119115, timestamp: 2022-08-19 22:55:18.189303\n",
      "resetting env. episode 6085, reward total was -17.0. running mean: -18.862555188347926, timestamp: 2022-08-19 22:55:21.692342\n",
      "resetting env. episode 6086, reward total was -19.0. running mean: -18.863929636464448, timestamp: 2022-08-19 22:55:25.077380\n",
      "resetting env. episode 6087, reward total was -18.0. running mean: -18.855290340099803, timestamp: 2022-08-19 22:55:28.224414\n",
      "resetting env. episode 6088, reward total was -17.0. running mean: -18.836737436698805, timestamp: 2022-08-19 22:55:31.659451\n",
      "resetting env. episode 6089, reward total was -18.0. running mean: -18.828370062331818, timestamp: 2022-08-19 22:55:35.056488\n",
      "resetting env. episode 6090, reward total was -19.0. running mean: -18.8300863617085, timestamp: 2022-08-19 22:55:38.366522\n",
      "resetting env. episode 6091, reward total was -21.0. running mean: -18.851785498091417, timestamp: 2022-08-19 22:55:41.942568\n",
      "resetting env. episode 6092, reward total was -20.0. running mean: -18.8632676431105, timestamp: 2022-08-19 22:55:44.227591\n",
      "resetting env. episode 6093, reward total was -18.0. running mean: -18.854634966679395, timestamp: 2022-08-19 22:55:47.735626\n",
      "resetting env. episode 6094, reward total was -19.0. running mean: -18.856088617012603, timestamp: 2022-08-19 22:55:51.057665\n",
      "resetting env. episode 6095, reward total was -19.0. running mean: -18.857527730842477, timestamp: 2022-08-19 22:55:54.269701\n",
      "resetting env. episode 6096, reward total was -19.0. running mean: -18.858952453534055, timestamp: 2022-08-19 22:55:57.550735\n",
      "resetting env. episode 6097, reward total was -19.0. running mean: -18.860362928998715, timestamp: 2022-08-19 22:56:01.364781\n",
      "resetting env. episode 6098, reward total was -17.0. running mean: -18.84175929970873, timestamp: 2022-08-19 22:56:05.496823\n",
      "resetting env. episode 6099, reward total was -21.0. running mean: -18.863341706711644, timestamp: 2022-08-19 22:56:08.317854\n",
      "resetting env. episode 6100, reward total was -21.0. running mean: -18.88470828964453, timestamp: 2022-08-19 22:56:11.030883\n",
      "resetting env. episode 6101, reward total was -17.0. running mean: -18.865861206748086, timestamp: 2022-08-19 22:56:14.203918\n",
      "resetting env. episode 6102, reward total was -21.0. running mean: -18.887202594680605, timestamp: 2022-08-19 22:56:17.844959\n",
      "resetting env. episode 6103, reward total was -17.0. running mean: -18.8683305687338, timestamp: 2022-08-19 22:56:21.458998\n",
      "resetting env. episode 6104, reward total was -18.0. running mean: -18.85964726304646, timestamp: 2022-08-19 22:56:24.698034\n",
      "resetting env. episode 6105, reward total was -19.0. running mean: -18.861050790415998, timestamp: 2022-08-19 22:56:27.347076\n",
      "resetting env. episode 6106, reward total was -19.0. running mean: -18.86244028251184, timestamp: 2022-08-19 22:56:30.367097\n",
      "resetting env. episode 6107, reward total was -17.0. running mean: -18.843815879686723, timestamp: 2022-08-19 22:56:34.490144\n",
      "resetting env. episode 6108, reward total was -16.0. running mean: -18.815377720889856, timestamp: 2022-08-19 22:56:39.045192\n",
      "resetting env. episode 6109, reward total was -19.0. running mean: -18.817223943680958, timestamp: 2022-08-19 22:56:42.533228\n",
      "resetting env. episode 6110, reward total was -17.0. running mean: -18.79905170424415, timestamp: 2022-08-19 22:56:47.030278\n",
      "resetting env. episode 6111, reward total was -21.0. running mean: -18.82106118720171, timestamp: 2022-08-19 22:56:49.956313\n",
      "resetting env. episode 6112, reward total was -17.0. running mean: -18.802850575329696, timestamp: 2022-08-19 22:56:53.953354\n",
      "resetting env. episode 6113, reward total was -19.0. running mean: -18.8048220695764, timestamp: 2022-08-19 22:56:57.534397\n",
      "resetting env. episode 6114, reward total was -20.0. running mean: -18.816773848880633, timestamp: 2022-08-19 22:57:00.897431\n",
      "resetting env. episode 6115, reward total was -18.0. running mean: -18.808606110391825, timestamp: 2022-08-19 22:57:04.365471\n",
      "resetting env. episode 6116, reward total was -20.0. running mean: -18.820520049287907, timestamp: 2022-08-19 22:57:07.955511\n",
      "resetting env. episode 6117, reward total was -17.0. running mean: -18.802314848795028, timestamp: 2022-08-19 22:57:11.600549\n",
      "resetting env. episode 6118, reward total was -21.0. running mean: -18.82429170030708, timestamp: 2022-08-19 22:57:15.322590\n",
      "resetting env. episode 6119, reward total was -19.0. running mean: -18.82604878330401, timestamp: 2022-08-19 22:57:18.702632\n",
      "resetting env. episode 6120, reward total was -19.0. running mean: -18.82778829547097, timestamp: 2022-08-19 22:57:22.968676\n",
      "resetting env. episode 6121, reward total was -20.0. running mean: -18.83951041251626, timestamp: 2022-08-19 22:57:26.464715\n",
      "resetting env. episode 6122, reward total was -19.0. running mean: -18.841115308391096, timestamp: 2022-08-19 22:57:30.437759\n",
      "resetting env. episode 6123, reward total was -15.0. running mean: -18.802704155307183, timestamp: 2022-08-19 22:57:34.936808\n",
      "resetting env. episode 6124, reward total was -19.0. running mean: -18.804677113754114, timestamp: 2022-08-19 22:57:38.155845\n",
      "resetting env. episode 6125, reward total was -19.0. running mean: -18.806630342616575, timestamp: 2022-08-19 22:57:41.928885\n",
      "resetting env. episode 6126, reward total was -19.0. running mean: -18.80856403919041, timestamp: 2022-08-19 22:57:45.460924\n",
      "resetting env. episode 6127, reward total was -21.0. running mean: -18.83047839879851, timestamp: 2022-08-19 22:57:49.429974\n",
      "resetting env. episode 6128, reward total was -19.0. running mean: -18.832173614810525, timestamp: 2022-08-19 22:57:52.961011\n",
      "resetting env. episode 6129, reward total was -16.0. running mean: -18.80385187866242, timestamp: 2022-08-19 22:57:56.357046\n",
      "resetting env. episode 6130, reward total was -21.0. running mean: -18.8258133598758, timestamp: 2022-08-19 22:58:00.417091\n",
      "resetting env. episode 6131, reward total was -18.0. running mean: -18.81755522627704, timestamp: 2022-08-19 22:58:04.780143\n",
      "resetting env. episode 6132, reward total was -20.0. running mean: -18.82937967401427, timestamp: 2022-08-19 22:58:08.430180\n",
      "resetting env. episode 6133, reward total was -20.0. running mean: -18.841085877274125, timestamp: 2022-08-19 22:58:11.398217\n",
      "resetting env. episode 6134, reward total was -17.0. running mean: -18.822675018501386, timestamp: 2022-08-19 22:58:15.440261\n",
      "resetting env. episode 6135, reward total was -14.0. running mean: -18.774448268316373, timestamp: 2022-08-19 22:58:20.154312\n",
      "resetting env. episode 6136, reward total was -19.0. running mean: -18.77670378563321, timestamp: 2022-08-19 22:58:23.107343\n",
      "resetting env. episode 6137, reward total was -19.0. running mean: -18.77893674777688, timestamp: 2022-08-19 22:58:26.436384\n",
      "resetting env. episode 6138, reward total was -20.0. running mean: -18.79114738029911, timestamp: 2022-08-19 22:58:30.049423\n",
      "resetting env. episode 6139, reward total was -18.0. running mean: -18.783235906496117, timestamp: 2022-08-19 22:58:33.953465\n",
      "resetting env. episode 6140, reward total was -21.0. running mean: -18.805403547431155, timestamp: 2022-08-19 22:58:37.212502\n",
      "resetting env. episode 6141, reward total was -16.0. running mean: -18.777349511956842, timestamp: 2022-08-19 22:58:40.806546\n",
      "resetting env. episode 6142, reward total was -19.0. running mean: -18.779576016837275, timestamp: 2022-08-19 22:58:44.442582\n",
      "resetting env. episode 6143, reward total was -19.0. running mean: -18.781780256668902, timestamp: 2022-08-19 22:58:48.106626\n",
      "resetting env. episode 6144, reward total was -17.0. running mean: -18.763962454102217, timestamp: 2022-08-19 22:58:52.615675\n",
      "resetting env. episode 6145, reward total was -20.0. running mean: -18.776322829561195, timestamp: 2022-08-19 22:58:55.876716\n",
      "resetting env. episode 6146, reward total was -21.0. running mean: -18.798559601265584, timestamp: 2022-08-19 22:58:59.251753\n",
      "resetting env. episode 6147, reward total was -14.0. running mean: -18.75057400525293, timestamp: 2022-08-19 22:59:05.097815\n",
      "resetting env. episode 6148, reward total was -21.0. running mean: -18.7730682652004, timestamp: 2022-08-19 22:59:08.318854\n",
      "resetting env. episode 6149, reward total was -20.0. running mean: -18.785337582548397, timestamp: 2022-08-19 22:59:11.108887\n",
      "resetting env. episode 6150, reward total was -21.0. running mean: -18.807484206722915, timestamp: 2022-08-19 22:59:14.376918\n",
      "resetting env. episode 6151, reward total was -17.0. running mean: -18.789409364655686, timestamp: 2022-08-19 22:59:18.092962\n",
      "resetting env. episode 6152, reward total was -16.0. running mean: -18.76151527100913, timestamp: 2022-08-19 22:59:21.633005\n",
      "resetting env. episode 6153, reward total was -21.0. running mean: -18.78390011829904, timestamp: 2022-08-19 22:59:25.298043\n",
      "resetting env. episode 6154, reward total was -18.0. running mean: -18.77606111711605, timestamp: 2022-08-19 22:59:28.710079\n",
      "resetting env. episode 6155, reward total was -18.0. running mean: -18.76830050594489, timestamp: 2022-08-19 22:59:32.097118\n",
      "resetting env. episode 6156, reward total was -17.0. running mean: -18.750617500885443, timestamp: 2022-08-19 22:59:35.871163\n",
      "resetting env. episode 6157, reward total was -21.0. running mean: -18.773111325876588, timestamp: 2022-08-19 22:59:39.889212\n",
      "resetting env. episode 6158, reward total was -20.0. running mean: -18.78538021261782, timestamp: 2022-08-19 22:59:42.937248\n",
      "resetting env. episode 6159, reward total was -21.0. running mean: -18.807526410491644, timestamp: 2022-08-19 22:59:45.394270\n",
      "resetting env. episode 6160, reward total was -15.0. running mean: -18.769451146386725, timestamp: 2022-08-19 22:59:50.106321\n",
      "resetting env. episode 6161, reward total was -20.0. running mean: -18.781756634922857, timestamp: 2022-08-19 22:59:53.470361\n",
      "resetting env. episode 6162, reward total was -18.0. running mean: -18.77393906857363, timestamp: 2022-08-19 22:59:57.856409\n",
      "resetting env. episode 6163, reward total was -18.0. running mean: -18.766199677887894, timestamp: 2022-08-19 23:00:01.209447\n",
      "resetting env. episode 6164, reward total was -19.0. running mean: -18.768537681109017, timestamp: 2022-08-19 23:00:04.557499\n",
      "resetting env. episode 6165, reward total was -18.0. running mean: -18.760852304297927, timestamp: 2022-08-19 23:00:08.619532\n",
      "resetting env. episode 6166, reward total was -20.0. running mean: -18.773243781254948, timestamp: 2022-08-19 23:00:11.687566\n",
      "resetting env. episode 6167, reward total was -16.0. running mean: -18.7455113434424, timestamp: 2022-08-19 23:00:15.239609\n",
      "resetting env. episode 6168, reward total was -20.0. running mean: -18.758056230007973, timestamp: 2022-08-19 23:00:18.931649\n",
      "resetting env. episode 6169, reward total was -19.0. running mean: -18.760475667707894, timestamp: 2022-08-19 23:00:22.304688\n",
      "resetting env. episode 6170, reward total was -20.0. running mean: -18.772870911030815, timestamp: 2022-08-19 23:00:25.601723\n",
      "resetting env. episode 6171, reward total was -20.0. running mean: -18.785142201920504, timestamp: 2022-08-19 23:00:29.671776\n",
      "resetting env. episode 6172, reward total was -20.0. running mean: -18.7972907799013, timestamp: 2022-08-19 23:00:32.726804\n",
      "resetting env. episode 6173, reward total was -18.0. running mean: -18.789317872102284, timestamp: 2022-08-19 23:00:37.379862\n",
      "resetting env. episode 6174, reward total was -19.0. running mean: -18.791424693381263, timestamp: 2022-08-19 23:00:40.527893\n",
      "resetting env. episode 6175, reward total was -17.0. running mean: -18.773510446447453, timestamp: 2022-08-19 23:00:44.439936\n",
      "resetting env. episode 6176, reward total was -18.0. running mean: -18.765775341982977, timestamp: 2022-08-19 23:00:47.297970\n",
      "resetting env. episode 6177, reward total was -21.0. running mean: -18.788117588563146, timestamp: 2022-08-19 23:00:51.411015\n",
      "resetting env. episode 6178, reward total was -18.0. running mean: -18.780236412677514, timestamp: 2022-08-19 23:00:54.909056\n",
      "resetting env. episode 6179, reward total was -18.0. running mean: -18.77243404855074, timestamp: 2022-08-19 23:00:58.516094\n",
      "resetting env. episode 6180, reward total was -19.0. running mean: -18.774709708065235, timestamp: 2022-08-19 23:01:02.115134\n",
      "resetting env. episode 6181, reward total was -17.0. running mean: -18.756962610984584, timestamp: 2022-08-19 23:01:06.431186\n",
      "resetting env. episode 6182, reward total was -17.0. running mean: -18.73939298487474, timestamp: 2022-08-19 23:01:10.202229\n",
      "resetting env. episode 6183, reward total was -19.0. running mean: -18.741999055025993, timestamp: 2022-08-19 23:01:13.746267\n",
      "resetting env. episode 6184, reward total was -19.0. running mean: -18.744579064475733, timestamp: 2022-08-19 23:01:16.462301\n",
      "resetting env. episode 6185, reward total was -17.0. running mean: -18.727133273830976, timestamp: 2022-08-19 23:01:20.502345\n",
      "resetting env. episode 6186, reward total was -19.0. running mean: -18.72986194109267, timestamp: 2022-08-19 23:01:23.844383\n",
      "resetting env. episode 6187, reward total was -19.0. running mean: -18.73256332168174, timestamp: 2022-08-19 23:01:26.726416\n",
      "resetting env. episode 6188, reward total was -19.0. running mean: -18.735237688464924, timestamp: 2022-08-19 23:01:29.770448\n",
      "resetting env. episode 6189, reward total was -17.0. running mean: -18.717885311580275, timestamp: 2022-08-19 23:01:33.284486\n",
      "resetting env. episode 6190, reward total was -20.0. running mean: -18.73070645846447, timestamp: 2022-08-19 23:01:36.617525\n",
      "resetting env. episode 6191, reward total was -20.0. running mean: -18.743399393879827, timestamp: 2022-08-19 23:01:39.660566\n",
      "resetting env. episode 6192, reward total was -16.0. running mean: -18.715965399941027, timestamp: 2022-08-19 23:01:43.311601\n",
      "resetting env. episode 6193, reward total was -19.0. running mean: -18.71880574594162, timestamp: 2022-08-19 23:01:47.385651\n",
      "resetting env. episode 6194, reward total was -18.0. running mean: -18.711617688482203, timestamp: 2022-08-19 23:01:50.667684\n",
      "resetting env. episode 6195, reward total was -19.0. running mean: -18.714501511597383, timestamp: 2022-08-19 23:01:54.090725\n",
      "resetting env. episode 6196, reward total was -17.0. running mean: -18.69735649648141, timestamp: 2022-08-19 23:01:57.775765\n",
      "resetting env. episode 6197, reward total was -17.0. running mean: -18.6803829315166, timestamp: 2022-08-19 23:02:02.262816\n",
      "resetting env. episode 6198, reward total was -17.0. running mean: -18.663579102201435, timestamp: 2022-08-19 23:02:05.830859\n",
      "resetting env. episode 6199, reward total was -18.0. running mean: -18.656943311179422, timestamp: 2022-08-19 23:02:10.119908\n",
      "resetting env. episode 6200, reward total was -20.0. running mean: -18.670373878067625, timestamp: 2022-08-19 23:02:13.019937\n",
      "resetting env. episode 6201, reward total was -19.0. running mean: -18.67367013928695, timestamp: 2022-08-19 23:02:16.973985\n",
      "resetting env. episode 6202, reward total was -17.0. running mean: -18.656933437894082, timestamp: 2022-08-19 23:02:21.236031\n",
      "resetting env. episode 6203, reward total was -18.0. running mean: -18.65036410351514, timestamp: 2022-08-19 23:02:25.365077\n",
      "resetting env. episode 6204, reward total was -18.0. running mean: -18.64386046247999, timestamp: 2022-08-19 23:02:30.107132\n",
      "resetting env. episode 6205, reward total was -19.0. running mean: -18.64742185785519, timestamp: 2022-08-19 23:02:33.878177\n",
      "resetting env. episode 6206, reward total was -19.0. running mean: -18.650947639276637, timestamp: 2022-08-19 23:02:37.040212\n",
      "resetting env. episode 6207, reward total was -20.0. running mean: -18.66443816288387, timestamp: 2022-08-19 23:02:41.652260\n",
      "resetting env. episode 6208, reward total was -18.0. running mean: -18.65779378125503, timestamp: 2022-08-19 23:02:45.291303\n",
      "resetting env. episode 6209, reward total was -21.0. running mean: -18.68121584344248, timestamp: 2022-08-19 23:02:48.704344\n",
      "resetting env. episode 6210, reward total was -21.0. running mean: -18.704403685008057, timestamp: 2022-08-19 23:02:52.259383\n",
      "resetting env. episode 6211, reward total was -15.0. running mean: -18.667359648157973, timestamp: 2022-08-19 23:02:56.650430\n",
      "resetting env. episode 6212, reward total was -17.0. running mean: -18.650686051676395, timestamp: 2022-08-19 23:03:00.140470\n",
      "resetting env. episode 6213, reward total was -14.0. running mean: -18.60417919115963, timestamp: 2022-08-19 23:03:04.918524\n",
      "resetting env. episode 6214, reward total was -18.0. running mean: -18.598137399248035, timestamp: 2022-08-19 23:03:08.965569\n",
      "resetting env. episode 6215, reward total was -15.0. running mean: -18.562156025255554, timestamp: 2022-08-19 23:03:12.786616\n",
      "resetting env. episode 6216, reward total was -20.0. running mean: -18.576534465002997, timestamp: 2022-08-19 23:03:15.650646\n",
      "resetting env. episode 6217, reward total was -19.0. running mean: -18.58076912035297, timestamp: 2022-08-19 23:03:19.953696\n",
      "resetting env. episode 6218, reward total was -20.0. running mean: -18.59496142914944, timestamp: 2022-08-19 23:03:23.519732\n",
      "resetting env. episode 6219, reward total was -20.0. running mean: -18.609011814857944, timestamp: 2022-08-19 23:03:26.755771\n",
      "resetting env. episode 6220, reward total was -20.0. running mean: -18.622921696709362, timestamp: 2022-08-19 23:03:30.244809\n",
      "resetting env. episode 6221, reward total was -20.0. running mean: -18.63669247974227, timestamp: 2022-08-19 23:03:33.222843\n",
      "resetting env. episode 6222, reward total was -19.0. running mean: -18.640325554944848, timestamp: 2022-08-19 23:03:37.039888\n",
      "resetting env. episode 6223, reward total was -19.0. running mean: -18.6439222993954, timestamp: 2022-08-19 23:03:40.985931\n",
      "resetting env. episode 6224, reward total was -17.0. running mean: -18.627483076401447, timestamp: 2022-08-19 23:03:45.162982\n",
      "resetting env. episode 6225, reward total was -17.0. running mean: -18.611208245637435, timestamp: 2022-08-19 23:03:49.591029\n",
      "resetting env. episode 6226, reward total was -20.0. running mean: -18.62509616318106, timestamp: 2022-08-19 23:03:53.661074\n",
      "resetting env. episode 6227, reward total was -11.0. running mean: -18.54884520154925, timestamp: 2022-08-19 23:03:59.179136\n",
      "resetting env. episode 6228, reward total was -21.0. running mean: -18.573356749533758, timestamp: 2022-08-19 23:04:02.213183\n",
      "resetting env. episode 6229, reward total was -18.0. running mean: -18.56762318203842, timestamp: 2022-08-19 23:04:05.913213\n",
      "resetting env. episode 6230, reward total was -17.0. running mean: -18.55194695021804, timestamp: 2022-08-19 23:04:09.541253\n",
      "resetting env. episode 6231, reward total was -20.0. running mean: -18.566427480715856, timestamp: 2022-08-19 23:04:12.631289\n",
      "resetting env. episode 6232, reward total was -17.0. running mean: -18.550763205908698, timestamp: 2022-08-19 23:04:16.182332\n",
      "resetting env. episode 6233, reward total was -20.0. running mean: -18.565255573849612, timestamp: 2022-08-19 23:04:19.793369\n",
      "resetting env. episode 6234, reward total was -17.0. running mean: -18.549603018111117, timestamp: 2022-08-19 23:04:22.864404\n",
      "resetting env. episode 6235, reward total was -19.0. running mean: -18.55410698793001, timestamp: 2022-08-19 23:04:26.154445\n",
      "resetting env. episode 6236, reward total was -20.0. running mean: -18.56856591805071, timestamp: 2022-08-19 23:04:29.540479\n",
      "resetting env. episode 6237, reward total was -20.0. running mean: -18.5828802588702, timestamp: 2022-08-19 23:04:33.112523\n",
      "resetting env. episode 6238, reward total was -18.0. running mean: -18.5770514562815, timestamp: 2022-08-19 23:04:36.108559\n",
      "resetting env. episode 6239, reward total was -21.0. running mean: -18.601280941718684, timestamp: 2022-08-19 23:04:39.108588\n",
      "resetting env. episode 6240, reward total was -12.0. running mean: -18.5352681323015, timestamp: 2022-08-19 23:04:42.972635\n",
      "resetting env. episode 6241, reward total was -17.0. running mean: -18.519915450978488, timestamp: 2022-08-19 23:04:46.580672\n",
      "resetting env. episode 6242, reward total was -18.0. running mean: -18.514716296468702, timestamp: 2022-08-19 23:04:50.156713\n",
      "resetting env. episode 6243, reward total was -19.0. running mean: -18.519569133504017, timestamp: 2022-08-19 23:04:53.706753\n",
      "resetting env. episode 6244, reward total was -20.0. running mean: -18.534373442168977, timestamp: 2022-08-19 23:04:57.119791\n",
      "resetting env. episode 6245, reward total was -21.0. running mean: -18.55902970774729, timestamp: 2022-08-19 23:05:01.213837\n",
      "resetting env. episode 6246, reward total was -17.0. running mean: -18.54343941066982, timestamp: 2022-08-19 23:05:05.091881\n",
      "resetting env. episode 6247, reward total was -20.0. running mean: -18.55800501656312, timestamp: 2022-08-19 23:05:08.514921\n",
      "resetting env. episode 6248, reward total was -19.0. running mean: -18.56242496639749, timestamp: 2022-08-19 23:05:12.212961\n",
      "resetting env. episode 6249, reward total was -21.0. running mean: -18.586800716733517, timestamp: 2022-08-19 23:05:15.189997\n",
      "resetting env. episode 6250, reward total was -17.0. running mean: -18.570932709566183, timestamp: 2022-08-19 23:05:19.480045\n",
      "resetting env. episode 6251, reward total was -19.0. running mean: -18.575223382470522, timestamp: 2022-08-19 23:05:23.140087\n",
      "resetting env. episode 6252, reward total was -17.0. running mean: -18.55947114864582, timestamp: 2022-08-19 23:05:26.250121\n",
      "resetting env. episode 6253, reward total was -16.0. running mean: -18.53387643715936, timestamp: 2022-08-19 23:05:30.538170\n",
      "resetting env. episode 6254, reward total was -21.0. running mean: -18.558537672787768, timestamp: 2022-08-19 23:05:34.101211\n",
      "resetting env. episode 6255, reward total was -18.0. running mean: -18.55295229605989, timestamp: 2022-08-19 23:05:37.866255\n",
      "resetting env. episode 6256, reward total was -19.0. running mean: -18.55742277309929, timestamp: 2022-08-19 23:05:42.876312\n",
      "resetting env. episode 6257, reward total was -21.0. running mean: -18.5818485453683, timestamp: 2022-08-19 23:05:46.579350\n",
      "resetting env. episode 6258, reward total was -17.0. running mean: -18.566030059914617, timestamp: 2022-08-19 23:05:50.511396\n",
      "resetting env. episode 6259, reward total was -17.0. running mean: -18.550369759315473, timestamp: 2022-08-19 23:05:53.740432\n",
      "resetting env. episode 6260, reward total was -18.0. running mean: -18.544866061722317, timestamp: 2022-08-19 23:05:57.350471\n",
      "resetting env. episode 6261, reward total was -14.0. running mean: -18.499417401105095, timestamp: 2022-08-19 23:06:01.588522\n",
      "resetting env. episode 6262, reward total was -19.0. running mean: -18.504423227094044, timestamp: 2022-08-19 23:06:05.268561\n",
      "resetting env. episode 6263, reward total was -19.0. running mean: -18.509378994823106, timestamp: 2022-08-19 23:06:09.651612\n",
      "resetting env. episode 6264, reward total was -18.0. running mean: -18.504285204874876, timestamp: 2022-08-19 23:06:13.225650\n",
      "resetting env. episode 6265, reward total was -19.0. running mean: -18.509242352826128, timestamp: 2022-08-19 23:06:16.312689\n",
      "resetting env. episode 6266, reward total was -18.0. running mean: -18.504149929297867, timestamp: 2022-08-19 23:06:19.496724\n",
      "resetting env. episode 6267, reward total was -19.0. running mean: -18.50910843000489, timestamp: 2022-08-19 23:06:23.291766\n",
      "resetting env. episode 6268, reward total was -16.0. running mean: -18.484017345704842, timestamp: 2022-08-19 23:06:27.526813\n",
      "resetting env. episode 6269, reward total was -19.0. running mean: -18.489177172247796, timestamp: 2022-08-19 23:06:30.939852\n",
      "resetting env. episode 6270, reward total was -19.0. running mean: -18.49428540052532, timestamp: 2022-08-19 23:06:34.621894\n",
      "resetting env. episode 6271, reward total was -17.0. running mean: -18.47934254652007, timestamp: 2022-08-19 23:06:38.536936\n",
      "resetting env. episode 6272, reward total was -19.0. running mean: -18.48454912105487, timestamp: 2022-08-19 23:06:42.215985\n",
      "resetting env. episode 6273, reward total was -19.0. running mean: -18.48970362984432, timestamp: 2022-08-19 23:06:46.347036\n",
      "resetting env. episode 6274, reward total was -21.0. running mean: -18.514806593545877, timestamp: 2022-08-19 23:06:49.343059\n",
      "resetting env. episode 6275, reward total was -17.0. running mean: -18.49965852761042, timestamp: 2022-08-19 23:06:53.065101\n",
      "resetting env. episode 6276, reward total was -19.0. running mean: -18.50466194233432, timestamp: 2022-08-19 23:06:57.629154\n",
      "resetting env. episode 6277, reward total was -18.0. running mean: -18.499615322910977, timestamp: 2022-08-19 23:07:01.927200\n",
      "resetting env. episode 6278, reward total was -20.0. running mean: -18.514619169681865, timestamp: 2022-08-19 23:07:05.666242\n",
      "resetting env. episode 6279, reward total was -20.0. running mean: -18.529472977985044, timestamp: 2022-08-19 23:07:09.240286\n",
      "resetting env. episode 6280, reward total was -14.0. running mean: -18.484178248205193, timestamp: 2022-08-19 23:07:12.554319\n",
      "resetting env. episode 6281, reward total was -20.0. running mean: -18.49933646572314, timestamp: 2022-08-19 23:07:15.687356\n",
      "resetting env. episode 6282, reward total was -19.0. running mean: -18.50434310106591, timestamp: 2022-08-19 23:07:18.341385\n",
      "resetting env. episode 6283, reward total was -21.0. running mean: -18.529299670055252, timestamp: 2022-08-19 23:07:22.425433\n",
      "resetting env. episode 6284, reward total was -20.0. running mean: -18.544006673354698, timestamp: 2022-08-19 23:07:25.739467\n",
      "resetting env. episode 6285, reward total was -18.0. running mean: -18.53856660662115, timestamp: 2022-08-19 23:07:28.679502\n",
      "resetting env. episode 6286, reward total was -21.0. running mean: -18.56318094055494, timestamp: 2022-08-19 23:07:31.585535\n",
      "resetting env. episode 6287, reward total was -16.0. running mean: -18.53754913114939, timestamp: 2022-08-19 23:07:35.264581\n",
      "resetting env. episode 6288, reward total was -18.0. running mean: -18.532173639837897, timestamp: 2022-08-19 23:07:39.529621\n",
      "resetting env. episode 6289, reward total was -19.0. running mean: -18.53685190343952, timestamp: 2022-08-19 23:07:43.736669\n",
      "resetting env. episode 6290, reward total was -19.0. running mean: -18.541483384405126, timestamp: 2022-08-19 23:07:47.070704\n",
      "resetting env. episode 6291, reward total was -20.0. running mean: -18.556068550561072, timestamp: 2022-08-19 23:07:51.049754\n",
      "resetting env. episode 6292, reward total was -20.0. running mean: -18.57050786505546, timestamp: 2022-08-19 23:07:55.432801\n",
      "resetting env. episode 6293, reward total was -20.0. running mean: -18.584802786404907, timestamp: 2022-08-19 23:07:58.584839\n",
      "resetting env. episode 6294, reward total was -20.0. running mean: -18.598954758540856, timestamp: 2022-08-19 23:08:02.795882\n",
      "resetting env. episode 6295, reward total was -14.0. running mean: -18.55296521095545, timestamp: 2022-08-19 23:08:06.841927\n",
      "resetting env. episode 6296, reward total was -15.0. running mean: -18.517435558845893, timestamp: 2022-08-19 23:08:11.608983\n",
      "resetting env. episode 6297, reward total was -13.0. running mean: -18.462261203257434, timestamp: 2022-08-19 23:08:16.153032\n",
      "resetting env. episode 6298, reward total was -19.0. running mean: -18.467638591224862, timestamp: 2022-08-19 23:08:18.954062\n",
      "resetting env. episode 6299, reward total was -15.0. running mean: -18.432962205312613, timestamp: 2022-08-19 23:08:22.818111\n",
      "resetting env. episode 6300, reward total was -19.0. running mean: -18.438632583259487, timestamp: 2022-08-19 23:08:26.552149\n",
      "resetting env. episode 6301, reward total was -18.0. running mean: -18.434246257426892, timestamp: 2022-08-19 23:08:30.281188\n",
      "resetting env. episode 6302, reward total was -19.0. running mean: -18.439903794852626, timestamp: 2022-08-19 23:08:34.740240\n",
      "resetting env. episode 6303, reward total was -18.0. running mean: -18.4355047569041, timestamp: 2022-08-19 23:08:39.157291\n",
      "resetting env. episode 6304, reward total was -18.0. running mean: -18.431149709335056, timestamp: 2022-08-19 23:08:42.412325\n",
      "resetting env. episode 6305, reward total was -20.0. running mean: -18.446838212241705, timestamp: 2022-08-19 23:08:45.635361\n",
      "resetting env. episode 6306, reward total was -15.0. running mean: -18.412369830119285, timestamp: 2022-08-19 23:08:49.062399\n",
      "resetting env. episode 6307, reward total was -19.0. running mean: -18.418246131818094, timestamp: 2022-08-19 23:08:52.526439\n",
      "resetting env. episode 6308, reward total was -19.0. running mean: -18.424063670499915, timestamp: 2022-08-19 23:08:56.493483\n",
      "resetting env. episode 6309, reward total was -19.0. running mean: -18.429823033794918, timestamp: 2022-08-19 23:09:00.383528\n",
      "resetting env. episode 6310, reward total was -16.0. running mean: -18.40552480345697, timestamp: 2022-08-19 23:09:04.883581\n",
      "resetting env. episode 6311, reward total was -18.0. running mean: -18.4014695554224, timestamp: 2022-08-19 23:09:08.501618\n",
      "resetting env. episode 6312, reward total was -19.0. running mean: -18.407454859868174, timestamp: 2022-08-19 23:09:12.088662\n",
      "resetting env. episode 6313, reward total was -17.0. running mean: -18.393380311269492, timestamp: 2022-08-19 23:09:15.908705\n",
      "resetting env. episode 6314, reward total was -16.0. running mean: -18.3694465081568, timestamp: 2022-08-19 23:09:19.780743\n",
      "resetting env. episode 6315, reward total was -21.0. running mean: -18.39575204307523, timestamp: 2022-08-19 23:09:23.292784\n",
      "resetting env. episode 6316, reward total was -18.0. running mean: -18.391794522644478, timestamp: 2022-08-19 23:09:26.579820\n",
      "resetting env. episode 6317, reward total was -19.0. running mean: -18.397876577418035, timestamp: 2022-08-19 23:09:29.513853\n",
      "resetting env. episode 6318, reward total was -20.0. running mean: -18.413897811643853, timestamp: 2022-08-19 23:09:33.047894\n",
      "resetting env. episode 6319, reward total was -18.0. running mean: -18.409758833527412, timestamp: 2022-08-19 23:09:37.066936\n",
      "resetting env. episode 6320, reward total was -20.0. running mean: -18.42566124519214, timestamp: 2022-08-19 23:09:40.373973\n",
      "resetting env. episode 6321, reward total was -20.0. running mean: -18.441404632740216, timestamp: 2022-08-19 23:09:43.291008\n",
      "resetting env. episode 6322, reward total was -19.0. running mean: -18.446990586412817, timestamp: 2022-08-19 23:09:47.114051\n",
      "resetting env. episode 6323, reward total was -17.0. running mean: -18.43252068054869, timestamp: 2022-08-19 23:09:50.894090\n",
      "resetting env. episode 6324, reward total was -21.0. running mean: -18.458195473743206, timestamp: 2022-08-19 23:09:53.640120\n",
      "resetting env. episode 6325, reward total was -17.0. running mean: -18.443613519005776, timestamp: 2022-08-19 23:09:57.571165\n",
      "resetting env. episode 6326, reward total was -17.0. running mean: -18.42917738381572, timestamp: 2022-08-19 23:10:00.910203\n",
      "resetting env. episode 6327, reward total was -16.0. running mean: -18.404885609977562, timestamp: 2022-08-19 23:10:04.743252\n",
      "resetting env. episode 6328, reward total was -16.0. running mean: -18.380836753877787, timestamp: 2022-08-19 23:10:07.972278\n",
      "resetting env. episode 6329, reward total was -21.0. running mean: -18.40702838633901, timestamp: 2022-08-19 23:10:11.482322\n",
      "resetting env. episode 6330, reward total was -16.0. running mean: -18.38295810247562, timestamp: 2022-08-19 23:10:15.161361\n",
      "resetting env. episode 6331, reward total was -14.0. running mean: -18.339128521450863, timestamp: 2022-08-19 23:10:18.576398\n",
      "resetting env. episode 6332, reward total was -15.0. running mean: -18.305737236236354, timestamp: 2022-08-19 23:10:22.923450\n",
      "resetting env. episode 6333, reward total was -17.0. running mean: -18.292679863873992, timestamp: 2022-08-19 23:10:26.517486\n",
      "resetting env. episode 6334, reward total was -17.0. running mean: -18.279753065235255, timestamp: 2022-08-19 23:10:29.667519\n",
      "resetting env. episode 6335, reward total was -20.0. running mean: -18.296955534582903, timestamp: 2022-08-19 23:10:32.286550\n",
      "resetting env. episode 6336, reward total was -18.0. running mean: -18.293985979237075, timestamp: 2022-08-19 23:10:35.714587\n",
      "resetting env. episode 6337, reward total was -17.0. running mean: -18.281046119444706, timestamp: 2022-08-19 23:10:39.476632\n",
      "resetting env. episode 6338, reward total was -18.0. running mean: -18.27823565825026, timestamp: 2022-08-19 23:10:42.998674\n",
      "resetting env. episode 6339, reward total was -18.0. running mean: -18.275453301667756, timestamp: 2022-08-19 23:10:47.064717\n",
      "resetting env. episode 6340, reward total was -20.0. running mean: -18.29269876865108, timestamp: 2022-08-19 23:10:50.470750\n",
      "resetting env. episode 6341, reward total was -18.0. running mean: -18.289771780964568, timestamp: 2022-08-19 23:10:54.011800\n",
      "resetting env. episode 6342, reward total was -18.0. running mean: -18.286874063154922, timestamp: 2022-08-19 23:10:57.550829\n",
      "resetting env. episode 6343, reward total was -18.0. running mean: -18.284005322523374, timestamp: 2022-08-19 23:11:02.074884\n",
      "resetting env. episode 6344, reward total was -18.0. running mean: -18.28116526929814, timestamp: 2022-08-19 23:11:06.363929\n",
      "resetting env. episode 6345, reward total was -21.0. running mean: -18.308353616605157, timestamp: 2022-08-19 23:11:09.550964\n",
      "resetting env. episode 6346, reward total was -14.0. running mean: -18.265270080439105, timestamp: 2022-08-19 23:11:14.258016\n",
      "resetting env. episode 6347, reward total was -19.0. running mean: -18.272617379634717, timestamp: 2022-08-19 23:11:17.741055\n",
      "resetting env. episode 6348, reward total was -20.0. running mean: -18.28989120583837, timestamp: 2022-08-19 23:11:20.783090\n",
      "resetting env. episode 6349, reward total was -15.0. running mean: -18.256992293779984, timestamp: 2022-08-19 23:11:25.270138\n",
      "resetting env. episode 6350, reward total was -21.0. running mean: -18.284422370842183, timestamp: 2022-08-19 23:11:28.814176\n",
      "resetting env. episode 6351, reward total was -21.0. running mean: -18.311578147133762, timestamp: 2022-08-19 23:11:32.477217\n",
      "resetting env. episode 6352, reward total was -18.0. running mean: -18.308462365662425, timestamp: 2022-08-19 23:11:36.572263\n",
      "resetting env. episode 6353, reward total was -21.0. running mean: -18.3353777420058, timestamp: 2022-08-19 23:11:39.890303\n",
      "resetting env. episode 6354, reward total was -17.0. running mean: -18.322023964585743, timestamp: 2022-08-19 23:11:43.635343\n",
      "resetting env. episode 6355, reward total was -20.0. running mean: -18.338803724939883, timestamp: 2022-08-19 23:11:47.546384\n",
      "resetting env. episode 6356, reward total was -20.0. running mean: -18.355415687690485, timestamp: 2022-08-19 23:11:51.099427\n",
      "resetting env. episode 6357, reward total was -20.0. running mean: -18.37186153081358, timestamp: 2022-08-19 23:11:54.556463\n",
      "resetting env. episode 6358, reward total was -16.0. running mean: -18.34814291550544, timestamp: 2022-08-19 23:11:58.215504\n",
      "resetting env. episode 6359, reward total was -18.0. running mean: -18.344661486350386, timestamp: 2022-08-19 23:12:02.297548\n",
      "resetting env. episode 6360, reward total was -19.0. running mean: -18.351214871486885, timestamp: 2022-08-19 23:12:06.131588\n",
      "resetting env. episode 6361, reward total was -19.0. running mean: -18.357702722772018, timestamp: 2022-08-19 23:12:09.651629\n",
      "resetting env. episode 6362, reward total was -21.0. running mean: -18.3841256955443, timestamp: 2022-08-19 23:12:12.634660\n",
      "resetting env. episode 6363, reward total was -19.0. running mean: -18.390284438588857, timestamp: 2022-08-19 23:12:16.396702\n",
      "resetting env. episode 6364, reward total was -17.0. running mean: -18.37638159420297, timestamp: 2022-08-19 23:12:20.419747\n",
      "resetting env. episode 6365, reward total was -18.0. running mean: -18.372617778260942, timestamp: 2022-08-19 23:12:24.181790\n",
      "resetting env. episode 6366, reward total was -21.0. running mean: -18.398891600478333, timestamp: 2022-08-19 23:12:27.172823\n",
      "resetting env. episode 6367, reward total was -15.0. running mean: -18.36490268447355, timestamp: 2022-08-19 23:12:31.582875\n",
      "resetting env. episode 6368, reward total was -17.0. running mean: -18.351253657628813, timestamp: 2022-08-19 23:12:35.533912\n",
      "resetting env. episode 6369, reward total was -20.0. running mean: -18.367741121052525, timestamp: 2022-08-19 23:12:39.292956\n",
      "resetting env. episode 6370, reward total was -21.0. running mean: -18.394063709842, timestamp: 2022-08-19 23:12:42.770995\n",
      "resetting env. episode 6371, reward total was -17.0. running mean: -18.380123072743583, timestamp: 2022-08-19 23:12:47.143041\n",
      "resetting env. episode 6372, reward total was -18.0. running mean: -18.376321842016146, timestamp: 2022-08-19 23:12:50.214074\n",
      "resetting env. episode 6373, reward total was -15.0. running mean: -18.342558623595984, timestamp: 2022-08-19 23:12:54.707125\n",
      "resetting env. episode 6374, reward total was -17.0. running mean: -18.329133037360027, timestamp: 2022-08-19 23:12:58.510167\n",
      "resetting env. episode 6375, reward total was -17.0. running mean: -18.31584170698643, timestamp: 2022-08-19 23:13:02.047204\n",
      "resetting env. episode 6376, reward total was -20.0. running mean: -18.332683289916563, timestamp: 2022-08-19 23:13:05.055242\n",
      "resetting env. episode 6377, reward total was -18.0. running mean: -18.329356457017397, timestamp: 2022-08-19 23:13:08.536276\n",
      "resetting env. episode 6378, reward total was -19.0. running mean: -18.336062892447224, timestamp: 2022-08-19 23:13:11.691313\n",
      "resetting env. episode 6379, reward total was -19.0. running mean: -18.342702263522753, timestamp: 2022-08-19 23:13:15.523356\n",
      "resetting env. episode 6380, reward total was -19.0. running mean: -18.349275240887525, timestamp: 2022-08-19 23:13:19.656397\n",
      "resetting env. episode 6381, reward total was -15.0. running mean: -18.31578248847865, timestamp: 2022-08-19 23:13:23.801445\n",
      "resetting env. episode 6382, reward total was -20.0. running mean: -18.33262466359386, timestamp: 2022-08-19 23:13:27.216482\n",
      "resetting env. episode 6383, reward total was -17.0. running mean: -18.319298416957924, timestamp: 2022-08-19 23:13:30.727521\n",
      "resetting env. episode 6384, reward total was -18.0. running mean: -18.316105432788344, timestamp: 2022-08-19 23:13:34.701564\n",
      "resetting env. episode 6385, reward total was -16.0. running mean: -18.29294437846046, timestamp: 2022-08-19 23:13:39.439617\n",
      "resetting env. episode 6386, reward total was -21.0. running mean: -18.320014934675857, timestamp: 2022-08-19 23:13:42.324649\n",
      "resetting env. episode 6387, reward total was -17.0. running mean: -18.3068147853291, timestamp: 2022-08-19 23:13:45.445683\n",
      "resetting env. episode 6388, reward total was -19.0. running mean: -18.31374663747581, timestamp: 2022-08-19 23:13:49.525725\n",
      "resetting env. episode 6389, reward total was -16.0. running mean: -18.29060917110105, timestamp: 2022-08-19 23:13:53.693777\n",
      "resetting env. episode 6390, reward total was -17.0. running mean: -18.27770307939004, timestamp: 2022-08-19 23:13:57.266811\n",
      "resetting env. episode 6391, reward total was -17.0. running mean: -18.26492604859614, timestamp: 2022-08-19 23:14:01.884863\n",
      "resetting env. episode 6392, reward total was -17.0. running mean: -18.25227678811018, timestamp: 2022-08-19 23:14:04.998896\n",
      "resetting env. episode 6393, reward total was -13.0. running mean: -18.199754020229076, timestamp: 2022-08-19 23:14:09.354947\n",
      "resetting env. episode 6394, reward total was -17.0. running mean: -18.187756480026785, timestamp: 2022-08-19 23:14:13.534991\n",
      "resetting env. episode 6395, reward total was -19.0. running mean: -18.19587891522652, timestamp: 2022-08-19 23:14:17.542035\n",
      "resetting env. episode 6396, reward total was -20.0. running mean: -18.213920126074253, timestamp: 2022-08-19 23:14:20.694069\n",
      "resetting env. episode 6397, reward total was -18.0. running mean: -18.21178092481351, timestamp: 2022-08-19 23:14:24.519113\n",
      "resetting env. episode 6398, reward total was -17.0. running mean: -18.199663115565375, timestamp: 2022-08-19 23:14:27.867149\n",
      "resetting env. episode 6399, reward total was -18.0. running mean: -18.19766648440972, timestamp: 2022-08-19 23:14:30.750187\n",
      "resetting env. episode 6400, reward total was -16.0. running mean: -18.175689819565623, timestamp: 2022-08-19 23:14:34.639224\n",
      "resetting env. episode 6401, reward total was -17.0. running mean: -18.16393292136997, timestamp: 2022-08-19 23:14:38.515271\n",
      "resetting env. episode 6402, reward total was -17.0. running mean: -18.152293592156273, timestamp: 2022-08-19 23:14:42.760318\n",
      "resetting env. episode 6403, reward total was -20.0. running mean: -18.17077065623471, timestamp: 2022-08-19 23:14:45.313345\n",
      "resetting env. episode 6404, reward total was -19.0. running mean: -18.179062949672364, timestamp: 2022-08-19 23:14:48.373379\n",
      "resetting env. episode 6405, reward total was -18.0. running mean: -18.17727232017564, timestamp: 2022-08-19 23:14:52.301422\n",
      "resetting env. episode 6406, reward total was -20.0. running mean: -18.19549959697388, timestamp: 2022-08-19 23:14:55.754460\n",
      "resetting env. episode 6407, reward total was -18.0. running mean: -18.19354460100414, timestamp: 2022-08-19 23:14:59.279499\n",
      "resetting env. episode 6408, reward total was -20.0. running mean: -18.2116091549941, timestamp: 2022-08-19 23:15:02.543534\n",
      "resetting env. episode 6409, reward total was -18.0. running mean: -18.20949306344416, timestamp: 2022-08-19 23:15:06.727581\n",
      "resetting env. episode 6410, reward total was -18.0. running mean: -18.20739813280972, timestamp: 2022-08-19 23:15:10.736628\n",
      "resetting env. episode 6411, reward total was -18.0. running mean: -18.20532415148162, timestamp: 2022-08-19 23:15:14.250664\n",
      "resetting env. episode 6412, reward total was -19.0. running mean: -18.213270909966806, timestamp: 2022-08-19 23:15:17.763708\n",
      "resetting env. episode 6413, reward total was -19.0. running mean: -18.221138200867138, timestamp: 2022-08-19 23:15:21.215745\n",
      "resetting env. episode 6414, reward total was -19.0. running mean: -18.22892681885847, timestamp: 2022-08-19 23:15:25.246789\n",
      "resetting env. episode 6415, reward total was -16.0. running mean: -18.206637550669885, timestamp: 2022-08-19 23:15:29.734839\n",
      "resetting env. episode 6416, reward total was -18.0. running mean: -18.204571175163185, timestamp: 2022-08-19 23:15:34.047888\n",
      "resetting env. episode 6417, reward total was -18.0. running mean: -18.202525463411554, timestamp: 2022-08-19 23:15:38.155932\n",
      "resetting env. episode 6418, reward total was -19.0. running mean: -18.21050020877744, timestamp: 2022-08-19 23:15:41.375967\n",
      "resetting env. episode 6419, reward total was -17.0. running mean: -18.198395206689668, timestamp: 2022-08-19 23:15:45.533015\n",
      "resetting env. episode 6420, reward total was -19.0. running mean: -18.206411254622772, timestamp: 2022-08-19 23:15:48.803050\n",
      "resetting env. episode 6421, reward total was -19.0. running mean: -18.214347142076544, timestamp: 2022-08-19 23:15:52.486096\n",
      "resetting env. episode 6422, reward total was -20.0. running mean: -18.232203670655778, timestamp: 2022-08-19 23:15:56.259135\n",
      "resetting env. episode 6423, reward total was -20.0. running mean: -18.24988163394922, timestamp: 2022-08-19 23:15:59.888179\n",
      "resetting env. episode 6424, reward total was -21.0. running mean: -18.277382817609727, timestamp: 2022-08-19 23:16:04.146224\n",
      "resetting env. episode 6425, reward total was -21.0. running mean: -18.304608989433632, timestamp: 2022-08-19 23:16:08.306272\n",
      "resetting env. episode 6426, reward total was -18.0. running mean: -18.301562899539295, timestamp: 2022-08-19 23:16:12.133313\n",
      "resetting env. episode 6427, reward total was -19.0. running mean: -18.308547270543905, timestamp: 2022-08-19 23:16:15.237347\n",
      "resetting env. episode 6428, reward total was -17.0. running mean: -18.295461797838467, timestamp: 2022-08-19 23:16:18.144381\n",
      "resetting env. episode 6429, reward total was -18.0. running mean: -18.29250717986008, timestamp: 2022-08-19 23:16:21.670422\n",
      "resetting env. episode 6430, reward total was -19.0. running mean: -18.299582108061482, timestamp: 2022-08-19 23:16:25.145458\n",
      "resetting env. episode 6431, reward total was -19.0. running mean: -18.30658628698087, timestamp: 2022-08-19 23:16:28.790500\n",
      "resetting env. episode 6432, reward total was -16.0. running mean: -18.28352042411106, timestamp: 2022-08-19 23:16:33.203550\n",
      "resetting env. episode 6433, reward total was -19.0. running mean: -18.29068521986995, timestamp: 2022-08-19 23:16:36.481584\n",
      "resetting env. episode 6434, reward total was -18.0. running mean: -18.28777836767125, timestamp: 2022-08-19 23:16:39.989627\n",
      "resetting env. episode 6435, reward total was -19.0. running mean: -18.29490058399454, timestamp: 2022-08-19 23:16:43.726667\n",
      "resetting env. episode 6436, reward total was -21.0. running mean: -18.321951578154597, timestamp: 2022-08-19 23:16:46.992702\n",
      "resetting env. episode 6437, reward total was -21.0. running mean: -18.348732062373053, timestamp: 2022-08-19 23:16:50.551745\n",
      "resetting env. episode 6438, reward total was -15.0. running mean: -18.31524474174932, timestamp: 2022-08-19 23:16:55.494799\n",
      "resetting env. episode 6439, reward total was -19.0. running mean: -18.322092294331828, timestamp: 2022-08-19 23:16:59.027840\n",
      "resetting env. episode 6440, reward total was -18.0. running mean: -18.31887137138851, timestamp: 2022-08-19 23:17:02.396874\n",
      "resetting env. episode 6441, reward total was -21.0. running mean: -18.345682657674626, timestamp: 2022-08-19 23:17:05.748916\n",
      "resetting env. episode 6442, reward total was -20.0. running mean: -18.362225831097877, timestamp: 2022-08-19 23:17:09.565959\n",
      "resetting env. episode 6443, reward total was -17.0. running mean: -18.3486035727869, timestamp: 2022-08-19 23:17:13.621002\n",
      "resetting env. episode 6444, reward total was -21.0. running mean: -18.37511753705903, timestamp: 2022-08-19 23:17:17.235042\n",
      "resetting env. episode 6445, reward total was -19.0. running mean: -18.38136636168844, timestamp: 2022-08-19 23:17:21.181089\n",
      "resetting env. episode 6446, reward total was -18.0. running mean: -18.377552698071554, timestamp: 2022-08-19 23:17:24.387123\n",
      "resetting env. episode 6447, reward total was -21.0. running mean: -18.40377717109084, timestamp: 2022-08-19 23:17:27.653170\n",
      "resetting env. episode 6448, reward total was -19.0. running mean: -18.409739399379934, timestamp: 2022-08-19 23:17:31.186197\n",
      "resetting env. episode 6449, reward total was -21.0. running mean: -18.435642005386136, timestamp: 2022-08-19 23:17:34.125245\n",
      "resetting env. episode 6450, reward total was -17.0. running mean: -18.421285585332274, timestamp: 2022-08-19 23:17:38.261277\n",
      "resetting env. episode 6451, reward total was -21.0. running mean: -18.447072729478954, timestamp: 2022-08-19 23:17:42.068319\n",
      "resetting env. episode 6452, reward total was -21.0. running mean: -18.472602002184164, timestamp: 2022-08-19 23:17:45.261357\n",
      "resetting env. episode 6453, reward total was -20.0. running mean: -18.487875982162322, timestamp: 2022-08-19 23:17:49.050398\n",
      "resetting env. episode 6454, reward total was -15.0. running mean: -18.4529972223407, timestamp: 2022-08-19 23:17:53.376448\n",
      "resetting env. episode 6455, reward total was -19.0. running mean: -18.45846725011729, timestamp: 2022-08-19 23:17:57.024489\n",
      "resetting env. episode 6456, reward total was -20.0. running mean: -18.473882577616116, timestamp: 2022-08-19 23:18:01.056533\n",
      "resetting env. episode 6457, reward total was -15.0. running mean: -18.439143751839953, timestamp: 2022-08-19 23:18:05.549585\n",
      "resetting env. episode 6458, reward total was -20.0. running mean: -18.454752314321553, timestamp: 2022-08-19 23:18:09.359626\n",
      "resetting env. episode 6459, reward total was -17.0. running mean: -18.44020479117834, timestamp: 2022-08-19 23:18:13.145668\n",
      "resetting env. episode 6460, reward total was -13.0. running mean: -18.385802743266552, timestamp: 2022-08-19 23:18:17.804720\n",
      "resetting env. episode 6461, reward total was -19.0. running mean: -18.391944715833887, timestamp: 2022-08-19 23:18:21.262760\n",
      "resetting env. episode 6462, reward total was -18.0. running mean: -18.38802526867555, timestamp: 2022-08-19 23:18:25.216804\n",
      "resetting env. episode 6463, reward total was -14.0. running mean: -18.344145015988794, timestamp: 2022-08-19 23:18:29.125853\n",
      "resetting env. episode 6464, reward total was -19.0. running mean: -18.35070356582891, timestamp: 2022-08-19 23:18:33.450897\n",
      "resetting env. episode 6465, reward total was -19.0. running mean: -18.357196530170622, timestamp: 2022-08-19 23:18:36.322931\n",
      "resetting env. episode 6466, reward total was -19.0. running mean: -18.363624564868918, timestamp: 2022-08-19 23:18:39.541969\n",
      "resetting env. episode 6467, reward total was -14.0. running mean: -18.31998831922023, timestamp: 2022-08-19 23:18:43.828015\n",
      "resetting env. episode 6468, reward total was -19.0. running mean: -18.32678843602803, timestamp: 2022-08-19 23:18:47.044052\n",
      "resetting env. episode 6469, reward total was -18.0. running mean: -18.323520551667748, timestamp: 2022-08-19 23:18:51.512104\n",
      "resetting env. episode 6470, reward total was -17.0. running mean: -18.310285346151073, timestamp: 2022-08-19 23:18:55.553149\n",
      "resetting env. episode 6471, reward total was -17.0. running mean: -18.297182492689565, timestamp: 2022-08-19 23:18:59.388193\n",
      "resetting env. episode 6472, reward total was -18.0. running mean: -18.29421066776267, timestamp: 2022-08-19 23:19:03.442238\n",
      "resetting env. episode 6473, reward total was -19.0. running mean: -18.301268561085045, timestamp: 2022-08-19 23:19:06.739276\n",
      "resetting env. episode 6474, reward total was -17.0. running mean: -18.288255875474196, timestamp: 2022-08-19 23:19:10.209314\n",
      "resetting env. episode 6475, reward total was -21.0. running mean: -18.315373316719455, timestamp: 2022-08-19 23:19:13.142348\n",
      "resetting env. episode 6476, reward total was -14.0. running mean: -18.27221958355226, timestamp: 2022-08-19 23:19:17.831400\n",
      "resetting env. episode 6477, reward total was -21.0. running mean: -18.299497387716738, timestamp: 2022-08-19 23:19:20.918438\n",
      "resetting env. episode 6478, reward total was -19.0. running mean: -18.30650241383957, timestamp: 2022-08-19 23:19:24.791478\n",
      "resetting env. episode 6479, reward total was -19.0. running mean: -18.313437389701175, timestamp: 2022-08-19 23:19:28.616524\n",
      "resetting env. episode 6480, reward total was -17.0. running mean: -18.300303015804165, timestamp: 2022-08-19 23:19:32.407562\n",
      "resetting env. episode 6481, reward total was -19.0. running mean: -18.307299985646125, timestamp: 2022-08-19 23:19:35.953603\n",
      "resetting env. episode 6482, reward total was -19.0. running mean: -18.314226985789666, timestamp: 2022-08-19 23:19:39.256639\n",
      "resetting env. episode 6483, reward total was -17.0. running mean: -18.301084715931772, timestamp: 2022-08-19 23:19:43.107684\n",
      "resetting env. episode 6484, reward total was -19.0. running mean: -18.308073868772457, timestamp: 2022-08-19 23:19:46.998731\n",
      "resetting env. episode 6485, reward total was -19.0. running mean: -18.314993130084734, timestamp: 2022-08-19 23:19:51.465777\n",
      "resetting env. episode 6486, reward total was -18.0. running mean: -18.311843198783887, timestamp: 2022-08-19 23:19:54.783817\n",
      "resetting env. episode 6487, reward total was -19.0. running mean: -18.31872476679605, timestamp: 2022-08-19 23:19:58.001853\n",
      "resetting env. episode 6488, reward total was -21.0. running mean: -18.34553751912809, timestamp: 2022-08-19 23:20:01.429888\n",
      "resetting env. episode 6489, reward total was -15.0. running mean: -18.31208214393681, timestamp: 2022-08-19 23:20:05.194934\n",
      "resetting env. episode 6490, reward total was -21.0. running mean: -18.338961322497443, timestamp: 2022-08-19 23:20:08.123963\n",
      "resetting env. episode 6491, reward total was -19.0. running mean: -18.34557170927247, timestamp: 2022-08-19 23:20:11.711003\n",
      "resetting env. episode 6492, reward total was -16.0. running mean: -18.322115992179747, timestamp: 2022-08-19 23:20:15.150047\n",
      "resetting env. episode 6493, reward total was -21.0. running mean: -18.34889483225795, timestamp: 2022-08-19 23:20:18.085077\n",
      "resetting env. episode 6494, reward total was -20.0. running mean: -18.36540588393537, timestamp: 2022-08-19 23:20:21.011108\n",
      "resetting env. episode 6495, reward total was -19.0. running mean: -18.371751825096016, timestamp: 2022-08-19 23:20:24.951151\n",
      "resetting env. episode 6496, reward total was -17.0. running mean: -18.358034306845056, timestamp: 2022-08-19 23:20:29.094201\n",
      "resetting env. episode 6497, reward total was -17.0. running mean: -18.34445396377661, timestamp: 2022-08-19 23:20:34.267259\n",
      "resetting env. episode 6498, reward total was -15.0. running mean: -18.31100942413884, timestamp: 2022-08-19 23:20:38.938310\n",
      "resetting env. episode 6499, reward total was -18.0. running mean: -18.307899329897452, timestamp: 2022-08-19 23:20:42.634351\n",
      "resetting env. episode 6500, reward total was -16.0. running mean: -18.28482033659848, timestamp: 2022-08-19 23:20:46.487392\n",
      "resetting env. episode 6501, reward total was -17.0. running mean: -18.271972133232495, timestamp: 2022-08-19 23:20:50.635439\n",
      "resetting env. episode 6502, reward total was -17.0. running mean: -18.25925241190017, timestamp: 2022-08-19 23:20:53.980477\n",
      "resetting env. episode 6503, reward total was -15.0. running mean: -18.226659887781167, timestamp: 2022-08-19 23:20:57.953523\n",
      "resetting env. episode 6504, reward total was -20.0. running mean: -18.244393288903353, timestamp: 2022-08-19 23:21:01.671565\n",
      "resetting env. episode 6505, reward total was -18.0. running mean: -18.24194935601432, timestamp: 2022-08-19 23:21:06.244615\n",
      "resetting env. episode 6506, reward total was -14.0. running mean: -18.199529862454177, timestamp: 2022-08-19 23:21:10.093661\n",
      "resetting env. episode 6507, reward total was -19.0. running mean: -18.207534563829636, timestamp: 2022-08-19 23:21:14.095702\n",
      "resetting env. episode 6508, reward total was -19.0. running mean: -18.21545921819134, timestamp: 2022-08-19 23:21:17.673744\n",
      "resetting env. episode 6509, reward total was -20.0. running mean: -18.233304626009428, timestamp: 2022-08-19 23:21:21.340783\n",
      "resetting env. episode 6510, reward total was -17.0. running mean: -18.220971579749335, timestamp: 2022-08-19 23:21:26.361840\n",
      "resetting env. episode 6511, reward total was -19.0. running mean: -18.228761863951842, timestamp: 2022-08-19 23:21:30.128887\n",
      "resetting env. episode 6512, reward total was -21.0. running mean: -18.256474245312326, timestamp: 2022-08-19 23:21:33.903929\n",
      "resetting env. episode 6513, reward total was -20.0. running mean: -18.2739095028592, timestamp: 2022-08-19 23:21:37.235967\n",
      "resetting env. episode 6514, reward total was -19.0. running mean: -18.28117040783061, timestamp: 2022-08-19 23:21:40.790008\n",
      "resetting env. episode 6515, reward total was -19.0. running mean: -18.288358703752305, timestamp: 2022-08-19 23:21:45.603064\n",
      "resetting env. episode 6516, reward total was -17.0. running mean: -18.275475116714784, timestamp: 2022-08-19 23:21:50.289117\n",
      "resetting env. episode 6517, reward total was -18.0. running mean: -18.272720365547634, timestamp: 2022-08-19 23:21:54.121158\n",
      "resetting env. episode 6518, reward total was -18.0. running mean: -18.269993161892156, timestamp: 2022-08-19 23:21:57.925204\n",
      "resetting env. episode 6519, reward total was -19.0. running mean: -18.277293230273237, timestamp: 2022-08-19 23:22:00.769233\n",
      "resetting env. episode 6520, reward total was -20.0. running mean: -18.294520297970504, timestamp: 2022-08-19 23:22:03.832270\n",
      "resetting env. episode 6521, reward total was -21.0. running mean: -18.3215750949908, timestamp: 2022-08-19 23:22:06.900302\n",
      "resetting env. episode 6522, reward total was -19.0. running mean: -18.32835934404089, timestamp: 2022-08-19 23:22:10.293341\n",
      "resetting env. episode 6523, reward total was -20.0. running mean: -18.345075750600483, timestamp: 2022-08-19 23:22:13.446377\n",
      "resetting env. episode 6524, reward total was -19.0. running mean: -18.35162499309448, timestamp: 2022-08-19 23:22:16.957415\n",
      "resetting env. episode 6525, reward total was -21.0. running mean: -18.378108743163533, timestamp: 2022-08-19 23:22:21.403466\n",
      "resetting env. episode 6526, reward total was -19.0. running mean: -18.384327655731898, timestamp: 2022-08-19 23:22:25.027504\n",
      "resetting env. episode 6527, reward total was -19.0. running mean: -18.39048437917458, timestamp: 2022-08-19 23:22:28.028541\n",
      "resetting env. episode 6528, reward total was -21.0. running mean: -18.416579535382834, timestamp: 2022-08-19 23:22:32.098587\n",
      "resetting env. episode 6529, reward total was -19.0. running mean: -18.422413740029008, timestamp: 2022-08-19 23:22:36.182630\n",
      "resetting env. episode 6530, reward total was -17.0. running mean: -18.40818960262872, timestamp: 2022-08-19 23:22:41.458689\n",
      "resetting env. episode 6531, reward total was -18.0. running mean: -18.40410770660243, timestamp: 2022-08-19 23:22:45.225734\n",
      "resetting env. episode 6532, reward total was -17.0. running mean: -18.39006662953641, timestamp: 2022-08-19 23:22:49.081774\n",
      "resetting env. episode 6533, reward total was -17.0. running mean: -18.376165963241046, timestamp: 2022-08-19 23:22:53.163820\n",
      "resetting env. episode 6534, reward total was -17.0. running mean: -18.36240430360864, timestamp: 2022-08-19 23:22:56.033855\n",
      "resetting env. episode 6535, reward total was -19.0. running mean: -18.368780260572553, timestamp: 2022-08-19 23:23:00.272902\n",
      "resetting env. episode 6536, reward total was -17.0. running mean: -18.35509245796683, timestamp: 2022-08-19 23:23:04.422946\n",
      "resetting env. episode 6537, reward total was -16.0. running mean: -18.33154153338716, timestamp: 2022-08-19 23:23:08.440992\n",
      "resetting env. episode 6538, reward total was -18.0. running mean: -18.328226118053287, timestamp: 2022-08-19 23:23:12.468041\n",
      "resetting env. episode 6539, reward total was -18.0. running mean: -18.324943856872753, timestamp: 2022-08-19 23:23:15.978077\n",
      "resetting env. episode 6540, reward total was -19.0. running mean: -18.33169441830403, timestamp: 2022-08-19 23:23:19.796117\n",
      "resetting env. episode 6541, reward total was -18.0. running mean: -18.328377474120988, timestamp: 2022-08-19 23:23:23.563160\n",
      "resetting env. episode 6542, reward total was -17.0. running mean: -18.31509369937978, timestamp: 2022-08-19 23:23:28.460215\n",
      "resetting env. episode 6543, reward total was -21.0. running mean: -18.341942762385983, timestamp: 2022-08-19 23:23:31.336249\n",
      "resetting env. episode 6544, reward total was -19.0. running mean: -18.348523334762124, timestamp: 2022-08-19 23:23:34.642285\n",
      "resetting env. episode 6545, reward total was -17.0. running mean: -18.335038101414504, timestamp: 2022-08-19 23:23:38.344326\n",
      "resetting env. episode 6546, reward total was -19.0. running mean: -18.341687720400362, timestamp: 2022-08-19 23:23:41.349360\n",
      "resetting env. episode 6547, reward total was -15.0. running mean: -18.308270843196357, timestamp: 2022-08-19 23:23:45.334403\n",
      "resetting env. episode 6548, reward total was -18.0. running mean: -18.305188134764393, timestamp: 2022-08-19 23:23:50.125457\n",
      "resetting env. episode 6549, reward total was -19.0. running mean: -18.31213625341675, timestamp: 2022-08-19 23:23:53.392495\n",
      "resetting env. episode 6550, reward total was -20.0. running mean: -18.329014890882583, timestamp: 2022-08-19 23:23:56.664529\n",
      "resetting env. episode 6551, reward total was -21.0. running mean: -18.35572474197376, timestamp: 2022-08-19 23:24:00.267573\n",
      "resetting env. episode 6552, reward total was -17.0. running mean: -18.342167494554023, timestamp: 2022-08-19 23:24:04.581618\n",
      "resetting env. episode 6553, reward total was -16.0. running mean: -18.318745819608484, timestamp: 2022-08-19 23:24:08.763662\n",
      "resetting env. episode 6554, reward total was -19.0. running mean: -18.3255583614124, timestamp: 2022-08-19 23:24:12.723708\n",
      "resetting env. episode 6555, reward total was -17.0. running mean: -18.31230277779828, timestamp: 2022-08-19 23:24:16.031747\n",
      "resetting env. episode 6556, reward total was -18.0. running mean: -18.309179750020295, timestamp: 2022-08-19 23:24:19.497785\n",
      "resetting env. episode 6557, reward total was -19.0. running mean: -18.316087952520093, timestamp: 2022-08-19 23:24:23.442825\n",
      "resetting env. episode 6558, reward total was -19.0. running mean: -18.322927072994894, timestamp: 2022-08-19 23:24:27.443873\n",
      "resetting env. episode 6559, reward total was -14.0. running mean: -18.279697802264945, timestamp: 2022-08-19 23:24:31.253914\n",
      "resetting env. episode 6560, reward total was -21.0. running mean: -18.306900824242295, timestamp: 2022-08-19 23:24:35.309958\n",
      "resetting env. episode 6561, reward total was -19.0. running mean: -18.313831815999873, timestamp: 2022-08-19 23:24:38.678997\n",
      "resetting env. episode 6562, reward total was -18.0. running mean: -18.310693497839875, timestamp: 2022-08-19 23:24:41.896034\n",
      "resetting env. episode 6563, reward total was -20.0. running mean: -18.327586562861477, timestamp: 2022-08-19 23:24:44.796063\n",
      "resetting env. episode 6564, reward total was -13.0. running mean: -18.27431069723286, timestamp: 2022-08-19 23:24:49.371118\n",
      "resetting env. episode 6565, reward total was -18.0. running mean: -18.27156759026053, timestamp: 2022-08-19 23:24:53.045155\n",
      "resetting env. episode 6566, reward total was -17.0. running mean: -18.258851914357926, timestamp: 2022-08-19 23:24:56.460194\n",
      "resetting env. episode 6567, reward total was -12.0. running mean: -18.19626339521435, timestamp: 2022-08-19 23:25:00.441243\n",
      "resetting env. episode 6568, reward total was -21.0. running mean: -18.224300761262207, timestamp: 2022-08-19 23:25:04.555285\n",
      "resetting env. episode 6569, reward total was -15.0. running mean: -18.192057753649582, timestamp: 2022-08-19 23:25:10.486350\n",
      "resetting env. episode 6570, reward total was -14.0. running mean: -18.150137176113088, timestamp: 2022-08-19 23:25:14.970401\n",
      "resetting env. episode 6571, reward total was -16.0. running mean: -18.12863580435196, timestamp: 2022-08-19 23:25:19.195449\n",
      "resetting env. episode 6572, reward total was -21.0. running mean: -18.15734944630844, timestamp: 2022-08-19 23:25:22.877485\n",
      "resetting env. episode 6573, reward total was -21.0. running mean: -18.185775951845358, timestamp: 2022-08-19 23:25:26.411537\n",
      "resetting env. episode 6574, reward total was -16.0. running mean: -18.163918192326904, timestamp: 2022-08-19 23:25:30.450569\n",
      "resetting env. episode 6575, reward total was -18.0. running mean: -18.162279010403633, timestamp: 2022-08-19 23:25:34.770620\n",
      "resetting env. episode 6576, reward total was -17.0. running mean: -18.1506562202996, timestamp: 2022-08-19 23:25:38.632660\n",
      "resetting env. episode 6577, reward total was -20.0. running mean: -18.1691496580966, timestamp: 2022-08-19 23:25:41.953697\n",
      "resetting env. episode 6578, reward total was -15.0. running mean: -18.13745816151563, timestamp: 2022-08-19 23:25:46.566749\n",
      "resetting env. episode 6579, reward total was -19.0. running mean: -18.146083579900477, timestamp: 2022-08-19 23:25:50.134789\n",
      "resetting env. episode 6580, reward total was -19.0. running mean: -18.154622744101474, timestamp: 2022-08-19 23:25:54.069832\n",
      "resetting env. episode 6581, reward total was -15.0. running mean: -18.123076516660458, timestamp: 2022-08-19 23:25:58.363880\n",
      "resetting env. episode 6582, reward total was -14.0. running mean: -18.081845751493855, timestamp: 2022-08-19 23:26:02.773931\n",
      "resetting env. episode 6583, reward total was -19.0. running mean: -18.091027293978918, timestamp: 2022-08-19 23:26:06.447972\n",
      "resetting env. episode 6584, reward total was -19.0. running mean: -18.10011702103913, timestamp: 2022-08-19 23:26:11.058022\n",
      "resetting env. episode 6585, reward total was -21.0. running mean: -18.12911585082874, timestamp: 2022-08-19 23:26:14.383060\n",
      "resetting env. episode 6586, reward total was -13.0. running mean: -18.07782469232045, timestamp: 2022-08-19 23:26:18.318103\n",
      "resetting env. episode 6587, reward total was -21.0. running mean: -18.10704644539725, timestamp: 2022-08-19 23:26:21.360137\n",
      "resetting env. episode 6588, reward total was -15.0. running mean: -18.075975980943273, timestamp: 2022-08-19 23:26:25.321178\n",
      "resetting env. episode 6589, reward total was -19.0. running mean: -18.08521622113384, timestamp: 2022-08-19 23:26:28.844217\n",
      "resetting env. episode 6590, reward total was -17.0. running mean: -18.074364058922505, timestamp: 2022-08-19 23:26:33.962274\n",
      "resetting env. episode 6591, reward total was -17.0. running mean: -18.063620418333283, timestamp: 2022-08-19 23:26:37.510317\n",
      "resetting env. episode 6592, reward total was -15.0. running mean: -18.03298421414995, timestamp: 2022-08-19 23:26:42.204364\n",
      "resetting env. episode 6593, reward total was -19.0. running mean: -18.04265437200845, timestamp: 2022-08-19 23:26:46.165408\n",
      "resetting env. episode 6594, reward total was -20.0. running mean: -18.062227828288364, timestamp: 2022-08-19 23:26:49.837454\n",
      "resetting env. episode 6595, reward total was -18.0. running mean: -18.06160555000548, timestamp: 2022-08-19 23:26:54.257497\n",
      "resetting env. episode 6596, reward total was -19.0. running mean: -18.070989494505426, timestamp: 2022-08-19 23:26:57.936536\n",
      "resetting env. episode 6597, reward total was -17.0. running mean: -18.060279599560374, timestamp: 2022-08-19 23:27:01.502579\n",
      "resetting env. episode 6598, reward total was -20.0. running mean: -18.07967680356477, timestamp: 2022-08-19 23:27:04.693615\n",
      "resetting env. episode 6599, reward total was -18.0. running mean: -18.07888003552912, timestamp: 2022-08-19 23:27:08.385651\n",
      "resetting env. episode 6600, reward total was -17.0. running mean: -18.06809123517383, timestamp: 2022-08-19 23:27:13.253705\n",
      "resetting env. episode 6601, reward total was -15.0. running mean: -18.03741032282209, timestamp: 2022-08-19 23:27:17.075747\n",
      "resetting env. episode 6602, reward total was -17.0. running mean: -18.02703621959387, timestamp: 2022-08-19 23:27:20.955792\n",
      "resetting env. episode 6603, reward total was -17.0. running mean: -18.016765857397935, timestamp: 2022-08-19 23:27:25.515842\n",
      "resetting env. episode 6604, reward total was -17.0. running mean: -18.00659819882396, timestamp: 2022-08-19 23:27:29.859889\n",
      "resetting env. episode 6605, reward total was -17.0. running mean: -17.99653221683572, timestamp: 2022-08-19 23:27:33.241930\n",
      "resetting env. episode 6606, reward total was -19.0. running mean: -18.006566894667365, timestamp: 2022-08-19 23:27:37.316971\n",
      "resetting env. episode 6607, reward total was -20.0. running mean: -18.02650122572069, timestamp: 2022-08-19 23:27:40.843010\n",
      "resetting env. episode 6608, reward total was -17.0. running mean: -18.016236213463486, timestamp: 2022-08-19 23:27:45.418059\n",
      "resetting env. episode 6609, reward total was -20.0. running mean: -18.03607385132885, timestamp: 2022-08-19 23:27:49.828107\n",
      "resetting env. episode 6610, reward total was -17.0. running mean: -18.025713112815563, timestamp: 2022-08-19 23:27:53.410148\n",
      "resetting env. episode 6611, reward total was -19.0. running mean: -18.03545598168741, timestamp: 2022-08-19 23:27:57.906197\n",
      "resetting env. episode 6612, reward total was -16.0. running mean: -18.015101421870536, timestamp: 2022-08-19 23:28:02.396246\n",
      "resetting env. episode 6613, reward total was -19.0. running mean: -18.024950407651833, timestamp: 2022-08-19 23:28:06.105287\n",
      "resetting env. episode 6614, reward total was -15.0. running mean: -17.994700903575314, timestamp: 2022-08-19 23:28:10.924340\n",
      "resetting env. episode 6615, reward total was -19.0. running mean: -18.00475389453956, timestamp: 2022-08-19 23:28:14.291379\n",
      "resetting env. episode 6616, reward total was -19.0. running mean: -18.014706355594168, timestamp: 2022-08-19 23:28:18.054422\n",
      "resetting env. episode 6617, reward total was -20.0. running mean: -18.034559292038224, timestamp: 2022-08-19 23:28:21.134452\n",
      "resetting env. episode 6618, reward total was -20.0. running mean: -18.05421369911784, timestamp: 2022-08-19 23:28:24.629490\n",
      "resetting env. episode 6619, reward total was -19.0. running mean: -18.063671562126665, timestamp: 2022-08-19 23:28:28.621537\n",
      "resetting env. episode 6620, reward total was -21.0. running mean: -18.0930348465054, timestamp: 2022-08-19 23:28:31.474565\n",
      "resetting env. episode 6621, reward total was -17.0. running mean: -18.082104498040348, timestamp: 2022-08-19 23:28:35.561611\n",
      "resetting env. episode 6622, reward total was -20.0. running mean: -18.101283453059942, timestamp: 2022-08-19 23:28:39.294655\n",
      "resetting env. episode 6623, reward total was -21.0. running mean: -18.130270618529345, timestamp: 2022-08-19 23:28:42.764690\n",
      "resetting env. episode 6624, reward total was -15.0. running mean: -18.09896791234405, timestamp: 2022-08-19 23:28:47.260740\n",
      "resetting env. episode 6625, reward total was -20.0. running mean: -18.117978233220608, timestamp: 2022-08-19 23:28:50.255770\n",
      "resetting env. episode 6626, reward total was -21.0. running mean: -18.146798450888404, timestamp: 2022-08-19 23:28:54.137817\n",
      "resetting env. episode 6627, reward total was -17.0. running mean: -18.13533046637952, timestamp: 2022-08-19 23:28:58.657863\n",
      "resetting env. episode 6628, reward total was -20.0. running mean: -18.153977161715726, timestamp: 2022-08-19 23:29:02.186902\n",
      "resetting env. episode 6629, reward total was -17.0. running mean: -18.14243739009857, timestamp: 2022-08-19 23:29:06.272945\n",
      "resetting env. episode 6630, reward total was -14.0. running mean: -18.101013016197587, timestamp: 2022-08-19 23:29:10.650993\n",
      "resetting env. episode 6631, reward total was -18.0. running mean: -18.10000288603561, timestamp: 2022-08-19 23:29:14.000029\n",
      "resetting env. episode 6632, reward total was -18.0. running mean: -18.099002857175254, timestamp: 2022-08-19 23:29:17.885072\n",
      "resetting env. episode 6633, reward total was -20.0. running mean: -18.1180128286035, timestamp: 2022-08-19 23:29:21.482112\n",
      "resetting env. episode 6634, reward total was -18.0. running mean: -18.116832700317467, timestamp: 2022-08-19 23:29:25.424155\n",
      "resetting env. episode 6635, reward total was -18.0. running mean: -18.115664373314292, timestamp: 2022-08-19 23:29:28.934197\n",
      "resetting env. episode 6636, reward total was -20.0. running mean: -18.13450772958115, timestamp: 2022-08-19 23:29:31.966225\n",
      "resetting env. episode 6637, reward total was -18.0. running mean: -18.133162652285336, timestamp: 2022-08-19 23:29:35.956270\n",
      "resetting env. episode 6638, reward total was -20.0. running mean: -18.15183102576248, timestamp: 2022-08-19 23:29:39.876313\n",
      "resetting env. episode 6639, reward total was -18.0. running mean: -18.150312715504853, timestamp: 2022-08-19 23:29:43.459350\n",
      "resetting env. episode 6640, reward total was -18.0. running mean: -18.148809588349803, timestamp: 2022-08-19 23:29:47.572396\n",
      "resetting env. episode 6641, reward total was -18.0. running mean: -18.147321492466304, timestamp: 2022-08-19 23:29:51.354439\n",
      "resetting env. episode 6642, reward total was -15.0. running mean: -18.11584827754164, timestamp: 2022-08-19 23:29:55.909489\n",
      "resetting env. episode 6643, reward total was -16.0. running mean: -18.094689794766225, timestamp: 2022-08-19 23:30:00.535537\n",
      "resetting env. episode 6644, reward total was -17.0. running mean: -18.083742896818563, timestamp: 2022-08-19 23:30:04.498582\n",
      "resetting env. episode 6645, reward total was -17.0. running mean: -18.07290546785038, timestamp: 2022-08-19 23:30:08.456624\n",
      "resetting env. episode 6646, reward total was -21.0. running mean: -18.102176413171875, timestamp: 2022-08-19 23:30:11.685661\n",
      "resetting env. episode 6647, reward total was -16.0. running mean: -18.08115464904016, timestamp: 2022-08-19 23:30:16.284713\n",
      "resetting env. episode 6648, reward total was -19.0. running mean: -18.090343102549756, timestamp: 2022-08-19 23:30:19.306745\n",
      "resetting env. episode 6649, reward total was -16.0. running mean: -18.069439671524258, timestamp: 2022-08-19 23:30:23.455787\n",
      "resetting env. episode 6650, reward total was -17.0. running mean: -18.058745274809016, timestamp: 2022-08-19 23:30:27.189826\n",
      "resetting env. episode 6651, reward total was -18.0. running mean: -18.058157822060927, timestamp: 2022-08-19 23:30:31.286876\n",
      "resetting env. episode 6652, reward total was -19.0. running mean: -18.067576243840318, timestamp: 2022-08-19 23:30:34.528908\n",
      "resetting env. episode 6653, reward total was -19.0. running mean: -18.076900481401914, timestamp: 2022-08-19 23:30:37.969945\n",
      "resetting env. episode 6654, reward total was -21.0. running mean: -18.106131476587894, timestamp: 2022-08-19 23:30:41.000981\n",
      "resetting env. episode 6655, reward total was -19.0. running mean: -18.115070161822015, timestamp: 2022-08-19 23:30:45.380027\n",
      "resetting env. episode 6656, reward total was -17.0. running mean: -18.103919460203795, timestamp: 2022-08-19 23:30:48.916067\n",
      "resetting env. episode 6657, reward total was -19.0. running mean: -18.112880265601756, timestamp: 2022-08-19 23:30:52.182102\n",
      "resetting env. episode 6658, reward total was -21.0. running mean: -18.141751462945738, timestamp: 2022-08-19 23:30:55.433137\n",
      "resetting env. episode 6659, reward total was -19.0. running mean: -18.15033394831628, timestamp: 2022-08-19 23:30:59.118177\n",
      "resetting env. episode 6660, reward total was -16.0. running mean: -18.128830608833116, timestamp: 2022-08-19 23:31:03.731226\n",
      "resetting env. episode 6661, reward total was -17.0. running mean: -18.117542302744788, timestamp: 2022-08-19 23:31:07.811272\n",
      "resetting env. episode 6662, reward total was -19.0. running mean: -18.12636687971734, timestamp: 2022-08-19 23:31:11.932323\n",
      "resetting env. episode 6663, reward total was -19.0. running mean: -18.13510321092017, timestamp: 2022-08-19 23:31:14.944352\n",
      "resetting env. episode 6664, reward total was -17.0. running mean: -18.12375217881097, timestamp: 2022-08-19 23:31:19.264402\n",
      "resetting env. episode 6665, reward total was -18.0. running mean: -18.12251465702286, timestamp: 2022-08-19 23:31:24.488456\n",
      "resetting env. episode 6666, reward total was -20.0. running mean: -18.141289510452633, timestamp: 2022-08-19 23:31:28.417499\n",
      "resetting env. episode 6667, reward total was -19.0. running mean: -18.14987661534811, timestamp: 2022-08-19 23:31:32.525547\n",
      "resetting env. episode 6668, reward total was -18.0. running mean: -18.148377849194627, timestamp: 2022-08-19 23:31:36.297587\n",
      "resetting env. episode 6669, reward total was -17.0. running mean: -18.136894070702684, timestamp: 2022-08-19 23:31:40.063628\n",
      "resetting env. episode 6670, reward total was -17.0. running mean: -18.12552512999566, timestamp: 2022-08-19 23:31:44.865679\n",
      "resetting env. episode 6671, reward total was -20.0. running mean: -18.144269878695702, timestamp: 2022-08-19 23:31:48.080716\n",
      "resetting env. episode 6672, reward total was -16.0. running mean: -18.122827179908747, timestamp: 2022-08-19 23:31:51.415752\n",
      "resetting env. episode 6673, reward total was -18.0. running mean: -18.121598908109657, timestamp: 2022-08-19 23:31:54.917792\n",
      "resetting env. episode 6674, reward total was -20.0. running mean: -18.14038291902856, timestamp: 2022-08-19 23:31:58.045824\n",
      "resetting env. episode 6675, reward total was -17.0. running mean: -18.128979089838275, timestamp: 2022-08-19 23:32:01.523864\n",
      "resetting env. episode 6676, reward total was -19.0. running mean: -18.137689298939893, timestamp: 2022-08-19 23:32:05.331906\n",
      "resetting env. episode 6677, reward total was -17.0. running mean: -18.126312405950497, timestamp: 2022-08-19 23:32:08.772946\n",
      "resetting env. episode 6678, reward total was -16.0. running mean: -18.10504928189099, timestamp: 2022-08-19 23:32:13.383996\n",
      "resetting env. episode 6679, reward total was -21.0. running mean: -18.13399878907208, timestamp: 2022-08-19 23:32:17.240039\n",
      "resetting env. episode 6680, reward total was -19.0. running mean: -18.142658801181362, timestamp: 2022-08-19 23:32:21.272081\n",
      "resetting env. episode 6681, reward total was -20.0. running mean: -18.161232213169548, timestamp: 2022-08-19 23:32:24.908124\n",
      "resetting env. episode 6682, reward total was -20.0. running mean: -18.179619891037852, timestamp: 2022-08-19 23:32:29.459176\n",
      "resetting env. episode 6683, reward total was -17.0. running mean: -18.167823692127474, timestamp: 2022-08-19 23:32:32.903212\n",
      "resetting env. episode 6684, reward total was -16.0. running mean: -18.1461454552062, timestamp: 2022-08-19 23:32:36.920256\n",
      "resetting env. episode 6685, reward total was -17.0. running mean: -18.13468400065414, timestamp: 2022-08-19 23:32:40.399296\n",
      "resetting env. episode 6686, reward total was -19.0. running mean: -18.1433371606476, timestamp: 2022-08-19 23:32:44.451340\n",
      "resetting env. episode 6687, reward total was -20.0. running mean: -18.161903789041123, timestamp: 2022-08-19 23:32:47.754380\n",
      "resetting env. episode 6688, reward total was -18.0. running mean: -18.160284751150712, timestamp: 2022-08-19 23:32:52.164424\n",
      "resetting env. episode 6689, reward total was -18.0. running mean: -18.158681903639206, timestamp: 2022-08-19 23:32:55.610466\n",
      "resetting env. episode 6690, reward total was -14.0. running mean: -18.117095084602813, timestamp: 2022-08-19 23:32:59.754509\n",
      "resetting env. episode 6691, reward total was -17.0. running mean: -18.105924133756787, timestamp: 2022-08-19 23:33:03.598554\n",
      "resetting env. episode 6692, reward total was -20.0. running mean: -18.124864892419218, timestamp: 2022-08-19 23:33:07.404594\n",
      "resetting env. episode 6693, reward total was -21.0. running mean: -18.153616243495026, timestamp: 2022-08-19 23:33:11.139638\n",
      "resetting env. episode 6694, reward total was -17.0. running mean: -18.142080081060076, timestamp: 2022-08-19 23:33:15.423684\n",
      "resetting env. episode 6695, reward total was -17.0. running mean: -18.13065928024948, timestamp: 2022-08-19 23:33:19.610733\n",
      "resetting env. episode 6696, reward total was -15.0. running mean: -18.09935268744698, timestamp: 2022-08-19 23:33:23.210774\n",
      "resetting env. episode 6697, reward total was -21.0. running mean: -18.12835916057251, timestamp: 2022-08-19 23:33:25.953801\n",
      "resetting env. episode 6698, reward total was -17.0. running mean: -18.117075568966786, timestamp: 2022-08-19 23:33:29.805848\n",
      "resetting env. episode 6699, reward total was -13.0. running mean: -18.06590481327712, timestamp: 2022-08-19 23:33:34.543898\n",
      "resetting env. episode 6700, reward total was -18.0. running mean: -18.065245765144347, timestamp: 2022-08-19 23:33:38.715944\n",
      "resetting env. episode 6701, reward total was -15.0. running mean: -18.0345933074929, timestamp: 2022-08-19 23:33:43.669000\n",
      "resetting env. episode 6702, reward total was -21.0. running mean: -18.064247374417974, timestamp: 2022-08-19 23:33:47.309044\n",
      "resetting env. episode 6703, reward total was -18.0. running mean: -18.063604900673795, timestamp: 2022-08-19 23:33:51.749091\n",
      "resetting env. episode 6704, reward total was -16.0. running mean: -18.042968851667055, timestamp: 2022-08-19 23:33:56.829147\n",
      "resetting env. episode 6705, reward total was -17.0. running mean: -18.032539163150386, timestamp: 2022-08-19 23:34:00.321187\n",
      "resetting env. episode 6706, reward total was -17.0. running mean: -18.02221377151888, timestamp: 2022-08-19 23:34:04.641238\n",
      "resetting env. episode 6707, reward total was -16.0. running mean: -18.001991633803694, timestamp: 2022-08-19 23:34:08.274276\n",
      "resetting env. episode 6708, reward total was -20.0. running mean: -18.021971717465657, timestamp: 2022-08-19 23:34:11.401314\n",
      "resetting env. episode 6709, reward total was -20.0. running mean: -18.041752000290998, timestamp: 2022-08-19 23:34:14.915352\n",
      "resetting env. episode 6710, reward total was -21.0. running mean: -18.07133448028809, timestamp: 2022-08-19 23:34:18.667391\n",
      "resetting env. episode 6711, reward total was -20.0. running mean: -18.090621135485208, timestamp: 2022-08-19 23:34:22.071432\n",
      "resetting env. episode 6712, reward total was -17.0. running mean: -18.079714924130357, timestamp: 2022-08-19 23:34:25.599471\n",
      "resetting env. episode 6713, reward total was -21.0. running mean: -18.108917774889054, timestamp: 2022-08-19 23:34:29.329514\n",
      "resetting env. episode 6714, reward total was -19.0. running mean: -18.117828597140164, timestamp: 2022-08-19 23:34:32.764552\n",
      "resetting env. episode 6715, reward total was -19.0. running mean: -18.126650311168763, timestamp: 2022-08-19 23:34:36.906599\n",
      "resetting env. episode 6716, reward total was -19.0. running mean: -18.135383808057078, timestamp: 2022-08-19 23:34:41.167647\n",
      "resetting env. episode 6717, reward total was -16.0. running mean: -18.114029969976507, timestamp: 2022-08-19 23:34:45.952700\n",
      "resetting env. episode 6718, reward total was -18.0. running mean: -18.11288967027674, timestamp: 2022-08-19 23:34:49.226739\n",
      "resetting env. episode 6719, reward total was -16.0. running mean: -18.091760773573974, timestamp: 2022-08-19 23:34:53.753787\n",
      "resetting env. episode 6720, reward total was -20.0. running mean: -18.110843165838233, timestamp: 2022-08-19 23:34:57.821830\n",
      "resetting env. episode 6721, reward total was -19.0. running mean: -18.11973473417985, timestamp: 2022-08-19 23:35:02.225881\n",
      "resetting env. episode 6722, reward total was -19.0. running mean: -18.128537386838055, timestamp: 2022-08-19 23:35:05.499918\n",
      "resetting env. episode 6723, reward total was -17.0. running mean: -18.117252012969676, timestamp: 2022-08-19 23:35:10.091969\n",
      "resetting env. episode 6724, reward total was -20.0. running mean: -18.13607949283998, timestamp: 2022-08-19 23:35:14.466018\n",
      "resetting env. episode 6725, reward total was -14.0. running mean: -18.09471869791158, timestamp: 2022-08-19 23:35:18.923068\n",
      "resetting env. episode 6726, reward total was -19.0. running mean: -18.103771510932468, timestamp: 2022-08-19 23:35:22.546108\n",
      "resetting env. episode 6727, reward total was -21.0. running mean: -18.132733795823142, timestamp: 2022-08-19 23:35:26.218149\n",
      "resetting env. episode 6728, reward total was -16.0. running mean: -18.111406457864913, timestamp: 2022-08-19 23:35:31.189207\n",
      "resetting env. episode 6729, reward total was -16.0. running mean: -18.090292393286262, timestamp: 2022-08-19 23:35:35.877261\n",
      "resetting env. episode 6730, reward total was -18.0. running mean: -18.0893894693534, timestamp: 2022-08-19 23:35:39.500299\n",
      "resetting env. episode 6731, reward total was -21.0. running mean: -18.118495574659867, timestamp: 2022-08-19 23:35:43.094342\n",
      "resetting env. episode 6732, reward total was -13.0. running mean: -18.067310618913268, timestamp: 2022-08-19 23:35:48.242399\n",
      "resetting env. episode 6733, reward total was -16.0. running mean: -18.046637512724136, timestamp: 2022-08-19 23:35:52.560447\n",
      "resetting env. episode 6734, reward total was -16.0. running mean: -18.026171137596894, timestamp: 2022-08-19 23:35:56.525490\n",
      "resetting env. episode 6735, reward total was -19.0. running mean: -18.035909426220925, timestamp: 2022-08-19 23:36:00.719538\n",
      "resetting env. episode 6736, reward total was -19.0. running mean: -18.04555033195872, timestamp: 2022-08-19 23:36:04.293582\n",
      "resetting env. episode 6737, reward total was -19.0. running mean: -18.05509482863913, timestamp: 2022-08-19 23:36:08.439636\n",
      "resetting env. episode 6738, reward total was -21.0. running mean: -18.08454388035274, timestamp: 2022-08-19 23:36:12.253668\n",
      "resetting env. episode 6739, reward total was -21.0. running mean: -18.113698441549214, timestamp: 2022-08-19 23:36:15.144707\n",
      "resetting env. episode 6740, reward total was -19.0. running mean: -18.122561457133724, timestamp: 2022-08-19 23:36:18.121733\n",
      "resetting env. episode 6741, reward total was -19.0. running mean: -18.131335842562386, timestamp: 2022-08-19 23:36:21.257775\n",
      "resetting env. episode 6742, reward total was -17.0. running mean: -18.120022484136765, timestamp: 2022-08-19 23:36:25.369818\n",
      "resetting env. episode 6743, reward total was -21.0. running mean: -18.148822259295397, timestamp: 2022-08-19 23:36:28.888859\n",
      "resetting env. episode 6744, reward total was -20.0. running mean: -18.167334036702442, timestamp: 2022-08-19 23:36:33.132908\n",
      "resetting env. episode 6745, reward total was -19.0. running mean: -18.17566069633542, timestamp: 2022-08-19 23:36:37.072948\n",
      "resetting env. episode 6746, reward total was -18.0. running mean: -18.173904089372066, timestamp: 2022-08-19 23:36:41.730001\n",
      "resetting env. episode 6747, reward total was -17.0. running mean: -18.162165048478347, timestamp: 2022-08-19 23:36:45.956049\n",
      "resetting env. episode 6748, reward total was -15.0. running mean: -18.130543397993563, timestamp: 2022-08-19 23:36:50.578103\n",
      "resetting env. episode 6749, reward total was -16.0. running mean: -18.109237964013627, timestamp: 2022-08-19 23:36:53.963139\n",
      "resetting env. episode 6750, reward total was -21.0. running mean: -18.13814558437349, timestamp: 2022-08-19 23:36:57.602179\n",
      "resetting env. episode 6751, reward total was -15.0. running mean: -18.106764128529754, timestamp: 2022-08-19 23:37:01.701231\n",
      "resetting env. episode 6752, reward total was -17.0. running mean: -18.095696487244457, timestamp: 2022-08-19 23:37:05.766272\n",
      "resetting env. episode 6753, reward total was -19.0. running mean: -18.104739522372014, timestamp: 2022-08-19 23:37:10.199330\n",
      "resetting env. episode 6754, reward total was -21.0. running mean: -18.133692127148294, timestamp: 2022-08-19 23:37:14.183369\n",
      "resetting env. episode 6755, reward total was -18.0. running mean: -18.13235520587681, timestamp: 2022-08-19 23:37:17.497405\n",
      "resetting env. episode 6756, reward total was -19.0. running mean: -18.141031653818043, timestamp: 2022-08-19 23:37:20.695441\n",
      "resetting env. episode 6757, reward total was -20.0. running mean: -18.159621337279862, timestamp: 2022-08-19 23:37:25.012490\n",
      "resetting env. episode 6758, reward total was -19.0. running mean: -18.168025123907064, timestamp: 2022-08-19 23:37:28.892536\n",
      "resetting env. episode 6759, reward total was -21.0. running mean: -18.196344872667993, timestamp: 2022-08-19 23:37:32.170573\n",
      "resetting env. episode 6760, reward total was -19.0. running mean: -18.204381423941314, timestamp: 2022-08-19 23:37:35.497608\n",
      "resetting env. episode 6761, reward total was -18.0. running mean: -18.2023376097019, timestamp: 2022-08-19 23:37:39.085650\n",
      "resetting env. episode 6762, reward total was -21.0. running mean: -18.230314233604883, timestamp: 2022-08-19 23:37:42.218684\n",
      "resetting env. episode 6763, reward total was -19.0. running mean: -18.238011091268834, timestamp: 2022-08-19 23:37:46.397733\n",
      "resetting env. episode 6764, reward total was -14.0. running mean: -18.195630980356146, timestamp: 2022-08-19 23:37:50.961783\n",
      "resetting env. episode 6765, reward total was -19.0. running mean: -18.203674670552587, timestamp: 2022-08-19 23:37:55.321833\n",
      "resetting env. episode 6766, reward total was -20.0. running mean: -18.22163792384706, timestamp: 2022-08-19 23:37:59.035875\n",
      "resetting env. episode 6767, reward total was -18.0. running mean: -18.219421544608586, timestamp: 2022-08-19 23:38:03.198924\n",
      "resetting env. episode 6768, reward total was -17.0. running mean: -18.207227329162503, timestamp: 2022-08-19 23:38:06.803966\n",
      "resetting env. episode 6769, reward total was -17.0. running mean: -18.19515505587088, timestamp: 2022-08-19 23:38:11.066013\n",
      "resetting env. episode 6770, reward total was -18.0. running mean: -18.193203505312173, timestamp: 2022-08-19 23:38:14.198047\n",
      "resetting env. episode 6771, reward total was -13.0. running mean: -18.14127147025905, timestamp: 2022-08-19 23:38:18.879107\n",
      "resetting env. episode 6772, reward total was -18.0. running mean: -18.139858755556457, timestamp: 2022-08-19 23:38:22.478138\n",
      "resetting env. episode 6773, reward total was -19.0. running mean: -18.148460168000895, timestamp: 2022-08-19 23:38:26.381184\n",
      "resetting env. episode 6774, reward total was -18.0. running mean: -18.146975566320886, timestamp: 2022-08-19 23:38:30.500229\n",
      "resetting env. episode 6775, reward total was -17.0. running mean: -18.13550581065768, timestamp: 2022-08-19 23:38:34.313274\n",
      "resetting env. episode 6776, reward total was -17.0. running mean: -18.124150752551106, timestamp: 2022-08-19 23:38:38.964326\n",
      "resetting env. episode 6777, reward total was -17.0. running mean: -18.112909245025598, timestamp: 2022-08-19 23:38:42.636367\n",
      "resetting env. episode 6778, reward total was -16.0. running mean: -18.091780152575343, timestamp: 2022-08-19 23:38:47.234416\n",
      "resetting env. episode 6779, reward total was -18.0. running mean: -18.090862351049587, timestamp: 2022-08-19 23:38:50.874459\n",
      "resetting env. episode 6780, reward total was -20.0. running mean: -18.10995372753909, timestamp: 2022-08-19 23:38:54.231497\n",
      "resetting env. episode 6781, reward total was -13.0. running mean: -18.0588541902637, timestamp: 2022-08-19 23:38:59.851557\n",
      "resetting env. episode 6782, reward total was -20.0. running mean: -18.07826564836106, timestamp: 2022-08-19 23:39:03.237597\n",
      "resetting env. episode 6783, reward total was -19.0. running mean: -18.08748299187745, timestamp: 2022-08-19 23:39:06.993640\n",
      "resetting env. episode 6784, reward total was -18.0. running mean: -18.086608161958676, timestamp: 2022-08-19 23:39:10.642682\n",
      "resetting env. episode 6785, reward total was -20.0. running mean: -18.105742080339088, timestamp: 2022-08-19 23:39:14.051717\n",
      "resetting env. episode 6786, reward total was -20.0. running mean: -18.124684659535696, timestamp: 2022-08-19 23:39:17.013751\n",
      "resetting env. episode 6787, reward total was -19.0. running mean: -18.13343781294034, timestamp: 2022-08-19 23:39:20.764791\n",
      "resetting env. episode 6788, reward total was -20.0. running mean: -18.152103434810936, timestamp: 2022-08-19 23:39:24.467832\n",
      "resetting env. episode 6789, reward total was -14.0. running mean: -18.110582400462828, timestamp: 2022-08-19 23:39:28.814882\n",
      "resetting env. episode 6790, reward total was -16.0. running mean: -18.0894765764582, timestamp: 2022-08-19 23:39:32.137920\n",
      "resetting env. episode 6791, reward total was -19.0. running mean: -18.09858181069362, timestamp: 2022-08-19 23:39:36.724973\n",
      "resetting env. episode 6792, reward total was -13.0. running mean: -18.047595992586682, timestamp: 2022-08-19 23:39:40.803015\n",
      "resetting env. episode 6793, reward total was -19.0. running mean: -18.057120032660816, timestamp: 2022-08-19 23:39:44.730064\n",
      "resetting env. episode 6794, reward total was -19.0. running mean: -18.06654883233421, timestamp: 2022-08-19 23:39:48.542103\n",
      "resetting env. episode 6795, reward total was -18.0. running mean: -18.065883344010867, timestamp: 2022-08-19 23:39:52.415147\n",
      "resetting env. episode 6796, reward total was -17.0. running mean: -18.05522451057076, timestamp: 2022-08-19 23:39:57.022205\n",
      "resetting env. episode 6797, reward total was -17.0. running mean: -18.044672265465053, timestamp: 2022-08-19 23:40:01.220250\n",
      "resetting env. episode 6798, reward total was -21.0. running mean: -18.074225542810403, timestamp: 2022-08-19 23:40:04.948289\n",
      "resetting env. episode 6799, reward total was -16.0. running mean: -18.0534832873823, timestamp: 2022-08-19 23:40:09.018337\n",
      "resetting env. episode 6800, reward total was -21.0. running mean: -18.082948454508475, timestamp: 2022-08-19 23:40:12.231368\n",
      "resetting env. episode 6801, reward total was -17.0. running mean: -18.07211896996339, timestamp: 2022-08-19 23:40:16.993423\n",
      "resetting env. episode 6802, reward total was -19.0. running mean: -18.081397780263757, timestamp: 2022-08-19 23:40:20.230459\n",
      "resetting env. episode 6803, reward total was -17.0. running mean: -18.07058380246112, timestamp: 2022-08-19 23:40:24.562505\n",
      "resetting env. episode 6804, reward total was -20.0. running mean: -18.089877964436507, timestamp: 2022-08-19 23:40:27.393548\n",
      "resetting env. episode 6805, reward total was -19.0. running mean: -18.098979184792142, timestamp: 2022-08-19 23:40:31.252582\n",
      "resetting env. episode 6806, reward total was -21.0. running mean: -18.127989392944222, timestamp: 2022-08-19 23:40:34.240617\n",
      "resetting env. episode 6807, reward total was -19.0. running mean: -18.13670949901478, timestamp: 2022-08-19 23:40:37.565652\n",
      "resetting env. episode 6808, reward total was -17.0. running mean: -18.125342404024636, timestamp: 2022-08-19 23:40:40.886700\n",
      "resetting env. episode 6809, reward total was -18.0. running mean: -18.12408897998439, timestamp: 2022-08-19 23:40:44.488732\n",
      "resetting env. episode 6810, reward total was -17.0. running mean: -18.112848090184546, timestamp: 2022-08-19 23:40:48.399772\n",
      "resetting env. episode 6811, reward total was -21.0. running mean: -18.141719609282703, timestamp: 2022-08-19 23:40:51.697809\n",
      "resetting env. episode 6812, reward total was -18.0. running mean: -18.140302413189875, timestamp: 2022-08-19 23:40:56.273862\n",
      "resetting env. episode 6813, reward total was -19.0. running mean: -18.148899389057977, timestamp: 2022-08-19 23:41:00.415909\n",
      "resetting env. episode 6814, reward total was -17.0. running mean: -18.1374103951674, timestamp: 2022-08-19 23:41:04.365958\n",
      "resetting env. episode 6815, reward total was -20.0. running mean: -18.156036291215724, timestamp: 2022-08-19 23:41:07.653993\n",
      "resetting env. episode 6816, reward total was -19.0. running mean: -18.164475928303567, timestamp: 2022-08-19 23:41:12.317041\n",
      "resetting env. episode 6817, reward total was -18.0. running mean: -18.16283116902053, timestamp: 2022-08-19 23:41:16.144085\n",
      "resetting env. episode 6818, reward total was -20.0. running mean: -18.181202857330327, timestamp: 2022-08-19 23:41:19.942128\n",
      "resetting env. episode 6819, reward total was -21.0. running mean: -18.209390828757023, timestamp: 2022-08-19 23:41:23.305170\n",
      "resetting env. episode 6820, reward total was -19.0. running mean: -18.217296920469455, timestamp: 2022-08-19 23:41:27.369210\n",
      "resetting env. episode 6821, reward total was -18.0. running mean: -18.21512395126476, timestamp: 2022-08-19 23:41:31.391256\n",
      "resetting env. episode 6822, reward total was -18.0. running mean: -18.212972711752112, timestamp: 2022-08-19 23:41:35.866305\n",
      "resetting env. episode 6823, reward total was -19.0. running mean: -18.220842984634594, timestamp: 2022-08-19 23:41:39.499346\n",
      "resetting env. episode 6824, reward total was -13.0. running mean: -18.168634554788248, timestamp: 2022-08-19 23:41:44.142397\n",
      "resetting env. episode 6825, reward total was -18.0. running mean: -18.166948209240367, timestamp: 2022-08-19 23:41:48.186444\n",
      "resetting env. episode 6826, reward total was -17.0. running mean: -18.155278727147966, timestamp: 2022-08-19 23:41:52.087488\n",
      "resetting env. episode 6827, reward total was -16.0. running mean: -18.133725939876488, timestamp: 2022-08-19 23:41:55.869528\n",
      "resetting env. episode 6828, reward total was -20.0. running mean: -18.15238868047772, timestamp: 2022-08-19 23:41:59.511568\n",
      "resetting env. episode 6829, reward total was -15.0. running mean: -18.120864793672943, timestamp: 2022-08-19 23:42:04.300627\n",
      "resetting env. episode 6830, reward total was -17.0. running mean: -18.109656145736217, timestamp: 2022-08-19 23:42:09.021674\n",
      "resetting env. episode 6831, reward total was -16.0. running mean: -18.088559584278855, timestamp: 2022-08-19 23:42:12.919721\n",
      "resetting env. episode 6832, reward total was -21.0. running mean: -18.117673988436067, timestamp: 2022-08-19 23:42:17.207765\n",
      "resetting env. episode 6833, reward total was -20.0. running mean: -18.136497248551706, timestamp: 2022-08-19 23:42:21.543813\n",
      "resetting env. episode 6834, reward total was -20.0. running mean: -18.155132276066187, timestamp: 2022-08-19 23:42:24.913852\n",
      "resetting env. episode 6835, reward total was -19.0. running mean: -18.163580953305527, timestamp: 2022-08-19 23:42:28.595897\n",
      "resetting env. episode 6836, reward total was -15.0. running mean: -18.13194514377247, timestamp: 2022-08-19 23:42:33.128944\n",
      "resetting env. episode 6837, reward total was -19.0. running mean: -18.140625692334744, timestamp: 2022-08-19 23:42:36.202975\n",
      "resetting env. episode 6838, reward total was -18.0. running mean: -18.139219435411395, timestamp: 2022-08-19 23:42:41.059029\n",
      "resetting env. episode 6839, reward total was -16.0. running mean: -18.11782724105728, timestamp: 2022-08-19 23:42:45.406078\n",
      "resetting env. episode 6840, reward total was -21.0. running mean: -18.14664896864671, timestamp: 2022-08-19 23:42:49.250119\n",
      "resetting env. episode 6841, reward total was -19.0. running mean: -18.155182478960242, timestamp: 2022-08-19 23:42:53.837175\n",
      "resetting env. episode 6842, reward total was -17.0. running mean: -18.143630654170643, timestamp: 2022-08-19 23:42:57.428211\n",
      "resetting env. episode 6843, reward total was -17.0. running mean: -18.13219434762894, timestamp: 2022-08-19 23:43:01.688261\n",
      "resetting env. episode 6844, reward total was -18.0. running mean: -18.13087240415265, timestamp: 2022-08-19 23:43:05.715308\n",
      "resetting env. episode 6845, reward total was -16.0. running mean: -18.109563680111126, timestamp: 2022-08-19 23:43:09.620346\n",
      "resetting env. episode 6846, reward total was -17.0. running mean: -18.098468043310017, timestamp: 2022-08-19 23:43:13.823394\n",
      "resetting env. episode 6847, reward total was -19.0. running mean: -18.10748336287692, timestamp: 2022-08-19 23:43:18.233443\n",
      "resetting env. episode 6848, reward total was -14.0. running mean: -18.06640852924815, timestamp: 2022-08-19 23:43:23.168499\n",
      "resetting env. episode 6849, reward total was -18.0. running mean: -18.06574444395567, timestamp: 2022-08-19 23:43:26.996541\n",
      "resetting env. episode 6850, reward total was -17.0. running mean: -18.055086999516114, timestamp: 2022-08-19 23:43:31.280588\n",
      "resetting env. episode 6851, reward total was -18.0. running mean: -18.05453612952095, timestamp: 2022-08-19 23:43:35.421633\n",
      "resetting env. episode 6852, reward total was -19.0. running mean: -18.063990768225743, timestamp: 2022-08-19 23:43:39.912687\n",
      "resetting env. episode 6853, reward total was -17.0. running mean: -18.053350860543485, timestamp: 2022-08-19 23:43:43.040717\n",
      "resetting env. episode 6854, reward total was -20.0. running mean: -18.07281735193805, timestamp: 2022-08-19 23:43:47.352775\n",
      "resetting env. episode 6855, reward total was -17.0. running mean: -18.06208917841867, timestamp: 2022-08-19 23:43:50.707802\n",
      "resetting env. episode 6856, reward total was -17.0. running mean: -18.051468286634485, timestamp: 2022-08-19 23:43:55.018853\n",
      "resetting env. episode 6857, reward total was -15.0. running mean: -18.020953603768138, timestamp: 2022-08-19 23:44:00.190911\n",
      "resetting env. episode 6858, reward total was -18.0. running mean: -18.020744067730455, timestamp: 2022-08-19 23:44:03.662947\n",
      "resetting env. episode 6859, reward total was -18.0. running mean: -18.02053662705315, timestamp: 2022-08-19 23:44:07.504988\n",
      "resetting env. episode 6860, reward total was -18.0. running mean: -18.02033126078262, timestamp: 2022-08-19 23:44:11.881038\n",
      "resetting env. episode 6861, reward total was -18.0. running mean: -18.020127948174792, timestamp: 2022-08-19 23:44:16.005084\n",
      "resetting env. episode 6862, reward total was -19.0. running mean: -18.029926668693047, timestamp: 2022-08-19 23:44:19.828125\n",
      "resetting env. episode 6863, reward total was -18.0. running mean: -18.029627402006117, timestamp: 2022-08-19 23:44:23.347164\n",
      "resetting env. episode 6864, reward total was -15.0. running mean: -17.999331127986054, timestamp: 2022-08-19 23:44:27.709212\n",
      "resetting env. episode 6865, reward total was -16.0. running mean: -17.97933781670619, timestamp: 2022-08-19 23:44:31.591255\n",
      "resetting env. episode 6866, reward total was -19.0. running mean: -17.98954443853913, timestamp: 2022-08-19 23:44:35.640300\n",
      "resetting env. episode 6867, reward total was -20.0. running mean: -18.00964899415374, timestamp: 2022-08-19 23:44:39.147339\n",
      "resetting env. episode 6868, reward total was -18.0. running mean: -18.009552504212202, timestamp: 2022-08-19 23:44:42.873381\n",
      "resetting env. episode 6869, reward total was -15.0. running mean: -17.979456979170077, timestamp: 2022-08-19 23:44:47.618434\n",
      "resetting env. episode 6870, reward total was -19.0. running mean: -17.98966240937838, timestamp: 2022-08-19 23:44:51.650474\n",
      "resetting env. episode 6871, reward total was -17.0. running mean: -17.9797657852846, timestamp: 2022-08-19 23:44:56.137527\n",
      "resetting env. episode 6872, reward total was -17.0. running mean: -17.969968127431756, timestamp: 2022-08-19 23:44:59.692568\n",
      "resetting env. episode 6873, reward total was -20.0. running mean: -17.990268446157437, timestamp: 2022-08-19 23:45:03.367607\n",
      "resetting env. episode 6874, reward total was -18.0. running mean: -17.990365761695863, timestamp: 2022-08-19 23:45:06.769644\n",
      "resetting env. episode 6875, reward total was -20.0. running mean: -18.010462104078904, timestamp: 2022-08-19 23:45:10.128680\n",
      "resetting env. episode 6876, reward total was -14.0. running mean: -17.970357483038114, timestamp: 2022-08-19 23:45:15.671739\n",
      "resetting env. episode 6877, reward total was -21.0. running mean: -18.000653908207735, timestamp: 2022-08-19 23:45:19.205780\n",
      "resetting env. episode 6878, reward total was -20.0. running mean: -18.020647369125655, timestamp: 2022-08-19 23:45:22.474815\n",
      "resetting env. episode 6879, reward total was -20.0. running mean: -18.040440895434397, timestamp: 2022-08-19 23:45:26.045853\n",
      "resetting env. episode 6880, reward total was -19.0. running mean: -18.050036486480053, timestamp: 2022-08-19 23:45:30.451902\n",
      "resetting env. episode 6881, reward total was -18.0. running mean: -18.04953612161525, timestamp: 2022-08-19 23:45:34.225943\n",
      "resetting env. episode 6882, reward total was -18.0. running mean: -18.049040760399098, timestamp: 2022-08-19 23:45:38.907998\n",
      "resetting env. episode 6883, reward total was -19.0. running mean: -18.05855035279511, timestamp: 2022-08-19 23:45:43.007053\n",
      "resetting env. episode 6884, reward total was -16.0. running mean: -18.03796484926716, timestamp: 2022-08-19 23:45:47.499091\n",
      "resetting env. episode 6885, reward total was -19.0. running mean: -18.04758520077449, timestamp: 2022-08-19 23:45:50.958133\n",
      "resetting env. episode 6886, reward total was -19.0. running mean: -18.057109348766744, timestamp: 2022-08-19 23:45:55.145176\n",
      "resetting env. episode 6887, reward total was -17.0. running mean: -18.046538255279078, timestamp: 2022-08-19 23:45:59.064217\n",
      "resetting env. episode 6888, reward total was -21.0. running mean: -18.07607287272629, timestamp: 2022-08-19 23:46:02.724258\n",
      "resetting env. episode 6889, reward total was -19.0. running mean: -18.085312143999026, timestamp: 2022-08-19 23:46:06.494299\n",
      "resetting env. episode 6890, reward total was -18.0. running mean: -18.084459022559034, timestamp: 2022-08-19 23:46:11.520354\n",
      "resetting env. episode 6891, reward total was -19.0. running mean: -18.093614432333446, timestamp: 2022-08-19 23:46:15.803400\n",
      "resetting env. episode 6892, reward total was -17.0. running mean: -18.08267828801011, timestamp: 2022-08-19 23:46:19.586443\n",
      "resetting env. episode 6893, reward total was -17.0. running mean: -18.071851505130013, timestamp: 2022-08-19 23:46:23.255487\n",
      "resetting env. episode 6894, reward total was -18.0. running mean: -18.071132990078713, timestamp: 2022-08-19 23:46:27.065524\n",
      "resetting env. episode 6895, reward total was -18.0. running mean: -18.070421660177924, timestamp: 2022-08-19 23:46:30.931571\n",
      "resetting env. episode 6896, reward total was -21.0. running mean: -18.099717443576147, timestamp: 2022-08-19 23:46:35.258617\n",
      "resetting env. episode 6897, reward total was -19.0. running mean: -18.108720269140385, timestamp: 2022-08-19 23:46:38.876658\n",
      "resetting env. episode 6898, reward total was -20.0. running mean: -18.12763306644898, timestamp: 2022-08-19 23:46:42.925699\n",
      "resetting env. episode 6899, reward total was -16.0. running mean: -18.10635673578449, timestamp: 2022-08-19 23:46:46.918747\n",
      "resetting env. episode 6900, reward total was -19.0. running mean: -18.115293168426646, timestamp: 2022-08-19 23:46:51.852796\n",
      "resetting env. episode 6901, reward total was -19.0. running mean: -18.12414023674238, timestamp: 2022-08-19 23:46:56.267846\n",
      "resetting env. episode 6902, reward total was -21.0. running mean: -18.15289883437496, timestamp: 2022-08-19 23:46:58.958874\n",
      "resetting env. episode 6903, reward total was -20.0. running mean: -18.171369846031208, timestamp: 2022-08-19 23:47:02.908919\n",
      "resetting env. episode 6904, reward total was -17.0. running mean: -18.159656147570896, timestamp: 2022-08-19 23:47:07.446968\n",
      "resetting env. episode 6905, reward total was -17.0. running mean: -18.14805958609519, timestamp: 2022-08-19 23:47:12.220021\n",
      "resetting env. episode 6906, reward total was -15.0. running mean: -18.11657899023424, timestamp: 2022-08-19 23:47:16.465066\n",
      "resetting env. episode 6907, reward total was -20.0. running mean: -18.135413200331897, timestamp: 2022-08-19 23:47:20.439111\n",
      "resetting env. episode 6908, reward total was -18.0. running mean: -18.13405906832858, timestamp: 2022-08-19 23:47:25.224164\n",
      "resetting env. episode 6909, reward total was -20.0. running mean: -18.15271847764529, timestamp: 2022-08-19 23:47:29.022205\n",
      "resetting env. episode 6910, reward total was -21.0. running mean: -18.18119129286884, timestamp: 2022-08-19 23:47:33.308248\n",
      "resetting env. episode 6911, reward total was -18.0. running mean: -18.17937937994015, timestamp: 2022-08-19 23:47:37.869300\n",
      "resetting env. episode 6912, reward total was -19.0. running mean: -18.187585586140752, timestamp: 2022-08-19 23:47:41.966346\n",
      "resetting env. episode 6913, reward total was -21.0. running mean: -18.215709730279347, timestamp: 2022-08-19 23:47:45.883387\n",
      "resetting env. episode 6914, reward total was -19.0. running mean: -18.223552632976553, timestamp: 2022-08-19 23:47:49.309432\n",
      "resetting env. episode 6915, reward total was -15.0. running mean: -18.191317106646785, timestamp: 2022-08-19 23:47:53.255467\n",
      "resetting env. episode 6916, reward total was -17.0. running mean: -18.179403935580318, timestamp: 2022-08-19 23:47:57.481512\n",
      "resetting env. episode 6917, reward total was -17.0. running mean: -18.167609896224516, timestamp: 2022-08-19 23:48:01.234557\n",
      "resetting env. episode 6918, reward total was -19.0. running mean: -18.17593379726227, timestamp: 2022-08-19 23:48:05.349600\n",
      "resetting env. episode 6919, reward total was -16.0. running mean: -18.15417445928965, timestamp: 2022-08-19 23:48:09.274643\n",
      "resetting env. episode 6920, reward total was -17.0. running mean: -18.142632714696756, timestamp: 2022-08-19 23:48:13.233686\n",
      "resetting env. episode 6921, reward total was -17.0. running mean: -18.13120638754979, timestamp: 2022-08-19 23:48:17.520734\n",
      "resetting env. episode 6922, reward total was -19.0. running mean: -18.13989432367429, timestamp: 2022-08-19 23:48:22.105793\n",
      "resetting env. episode 6923, reward total was -19.0. running mean: -18.14849538043755, timestamp: 2022-08-19 23:48:26.156829\n",
      "resetting env. episode 6924, reward total was -21.0. running mean: -18.177010426633174, timestamp: 2022-08-19 23:48:30.548877\n",
      "resetting env. episode 6925, reward total was -16.0. running mean: -18.155240322366843, timestamp: 2022-08-19 23:48:35.128930\n",
      "resetting env. episode 6926, reward total was -19.0. running mean: -18.163687919143175, timestamp: 2022-08-19 23:48:39.273975\n",
      "resetting env. episode 6927, reward total was -19.0. running mean: -18.172051039951743, timestamp: 2022-08-19 23:48:42.571012\n",
      "resetting env. episode 6928, reward total was -17.0. running mean: -18.160330529552226, timestamp: 2022-08-19 23:48:46.330052\n",
      "resetting env. episode 6929, reward total was -17.0. running mean: -18.148727224256707, timestamp: 2022-08-19 23:48:49.982095\n",
      "resetting env. episode 6930, reward total was -19.0. running mean: -18.15723995201414, timestamp: 2022-08-19 23:48:53.499130\n",
      "resetting env. episode 6931, reward total was -19.0. running mean: -18.165667552494, timestamp: 2022-08-19 23:48:58.615188\n",
      "resetting env. episode 6932, reward total was -19.0. running mean: -18.17401087696906, timestamp: 2022-08-19 23:49:02.658232\n",
      "resetting env. episode 6933, reward total was -16.0. running mean: -18.15227076819937, timestamp: 2022-08-19 23:49:06.608278\n",
      "resetting env. episode 6934, reward total was -20.0. running mean: -18.170748060517376, timestamp: 2022-08-19 23:49:10.977330\n",
      "resetting env. episode 6935, reward total was -19.0. running mean: -18.179040579912204, timestamp: 2022-08-19 23:49:14.819368\n",
      "resetting env. episode 6936, reward total was -19.0. running mean: -18.187250174113082, timestamp: 2022-08-19 23:49:18.487411\n",
      "resetting env. episode 6937, reward total was -15.0. running mean: -18.155377672371948, timestamp: 2022-08-19 23:49:22.790457\n",
      "resetting env. episode 6938, reward total was -20.0. running mean: -18.173823895648226, timestamp: 2022-08-19 23:49:26.625501\n",
      "resetting env. episode 6939, reward total was -20.0. running mean: -18.19208565669174, timestamp: 2022-08-19 23:49:30.158537\n",
      "resetting env. episode 6940, reward total was -18.0. running mean: -18.190164800124823, timestamp: 2022-08-19 23:49:34.192586\n",
      "resetting env. episode 6941, reward total was -18.0. running mean: -18.188263152123575, timestamp: 2022-08-19 23:49:38.099629\n",
      "resetting env. episode 6942, reward total was -19.0. running mean: -18.19638052060234, timestamp: 2022-08-19 23:49:42.446677\n",
      "resetting env. episode 6943, reward total was -20.0. running mean: -18.214416715396315, timestamp: 2022-08-19 23:49:46.104716\n",
      "resetting env. episode 6944, reward total was -21.0. running mean: -18.24227254824235, timestamp: 2022-08-19 23:49:49.994763\n",
      "resetting env. episode 6945, reward total was -14.0. running mean: -18.199849822759926, timestamp: 2022-08-19 23:49:54.643814\n",
      "resetting env. episode 6946, reward total was -20.0. running mean: -18.217851324532326, timestamp: 2022-08-19 23:49:58.588859\n",
      "resetting env. episode 6947, reward total was -19.0. running mean: -18.225672811287005, timestamp: 2022-08-19 23:50:01.898893\n",
      "resetting env. episode 6948, reward total was -17.0. running mean: -18.213416083174135, timestamp: 2022-08-19 23:50:06.504946\n",
      "resetting env. episode 6949, reward total was -16.0. running mean: -18.191281922342394, timestamp: 2022-08-19 23:50:11.938007\n",
      "resetting env. episode 6950, reward total was -19.0. running mean: -18.199369103118972, timestamp: 2022-08-19 23:50:16.723060\n",
      "resetting env. episode 6951, reward total was -16.0. running mean: -18.177375412087784, timestamp: 2022-08-19 23:50:20.804108\n",
      "resetting env. episode 6952, reward total was -19.0. running mean: -18.185601657966906, timestamp: 2022-08-19 23:50:24.370149\n",
      "resetting env. episode 6953, reward total was -18.0. running mean: -18.183745641387237, timestamp: 2022-08-19 23:50:28.314193\n",
      "resetting env. episode 6954, reward total was -17.0. running mean: -18.171908184973365, timestamp: 2022-08-19 23:50:32.809243\n",
      "resetting env. episode 6955, reward total was -21.0. running mean: -18.20018910312363, timestamp: 2022-08-19 23:50:37.034287\n",
      "resetting env. episode 6956, reward total was -19.0. running mean: -18.208187212092394, timestamp: 2022-08-19 23:50:42.564352\n",
      "resetting env. episode 6957, reward total was -17.0. running mean: -18.19610533997147, timestamp: 2022-08-19 23:50:47.520407\n",
      "resetting env. episode 6958, reward total was -17.0. running mean: -18.184144286571758, timestamp: 2022-08-19 23:50:52.093459\n",
      "resetting env. episode 6959, reward total was -13.0. running mean: -18.13230284370604, timestamp: 2022-08-19 23:50:57.017516\n",
      "resetting env. episode 6960, reward total was -18.0. running mean: -18.13097981526898, timestamp: 2022-08-19 23:51:02.016569\n",
      "resetting env. episode 6961, reward total was -20.0. running mean: -18.14967001711629, timestamp: 2022-08-19 23:51:05.372609\n",
      "resetting env. episode 6962, reward total was -21.0. running mean: -18.178173316945127, timestamp: 2022-08-19 23:51:08.916649\n",
      "resetting env. episode 6963, reward total was -18.0. running mean: -18.176391583775676, timestamp: 2022-08-19 23:51:12.612689\n",
      "resetting env. episode 6964, reward total was -19.0. running mean: -18.18462766793792, timestamp: 2022-08-19 23:51:16.046728\n",
      "resetting env. episode 6965, reward total was -19.0. running mean: -18.192781391258542, timestamp: 2022-08-19 23:51:19.580768\n",
      "resetting env. episode 6966, reward total was -16.0. running mean: -18.170853577345955, timestamp: 2022-08-19 23:51:23.637816\n",
      "resetting env. episode 6967, reward total was -17.0. running mean: -18.159145041572497, timestamp: 2022-08-19 23:51:28.756871\n",
      "resetting env. episode 6968, reward total was -19.0. running mean: -18.167553591156775, timestamp: 2022-08-19 23:51:32.757917\n",
      "resetting env. episode 6969, reward total was -17.0. running mean: -18.155878055245207, timestamp: 2022-08-19 23:51:36.228954\n",
      "resetting env. episode 6970, reward total was -19.0. running mean: -18.164319274692755, timestamp: 2022-08-19 23:51:39.553994\n",
      "resetting env. episode 6971, reward total was -18.0. running mean: -18.162676081945826, timestamp: 2022-08-19 23:51:43.648047\n",
      "resetting env. episode 6972, reward total was -15.0. running mean: -18.131049321126365, timestamp: 2022-08-19 23:51:47.485083\n",
      "resetting env. episode 6973, reward total was -20.0. running mean: -18.1497388279151, timestamp: 2022-08-19 23:51:51.149127\n",
      "resetting env. episode 6974, reward total was -16.0. running mean: -18.12824143963595, timestamp: 2022-08-19 23:51:55.661177\n",
      "resetting env. episode 6975, reward total was -17.0. running mean: -18.11695902523959, timestamp: 2022-08-19 23:51:59.867228\n",
      "resetting env. episode 6976, reward total was -19.0. running mean: -18.125789434987198, timestamp: 2022-08-19 23:52:03.925269\n",
      "resetting env. episode 6977, reward total was -19.0. running mean: -18.134531540637326, timestamp: 2022-08-19 23:52:07.638314\n",
      "resetting env. episode 6978, reward total was -16.0. running mean: -18.11318622523095, timestamp: 2022-08-19 23:52:12.050362\n",
      "resetting env. episode 6979, reward total was -16.0. running mean: -18.09205436297864, timestamp: 2022-08-19 23:52:16.432414\n",
      "resetting env. episode 6980, reward total was -20.0. running mean: -18.111133819348854, timestamp: 2022-08-19 23:52:19.937451\n",
      "resetting env. episode 6981, reward total was -13.0. running mean: -18.060022481155364, timestamp: 2022-08-19 23:52:25.154509\n",
      "resetting env. episode 6982, reward total was -18.0. running mean: -18.05942225634381, timestamp: 2022-08-19 23:52:28.817554\n",
      "resetting env. episode 6983, reward total was -13.0. running mean: -18.00882803378037, timestamp: 2022-08-19 23:52:32.740594\n",
      "resetting env. episode 6984, reward total was -19.0. running mean: -18.01873975344257, timestamp: 2022-08-19 23:52:36.741638\n",
      "resetting env. episode 6985, reward total was -17.0. running mean: -18.008552355908147, timestamp: 2022-08-19 23:52:41.274690\n",
      "resetting env. episode 6986, reward total was -17.0. running mean: -17.998466832349067, timestamp: 2022-08-19 23:52:45.810742\n",
      "resetting env. episode 6987, reward total was -20.0. running mean: -18.018482164025574, timestamp: 2022-08-19 23:52:49.556785\n",
      "resetting env. episode 6988, reward total was -16.0. running mean: -17.998297342385317, timestamp: 2022-08-19 23:52:54.003834\n",
      "resetting env. episode 6989, reward total was -21.0. running mean: -18.028314368961464, timestamp: 2022-08-19 23:52:57.560875\n",
      "resetting env. episode 6990, reward total was -17.0. running mean: -18.01803122527185, timestamp: 2022-08-19 23:53:01.110915\n",
      "resetting env. episode 6991, reward total was -16.0. running mean: -17.997850913019132, timestamp: 2022-08-19 23:53:06.193972\n",
      "resetting env. episode 6992, reward total was -18.0. running mean: -17.99787240388894, timestamp: 2022-08-19 23:53:10.449023\n",
      "resetting env. episode 6993, reward total was -15.0. running mean: -17.96789367985005, timestamp: 2022-08-19 23:53:15.147075\n",
      "resetting env. episode 6994, reward total was -18.0. running mean: -17.96821474305155, timestamp: 2022-08-19 23:53:18.695117\n",
      "resetting env. episode 6995, reward total was -15.0. running mean: -17.938532595621034, timestamp: 2022-08-19 23:53:23.617169\n",
      "resetting env. episode 6996, reward total was -19.0. running mean: -17.949147269664824, timestamp: 2022-08-19 23:53:26.908205\n",
      "resetting env. episode 6997, reward total was -19.0. running mean: -17.95965579696818, timestamp: 2022-08-19 23:53:31.392257\n",
      "resetting env. episode 6998, reward total was -21.0. running mean: -17.990059238998498, timestamp: 2022-08-19 23:53:34.874298\n",
      "resetting env. episode 6999, reward total was -18.0. running mean: -17.990158646608513, timestamp: 2022-08-19 23:53:39.316347\n",
      "resetting env. episode 7000, reward total was -13.0. running mean: -17.94025706014243, timestamp: 2022-08-19 23:53:43.909398\n",
      "resetting env. episode 7001, reward total was -19.0. running mean: -17.950854489541005, timestamp: 2022-08-19 23:53:47.940444\n",
      "resetting env. episode 7002, reward total was -13.0. running mean: -17.901345944645595, timestamp: 2022-08-19 23:53:52.702499\n",
      "resetting env. episode 7003, reward total was -17.0. running mean: -17.89233248519914, timestamp: 2022-08-19 23:53:56.283539\n",
      "resetting env. episode 7004, reward total was -18.0. running mean: -17.89340916034715, timestamp: 2022-08-19 23:53:59.748578\n",
      "resetting env. episode 7005, reward total was -21.0. running mean: -17.92447506874368, timestamp: 2022-08-19 23:54:03.426621\n",
      "resetting env. episode 7006, reward total was -20.0. running mean: -17.94523031805624, timestamp: 2022-08-19 23:54:08.132673\n",
      "resetting env. episode 7007, reward total was -17.0. running mean: -17.93577801487568, timestamp: 2022-08-19 23:54:11.742711\n",
      "resetting env. episode 7008, reward total was -18.0. running mean: -17.936420234726924, timestamp: 2022-08-19 23:54:15.652758\n",
      "resetting env. episode 7009, reward total was -21.0. running mean: -17.967056032379656, timestamp: 2022-08-19 23:54:19.434799\n",
      "resetting env. episode 7010, reward total was -15.0. running mean: -17.93738547205586, timestamp: 2022-08-19 23:54:23.605848\n",
      "resetting env. episode 7011, reward total was -19.0. running mean: -17.9480116173353, timestamp: 2022-08-19 23:54:27.255887\n",
      "resetting env. episode 7012, reward total was -18.0. running mean: -17.94853150116195, timestamp: 2022-08-19 23:54:32.034942\n",
      "resetting env. episode 7013, reward total was -18.0. running mean: -17.94904618615033, timestamp: 2022-08-19 23:54:35.369982\n",
      "resetting env. episode 7014, reward total was -20.0. running mean: -17.969555724288824, timestamp: 2022-08-19 23:54:37.962014\n",
      "resetting env. episode 7015, reward total was -19.0. running mean: -17.97986016704594, timestamp: 2022-08-19 23:54:42.371058\n",
      "resetting env. episode 7016, reward total was -20.0. running mean: -18.00006156537548, timestamp: 2022-08-19 23:54:46.386107\n",
      "resetting env. episode 7017, reward total was -19.0. running mean: -18.010060949721726, timestamp: 2022-08-19 23:54:50.389150\n",
      "resetting env. episode 7018, reward total was -17.0. running mean: -17.99996034022451, timestamp: 2022-08-19 23:54:53.814188\n",
      "resetting env. episode 7019, reward total was -15.0. running mean: -17.969960736822266, timestamp: 2022-08-19 23:54:58.287240\n",
      "resetting env. episode 7020, reward total was -16.0. running mean: -17.95026112945404, timestamp: 2022-08-19 23:55:03.745301\n",
      "resetting env. episode 7021, reward total was -15.0. running mean: -17.9207585181595, timestamp: 2022-08-19 23:55:08.492357\n",
      "resetting env. episode 7022, reward total was -13.0. running mean: -17.871550932977904, timestamp: 2022-08-19 23:55:12.863405\n",
      "resetting env. episode 7023, reward total was -19.0. running mean: -17.882835423648125, timestamp: 2022-08-19 23:55:16.770449\n",
      "resetting env. episode 7024, reward total was -18.0. running mean: -17.88400706941164, timestamp: 2022-08-19 23:55:20.514492\n",
      "resetting env. episode 7025, reward total was -20.0. running mean: -17.905166998717522, timestamp: 2022-08-19 23:55:24.232530\n",
      "resetting env. episode 7026, reward total was -16.0. running mean: -17.886115328730348, timestamp: 2022-08-19 23:55:27.853571\n",
      "resetting env. episode 7027, reward total was -18.0. running mean: -17.887254175443044, timestamp: 2022-08-19 23:55:31.618614\n",
      "resetting env. episode 7028, reward total was -19.0. running mean: -17.898381633688615, timestamp: 2022-08-19 23:55:34.927653\n",
      "resetting env. episode 7029, reward total was -20.0. running mean: -17.91939781735173, timestamp: 2022-08-19 23:55:38.492696\n",
      "resetting env. episode 7030, reward total was -17.0. running mean: -17.910203839178212, timestamp: 2022-08-19 23:55:42.572739\n",
      "resetting env. episode 7031, reward total was -16.0. running mean: -17.89110180078643, timestamp: 2022-08-19 23:55:46.070778\n",
      "resetting env. episode 7032, reward total was -20.0. running mean: -17.912190782778566, timestamp: 2022-08-19 23:55:49.639822\n",
      "resetting env. episode 7033, reward total was -15.0. running mean: -17.88306887495078, timestamp: 2022-08-19 23:55:53.458865\n",
      "resetting env. episode 7034, reward total was -18.0. running mean: -17.884238186201273, timestamp: 2022-08-19 23:55:57.966913\n",
      "resetting env. episode 7035, reward total was -16.0. running mean: -17.86539580433926, timestamp: 2022-08-19 23:56:03.284973\n",
      "resetting env. episode 7036, reward total was -17.0. running mean: -17.856741846295872, timestamp: 2022-08-19 23:56:07.529023\n",
      "resetting env. episode 7037, reward total was -17.0. running mean: -17.848174427832916, timestamp: 2022-08-19 23:56:11.877074\n",
      "resetting env. episode 7038, reward total was -19.0. running mean: -17.859692683554588, timestamp: 2022-08-19 23:56:16.096119\n",
      "resetting env. episode 7039, reward total was -14.0. running mean: -17.821095756719043, timestamp: 2022-08-19 23:56:20.183167\n",
      "resetting env. episode 7040, reward total was -18.0. running mean: -17.82288479915185, timestamp: 2022-08-19 23:56:23.888205\n",
      "resetting env. episode 7041, reward total was -20.0. running mean: -17.84465595116033, timestamp: 2022-08-19 23:56:27.834253\n",
      "resetting env. episode 7042, reward total was -20.0. running mean: -17.866209391648727, timestamp: 2022-08-19 23:56:31.557295\n",
      "resetting env. episode 7043, reward total was -21.0. running mean: -17.897547297732242, timestamp: 2022-08-19 23:56:35.006336\n",
      "resetting env. episode 7044, reward total was -18.0. running mean: -17.898571824754917, timestamp: 2022-08-19 23:56:39.235381\n",
      "resetting env. episode 7045, reward total was -17.0. running mean: -17.88958610650737, timestamp: 2022-08-19 23:56:43.311427\n",
      "resetting env. episode 7046, reward total was -18.0. running mean: -17.890690245442297, timestamp: 2022-08-19 23:56:46.827468\n",
      "resetting env. episode 7047, reward total was -17.0. running mean: -17.881783342987877, timestamp: 2022-08-19 23:56:51.676522\n",
      "resetting env. episode 7048, reward total was -19.0. running mean: -17.892965509558, timestamp: 2022-08-19 23:56:56.003570\n",
      "resetting env. episode 7049, reward total was -14.0. running mean: -17.85403585446242, timestamp: 2022-08-19 23:56:59.335609\n",
      "resetting env. episode 7050, reward total was -20.0. running mean: -17.875495495917797, timestamp: 2022-08-19 23:57:02.761646\n",
      "resetting env. episode 7051, reward total was -19.0. running mean: -17.88674054095862, timestamp: 2022-08-19 23:57:07.421700\n",
      "resetting env. episode 7052, reward total was -15.0. running mean: -17.85787313554903, timestamp: 2022-08-19 23:57:11.833749\n",
      "resetting env. episode 7053, reward total was -18.0. running mean: -17.85929440419354, timestamp: 2022-08-19 23:57:16.132795\n",
      "resetting env. episode 7054, reward total was -19.0. running mean: -17.870701460151608, timestamp: 2022-08-19 23:57:19.895838\n",
      "resetting env. episode 7055, reward total was -20.0. running mean: -17.89199444555009, timestamp: 2022-08-19 23:57:23.906889\n",
      "resetting env. episode 7056, reward total was -18.0. running mean: -17.89307450109459, timestamp: 2022-08-19 23:57:27.345923\n",
      "resetting env. episode 7057, reward total was -14.0. running mean: -17.854143756083644, timestamp: 2022-08-19 23:57:31.071966\n",
      "resetting env. episode 7058, reward total was -18.0. running mean: -17.855602318522806, timestamp: 2022-08-19 23:57:35.195010\n",
      "resetting env. episode 7059, reward total was -18.0. running mean: -17.85704629533758, timestamp: 2022-08-19 23:57:39.486062\n",
      "resetting env. episode 7060, reward total was -17.0. running mean: -17.848475832384203, timestamp: 2022-08-19 23:57:42.979099\n",
      "resetting env. episode 7061, reward total was -18.0. running mean: -17.84999107406036, timestamp: 2022-08-19 23:57:47.364148\n",
      "resetting env. episode 7062, reward total was -19.0. running mean: -17.861491163319755, timestamp: 2022-08-19 23:57:51.588199\n",
      "resetting env. episode 7063, reward total was -21.0. running mean: -17.89287625168656, timestamp: 2022-08-19 23:57:55.269241\n",
      "resetting env. episode 7064, reward total was -19.0. running mean: -17.903947489169695, timestamp: 2022-08-19 23:57:58.473275\n",
      "resetting env. episode 7065, reward total was -16.0. running mean: -17.884908014277997, timestamp: 2022-08-19 23:58:03.121327\n",
      "resetting env. episode 7066, reward total was -19.0. running mean: -17.89605893413522, timestamp: 2022-08-19 23:58:07.899381\n",
      "resetting env. episode 7067, reward total was -20.0. running mean: -17.917098344793867, timestamp: 2022-08-19 23:58:11.554423\n",
      "resetting env. episode 7068, reward total was -14.0. running mean: -17.87792736134593, timestamp: 2022-08-19 23:58:17.454488\n",
      "resetting env. episode 7069, reward total was -19.0. running mean: -17.889148087732472, timestamp: 2022-08-19 23:58:21.211530\n",
      "resetting env. episode 7070, reward total was -19.0. running mean: -17.900256606855148, timestamp: 2022-08-19 23:58:24.679568\n",
      "resetting env. episode 7071, reward total was -19.0. running mean: -17.9112540407866, timestamp: 2022-08-19 23:58:28.999619\n",
      "resetting env. episode 7072, reward total was -16.0. running mean: -17.89214150037873, timestamp: 2022-08-19 23:58:33.180667\n",
      "resetting env. episode 7073, reward total was -21.0. running mean: -17.923220085374943, timestamp: 2022-08-19 23:58:37.250712\n",
      "resetting env. episode 7074, reward total was -21.0. running mean: -17.953987884521194, timestamp: 2022-08-19 23:58:41.033751\n",
      "resetting env. episode 7075, reward total was -19.0. running mean: -17.964448005675983, timestamp: 2022-08-19 23:58:44.825796\n",
      "resetting env. episode 7076, reward total was -14.0. running mean: -17.924803525619225, timestamp: 2022-08-19 23:58:48.978841\n",
      "resetting env. episode 7077, reward total was -19.0. running mean: -17.935555490363033, timestamp: 2022-08-19 23:58:52.619881\n",
      "resetting env. episode 7078, reward total was -18.0. running mean: -17.936199935459403, timestamp: 2022-08-19 23:58:56.498925\n",
      "resetting env. episode 7079, reward total was -16.0. running mean: -17.91683793610481, timestamp: 2022-08-19 23:59:00.452971\n",
      "resetting env. episode 7080, reward total was -13.0. running mean: -17.86766955674376, timestamp: 2022-08-19 23:59:06.408036\n",
      "resetting env. episode 7081, reward total was -18.0. running mean: -17.86899286117632, timestamp: 2022-08-19 23:59:09.933074\n",
      "resetting env. episode 7082, reward total was -17.0. running mean: -17.860302932564558, timestamp: 2022-08-19 23:59:13.111109\n",
      "resetting env. episode 7083, reward total was -18.0. running mean: -17.86169990323891, timestamp: 2022-08-19 23:59:17.366158\n",
      "resetting env. episode 7084, reward total was -17.0. running mean: -17.853082904206524, timestamp: 2022-08-19 23:59:21.462204\n",
      "resetting env. episode 7085, reward total was -19.0. running mean: -17.86455207516446, timestamp: 2022-08-19 23:59:25.184245\n",
      "resetting env. episode 7086, reward total was -17.0. running mean: -17.85590655441282, timestamp: 2022-08-19 23:59:29.611307\n",
      "resetting env. episode 7087, reward total was -19.0. running mean: -17.867347488868692, timestamp: 2022-08-19 23:59:33.490343\n",
      "resetting env. episode 7088, reward total was -19.0. running mean: -17.878674013980007, timestamp: 2022-08-19 23:59:38.372394\n",
      "resetting env. episode 7089, reward total was -17.0. running mean: -17.86988727384021, timestamp: 2022-08-19 23:59:41.812436\n",
      "resetting env. episode 7090, reward total was -19.0. running mean: -17.88118840110181, timestamp: 2022-08-19 23:59:45.086468\n",
      "resetting env. episode 7091, reward total was -17.0. running mean: -17.872376517090792, timestamp: 2022-08-19 23:59:49.217515\n",
      "resetting env. episode 7092, reward total was -18.0. running mean: -17.873652751919884, timestamp: 2022-08-19 23:59:53.168560\n",
      "resetting env. episode 7093, reward total was -16.0. running mean: -17.854916224400686, timestamp: 2022-08-19 23:59:57.806612\n",
      "resetting env. episode 7094, reward total was -20.0. running mean: -17.876367062156678, timestamp: 2022-08-20 00:00:01.220651\n",
      "resetting env. episode 7095, reward total was -17.0. running mean: -17.867603391535113, timestamp: 2022-08-20 00:00:05.236693\n",
      "resetting env. episode 7096, reward total was -19.0. running mean: -17.878927357619762, timestamp: 2022-08-20 00:00:09.313742\n",
      "resetting env. episode 7097, reward total was -19.0. running mean: -17.890138084043567, timestamp: 2022-08-20 00:00:14.255797\n",
      "resetting env. episode 7098, reward total was -13.0. running mean: -17.84123670320313, timestamp: 2022-08-20 00:00:19.145852\n",
      "resetting env. episode 7099, reward total was -16.0. running mean: -17.8228243361711, timestamp: 2022-08-20 00:00:23.394898\n",
      "resetting env. episode 7100, reward total was -18.0. running mean: -17.824596092809387, timestamp: 2022-08-20 00:00:27.341943\n",
      "resetting env. episode 7101, reward total was -19.0. running mean: -17.836350131881293, timestamp: 2022-08-20 00:00:31.279986\n",
      "resetting env. episode 7102, reward total was -19.0. running mean: -17.84798663056248, timestamp: 2022-08-20 00:00:35.122032\n",
      "resetting env. episode 7103, reward total was -19.0. running mean: -17.859506764256857, timestamp: 2022-08-20 00:00:38.695069\n",
      "resetting env. episode 7104, reward total was -19.0. running mean: -17.87091169661429, timestamp: 2022-08-20 00:00:42.589114\n",
      "resetting env. episode 7105, reward total was -19.0. running mean: -17.882202579648148, timestamp: 2022-08-20 00:00:46.784167\n",
      "resetting env. episode 7106, reward total was -17.0. running mean: -17.873380553851668, timestamp: 2022-08-20 00:00:51.073207\n",
      "resetting env. episode 7107, reward total was -20.0. running mean: -17.89464674831315, timestamp: 2022-08-20 00:00:55.469256\n",
      "resetting env. episode 7108, reward total was -20.0. running mean: -17.915700280830016, timestamp: 2022-08-20 00:00:59.472300\n",
      "resetting env. episode 7109, reward total was -18.0. running mean: -17.916543278021717, timestamp: 2022-08-20 00:01:03.429346\n",
      "resetting env. episode 7110, reward total was -18.0. running mean: -17.9173778452415, timestamp: 2022-08-20 00:01:07.241385\n",
      "resetting env. episode 7111, reward total was -17.0. running mean: -17.908204066789086, timestamp: 2022-08-20 00:01:11.673436\n",
      "resetting env. episode 7112, reward total was -18.0. running mean: -17.909122026121196, timestamp: 2022-08-20 00:01:15.504479\n",
      "resetting env. episode 7113, reward total was -18.0. running mean: -17.910030805859982, timestamp: 2022-08-20 00:01:19.252522\n",
      "resetting env. episode 7114, reward total was -16.0. running mean: -17.89093049780138, timestamp: 2022-08-20 00:01:23.264562\n",
      "resetting env. episode 7115, reward total was -19.0. running mean: -17.90202119282337, timestamp: 2022-08-20 00:01:27.160608\n",
      "resetting env. episode 7116, reward total was -16.0. running mean: -17.883000980895137, timestamp: 2022-08-20 00:01:31.339656\n",
      "resetting env. episode 7117, reward total was -19.0. running mean: -17.894170971086186, timestamp: 2022-08-20 00:01:35.370697\n",
      "resetting env. episode 7118, reward total was -19.0. running mean: -17.905229261375325, timestamp: 2022-08-20 00:01:40.161752\n",
      "resetting env. episode 7119, reward total was -17.0. running mean: -17.896176968761573, timestamp: 2022-08-20 00:01:44.953805\n",
      "resetting env. episode 7120, reward total was -21.0. running mean: -17.92721519907396, timestamp: 2022-08-20 00:01:48.397844\n",
      "resetting env. episode 7121, reward total was -13.0. running mean: -17.877943047083217, timestamp: 2022-08-20 00:01:52.943896\n",
      "resetting env. episode 7122, reward total was -18.0. running mean: -17.879163616612384, timestamp: 2022-08-20 00:01:56.703933\n",
      "resetting env. episode 7123, reward total was -19.0. running mean: -17.89037198044626, timestamp: 2022-08-20 00:02:00.117975\n",
      "resetting env. episode 7124, reward total was -15.0. running mean: -17.861468260641796, timestamp: 2022-08-20 00:02:04.854027\n",
      "resetting env. episode 7125, reward total was -21.0. running mean: -17.89285357803538, timestamp: 2022-08-20 00:02:08.805070\n",
      "resetting env. episode 7126, reward total was -21.0. running mean: -17.923925042255025, timestamp: 2022-08-20 00:02:12.793118\n",
      "resetting env. episode 7127, reward total was -17.0. running mean: -17.914685791832476, timestamp: 2022-08-20 00:02:18.048175\n",
      "resetting env. episode 7128, reward total was -19.0. running mean: -17.92553893391415, timestamp: 2022-08-20 00:02:22.015221\n",
      "resetting env. episode 7129, reward total was -18.0. running mean: -17.92628354457501, timestamp: 2022-08-20 00:02:25.774262\n",
      "resetting env. episode 7130, reward total was -20.0. running mean: -17.94702070912926, timestamp: 2022-08-20 00:02:29.444300\n",
      "resetting env. episode 7131, reward total was -17.0. running mean: -17.93755050203797, timestamp: 2022-08-20 00:02:33.676347\n",
      "resetting env. episode 7132, reward total was -19.0. running mean: -17.94817499701759, timestamp: 2022-08-20 00:02:37.849394\n",
      "resetting env. episode 7133, reward total was -18.0. running mean: -17.948693247047412, timestamp: 2022-08-20 00:02:41.425431\n",
      "resetting env. episode 7134, reward total was -19.0. running mean: -17.95920631457694, timestamp: 2022-08-20 00:02:45.699479\n",
      "resetting env. episode 7135, reward total was -18.0. running mean: -17.95961425143117, timestamp: 2022-08-20 00:02:49.638524\n",
      "resetting env. episode 7136, reward total was -14.0. running mean: -17.920018108916857, timestamp: 2022-08-20 00:02:54.162577\n",
      "resetting env. episode 7137, reward total was -17.0. running mean: -17.91081792782769, timestamp: 2022-08-20 00:02:59.556631\n",
      "resetting env. episode 7138, reward total was -15.0. running mean: -17.88170974854941, timestamp: 2022-08-20 00:03:02.979671\n",
      "resetting env. episode 7139, reward total was -19.0. running mean: -17.892892651063917, timestamp: 2022-08-20 00:03:06.426709\n",
      "resetting env. episode 7140, reward total was -19.0. running mean: -17.90396372455328, timestamp: 2022-08-20 00:03:10.021747\n",
      "resetting env. episode 7141, reward total was -15.0. running mean: -17.874924087307743, timestamp: 2022-08-20 00:03:15.024804\n",
      "resetting env. episode 7142, reward total was -14.0. running mean: -17.836174846434666, timestamp: 2022-08-20 00:03:19.501855\n",
      "resetting env. episode 7143, reward total was -20.0. running mean: -17.85781309797032, timestamp: 2022-08-20 00:03:22.939892\n",
      "resetting env. episode 7144, reward total was -16.0. running mean: -17.839234966990617, timestamp: 2022-08-20 00:03:28.275948\n",
      "resetting env. episode 7145, reward total was -21.0. running mean: -17.87084261732071, timestamp: 2022-08-20 00:03:31.481987\n",
      "resetting env. episode 7146, reward total was -19.0. running mean: -17.882134191147504, timestamp: 2022-08-20 00:03:35.420029\n",
      "resetting env. episode 7147, reward total was -21.0. running mean: -17.91331284923603, timestamp: 2022-08-20 00:03:39.366071\n",
      "resetting env. episode 7148, reward total was -15.0. running mean: -17.884179720743667, timestamp: 2022-08-20 00:03:43.995125\n",
      "resetting env. episode 7149, reward total was -18.0. running mean: -17.88533792353623, timestamp: 2022-08-20 00:03:46.940155\n",
      "resetting env. episode 7150, reward total was -19.0. running mean: -17.89648454430087, timestamp: 2022-08-20 00:03:50.939197\n",
      "resetting env. episode 7151, reward total was -15.0. running mean: -17.86751969885786, timestamp: 2022-08-20 00:03:55.248247\n",
      "resetting env. episode 7152, reward total was -17.0. running mean: -17.85884450186928, timestamp: 2022-08-20 00:03:58.623282\n",
      "resetting env. episode 7153, reward total was -17.0. running mean: -17.85025605685059, timestamp: 2022-08-20 00:04:04.991352\n",
      "resetting env. episode 7154, reward total was -19.0. running mean: -17.861753496282084, timestamp: 2022-08-20 00:04:08.595396\n",
      "resetting env. episode 7155, reward total was -19.0. running mean: -17.873135961319264, timestamp: 2022-08-20 00:04:12.822440\n",
      "resetting env. episode 7156, reward total was -18.0. running mean: -17.874404601706072, timestamp: 2022-08-20 00:04:16.637486\n",
      "resetting env. episode 7157, reward total was -19.0. running mean: -17.88566055568901, timestamp: 2022-08-20 00:04:20.580524\n",
      "resetting env. episode 7158, reward total was -16.0. running mean: -17.86680395013212, timestamp: 2022-08-20 00:04:24.357566\n",
      "resetting env. episode 7159, reward total was -16.0. running mean: -17.8481359106308, timestamp: 2022-08-20 00:04:28.725614\n",
      "resetting env. episode 7160, reward total was -9.0. running mean: -17.75965455152449, timestamp: 2022-08-20 00:04:33.722668\n",
      "resetting env. episode 7161, reward total was -16.0. running mean: -17.742058006009245, timestamp: 2022-08-20 00:04:38.309721\n",
      "resetting env. episode 7162, reward total was -18.0. running mean: -17.74463742594915, timestamp: 2022-08-20 00:04:42.522766\n",
      "resetting env. episode 7163, reward total was -19.0. running mean: -17.75719105168966, timestamp: 2022-08-20 00:04:46.676811\n",
      "resetting env. episode 7164, reward total was -18.0. running mean: -17.759619141172763, timestamp: 2022-08-20 00:04:50.413852\n",
      "resetting env. episode 7165, reward total was -14.0. running mean: -17.722022949761037, timestamp: 2022-08-20 00:04:54.989905\n",
      "resetting env. episode 7166, reward total was -19.0. running mean: -17.734802720263428, timestamp: 2022-08-20 00:04:58.640944\n",
      "resetting env. episode 7167, reward total was -16.0. running mean: -17.717454693060795, timestamp: 2022-08-20 00:05:03.061994\n",
      "resetting env. episode 7168, reward total was -19.0. running mean: -17.730280146130188, timestamp: 2022-08-20 00:05:06.400038\n",
      "resetting env. episode 7169, reward total was -19.0. running mean: -17.742977344668887, timestamp: 2022-08-20 00:05:10.529073\n",
      "resetting env. episode 7170, reward total was -19.0. running mean: -17.7555475712222, timestamp: 2022-08-20 00:05:14.254115\n",
      "resetting env. episode 7171, reward total was -14.0. running mean: -17.717992095509977, timestamp: 2022-08-20 00:05:19.159176\n",
      "resetting env. episode 7172, reward total was -14.0. running mean: -17.680812174554877, timestamp: 2022-08-20 00:05:23.839221\n",
      "resetting env. episode 7173, reward total was -18.0. running mean: -17.68400405280933, timestamp: 2022-08-20 00:05:27.643265\n",
      "resetting env. episode 7174, reward total was -19.0. running mean: -17.697164012281235, timestamp: 2022-08-20 00:05:31.553307\n",
      "resetting env. episode 7175, reward total was -21.0. running mean: -17.730192372158424, timestamp: 2022-08-20 00:05:35.014346\n",
      "resetting env. episode 7176, reward total was -16.0. running mean: -17.71289044843684, timestamp: 2022-08-20 00:05:39.255392\n",
      "resetting env. episode 7177, reward total was -21.0. running mean: -17.745761543952472, timestamp: 2022-08-20 00:05:42.817432\n",
      "resetting env. episode 7178, reward total was -18.0. running mean: -17.748303928512946, timestamp: 2022-08-20 00:05:47.101481\n",
      "resetting env. episode 7179, reward total was -16.0. running mean: -17.730820889227818, timestamp: 2022-08-20 00:05:51.099524\n",
      "resetting env. episode 7180, reward total was -17.0. running mean: -17.723512680335542, timestamp: 2022-08-20 00:05:55.101569\n",
      "resetting env. episode 7181, reward total was -16.0. running mean: -17.706277553532185, timestamp: 2022-08-20 00:05:59.330621\n",
      "resetting env. episode 7182, reward total was -19.0. running mean: -17.719214777996864, timestamp: 2022-08-20 00:06:02.748659\n",
      "resetting env. episode 7183, reward total was -20.0. running mean: -17.742022630216894, timestamp: 2022-08-20 00:06:06.916711\n",
      "resetting env. episode 7184, reward total was -20.0. running mean: -17.764602403914726, timestamp: 2022-08-20 00:06:09.970737\n",
      "resetting env. episode 7185, reward total was -19.0. running mean: -17.77695637987558, timestamp: 2022-08-20 00:06:13.960783\n",
      "resetting env. episode 7186, reward total was -18.0. running mean: -17.779186816076823, timestamp: 2022-08-20 00:06:18.354829\n",
      "resetting env. episode 7187, reward total was -16.0. running mean: -17.761394947916056, timestamp: 2022-08-20 00:06:22.741882\n",
      "resetting env. episode 7188, reward total was -20.0. running mean: -17.783780998436896, timestamp: 2022-08-20 00:06:26.422921\n",
      "resetting env. episode 7189, reward total was -15.0. running mean: -17.755943188452527, timestamp: 2022-08-20 00:06:31.460978\n",
      "resetting env. episode 7190, reward total was -17.0. running mean: -17.748383756568003, timestamp: 2022-08-20 00:06:34.961016\n",
      "resetting env. episode 7191, reward total was -21.0. running mean: -17.780899919002323, timestamp: 2022-08-20 00:06:37.936050\n",
      "resetting env. episode 7192, reward total was -15.0. running mean: -17.753090919812298, timestamp: 2022-08-20 00:06:42.499101\n",
      "resetting env. episode 7193, reward total was -18.0. running mean: -17.755560010614175, timestamp: 2022-08-20 00:06:47.099154\n",
      "resetting env. episode 7194, reward total was -18.0. running mean: -17.758004410508033, timestamp: 2022-08-20 00:06:51.341205\n",
      "resetting env. episode 7195, reward total was -19.0. running mean: -17.770424366402953, timestamp: 2022-08-20 00:06:55.757252\n",
      "resetting env. episode 7196, reward total was -18.0. running mean: -17.772720122738924, timestamp: 2022-08-20 00:07:00.251302\n",
      "resetting env. episode 7197, reward total was -21.0. running mean: -17.804992921511534, timestamp: 2022-08-20 00:07:04.350352\n",
      "resetting env. episode 7198, reward total was -17.0. running mean: -17.79694299229642, timestamp: 2022-08-20 00:07:08.120391\n",
      "resetting env. episode 7199, reward total was -19.0. running mean: -17.808973562373456, timestamp: 2022-08-20 00:07:11.944435\n",
      "resetting env. episode 7200, reward total was -19.0. running mean: -17.82088382674972, timestamp: 2022-08-20 00:07:15.583475\n",
      "resetting env. episode 7201, reward total was -16.0. running mean: -17.802674988482224, timestamp: 2022-08-20 00:07:20.167529\n",
      "resetting env. episode 7202, reward total was -19.0. running mean: -17.814648238597403, timestamp: 2022-08-20 00:07:23.159566\n",
      "resetting env. episode 7203, reward total was -19.0. running mean: -17.82650175621143, timestamp: 2022-08-20 00:07:27.159607\n",
      "resetting env. episode 7204, reward total was -15.0. running mean: -17.798236738649315, timestamp: 2022-08-20 00:07:31.424654\n",
      "resetting env. episode 7205, reward total was -19.0. running mean: -17.810254371262822, timestamp: 2022-08-20 00:07:34.615693\n",
      "resetting env. episode 7206, reward total was -19.0. running mean: -17.822151827550194, timestamp: 2022-08-20 00:07:38.466735\n",
      "resetting env. episode 7207, reward total was -19.0. running mean: -17.83393030927469, timestamp: 2022-08-20 00:07:42.000776\n",
      "resetting env. episode 7208, reward total was -16.0. running mean: -17.815591006181943, timestamp: 2022-08-20 00:07:45.918820\n",
      "resetting env. episode 7209, reward total was -20.0. running mean: -17.837435096120124, timestamp: 2022-08-20 00:07:49.746867\n",
      "resetting env. episode 7210, reward total was -15.0. running mean: -17.80906074515892, timestamp: 2022-08-20 00:07:54.172919\n",
      "resetting env. episode 7211, reward total was -16.0. running mean: -17.79097013770733, timestamp: 2022-08-20 00:07:58.310960\n",
      "resetting env. episode 7212, reward total was -20.0. running mean: -17.813060436330254, timestamp: 2022-08-20 00:08:01.927005\n",
      "resetting env. episode 7213, reward total was -17.0. running mean: -17.804929831966952, timestamp: 2022-08-20 00:08:05.227042\n",
      "resetting env. episode 7214, reward total was -19.0. running mean: -17.816880533647282, timestamp: 2022-08-20 00:08:09.482090\n",
      "resetting env. episode 7215, reward total was -16.0. running mean: -17.79871172831081, timestamp: 2022-08-20 00:08:13.667137\n",
      "resetting env. episode 7216, reward total was -19.0. running mean: -17.8107246110277, timestamp: 2022-08-20 00:08:18.495190\n",
      "resetting env. episode 7217, reward total was -18.0. running mean: -17.812617364917426, timestamp: 2022-08-20 00:08:23.267246\n",
      "resetting env. episode 7218, reward total was -19.0. running mean: -17.82449119126825, timestamp: 2022-08-20 00:08:27.785297\n",
      "resetting env. episode 7219, reward total was -18.0. running mean: -17.82624627935557, timestamp: 2022-08-20 00:08:31.535341\n",
      "resetting env. episode 7220, reward total was -17.0. running mean: -17.817983816562016, timestamp: 2022-08-20 00:08:36.248394\n",
      "resetting env. episode 7221, reward total was -19.0. running mean: -17.8298039783964, timestamp: 2022-08-20 00:08:40.252441\n",
      "resetting env. episode 7222, reward total was -17.0. running mean: -17.821505938612436, timestamp: 2022-08-20 00:08:44.962494\n",
      "resetting env. episode 7223, reward total was -21.0. running mean: -17.85329087922631, timestamp: 2022-08-20 00:08:48.635534\n",
      "resetting env. episode 7224, reward total was -15.0. running mean: -17.824757970434046, timestamp: 2022-08-20 00:08:53.132585\n",
      "resetting env. episode 7225, reward total was -21.0. running mean: -17.856510390729706, timestamp: 2022-08-20 00:08:56.568625\n",
      "resetting env. episode 7226, reward total was -16.0. running mean: -17.83794528682241, timestamp: 2022-08-20 00:09:00.124664\n",
      "resetting env. episode 7227, reward total was -17.0. running mean: -17.829565833954188, timestamp: 2022-08-20 00:09:04.763718\n",
      "resetting env. episode 7228, reward total was -17.0. running mean: -17.821270175614647, timestamp: 2022-08-20 00:09:09.269773\n",
      "resetting env. episode 7229, reward total was -18.0. running mean: -17.8230574738585, timestamp: 2022-08-20 00:09:13.540818\n",
      "resetting env. episode 7230, reward total was -14.0. running mean: -17.784826899119917, timestamp: 2022-08-20 00:09:17.974868\n",
      "resetting env. episode 7231, reward total was -15.0. running mean: -17.756978630128717, timestamp: 2022-08-20 00:09:22.940927\n",
      "resetting env. episode 7232, reward total was -14.0. running mean: -17.71940884382743, timestamp: 2022-08-20 00:09:27.346975\n",
      "resetting env. episode 7233, reward total was -10.0. running mean: -17.64221475538916, timestamp: 2022-08-20 00:09:31.945029\n",
      "resetting env. episode 7234, reward total was -17.0. running mean: -17.635792607835267, timestamp: 2022-08-20 00:09:35.607072\n",
      "resetting env. episode 7235, reward total was -20.0. running mean: -17.659434681756913, timestamp: 2022-08-20 00:09:39.009113\n",
      "resetting env. episode 7236, reward total was -18.0. running mean: -17.662840334939343, timestamp: 2022-08-20 00:09:42.655155\n",
      "resetting env. episode 7237, reward total was -19.0. running mean: -17.67621193158995, timestamp: 2022-08-20 00:09:46.612205\n",
      "resetting env. episode 7238, reward total was -20.0. running mean: -17.69944981227405, timestamp: 2022-08-20 00:09:50.579243\n",
      "resetting env. episode 7239, reward total was -18.0. running mean: -17.702455314151308, timestamp: 2022-08-20 00:09:54.882292\n",
      "resetting env. episode 7240, reward total was -17.0. running mean: -17.695430761009796, timestamp: 2022-08-20 00:10:00.011354\n",
      "resetting env. episode 7241, reward total was -19.0. running mean: -17.708476453399697, timestamp: 2022-08-20 00:10:04.527403\n",
      "resetting env. episode 7242, reward total was -21.0. running mean: -17.7413916888657, timestamp: 2022-08-20 00:10:08.127445\n",
      "resetting env. episode 7243, reward total was -19.0. running mean: -17.753977771977045, timestamp: 2022-08-20 00:10:12.688497\n",
      "resetting env. episode 7244, reward total was -15.0. running mean: -17.726437994257275, timestamp: 2022-08-20 00:10:17.244552\n",
      "resetting env. episode 7245, reward total was -19.0. running mean: -17.7391736143147, timestamp: 2022-08-20 00:10:21.311596\n",
      "resetting env. episode 7246, reward total was -19.0. running mean: -17.751781878171556, timestamp: 2022-08-20 00:10:25.455645\n",
      "resetting env. episode 7247, reward total was -13.0. running mean: -17.70426405938984, timestamp: 2022-08-20 00:10:30.270702\n",
      "resetting env. episode 7248, reward total was -21.0. running mean: -17.73722141879594, timestamp: 2022-08-20 00:10:33.793740\n",
      "resetting env. episode 7249, reward total was -19.0. running mean: -17.749849204607983, timestamp: 2022-08-20 00:10:38.246791\n",
      "resetting env. episode 7250, reward total was -15.0. running mean: -17.7223507125619, timestamp: 2022-08-20 00:10:43.384852\n",
      "resetting env. episode 7251, reward total was -15.0. running mean: -17.695127205436282, timestamp: 2022-08-20 00:10:48.650913\n",
      "resetting env. episode 7252, reward total was -18.0. running mean: -17.69817593338192, timestamp: 2022-08-20 00:10:52.329956\n",
      "resetting env. episode 7253, reward total was -17.0. running mean: -17.6911941740481, timestamp: 2022-08-20 00:10:57.174009\n",
      "resetting env. episode 7254, reward total was -16.0. running mean: -17.67428223230762, timestamp: 2022-08-20 00:11:01.463061\n",
      "resetting env. episode 7255, reward total was -16.0. running mean: -17.65753940998454, timestamp: 2022-08-20 00:11:06.362119\n",
      "resetting env. episode 7256, reward total was -19.0. running mean: -17.670964015884696, timestamp: 2022-08-20 00:11:10.534167\n",
      "resetting env. episode 7257, reward total was -19.0. running mean: -17.68425437572585, timestamp: 2022-08-20 00:11:15.789234\n",
      "resetting env. episode 7258, reward total was -18.0. running mean: -17.68741183196859, timestamp: 2022-08-20 00:11:19.856284\n",
      "resetting env. episode 7259, reward total was -20.0. running mean: -17.710537713648904, timestamp: 2022-08-20 00:11:23.785326\n",
      "resetting env. episode 7260, reward total was -18.0. running mean: -17.713432336512415, timestamp: 2022-08-20 00:11:27.909373\n",
      "resetting env. episode 7261, reward total was -17.0. running mean: -17.706298013147293, timestamp: 2022-08-20 00:11:31.719417\n",
      "resetting env. episode 7262, reward total was -19.0. running mean: -17.71923503301582, timestamp: 2022-08-20 00:11:36.163467\n",
      "resetting env. episode 7263, reward total was -15.0. running mean: -17.69204268268566, timestamp: 2022-08-20 00:11:40.388518\n",
      "resetting env. episode 7264, reward total was -18.0. running mean: -17.695122255858802, timestamp: 2022-08-20 00:11:43.989559\n",
      "resetting env. episode 7265, reward total was -20.0. running mean: -17.718171033300212, timestamp: 2022-08-20 00:11:48.627615\n",
      "resetting env. episode 7266, reward total was -17.0. running mean: -17.71098932296721, timestamp: 2022-08-20 00:11:52.210653\n",
      "resetting env. episode 7267, reward total was -17.0. running mean: -17.70387942973754, timestamp: 2022-08-20 00:11:56.142699\n",
      "resetting env. episode 7268, reward total was -13.0. running mean: -17.656840635440165, timestamp: 2022-08-20 00:12:00.587752\n",
      "resetting env. episode 7269, reward total was -20.0. running mean: -17.680272229085762, timestamp: 2022-08-20 00:12:05.169801\n",
      "resetting env. episode 7270, reward total was -19.0. running mean: -17.693469506794905, timestamp: 2022-08-20 00:12:09.493853\n",
      "resetting env. episode 7271, reward total was -18.0. running mean: -17.696534811726956, timestamp: 2022-08-20 00:12:13.092898\n",
      "resetting env. episode 7272, reward total was -13.0. running mean: -17.649569463609684, timestamp: 2022-08-20 00:12:18.485957\n",
      "resetting env. episode 7273, reward total was -21.0. running mean: -17.68307376897359, timestamp: 2022-08-20 00:12:22.186999\n",
      "resetting env. episode 7274, reward total was -15.0. running mean: -17.65624303128385, timestamp: 2022-08-20 00:12:26.679053\n",
      "resetting env. episode 7275, reward total was -15.0. running mean: -17.62968060097101, timestamp: 2022-08-20 00:12:31.095100\n",
      "resetting env. episode 7276, reward total was -18.0. running mean: -17.6333837949613, timestamp: 2022-08-20 00:12:35.833153\n",
      "resetting env. episode 7277, reward total was -14.0. running mean: -17.597049957011688, timestamp: 2022-08-20 00:12:40.149205\n",
      "resetting env. episode 7278, reward total was -18.0. running mean: -17.60107945744157, timestamp: 2022-08-20 00:12:44.922261\n",
      "resetting env. episode 7279, reward total was -15.0. running mean: -17.575068662867153, timestamp: 2022-08-20 00:12:49.653316\n",
      "resetting env. episode 7280, reward total was -19.0. running mean: -17.589317976238483, timestamp: 2022-08-20 00:12:54.649370\n",
      "resetting env. episode 7281, reward total was -17.0. running mean: -17.5834247964761, timestamp: 2022-08-20 00:12:59.531429\n",
      "resetting env. episode 7282, reward total was -19.0. running mean: -17.597590548511338, timestamp: 2022-08-20 00:13:03.523474\n",
      "resetting env. episode 7283, reward total was -18.0. running mean: -17.601614643026224, timestamp: 2022-08-20 00:13:07.402520\n",
      "resetting env. episode 7284, reward total was -20.0. running mean: -17.62559849659596, timestamp: 2022-08-20 00:13:11.071562\n",
      "resetting env. episode 7285, reward total was -16.0. running mean: -17.60934251163, timestamp: 2022-08-20 00:13:15.409612\n",
      "resetting env. episode 7286, reward total was -21.0. running mean: -17.643249086513702, timestamp: 2022-08-20 00:13:19.155653\n",
      "resetting env. episode 7287, reward total was -16.0. running mean: -17.626816595648563, timestamp: 2022-08-20 00:13:24.680717\n",
      "resetting env. episode 7288, reward total was -17.0. running mean: -17.62054842969208, timestamp: 2022-08-20 00:13:28.788766\n",
      "resetting env. episode 7289, reward total was -20.0. running mean: -17.644342945395156, timestamp: 2022-08-20 00:13:33.218816\n",
      "resetting env. episode 7290, reward total was -20.0. running mean: -17.667899515941205, timestamp: 2022-08-20 00:13:36.978857\n",
      "resetting env. episode 7291, reward total was -15.0. running mean: -17.64122052078179, timestamp: 2022-08-20 00:13:41.410906\n",
      "resetting env. episode 7292, reward total was -17.0. running mean: -17.634808315573974, timestamp: 2022-08-20 00:13:45.149952\n",
      "resetting env. episode 7293, reward total was -18.0. running mean: -17.638460232418232, timestamp: 2022-08-20 00:13:49.104995\n",
      "resetting env. episode 7294, reward total was -20.0. running mean: -17.662075630094048, timestamp: 2022-08-20 00:13:53.009040\n",
      "resetting env. episode 7295, reward total was -21.0. running mean: -17.695454873793107, timestamp: 2022-08-20 00:13:57.224094\n",
      "resetting env. episode 7296, reward total was -19.0. running mean: -17.708500325055176, timestamp: 2022-08-20 00:14:02.196145\n",
      "resetting env. episode 7297, reward total was -18.0. running mean: -17.711415321804623, timestamp: 2022-08-20 00:14:06.350191\n",
      "resetting env. episode 7298, reward total was -17.0. running mean: -17.70430116858658, timestamp: 2022-08-20 00:14:10.287237\n",
      "resetting env. episode 7299, reward total was -19.0. running mean: -17.717258156900712, timestamp: 2022-08-20 00:14:14.875289\n",
      "resetting env. episode 7300, reward total was -17.0. running mean: -17.710085575331707, timestamp: 2022-08-20 00:14:19.203340\n",
      "resetting env. episode 7301, reward total was -17.0. running mean: -17.702984719578392, timestamp: 2022-08-20 00:14:23.355385\n",
      "resetting env. episode 7302, reward total was -11.0. running mean: -17.63595487238261, timestamp: 2022-08-20 00:14:29.309456\n",
      "resetting env. episode 7303, reward total was -18.0. running mean: -17.63959532365878, timestamp: 2022-08-20 00:14:32.978498\n",
      "resetting env. episode 7304, reward total was -19.0. running mean: -17.653199370422193, timestamp: 2022-08-20 00:14:37.286545\n",
      "resetting env. episode 7305, reward total was -18.0. running mean: -17.65666737671797, timestamp: 2022-08-20 00:14:41.456591\n",
      "resetting env. episode 7306, reward total was -18.0. running mean: -17.66010070295079, timestamp: 2022-08-20 00:14:45.597638\n",
      "resetting env. episode 7307, reward total was -15.0. running mean: -17.63349969592128, timestamp: 2022-08-20 00:14:50.518698\n",
      "resetting env. episode 7308, reward total was -17.0. running mean: -17.62716469896207, timestamp: 2022-08-20 00:14:54.172736\n",
      "resetting env. episode 7309, reward total was -16.0. running mean: -17.610893051972447, timestamp: 2022-08-20 00:14:58.827791\n",
      "resetting env. episode 7310, reward total was -16.0. running mean: -17.594784121452722, timestamp: 2022-08-20 00:15:03.120840\n",
      "resetting env. episode 7311, reward total was -19.0. running mean: -17.608836280238197, timestamp: 2022-08-20 00:15:07.001884\n",
      "resetting env. episode 7312, reward total was -16.0. running mean: -17.592747917435815, timestamp: 2022-08-20 00:15:12.403945\n",
      "resetting env. episode 7313, reward total was -18.0. running mean: -17.596820438261457, timestamp: 2022-08-20 00:15:16.370990\n",
      "resetting env. episode 7314, reward total was -17.0. running mean: -17.590852233878845, timestamp: 2022-08-20 00:15:20.551040\n",
      "resetting env. episode 7315, reward total was -16.0. running mean: -17.574943711540058, timestamp: 2022-08-20 00:15:24.548084\n",
      "resetting env. episode 7316, reward total was -17.0. running mean: -17.56919427442466, timestamp: 2022-08-20 00:15:28.977135\n",
      "resetting env. episode 7317, reward total was -19.0. running mean: -17.583502331680414, timestamp: 2022-08-20 00:15:32.775177\n",
      "resetting env. episode 7318, reward total was -18.0. running mean: -17.58766730836361, timestamp: 2022-08-20 00:15:37.195228\n",
      "resetting env. episode 7319, reward total was -17.0. running mean: -17.581790635279976, timestamp: 2022-08-20 00:15:41.095271\n",
      "resetting env. episode 7320, reward total was -20.0. running mean: -17.605972728927174, timestamp: 2022-08-20 00:15:45.256318\n",
      "resetting env. episode 7321, reward total was -19.0. running mean: -17.619913001637904, timestamp: 2022-08-20 00:15:50.105375\n",
      "resetting env. episode 7322, reward total was -14.0. running mean: -17.583713871621526, timestamp: 2022-08-20 00:15:54.484426\n",
      "resetting env. episode 7323, reward total was -15.0. running mean: -17.55787673290531, timestamp: 2022-08-20 00:15:58.655471\n",
      "resetting env. episode 7324, reward total was -18.0. running mean: -17.562297965576256, timestamp: 2022-08-20 00:16:03.249525\n",
      "resetting env. episode 7325, reward total was -17.0. running mean: -17.556674985920495, timestamp: 2022-08-20 00:16:08.032581\n",
      "resetting env. episode 7326, reward total was -18.0. running mean: -17.56110823606129, timestamp: 2022-08-20 00:16:12.230627\n",
      "resetting env. episode 7327, reward total was -18.0. running mean: -17.565497153700676, timestamp: 2022-08-20 00:16:17.199684\n",
      "resetting env. episode 7328, reward total was -18.0. running mean: -17.56984218216367, timestamp: 2022-08-20 00:16:21.256733\n",
      "resetting env. episode 7329, reward total was -17.0. running mean: -17.564143760342034, timestamp: 2022-08-20 00:16:25.091773\n",
      "resetting env. episode 7330, reward total was -18.0. running mean: -17.568502322738613, timestamp: 2022-08-20 00:16:29.325821\n",
      "resetting env. episode 7331, reward total was -19.0. running mean: -17.582817299511227, timestamp: 2022-08-20 00:16:33.257868\n",
      "resetting env. episode 7332, reward total was -18.0. running mean: -17.586989126516116, timestamp: 2022-08-20 00:16:37.773917\n",
      "resetting env. episode 7333, reward total was -17.0. running mean: -17.581119235250956, timestamp: 2022-08-20 00:16:42.424971\n",
      "resetting env. episode 7334, reward total was -20.0. running mean: -17.605308042898447, timestamp: 2022-08-20 00:16:46.730021\n",
      "resetting env. episode 7335, reward total was -16.0. running mean: -17.58925496246946, timestamp: 2022-08-20 00:16:52.177079\n",
      "resetting env. episode 7336, reward total was -15.0. running mean: -17.563362412844764, timestamp: 2022-08-20 00:16:57.158143\n",
      "resetting env. episode 7337, reward total was -18.0. running mean: -17.567728788716316, timestamp: 2022-08-20 00:17:00.832181\n",
      "resetting env. episode 7338, reward total was -17.0. running mean: -17.562051500829153, timestamp: 2022-08-20 00:17:04.889227\n",
      "resetting env. episode 7339, reward total was -18.0. running mean: -17.566430985820862, timestamp: 2022-08-20 00:17:08.318268\n",
      "resetting env. episode 7340, reward total was -19.0. running mean: -17.580766675962654, timestamp: 2022-08-20 00:17:12.824315\n",
      "resetting env. episode 7341, reward total was -21.0. running mean: -17.614959009203027, timestamp: 2022-08-20 00:17:16.590356\n",
      "resetting env. episode 7342, reward total was -20.0. running mean: -17.638809419110995, timestamp: 2022-08-20 00:17:20.650403\n",
      "resetting env. episode 7343, reward total was -17.0. running mean: -17.632421324919886, timestamp: 2022-08-20 00:17:25.265459\n",
      "resetting env. episode 7344, reward total was -18.0. running mean: -17.636097111670686, timestamp: 2022-08-20 00:17:29.552502\n",
      "resetting env. episode 7345, reward total was -17.0. running mean: -17.62973614055398, timestamp: 2022-08-20 00:17:33.773550\n",
      "resetting env. episode 7346, reward total was -17.0. running mean: -17.623438779148444, timestamp: 2022-08-20 00:17:37.773598\n",
      "resetting env. episode 7347, reward total was -15.0. running mean: -17.597204391356957, timestamp: 2022-08-20 00:17:42.815654\n",
      "resetting env. episode 7348, reward total was -17.0. running mean: -17.591232347443388, timestamp: 2022-08-20 00:17:46.876698\n",
      "resetting env. episode 7349, reward total was -18.0. running mean: -17.595320023968952, timestamp: 2022-08-20 00:17:50.610741\n",
      "resetting env. episode 7350, reward total was -19.0. running mean: -17.609366823729264, timestamp: 2022-08-20 00:17:54.727787\n",
      "resetting env. episode 7351, reward total was -18.0. running mean: -17.61327315549197, timestamp: 2022-08-20 00:17:58.606830\n",
      "resetting env. episode 7352, reward total was -19.0. running mean: -17.627140423937053, timestamp: 2022-08-20 00:18:02.959880\n",
      "resetting env. episode 7353, reward total was -17.0. running mean: -17.620869019697686, timestamp: 2022-08-20 00:18:07.585936\n",
      "resetting env. episode 7354, reward total was -21.0. running mean: -17.65466032950071, timestamp: 2022-08-20 00:18:11.154973\n",
      "resetting env. episode 7355, reward total was -15.0. running mean: -17.6281137262057, timestamp: 2022-08-20 00:18:15.831026\n",
      "resetting env. episode 7356, reward total was -16.0. running mean: -17.611832588943646, timestamp: 2022-08-20 00:18:20.513077\n",
      "resetting env. episode 7357, reward total was -15.0. running mean: -17.585714263054207, timestamp: 2022-08-20 00:18:24.716129\n",
      "resetting env. episode 7358, reward total was -21.0. running mean: -17.619857120423667, timestamp: 2022-08-20 00:18:28.725172\n",
      "resetting env. episode 7359, reward total was -17.0. running mean: -17.613658549219434, timestamp: 2022-08-20 00:18:33.955234\n",
      "resetting env. episode 7360, reward total was -14.0. running mean: -17.57752196372724, timestamp: 2022-08-20 00:18:37.965278\n",
      "resetting env. episode 7361, reward total was -17.0. running mean: -17.571746744089968, timestamp: 2022-08-20 00:18:42.159327\n",
      "resetting env. episode 7362, reward total was -14.0. running mean: -17.536029276649067, timestamp: 2022-08-20 00:18:47.349382\n",
      "resetting env. episode 7363, reward total was -19.0. running mean: -17.550668983882577, timestamp: 2022-08-20 00:18:51.632432\n",
      "resetting env. episode 7364, reward total was -16.0. running mean: -17.53516229404375, timestamp: 2022-08-20 00:18:55.129469\n",
      "resetting env. episode 7365, reward total was -13.0. running mean: -17.489810671103314, timestamp: 2022-08-20 00:18:59.137519\n",
      "resetting env. episode 7366, reward total was -16.0. running mean: -17.47491256439228, timestamp: 2022-08-20 00:19:03.741567\n",
      "resetting env. episode 7367, reward total was -14.0. running mean: -17.440163438748357, timestamp: 2022-08-20 00:19:09.475633\n",
      "resetting env. episode 7368, reward total was -21.0. running mean: -17.475761804360875, timestamp: 2022-08-20 00:19:13.364676\n",
      "resetting env. episode 7369, reward total was -21.0. running mean: -17.511004186317265, timestamp: 2022-08-20 00:19:17.622725\n",
      "resetting env. episode 7370, reward total was -18.0. running mean: -17.51589414445409, timestamp: 2022-08-20 00:19:21.957777\n",
      "resetting env. episode 7371, reward total was -11.0. running mean: -17.45073520300955, timestamp: 2022-08-20 00:19:27.112829\n",
      "resetting env. episode 7372, reward total was -17.0. running mean: -17.446227850979458, timestamp: 2022-08-20 00:19:31.523878\n",
      "resetting env. episode 7373, reward total was -17.0. running mean: -17.441765572469667, timestamp: 2022-08-20 00:19:35.820926\n",
      "resetting env. episode 7374, reward total was -20.0. running mean: -17.46734791674497, timestamp: 2022-08-20 00:19:39.931972\n",
      "resetting env. episode 7375, reward total was -21.0. running mean: -17.50267443757752, timestamp: 2022-08-20 00:19:43.284015\n",
      "resetting env. episode 7376, reward total was -16.0. running mean: -17.487647693201748, timestamp: 2022-08-20 00:19:47.870061\n",
      "resetting env. episode 7377, reward total was -17.0. running mean: -17.482771216269732, timestamp: 2022-08-20 00:19:51.716108\n",
      "resetting env. episode 7378, reward total was -9.0. running mean: -17.397943504107033, timestamp: 2022-08-20 00:19:57.510175\n",
      "resetting env. episode 7379, reward total was -18.0. running mean: -17.403964069065964, timestamp: 2022-08-20 00:20:01.922222\n",
      "resetting env. episode 7380, reward total was -19.0. running mean: -17.419924428375307, timestamp: 2022-08-20 00:20:05.999264\n",
      "resetting env. episode 7381, reward total was -21.0. running mean: -17.455725184091555, timestamp: 2022-08-20 00:20:09.407305\n",
      "resetting env. episode 7382, reward total was -15.0. running mean: -17.431167932250638, timestamp: 2022-08-20 00:20:14.042356\n",
      "resetting env. episode 7383, reward total was -20.0. running mean: -17.45685625292813, timestamp: 2022-08-20 00:20:18.484407\n",
      "resetting env. episode 7384, reward total was -19.0. running mean: -17.47228769039885, timestamp: 2022-08-20 00:20:22.571452\n",
      "resetting env. episode 7385, reward total was -16.0. running mean: -17.457564813494862, timestamp: 2022-08-20 00:20:26.982498\n",
      "resetting env. episode 7386, reward total was -17.0. running mean: -17.452989165359917, timestamp: 2022-08-20 00:20:31.244545\n",
      "resetting env. episode 7387, reward total was -19.0. running mean: -17.46845927370632, timestamp: 2022-08-20 00:20:35.092595\n",
      "resetting env. episode 7388, reward total was -19.0. running mean: -17.48377468096926, timestamp: 2022-08-20 00:20:38.679634\n",
      "resetting env. episode 7389, reward total was -18.0. running mean: -17.488936934159565, timestamp: 2022-08-20 00:20:42.230673\n",
      "resetting env. episode 7390, reward total was -17.0. running mean: -17.48404756481797, timestamp: 2022-08-20 00:20:46.532719\n",
      "resetting env. episode 7391, reward total was -19.0. running mean: -17.499207089169794, timestamp: 2022-08-20 00:20:51.387774\n",
      "resetting env. episode 7392, reward total was -18.0. running mean: -17.504215018278096, timestamp: 2022-08-20 00:20:55.878837\n",
      "resetting env. episode 7393, reward total was -21.0. running mean: -17.539172868095317, timestamp: 2022-08-20 00:20:59.204861\n",
      "resetting env. episode 7394, reward total was -20.0. running mean: -17.563781139414363, timestamp: 2022-08-20 00:21:02.764900\n",
      "resetting env. episode 7395, reward total was -15.0. running mean: -17.53814332802022, timestamp: 2022-08-20 00:21:07.362951\n",
      "resetting env. episode 7396, reward total was -15.0. running mean: -17.512761894740017, timestamp: 2022-08-20 00:21:11.588999\n",
      "resetting env. episode 7397, reward total was -18.0. running mean: -17.517634275792616, timestamp: 2022-08-20 00:21:16.451056\n",
      "resetting env. episode 7398, reward total was -17.0. running mean: -17.512457933034693, timestamp: 2022-08-20 00:21:20.783109\n",
      "resetting env. episode 7399, reward total was -19.0. running mean: -17.527333353704346, timestamp: 2022-08-20 00:21:25.381154\n",
      "resetting env. episode 7400, reward total was -18.0. running mean: -17.532060020167304, timestamp: 2022-08-20 00:21:29.370199\n",
      "resetting env. episode 7401, reward total was -20.0. running mean: -17.55673941996563, timestamp: 2022-08-20 00:21:33.169239\n",
      "resetting env. episode 7402, reward total was -19.0. running mean: -17.571172025765975, timestamp: 2022-08-20 00:21:37.102285\n",
      "resetting env. episode 7403, reward total was -15.0. running mean: -17.545460305508314, timestamp: 2022-08-20 00:21:40.754328\n",
      "resetting env. episode 7404, reward total was -20.0. running mean: -17.57000570245323, timestamp: 2022-08-20 00:21:44.882372\n",
      "resetting env. episode 7405, reward total was -16.0. running mean: -17.5543056454287, timestamp: 2022-08-20 00:21:48.971415\n",
      "resetting env. episode 7406, reward total was -17.0. running mean: -17.548762588974412, timestamp: 2022-08-20 00:21:53.019460\n",
      "resetting env. episode 7407, reward total was -18.0. running mean: -17.553274963084668, timestamp: 2022-08-20 00:21:57.779515\n",
      "resetting env. episode 7408, reward total was -13.0. running mean: -17.50774221345382, timestamp: 2022-08-20 00:22:02.783571\n",
      "resetting env. episode 7409, reward total was -19.0. running mean: -17.522664791319283, timestamp: 2022-08-20 00:22:06.315610\n",
      "resetting env. episode 7410, reward total was -14.0. running mean: -17.48743814340609, timestamp: 2022-08-20 00:22:11.728671\n",
      "resetting env. episode 7411, reward total was -18.0. running mean: -17.49256376197203, timestamp: 2022-08-20 00:22:15.098711\n",
      "resetting env. episode 7412, reward total was -21.0. running mean: -17.52763812435231, timestamp: 2022-08-20 00:22:19.073755\n",
      "resetting env. episode 7413, reward total was -17.0. running mean: -17.52236174310879, timestamp: 2022-08-20 00:22:22.972802\n",
      "resetting env. episode 7414, reward total was -15.0. running mean: -17.4971381256777, timestamp: 2022-08-20 00:22:27.068845\n",
      "resetting env. episode 7415, reward total was -20.0. running mean: -17.52216674442092, timestamp: 2022-08-20 00:22:31.147889\n",
      "resetting env. episode 7416, reward total was -21.0. running mean: -17.556945076976714, timestamp: 2022-08-20 00:22:35.123936\n",
      "resetting env. episode 7417, reward total was -19.0. running mean: -17.571375626206947, timestamp: 2022-08-20 00:22:39.774986\n",
      "resetting env. episode 7418, reward total was -15.0. running mean: -17.545661869944876, timestamp: 2022-08-20 00:22:44.063034\n",
      "resetting env. episode 7419, reward total was -20.0. running mean: -17.570205251245426, timestamp: 2022-08-20 00:22:47.263075\n",
      "resetting env. episode 7420, reward total was -19.0. running mean: -17.58450319873297, timestamp: 2022-08-20 00:22:51.305116\n",
      "resetting env. episode 7421, reward total was -18.0. running mean: -17.588658166745642, timestamp: 2022-08-20 00:22:54.956160\n",
      "resetting env. episode 7422, reward total was -20.0. running mean: -17.612771585078185, timestamp: 2022-08-20 00:22:58.854202\n",
      "resetting env. episode 7423, reward total was -18.0. running mean: -17.616643869227403, timestamp: 2022-08-20 00:23:02.714250\n",
      "resetting env. episode 7424, reward total was -15.0. running mean: -17.590477430535127, timestamp: 2022-08-20 00:23:07.472299\n",
      "resetting env. episode 7425, reward total was -20.0. running mean: -17.614572656229775, timestamp: 2022-08-20 00:23:11.008342\n",
      "resetting env. episode 7426, reward total was -15.0. running mean: -17.588426929667477, timestamp: 2022-08-20 00:23:15.416393\n",
      "resetting env. episode 7427, reward total was -20.0. running mean: -17.612542660370803, timestamp: 2022-08-20 00:23:19.688439\n",
      "resetting env. episode 7428, reward total was -19.0. running mean: -17.626417233767096, timestamp: 2022-08-20 00:23:23.867484\n",
      "resetting env. episode 7429, reward total was -21.0. running mean: -17.660153061429426, timestamp: 2022-08-20 00:23:27.507536\n",
      "resetting env. episode 7430, reward total was -17.0. running mean: -17.653551530815133, timestamp: 2022-08-20 00:23:32.169576\n",
      "resetting env. episode 7431, reward total was -21.0. running mean: -17.68701601550698, timestamp: 2022-08-20 00:23:36.533629\n",
      "resetting env. episode 7432, reward total was -16.0. running mean: -17.67014585535191, timestamp: 2022-08-20 00:23:40.950682\n",
      "resetting env. episode 7433, reward total was -19.0. running mean: -17.683444396798393, timestamp: 2022-08-20 00:23:44.583719\n",
      "resetting env. episode 7434, reward total was -17.0. running mean: -17.67660995283041, timestamp: 2022-08-20 00:23:48.300764\n",
      "resetting env. episode 7435, reward total was -20.0. running mean: -17.699843853302106, timestamp: 2022-08-20 00:23:52.723814\n",
      "resetting env. episode 7436, reward total was -17.0. running mean: -17.692845414769085, timestamp: 2022-08-20 00:23:56.921862\n",
      "resetting env. episode 7437, reward total was -15.0. running mean: -17.66591696062139, timestamp: 2022-08-20 00:24:02.048923\n",
      "resetting env. episode 7438, reward total was -15.0. running mean: -17.639257791015176, timestamp: 2022-08-20 00:24:05.653959\n",
      "resetting env. episode 7439, reward total was -17.0. running mean: -17.632865213105024, timestamp: 2022-08-20 00:24:09.527004\n",
      "resetting env. episode 7440, reward total was -16.0. running mean: -17.616536560973973, timestamp: 2022-08-20 00:24:13.631053\n",
      "resetting env. episode 7441, reward total was -15.0. running mean: -17.59037119536423, timestamp: 2022-08-20 00:24:18.338104\n",
      "resetting env. episode 7442, reward total was -19.0. running mean: -17.60446748341059, timestamp: 2022-08-20 00:24:22.498154\n",
      "resetting env. episode 7443, reward total was -19.0. running mean: -17.618422808576486, timestamp: 2022-08-20 00:24:26.787201\n",
      "resetting env. episode 7444, reward total was -21.0. running mean: -17.65223858049072, timestamp: 2022-08-20 00:24:30.578243\n",
      "resetting env. episode 7445, reward total was -16.0. running mean: -17.635716194685813, timestamp: 2022-08-20 00:24:35.186296\n",
      "resetting env. episode 7446, reward total was -17.0. running mean: -17.629359032738957, timestamp: 2022-08-20 00:24:40.030352\n",
      "resetting env. episode 7447, reward total was -16.0. running mean: -17.613065442411568, timestamp: 2022-08-20 00:24:44.245399\n",
      "resetting env. episode 7448, reward total was -16.0. running mean: -17.59693478798745, timestamp: 2022-08-20 00:24:48.591451\n",
      "resetting env. episode 7449, reward total was -16.0. running mean: -17.580965440107576, timestamp: 2022-08-20 00:24:53.006504\n",
      "resetting env. episode 7450, reward total was -19.0. running mean: -17.595155785706503, timestamp: 2022-08-20 00:24:56.273537\n",
      "resetting env. episode 7451, reward total was -20.0. running mean: -17.619204227849437, timestamp: 2022-08-20 00:25:00.691590\n",
      "resetting env. episode 7452, reward total was -19.0. running mean: -17.633012185570944, timestamp: 2022-08-20 00:25:05.964650\n",
      "resetting env. episode 7453, reward total was -16.0. running mean: -17.616682063715235, timestamp: 2022-08-20 00:25:11.189709\n",
      "resetting env. episode 7454, reward total was -15.0. running mean: -17.59051524307808, timestamp: 2022-08-20 00:25:14.833752\n",
      "resetting env. episode 7455, reward total was -21.0. running mean: -17.6246100906473, timestamp: 2022-08-20 00:25:18.833799\n",
      "resetting env. episode 7456, reward total was -18.0. running mean: -17.62836398974083, timestamp: 2022-08-20 00:25:23.434849\n",
      "resetting env. episode 7457, reward total was -16.0. running mean: -17.61208034984342, timestamp: 2022-08-20 00:25:28.371906\n",
      "resetting env. episode 7458, reward total was -18.0. running mean: -17.615959546344985, timestamp: 2022-08-20 00:25:32.148949\n",
      "resetting env. episode 7459, reward total was -21.0. running mean: -17.649799950881537, timestamp: 2022-08-20 00:25:35.772994\n",
      "resetting env. episode 7460, reward total was -19.0. running mean: -17.663301951372723, timestamp: 2022-08-20 00:25:39.673034\n",
      "resetting env. episode 7461, reward total was -18.0. running mean: -17.666668931858997, timestamp: 2022-08-20 00:25:43.199079\n",
      "resetting env. episode 7462, reward total was -15.0. running mean: -17.640002242540405, timestamp: 2022-08-20 00:25:47.477127\n",
      "resetting env. episode 7463, reward total was -14.0. running mean: -17.603602220115, timestamp: 2022-08-20 00:25:53.081192\n",
      "resetting env. episode 7464, reward total was -21.0. running mean: -17.637566197913852, timestamp: 2022-08-20 00:25:57.483240\n",
      "resetting env. episode 7465, reward total was -17.0. running mean: -17.631190535934714, timestamp: 2022-08-20 00:26:01.314288\n",
      "resetting env. episode 7466, reward total was -15.0. running mean: -17.604878630575364, timestamp: 2022-08-20 00:26:05.491333\n",
      "resetting env. episode 7467, reward total was -21.0. running mean: -17.638829844269612, timestamp: 2022-08-20 00:26:09.035377\n",
      "resetting env. episode 7468, reward total was -17.0. running mean: -17.632441545826918, timestamp: 2022-08-20 00:26:14.244434\n",
      "resetting env. episode 7469, reward total was -18.0. running mean: -17.63611713036865, timestamp: 2022-08-20 00:26:18.549482\n",
      "resetting env. episode 7470, reward total was -14.0. running mean: -17.599755959064964, timestamp: 2022-08-20 00:26:23.305537\n",
      "resetting env. episode 7471, reward total was -18.0. running mean: -17.603758399474316, timestamp: 2022-08-20 00:26:27.380588\n",
      "resetting env. episode 7472, reward total was -19.0. running mean: -17.617720815479572, timestamp: 2022-08-20 00:26:32.271641\n",
      "resetting env. episode 7473, reward total was -16.0. running mean: -17.601543607324775, timestamp: 2022-08-20 00:26:37.041697\n",
      "resetting env. episode 7474, reward total was -18.0. running mean: -17.605528171251528, timestamp: 2022-08-20 00:26:41.067743\n",
      "resetting env. episode 7475, reward total was -21.0. running mean: -17.639472889539014, timestamp: 2022-08-20 00:26:46.122800\n",
      "resetting env. episode 7476, reward total was -19.0. running mean: -17.653078160643627, timestamp: 2022-08-20 00:26:49.911846\n",
      "resetting env. episode 7477, reward total was -20.0. running mean: -17.67654737903719, timestamp: 2022-08-20 00:26:53.451885\n",
      "resetting env. episode 7478, reward total was -17.0. running mean: -17.66978190524682, timestamp: 2022-08-20 00:26:57.916934\n",
      "resetting env. episode 7479, reward total was -18.0. running mean: -17.67308408619435, timestamp: 2022-08-20 00:27:01.511978\n",
      "resetting env. episode 7480, reward total was -15.0. running mean: -17.646353245332406, timestamp: 2022-08-20 00:27:06.025029\n",
      "resetting env. episode 7481, reward total was -21.0. running mean: -17.67988971287908, timestamp: 2022-08-20 00:27:09.559072\n",
      "resetting env. episode 7482, reward total was -17.0. running mean: -17.673090815750292, timestamp: 2022-08-20 00:27:14.533130\n",
      "resetting env. episode 7483, reward total was -16.0. running mean: -17.65635990759279, timestamp: 2022-08-20 00:27:18.896180\n",
      "resetting env. episode 7484, reward total was -14.0. running mean: -17.619796308516865, timestamp: 2022-08-20 00:27:23.423232\n",
      "resetting env. episode 7485, reward total was -16.0. running mean: -17.603598345431696, timestamp: 2022-08-20 00:27:27.622276\n",
      "resetting env. episode 7486, reward total was -18.0. running mean: -17.60756236197738, timestamp: 2022-08-20 00:27:32.627336\n",
      "resetting env. episode 7487, reward total was -20.0. running mean: -17.631486738357605, timestamp: 2022-08-20 00:27:35.867374\n",
      "resetting env. episode 7488, reward total was -19.0. running mean: -17.64517187097403, timestamp: 2022-08-20 00:27:40.638428\n",
      "resetting env. episode 7489, reward total was -18.0. running mean: -17.64872015226429, timestamp: 2022-08-20 00:27:45.168481\n",
      "resetting env. episode 7490, reward total was -17.0. running mean: -17.642232950741647, timestamp: 2022-08-20 00:27:49.932535\n",
      "resetting env. episode 7491, reward total was -17.0. running mean: -17.63581062123423, timestamp: 2022-08-20 00:27:54.492587\n",
      "resetting env. episode 7492, reward total was -20.0. running mean: -17.65945251502189, timestamp: 2022-08-20 00:27:58.382634\n",
      "resetting env. episode 7493, reward total was -18.0. running mean: -17.66285798987167, timestamp: 2022-08-20 00:28:02.386678\n",
      "resetting env. episode 7494, reward total was -16.0. running mean: -17.646229409972953, timestamp: 2022-08-20 00:28:07.013730\n",
      "resetting env. episode 7495, reward total was -21.0. running mean: -17.679767115873226, timestamp: 2022-08-20 00:28:10.197769\n",
      "resetting env. episode 7496, reward total was -18.0. running mean: -17.682969444714495, timestamp: 2022-08-20 00:28:14.159814\n",
      "resetting env. episode 7497, reward total was -21.0. running mean: -17.71613975026735, timestamp: 2022-08-20 00:28:18.133860\n",
      "resetting env. episode 7498, reward total was -17.0. running mean: -17.708978352764678, timestamp: 2022-08-20 00:28:22.730910\n",
      "resetting env. episode 7499, reward total was -20.0. running mean: -17.73188856923703, timestamp: 2022-08-20 00:28:27.091961\n",
      "resetting env. episode 7500, reward total was -17.0. running mean: -17.72456968354466, timestamp: 2022-08-20 00:28:32.511025\n",
      "resetting env. episode 7501, reward total was -12.0. running mean: -17.667323986709217, timestamp: 2022-08-20 00:28:38.127088\n",
      "resetting env. episode 7502, reward total was -20.0. running mean: -17.690650746842124, timestamp: 2022-08-20 00:28:42.739141\n",
      "resetting env. episode 7503, reward total was -19.0. running mean: -17.703744239373705, timestamp: 2022-08-20 00:28:47.678199\n",
      "resetting env. episode 7504, reward total was -16.0. running mean: -17.68670679697997, timestamp: 2022-08-20 00:28:52.508258\n",
      "resetting env. episode 7505, reward total was -21.0. running mean: -17.71983972901017, timestamp: 2022-08-20 00:28:56.465298\n",
      "resetting env. episode 7506, reward total was -17.0. running mean: -17.71264133172007, timestamp: 2022-08-20 00:29:00.507348\n",
      "resetting env. episode 7507, reward total was -19.0. running mean: -17.725514918402872, timestamp: 2022-08-20 00:29:03.949383\n",
      "resetting env. episode 7508, reward total was -16.0. running mean: -17.708259769218845, timestamp: 2022-08-20 00:29:08.573440\n",
      "resetting env. episode 7509, reward total was -20.0. running mean: -17.731177171526657, timestamp: 2022-08-20 00:29:12.715487\n",
      "resetting env. episode 7510, reward total was -18.0. running mean: -17.73386539981139, timestamp: 2022-08-20 00:29:17.268538\n",
      "resetting env. episode 7511, reward total was -17.0. running mean: -17.726526745813278, timestamp: 2022-08-20 00:29:22.248596\n",
      "resetting env. episode 7512, reward total was -15.0. running mean: -17.699261478355144, timestamp: 2022-08-20 00:29:26.782648\n",
      "resetting env. episode 7513, reward total was -18.0. running mean: -17.702268863571593, timestamp: 2022-08-20 00:29:31.309702\n",
      "resetting env. episode 7514, reward total was -18.0. running mean: -17.705246174935876, timestamp: 2022-08-20 00:29:35.801750\n",
      "resetting env. episode 7515, reward total was -17.0. running mean: -17.69819371318652, timestamp: 2022-08-20 00:29:40.155800\n",
      "resetting env. episode 7516, reward total was -17.0. running mean: -17.691211776054654, timestamp: 2022-08-20 00:29:45.026857\n",
      "resetting env. episode 7517, reward total was -17.0. running mean: -17.68429965829411, timestamp: 2022-08-20 00:29:49.361908\n",
      "resetting env. episode 7518, reward total was -18.0. running mean: -17.687456661711167, timestamp: 2022-08-20 00:29:54.280969\n",
      "resetting env. episode 7519, reward total was -18.0. running mean: -17.690582095094054, timestamp: 2022-08-20 00:29:58.414020\n",
      "resetting env. episode 7520, reward total was -18.0. running mean: -17.69367627414311, timestamp: 2022-08-20 00:30:03.275066\n",
      "resetting env. episode 7521, reward total was -20.0. running mean: -17.71673951140168, timestamp: 2022-08-20 00:30:07.886121\n",
      "resetting env. episode 7522, reward total was -20.0. running mean: -17.73957211628766, timestamp: 2022-08-20 00:30:12.239173\n",
      "resetting env. episode 7523, reward total was -17.0. running mean: -17.732176395124785, timestamp: 2022-08-20 00:30:16.820222\n",
      "resetting env. episode 7524, reward total was -19.0. running mean: -17.74485463117354, timestamp: 2022-08-20 00:30:21.348275\n",
      "resetting env. episode 7525, reward total was -15.0. running mean: -17.7174060848618, timestamp: 2022-08-20 00:30:26.075329\n",
      "resetting env. episode 7526, reward total was -17.0. running mean: -17.710232024013184, timestamp: 2022-08-20 00:30:30.349382\n",
      "resetting env. episode 7527, reward total was -17.0. running mean: -17.703129703773055, timestamp: 2022-08-20 00:30:34.649429\n",
      "resetting env. episode 7528, reward total was -16.0. running mean: -17.686098406735326, timestamp: 2022-08-20 00:30:38.971478\n",
      "resetting env. episode 7529, reward total was -17.0. running mean: -17.679237422667974, timestamp: 2022-08-20 00:30:43.828532\n",
      "resetting env. episode 7530, reward total was -15.0. running mean: -17.652445048441294, timestamp: 2022-08-20 00:30:48.948594\n",
      "resetting env. episode 7531, reward total was -15.0. running mean: -17.625920597956878, timestamp: 2022-08-20 00:30:54.112659\n",
      "resetting env. episode 7532, reward total was -15.0. running mean: -17.599661391977307, timestamp: 2022-08-20 00:30:57.858695\n",
      "resetting env. episode 7533, reward total was -17.0. running mean: -17.593664778057537, timestamp: 2022-08-20 00:31:01.793742\n",
      "resetting env. episode 7534, reward total was -15.0. running mean: -17.56772813027696, timestamp: 2022-08-20 00:31:06.255794\n",
      "resetting env. episode 7535, reward total was -19.0. running mean: -17.582050848974195, timestamp: 2022-08-20 00:31:10.810851\n",
      "resetting env. episode 7536, reward total was -19.0. running mean: -17.596230340484453, timestamp: 2022-08-20 00:31:14.024880\n",
      "resetting env. episode 7537, reward total was -19.0. running mean: -17.61026803707961, timestamp: 2022-08-20 00:31:18.054926\n",
      "resetting env. episode 7538, reward total was -19.0. running mean: -17.624165356708815, timestamp: 2022-08-20 00:31:21.546970\n",
      "resetting env. episode 7539, reward total was -14.0. running mean: -17.587923703141726, timestamp: 2022-08-20 00:31:25.841020\n",
      "resetting env. episode 7540, reward total was -17.0. running mean: -17.58204446611031, timestamp: 2022-08-20 00:31:30.459068\n",
      "resetting env. episode 7541, reward total was -19.0. running mean: -17.59622402144921, timestamp: 2022-08-20 00:31:34.585118\n",
      "resetting env. episode 7542, reward total was -16.0. running mean: -17.580261781234718, timestamp: 2022-08-20 00:31:39.056169\n",
      "resetting env. episode 7543, reward total was -15.0. running mean: -17.55445916342237, timestamp: 2022-08-20 00:31:43.872226\n",
      "resetting env. episode 7544, reward total was -17.0. running mean: -17.548914571788146, timestamp: 2022-08-20 00:31:47.547266\n",
      "resetting env. episode 7545, reward total was -16.0. running mean: -17.533425426070263, timestamp: 2022-08-20 00:31:52.124317\n",
      "resetting env. episode 7546, reward total was -16.0. running mean: -17.51809117180956, timestamp: 2022-08-20 00:31:55.850361\n",
      "resetting env. episode 7547, reward total was -18.0. running mean: -17.522910260091464, timestamp: 2022-08-20 00:32:00.503414\n",
      "resetting env. episode 7548, reward total was -19.0. running mean: -17.53768115749055, timestamp: 2022-08-20 00:32:05.929475\n",
      "resetting env. episode 7549, reward total was -20.0. running mean: -17.562304345915642, timestamp: 2022-08-20 00:32:10.047525\n",
      "resetting env. episode 7550, reward total was -19.0. running mean: -17.576681302456485, timestamp: 2022-08-20 00:32:13.942567\n",
      "resetting env. episode 7551, reward total was -17.0. running mean: -17.57091448943192, timestamp: 2022-08-20 00:32:17.308607\n",
      "resetting env. episode 7552, reward total was -18.0. running mean: -17.5752053445376, timestamp: 2022-08-20 00:32:22.028657\n",
      "resetting env. episode 7553, reward total was -16.0. running mean: -17.559453291092225, timestamp: 2022-08-20 00:32:26.513709\n",
      "resetting env. episode 7554, reward total was -17.0. running mean: -17.553858758181306, timestamp: 2022-08-20 00:32:31.435767\n",
      "resetting env. episode 7555, reward total was -16.0. running mean: -17.538320170599494, timestamp: 2022-08-20 00:32:35.277808\n",
      "resetting env. episode 7556, reward total was -11.0. running mean: -17.4729369688935, timestamp: 2022-08-20 00:32:40.702871\n",
      "resetting env. episode 7557, reward total was -18.0. running mean: -17.478207599204563, timestamp: 2022-08-20 00:32:45.362922\n",
      "resetting env. episode 7558, reward total was -18.0. running mean: -17.483425523212517, timestamp: 2022-08-20 00:32:50.248983\n",
      "resetting env. episode 7559, reward total was -19.0. running mean: -17.498591267980395, timestamp: 2022-08-20 00:32:53.838022\n",
      "resetting env. episode 7560, reward total was -20.0. running mean: -17.52360535530059, timestamp: 2022-08-20 00:32:57.947067\n",
      "resetting env. episode 7561, reward total was -15.0. running mean: -17.49836930174758, timestamp: 2022-08-20 00:33:03.492132\n",
      "resetting env. episode 7562, reward total was -15.0. running mean: -17.4733856087301, timestamp: 2022-08-20 00:33:08.865194\n",
      "resetting env. episode 7563, reward total was -19.0. running mean: -17.488651752642802, timestamp: 2022-08-20 00:33:12.555237\n",
      "resetting env. episode 7564, reward total was -17.0. running mean: -17.483765235116376, timestamp: 2022-08-20 00:33:16.893283\n",
      "resetting env. episode 7565, reward total was -16.0. running mean: -17.46892758276521, timestamp: 2022-08-20 00:33:21.876343\n",
      "resetting env. episode 7566, reward total was -17.0. running mean: -17.46423830693756, timestamp: 2022-08-20 00:33:27.064399\n",
      "resetting env. episode 7567, reward total was -19.0. running mean: -17.479595923868185, timestamp: 2022-08-20 00:33:31.187449\n",
      "resetting env. episode 7568, reward total was -15.0. running mean: -17.4547999646295, timestamp: 2022-08-20 00:33:36.408507\n",
      "resetting env. episode 7569, reward total was -19.0. running mean: -17.470251964983206, timestamp: 2022-08-20 00:33:40.834556\n",
      "resetting env. episode 7570, reward total was -17.0. running mean: -17.465549445333377, timestamp: 2022-08-20 00:33:44.941604\n",
      "resetting env. episode 7571, reward total was -15.0. running mean: -17.440893950880042, timestamp: 2022-08-20 00:33:49.424655\n",
      "resetting env. episode 7572, reward total was -17.0. running mean: -17.436485011371243, timestamp: 2022-08-20 00:33:53.368698\n",
      "resetting env. episode 7573, reward total was -20.0. running mean: -17.46212016125753, timestamp: 2022-08-20 00:33:58.421761\n",
      "resetting env. episode 7574, reward total was -16.0. running mean: -17.447498959644957, timestamp: 2022-08-20 00:34:02.883807\n",
      "resetting env. episode 7575, reward total was -17.0. running mean: -17.443023970048507, timestamp: 2022-08-20 00:34:06.633854\n",
      "resetting env. episode 7576, reward total was -17.0. running mean: -17.438593730348025, timestamp: 2022-08-20 00:34:11.716909\n",
      "resetting env. episode 7577, reward total was -19.0. running mean: -17.454207793044546, timestamp: 2022-08-20 00:34:15.978958\n",
      "resetting env. episode 7578, reward total was -18.0. running mean: -17.4596657151141, timestamp: 2022-08-20 00:34:19.169996\n",
      "resetting env. episode 7579, reward total was -15.0. running mean: -17.435069057962956, timestamp: 2022-08-20 00:34:24.227056\n",
      "resetting env. episode 7580, reward total was -20.0. running mean: -17.460718367383325, timestamp: 2022-08-20 00:34:27.486087\n",
      "resetting env. episode 7581, reward total was -17.0. running mean: -17.456111183709496, timestamp: 2022-08-20 00:34:31.848139\n",
      "resetting env. episode 7582, reward total was -20.0. running mean: -17.481550071872398, timestamp: 2022-08-20 00:34:35.144175\n",
      "resetting env. episode 7583, reward total was -17.0. running mean: -17.476734571153674, timestamp: 2022-08-20 00:34:39.640230\n",
      "resetting env. episode 7584, reward total was -20.0. running mean: -17.501967225442137, timestamp: 2022-08-20 00:34:43.614273\n",
      "resetting env. episode 7585, reward total was -20.0. running mean: -17.526947553187714, timestamp: 2022-08-20 00:34:47.495316\n",
      "resetting env. episode 7586, reward total was -18.0. running mean: -17.531678077655837, timestamp: 2022-08-20 00:34:51.687362\n",
      "resetting env. episode 7587, reward total was -20.0. running mean: -17.556361296879277, timestamp: 2022-08-20 00:34:56.155415\n",
      "resetting env. episode 7588, reward total was -18.0. running mean: -17.560797683910483, timestamp: 2022-08-20 00:35:01.716477\n",
      "resetting env. episode 7589, reward total was -21.0. running mean: -17.59518970707138, timestamp: 2022-08-20 00:35:06.061525\n",
      "resetting env. episode 7590, reward total was -19.0. running mean: -17.609237810000668, timestamp: 2022-08-20 00:35:09.462564\n",
      "resetting env. episode 7591, reward total was -13.0. running mean: -17.56314543190066, timestamp: 2022-08-20 00:35:13.895615\n",
      "resetting env. episode 7592, reward total was -19.0. running mean: -17.577513977581656, timestamp: 2022-08-20 00:35:17.870657\n",
      "resetting env. episode 7593, reward total was -16.0. running mean: -17.56173883780584, timestamp: 2022-08-20 00:35:22.203707\n",
      "resetting env. episode 7594, reward total was -15.0. running mean: -17.53612144942778, timestamp: 2022-08-20 00:35:26.959759\n",
      "resetting env. episode 7595, reward total was -18.0. running mean: -17.540760234933504, timestamp: 2022-08-20 00:35:31.153810\n",
      "resetting env. episode 7596, reward total was -14.0. running mean: -17.50535263258417, timestamp: 2022-08-20 00:35:35.096852\n",
      "resetting env. episode 7597, reward total was -15.0. running mean: -17.480299106258325, timestamp: 2022-08-20 00:35:39.856910\n",
      "resetting env. episode 7598, reward total was -19.0. running mean: -17.495496115195742, timestamp: 2022-08-20 00:35:43.601952\n",
      "resetting env. episode 7599, reward total was -21.0. running mean: -17.530541154043785, timestamp: 2022-08-20 00:35:48.116003\n",
      "resetting env. episode 7600, reward total was -17.0. running mean: -17.525235742503348, timestamp: 2022-08-20 00:35:52.801052\n",
      "resetting env. episode 7601, reward total was -18.0. running mean: -17.529983385078314, timestamp: 2022-08-20 00:35:56.664095\n",
      "resetting env. episode 7602, reward total was -12.0. running mean: -17.474683551227532, timestamp: 2022-08-20 00:36:02.208160\n",
      "resetting env. episode 7603, reward total was -21.0. running mean: -17.509936715715256, timestamp: 2022-08-20 00:36:06.034206\n",
      "resetting env. episode 7604, reward total was -19.0. running mean: -17.524837348558105, timestamp: 2022-08-20 00:36:10.287251\n",
      "resetting env. episode 7605, reward total was -17.0. running mean: -17.519588975072526, timestamp: 2022-08-20 00:36:14.700300\n",
      "resetting env. episode 7606, reward total was -21.0. running mean: -17.554393085321802, timestamp: 2022-08-20 00:36:18.796346\n",
      "resetting env. episode 7607, reward total was -17.0. running mean: -17.548849154468584, timestamp: 2022-08-20 00:36:23.767406\n",
      "resetting env. episode 7608, reward total was -21.0. running mean: -17.583360662923898, timestamp: 2022-08-20 00:36:27.383445\n",
      "resetting env. episode 7609, reward total was -19.0. running mean: -17.59752705629466, timestamp: 2022-08-20 00:36:32.353500\n",
      "resetting env. episode 7610, reward total was -19.0. running mean: -17.611551785731713, timestamp: 2022-08-20 00:36:36.768548\n",
      "resetting env. episode 7611, reward total was -18.0. running mean: -17.615436267874394, timestamp: 2022-08-20 00:36:40.384591\n",
      "resetting env. episode 7612, reward total was -19.0. running mean: -17.62928190519565, timestamp: 2022-08-20 00:36:44.421637\n",
      "resetting env. episode 7613, reward total was -18.0. running mean: -17.632989086143695, timestamp: 2022-08-20 00:36:48.876688\n",
      "resetting env. episode 7614, reward total was -19.0. running mean: -17.646659195282258, timestamp: 2022-08-20 00:36:52.185727\n",
      "resetting env. episode 7615, reward total was -17.0. running mean: -17.640192603329435, timestamp: 2022-08-20 00:36:56.344768\n",
      "resetting env. episode 7616, reward total was -17.0. running mean: -17.633790677296144, timestamp: 2022-08-20 00:36:59.941810\n",
      "resetting env. episode 7617, reward total was -19.0. running mean: -17.647452770523184, timestamp: 2022-08-20 00:37:03.650853\n",
      "resetting env. episode 7618, reward total was -18.0. running mean: -17.650978242817953, timestamp: 2022-08-20 00:37:07.730897\n",
      "resetting env. episode 7619, reward total was -13.0. running mean: -17.60446846038977, timestamp: 2022-08-20 00:37:13.505963\n",
      "resetting env. episode 7620, reward total was -16.0. running mean: -17.588423775785873, timestamp: 2022-08-20 00:37:18.268013\n",
      "resetting env. episode 7621, reward total was -18.0. running mean: -17.592539538028014, timestamp: 2022-08-20 00:37:22.037056\n",
      "resetting env. episode 7622, reward total was -20.0. running mean: -17.616614142647734, timestamp: 2022-08-20 00:37:26.334106\n",
      "resetting env. episode 7623, reward total was -17.0. running mean: -17.610448001221258, timestamp: 2022-08-20 00:37:30.800156\n",
      "resetting env. episode 7624, reward total was -17.0. running mean: -17.604343521209046, timestamp: 2022-08-20 00:37:34.826202\n",
      "resetting env. episode 7625, reward total was -17.0. running mean: -17.598300085996957, timestamp: 2022-08-20 00:37:39.072249\n",
      "resetting env. episode 7626, reward total was -17.0. running mean: -17.59231708513699, timestamp: 2022-08-20 00:37:43.465300\n",
      "resetting env. episode 7627, reward total was -15.0. running mean: -17.56639391428562, timestamp: 2022-08-20 00:37:48.855360\n",
      "resetting env. episode 7628, reward total was -16.0. running mean: -17.55072997514276, timestamp: 2022-08-20 00:37:53.479408\n",
      "resetting env. episode 7629, reward total was -19.0. running mean: -17.565222675391336, timestamp: 2022-08-20 00:37:57.318452\n",
      "resetting env. episode 7630, reward total was -17.0. running mean: -17.559570448637423, timestamp: 2022-08-20 00:38:01.461498\n",
      "resetting env. episode 7631, reward total was -19.0. running mean: -17.57397474415105, timestamp: 2022-08-20 00:38:05.932547\n",
      "resetting env. episode 7632, reward total was -18.0. running mean: -17.57823499670954, timestamp: 2022-08-20 00:38:10.541602\n",
      "resetting env. episode 7633, reward total was -19.0. running mean: -17.592452646742444, timestamp: 2022-08-20 00:38:14.120644\n",
      "resetting env. episode 7634, reward total was -18.0. running mean: -17.596528120275018, timestamp: 2022-08-20 00:38:18.889695\n",
      "resetting env. episode 7635, reward total was -20.0. running mean: -17.620562839072267, timestamp: 2022-08-20 00:38:23.180742\n",
      "resetting env. episode 7636, reward total was -19.0. running mean: -17.634357210681546, timestamp: 2022-08-20 00:38:28.049797\n",
      "resetting env. episode 7637, reward total was -16.0. running mean: -17.61801363857473, timestamp: 2022-08-20 00:38:32.138844\n",
      "resetting env. episode 7638, reward total was -16.0. running mean: -17.601833502188985, timestamp: 2022-08-20 00:38:37.036896\n",
      "resetting env. episode 7639, reward total was -19.0. running mean: -17.615815167167096, timestamp: 2022-08-20 00:38:41.188943\n",
      "resetting env. episode 7640, reward total was -18.0. running mean: -17.619657015495424, timestamp: 2022-08-20 00:38:45.436992\n",
      "resetting env. episode 7641, reward total was -17.0. running mean: -17.613460445340472, timestamp: 2022-08-20 00:38:49.314035\n",
      "resetting env. episode 7642, reward total was -13.0. running mean: -17.567325840887065, timestamp: 2022-08-20 00:38:55.411105\n",
      "resetting env. episode 7643, reward total was -13.0. running mean: -17.521652582478193, timestamp: 2022-08-20 00:39:00.077157\n",
      "resetting env. episode 7644, reward total was -16.0. running mean: -17.50643605665341, timestamp: 2022-08-20 00:39:05.187212\n",
      "resetting env. episode 7645, reward total was -16.0. running mean: -17.491371696086876, timestamp: 2022-08-20 00:39:09.462262\n",
      "resetting env. episode 7646, reward total was -18.0. running mean: -17.496457979126006, timestamp: 2022-08-20 00:39:14.119313\n",
      "resetting env. episode 7647, reward total was -17.0. running mean: -17.491493399334747, timestamp: 2022-08-20 00:39:18.156359\n",
      "resetting env. episode 7648, reward total was -13.0. running mean: -17.4465784653414, timestamp: 2022-08-20 00:39:22.751413\n",
      "resetting env. episode 7649, reward total was -15.0. running mean: -17.422112680687984, timestamp: 2022-08-20 00:39:27.943466\n",
      "resetting env. episode 7650, reward total was -18.0. running mean: -17.427891553881103, timestamp: 2022-08-20 00:39:32.058513\n",
      "resetting env. episode 7651, reward total was -18.0. running mean: -17.433612638342293, timestamp: 2022-08-20 00:39:37.245571\n",
      "resetting env. episode 7652, reward total was -18.0. running mean: -17.43927651195887, timestamp: 2022-08-20 00:39:41.096616\n",
      "resetting env. episode 7653, reward total was -14.0. running mean: -17.404883746839282, timestamp: 2022-08-20 00:39:44.811658\n",
      "resetting env. episode 7654, reward total was -19.0. running mean: -17.42083490937089, timestamp: 2022-08-20 00:39:48.853705\n",
      "resetting env. episode 7655, reward total was -21.0. running mean: -17.45662656027718, timestamp: 2022-08-20 00:39:51.692738\n",
      "resetting env. episode 7656, reward total was -15.0. running mean: -17.432060294674407, timestamp: 2022-08-20 00:39:57.565801\n",
      "resetting env. episode 7657, reward total was -19.0. running mean: -17.447739691727666, timestamp: 2022-08-20 00:40:02.092854\n",
      "resetting env. episode 7658, reward total was -18.0. running mean: -17.45326229481039, timestamp: 2022-08-20 00:40:06.274901\n",
      "resetting env. episode 7659, reward total was -19.0. running mean: -17.468729671862288, timestamp: 2022-08-20 00:40:10.110944\n",
      "resetting env. episode 7660, reward total was -19.0. running mean: -17.484042375143666, timestamp: 2022-08-20 00:40:14.366993\n",
      "resetting env. episode 7661, reward total was -15.0. running mean: -17.459201951392227, timestamp: 2022-08-20 00:40:19.621054\n",
      "resetting env. episode 7662, reward total was -15.0. running mean: -17.434609931878303, timestamp: 2022-08-20 00:40:24.767117\n",
      "resetting env. episode 7663, reward total was -20.0. running mean: -17.46026383255952, timestamp: 2022-08-20 00:40:28.263148\n",
      "resetting env. episode 7664, reward total was -17.0. running mean: -17.455661194233926, timestamp: 2022-08-20 00:40:33.069203\n",
      "resetting env. episode 7665, reward total was -16.0. running mean: -17.441104582291587, timestamp: 2022-08-20 00:40:37.253251\n",
      "resetting env. episode 7666, reward total was -16.0. running mean: -17.426693536468672, timestamp: 2022-08-20 00:40:42.764316\n",
      "resetting env. episode 7667, reward total was -17.0. running mean: -17.422426601103986, timestamp: 2022-08-20 00:40:47.079363\n",
      "resetting env. episode 7668, reward total was -15.0. running mean: -17.398202335092943, timestamp: 2022-08-20 00:40:51.876419\n",
      "resetting env. episode 7669, reward total was -19.0. running mean: -17.414220311742014, timestamp: 2022-08-20 00:40:55.950468\n",
      "resetting env. episode 7670, reward total was -14.0. running mean: -17.380078108624595, timestamp: 2022-08-20 00:41:01.839533\n",
      "resetting env. episode 7671, reward total was -15.0. running mean: -17.356277327538347, timestamp: 2022-08-20 00:41:07.656598\n",
      "resetting env. episode 7672, reward total was -21.0. running mean: -17.392714554262966, timestamp: 2022-08-20 00:41:11.024635\n",
      "resetting env. episode 7673, reward total was -13.0. running mean: -17.348787408720334, timestamp: 2022-08-20 00:41:15.412685\n",
      "resetting env. episode 7674, reward total was -20.0. running mean: -17.37529953463313, timestamp: 2022-08-20 00:41:19.156728\n",
      "resetting env. episode 7675, reward total was -13.0. running mean: -17.331546539286798, timestamp: 2022-08-20 00:41:23.542779\n",
      "resetting env. episode 7676, reward total was -17.0. running mean: -17.32823107389393, timestamp: 2022-08-20 00:41:28.110834\n",
      "resetting env. episode 7677, reward total was -17.0. running mean: -17.324948763154993, timestamp: 2022-08-20 00:41:32.012879\n",
      "resetting env. episode 7678, reward total was -15.0. running mean: -17.30169927552344, timestamp: 2022-08-20 00:41:37.512938\n",
      "resetting env. episode 7679, reward total was -20.0. running mean: -17.328682282768206, timestamp: 2022-08-20 00:41:41.586983\n",
      "resetting env. episode 7680, reward total was -20.0. running mean: -17.355395459940524, timestamp: 2022-08-20 00:41:46.359039\n",
      "resetting env. episode 7681, reward total was -17.0. running mean: -17.35184150534112, timestamp: 2022-08-20 00:41:50.673087\n",
      "resetting env. episode 7682, reward total was -15.0. running mean: -17.328323090287707, timestamp: 2022-08-20 00:41:55.201142\n",
      "resetting env. episode 7683, reward total was -19.0. running mean: -17.34503985938483, timestamp: 2022-08-20 00:41:59.407188\n",
      "resetting env. episode 7684, reward total was -13.0. running mean: -17.301589460790982, timestamp: 2022-08-20 00:42:04.890252\n",
      "resetting env. episode 7685, reward total was -19.0. running mean: -17.318573566183073, timestamp: 2022-08-20 00:42:08.029289\n",
      "resetting env. episode 7686, reward total was -19.0. running mean: -17.335387830521242, timestamp: 2022-08-20 00:42:12.349338\n",
      "resetting env. episode 7687, reward total was -15.0. running mean: -17.312033952216026, timestamp: 2022-08-20 00:42:16.109381\n",
      "resetting env. episode 7688, reward total was -15.0. running mean: -17.288913612693865, timestamp: 2022-08-20 00:42:21.428440\n",
      "resetting env. episode 7689, reward total was -14.0. running mean: -17.256024476566925, timestamp: 2022-08-20 00:42:26.300500\n",
      "resetting env. episode 7690, reward total was -19.0. running mean: -17.273464231801256, timestamp: 2022-08-20 00:42:31.089552\n",
      "resetting env. episode 7691, reward total was -17.0. running mean: -17.270729589483246, timestamp: 2022-08-20 00:42:35.133599\n",
      "resetting env. episode 7692, reward total was -18.0. running mean: -17.278022293588414, timestamp: 2022-08-20 00:42:39.680651\n",
      "resetting env. episode 7693, reward total was -14.0. running mean: -17.24524207065253, timestamp: 2022-08-20 00:42:45.197717\n",
      "resetting env. episode 7694, reward total was -16.0. running mean: -17.232789649946003, timestamp: 2022-08-20 00:42:50.356779\n",
      "resetting env. episode 7695, reward total was -21.0. running mean: -17.270461753446543, timestamp: 2022-08-20 00:42:54.646825\n",
      "resetting env. episode 7696, reward total was -20.0. running mean: -17.29775713591208, timestamp: 2022-08-20 00:42:58.764871\n",
      "resetting env. episode 7697, reward total was -21.0. running mean: -17.33477956455296, timestamp: 2022-08-20 00:43:02.300913\n",
      "resetting env. episode 7698, reward total was -16.0. running mean: -17.32143176890743, timestamp: 2022-08-20 00:43:07.031968\n",
      "resetting env. episode 7699, reward total was -19.0. running mean: -17.33821745121836, timestamp: 2022-08-20 00:43:11.290025\n",
      "resetting env. episode 7700, reward total was -14.0. running mean: -17.304835276706175, timestamp: 2022-08-20 00:43:17.055081\n",
      "resetting env. episode 7701, reward total was -19.0. running mean: -17.321786923939115, timestamp: 2022-08-20 00:43:20.608124\n",
      "resetting env. episode 7702, reward total was -18.0. running mean: -17.328569054699724, timestamp: 2022-08-20 00:43:26.078186\n",
      "resetting env. episode 7703, reward total was -16.0. running mean: -17.315283364152727, timestamp: 2022-08-20 00:43:31.336246\n",
      "resetting env. episode 7704, reward total was -14.0. running mean: -17.2821305305112, timestamp: 2022-08-20 00:43:36.341304\n",
      "resetting env. episode 7705, reward total was -18.0. running mean: -17.289309225206086, timestamp: 2022-08-20 00:43:40.440350\n",
      "resetting env. episode 7706, reward total was -14.0. running mean: -17.256416132954026, timestamp: 2022-08-20 00:43:45.283407\n",
      "resetting env. episode 7707, reward total was -14.0. running mean: -17.223851971624487, timestamp: 2022-08-20 00:43:49.656456\n",
      "resetting env. episode 7708, reward total was -18.0. running mean: -17.231613451908242, timestamp: 2022-08-20 00:43:53.521500\n",
      "resetting env. episode 7709, reward total was -15.0. running mean: -17.209297317389158, timestamp: 2022-08-20 00:43:58.524563\n",
      "resetting env. episode 7710, reward total was -17.0. running mean: -17.207204344215267, timestamp: 2022-08-20 00:44:02.525605\n",
      "resetting env. episode 7711, reward total was -19.0. running mean: -17.225132300773115, timestamp: 2022-08-20 00:44:06.987656\n",
      "resetting env. episode 7712, reward total was -18.0. running mean: -17.232880977765383, timestamp: 2022-08-20 00:44:11.944718\n",
      "resetting env. episode 7713, reward total was -18.0. running mean: -17.24055216798773, timestamp: 2022-08-20 00:44:16.755770\n",
      "resetting env. episode 7714, reward total was -14.0. running mean: -17.208146646307853, timestamp: 2022-08-20 00:44:22.132832\n",
      "resetting env. episode 7715, reward total was -16.0. running mean: -17.196065179844773, timestamp: 2022-08-20 00:44:26.545885\n",
      "resetting env. episode 7716, reward total was -17.0. running mean: -17.194104528046328, timestamp: 2022-08-20 00:44:31.373937\n",
      "resetting env. episode 7717, reward total was -17.0. running mean: -17.192163482765867, timestamp: 2022-08-20 00:44:34.838980\n",
      "resetting env. episode 7718, reward total was -14.0. running mean: -17.16024184793821, timestamp: 2022-08-20 00:44:40.225040\n",
      "resetting env. episode 7719, reward total was -17.0. running mean: -17.15863942945883, timestamp: 2022-08-20 00:44:44.938093\n",
      "resetting env. episode 7720, reward total was -18.0. running mean: -17.16705303516424, timestamp: 2022-08-20 00:44:49.254147\n",
      "resetting env. episode 7721, reward total was -19.0. running mean: -17.185382504812598, timestamp: 2022-08-20 00:44:52.812186\n",
      "resetting env. episode 7722, reward total was -17.0. running mean: -17.183528679764475, timestamp: 2022-08-20 00:44:56.298226\n",
      "resetting env. episode 7723, reward total was -15.0. running mean: -17.16169339296683, timestamp: 2022-08-20 00:45:01.218289\n",
      "resetting env. episode 7724, reward total was -16.0. running mean: -17.15007645903716, timestamp: 2022-08-20 00:45:05.758334\n",
      "resetting env. episode 7725, reward total was -19.0. running mean: -17.168575694446787, timestamp: 2022-08-20 00:45:10.677392\n",
      "resetting env. episode 7726, reward total was -20.0. running mean: -17.19688993750232, timestamp: 2022-08-20 00:45:14.481434\n",
      "resetting env. episode 7727, reward total was -19.0. running mean: -17.214921038127297, timestamp: 2022-08-20 00:45:18.757483\n",
      "resetting env. episode 7728, reward total was -15.0. running mean: -17.19277182774602, timestamp: 2022-08-20 00:45:23.869545\n",
      "resetting env. episode 7729, reward total was -21.0. running mean: -17.230844109468563, timestamp: 2022-08-20 00:45:28.047593\n",
      "resetting env. episode 7730, reward total was -17.0. running mean: -17.22853566837388, timestamp: 2022-08-20 00:45:32.765644\n",
      "resetting env. episode 7731, reward total was -19.0. running mean: -17.246250311690144, timestamp: 2022-08-20 00:45:37.470699\n",
      "resetting env. episode 7732, reward total was -18.0. running mean: -17.253787808573243, timestamp: 2022-08-20 00:45:41.790748\n",
      "resetting env. episode 7733, reward total was -18.0. running mean: -17.26124993048751, timestamp: 2022-08-20 00:45:45.585793\n",
      "resetting env. episode 7734, reward total was -17.0. running mean: -17.258637431182635, timestamp: 2022-08-20 00:45:50.790853\n",
      "resetting env. episode 7735, reward total was -17.0. running mean: -17.25605105687081, timestamp: 2022-08-20 00:45:55.633908\n",
      "resetting env. episode 7736, reward total was -15.0. running mean: -17.2334905463021, timestamp: 2022-08-20 00:46:00.931969\n",
      "resetting env. episode 7737, reward total was -13.0. running mean: -17.191155640839078, timestamp: 2022-08-20 00:46:06.064027\n",
      "resetting env. episode 7738, reward total was -20.0. running mean: -17.219244084430688, timestamp: 2022-08-20 00:46:10.349078\n",
      "resetting env. episode 7739, reward total was -14.0. running mean: -17.187051643586383, timestamp: 2022-08-20 00:46:15.026131\n",
      "resetting env. episode 7740, reward total was -18.0. running mean: -17.19518112715052, timestamp: 2022-08-20 00:46:18.975174\n",
      "resetting env. episode 7741, reward total was -18.0. running mean: -17.203229315879014, timestamp: 2022-08-20 00:46:22.796222\n",
      "resetting env. episode 7742, reward total was -13.0. running mean: -17.161197022720224, timestamp: 2022-08-20 00:46:28.943292\n",
      "resetting env. episode 7743, reward total was -16.0. running mean: -17.14958505249302, timestamp: 2022-08-20 00:46:33.391344\n",
      "resetting env. episode 7744, reward total was -17.0. running mean: -17.14808920196809, timestamp: 2022-08-20 00:46:37.786395\n",
      "resetting env. episode 7745, reward total was -17.0. running mean: -17.146608309948412, timestamp: 2022-08-20 00:46:42.107440\n",
      "resetting env. episode 7746, reward total was -20.0. running mean: -17.175142226848926, timestamp: 2022-08-20 00:46:46.007489\n",
      "resetting env. episode 7747, reward total was -17.0. running mean: -17.17339080458044, timestamp: 2022-08-20 00:46:50.733542\n",
      "resetting env. episode 7748, reward total was -21.0. running mean: -17.211656896534635, timestamp: 2022-08-20 00:46:54.476585\n",
      "resetting env. episode 7749, reward total was -14.0. running mean: -17.17954032756929, timestamp: 2022-08-20 00:46:59.353641\n",
      "resetting env. episode 7750, reward total was -17.0. running mean: -17.1777449242936, timestamp: 2022-08-20 00:47:04.444697\n",
      "resetting env. episode 7751, reward total was -19.0. running mean: -17.195967475050665, timestamp: 2022-08-20 00:47:07.945739\n",
      "resetting env. episode 7752, reward total was -15.0. running mean: -17.174007800300156, timestamp: 2022-08-20 00:47:11.992786\n",
      "resetting env. episode 7753, reward total was -19.0. running mean: -17.192267722297156, timestamp: 2022-08-20 00:47:16.113835\n",
      "resetting env. episode 7754, reward total was -20.0. running mean: -17.220345045074183, timestamp: 2022-08-20 00:47:19.344873\n",
      "resetting env. episode 7755, reward total was -20.0. running mean: -17.24814159462344, timestamp: 2022-08-20 00:47:24.124925\n",
      "resetting env. episode 7756, reward total was -16.0. running mean: -17.235660178677207, timestamp: 2022-08-20 00:47:28.776982\n",
      "resetting env. episode 7757, reward total was -17.0. running mean: -17.233303576890435, timestamp: 2022-08-20 00:47:33.313032\n",
      "resetting env. episode 7758, reward total was -19.0. running mean: -17.250970541121532, timestamp: 2022-08-20 00:47:37.438078\n",
      "resetting env. episode 7759, reward total was -16.0. running mean: -17.238460835710317, timestamp: 2022-08-20 00:47:42.341135\n",
      "resetting env. episode 7760, reward total was -20.0. running mean: -17.266076227353214, timestamp: 2022-08-20 00:47:45.545171\n",
      "resetting env. episode 7761, reward total was -19.0. running mean: -17.28341546507968, timestamp: 2022-08-20 00:47:48.954210\n",
      "resetting env. episode 7762, reward total was -19.0. running mean: -17.300581310428885, timestamp: 2022-08-20 00:47:53.637265\n",
      "resetting env. episode 7763, reward total was -20.0. running mean: -17.327575497324595, timestamp: 2022-08-20 00:47:57.348311\n",
      "resetting env. episode 7764, reward total was -16.0. running mean: -17.31429974235135, timestamp: 2022-08-20 00:48:02.064363\n",
      "resetting env. episode 7765, reward total was -17.0. running mean: -17.311156744927835, timestamp: 2022-08-20 00:48:07.926429\n",
      "resetting env. episode 7766, reward total was -19.0. running mean: -17.328045177478558, timestamp: 2022-08-20 00:48:12.496483\n",
      "resetting env. episode 7767, reward total was -16.0. running mean: -17.31476472570377, timestamp: 2022-08-20 00:48:16.545537\n",
      "resetting env. episode 7768, reward total was -15.0. running mean: -17.29161707844673, timestamp: 2022-08-20 00:48:21.623588\n",
      "resetting env. episode 7769, reward total was -21.0. running mean: -17.328700907662263, timestamp: 2022-08-20 00:48:26.406642\n",
      "resetting env. episode 7770, reward total was -14.0. running mean: -17.29541389858564, timestamp: 2022-08-20 00:48:32.469709\n",
      "resetting env. episode 7771, reward total was -16.0. running mean: -17.28245975959978, timestamp: 2022-08-20 00:48:37.193764\n",
      "resetting env. episode 7772, reward total was -16.0. running mean: -17.269635162003784, timestamp: 2022-08-20 00:48:42.328823\n",
      "resetting env. episode 7773, reward total was -18.0. running mean: -17.276938810383747, timestamp: 2022-08-20 00:48:46.482873\n",
      "resetting env. episode 7774, reward total was -14.0. running mean: -17.24416942227991, timestamp: 2022-08-20 00:48:50.834923\n",
      "resetting env. episode 7775, reward total was -19.0. running mean: -17.261727728057114, timestamp: 2022-08-20 00:48:55.955980\n",
      "resetting env. episode 7776, reward total was -19.0. running mean: -17.279110450776543, timestamp: 2022-08-20 00:49:00.293031\n",
      "resetting env. episode 7777, reward total was -16.0. running mean: -17.266319346268777, timestamp: 2022-08-20 00:49:05.590089\n",
      "resetting env. episode 7778, reward total was -18.0. running mean: -17.273656152806087, timestamp: 2022-08-20 00:49:09.241130\n",
      "resetting env. episode 7779, reward total was -16.0. running mean: -17.260919591278025, timestamp: 2022-08-20 00:49:13.642181\n",
      "resetting env. episode 7780, reward total was -16.0. running mean: -17.248310395365245, timestamp: 2022-08-20 00:49:19.459246\n",
      "resetting env. episode 7781, reward total was -16.0. running mean: -17.235827291411592, timestamp: 2022-08-20 00:49:24.352303\n",
      "resetting env. episode 7782, reward total was -16.0. running mean: -17.223469018497475, timestamp: 2022-08-20 00:49:28.588349\n",
      "resetting env. episode 7783, reward total was -18.0. running mean: -17.2312343283125, timestamp: 2022-08-20 00:49:32.682396\n",
      "resetting env. episode 7784, reward total was -19.0. running mean: -17.248921985029376, timestamp: 2022-08-20 00:49:36.566440\n",
      "resetting env. episode 7785, reward total was -15.0. running mean: -17.22643276517908, timestamp: 2022-08-20 00:49:40.190484\n",
      "resetting env. episode 7786, reward total was -19.0. running mean: -17.24416843752729, timestamp: 2022-08-20 00:49:44.525534\n",
      "resetting env. episode 7787, reward total was -17.0. running mean: -17.24172675315202, timestamp: 2022-08-20 00:49:48.731582\n",
      "resetting env. episode 7788, reward total was -16.0. running mean: -17.229309485620497, timestamp: 2022-08-20 00:49:53.386633\n",
      "resetting env. episode 7789, reward total was -19.0. running mean: -17.247016390764294, timestamp: 2022-08-20 00:49:57.640680\n",
      "resetting env. episode 7790, reward total was -15.0. running mean: -17.22454622685665, timestamp: 2022-08-20 00:50:01.539727\n",
      "resetting env. episode 7791, reward total was -18.0. running mean: -17.232300764588082, timestamp: 2022-08-20 00:50:06.084779\n",
      "resetting env. episode 7792, reward total was -19.0. running mean: -17.2499777569422, timestamp: 2022-08-20 00:50:10.013824\n",
      "resetting env. episode 7793, reward total was -17.0. running mean: -17.247477979372782, timestamp: 2022-08-20 00:50:14.501873\n",
      "resetting env. episode 7794, reward total was -17.0. running mean: -17.245003199579056, timestamp: 2022-08-20 00:50:18.635920\n",
      "resetting env. episode 7795, reward total was -17.0. running mean: -17.242553167583267, timestamp: 2022-08-20 00:50:23.515981\n",
      "resetting env. episode 7796, reward total was -13.0. running mean: -17.20012763590743, timestamp: 2022-08-20 00:50:28.729036\n",
      "resetting env. episode 7797, reward total was -14.0. running mean: -17.168126359548356, timestamp: 2022-08-20 00:50:33.601092\n",
      "resetting env. episode 7798, reward total was -16.0. running mean: -17.156445095952872, timestamp: 2022-08-20 00:50:38.459146\n",
      "resetting env. episode 7799, reward total was -16.0. running mean: -17.144880644993343, timestamp: 2022-08-20 00:50:42.973200\n",
      "resetting env. episode 7800, reward total was -18.0. running mean: -17.15343183854341, timestamp: 2022-08-20 00:50:47.064245\n",
      "resetting env. episode 7801, reward total was -18.0. running mean: -17.161897520157975, timestamp: 2022-08-20 00:50:51.273291\n",
      "resetting env. episode 7802, reward total was -17.0. running mean: -17.160278544956398, timestamp: 2022-08-20 00:50:55.711346\n",
      "resetting env. episode 7803, reward total was -18.0. running mean: -17.168675759506833, timestamp: 2022-08-20 00:51:01.165407\n",
      "resetting env. episode 7804, reward total was -20.0. running mean: -17.196989001911763, timestamp: 2022-08-20 00:51:05.479456\n",
      "resetting env. episode 7805, reward total was -19.0. running mean: -17.215019111892648, timestamp: 2022-08-20 00:51:10.236509\n",
      "resetting env. episode 7806, reward total was -13.0. running mean: -17.17286892077372, timestamp: 2022-08-20 00:51:16.016574\n",
      "resetting env. episode 7807, reward total was -14.0. running mean: -17.141140231565984, timestamp: 2022-08-20 00:51:21.282634\n",
      "resetting env. episode 7808, reward total was -17.0. running mean: -17.139728829250327, timestamp: 2022-08-20 00:51:25.476681\n",
      "resetting env. episode 7809, reward total was -13.0. running mean: -17.098331540957822, timestamp: 2022-08-20 00:51:30.892743\n",
      "resetting env. episode 7810, reward total was -13.0. running mean: -17.057348225548242, timestamp: 2022-08-20 00:51:36.878810\n",
      "resetting env. episode 7811, reward total was -19.0. running mean: -17.076774743292763, timestamp: 2022-08-20 00:51:41.208862\n",
      "resetting env. episode 7812, reward total was -16.0. running mean: -17.066006995859833, timestamp: 2022-08-20 00:51:45.814915\n",
      "resetting env. episode 7813, reward total was -18.0. running mean: -17.075346925901236, timestamp: 2022-08-20 00:51:50.241962\n",
      "resetting env. episode 7814, reward total was -13.0. running mean: -17.034593456642224, timestamp: 2022-08-20 00:51:55.746025\n",
      "resetting env. episode 7815, reward total was -19.0. running mean: -17.0542475220758, timestamp: 2022-08-20 00:52:00.511080\n",
      "resetting env. episode 7816, reward total was -16.0. running mean: -17.04370504685504, timestamp: 2022-08-20 00:52:05.704138\n",
      "resetting env. episode 7817, reward total was -16.0. running mean: -17.033267996386492, timestamp: 2022-08-20 00:52:10.507205\n",
      "resetting env. episode 7818, reward total was -19.0. running mean: -17.052935316422626, timestamp: 2022-08-20 00:52:14.636238\n",
      "resetting env. episode 7819, reward total was -21.0. running mean: -17.0924059632584, timestamp: 2022-08-20 00:52:18.228279\n",
      "resetting env. episode 7820, reward total was -19.0. running mean: -17.11148190362582, timestamp: 2022-08-20 00:52:23.444336\n",
      "resetting env. episode 7821, reward total was -19.0. running mean: -17.13036708458956, timestamp: 2022-08-20 00:52:28.234393\n",
      "resetting env. episode 7822, reward total was -21.0. running mean: -17.169063413743668, timestamp: 2022-08-20 00:52:31.916434\n",
      "resetting env. episode 7823, reward total was -20.0. running mean: -17.19737277960623, timestamp: 2022-08-20 00:52:35.354471\n",
      "resetting env. episode 7824, reward total was -17.0. running mean: -17.19539905181017, timestamp: 2022-08-20 00:52:39.966527\n",
      "resetting env. episode 7825, reward total was -12.0. running mean: -17.14344506129207, timestamp: 2022-08-20 00:52:44.257572\n",
      "resetting env. episode 7826, reward total was -12.0. running mean: -17.09201061067915, timestamp: 2022-08-20 00:52:49.311630\n",
      "resetting env. episode 7827, reward total was -21.0. running mean: -17.13109050457236, timestamp: 2022-08-20 00:52:53.571677\n",
      "resetting env. episode 7828, reward total was -21.0. running mean: -17.16977959952664, timestamp: 2022-08-20 00:52:58.091728\n",
      "resetting env. episode 7829, reward total was -18.0. running mean: -17.17808180353137, timestamp: 2022-08-20 00:53:03.108787\n",
      "resetting env. episode 7830, reward total was -17.0. running mean: -17.17630098549606, timestamp: 2022-08-20 00:53:08.387844\n",
      "resetting env. episode 7831, reward total was -20.0. running mean: -17.2045379756411, timestamp: 2022-08-20 00:53:11.896889\n",
      "resetting env. episode 7832, reward total was -16.0. running mean: -17.192492595884687, timestamp: 2022-08-20 00:53:16.237936\n",
      "resetting env. episode 7833, reward total was -19.0. running mean: -17.21056766992584, timestamp: 2022-08-20 00:53:21.097988\n",
      "resetting env. episode 7834, reward total was -17.0. running mean: -17.208461993226585, timestamp: 2022-08-20 00:53:24.932032\n",
      "resetting env. episode 7835, reward total was -19.0. running mean: -17.22637737329432, timestamp: 2022-08-20 00:53:28.717078\n",
      "resetting env. episode 7836, reward total was -15.0. running mean: -17.204113599561374, timestamp: 2022-08-20 00:53:33.468129\n",
      "resetting env. episode 7837, reward total was -21.0. running mean: -17.242072463565762, timestamp: 2022-08-20 00:53:37.611174\n",
      "resetting env. episode 7838, reward total was -20.0. running mean: -17.269651738930104, timestamp: 2022-08-20 00:53:41.840222\n",
      "resetting env. episode 7839, reward total was -20.0. running mean: -17.296955221540802, timestamp: 2022-08-20 00:53:46.400274\n",
      "resetting env. episode 7840, reward total was -18.0. running mean: -17.303985669325392, timestamp: 2022-08-20 00:53:49.903313\n",
      "resetting env. episode 7841, reward total was -16.0. running mean: -17.29094581263214, timestamp: 2022-08-20 00:53:55.337375\n",
      "resetting env. episode 7842, reward total was -20.0. running mean: -17.318036354505814, timestamp: 2022-08-20 00:53:58.881416\n",
      "resetting env. episode 7843, reward total was -20.0. running mean: -17.344855990960756, timestamp: 2022-08-20 00:54:02.490453\n",
      "resetting env. episode 7844, reward total was -19.0. running mean: -17.36140743105115, timestamp: 2022-08-20 00:54:06.511499\n",
      "resetting env. episode 7845, reward total was -19.0. running mean: -17.37779335674064, timestamp: 2022-08-20 00:54:10.400543\n",
      "resetting env. episode 7846, reward total was -19.0. running mean: -17.394015423173233, timestamp: 2022-08-20 00:54:14.579592\n",
      "resetting env. episode 7847, reward total was -13.0. running mean: -17.3500752689415, timestamp: 2022-08-20 00:54:19.632646\n",
      "resetting env. episode 7848, reward total was -18.0. running mean: -17.356574516252085, timestamp: 2022-08-20 00:54:24.744703\n",
      "resetting env. episode 7849, reward total was -19.0. running mean: -17.373008771089566, timestamp: 2022-08-20 00:54:28.037740\n",
      "resetting env. episode 7850, reward total was -21.0. running mean: -17.40927868337867, timestamp: 2022-08-20 00:54:33.476802\n",
      "resetting env. episode 7851, reward total was -13.0. running mean: -17.365185896544883, timestamp: 2022-08-20 00:54:38.003851\n",
      "resetting env. episode 7852, reward total was -19.0. running mean: -17.381534037579435, timestamp: 2022-08-20 00:54:42.378900\n",
      "resetting env. episode 7853, reward total was -13.0. running mean: -17.337718697203638, timestamp: 2022-08-20 00:54:47.692961\n",
      "resetting env. episode 7854, reward total was -17.0. running mean: -17.334341510231603, timestamp: 2022-08-20 00:54:53.084028\n",
      "resetting env. episode 7855, reward total was -20.0. running mean: -17.360998095129286, timestamp: 2022-08-20 00:54:57.644070\n",
      "resetting env. episode 7856, reward total was -17.0. running mean: -17.357388114177994, timestamp: 2022-08-20 00:55:02.760129\n",
      "resetting env. episode 7857, reward total was -15.0. running mean: -17.33381423303621, timestamp: 2022-08-20 00:55:06.922180\n",
      "resetting env. episode 7858, reward total was -18.0. running mean: -17.34047609070585, timestamp: 2022-08-20 00:55:11.225227\n",
      "resetting env. episode 7859, reward total was -13.0. running mean: -17.29707132979879, timestamp: 2022-08-20 00:55:16.989288\n",
      "resetting env. episode 7860, reward total was -17.0. running mean: -17.294100616500803, timestamp: 2022-08-20 00:55:22.311349\n",
      "resetting env. episode 7861, reward total was -19.0. running mean: -17.311159610335796, timestamp: 2022-08-20 00:55:26.742400\n",
      "resetting env. episode 7862, reward total was -18.0. running mean: -17.31804801423244, timestamp: 2022-08-20 00:55:31.351452\n",
      "resetting env. episode 7863, reward total was -16.0. running mean: -17.304867534090114, timestamp: 2022-08-20 00:55:35.638499\n",
      "resetting env. episode 7864, reward total was -21.0. running mean: -17.341818858749214, timestamp: 2022-08-20 00:55:38.452536\n",
      "resetting env. episode 7865, reward total was -19.0. running mean: -17.35840067016172, timestamp: 2022-08-20 00:55:42.731576\n",
      "resetting env. episode 7866, reward total was -18.0. running mean: -17.364816663460104, timestamp: 2022-08-20 00:55:47.194626\n",
      "resetting env. episode 7867, reward total was -15.0. running mean: -17.341168496825503, timestamp: 2022-08-20 00:55:52.229683\n",
      "resetting env. episode 7868, reward total was -17.0. running mean: -17.33775681185725, timestamp: 2022-08-20 00:55:56.410732\n",
      "resetting env. episode 7869, reward total was -18.0. running mean: -17.34437924373868, timestamp: 2022-08-20 00:56:01.095780\n",
      "resetting env. episode 7870, reward total was -14.0. running mean: -17.310935451301294, timestamp: 2022-08-20 00:56:05.530831\n",
      "resetting env. episode 7871, reward total was -19.0. running mean: -17.327826096788282, timestamp: 2022-08-20 00:56:10.182886\n",
      "resetting env. episode 7872, reward total was -16.0. running mean: -17.3145478358204, timestamp: 2022-08-20 00:56:14.710937\n",
      "resetting env. episode 7873, reward total was -16.0. running mean: -17.301402357462194, timestamp: 2022-08-20 00:56:19.173988\n",
      "resetting env. episode 7874, reward total was -18.0. running mean: -17.30838833388757, timestamp: 2022-08-20 00:56:24.046038\n",
      "resetting env. episode 7875, reward total was -18.0. running mean: -17.315304450548695, timestamp: 2022-08-20 00:56:28.436088\n",
      "resetting env. episode 7876, reward total was -18.0. running mean: -17.322151406043208, timestamp: 2022-08-20 00:56:33.049140\n",
      "resetting env. episode 7877, reward total was -15.0. running mean: -17.298929891982773, timestamp: 2022-08-20 00:56:37.726715\n",
      "resetting env. episode 7878, reward total was -15.0. running mean: -17.275940593062945, timestamp: 2022-08-20 00:56:42.458768\n",
      "resetting env. episode 7879, reward total was -18.0. running mean: -17.283181187132314, timestamp: 2022-08-20 00:56:46.769821\n",
      "resetting env. episode 7880, reward total was -19.0. running mean: -17.300349375260993, timestamp: 2022-08-20 00:56:51.186866\n",
      "resetting env. episode 7881, reward total was -19.0. running mean: -17.317345881508384, timestamp: 2022-08-20 00:56:55.133916\n",
      "resetting env. episode 7882, reward total was -17.0. running mean: -17.3141724226933, timestamp: 2022-08-20 00:57:00.504975\n",
      "resetting env. episode 7883, reward total was -17.0. running mean: -17.311030698466368, timestamp: 2022-08-20 00:57:05.614029\n",
      "resetting env. episode 7884, reward total was -17.0. running mean: -17.307920391481705, timestamp: 2022-08-20 00:57:11.133093\n",
      "resetting env. episode 7885, reward total was -20.0. running mean: -17.334841187566887, timestamp: 2022-08-20 00:57:15.337145\n",
      "resetting env. episode 7886, reward total was -18.0. running mean: -17.34149277569122, timestamp: 2022-08-20 00:57:19.860192\n",
      "resetting env. episode 7887, reward total was -19.0. running mean: -17.358077847934307, timestamp: 2022-08-20 00:57:24.704246\n",
      "resetting env. episode 7888, reward total was -15.0. running mean: -17.33449706945496, timestamp: 2022-08-20 00:57:29.357298\n",
      "resetting env. episode 7889, reward total was -17.0. running mean: -17.331152098760413, timestamp: 2022-08-20 00:57:33.592352\n",
      "resetting env. episode 7890, reward total was -17.0. running mean: -17.32784057777281, timestamp: 2022-08-20 00:57:38.436402\n",
      "resetting env. episode 7891, reward total was -18.0. running mean: -17.33456217199508, timestamp: 2022-08-20 00:57:43.148455\n",
      "resetting env. episode 7892, reward total was -19.0. running mean: -17.351216550275133, timestamp: 2022-08-20 00:57:47.343032\n",
      "resetting env. episode 7893, reward total was -20.0. running mean: -17.377704384772382, timestamp: 2022-08-20 00:57:50.959074\n",
      "resetting env. episode 7894, reward total was -19.0. running mean: -17.39392734092466, timestamp: 2022-08-20 00:57:55.298648\n",
      "resetting env. episode 7895, reward total was -18.0. running mean: -17.399988067515412, timestamp: 2022-08-20 00:58:00.016700\n",
      "resetting env. episode 7896, reward total was -18.0. running mean: -17.405988186840258, timestamp: 2022-08-20 00:58:04.162752\n",
      "resetting env. episode 7897, reward total was -16.0. running mean: -17.391928304971856, timestamp: 2022-08-20 00:58:07.548787\n",
      "resetting env. episode 7898, reward total was -16.0. running mean: -17.378009021922136, timestamp: 2022-08-20 00:58:12.890848\n",
      "resetting env. episode 7899, reward total was -16.0. running mean: -17.364228931702915, timestamp: 2022-08-20 00:58:17.574905\n",
      "resetting env. episode 7900, reward total was -20.0. running mean: -17.390586642385884, timestamp: 2022-08-20 00:58:21.492945\n",
      "resetting env. episode 7901, reward total was -20.0. running mean: -17.416680775962025, timestamp: 2022-08-20 00:58:25.666994\n",
      "resetting env. episode 7902, reward total was -18.0. running mean: -17.422513968202406, timestamp: 2022-08-20 00:58:30.690051\n",
      "resetting env. episode 7903, reward total was -16.0. running mean: -17.40828882852038, timestamp: 2022-08-20 00:58:37.509131\n",
      "resetting env. episode 7904, reward total was -15.0. running mean: -17.384205940235173, timestamp: 2022-08-20 00:58:42.143703\n",
      "resetting env. episode 7905, reward total was -19.0. running mean: -17.400363880832824, timestamp: 2022-08-20 00:58:47.169764\n",
      "resetting env. episode 7906, reward total was -18.0. running mean: -17.406360242024494, timestamp: 2022-08-20 00:58:52.107344\n",
      "resetting env. episode 7907, reward total was -16.0. running mean: -17.39229663960425, timestamp: 2022-08-20 00:58:56.955396\n",
      "resetting env. episode 7908, reward total was -19.0. running mean: -17.40837367320821, timestamp: 2022-08-20 00:59:01.594449\n",
      "resetting env. episode 7909, reward total was -17.0. running mean: -17.40428993647613, timestamp: 2022-08-20 00:59:06.309502\n",
      "resetting env. episode 7910, reward total was -17.0. running mean: -17.40024703711137, timestamp: 2022-08-20 00:59:11.657083\n",
      "resetting env. episode 7911, reward total was -17.0. running mean: -17.396244566740258, timestamp: 2022-08-20 00:59:16.532138\n",
      "resetting env. episode 7912, reward total was -13.0. running mean: -17.352282121072854, timestamp: 2022-08-20 00:59:21.762202\n",
      "resetting env. episode 7913, reward total was -20.0. running mean: -17.378759299862125, timestamp: 2022-08-20 00:59:25.628768\n",
      "resetting env. episode 7914, reward total was -19.0. running mean: -17.394971706863505, timestamp: 2022-08-20 00:59:29.693816\n",
      "resetting env. episode 7915, reward total was -17.0. running mean: -17.391021989794872, timestamp: 2022-08-20 00:59:34.225869\n",
      "resetting env. episode 7916, reward total was -17.0. running mean: -17.387111769896926, timestamp: 2022-08-20 00:59:38.930924\n",
      "resetting env. episode 7917, reward total was -17.0. running mean: -17.38324065219796, timestamp: 2022-08-20 00:59:42.712964\n",
      "resetting env. episode 7918, reward total was -15.0. running mean: -17.359408245675976, timestamp: 2022-08-20 00:59:48.554033\n",
      "resetting env. episode 7919, reward total was -18.0. running mean: -17.365814163219216, timestamp: 2022-08-20 00:59:53.156083\n",
      "resetting env. episode 7920, reward total was -15.0. running mean: -17.342156021587023, timestamp: 2022-08-20 00:59:57.682134\n",
      "resetting env. episode 7921, reward total was -17.0. running mean: -17.338734461371153, timestamp: 2022-08-20 01:00:02.561190\n",
      "resetting env. episode 7922, reward total was -19.0. running mean: -17.355347116757443, timestamp: 2022-08-20 01:00:06.837243\n",
      "resetting env. episode 7923, reward total was -19.0. running mean: -17.371793645589868, timestamp: 2022-08-20 01:00:10.797283\n",
      "resetting env. episode 7924, reward total was -21.0. running mean: -17.40807570913397, timestamp: 2022-08-20 01:00:16.039345\n",
      "resetting env. episode 7925, reward total was -18.0. running mean: -17.413994952042632, timestamp: 2022-08-20 01:00:20.085392\n",
      "resetting env. episode 7926, reward total was -17.0. running mean: -17.409855002522207, timestamp: 2022-08-20 01:00:25.481451\n",
      "resetting env. episode 7927, reward total was -18.0. running mean: -17.415756452496986, timestamp: 2022-08-20 01:00:30.835514\n",
      "resetting env. episode 7928, reward total was -13.0. running mean: -17.371598887972013, timestamp: 2022-08-20 01:00:35.623568\n",
      "resetting env. episode 7929, reward total was -21.0. running mean: -17.407882899092293, timestamp: 2022-08-20 01:00:40.494627\n",
      "resetting env. episode 7930, reward total was -21.0. running mean: -17.443804070101372, timestamp: 2022-08-20 01:00:44.034661\n",
      "resetting env. episode 7931, reward total was -17.0. running mean: -17.43936602940036, timestamp: 2022-08-20 01:00:48.859717\n",
      "resetting env. episode 7932, reward total was -16.0. running mean: -17.424972369106356, timestamp: 2022-08-20 01:00:54.475784\n",
      "resetting env. episode 7933, reward total was -17.0. running mean: -17.420722645415296, timestamp: 2022-08-20 01:00:59.402837\n",
      "resetting env. episode 7934, reward total was -15.0. running mean: -17.39651541896114, timestamp: 2022-08-20 01:01:04.561898\n",
      "resetting env. episode 7935, reward total was -18.0. running mean: -17.402550264771527, timestamp: 2022-08-20 01:01:08.642946\n",
      "resetting env. episode 7936, reward total was -16.0. running mean: -17.38852476212381, timestamp: 2022-08-20 01:01:13.826013\n",
      "resetting env. episode 7937, reward total was -18.0. running mean: -17.394639514502572, timestamp: 2022-08-20 01:01:17.791048\n",
      "resetting env. episode 7938, reward total was -17.0. running mean: -17.390693119357547, timestamp: 2022-08-20 01:01:22.508102\n",
      "resetting env. episode 7939, reward total was -18.0. running mean: -17.396786188163972, timestamp: 2022-08-20 01:01:27.030155\n",
      "resetting env. episode 7940, reward total was -19.0. running mean: -17.412818326282334, timestamp: 2022-08-20 01:01:32.862220\n",
      "resetting env. episode 7941, reward total was -19.0. running mean: -17.428690143019512, timestamp: 2022-08-20 01:01:38.026277\n",
      "resetting env. episode 7942, reward total was -16.0. running mean: -17.414403241589316, timestamp: 2022-08-20 01:01:42.771335\n",
      "resetting env. episode 7943, reward total was -18.0. running mean: -17.420259209173423, timestamp: 2022-08-20 01:01:47.168382\n",
      "resetting env. episode 7944, reward total was -21.0. running mean: -17.45605661708169, timestamp: 2022-08-20 01:01:51.949487\n",
      "resetting env. episode 7945, reward total was -17.0. running mean: -17.451496050910873, timestamp: 2022-08-20 01:01:56.297535\n",
      "resetting env. episode 7946, reward total was -18.0. running mean: -17.456981090401765, timestamp: 2022-08-20 01:02:01.967123\n",
      "resetting env. episode 7947, reward total was -15.0. running mean: -17.432411279497746, timestamp: 2022-08-20 01:02:06.893182\n",
      "resetting env. episode 7948, reward total was -19.0. running mean: -17.44808716670277, timestamp: 2022-08-20 01:02:11.061229\n",
      "resetting env. episode 7949, reward total was -11.0. running mean: -17.38360629503574, timestamp: 2022-08-20 01:02:16.726294\n",
      "resetting env. episode 7950, reward total was -16.0. running mean: -17.369770232085383, timestamp: 2022-08-20 01:02:22.136353\n",
      "resetting env. episode 7951, reward total was -17.0. running mean: -17.36607252976453, timestamp: 2022-08-20 01:02:27.031409\n",
      "resetting env. episode 7952, reward total was -13.0. running mean: -17.322411804466885, timestamp: 2022-08-20 01:02:32.601476\n",
      "resetting env. episode 7953, reward total was -12.0. running mean: -17.269187686422217, timestamp: 2022-08-20 01:02:38.203536\n",
      "resetting env. episode 7954, reward total was -19.0. running mean: -17.286495809557998, timestamp: 2022-08-20 01:02:42.167582\n",
      "resetting env. episode 7955, reward total was -17.0. running mean: -17.28363085146242, timestamp: 2022-08-20 01:02:47.014638\n",
      "resetting env. episode 7956, reward total was -18.0. running mean: -17.290794542947793, timestamp: 2022-08-20 01:02:51.388691\n",
      "resetting env. episode 7957, reward total was -14.0. running mean: -17.257886597518315, timestamp: 2022-08-20 01:02:55.561736\n",
      "resetting env. episode 7958, reward total was -21.0. running mean: -17.295307731543133, timestamp: 2022-08-20 01:02:59.570783\n",
      "resetting env. episode 7959, reward total was -17.0. running mean: -17.292354654227704, timestamp: 2022-08-20 01:03:04.791841\n",
      "resetting env. episode 7960, reward total was -16.0. running mean: -17.279431107685426, timestamp: 2022-08-20 01:03:09.148893\n",
      "resetting env. episode 7961, reward total was -15.0. running mean: -17.25663679660857, timestamp: 2022-08-20 01:03:15.815967\n",
      "resetting env. episode 7962, reward total was -15.0. running mean: -17.234070428642482, timestamp: 2022-08-20 01:03:21.877035\n",
      "resetting env. episode 7963, reward total was -17.0. running mean: -17.231729724356057, timestamp: 2022-08-20 01:03:26.367089\n",
      "resetting env. episode 7964, reward total was -16.0. running mean: -17.2194124271125, timestamp: 2022-08-20 01:03:31.545146\n",
      "resetting env. episode 7965, reward total was -17.0. running mean: -17.217218302841374, timestamp: 2022-08-20 01:03:36.857207\n",
      "resetting env. episode 7966, reward total was -19.0. running mean: -17.23504611981296, timestamp: 2022-08-20 01:03:41.167260\n",
      "resetting env. episode 7967, reward total was -17.0. running mean: -17.232695658614833, timestamp: 2022-08-20 01:03:45.803310\n",
      "resetting env. episode 7968, reward total was -18.0. running mean: -17.240368702028686, timestamp: 2022-08-20 01:03:50.353363\n",
      "resetting env. episode 7969, reward total was -17.0. running mean: -17.2379650150084, timestamp: 2022-08-20 01:03:54.313406\n",
      "resetting env. episode 7970, reward total was -16.0. running mean: -17.225585364858315, timestamp: 2022-08-20 01:04:00.079470\n",
      "resetting env. episode 7971, reward total was -20.0. running mean: -17.25332951120973, timestamp: 2022-08-20 01:04:04.521043\n",
      "resetting env. episode 7972, reward total was -17.0. running mean: -17.250796216097637, timestamp: 2022-08-20 01:04:08.930092\n",
      "resetting env. episode 7973, reward total was -16.0. running mean: -17.23828825393666, timestamp: 2022-08-20 01:04:12.721136\n",
      "resetting env. episode 7974, reward total was -20.0. running mean: -17.26590537139729, timestamp: 2022-08-20 01:04:16.952706\n",
      "resetting env. episode 7975, reward total was -19.0. running mean: -17.28324631768332, timestamp: 2022-08-20 01:04:20.767748\n",
      "resetting env. episode 7976, reward total was -17.0. running mean: -17.28041385450649, timestamp: 2022-08-20 01:04:25.202800\n",
      "resetting env. episode 7977, reward total was -18.0. running mean: -17.287609715961427, timestamp: 2022-08-20 01:04:29.925854\n",
      "resetting env. episode 7978, reward total was -18.0. running mean: -17.29473361880181, timestamp: 2022-08-20 01:04:34.315903\n",
      "resetting env. episode 7979, reward total was -19.0. running mean: -17.311786282613795, timestamp: 2022-08-20 01:04:38.503953\n",
      "resetting env. episode 7980, reward total was -19.0. running mean: -17.328668419787657, timestamp: 2022-08-20 01:04:42.775998\n",
      "resetting env. episode 7981, reward total was -19.0. running mean: -17.345381735589783, timestamp: 2022-08-20 01:04:46.657046\n",
      "resetting env. episode 7982, reward total was -14.0. running mean: -17.311927918233884, timestamp: 2022-08-20 01:04:51.802103\n",
      "resetting env. episode 7983, reward total was -17.0. running mean: -17.30880863905155, timestamp: 2022-08-20 01:04:56.304155\n",
      "resetting env. episode 7984, reward total was -19.0. running mean: -17.325720552661036, timestamp: 2022-08-20 01:05:00.500204\n",
      "resetting env. episode 7985, reward total was -17.0. running mean: -17.322463347134427, timestamp: 2022-08-20 01:05:05.314258\n",
      "resetting env. episode 7986, reward total was -18.0. running mean: -17.32923871366308, timestamp: 2022-08-20 01:05:09.817307\n",
      "resetting env. episode 7987, reward total was -18.0. running mean: -17.33594632652645, timestamp: 2022-08-20 01:05:14.750365\n",
      "resetting env. episode 7988, reward total was -17.0. running mean: -17.332586863261188, timestamp: 2022-08-20 01:05:20.388428\n",
      "resetting env. episode 7989, reward total was -20.0. running mean: -17.359260994628574, timestamp: 2022-08-20 01:05:25.170483\n",
      "resetting env. episode 7990, reward total was -13.0. running mean: -17.315668384682287, timestamp: 2022-08-20 01:05:29.863536\n",
      "resetting env. episode 7991, reward total was -17.0. running mean: -17.312511700835465, timestamp: 2022-08-20 01:05:34.356588\n",
      "resetting env. episode 7992, reward total was -16.0. running mean: -17.29938658382711, timestamp: 2022-08-20 01:05:39.237645\n",
      "resetting env. episode 7993, reward total was -19.0. running mean: -17.31639271798884, timestamp: 2022-08-20 01:05:44.032697\n",
      "resetting env. episode 7994, reward total was -17.0. running mean: -17.313228790808953, timestamp: 2022-08-20 01:05:48.778751\n",
      "resetting env. episode 7995, reward total was -19.0. running mean: -17.330096502900865, timestamp: 2022-08-20 01:05:53.015801\n",
      "resetting env. episode 7996, reward total was -21.0. running mean: -17.36679553787186, timestamp: 2022-08-20 01:05:56.715842\n",
      "resetting env. episode 7997, reward total was -14.0. running mean: -17.33312758249314, timestamp: 2022-08-20 01:06:02.202902\n",
      "resetting env. episode 7998, reward total was -17.0. running mean: -17.32979630666821, timestamp: 2022-08-20 01:06:06.707954\n",
      "resetting env. episode 7999, reward total was -17.0. running mean: -17.32649834360153, timestamp: 2022-08-20 01:06:10.624998\n",
      "resetting env. episode 8000, reward total was -15.0. running mean: -17.30323336016551, timestamp: 2022-08-20 01:06:15.456051\n",
      "resetting env. episode 8001, reward total was -18.0. running mean: -17.310201026563856, timestamp: 2022-08-20 01:06:19.136096\n",
      "resetting env. episode 8002, reward total was -13.0. running mean: -17.267099016298218, timestamp: 2022-08-20 01:06:24.202151\n",
      "resetting env. episode 8003, reward total was -17.0. running mean: -17.26442802613524, timestamp: 2022-08-20 01:06:28.482201\n",
      "resetting env. episode 8004, reward total was -17.0. running mean: -17.26178374587389, timestamp: 2022-08-20 01:06:34.005262\n",
      "resetting env. episode 8005, reward total was -12.0. running mean: -17.20916590841515, timestamp: 2022-08-20 01:06:39.559325\n",
      "resetting env. episode 8006, reward total was -20.0. running mean: -17.237074249331, timestamp: 2022-08-20 01:06:44.506383\n",
      "resetting env. episode 8007, reward total was -19.0. running mean: -17.25470350683769, timestamp: 2022-08-20 01:06:49.344434\n",
      "resetting env. episode 8008, reward total was -20.0. running mean: -17.282156471769312, timestamp: 2022-08-20 01:06:53.630486\n",
      "resetting env. episode 8009, reward total was -19.0. running mean: -17.29933490705162, timestamp: 2022-08-20 01:06:57.785530\n",
      "resetting env. episode 8010, reward total was -18.0. running mean: -17.306341557981103, timestamp: 2022-08-20 01:07:03.060592\n",
      "resetting env. episode 8011, reward total was -20.0. running mean: -17.33327814240129, timestamp: 2022-08-20 01:07:06.933637\n",
      "resetting env. episode 8012, reward total was -18.0. running mean: -17.33994536097728, timestamp: 2022-08-20 01:07:10.858679\n",
      "resetting env. episode 8013, reward total was -18.0. running mean: -17.346545907367506, timestamp: 2022-08-20 01:07:16.060738\n",
      "resetting env. episode 8014, reward total was -13.0. running mean: -17.30308044829383, timestamp: 2022-08-20 01:07:21.594802\n",
      "resetting env. episode 8015, reward total was -18.0. running mean: -17.310049643810892, timestamp: 2022-08-20 01:07:26.723857\n",
      "resetting env. episode 8016, reward total was -15.0. running mean: -17.28694914737278, timestamp: 2022-08-20 01:07:31.319912\n",
      "resetting env. episode 8017, reward total was -19.0. running mean: -17.304079655899052, timestamp: 2022-08-20 01:07:35.598480\n",
      "resetting env. episode 8018, reward total was -19.0. running mean: -17.321038859340064, timestamp: 2022-08-20 01:07:39.794053\n",
      "resetting env. episode 8019, reward total was -14.0. running mean: -17.287828470746664, timestamp: 2022-08-20 01:07:43.671097\n",
      "resetting env. episode 8020, reward total was -19.0. running mean: -17.3049501860392, timestamp: 2022-08-20 01:07:47.982144\n",
      "resetting env. episode 8021, reward total was -17.0. running mean: -17.301900684178808, timestamp: 2022-08-20 01:07:53.299729\n",
      "resetting env. episode 8022, reward total was -20.0. running mean: -17.32888167733702, timestamp: 2022-08-20 01:07:57.912782\n",
      "resetting env. episode 8023, reward total was -19.0. running mean: -17.34559286056365, timestamp: 2022-08-20 01:08:02.564832\n",
      "resetting env. episode 8024, reward total was -15.0. running mean: -17.32213693195801, timestamp: 2022-08-20 01:08:07.185884\n",
      "resetting env. episode 8025, reward total was -17.0. running mean: -17.31891556263843, timestamp: 2022-08-20 01:08:10.868929\n",
      "resetting env. episode 8026, reward total was -19.0. running mean: -17.335726407012046, timestamp: 2022-08-20 01:08:15.320505\n",
      "resetting env. episode 8027, reward total was -14.0. running mean: -17.302369142941927, timestamp: 2022-08-20 01:08:21.319572\n",
      "resetting env. episode 8028, reward total was -16.0. running mean: -17.289345451512506, timestamp: 2022-08-20 01:08:26.568630\n",
      "resetting env. episode 8029, reward total was -18.0. running mean: -17.29645199699738, timestamp: 2022-08-20 01:08:31.320686\n",
      "resetting env. episode 8030, reward total was -16.0. running mean: -17.283487477027407, timestamp: 2022-08-20 01:08:36.512746\n",
      "resetting env. episode 8031, reward total was -15.0. running mean: -17.26065260225713, timestamp: 2022-08-20 01:08:41.743803\n",
      "resetting env. episode 8032, reward total was -18.0. running mean: -17.26804607623456, timestamp: 2022-08-20 01:08:47.078864\n",
      "resetting env. episode 8033, reward total was -15.0. running mean: -17.24536561547221, timestamp: 2022-08-20 01:08:51.442915\n",
      "resetting env. episode 8034, reward total was -17.0. running mean: -17.24291195931749, timestamp: 2022-08-20 01:08:56.524971\n",
      "resetting env. episode 8035, reward total was -15.0. running mean: -17.220482839724312, timestamp: 2022-08-20 01:09:02.144035\n",
      "resetting env. episode 8036, reward total was -15.0. running mean: -17.198278011327066, timestamp: 2022-08-20 01:09:07.425092\n",
      "resetting env. episode 8037, reward total was -14.0. running mean: -17.166295231213795, timestamp: 2022-08-20 01:09:12.864154\n",
      "resetting env. episode 8038, reward total was -15.0. running mean: -17.144632278901653, timestamp: 2022-08-20 01:09:16.781195\n",
      "resetting env. episode 8039, reward total was -17.0. running mean: -17.14318595611264, timestamp: 2022-08-20 01:09:21.691250\n",
      "resetting env. episode 8040, reward total was -18.0. running mean: -17.15175409655151, timestamp: 2022-08-20 01:09:26.880307\n",
      "resetting env. episode 8041, reward total was -13.0. running mean: -17.110236555585995, timestamp: 2022-08-20 01:09:32.805375\n",
      "resetting env. episode 8042, reward total was -21.0. running mean: -17.149134190030136, timestamp: 2022-08-20 01:09:37.119424\n",
      "resetting env. episode 8043, reward total was -16.0. running mean: -17.137642848129833, timestamp: 2022-08-20 01:09:42.004481\n",
      "resetting env. episode 8044, reward total was -15.0. running mean: -17.116266419648532, timestamp: 2022-08-20 01:09:47.268536\n",
      "resetting env. episode 8045, reward total was -16.0. running mean: -17.105103755452046, timestamp: 2022-08-20 01:09:51.967602\n",
      "resetting env. episode 8046, reward total was -16.0. running mean: -17.094052717897526, timestamp: 2022-08-20 01:09:55.519630\n",
      "resetting env. episode 8047, reward total was -19.0. running mean: -17.113112190718553, timestamp: 2022-08-20 01:10:00.457685\n",
      "resetting env. episode 8048, reward total was -15.0. running mean: -17.091981068811364, timestamp: 2022-08-20 01:10:05.555741\n",
      "resetting env. episode 8049, reward total was -17.0. running mean: -17.09106125812325, timestamp: 2022-08-20 01:10:10.226794\n",
      "resetting env. episode 8050, reward total was -16.0. running mean: -17.08015064554202, timestamp: 2022-08-20 01:10:14.507842\n",
      "resetting env. episode 8051, reward total was -14.0. running mean: -17.0493491390866, timestamp: 2022-08-20 01:10:20.638911\n",
      "resetting env. episode 8052, reward total was -16.0. running mean: -17.038855647695737, timestamp: 2022-08-20 01:10:26.084973\n",
      "resetting env. episode 8053, reward total was -17.0. running mean: -17.03846709121878, timestamp: 2022-08-20 01:10:31.033027\n",
      "resetting env. episode 8054, reward total was -17.0. running mean: -17.038082420306594, timestamp: 2022-08-20 01:10:36.664096\n",
      "resetting env. episode 8055, reward total was -19.0. running mean: -17.05770159610353, timestamp: 2022-08-20 01:10:41.140144\n",
      "resetting env. episode 8056, reward total was -19.0. running mean: -17.077124580142495, timestamp: 2022-08-20 01:10:45.602193\n",
      "resetting env. episode 8057, reward total was -21.0. running mean: -17.11635333434107, timestamp: 2022-08-20 01:10:49.687236\n",
      "resetting env. episode 8058, reward total was -16.0. running mean: -17.10518980099766, timestamp: 2022-08-20 01:10:54.888295\n",
      "resetting env. episode 8059, reward total was -20.0. running mean: -17.134137902987682, timestamp: 2022-08-20 01:10:58.887343\n",
      "resetting env. episode 8060, reward total was -19.0. running mean: -17.152796523957807, timestamp: 2022-08-20 01:11:03.143389\n",
      "resetting env. episode 8061, reward total was -16.0. running mean: -17.14126855871823, timestamp: 2022-08-20 01:11:08.652449\n",
      "resetting env. episode 8062, reward total was -11.0. running mean: -17.07985587313105, timestamp: 2022-08-20 01:11:14.032507\n",
      "resetting env. episode 8063, reward total was -18.0. running mean: -17.08905731439974, timestamp: 2022-08-20 01:11:18.460560\n",
      "resetting env. episode 8064, reward total was -18.0. running mean: -17.098166741255742, timestamp: 2022-08-20 01:11:22.821605\n",
      "resetting env. episode 8065, reward total was -19.0. running mean: -17.117185073843185, timestamp: 2022-08-20 01:11:26.740651\n",
      "resetting env. episode 8066, reward total was -16.0. running mean: -17.106013223104753, timestamp: 2022-08-20 01:11:32.312711\n",
      "resetting env. episode 8067, reward total was -16.0. running mean: -17.094953090873705, timestamp: 2022-08-20 01:11:37.045763\n",
      "resetting env. episode 8068, reward total was -19.0. running mean: -17.11400355996497, timestamp: 2022-08-20 01:11:41.630815\n",
      "resetting env. episode 8069, reward total was -18.0. running mean: -17.12286352436532, timestamp: 2022-08-20 01:11:46.027862\n",
      "resetting env. episode 8070, reward total was -16.0. running mean: -17.111634889121667, timestamp: 2022-08-20 01:11:51.593924\n",
      "resetting env. episode 8071, reward total was -17.0. running mean: -17.11051854023045, timestamp: 2022-08-20 01:11:57.120989\n",
      "resetting env. episode 8072, reward total was -15.0. running mean: -17.089413354828146, timestamp: 2022-08-20 01:12:02.385047\n",
      "resetting env. episode 8073, reward total was -10.0. running mean: -17.018519221279867, timestamp: 2022-08-20 01:12:08.322111\n",
      "resetting env. episode 8074, reward total was -14.0. running mean: -16.98833402906707, timestamp: 2022-08-20 01:12:14.721180\n",
      "resetting env. episode 8075, reward total was -15.0. running mean: -16.968450688776397, timestamp: 2022-08-20 01:12:21.170254\n",
      "resetting env. episode 8076, reward total was -15.0. running mean: -16.94876618188863, timestamp: 2022-08-20 01:12:26.310319\n",
      "resetting env. episode 8077, reward total was -16.0. running mean: -16.93927852006974, timestamp: 2022-08-20 01:12:31.820372\n",
      "resetting env. episode 8078, reward total was -17.0. running mean: -16.939885734869044, timestamp: 2022-08-20 01:12:36.502424\n",
      "resetting env. episode 8079, reward total was -17.0. running mean: -16.940486877520357, timestamp: 2022-08-20 01:12:42.550490\n",
      "resetting env. episode 8080, reward total was -17.0. running mean: -16.941082008745155, timestamp: 2022-08-20 01:12:46.631538\n",
      "resetting env. episode 8081, reward total was -17.0. running mean: -16.941671188657704, timestamp: 2022-08-20 01:12:52.401121\n",
      "resetting env. episode 8082, reward total was -16.0. running mean: -16.932254476771128, timestamp: 2022-08-20 01:12:57.750180\n",
      "resetting env. episode 8083, reward total was -16.0. running mean: -16.922931932003415, timestamp: 2022-08-20 01:13:03.566245\n",
      "resetting env. episode 8084, reward total was -17.0. running mean: -16.923702612683382, timestamp: 2022-08-20 01:13:08.068295\n",
      "resetting env. episode 8085, reward total was -16.0. running mean: -16.91446558655655, timestamp: 2022-08-20 01:13:12.967352\n",
      "resetting env. episode 8086, reward total was -19.0. running mean: -16.935320930690985, timestamp: 2022-08-20 01:13:17.742400\n",
      "resetting env. episode 8087, reward total was -14.0. running mean: -16.905967721384076, timestamp: 2022-08-20 01:13:22.304460\n",
      "resetting env. episode 8088, reward total was -19.0. running mean: -16.926908044170236, timestamp: 2022-08-20 01:13:27.161505\n",
      "resetting env. episode 8089, reward total was -19.0. running mean: -16.947638963728537, timestamp: 2022-08-20 01:13:31.102552\n",
      "resetting env. episode 8090, reward total was -19.0. running mean: -16.968162574091252, timestamp: 2022-08-20 01:13:35.125596\n",
      "resetting env. episode 8091, reward total was -16.0. running mean: -16.95848094835034, timestamp: 2022-08-20 01:13:40.235653\n",
      "resetting env. episode 8092, reward total was -13.0. running mean: -16.918896138866835, timestamp: 2022-08-20 01:13:46.375722\n",
      "resetting env. episode 8093, reward total was -21.0. running mean: -16.959707177478165, timestamp: 2022-08-20 01:13:50.440297\n",
      "resetting env. episode 8094, reward total was -18.0. running mean: -16.970110105703384, timestamp: 2022-08-20 01:13:56.694366\n",
      "resetting env. episode 8095, reward total was -18.0. running mean: -16.98040900464635, timestamp: 2022-08-20 01:14:01.596424\n",
      "resetting env. episode 8096, reward total was -18.0. running mean: -16.99060491459989, timestamp: 2022-08-20 01:14:06.636477\n",
      "resetting env. episode 8097, reward total was -20.0. running mean: -17.020698865453888, timestamp: 2022-08-20 01:14:10.300520\n",
      "resetting env. episode 8098, reward total was -15.0. running mean: -17.000491876799348, timestamp: 2022-08-20 01:14:15.343574\n",
      "resetting env. episode 8099, reward total was -18.0. running mean: -17.010486958031354, timestamp: 2022-08-20 01:14:19.245619\n",
      "resetting env. episode 8100, reward total was -16.0. running mean: -17.00038208845104, timestamp: 2022-08-20 01:14:23.917192\n",
      "resetting env. episode 8101, reward total was -12.0. running mean: -16.95037826756653, timestamp: 2022-08-20 01:14:30.533797\n",
      "resetting env. episode 8102, reward total was -18.0. running mean: -16.960874484890866, timestamp: 2022-08-20 01:14:35.441848\n",
      "resetting env. episode 8103, reward total was -16.0. running mean: -16.951265740041958, timestamp: 2022-08-20 01:14:39.584896\n",
      "resetting env. episode 8104, reward total was -16.0. running mean: -16.941753082641537, timestamp: 2022-08-20 01:14:45.299961\n",
      "resetting env. episode 8105, reward total was -16.0. running mean: -16.93233555181512, timestamp: 2022-08-20 01:14:50.551020\n",
      "resetting env. episode 8106, reward total was -17.0. running mean: -16.93301219629697, timestamp: 2022-08-20 01:14:56.000088\n",
      "resetting env. episode 8107, reward total was -16.0. running mean: -16.923682074334003, timestamp: 2022-08-20 01:15:01.248145\n",
      "resetting env. episode 8108, reward total was -17.0. running mean: -16.924445253590665, timestamp: 2022-08-20 01:15:06.254196\n",
      "resetting env. episode 8109, reward total was -12.0. running mean: -16.87520080105476, timestamp: 2022-08-20 01:15:11.647259\n",
      "resetting env. episode 8110, reward total was -14.0. running mean: -16.846448793044214, timestamp: 2022-08-20 01:15:18.178334\n",
      "resetting env. episode 8111, reward total was -15.0. running mean: -16.82798430511377, timestamp: 2022-08-20 01:15:23.371393\n",
      "resetting env. episode 8112, reward total was -20.0. running mean: -16.85970446206263, timestamp: 2022-08-20 01:15:28.153446\n",
      "resetting env. episode 8113, reward total was -16.0. running mean: -16.851107417442005, timestamp: 2022-08-20 01:15:32.582498\n",
      "resetting env. episode 8114, reward total was -14.0. running mean: -16.822596343267584, timestamp: 2022-08-20 01:15:38.909567\n",
      "resetting env. episode 8115, reward total was -16.0. running mean: -16.81437037983491, timestamp: 2022-08-20 01:15:43.455619\n",
      "resetting env. episode 8116, reward total was -17.0. running mean: -16.81622667603656, timestamp: 2022-08-20 01:15:47.065663\n",
      "resetting env. episode 8117, reward total was -19.0. running mean: -16.838064409276196, timestamp: 2022-08-20 01:15:51.830714\n",
      "resetting env. episode 8118, reward total was -17.0. running mean: -16.839683765183437, timestamp: 2022-08-20 01:15:56.745769\n",
      "resetting env. episode 8119, reward total was -13.0. running mean: -16.801286927531603, timestamp: 2022-08-20 01:16:00.269811\n",
      "resetting env. episode 8120, reward total was -13.0. running mean: -16.763274058256286, timestamp: 2022-08-20 01:16:06.277880\n",
      "resetting env. episode 8121, reward total was -14.0. running mean: -16.735641317673725, timestamp: 2022-08-20 01:16:10.848932\n",
      "resetting env. episode 8122, reward total was -14.0. running mean: -16.70828490449699, timestamp: 2022-08-20 01:16:15.916992\n",
      "resetting env. episode 8123, reward total was -14.0. running mean: -16.68120205545202, timestamp: 2022-08-20 01:16:21.149048\n",
      "resetting env. episode 8124, reward total was -18.0. running mean: -16.6943900348975, timestamp: 2022-08-20 01:16:26.636110\n",
      "resetting env. episode 8125, reward total was -14.0. running mean: -16.667446134548523, timestamp: 2022-08-20 01:16:32.442701\n",
      "resetting env. episode 8126, reward total was -18.0. running mean: -16.680771673203036, timestamp: 2022-08-20 01:16:38.135765\n",
      "resetting env. episode 8127, reward total was -17.0. running mean: -16.683963956471008, timestamp: 2022-08-20 01:16:44.090831\n",
      "resetting env. episode 8128, reward total was -17.0. running mean: -16.6871243169063, timestamp: 2022-08-20 01:16:48.863887\n",
      "resetting env. episode 8129, reward total was -17.0. running mean: -16.69025307373724, timestamp: 2022-08-20 01:16:54.089947\n",
      "resetting env. episode 8130, reward total was -18.0. running mean: -16.703350542999868, timestamp: 2022-08-20 01:16:58.597998\n",
      "resetting env. episode 8131, reward total was -15.0. running mean: -16.686317037569868, timestamp: 2022-08-20 01:17:03.712054\n",
      "resetting env. episode 8132, reward total was -20.0. running mean: -16.71945386719417, timestamp: 2022-08-20 01:17:08.465109\n",
      "resetting env. episode 8133, reward total was -15.0. running mean: -16.702259328522224, timestamp: 2022-08-20 01:17:13.570696\n",
      "resetting env. episode 8134, reward total was -14.0. running mean: -16.675236735237004, timestamp: 2022-08-20 01:17:18.628765\n",
      "resetting env. episode 8135, reward total was -16.0. running mean: -16.668484367884634, timestamp: 2022-08-20 01:17:24.310341\n",
      "resetting env. episode 8136, reward total was -17.0. running mean: -16.671799524205788, timestamp: 2022-08-20 01:17:28.774391\n",
      "resetting env. episode 8137, reward total was -19.0. running mean: -16.69508152896373, timestamp: 2022-08-20 01:17:33.977983\n",
      "resetting env. episode 8138, reward total was -16.0. running mean: -16.68813071367409, timestamp: 2022-08-20 01:17:38.597035\n",
      "resetting env. episode 8139, reward total was -20.0. running mean: -16.72124940653735, timestamp: 2022-08-20 01:17:43.556091\n",
      "resetting env. episode 8140, reward total was -14.0. running mean: -16.694036912471976, timestamp: 2022-08-20 01:17:48.273143\n",
      "resetting env. episode 8141, reward total was -19.0. running mean: -16.717096543347257, timestamp: 2022-08-20 01:17:52.822199\n",
      "resetting env. episode 8142, reward total was -19.0. running mean: -16.739925577913784, timestamp: 2022-08-20 01:17:58.513260\n",
      "resetting env. episode 8143, reward total was -21.0. running mean: -16.782526322134647, timestamp: 2022-08-20 01:18:01.670300\n",
      "resetting env. episode 8144, reward total was -21.0. running mean: -16.824701058913302, timestamp: 2022-08-20 01:18:06.316350\n",
      "resetting env. episode 8145, reward total was -15.0. running mean: -16.806454048324166, timestamp: 2022-08-20 01:18:12.287943\n",
      "resetting env. episode 8146, reward total was -17.0. running mean: -16.808389507840925, timestamp: 2022-08-20 01:18:17.340002\n",
      "resetting env. episode 8147, reward total was -19.0. running mean: -16.830305612762515, timestamp: 2022-08-20 01:18:21.153046\n",
      "resetting env. episode 8148, reward total was -16.0. running mean: -16.82200255663489, timestamp: 2022-08-20 01:18:26.698109\n",
      "resetting env. episode 8149, reward total was -15.0. running mean: -16.80378253106854, timestamp: 2022-08-20 01:18:31.475163\n",
      "resetting env. episode 8150, reward total was -13.0. running mean: -16.765744705757854, timestamp: 2022-08-20 01:18:37.382232\n",
      "resetting env. episode 8151, reward total was -17.0. running mean: -16.768087258700277, timestamp: 2022-08-20 01:18:41.938291\n",
      "resetting env. episode 8152, reward total was -16.0. running mean: -16.760406386113274, timestamp: 2022-08-20 01:18:48.014357\n",
      "resetting env. episode 8153, reward total was -18.0. running mean: -16.77280232225214, timestamp: 2022-08-20 01:18:52.022401\n",
      "resetting env. episode 8154, reward total was -18.0. running mean: -16.785074299029617, timestamp: 2022-08-20 01:18:57.749466\n",
      "resetting env. episode 8155, reward total was -19.0. running mean: -16.80722355603932, timestamp: 2022-08-20 01:19:01.895513\n",
      "resetting env. episode 8156, reward total was -14.0. running mean: -16.779151320478928, timestamp: 2022-08-20 01:19:07.929585\n",
      "resetting env. episode 8157, reward total was -19.0. running mean: -16.80135980727414, timestamp: 2022-08-20 01:19:12.071630\n",
      "resetting env. episode 8158, reward total was -20.0. running mean: -16.833346209201398, timestamp: 2022-08-20 01:19:16.742206\n",
      "resetting env. episode 8159, reward total was -17.0. running mean: -16.835012747109385, timestamp: 2022-08-20 01:19:21.753263\n",
      "resetting env. episode 8160, reward total was -18.0. running mean: -16.84666261963829, timestamp: 2022-08-20 01:19:26.333318\n",
      "resetting env. episode 8161, reward total was -19.0. running mean: -16.86819599344191, timestamp: 2022-08-20 01:19:31.169372\n",
      "resetting env. episode 8162, reward total was -15.0. running mean: -16.84951403350749, timestamp: 2022-08-20 01:19:35.755423\n",
      "resetting env. episode 8163, reward total was -19.0. running mean: -16.871018893172415, timestamp: 2022-08-20 01:19:40.541477\n",
      "resetting env. episode 8164, reward total was -21.0. running mean: -16.912308704240694, timestamp: 2022-08-20 01:19:45.779539\n",
      "resetting env. episode 8165, reward total was -21.0. running mean: -16.953185617198287, timestamp: 2022-08-20 01:19:50.876599\n",
      "resetting env. episode 8166, reward total was -18.0. running mean: -16.963653761026304, timestamp: 2022-08-20 01:19:54.997646\n",
      "resetting env. episode 8167, reward total was -13.0. running mean: -16.92401722341604, timestamp: 2022-08-20 01:20:00.008703\n",
      "resetting env. episode 8168, reward total was -18.0. running mean: -16.93477705118188, timestamp: 2022-08-20 01:20:04.895760\n",
      "resetting env. episode 8169, reward total was -13.0. running mean: -16.895429280670058, timestamp: 2022-08-20 01:20:11.082831\n",
      "resetting env. episode 8170, reward total was -17.0. running mean: -16.89647498786336, timestamp: 2022-08-20 01:20:16.310891\n",
      "resetting env. episode 8171, reward total was -15.0. running mean: -16.877510237984726, timestamp: 2022-08-20 01:20:21.537473\n",
      "resetting env. episode 8172, reward total was -17.0. running mean: -16.87873513560488, timestamp: 2022-08-20 01:20:26.031522\n",
      "resetting env. episode 8173, reward total was -20.0. running mean: -16.909947784248832, timestamp: 2022-08-20 01:20:31.357583\n",
      "resetting env. episode 8174, reward total was -17.0. running mean: -16.910848306406344, timestamp: 2022-08-20 01:20:36.015636\n",
      "resetting env. episode 8175, reward total was -17.0. running mean: -16.91173982334228, timestamp: 2022-08-20 01:20:40.131685\n",
      "resetting env. episode 8176, reward total was -18.0. running mean: -16.92262242510886, timestamp: 2022-08-20 01:20:44.770739\n",
      "resetting env. episode 8177, reward total was -18.0. running mean: -16.93339620085777, timestamp: 2022-08-20 01:20:50.334320\n",
      "resetting env. episode 8178, reward total was -14.0. running mean: -16.904062238849193, timestamp: 2022-08-20 01:20:55.136374\n",
      "resetting env. episode 8179, reward total was -21.0. running mean: -16.9450216164607, timestamp: 2022-08-20 01:20:59.309949\n",
      "resetting env. episode 8180, reward total was -14.0. running mean: -16.915571400296095, timestamp: 2022-08-20 01:21:04.570008\n",
      "resetting env. episode 8181, reward total was -17.0. running mean: -16.916415686293135, timestamp: 2022-08-20 01:21:08.864061\n",
      "resetting env. episode 8182, reward total was -14.0. running mean: -16.887251529430205, timestamp: 2022-08-20 01:21:13.740113\n",
      "resetting env. episode 8183, reward total was -17.0. running mean: -16.888379014135904, timestamp: 2022-08-20 01:21:18.133684\n",
      "resetting env. episode 8184, reward total was -14.0. running mean: -16.859495223994546, timestamp: 2022-08-20 01:21:23.344262\n",
      "resetting env. episode 8185, reward total was -19.0. running mean: -16.8809002717546, timestamp: 2022-08-20 01:21:28.401320\n",
      "resetting env. episode 8186, reward total was -21.0. running mean: -16.922091269037058, timestamp: 2022-08-20 01:21:32.074362\n",
      "resetting env. episode 8187, reward total was -14.0. running mean: -16.892870356346688, timestamp: 2022-08-20 01:21:37.188420\n",
      "resetting env. episode 8188, reward total was -15.0. running mean: -16.87394165278322, timestamp: 2022-08-20 01:21:42.281478\n",
      "resetting env. episode 8189, reward total was -15.0. running mean: -16.855202236255387, timestamp: 2022-08-20 01:21:47.745542\n",
      "resetting env. episode 8190, reward total was -17.0. running mean: -16.856650213892834, timestamp: 2022-08-20 01:21:53.245607\n",
      "resetting env. episode 8191, reward total was -20.0. running mean: -16.888083711753904, timestamp: 2022-08-20 01:21:58.050180\n",
      "resetting env. episode 8192, reward total was -16.0. running mean: -16.879202874636366, timestamp: 2022-08-20 01:22:03.265241\n",
      "resetting env. episode 8193, reward total was -13.0. running mean: -16.840410845890002, timestamp: 2022-08-20 01:22:08.232824\n",
      "resetting env. episode 8194, reward total was -15.0. running mean: -16.8220067374311, timestamp: 2022-08-20 01:22:13.215879\n",
      "resetting env. episode 8195, reward total was -18.0. running mean: -16.83378667005679, timestamp: 2022-08-20 01:22:17.062922\n",
      "resetting env. episode 8196, reward total was -14.0. running mean: -16.80544880335622, timestamp: 2022-08-20 01:22:22.698565\n",
      "resetting env. episode 8197, reward total was -20.0. running mean: -16.83739431532266, timestamp: 2022-08-20 01:22:27.414616\n",
      "resetting env. episode 8198, reward total was -17.0. running mean: -16.839020372169433, timestamp: 2022-08-20 01:22:32.565677\n",
      "resetting env. episode 8199, reward total was -17.0. running mean: -16.84063016844774, timestamp: 2022-08-20 01:22:36.436719\n",
      "resetting env. episode 8200, reward total was -20.0. running mean: -16.87222386676326, timestamp: 2022-08-20 01:22:40.524763\n",
      "resetting env. episode 8201, reward total was -15.0. running mean: -16.853501628095625, timestamp: 2022-08-20 01:22:44.701813\n",
      "resetting env. episode 8202, reward total was -17.0. running mean: -16.85496661181467, timestamp: 2022-08-20 01:22:49.484870\n",
      "resetting env. episode 8203, reward total was -13.0. running mean: -16.816416945696524, timestamp: 2022-08-20 01:22:55.734939\n",
      "resetting env. episode 8204, reward total was -17.0. running mean: -16.81825277623956, timestamp: 2022-08-20 01:23:00.404993\n",
      "resetting env. episode 8205, reward total was -15.0. running mean: -16.800070248477162, timestamp: 2022-08-20 01:23:05.543052\n",
      "resetting env. episode 8206, reward total was -19.0. running mean: -16.82206954599239, timestamp: 2022-08-20 01:23:09.606095\n",
      "resetting env. episode 8207, reward total was -21.0. running mean: -16.86384885053247, timestamp: 2022-08-20 01:23:14.774155\n",
      "resetting env. episode 8208, reward total was -20.0. running mean: -16.895210362027143, timestamp: 2022-08-20 01:23:20.574223\n",
      "resetting env. episode 8209, reward total was -14.0. running mean: -16.866258258406873, timestamp: 2022-08-20 01:23:25.485280\n",
      "resetting env. episode 8210, reward total was -16.0. running mean: -16.857595675822804, timestamp: 2022-08-20 01:23:30.921868\n",
      "resetting env. episode 8211, reward total was -17.0. running mean: -16.859019719064577, timestamp: 2022-08-20 01:23:35.339924\n",
      "resetting env. episode 8212, reward total was -18.0. running mean: -16.87042952187393, timestamp: 2022-08-20 01:23:40.966984\n",
      "resetting env. episode 8213, reward total was -19.0. running mean: -16.891725226655193, timestamp: 2022-08-20 01:23:45.011033\n",
      "resetting env. episode 8214, reward total was -16.0. running mean: -16.88280797438864, timestamp: 2022-08-20 01:23:50.741098\n",
      "resetting env. episode 8215, reward total was -15.0. running mean: -16.863979894644753, timestamp: 2022-08-20 01:23:55.555151\n",
      "resetting env. episode 8216, reward total was -16.0. running mean: -16.855340095698306, timestamp: 2022-08-20 01:24:00.079205\n",
      "resetting env. episode 8217, reward total was -17.0. running mean: -16.856786694741324, timestamp: 2022-08-20 01:24:05.716266\n",
      "resetting env. episode 8218, reward total was -15.0. running mean: -16.83821882779391, timestamp: 2022-08-20 01:24:10.153843\n",
      "resetting env. episode 8219, reward total was -21.0. running mean: -16.879836639515972, timestamp: 2022-08-20 01:24:14.103889\n",
      "resetting env. episode 8220, reward total was -18.0. running mean: -16.891038273120813, timestamp: 2022-08-20 01:24:18.641461\n",
      "resetting env. episode 8221, reward total was -18.0. running mean: -16.902127890389604, timestamp: 2022-08-20 01:24:22.466506\n",
      "resetting env. episode 8222, reward total was -17.0. running mean: -16.90310661148571, timestamp: 2022-08-20 01:24:28.103568\n",
      "resetting env. episode 8223, reward total was -15.0. running mean: -16.88407554537085, timestamp: 2022-08-20 01:24:32.459621\n",
      "resetting env. episode 8224, reward total was -15.0. running mean: -16.865234789917142, timestamp: 2022-08-20 01:24:37.795680\n",
      "resetting env. episode 8225, reward total was -18.0. running mean: -16.87658244201797, timestamp: 2022-08-20 01:24:42.402731\n",
      "resetting env. episode 8226, reward total was -16.0. running mean: -16.86781661759779, timestamp: 2022-08-20 01:24:47.092312\n",
      "resetting env. episode 8227, reward total was -18.0. running mean: -16.87913845142181, timestamp: 2022-08-20 01:24:51.469363\n",
      "resetting env. episode 8228, reward total was -19.0. running mean: -16.900347066907592, timestamp: 2022-08-20 01:24:56.865425\n",
      "resetting env. episode 8229, reward total was -18.0. running mean: -16.911343596238517, timestamp: 2022-08-20 01:25:00.616992\n",
      "resetting env. episode 8230, reward total was -19.0. running mean: -16.932230160276134, timestamp: 2022-08-20 01:25:06.563060\n",
      "resetting env. episode 8231, reward total was -18.0. running mean: -16.942907858673372, timestamp: 2022-08-20 01:25:11.834643\n",
      "resetting env. episode 8232, reward total was -17.0. running mean: -16.94347878008664, timestamp: 2022-08-20 01:25:18.219237\n",
      "resetting env. episode 8233, reward total was -15.0. running mean: -16.92404399228577, timestamp: 2022-08-20 01:25:23.410297\n",
      "resetting env. episode 8234, reward total was -20.0. running mean: -16.95480355236291, timestamp: 2022-08-20 01:25:28.355352\n",
      "resetting env. episode 8235, reward total was -17.0. running mean: -16.955255516839284, timestamp: 2022-08-20 01:25:33.009404\n",
      "resetting env. episode 8236, reward total was -18.0. running mean: -16.96570296167089, timestamp: 2022-08-20 01:25:38.166464\n",
      "resetting env. episode 8237, reward total was -15.0. running mean: -16.94604593205418, timestamp: 2022-08-20 01:25:44.089530\n",
      "resetting env. episode 8238, reward total was -18.0. running mean: -16.956585472733636, timestamp: 2022-08-20 01:25:49.434591\n",
      "resetting env. episode 8239, reward total was -17.0. running mean: -16.9570196180063, timestamp: 2022-08-20 01:25:53.286637\n",
      "resetting env. episode 8240, reward total was -15.0. running mean: -16.937449421826233, timestamp: 2022-08-20 01:25:59.919708\n",
      "resetting env. episode 8241, reward total was -19.0. running mean: -16.95807492760797, timestamp: 2022-08-20 01:26:05.082770\n",
      "resetting env. episode 8242, reward total was -11.0. running mean: -16.89849417833189, timestamp: 2022-08-20 01:26:10.461831\n",
      "resetting env. episode 8243, reward total was -11.0. running mean: -16.839509236548572, timestamp: 2022-08-20 01:26:15.953892\n",
      "resetting env. episode 8244, reward total was -19.0. running mean: -16.861114144183087, timestamp: 2022-08-20 01:26:20.970947\n",
      "resetting env. episode 8245, reward total was -14.0. running mean: -16.832503002741255, timestamp: 2022-08-20 01:26:25.755001\n",
      "resetting env. episode 8246, reward total was -13.0. running mean: -16.794177972713843, timestamp: 2022-08-20 01:26:31.791069\n",
      "resetting env. episode 8247, reward total was -21.0. running mean: -16.836236192986707, timestamp: 2022-08-20 01:26:36.069119\n",
      "resetting env. episode 8248, reward total was -19.0. running mean: -16.857873831056843, timestamp: 2022-08-20 01:26:40.813174\n",
      "resetting env. episode 8249, reward total was -16.0. running mean: -16.849295092746274, timestamp: 2022-08-20 01:26:46.611237\n",
      "resetting env. episode 8250, reward total was -16.0. running mean: -16.840802141818813, timestamp: 2022-08-20 01:26:52.130299\n",
      "resetting env. episode 8251, reward total was -13.0. running mean: -16.802394120400624, timestamp: 2022-08-20 01:26:58.129370\n",
      "resetting env. episode 8252, reward total was -13.0. running mean: -16.764370179196618, timestamp: 2022-08-20 01:27:03.623429\n",
      "resetting env. episode 8253, reward total was -18.0. running mean: -16.77672647740465, timestamp: 2022-08-20 01:27:08.101481\n",
      "resetting env. episode 8254, reward total was -18.0. running mean: -16.788959212630605, timestamp: 2022-08-20 01:27:12.965533\n",
      "resetting env. episode 8255, reward total was -17.0. running mean: -16.7910696205043, timestamp: 2022-08-20 01:27:17.562586\n",
      "resetting env. episode 8256, reward total was -19.0. running mean: -16.813158924299255, timestamp: 2022-08-20 01:27:22.197637\n",
      "resetting env. episode 8257, reward total was -17.0. running mean: -16.815027335056264, timestamp: 2022-08-20 01:27:27.445694\n",
      "resetting env. episode 8258, reward total was -20.0. running mean: -16.8468770617057, timestamp: 2022-08-20 01:27:32.332751\n",
      "resetting env. episode 8259, reward total was -16.0. running mean: -16.838408291088644, timestamp: 2022-08-20 01:27:37.764812\n",
      "resetting env. episode 8260, reward total was -21.0. running mean: -16.88002420817776, timestamp: 2022-08-20 01:27:42.061858\n",
      "resetting env. episode 8261, reward total was -18.0. running mean: -16.891223966095982, timestamp: 2022-08-20 01:27:46.771915\n",
      "resetting env. episode 8262, reward total was -13.0. running mean: -16.852311726435023, timestamp: 2022-08-20 01:27:52.614977\n",
      "resetting env. episode 8263, reward total was -15.0. running mean: -16.83378860917067, timestamp: 2022-08-20 01:27:57.981039\n",
      "resetting env. episode 8264, reward total was -18.0. running mean: -16.845450723078965, timestamp: 2022-08-20 01:28:03.458099\n",
      "resetting env. episode 8265, reward total was -15.0. running mean: -16.826996215848173, timestamp: 2022-08-20 01:28:08.058150\n",
      "resetting env. episode 8266, reward total was -19.0. running mean: -16.84872625368969, timestamp: 2022-08-20 01:28:12.478200\n",
      "resetting env. episode 8267, reward total was -18.0. running mean: -16.860238991152794, timestamp: 2022-08-20 01:28:18.001262\n",
      "resetting env. episode 8268, reward total was -21.0. running mean: -16.901636601241268, timestamp: 2022-08-20 01:28:22.414313\n",
      "resetting env. episode 8269, reward total was -21.0. running mean: -16.942620235228855, timestamp: 2022-08-20 01:28:27.299365\n",
      "resetting env. episode 8270, reward total was -20.0. running mean: -16.973194032876567, timestamp: 2022-08-20 01:28:32.469423\n",
      "resetting env. episode 8271, reward total was -18.0. running mean: -16.9834620925478, timestamp: 2022-08-20 01:28:37.226004\n",
      "resetting env. episode 8272, reward total was -15.0. running mean: -16.96362747162232, timestamp: 2022-08-20 01:28:42.362116\n",
      "resetting env. episode 8273, reward total was -19.0. running mean: -16.9839911969061, timestamp: 2022-08-20 01:28:48.572185\n",
      "resetting env. episode 8274, reward total was -17.0. running mean: -16.98415128493704, timestamp: 2022-08-20 01:28:52.578232\n",
      "resetting env. episode 8275, reward total was -17.0. running mean: -16.984309772087673, timestamp: 2022-08-20 01:28:57.936822\n",
      "resetting env. episode 8276, reward total was -19.0. running mean: -17.0044666743668, timestamp: 2022-08-20 01:29:02.859877\n",
      "resetting env. episode 8277, reward total was -15.0. running mean: -16.98442200762313, timestamp: 2022-08-20 01:29:08.856945\n",
      "resetting env. episode 8278, reward total was -19.0. running mean: -17.0045777875469, timestamp: 2022-08-20 01:29:12.825991\n",
      "resetting env. episode 8279, reward total was -15.0. running mean: -16.98453200967143, timestamp: 2022-08-20 01:29:17.013557\n",
      "resetting env. episode 8280, reward total was -15.0. running mean: -16.964686689574712, timestamp: 2022-08-20 01:29:22.530617\n",
      "resetting env. episode 8281, reward total was -18.0. running mean: -16.975039822678966, timestamp: 2022-08-20 01:29:26.971669\n",
      "resetting env. episode 8282, reward total was -18.0. running mean: -16.985289424452176, timestamp: 2022-08-20 01:29:32.814735\n",
      "resetting env. episode 8283, reward total was -15.0. running mean: -16.965436530207654, timestamp: 2022-08-20 01:29:38.301795\n",
      "resetting env. episode 8284, reward total was -13.0. running mean: -16.925782164905577, timestamp: 2022-08-20 01:29:43.091849\n",
      "resetting env. episode 8285, reward total was -21.0. running mean: -16.966524343256523, timestamp: 2022-08-20 01:29:47.709901\n",
      "resetting env. episode 8286, reward total was -17.0. running mean: -16.96685909982396, timestamp: 2022-08-20 01:29:52.592956\n",
      "resetting env. episode 8287, reward total was -13.0. running mean: -16.92719050882572, timestamp: 2022-08-20 01:29:58.294540\n",
      "resetting env. episode 8288, reward total was -16.0. running mean: -16.917918603737462, timestamp: 2022-08-20 01:30:03.578599\n",
      "resetting env. episode 8289, reward total was -16.0. running mean: -16.908739417700087, timestamp: 2022-08-20 01:30:07.986649\n",
      "resetting env. episode 8290, reward total was -20.0. running mean: -16.939652023523085, timestamp: 2022-08-20 01:30:13.952241\n",
      "resetting env. episode 8291, reward total was -21.0. running mean: -16.980255503287854, timestamp: 2022-08-20 01:30:18.036286\n",
      "resetting env. episode 8292, reward total was -17.0. running mean: -16.980452948254978, timestamp: 2022-08-20 01:30:22.655337\n",
      "resetting env. episode 8293, reward total was -17.0. running mean: -16.98064841877243, timestamp: 2022-08-20 01:30:27.110387\n",
      "resetting env. episode 8294, reward total was -19.0. running mean: -17.000841934584706, timestamp: 2022-08-20 01:30:31.283437\n",
      "resetting env. episode 8295, reward total was -16.0. running mean: -16.990833515238858, timestamp: 2022-08-20 01:30:37.466504\n",
      "resetting env. episode 8296, reward total was -19.0. running mean: -17.01092518008647, timestamp: 2022-08-20 01:30:43.153566\n",
      "resetting env. episode 8297, reward total was -14.0. running mean: -16.980815928285605, timestamp: 2022-08-20 01:30:48.598627\n",
      "resetting env. episode 8298, reward total was -15.0. running mean: -16.961007769002748, timestamp: 2022-08-20 01:30:53.614682\n",
      "resetting env. episode 8299, reward total was -16.0. running mean: -16.95139769131272, timestamp: 2022-08-20 01:30:58.182736\n",
      "resetting env. episode 8300, reward total was -17.0. running mean: -16.951883714399596, timestamp: 2022-08-20 01:31:02.823785\n",
      "resetting env. episode 8301, reward total was -18.0. running mean: -16.9623648772556, timestamp: 2022-08-20 01:31:08.369852\n",
      "resetting env. episode 8302, reward total was -13.0. running mean: -16.92274122848304, timestamp: 2022-08-20 01:31:14.610921\n",
      "resetting env. episode 8303, reward total was -15.0. running mean: -16.90351381619821, timestamp: 2022-08-20 01:31:20.717987\n",
      "resetting env. episode 8304, reward total was -16.0. running mean: -16.89447867803623, timestamp: 2022-08-20 01:31:25.215039\n",
      "resetting env. episode 8305, reward total was -19.0. running mean: -16.91553389125587, timestamp: 2022-08-20 01:31:30.493099\n",
      "resetting env. episode 8306, reward total was -16.0. running mean: -16.90637855234331, timestamp: 2022-08-20 01:31:35.635156\n",
      "resetting env. episode 8307, reward total was -14.0. running mean: -16.877314766819875, timestamp: 2022-08-20 01:31:41.330222\n",
      "resetting env. episode 8308, reward total was -20.0. running mean: -16.908541619151677, timestamp: 2022-08-20 01:31:46.070274\n",
      "resetting env. episode 8309, reward total was -19.0. running mean: -16.92945620296016, timestamp: 2022-08-20 01:31:50.616329\n",
      "resetting env. episode 8310, reward total was -17.0. running mean: -16.93016164093056, timestamp: 2022-08-20 01:31:56.665393\n",
      "resetting env. episode 8311, reward total was -14.0. running mean: -16.900860024521254, timestamp: 2022-08-20 01:32:02.300459\n",
      "resetting env. episode 8312, reward total was -17.0. running mean: -16.901851424276042, timestamp: 2022-08-20 01:32:07.399520\n",
      "resetting env. episode 8313, reward total was -16.0. running mean: -16.89283291003328, timestamp: 2022-08-20 01:32:12.243095\n",
      "resetting env. episode 8314, reward total was -19.0. running mean: -16.91390458093295, timestamp: 2022-08-20 01:32:15.587133\n",
      "resetting env. episode 8315, reward total was -18.0. running mean: -16.92476553512362, timestamp: 2022-08-20 01:32:20.793712\n",
      "resetting env. episode 8316, reward total was -18.0. running mean: -16.935517879772384, timestamp: 2022-08-20 01:32:25.947770\n",
      "resetting env. episode 8317, reward total was -18.0. running mean: -16.94616270097466, timestamp: 2022-08-20 01:32:30.789827\n",
      "resetting env. episode 8318, reward total was -21.0. running mean: -16.986701073964916, timestamp: 2022-08-20 01:32:35.462878\n",
      "resetting env. episode 8319, reward total was -21.0. running mean: -17.026834063225266, timestamp: 2022-08-20 01:32:40.354934\n",
      "resetting env. episode 8320, reward total was -20.0. running mean: -17.056565722593014, timestamp: 2022-08-20 01:32:46.087000\n",
      "resetting env. episode 8321, reward total was -13.0. running mean: -17.016000065367084, timestamp: 2022-08-20 01:32:52.209594\n",
      "resetting env. episode 8322, reward total was -15.0. running mean: -16.995840064713413, timestamp: 2022-08-20 01:32:56.975171\n",
      "resetting env. episode 8323, reward total was -19.0. running mean: -17.01588166406628, timestamp: 2022-08-20 01:33:01.064220\n",
      "resetting env. episode 8324, reward total was -19.0. running mean: -17.03572284742562, timestamp: 2022-08-20 01:33:05.667268\n",
      "resetting env. episode 8325, reward total was -18.0. running mean: -17.045365618951365, timestamp: 2022-08-20 01:33:11.757338\n",
      "resetting env. episode 8326, reward total was -15.0. running mean: -17.02491196276185, timestamp: 2022-08-20 01:33:17.236925\n",
      "resetting env. episode 8327, reward total was -17.0. running mean: -17.02466284313423, timestamp: 2022-08-20 01:33:22.841516\n",
      "resetting env. episode 8328, reward total was -18.0. running mean: -17.034416214702887, timestamp: 2022-08-20 01:33:27.945572\n",
      "resetting env. episode 8329, reward total was -18.0. running mean: -17.044072052555858, timestamp: 2022-08-20 01:33:34.285166\n",
      "resetting env. episode 8330, reward total was -19.0. running mean: -17.0636313320303, timestamp: 2022-08-20 01:33:38.194734\n",
      "resetting env. episode 8331, reward total was -18.0. running mean: -17.072995018709996, timestamp: 2022-08-20 01:33:42.760791\n",
      "resetting env. episode 8332, reward total was -15.0. running mean: -17.052265068522896, timestamp: 2022-08-20 01:33:48.269848\n",
      "resetting env. episode 8333, reward total was -17.0. running mean: -17.05174241783767, timestamp: 2022-08-20 01:33:54.207919\n",
      "resetting env. episode 8334, reward total was -13.0. running mean: -17.01122499365929, timestamp: 2022-08-20 01:33:59.906985\n",
      "resetting env. episode 8335, reward total was -19.0. running mean: -17.031112743722698, timestamp: 2022-08-20 01:34:04.971565\n",
      "resetting env. episode 8336, reward total was -14.0. running mean: -17.00080161628547, timestamp: 2022-08-20 01:34:10.360629\n",
      "resetting env. episode 8337, reward total was -11.0. running mean: -16.940793600122618, timestamp: 2022-08-20 01:34:17.084222\n",
      "resetting env. episode 8338, reward total was -18.0. running mean: -16.951385664121393, timestamp: 2022-08-20 01:34:22.073277\n",
      "resetting env. episode 8339, reward total was -20.0. running mean: -16.98187180748018, timestamp: 2022-08-20 01:34:26.655330\n",
      "resetting env. episode 8340, reward total was -16.0. running mean: -16.972053089405378, timestamp: 2022-08-20 01:34:32.796441\n",
      "resetting env. episode 8341, reward total was -18.0. running mean: -16.982332558511324, timestamp: 2022-08-20 01:34:37.231493\n",
      "resetting env. episode 8342, reward total was -15.0. running mean: -16.96250923292621, timestamp: 2022-08-20 01:34:42.935080\n",
      "resetting env. episode 8343, reward total was -19.0. running mean: -16.982884140596948, timestamp: 2022-08-20 01:34:48.057137\n",
      "resetting env. episode 8344, reward total was -20.0. running mean: -17.013055299190977, timestamp: 2022-08-20 01:34:52.507191\n",
      "resetting env. episode 8345, reward total was -17.0. running mean: -17.01292474619907, timestamp: 2022-08-20 01:34:57.050244\n",
      "resetting env. episode 8346, reward total was -13.0. running mean: -16.972795498737078, timestamp: 2022-08-20 01:35:03.352314\n",
      "resetting env. episode 8347, reward total was -18.0. running mean: -16.983067543749705, timestamp: 2022-08-20 01:35:08.463372\n",
      "resetting env. episode 8348, reward total was -17.0. running mean: -16.983236868312208, timestamp: 2022-08-20 01:35:13.690429\n",
      "resetting env. episode 8349, reward total was -16.0. running mean: -16.973404499629087, timestamp: 2022-08-20 01:35:18.708535\n",
      "resetting env. episode 8350, reward total was -19.0. running mean: -16.9936704546328, timestamp: 2022-08-20 01:35:23.587589\n",
      "resetting env. episode 8351, reward total was -18.0. running mean: -17.00373375008647, timestamp: 2022-08-20 01:35:28.379166\n",
      "resetting env. episode 8352, reward total was -19.0. running mean: -17.023696412585608, timestamp: 2022-08-20 01:35:33.254226\n",
      "resetting env. episode 8353, reward total was -19.0. running mean: -17.043459448459753, timestamp: 2022-08-20 01:35:37.365268\n",
      "resetting env. episode 8354, reward total was -19.0. running mean: -17.063024853975158, timestamp: 2022-08-20 01:35:42.293330\n",
      "resetting env. episode 8355, reward total was -19.0. running mean: -17.082394605435407, timestamp: 2022-08-20 01:35:46.812378\n",
      "resetting env. episode 8356, reward total was -17.0. running mean: -17.081570659381054, timestamp: 2022-08-20 01:35:53.409977\n",
      "resetting env. episode 8357, reward total was -15.0. running mean: -17.060754952787242, timestamp: 2022-08-20 01:35:58.171031\n",
      "resetting env. episode 8358, reward total was -17.0. running mean: -17.06014740325937, timestamp: 2022-08-20 01:36:02.579607\n",
      "resetting env. episode 8359, reward total was -17.0. running mean: -17.05954592922678, timestamp: 2022-08-20 01:36:06.416663\n",
      "resetting env. episode 8360, reward total was -14.0. running mean: -17.02895046993451, timestamp: 2022-08-20 01:36:12.595723\n",
      "resetting env. episode 8361, reward total was -11.0. running mean: -16.968660965235166, timestamp: 2022-08-20 01:36:17.587780\n",
      "resetting env. episode 8362, reward total was -18.0. running mean: -16.978974355582814, timestamp: 2022-08-20 01:36:22.311832\n",
      "resetting env. episode 8363, reward total was -17.0. running mean: -16.979184612026987, timestamp: 2022-08-20 01:36:27.496890\n",
      "resetting env. episode 8364, reward total was -15.0. running mean: -16.959392765906717, timestamp: 2022-08-20 01:36:32.128944\n",
      "resetting env. episode 8365, reward total was -15.0. running mean: -16.939798838247647, timestamp: 2022-08-20 01:36:36.953001\n",
      "resetting env. episode 8366, reward total was -20.0. running mean: -16.970400849865168, timestamp: 2022-08-20 01:36:41.114047\n",
      "resetting env. episode 8367, reward total was -18.0. running mean: -16.980696841366516, timestamp: 2022-08-20 01:36:46.197104\n",
      "resetting env. episode 8368, reward total was -17.0. running mean: -16.98088987295285, timestamp: 2022-08-20 01:36:51.016158\n",
      "resetting env. episode 8369, reward total was -17.0. running mean: -16.981080974223325, timestamp: 2022-08-20 01:36:56.048220\n",
      "resetting env. episode 8370, reward total was -19.0. running mean: -17.00127016448109, timestamp: 2022-08-20 01:37:00.881270\n",
      "resetting env. episode 8371, reward total was -13.0. running mean: -16.96125746283628, timestamp: 2022-08-20 01:37:06.281335\n",
      "resetting env. episode 8372, reward total was -17.0. running mean: -16.961644888207918, timestamp: 2022-08-20 01:37:11.423918\n",
      "resetting env. episode 8373, reward total was -16.0. running mean: -16.95202843932584, timestamp: 2022-08-20 01:37:15.520968\n",
      "resetting env. episode 8374, reward total was -12.0. running mean: -16.902508154932583, timestamp: 2022-08-20 01:37:21.539034\n",
      "resetting env. episode 8375, reward total was -19.0. running mean: -16.92348307338326, timestamp: 2022-08-20 01:37:26.727093\n",
      "resetting env. episode 8376, reward total was -18.0. running mean: -16.934248242649428, timestamp: 2022-08-20 01:37:31.463151\n",
      "resetting env. episode 8377, reward total was -14.0. running mean: -16.904905760222935, timestamp: 2022-08-20 01:37:35.760195\n",
      "resetting env. episode 8378, reward total was -17.0. running mean: -16.905856702620706, timestamp: 2022-08-20 01:37:40.226246\n",
      "resetting env. episode 8379, reward total was -13.0. running mean: -16.866798135594497, timestamp: 2022-08-20 01:37:46.178315\n",
      "resetting env. episode 8380, reward total was -21.0. running mean: -16.908130154238552, timestamp: 2022-08-20 01:37:49.887356\n",
      "resetting env. episode 8381, reward total was -17.0. running mean: -16.90904885269617, timestamp: 2022-08-20 01:37:55.826423\n",
      "resetting env. episode 8382, reward total was -17.0. running mean: -16.90995836416921, timestamp: 2022-08-20 01:38:00.976481\n",
      "resetting env. episode 8383, reward total was -13.0. running mean: -16.870858780527517, timestamp: 2022-08-20 01:38:06.528545\n",
      "resetting env. episode 8384, reward total was -19.0. running mean: -16.89215019272224, timestamp: 2022-08-20 01:38:10.215586\n",
      "resetting env. episode 8385, reward total was -17.0. running mean: -16.89322869079502, timestamp: 2022-08-20 01:38:15.667649\n",
      "resetting env. episode 8386, reward total was -12.0. running mean: -16.84429640388707, timestamp: 2022-08-20 01:38:21.990722\n",
      "resetting env. episode 8387, reward total was -16.0. running mean: -16.8358534398482, timestamp: 2022-08-20 01:38:26.132765\n",
      "resetting env. episode 8388, reward total was -18.0. running mean: -16.847494905449718, timestamp: 2022-08-20 01:38:32.124834\n",
      "resetting env. episode 8389, reward total was -19.0. running mean: -16.86901995639522, timestamp: 2022-08-20 01:38:37.100889\n",
      "resetting env. episode 8390, reward total was -19.0. running mean: -16.89032975683127, timestamp: 2022-08-20 01:38:42.798954\n",
      "resetting env. episode 8391, reward total was -19.0. running mean: -16.91142645926296, timestamp: 2022-08-20 01:38:47.636010\n",
      "resetting env. episode 8392, reward total was -6.0. running mean: -16.80231219467033, timestamp: 2022-08-20 01:38:56.188106\n",
      "resetting env. episode 8393, reward total was -18.0. running mean: -16.814289072723625, timestamp: 2022-08-20 01:39:00.814160\n",
      "resetting env. episode 8394, reward total was -18.0. running mean: -16.82614618199639, timestamp: 2022-08-20 01:39:05.047205\n",
      "resetting env. episode 8395, reward total was -9.0. running mean: -16.747884720176426, timestamp: 2022-08-20 01:39:10.627271\n",
      "resetting env. episode 8396, reward total was -17.0. running mean: -16.750405872974664, timestamp: 2022-08-20 01:39:15.953858\n",
      "resetting env. episode 8397, reward total was -17.0. running mean: -16.752901814244918, timestamp: 2022-08-20 01:39:20.161423\n",
      "resetting env. episode 8398, reward total was -18.0. running mean: -16.76537279610247, timestamp: 2022-08-20 01:39:23.872510\n",
      "resetting env. episode 8399, reward total was -15.0. running mean: -16.747719068141443, timestamp: 2022-08-20 01:39:28.488563\n",
      "resetting env. episode 8400, reward total was -20.0. running mean: -16.78024187746003, timestamp: 2022-08-20 01:39:32.873611\n",
      "resetting env. episode 8401, reward total was -15.0. running mean: -16.762439458685428, timestamp: 2022-08-20 01:39:38.727678\n",
      "resetting env. episode 8402, reward total was -15.0. running mean: -16.74481506409857, timestamp: 2022-08-20 01:39:45.049756\n",
      "resetting env. episode 8403, reward total was -13.0. running mean: -16.707366913457584, timestamp: 2022-08-20 01:39:51.526823\n",
      "resetting env. episode 8404, reward total was -21.0. running mean: -16.750293244323007, timestamp: 2022-08-20 01:39:56.084877\n",
      "resetting env. episode 8405, reward total was -21.0. running mean: -16.792790311879777, timestamp: 2022-08-20 01:40:00.505928\n",
      "resetting env. episode 8406, reward total was -17.0. running mean: -16.79486240876098, timestamp: 2022-08-20 01:40:05.109979\n",
      "resetting env. episode 8407, reward total was -15.0. running mean: -16.77691378467337, timestamp: 2022-08-20 01:40:10.294034\n",
      "resetting env. episode 8408, reward total was -16.0. running mean: -16.769144646826636, timestamp: 2022-08-20 01:40:15.712096\n",
      "resetting env. episode 8409, reward total was -15.0. running mean: -16.751453200358366, timestamp: 2022-08-20 01:40:20.913156\n",
      "resetting env. episode 8410, reward total was -17.0. running mean: -16.753938668354785, timestamp: 2022-08-20 01:40:25.806213\n",
      "resetting env. episode 8411, reward total was -19.0. running mean: -16.77639928167124, timestamp: 2022-08-20 01:40:29.822255\n",
      "resetting env. episode 8412, reward total was -10.0. running mean: -16.708635288854527, timestamp: 2022-08-20 01:40:36.960337\n",
      "resetting env. episode 8413, reward total was -16.0. running mean: -16.70154893596598, timestamp: 2022-08-20 01:40:41.844390\n",
      "resetting env. episode 8414, reward total was -17.0. running mean: -16.704533446606323, timestamp: 2022-08-20 01:40:46.903449\n",
      "resetting env. episode 8415, reward total was -15.0. running mean: -16.687488112140258, timestamp: 2022-08-20 01:40:51.486501\n",
      "resetting env. episode 8416, reward total was -17.0. running mean: -16.690613231018858, timestamp: 2022-08-20 01:40:57.124562\n",
      "resetting env. episode 8417, reward total was -17.0. running mean: -16.69370709870867, timestamp: 2022-08-20 01:41:01.290614\n",
      "resetting env. episode 8418, reward total was -19.0. running mean: -16.716770027721587, timestamp: 2022-08-20 01:41:05.765661\n",
      "resetting env. episode 8419, reward total was -20.0. running mean: -16.74960232744437, timestamp: 2022-08-20 01:41:10.717720\n",
      "resetting env. episode 8420, reward total was -19.0. running mean: -16.772106304169927, timestamp: 2022-08-20 01:41:16.133777\n",
      "resetting env. episode 8421, reward total was -9.0. running mean: -16.694385241128227, timestamp: 2022-08-20 01:41:22.867854\n",
      "resetting env. episode 8422, reward total was -12.0. running mean: -16.647441388716945, timestamp: 2022-08-20 01:41:28.300915\n",
      "resetting env. episode 8423, reward total was -14.0. running mean: -16.620966974829777, timestamp: 2022-08-20 01:41:34.380983\n",
      "resetting env. episode 8424, reward total was -17.0. running mean: -16.62475730508148, timestamp: 2022-08-20 01:41:39.674047\n",
      "resetting env. episode 8425, reward total was -13.0. running mean: -16.588509732030666, timestamp: 2022-08-20 01:41:44.492099\n",
      "resetting env. episode 8426, reward total was -20.0. running mean: -16.62262463471036, timestamp: 2022-08-20 01:41:48.599144\n",
      "resetting env. episode 8427, reward total was -18.0. running mean: -16.636398388363254, timestamp: 2022-08-20 01:41:53.652197\n",
      "resetting env. episode 8428, reward total was -14.0. running mean: -16.610034404479624, timestamp: 2022-08-20 01:41:58.772256\n",
      "resetting env. episode 8429, reward total was -14.0. running mean: -16.583934060434828, timestamp: 2022-08-20 01:42:03.811315\n",
      "resetting env. episode 8430, reward total was -18.0. running mean: -16.598094719830478, timestamp: 2022-08-20 01:42:10.261385\n",
      "resetting env. episode 8431, reward total was -20.0. running mean: -16.63211377263217, timestamp: 2022-08-20 01:42:14.266434\n",
      "resetting env. episode 8432, reward total was -11.0. running mean: -16.57579263490585, timestamp: 2022-08-20 01:42:21.317512\n",
      "resetting env. episode 8433, reward total was -19.0. running mean: -16.60003470855679, timestamp: 2022-08-20 01:42:26.475573\n",
      "resetting env. episode 8434, reward total was -12.0. running mean: -16.554034361471224, timestamp: 2022-08-20 01:42:32.594636\n",
      "resetting env. episode 8435, reward total was -17.0. running mean: -16.558494017856514, timestamp: 2022-08-20 01:42:37.525693\n",
      "resetting env. episode 8436, reward total was -19.0. running mean: -16.58290907767795, timestamp: 2022-08-20 01:42:42.023739\n",
      "resetting env. episode 8437, reward total was -17.0. running mean: -16.587079986901173, timestamp: 2022-08-20 01:42:47.224321\n",
      "resetting env. episode 8438, reward total was -12.0. running mean: -16.541209187032162, timestamp: 2022-08-20 01:42:53.780393\n",
      "resetting env. episode 8439, reward total was -13.0. running mean: -16.50579709516184, timestamp: 2022-08-20 01:42:59.576460\n",
      "resetting env. episode 8440, reward total was -17.0. running mean: -16.51073912421022, timestamp: 2022-08-20 01:43:04.559512\n",
      "resetting env. episode 8441, reward total was -16.0. running mean: -16.50563173296812, timestamp: 2022-08-20 01:43:10.875585\n",
      "resetting env. episode 8442, reward total was -17.0. running mean: -16.51057541563844, timestamp: 2022-08-20 01:43:15.650641\n",
      "resetting env. episode 8443, reward total was -19.0. running mean: -16.535469661482054, timestamp: 2022-08-20 01:43:19.709683\n",
      "resetting env. episode 8444, reward total was -14.0. running mean: -16.510114964867235, timestamp: 2022-08-20 01:43:24.920742\n",
      "resetting env. episode 8445, reward total was -14.0. running mean: -16.48501381521856, timestamp: 2022-08-20 01:43:31.208335\n",
      "resetting env. episode 8446, reward total was -16.0. running mean: -16.480163677066376, timestamp: 2022-08-20 01:43:36.921399\n",
      "resetting env. episode 8447, reward total was -17.0. running mean: -16.485362040295712, timestamp: 2022-08-20 01:43:41.742451\n",
      "resetting env. episode 8448, reward total was -17.0. running mean: -16.490508419892755, timestamp: 2022-08-20 01:43:46.250507\n",
      "resetting env. episode 8449, reward total was -17.0. running mean: -16.49560333569383, timestamp: 2022-08-20 01:43:51.874567\n",
      "resetting env. episode 8450, reward total was -16.0. running mean: -16.490647302336892, timestamp: 2022-08-20 01:43:57.702629\n",
      "resetting env. episode 8451, reward total was -15.0. running mean: -16.475740829313523, timestamp: 2022-08-20 01:44:02.385683\n",
      "resetting env. episode 8452, reward total was -15.0. running mean: -16.460983421020387, timestamp: 2022-08-20 01:44:07.782745\n",
      "resetting env. episode 8453, reward total was -15.0. running mean: -16.446373586810182, timestamp: 2022-08-20 01:44:14.055815\n",
      "resetting env. episode 8454, reward total was -19.0. running mean: -16.471909850942083, timestamp: 2022-08-20 01:44:17.998859\n",
      "resetting env. episode 8455, reward total was -19.0. running mean: -16.49719075243266, timestamp: 2022-08-20 01:44:22.963911\n",
      "resetting env. episode 8456, reward total was -17.0. running mean: -16.502218844908338, timestamp: 2022-08-20 01:44:27.660488\n",
      "resetting env. episode 8457, reward total was -18.0. running mean: -16.517196656459255, timestamp: 2022-08-20 01:44:31.415529\n",
      "resetting env. episode 8458, reward total was -17.0. running mean: -16.522024689894664, timestamp: 2022-08-20 01:44:36.873588\n",
      "resetting env. episode 8459, reward total was -19.0. running mean: -16.546804442995718, timestamp: 2022-08-20 01:44:41.220637\n",
      "resetting env. episode 8460, reward total was -14.0. running mean: -16.52133639856576, timestamp: 2022-08-20 01:44:47.082228\n",
      "resetting env. episode 8461, reward total was -19.0. running mean: -16.546123034580106, timestamp: 2022-08-20 01:44:52.161288\n",
      "resetting env. episode 8462, reward total was -16.0. running mean: -16.540661804234304, timestamp: 2022-08-20 01:44:56.955338\n",
      "resetting env. episode 8463, reward total was -12.0. running mean: -16.49525518619196, timestamp: 2022-08-20 01:45:02.706402\n",
      "resetting env. episode 8464, reward total was -15.0. running mean: -16.48030263433004, timestamp: 2022-08-20 01:45:08.581467\n",
      "resetting env. episode 8465, reward total was -13.0. running mean: -16.44549960798674, timestamp: 2022-08-20 01:45:13.619044\n",
      "resetting env. episode 8466, reward total was -19.0. running mean: -16.471044611906873, timestamp: 2022-08-20 01:45:18.599101\n",
      "resetting env. episode 8467, reward total was -17.0. running mean: -16.476334165787804, timestamp: 2022-08-20 01:45:23.437679\n",
      "resetting env. episode 8468, reward total was -18.0. running mean: -16.491570824129926, timestamp: 2022-08-20 01:45:28.811740\n",
      "resetting env. episode 8469, reward total was -21.0. running mean: -16.536655115888628, timestamp: 2022-08-20 01:45:32.499780\n",
      "resetting env. episode 8470, reward total was -19.0. running mean: -16.561288564729743, timestamp: 2022-08-20 01:45:37.457833\n",
      "resetting env. episode 8471, reward total was -14.0. running mean: -16.535675679082445, timestamp: 2022-08-20 01:45:42.432952\n",
      "resetting env. episode 8472, reward total was -16.0. running mean: -16.53031892229162, timestamp: 2022-08-20 01:45:47.243522\n",
      "resetting env. episode 8473, reward total was -11.0. running mean: -16.4750157330687, timestamp: 2022-08-20 01:45:53.984598\n",
      "resetting env. episode 8474, reward total was -14.0. running mean: -16.450265575738015, timestamp: 2022-08-20 01:45:59.589663\n",
      "resetting env. episode 8475, reward total was -15.0. running mean: -16.435762919980633, timestamp: 2022-08-20 01:46:04.333716\n",
      "resetting env. episode 8476, reward total was -10.0. running mean: -16.371405290780828, timestamp: 2022-08-20 01:46:10.896787\n",
      "resetting env. episode 8477, reward total was -17.0. running mean: -16.377691237873023, timestamp: 2022-08-20 01:46:15.813363\n",
      "resetting env. episode 8478, reward total was -14.0. running mean: -16.353914325494294, timestamp: 2022-08-20 01:46:21.725430\n",
      "resetting env. episode 8479, reward total was -20.0. running mean: -16.39037518223935, timestamp: 2022-08-20 01:46:26.545482\n",
      "resetting env. episode 8480, reward total was -19.0. running mean: -16.41647143041696, timestamp: 2022-08-20 01:46:31.772538\n",
      "resetting env. episode 8481, reward total was -16.0. running mean: -16.412306716112788, timestamp: 2022-08-20 01:46:38.148612\n",
      "resetting env. episode 8482, reward total was -16.0. running mean: -16.40818364895166, timestamp: 2022-08-20 01:46:43.590671\n",
      "resetting env. episode 8483, reward total was -17.0. running mean: -16.414101812462146, timestamp: 2022-08-20 01:46:47.837718\n",
      "resetting env. episode 8484, reward total was -12.0. running mean: -16.369960794337526, timestamp: 2022-08-20 01:46:54.966794\n",
      "resetting env. episode 8485, reward total was -17.0. running mean: -16.376261186394153, timestamp: 2022-08-20 01:47:00.876861\n",
      "resetting env. episode 8486, reward total was -20.0. running mean: -16.41249857453021, timestamp: 2022-08-20 01:47:05.484912\n",
      "resetting env. episode 8487, reward total was -17.0. running mean: -16.41837358878491, timestamp: 2022-08-20 01:47:11.163979\n",
      "resetting env. episode 8488, reward total was -19.0. running mean: -16.44418985289706, timestamp: 2022-08-20 01:47:16.277031\n",
      "resetting env. episode 8489, reward total was -20.0. running mean: -16.47974795436809, timestamp: 2022-08-20 01:47:20.745078\n",
      "resetting env. episode 8490, reward total was -18.0. running mean: -16.49495047482441, timestamp: 2022-08-20 01:47:26.381143\n",
      "resetting env. episode 8491, reward total was -12.0. running mean: -16.450000970076168, timestamp: 2022-08-20 01:47:31.415199\n",
      "resetting env. episode 8492, reward total was -13.0. running mean: -16.415500960375404, timestamp: 2022-08-20 01:47:37.731266\n",
      "resetting env. episode 8493, reward total was -19.0. running mean: -16.44134595077165, timestamp: 2022-08-20 01:47:43.152327\n",
      "resetting env. episode 8494, reward total was -14.0. running mean: -16.416932491263935, timestamp: 2022-08-20 01:47:49.709399\n",
      "resetting env. episode 8495, reward total was -20.0. running mean: -16.452763166351296, timestamp: 2022-08-20 01:47:53.294975\n",
      "resetting env. episode 8496, reward total was -17.0. running mean: -16.458235534687784, timestamp: 2022-08-20 01:47:59.021035\n",
      "resetting env. episode 8497, reward total was -15.0. running mean: -16.443653179340906, timestamp: 2022-08-20 01:48:03.924093\n",
      "resetting env. episode 8498, reward total was -17.0. running mean: -16.449216647547498, timestamp: 2022-08-20 01:48:10.097159\n",
      "resetting env. episode 8499, reward total was -9.0. running mean: -16.374724481072022, timestamp: 2022-08-20 01:48:16.430286\n",
      "resetting env. episode 8500, reward total was -15.0. running mean: -16.3609772362613, timestamp: 2022-08-20 01:48:23.188361\n",
      "resetting env. episode 8501, reward total was -20.0. running mean: -16.397367463898686, timestamp: 2022-08-20 01:48:28.987427\n",
      "resetting env. episode 8502, reward total was -15.0. running mean: -16.383393789259696, timestamp: 2022-08-20 01:48:34.851015\n",
      "resetting env. episode 8503, reward total was -11.0. running mean: -16.329559851367097, timestamp: 2022-08-20 01:48:40.540664\n",
      "resetting env. episode 8504, reward total was -18.0. running mean: -16.346264252853427, timestamp: 2022-08-20 01:48:46.045724\n",
      "resetting env. episode 8505, reward total was -16.0. running mean: -16.34280161032489, timestamp: 2022-08-20 01:48:51.215781\n",
      "resetting env. episode 8506, reward total was -21.0. running mean: -16.38937359422164, timestamp: 2022-08-20 01:48:57.237848\n",
      "resetting env. episode 8507, reward total was -18.0. running mean: -16.405479858279424, timestamp: 2022-08-20 01:49:02.797913\n",
      "resetting env. episode 8508, reward total was -18.0. running mean: -16.42142505969663, timestamp: 2022-08-20 01:49:07.612965\n",
      "resetting env. episode 8509, reward total was -15.0. running mean: -16.407210809099663, timestamp: 2022-08-20 01:49:11.996535\n",
      "resetting env. episode 8510, reward total was -19.0. running mean: -16.433138701008666, timestamp: 2022-08-20 01:49:16.242583\n",
      "resetting env. episode 8511, reward total was -15.0. running mean: -16.418807313998578, timestamp: 2022-08-20 01:49:21.928169\n",
      "resetting env. episode 8512, reward total was -17.0. running mean: -16.424619240858593, timestamp: 2022-08-20 01:49:27.843235\n",
      "resetting env. episode 8513, reward total was -18.0. running mean: -16.440373048450006, timestamp: 2022-08-20 01:49:32.568288\n",
      "resetting env. episode 8514, reward total was -21.0. running mean: -16.485969317965505, timestamp: 2022-08-20 01:49:36.693338\n",
      "resetting env. episode 8515, reward total was -12.0. running mean: -16.441109624785852, timestamp: 2022-08-20 01:49:42.395398\n",
      "resetting env. episode 8516, reward total was -16.0. running mean: -16.436698528537995, timestamp: 2022-08-20 01:49:47.995464\n",
      "resetting env. episode 8517, reward total was -13.0. running mean: -16.402331543252615, timestamp: 2022-08-20 01:49:54.148529\n",
      "resetting env. episode 8518, reward total was -16.0. running mean: -16.39830822782009, timestamp: 2022-08-20 01:49:59.170586\n",
      "resetting env. episode 8519, reward total was -21.0. running mean: -16.44432514554189, timestamp: 2022-08-20 01:50:04.744173\n",
      "resetting env. episode 8520, reward total was -15.0. running mean: -16.429881894086467, timestamp: 2022-08-20 01:50:10.052237\n",
      "resetting env. episode 8521, reward total was -17.0. running mean: -16.435583075145605, timestamp: 2022-08-20 01:50:15.709300\n",
      "resetting env. episode 8522, reward total was -20.0. running mean: -16.471227244394147, timestamp: 2022-08-20 01:50:20.958878\n",
      "resetting env. episode 8523, reward total was -17.0. running mean: -16.476514971950206, timestamp: 2022-08-20 01:50:26.976951\n",
      "resetting env. episode 8524, reward total was -19.0. running mean: -16.501749822230703, timestamp: 2022-08-20 01:50:31.986005\n",
      "resetting env. episode 8525, reward total was -16.0. running mean: -16.496732324008395, timestamp: 2022-08-20 01:50:36.623056\n",
      "resetting env. episode 8526, reward total was -18.0. running mean: -16.51176500076831, timestamp: 2022-08-20 01:50:42.421121\n",
      "resetting env. episode 8527, reward total was -16.0. running mean: -16.506647350760627, timestamp: 2022-08-20 01:50:47.774180\n",
      "resetting env. episode 8528, reward total was -15.0. running mean: -16.491580877253018, timestamp: 2022-08-20 01:50:53.637249\n",
      "resetting env. episode 8529, reward total was -15.0. running mean: -16.476665068480486, timestamp: 2022-08-20 01:50:58.708305\n",
      "resetting env. episode 8530, reward total was -19.0. running mean: -16.501898417795683, timestamp: 2022-08-20 01:51:03.087354\n",
      "resetting env. episode 8531, reward total was -16.0. running mean: -16.496879433617725, timestamp: 2022-08-20 01:51:08.153939\n",
      "resetting env. episode 8532, reward total was -18.0. running mean: -16.511910639281545, timestamp: 2022-08-20 01:51:14.165527\n",
      "resetting env. episode 8533, reward total was -21.0. running mean: -16.55679153288873, timestamp: 2022-08-20 01:51:19.504587\n",
      "resetting env. episode 8534, reward total was -14.0. running mean: -16.531223617559846, timestamp: 2022-08-20 01:51:26.093662\n",
      "resetting env. episode 8535, reward total was -19.0. running mean: -16.55591138138425, timestamp: 2022-08-20 01:51:31.316242\n",
      "resetting env. episode 8536, reward total was -18.0. running mean: -16.570352267570406, timestamp: 2022-08-20 01:51:36.656303\n",
      "resetting env. episode 8537, reward total was -16.0. running mean: -16.5646487448947, timestamp: 2022-08-20 01:51:43.475379\n",
      "resetting env. episode 8538, reward total was -15.0. running mean: -16.549002257445753, timestamp: 2022-08-20 01:51:48.622437\n",
      "resetting env. episode 8539, reward total was -20.0. running mean: -16.583512234871296, timestamp: 2022-08-20 01:51:53.573495\n",
      "resetting env. episode 8540, reward total was -18.0. running mean: -16.597677112522582, timestamp: 2022-08-20 01:51:58.019546\n",
      "resetting env. episode 8541, reward total was -17.0. running mean: -16.601700341397358, timestamp: 2022-08-20 01:52:04.193614\n",
      "resetting env. episode 8542, reward total was -19.0. running mean: -16.625683337983386, timestamp: 2022-08-20 01:52:07.753653\n",
      "resetting env. episode 8543, reward total was -12.0. running mean: -16.579426504603553, timestamp: 2022-08-20 01:52:13.872723\n",
      "resetting env. episode 8544, reward total was -14.0. running mean: -16.55363223955752, timestamp: 2022-08-20 01:52:19.514787\n",
      "resetting env. episode 8545, reward total was -16.0. running mean: -16.548095917161945, timestamp: 2022-08-20 01:52:25.421854\n",
      "resetting env. episode 8546, reward total was -19.0. running mean: -16.572614957990325, timestamp: 2022-08-20 01:52:29.976440\n",
      "resetting env. episode 8547, reward total was -16.0. running mean: -16.56688880841042, timestamp: 2022-08-20 01:52:34.557012\n",
      "resetting env. episode 8548, reward total was -18.0. running mean: -16.581219920326316, timestamp: 2022-08-20 01:52:40.401075\n",
      "resetting env. episode 8549, reward total was -17.0. running mean: -16.585407721123055, timestamp: 2022-08-20 01:52:45.386130\n",
      "resetting env. episode 8550, reward total was -17.0. running mean: -16.589553643911824, timestamp: 2022-08-20 01:52:50.583187\n",
      "resetting env. episode 8551, reward total was -18.0. running mean: -16.603658107472704, timestamp: 2022-08-20 01:52:54.568771\n",
      "resetting env. episode 8552, reward total was -20.0. running mean: -16.637621526397975, timestamp: 2022-08-20 01:52:59.115822\n",
      "resetting env. episode 8553, reward total was -17.0. running mean: -16.641245311133996, timestamp: 2022-08-20 01:53:04.780408\n",
      "resetting env. episode 8554, reward total was -13.0. running mean: -16.604832858022654, timestamp: 2022-08-20 01:53:11.691052\n",
      "resetting env. episode 8555, reward total was -19.0. running mean: -16.628784529442427, timestamp: 2022-08-20 01:53:17.518640\n",
      "resetting env. episode 8556, reward total was -18.0. running mean: -16.642496684148004, timestamp: 2022-08-20 01:53:22.463696\n",
      "resetting env. episode 8557, reward total was -19.0. running mean: -16.666071717306526, timestamp: 2022-08-20 01:53:28.482808\n",
      "resetting env. episode 8558, reward total was -15.0. running mean: -16.64941100013346, timestamp: 2022-08-20 01:53:34.379875\n",
      "resetting env. episode 8559, reward total was -17.0. running mean: -16.652916890132126, timestamp: 2022-08-20 01:53:38.803923\n",
      "resetting env. episode 8560, reward total was -15.0. running mean: -16.636387721230804, timestamp: 2022-08-20 01:53:43.492977\n",
      "resetting env. episode 8561, reward total was -16.0. running mean: -16.630023844018496, timestamp: 2022-08-20 01:53:49.363568\n",
      "resetting env. episode 8562, reward total was -16.0. running mean: -16.62372360557831, timestamp: 2022-08-20 01:53:54.364627\n",
      "resetting env. episode 8563, reward total was -15.0. running mean: -16.607486369522526, timestamp: 2022-08-20 01:54:00.133690\n",
      "resetting env. episode 8564, reward total was -19.0. running mean: -16.6314115058273, timestamp: 2022-08-20 01:54:05.123744\n",
      "resetting env. episode 8565, reward total was -19.0. running mean: -16.65509739076903, timestamp: 2022-08-20 01:54:09.465795\n",
      "resetting env. episode 8566, reward total was -20.0. running mean: -16.68854641686134, timestamp: 2022-08-20 01:54:13.997849\n",
      "resetting env. episode 8567, reward total was -19.0. running mean: -16.711660952692725, timestamp: 2022-08-20 01:54:18.826904\n",
      "resetting env. episode 8568, reward total was -18.0. running mean: -16.724544343165796, timestamp: 2022-08-20 01:54:23.293955\n",
      "resetting env. episode 8569, reward total was -16.0. running mean: -16.71729889973414, timestamp: 2022-08-20 01:54:28.292008\n",
      "resetting env. episode 8570, reward total was -19.0. running mean: -16.7401259107368, timestamp: 2022-08-20 01:54:32.625056\n",
      "resetting env. episode 8571, reward total was -19.0. running mean: -16.762724651629433, timestamp: 2022-08-20 01:54:36.993630\n",
      "resetting env. episode 8572, reward total was -18.0. running mean: -16.77509740511314, timestamp: 2022-08-20 01:54:42.109688\n",
      "resetting env. episode 8573, reward total was -14.0. running mean: -16.74734643106201, timestamp: 2022-08-20 01:54:47.454270\n",
      "resetting env. episode 8574, reward total was -18.0. running mean: -16.759872966751388, timestamp: 2022-08-20 01:54:52.888331\n",
      "resetting env. episode 8575, reward total was -17.0. running mean: -16.762274237083876, timestamp: 2022-08-20 01:54:58.312393\n",
      "resetting env. episode 8576, reward total was -13.0. running mean: -16.724651494713036, timestamp: 2022-08-20 01:55:04.308462\n",
      "resetting env. episode 8577, reward total was -19.0. running mean: -16.747404979765907, timestamp: 2022-08-20 01:55:09.042516\n",
      "resetting env. episode 8578, reward total was -16.0. running mean: -16.73993092996825, timestamp: 2022-08-20 01:55:13.189562\n",
      "resetting env. episode 8579, reward total was -17.0. running mean: -16.74253162066857, timestamp: 2022-08-20 01:55:18.281617\n",
      "resetting env. episode 8580, reward total was -12.0. running mean: -16.695106304461884, timestamp: 2022-08-20 01:55:22.669668\n",
      "resetting env. episode 8581, reward total was -15.0. running mean: -16.678155241417265, timestamp: 2022-08-20 01:55:28.199731\n",
      "resetting env. episode 8582, reward total was -19.0. running mean: -16.701373689003095, timestamp: 2022-08-20 01:55:33.295310\n",
      "resetting env. episode 8583, reward total was -19.0. running mean: -16.724359952113065, timestamp: 2022-08-20 01:55:37.640359\n",
      "resetting env. episode 8584, reward total was -17.0. running mean: -16.727116352591935, timestamp: 2022-08-20 01:55:43.184423\n",
      "resetting env. episode 8585, reward total was -19.0. running mean: -16.749845189066015, timestamp: 2022-08-20 01:55:46.996464\n",
      "resetting env. episode 8586, reward total was -17.0. running mean: -16.752346737175355, timestamp: 2022-08-20 01:55:53.009533\n",
      "resetting env. episode 8587, reward total was -19.0. running mean: -16.7748232698036, timestamp: 2022-08-20 01:55:57.476583\n",
      "resetting env. episode 8588, reward total was -21.0. running mean: -16.817075037105568, timestamp: 2022-08-20 01:56:02.845648\n",
      "resetting env. episode 8589, reward total was -13.0. running mean: -16.778904286734512, timestamp: 2022-08-20 01:56:08.414708\n",
      "resetting env. episode 8590, reward total was -19.0. running mean: -16.80111524386717, timestamp: 2022-08-20 01:56:12.789756\n",
      "resetting env. episode 8591, reward total was -16.0. running mean: -16.793104091428496, timestamp: 2022-08-20 01:56:18.270820\n",
      "resetting env. episode 8592, reward total was -14.0. running mean: -16.76517305051421, timestamp: 2022-08-20 01:56:23.357877\n",
      "resetting env. episode 8593, reward total was -15.0. running mean: -16.747521320009067, timestamp: 2022-08-20 01:56:28.597934\n",
      "resetting env. episode 8594, reward total was -17.0. running mean: -16.750046106808977, timestamp: 2022-08-20 01:56:34.501001\n",
      "resetting env. episode 8595, reward total was -21.0. running mean: -16.792545645740887, timestamp: 2022-08-20 01:56:38.082043\n",
      "resetting env. episode 8596, reward total was -11.0. running mean: -16.73462018928348, timestamp: 2022-08-20 01:56:44.595117\n",
      "resetting env. episode 8597, reward total was -14.0. running mean: -16.707273987390646, timestamp: 2022-08-20 01:56:50.035179\n",
      "resetting env. episode 8598, reward total was -18.0. running mean: -16.72020124751674, timestamp: 2022-08-20 01:56:54.225225\n",
      "resetting env. episode 8599, reward total was -18.0. running mean: -16.73299923504157, timestamp: 2022-08-20 01:56:58.724804\n",
      "resetting env. episode 8600, reward total was -16.0. running mean: -16.725669242691154, timestamp: 2022-08-20 01:57:03.615373\n",
      "resetting env. episode 8601, reward total was -20.0. running mean: -16.758412550264243, timestamp: 2022-08-20 01:57:08.067425\n",
      "resetting env. episode 8602, reward total was -13.0. running mean: -16.7208284247616, timestamp: 2022-08-20 01:57:14.657500\n",
      "resetting env. episode 8603, reward total was -17.0. running mean: -16.723620140513983, timestamp: 2022-08-20 01:57:19.489556\n",
      "resetting env. episode 8604, reward total was -12.0. running mean: -16.676383939108845, timestamp: 2022-08-20 01:57:25.195618\n",
      "resetting env. episode 8605, reward total was -19.0. running mean: -16.69962009971776, timestamp: 2022-08-20 01:57:30.667204\n",
      "resetting env. episode 8606, reward total was -14.0. running mean: -16.67262389872058, timestamp: 2022-08-20 01:57:36.993277\n",
      "resetting env. episode 8607, reward total was -16.0. running mean: -16.665897659733375, timestamp: 2022-08-20 01:57:42.118856\n",
      "resetting env. episode 8608, reward total was -19.0. running mean: -16.689238683136043, timestamp: 2022-08-20 01:57:47.872921\n",
      "resetting env. episode 8609, reward total was -20.0. running mean: -16.722346296304682, timestamp: 2022-08-20 01:57:52.962503\n",
      "resetting env. episode 8610, reward total was -17.0. running mean: -16.725122833341636, timestamp: 2022-08-20 01:57:57.416071\n",
      "resetting env. episode 8611, reward total was -17.0. running mean: -16.72787160500822, timestamp: 2022-08-20 01:58:03.204136\n",
      "resetting env. episode 8612, reward total was -16.0. running mean: -16.72059288895814, timestamp: 2022-08-20 01:58:08.029192\n",
      "resetting env. episode 8613, reward total was -19.0. running mean: -16.74338696006856, timestamp: 2022-08-20 01:58:12.311240\n",
      "resetting env. episode 8614, reward total was -15.0. running mean: -16.725953090467872, timestamp: 2022-08-20 01:58:17.733299\n",
      "resetting env. episode 8615, reward total was -17.0. running mean: -16.728693559563194, timestamp: 2022-08-20 01:58:22.037350\n",
      "resetting env. episode 8616, reward total was -19.0. running mean: -16.75140662396756, timestamp: 2022-08-20 01:58:26.116395\n",
      "resetting env. episode 8617, reward total was -18.0. running mean: -16.763892557727885, timestamp: 2022-08-20 01:58:31.640457\n",
      "resetting env. episode 8618, reward total was -15.0. running mean: -16.746253632150605, timestamp: 2022-08-20 01:58:37.638048\n",
      "resetting env. episode 8619, reward total was -17.0. running mean: -16.7487910958291, timestamp: 2022-08-20 01:58:42.337104\n",
      "resetting env. episode 8620, reward total was -15.0. running mean: -16.73130318487081, timestamp: 2022-08-20 01:58:46.702153\n",
      "resetting env. episode 8621, reward total was -15.0. running mean: -16.713990153022102, timestamp: 2022-08-20 01:58:50.835195\n",
      "resetting env. episode 8622, reward total was -18.0. running mean: -16.726850251491882, timestamp: 2022-08-20 01:58:56.290258\n",
      "resetting env. episode 8623, reward total was -19.0. running mean: -16.749581748976965, timestamp: 2022-08-20 01:59:02.156320\n",
      "resetting env. episode 8624, reward total was -15.0. running mean: -16.732085931487195, timestamp: 2022-08-20 01:59:07.436380\n",
      "resetting env. episode 8625, reward total was -15.0. running mean: -16.71476507217232, timestamp: 2022-08-20 01:59:12.624438\n",
      "resetting env. episode 8626, reward total was -19.0. running mean: -16.737617421450597, timestamp: 2022-08-20 01:59:18.114501\n",
      "resetting env. episode 8627, reward total was -17.0. running mean: -16.740241247236092, timestamp: 2022-08-20 01:59:23.929566\n",
      "resetting env. episode 8628, reward total was -19.0. running mean: -16.762838834763734, timestamp: 2022-08-20 01:59:28.711140\n",
      "resetting env. episode 8629, reward total was -17.0. running mean: -16.7652104464161, timestamp: 2022-08-20 01:59:33.563193\n",
      "resetting env. episode 8630, reward total was -17.0. running mean: -16.76755834195194, timestamp: 2022-08-20 01:59:40.883279\n",
      "resetting env. episode 8631, reward total was -17.0. running mean: -16.76988275853242, timestamp: 2022-08-20 01:59:46.877869\n",
      "resetting env. episode 8632, reward total was -19.0. running mean: -16.7921839309471, timestamp: 2022-08-20 01:59:51.838924\n",
      "resetting env. episode 8633, reward total was -16.0. running mean: -16.78426209163763, timestamp: 2022-08-20 01:59:56.271977\n",
      "resetting env. episode 8634, reward total was -13.0. running mean: -16.74641947072125, timestamp: 2022-08-20 02:00:02.703050\n",
      "resetting env. episode 8635, reward total was -16.0. running mean: -16.73895527601404, timestamp: 2022-08-20 02:00:06.467090\n",
      "resetting env. episode 8636, reward total was -19.0. running mean: -16.7615657232539, timestamp: 2022-08-20 02:00:10.919141\n",
      "resetting env. episode 8637, reward total was -17.0. running mean: -16.763950066021362, timestamp: 2022-08-20 02:00:15.072185\n",
      "resetting env. episode 8638, reward total was -18.0. running mean: -16.776310565361147, timestamp: 2022-08-20 02:00:20.235242\n",
      "resetting env. episode 8639, reward total was -17.0. running mean: -16.778547459707536, timestamp: 2022-08-20 02:00:25.160298\n",
      "resetting env. episode 8640, reward total was -15.0. running mean: -16.76076198511046, timestamp: 2022-08-20 02:00:30.540356\n",
      "resetting env. episode 8641, reward total was -18.0. running mean: -16.773154365259355, timestamp: 2022-08-20 02:00:35.292410\n",
      "resetting env. episode 8642, reward total was -17.0. running mean: -16.775422821606764, timestamp: 2022-08-20 02:00:40.946473\n",
      "resetting env. episode 8643, reward total was -15.0. running mean: -16.757668593390694, timestamp: 2022-08-20 02:00:45.935530\n",
      "resetting env. episode 8644, reward total was -9.0. running mean: -16.680091907456788, timestamp: 2022-08-20 02:00:51.516590\n",
      "resetting env. episode 8645, reward total was -17.0. running mean: -16.683290988382222, timestamp: 2022-08-20 02:00:56.391644\n",
      "resetting env. episode 8646, reward total was -14.0. running mean: -16.6564580784984, timestamp: 2022-08-20 02:01:02.869718\n",
      "resetting env. episode 8647, reward total was -19.0. running mean: -16.679893497713415, timestamp: 2022-08-20 02:01:06.822760\n",
      "resetting env. episode 8648, reward total was -16.0. running mean: -16.67309456273628, timestamp: 2022-08-20 02:01:12.490821\n",
      "resetting env. episode 8649, reward total was -19.0. running mean: -16.69636361710892, timestamp: 2022-08-20 02:01:17.437877\n",
      "resetting env. episode 8650, reward total was -17.0. running mean: -16.69939998093783, timestamp: 2022-08-20 02:01:23.605472\n",
      "resetting env. episode 8651, reward total was -14.0. running mean: -16.672405981128453, timestamp: 2022-08-20 02:01:29.513539\n",
      "resetting env. episode 8652, reward total was -16.0. running mean: -16.66568192131717, timestamp: 2022-08-20 02:01:35.039601\n",
      "resetting env. episode 8653, reward total was -16.0. running mean: -16.659025102103996, timestamp: 2022-08-20 02:01:40.806667\n",
      "resetting env. episode 8654, reward total was -17.0. running mean: -16.662434851082956, timestamp: 2022-08-20 02:01:46.198725\n",
      "resetting env. episode 8655, reward total was -15.0. running mean: -16.645810502572125, timestamp: 2022-08-20 02:01:51.543784\n",
      "resetting env. episode 8656, reward total was -19.0. running mean: -16.669352397546405, timestamp: 2022-08-20 02:01:57.344848\n",
      "resetting env. episode 8657, reward total was -17.0. running mean: -16.672658873570942, timestamp: 2022-08-20 02:02:01.716898\n",
      "resetting env. episode 8658, reward total was -17.0. running mean: -16.675932284835234, timestamp: 2022-08-20 02:02:07.041477\n",
      "resetting env. episode 8659, reward total was -17.0. running mean: -16.679172961986882, timestamp: 2022-08-20 02:02:13.077544\n",
      "resetting env. episode 8660, reward total was -21.0. running mean: -16.722381232367013, timestamp: 2022-08-20 02:02:17.501126\n",
      "resetting env. episode 8661, reward total was -15.0. running mean: -16.705157420043342, timestamp: 2022-08-20 02:02:22.675183\n",
      "resetting env. episode 8662, reward total was -17.0. running mean: -16.708105845842912, timestamp: 2022-08-20 02:02:27.555235\n",
      "resetting env. episode 8663, reward total was -15.0. running mean: -16.69102478738448, timestamp: 2022-08-20 02:02:33.028298\n",
      "resetting env. episode 8664, reward total was -14.0. running mean: -16.66411453951064, timestamp: 2022-08-20 02:02:40.473378\n",
      "resetting env. episode 8665, reward total was -19.0. running mean: -16.687473394115532, timestamp: 2022-08-20 02:02:45.418437\n",
      "resetting env. episode 8666, reward total was -19.0. running mean: -16.710598660174377, timestamp: 2022-08-20 02:02:49.701481\n",
      "resetting env. episode 8667, reward total was -16.0. running mean: -16.703492673572633, timestamp: 2022-08-20 02:02:54.990538\n",
      "resetting env. episode 8668, reward total was -18.0. running mean: -16.716457746836905, timestamp: 2022-08-20 02:03:00.122119\n",
      "resetting env. episode 8669, reward total was -17.0. running mean: -16.719293169368537, timestamp: 2022-08-20 02:03:05.399176\n",
      "resetting env. episode 8670, reward total was -17.0. running mean: -16.722100237674855, timestamp: 2022-08-20 02:03:10.486235\n",
      "resetting env. episode 8671, reward total was -17.0. running mean: -16.724879235298108, timestamp: 2022-08-20 02:03:16.220296\n",
      "resetting env. episode 8672, reward total was -17.0. running mean: -16.727630442945127, timestamp: 2022-08-20 02:03:21.282353\n",
      "resetting env. episode 8673, reward total was -19.0. running mean: -16.75035413851568, timestamp: 2022-08-20 02:03:25.881404\n",
      "resetting env. episode 8674, reward total was -17.0. running mean: -16.752850597130525, timestamp: 2022-08-20 02:03:31.599466\n",
      "resetting env. episode 8675, reward total was -19.0. running mean: -16.77532209115922, timestamp: 2022-08-20 02:03:35.779514\n",
      "resetting env. episode 8676, reward total was -15.0. running mean: -16.757568870247628, timestamp: 2022-08-20 02:03:41.189572\n",
      "resetting env. episode 8677, reward total was -17.0. running mean: -16.759993181545152, timestamp: 2022-08-20 02:03:47.056636\n",
      "resetting env. episode 8678, reward total was -14.0. running mean: -16.7323932497297, timestamp: 2022-08-20 02:03:53.325705\n",
      "resetting env. episode 8679, reward total was -15.0. running mean: -16.715069317232402, timestamp: 2022-08-20 02:03:58.352759\n",
      "resetting env. episode 8680, reward total was -20.0. running mean: -16.747918624060077, timestamp: 2022-08-20 02:04:02.671805\n",
      "resetting env. episode 8681, reward total was -13.0. running mean: -16.710439437819474, timestamp: 2022-08-20 02:04:07.473860\n",
      "resetting env. episode 8682, reward total was -13.0. running mean: -16.673335043441277, timestamp: 2022-08-20 02:04:12.901924\n",
      "resetting env. episode 8683, reward total was -18.0. running mean: -16.686601693006864, timestamp: 2022-08-20 02:04:17.891973\n",
      "resetting env. episode 8684, reward total was -15.0. running mean: -16.669735676076794, timestamp: 2022-08-20 02:04:22.544025\n",
      "resetting env. episode 8685, reward total was -15.0. running mean: -16.653038319316025, timestamp: 2022-08-20 02:04:28.705095\n",
      "resetting env. episode 8686, reward total was -20.0. running mean: -16.686507936122865, timestamp: 2022-08-20 02:04:32.819139\n",
      "resetting env. episode 8687, reward total was -13.0. running mean: -16.649642856761634, timestamp: 2022-08-20 02:04:38.366199\n",
      "resetting env. episode 8688, reward total was -19.0. running mean: -16.67314642819402, timestamp: 2022-08-20 02:04:42.530247\n",
      "resetting env. episode 8689, reward total was -18.0. running mean: -16.68641496391208, timestamp: 2022-08-20 02:04:47.238297\n",
      "resetting env. episode 8690, reward total was -16.0. running mean: -16.679550814272957, timestamp: 2022-08-20 02:04:52.440354\n",
      "resetting env. episode 8691, reward total was -21.0. running mean: -16.722755306130228, timestamp: 2022-08-20 02:04:56.777406\n",
      "resetting env. episode 8692, reward total was -21.0. running mean: -16.765527753068927, timestamp: 2022-08-20 02:05:02.572994\n",
      "resetting env. episode 8693, reward total was -16.0. running mean: -16.75787247553824, timestamp: 2022-08-20 02:05:07.503046\n",
      "resetting env. episode 8694, reward total was -18.0. running mean: -16.770293750782855, timestamp: 2022-08-20 02:05:12.164097\n",
      "resetting env. episode 8695, reward total was -19.0. running mean: -16.792590813275027, timestamp: 2022-08-20 02:05:17.108154\n",
      "resetting env. episode 8696, reward total was -14.0. running mean: -16.764664905142276, timestamp: 2022-08-20 02:05:23.521224\n",
      "resetting env. episode 8697, reward total was -17.0. running mean: -16.767018256090854, timestamp: 2022-08-20 02:05:28.938282\n",
      "resetting env. episode 8698, reward total was -18.0. running mean: -16.779348073529945, timestamp: 2022-08-20 02:05:34.753349\n",
      "resetting env. episode 8699, reward total was -18.0. running mean: -16.791554592794647, timestamp: 2022-08-20 02:05:39.200397\n",
      "resetting env. episode 8700, reward total was -16.0. running mean: -16.7836390468667, timestamp: 2022-08-20 02:05:44.103451\n",
      "resetting env. episode 8701, reward total was -17.0. running mean: -16.785802656398033, timestamp: 2022-08-20 02:05:49.115510\n",
      "resetting env. episode 8702, reward total was -19.0. running mean: -16.807944629834054, timestamp: 2022-08-20 02:05:53.752084\n",
      "resetting env. episode 8703, reward total was -14.0. running mean: -16.779865183535716, timestamp: 2022-08-20 02:06:00.274213\n",
      "resetting env. episode 8704, reward total was -16.0. running mean: -16.772066531700357, timestamp: 2022-08-20 02:06:05.359271\n",
      "resetting env. episode 8705, reward total was -16.0. running mean: -16.764345866383355, timestamp: 2022-08-20 02:06:10.808333\n",
      "resetting env. episode 8706, reward total was -14.0. running mean: -16.736702407719523, timestamp: 2022-08-20 02:06:16.657396\n",
      "resetting env. episode 8707, reward total was -19.0. running mean: -16.75933538364233, timestamp: 2022-08-20 02:06:21.678455\n",
      "resetting env. episode 8708, reward total was -18.0. running mean: -16.771742029805907, timestamp: 2022-08-20 02:06:27.211514\n",
      "resetting env. episode 8709, reward total was -15.0. running mean: -16.754024609507844, timestamp: 2022-08-20 02:06:33.302582\n",
      "resetting env. episode 8710, reward total was -18.0. running mean: -16.766484363412765, timestamp: 2022-08-20 02:06:37.677630\n",
      "resetting env. episode 8711, reward total was -17.0. running mean: -16.76881951977864, timestamp: 2022-08-20 02:06:43.140692\n",
      "resetting env. episode 8712, reward total was -18.0. running mean: -16.78113132458085, timestamp: 2022-08-20 02:06:47.544744\n",
      "resetting env. episode 8713, reward total was -21.0. running mean: -16.823320011335042, timestamp: 2022-08-20 02:06:51.439784\n",
      "resetting env. episode 8714, reward total was -16.0. running mean: -16.815086811221693, timestamp: 2022-08-20 02:06:56.891369\n",
      "resetting env. episode 8715, reward total was -17.0. running mean: -16.816935943109478, timestamp: 2022-08-20 02:07:01.923425\n",
      "resetting env. episode 8716, reward total was -18.0. running mean: -16.828766583678384, timestamp: 2022-08-20 02:07:07.755492\n",
      "resetting env. episode 8717, reward total was -17.0. running mean: -16.830478917841603, timestamp: 2022-08-20 02:07:12.651546\n",
      "resetting env. episode 8718, reward total was -20.0. running mean: -16.862174128663185, timestamp: 2022-08-20 02:07:17.672604\n",
      "resetting env. episode 8719, reward total was -15.0. running mean: -16.84355238737655, timestamp: 2022-08-20 02:07:22.264181\n",
      "resetting env. episode 8720, reward total was -17.0. running mean: -16.84511686350279, timestamp: 2022-08-20 02:07:27.510239\n",
      "resetting env. episode 8721, reward total was -16.0. running mean: -16.83666569486776, timestamp: 2022-08-20 02:07:32.306295\n",
      "resetting env. episode 8722, reward total was -18.0. running mean: -16.848299037919084, timestamp: 2022-08-20 02:07:37.545874\n",
      "resetting env. episode 8723, reward total was -16.0. running mean: -16.839816047539895, timestamp: 2022-08-20 02:07:42.697976\n",
      "resetting env. episode 8724, reward total was -13.0. running mean: -16.801417887064495, timestamp: 2022-08-20 02:07:48.696042\n",
      "resetting env. episode 8725, reward total was -16.0. running mean: -16.79340370819385, timestamp: 2022-08-20 02:07:55.073114\n",
      "resetting env. episode 8726, reward total was -19.0. running mean: -16.815469671111913, timestamp: 2022-08-20 02:07:59.515168\n",
      "resetting env. episode 8727, reward total was -17.0. running mean: -16.817314974400794, timestamp: 2022-08-20 02:08:03.509208\n",
      "resetting env. episode 8728, reward total was -16.0. running mean: -16.809141824656788, timestamp: 2022-08-20 02:08:09.860280\n",
      "resetting env. episode 8729, reward total was -16.0. running mean: -16.80105040641022, timestamp: 2022-08-20 02:08:15.259389\n",
      "resetting env. episode 8730, reward total was -17.0. running mean: -16.803039902346118, timestamp: 2022-08-20 02:08:20.204443\n",
      "resetting env. episode 8731, reward total was -12.0. running mean: -16.755009503322658, timestamp: 2022-08-20 02:08:26.892519\n",
      "resetting env. episode 8732, reward total was -19.0. running mean: -16.77745940828943, timestamp: 2022-08-20 02:08:32.528582\n",
      "resetting env. episode 8733, reward total was -14.0. running mean: -16.74968481420654, timestamp: 2022-08-20 02:08:39.365660\n",
      "resetting env. episode 8734, reward total was -18.0. running mean: -16.762187966064474, timestamp: 2022-08-20 02:08:44.285713\n",
      "resetting env. episode 8735, reward total was -16.0. running mean: -16.75456608640383, timestamp: 2022-08-20 02:08:50.372782\n",
      "resetting env. episode 8736, reward total was -19.0. running mean: -16.777020425539792, timestamp: 2022-08-20 02:08:55.041834\n",
      "resetting env. episode 8737, reward total was -19.0. running mean: -16.799250221284396, timestamp: 2022-08-20 02:08:59.851890\n",
      "resetting env. episode 8738, reward total was -19.0. running mean: -16.821257719071554, timestamp: 2022-08-20 02:09:05.490960\n",
      "resetting env. episode 8739, reward total was -16.0. running mean: -16.81304514188084, timestamp: 2022-08-20 02:09:10.263005\n",
      "resetting env. episode 8740, reward total was -20.0. running mean: -16.84491469046203, timestamp: 2022-08-20 02:09:15.388064\n",
      "resetting env. episode 8741, reward total was -17.0. running mean: -16.84646554355741, timestamp: 2022-08-20 02:09:21.415134\n",
      "resetting env. episode 8742, reward total was -12.0. running mean: -16.798000888121837, timestamp: 2022-08-20 02:09:27.909210\n",
      "resetting env. episode 8743, reward total was -15.0. running mean: -16.780020879240617, timestamp: 2022-08-20 02:09:33.295266\n",
      "resetting env. episode 8744, reward total was -17.0. running mean: -16.78222067044821, timestamp: 2022-08-20 02:09:38.307321\n",
      "resetting env. episode 8745, reward total was -19.0. running mean: -16.80439846374373, timestamp: 2022-08-20 02:09:42.778376\n",
      "resetting env. episode 8746, reward total was -19.0. running mean: -16.826354479106293, timestamp: 2022-08-20 02:09:48.512976\n",
      "resetting env. episode 8747, reward total was -17.0. running mean: -16.82809093431523, timestamp: 2022-08-20 02:09:53.605035\n",
      "resetting env. episode 8748, reward total was -21.0. running mean: -16.86981002497208, timestamp: 2022-08-20 02:09:58.611091\n",
      "resetting env. episode 8749, reward total was -18.0. running mean: -16.881111924722358, timestamp: 2022-08-20 02:10:03.786151\n",
      "resetting env. episode 8750, reward total was -15.0. running mean: -16.862300805475133, timestamp: 2022-08-20 02:10:09.764742\n",
      "resetting env. episode 8751, reward total was -17.0. running mean: -16.863677797420383, timestamp: 2022-08-20 02:10:15.526809\n",
      "resetting env. episode 8752, reward total was -17.0. running mean: -16.86504101944618, timestamp: 2022-08-20 02:10:20.408867\n",
      "resetting env. episode 8753, reward total was -15.0. running mean: -16.846390609251717, timestamp: 2022-08-20 02:10:26.309929\n",
      "resetting env. episode 8754, reward total was -17.0. running mean: -16.847926703159203, timestamp: 2022-08-20 02:10:32.006994\n",
      "resetting env. episode 8755, reward total was -21.0. running mean: -16.88944743612761, timestamp: 2022-08-20 02:10:37.010054\n",
      "resetting env. episode 8756, reward total was -15.0. running mean: -16.870552961766332, timestamp: 2022-08-20 02:10:43.164124\n",
      "resetting env. episode 8757, reward total was -17.0. running mean: -16.87184743214867, timestamp: 2022-08-20 02:10:48.734185\n",
      "resetting env. episode 8758, reward total was -17.0. running mean: -16.873128957827184, timestamp: 2022-08-20 02:10:54.114244\n",
      "resetting env. episode 8759, reward total was -12.0. running mean: -16.824397668248913, timestamp: 2022-08-20 02:11:00.366317\n",
      "resetting env. episode 8760, reward total was -18.0. running mean: -16.836153691566423, timestamp: 2022-08-20 02:11:05.163368\n",
      "resetting env. episode 8761, reward total was -18.0. running mean: -16.847792154650758, timestamp: 2022-08-20 02:11:08.960412\n",
      "resetting env. episode 8762, reward total was -13.0. running mean: -16.80931423310425, timestamp: 2022-08-20 02:11:14.839000\n",
      "resetting env. episode 8763, reward total was -20.0. running mean: -16.841221090773207, timestamp: 2022-08-20 02:11:19.064044\n",
      "resetting env. episode 8764, reward total was -19.0. running mean: -16.862808879865476, timestamp: 2022-08-20 02:11:23.029097\n",
      "resetting env. episode 8765, reward total was -18.0. running mean: -16.87418079106682, timestamp: 2022-08-20 02:11:28.593153\n",
      "resetting env. episode 8766, reward total was -17.0. running mean: -16.875438983156155, timestamp: 2022-08-20 02:11:34.754221\n",
      "resetting env. episode 8767, reward total was -17.0. running mean: -16.876684593324594, timestamp: 2022-08-20 02:11:41.473297\n",
      "resetting env. episode 8768, reward total was -12.0. running mean: -16.82791774739135, timestamp: 2022-08-20 02:11:48.505376\n",
      "resetting env. episode 8769, reward total was -14.0. running mean: -16.799638569917438, timestamp: 2022-08-20 02:11:53.704437\n",
      "resetting env. episode 8770, reward total was -17.0. running mean: -16.801642184218263, timestamp: 2022-08-20 02:11:58.581486\n",
      "resetting env. episode 8771, reward total was -21.0. running mean: -16.84362576237608, timestamp: 2022-08-20 02:12:03.492066\n",
      "resetting env. episode 8772, reward total was -17.0. running mean: -16.845189504752323, timestamp: 2022-08-20 02:12:09.775134\n",
      "resetting env. episode 8773, reward total was -19.0. running mean: -16.8667376097048, timestamp: 2022-08-20 02:12:15.088196\n",
      "resetting env. episode 8774, reward total was -19.0. running mean: -16.888070233607753, timestamp: 2022-08-20 02:12:20.471253\n",
      "resetting env. episode 8775, reward total was -17.0. running mean: -16.889189531271676, timestamp: 2022-08-20 02:12:25.818318\n",
      "resetting env. episode 8776, reward total was -18.0. running mean: -16.900297635958957, timestamp: 2022-08-20 02:12:30.186365\n",
      "resetting env. episode 8777, reward total was -19.0. running mean: -16.92129465959937, timestamp: 2022-08-20 02:12:34.785415\n",
      "resetting env. episode 8778, reward total was -15.0. running mean: -16.902081713003373, timestamp: 2022-08-20 02:12:40.001473\n",
      "resetting env. episode 8779, reward total was -19.0. running mean: -16.92306089587334, timestamp: 2022-08-20 02:12:45.015531\n",
      "resetting env. episode 8780, reward total was -15.0. running mean: -16.903830286914605, timestamp: 2022-08-20 02:12:49.752581\n",
      "resetting env. episode 8781, reward total was -19.0. running mean: -16.92479198404546, timestamp: 2022-08-20 02:12:54.575641\n",
      "resetting env. episode 8782, reward total was -19.0. running mean: -16.945544064205006, timestamp: 2022-08-20 02:12:59.720697\n",
      "resetting env. episode 8783, reward total was -9.0. running mean: -16.866088623562955, timestamp: 2022-08-20 02:13:06.251768\n",
      "resetting env. episode 8784, reward total was -18.0. running mean: -16.877427737327327, timestamp: 2022-08-20 02:13:10.595818\n",
      "resetting env. episode 8785, reward total was -14.0. running mean: -16.848653459954054, timestamp: 2022-08-20 02:13:17.628894\n",
      "resetting env. episode 8786, reward total was -12.0. running mean: -16.800166925354514, timestamp: 2022-08-20 02:13:23.934965\n",
      "resetting env. episode 8787, reward total was -19.0. running mean: -16.82216525610097, timestamp: 2022-08-20 02:13:28.631020\n",
      "resetting env. episode 8788, reward total was -15.0. running mean: -16.80394360353996, timestamp: 2022-08-20 02:13:35.340093\n",
      "resetting env. episode 8789, reward total was -15.0. running mean: -16.785904167504558, timestamp: 2022-08-20 02:13:39.701142\n",
      "resetting env. episode 8790, reward total was -18.0. running mean: -16.79804512582951, timestamp: 2022-08-20 02:13:45.282206\n",
      "resetting env. episode 8791, reward total was -17.0. running mean: -16.800064674571217, timestamp: 2022-08-20 02:13:51.195806\n",
      "resetting env. episode 8792, reward total was -16.0. running mean: -16.792064027825504, timestamp: 2022-08-20 02:13:55.857855\n",
      "resetting env. episode 8793, reward total was -17.0. running mean: -16.79414338754725, timestamp: 2022-08-20 02:14:01.632918\n",
      "resetting env. episode 8794, reward total was -18.0. running mean: -16.806201953671778, timestamp: 2022-08-20 02:14:06.599491\n",
      "resetting env. episode 8795, reward total was -16.0. running mean: -16.79813993413506, timestamp: 2022-08-20 02:14:12.844563\n",
      "resetting env. episode 8796, reward total was -15.0. running mean: -16.78015853479371, timestamp: 2022-08-20 02:14:18.556682\n",
      "resetting env. episode 8797, reward total was -14.0. running mean: -16.752356949445772, timestamp: 2022-08-20 02:14:23.921740\n",
      "resetting env. episode 8798, reward total was -21.0. running mean: -16.794833379951317, timestamp: 2022-08-20 02:14:29.134805\n",
      "resetting env. episode 8799, reward total was -17.0. running mean: -16.796885046151807, timestamp: 2022-08-20 02:14:33.894852\n",
      "resetting env. episode 8800, reward total was -21.0. running mean: -16.838916195690288, timestamp: 2022-08-20 02:14:38.120421\n",
      "resetting env. episode 8801, reward total was -17.0. running mean: -16.840527033733387, timestamp: 2022-08-20 02:14:44.527496\n",
      "resetting env. episode 8802, reward total was -19.0. running mean: -16.862121763396054, timestamp: 2022-08-20 02:14:50.392559\n",
      "resetting env. episode 8803, reward total was -17.0. running mean: -16.863500545762093, timestamp: 2022-08-20 02:14:55.695620\n",
      "resetting env. episode 8804, reward total was -17.0. running mean: -16.864865540304475, timestamp: 2022-08-20 02:15:00.978685\n",
      "resetting env. episode 8805, reward total was -21.0. running mean: -16.90621688490143, timestamp: 2022-08-20 02:15:06.764267\n",
      "resetting env. episode 8806, reward total was -18.0. running mean: -16.917154716052416, timestamp: 2022-08-20 02:15:11.340842\n",
      "resetting env. episode 8807, reward total was -17.0. running mean: -16.917983168891894, timestamp: 2022-08-20 02:15:16.133895\n",
      "resetting env. episode 8808, reward total was -14.0. running mean: -16.888803337202976, timestamp: 2022-08-20 02:15:21.859959\n",
      "resetting env. episode 8809, reward total was -17.0. running mean: -16.889915303830946, timestamp: 2022-08-20 02:15:26.843011\n",
      "resetting env. episode 8810, reward total was -13.0. running mean: -16.851016150792635, timestamp: 2022-08-20 02:15:32.333073\n",
      "resetting env. episode 8811, reward total was -18.0. running mean: -16.86250598928471, timestamp: 2022-08-20 02:15:37.001123\n",
      "resetting env. episode 8812, reward total was -17.0. running mean: -16.863880929391865, timestamp: 2022-08-20 02:15:41.789178\n",
      "resetting env. episode 8813, reward total was -19.0. running mean: -16.885242120097946, timestamp: 2022-08-20 02:15:45.796223\n",
      "resetting env. episode 8814, reward total was -19.0. running mean: -16.906389698896966, timestamp: 2022-08-20 02:15:51.391284\n",
      "resetting env. episode 8815, reward total was -21.0. running mean: -16.947325801907997, timestamp: 2022-08-20 02:15:55.498329\n",
      "resetting env. episode 8816, reward total was -12.0. running mean: -16.897852543888916, timestamp: 2022-08-20 02:16:02.780935\n",
      "resetting env. episode 8817, reward total was -17.0. running mean: -16.89887401845003, timestamp: 2022-08-20 02:16:07.915991\n",
      "resetting env. episode 8818, reward total was -12.0. running mean: -16.849885278265532, timestamp: 2022-08-20 02:16:14.030059\n",
      "resetting env. episode 8819, reward total was -17.0. running mean: -16.85138642548288, timestamp: 2022-08-20 02:16:20.932138\n",
      "resetting env. episode 8820, reward total was -21.0. running mean: -16.89287256122805, timestamp: 2022-08-20 02:16:24.839179\n",
      "resetting env. episode 8821, reward total was -18.0. running mean: -16.90394383561577, timestamp: 2022-08-20 02:16:30.364769\n",
      "resetting env. episode 8822, reward total was -20.0. running mean: -16.93490439725961, timestamp: 2022-08-20 02:16:35.118819\n",
      "resetting env. episode 8823, reward total was -15.0. running mean: -16.915555353287015, timestamp: 2022-08-20 02:16:41.140894\n",
      "resetting env. episode 8824, reward total was -14.0. running mean: -16.886399799754145, timestamp: 2022-08-20 02:16:47.262954\n",
      "resetting env. episode 8825, reward total was -20.0. running mean: -16.917535801756603, timestamp: 2022-08-20 02:16:52.230012\n",
      "resetting env. episode 8826, reward total was -21.0. running mean: -16.95836044373904, timestamp: 2022-08-20 02:16:56.666057\n",
      "resetting env. episode 8827, reward total was -19.0. running mean: -16.97877683930165, timestamp: 2022-08-20 02:17:01.746643\n",
      "resetting env. episode 8828, reward total was -20.0. running mean: -17.00898907090863, timestamp: 2022-08-20 02:17:08.628717\n",
      "resetting env. episode 8829, reward total was -17.0. running mean: -17.008899180199545, timestamp: 2022-08-20 02:17:13.352770\n",
      "resetting env. episode 8830, reward total was -17.0. running mean: -17.00881018839755, timestamp: 2022-08-20 02:17:19.412836\n",
      "resetting env. episode 8831, reward total was -13.0. running mean: -16.968722086513573, timestamp: 2022-08-20 02:17:25.617908\n",
      "resetting env. episode 8832, reward total was -16.0. running mean: -16.959034865648437, timestamp: 2022-08-20 02:17:30.434480\n",
      "resetting env. episode 8833, reward total was -13.0. running mean: -16.919444516991952, timestamp: 2022-08-20 02:17:36.165545\n",
      "resetting env. episode 8834, reward total was -17.0. running mean: -16.920250071822032, timestamp: 2022-08-20 02:17:42.123610\n",
      "resetting env. episode 8835, reward total was -18.0. running mean: -16.93104757110381, timestamp: 2022-08-20 02:17:47.201667\n",
      "resetting env. episode 8836, reward total was -15.0. running mean: -16.91173709539277, timestamp: 2022-08-20 02:17:52.841251\n",
      "resetting env. episode 8837, reward total was -18.0. running mean: -16.922619724438842, timestamp: 2022-08-20 02:17:58.255312\n",
      "resetting env. episode 8838, reward total was -18.0. running mean: -16.933393527194454, timestamp: 2022-08-20 02:18:03.590369\n",
      "resetting env. episode 8839, reward total was -11.0. running mean: -16.87405959192251, timestamp: 2022-08-20 02:18:09.319432\n",
      "resetting env. episode 8840, reward total was -15.0. running mean: -16.855318996003284, timestamp: 2022-08-20 02:18:14.955492\n",
      "resetting env. episode 8841, reward total was -17.0. running mean: -16.856765806043253, timestamp: 2022-08-20 02:18:21.878570\n",
      "resetting env. episode 8842, reward total was -15.0. running mean: -16.83819814798282, timestamp: 2022-08-20 02:18:27.262628\n",
      "resetting env. episode 8843, reward total was -17.0. running mean: -16.83981616650299, timestamp: 2022-08-20 02:18:33.644699\n",
      "resetting env. episode 8844, reward total was -19.0. running mean: -16.86141800483796, timestamp: 2022-08-20 02:18:38.941759\n",
      "resetting env. episode 8845, reward total was -19.0. running mean: -16.882803824789583, timestamp: 2022-08-20 02:18:44.489819\n",
      "resetting env. episode 8846, reward total was -15.0. running mean: -16.863975786541687, timestamp: 2022-08-20 02:18:49.081395\n",
      "resetting env. episode 8847, reward total was -18.0. running mean: -16.87533602867627, timestamp: 2022-08-20 02:18:52.838436\n",
      "resetting env. episode 8848, reward total was -18.0. running mean: -16.886582668389504, timestamp: 2022-08-20 02:18:57.585488\n",
      "resetting env. episode 8849, reward total was -18.0. running mean: -16.89771684170561, timestamp: 2022-08-20 02:19:02.590544\n",
      "resetting env. episode 8850, reward total was -17.0. running mean: -16.898739673288553, timestamp: 2022-08-20 02:19:08.717612\n",
      "resetting env. episode 8851, reward total was -15.0. running mean: -16.879752276555667, timestamp: 2022-08-20 02:19:15.177685\n",
      "resetting env. episode 8852, reward total was -17.0. running mean: -16.88095475379011, timestamp: 2022-08-20 02:19:21.260750\n",
      "resetting env. episode 8853, reward total was -17.0. running mean: -16.88214520625221, timestamp: 2022-08-20 02:19:25.700800\n",
      "resetting env. episode 8854, reward total was -19.0. running mean: -16.90332375418969, timestamp: 2022-08-20 02:19:30.524850\n",
      "resetting env. episode 8855, reward total was -17.0. running mean: -16.904290516647794, timestamp: 2022-08-20 02:19:35.868910\n",
      "resetting env. episode 8856, reward total was -20.0. running mean: -16.935247611481316, timestamp: 2022-08-20 02:19:40.935970\n",
      "resetting env. episode 8857, reward total was -14.0. running mean: -16.905895135366503, timestamp: 2022-08-20 02:19:46.199025\n",
      "resetting env. episode 8858, reward total was -18.0. running mean: -16.916836184012837, timestamp: 2022-08-20 02:19:50.591075\n",
      "resetting env. episode 8859, reward total was -14.0. running mean: -16.88766782217271, timestamp: 2022-08-20 02:19:55.572135\n",
      "resetting env. episode 8860, reward total was -14.0. running mean: -16.85879114395098, timestamp: 2022-08-20 02:20:01.415191\n",
      "resetting env. episode 8861, reward total was -14.0. running mean: -16.830203232511472, timestamp: 2022-08-20 02:20:07.052253\n",
      "resetting env. episode 8862, reward total was -20.0. running mean: -16.861901200186356, timestamp: 2022-08-20 02:20:13.576324\n",
      "resetting env. episode 8863, reward total was -15.0. running mean: -16.843282188184492, timestamp: 2022-08-20 02:20:19.377391\n",
      "resetting env. episode 8864, reward total was -15.0. running mean: -16.824849366302647, timestamp: 2022-08-20 02:20:25.922463\n",
      "resetting env. episode 8865, reward total was -17.0. running mean: -16.826600872639624, timestamp: 2022-08-20 02:20:30.115509\n",
      "resetting env. episode 8866, reward total was -14.0. running mean: -16.79833486391323, timestamp: 2022-08-20 02:20:35.031081\n",
      "resetting env. episode 8867, reward total was -18.0. running mean: -16.810351515274096, timestamp: 2022-08-20 02:20:41.498680\n",
      "resetting env. episode 8868, reward total was -15.0. running mean: -16.792248000121354, timestamp: 2022-08-20 02:20:47.241744\n",
      "resetting env. episode 8869, reward total was -19.0. running mean: -16.814325520120143, timestamp: 2022-08-20 02:20:53.236338\n",
      "resetting env. episode 8870, reward total was -12.0. running mean: -16.766182264918942, timestamp: 2022-08-20 02:20:59.471934\n",
      "resetting env. episode 8871, reward total was -13.0. running mean: -16.72852044226975, timestamp: 2022-08-20 02:21:06.893014\n",
      "resetting env. episode 8872, reward total was -19.0. running mean: -16.751235237847055, timestamp: 2022-08-20 02:21:10.750057\n",
      "resetting env. episode 8873, reward total was -15.0. running mean: -16.733722885468584, timestamp: 2022-08-20 02:21:17.532653\n",
      "resetting env. episode 8874, reward total was -21.0. running mean: -16.7763856566139, timestamp: 2022-08-20 02:21:21.701699\n",
      "resetting env. episode 8875, reward total was -12.0. running mean: -16.728621800047762, timestamp: 2022-08-20 02:21:29.258780\n",
      "resetting env. episode 8876, reward total was -19.0. running mean: -16.751335582047286, timestamp: 2022-08-20 02:21:33.940833\n",
      "resetting env. episode 8877, reward total was -12.0. running mean: -16.703822226226816, timestamp: 2022-08-20 02:21:40.475902\n",
      "resetting env. episode 8878, reward total was -17.0. running mean: -16.70678400396455, timestamp: 2022-08-20 02:21:45.599483\n",
      "resetting env. episode 8879, reward total was -19.0. running mean: -16.729716163924905, timestamp: 2022-08-20 02:21:50.574538\n",
      "resetting env. episode 8880, reward total was -14.0. running mean: -16.702419002285655, timestamp: 2022-08-20 02:21:56.885610\n",
      "resetting env. episode 8881, reward total was -19.0. running mean: -16.7253948122628, timestamp: 2022-08-20 02:22:02.398671\n",
      "resetting env. episode 8882, reward total was -14.0. running mean: -16.69814086414017, timestamp: 2022-08-20 02:22:08.059731\n",
      "resetting env. episode 8883, reward total was -9.0. running mean: -16.62115945549877, timestamp: 2022-08-20 02:22:14.522802\n",
      "resetting env. episode 8884, reward total was -14.0. running mean: -16.594947860943783, timestamp: 2022-08-20 02:22:20.861873\n",
      "resetting env. episode 8885, reward total was -15.0. running mean: -16.578998382334344, timestamp: 2022-08-20 02:22:26.313932\n",
      "resetting env. episode 8886, reward total was -19.0. running mean: -16.603208398511, timestamp: 2022-08-20 02:22:31.601989\n",
      "resetting env. episode 8887, reward total was -19.0. running mean: -16.62717631452589, timestamp: 2022-08-20 02:22:36.271044\n",
      "resetting env. episode 8888, reward total was -17.0. running mean: -16.63090455138063, timestamp: 2022-08-20 02:22:41.540103\n",
      "resetting env. episode 8889, reward total was -13.0. running mean: -16.594595505866824, timestamp: 2022-08-20 02:22:48.104176\n",
      "resetting env. episode 8890, reward total was -18.0. running mean: -16.608649550808156, timestamp: 2022-08-20 02:22:53.020750\n",
      "resetting env. episode 8891, reward total was -16.0. running mean: -16.602563055300074, timestamp: 2022-08-20 02:23:00.175831\n",
      "resetting env. episode 8892, reward total was -18.0. running mean: -16.616537424747072, timestamp: 2022-08-20 02:23:04.541878\n",
      "resetting env. episode 8893, reward total was -18.0. running mean: -16.630372050499602, timestamp: 2022-08-20 02:23:09.094931\n",
      "resetting env. episode 8894, reward total was -19.0. running mean: -16.654068329994608, timestamp: 2022-08-20 02:23:14.985994\n",
      "resetting env. episode 8895, reward total was -16.0. running mean: -16.647527646694662, timestamp: 2022-08-20 02:23:20.463055\n",
      "resetting env. episode 8896, reward total was -15.0. running mean: -16.631052370227714, timestamp: 2022-08-20 02:23:26.035117\n",
      "resetting env. episode 8897, reward total was -20.0. running mean: -16.664741846525434, timestamp: 2022-08-20 02:23:30.888175\n",
      "resetting env. episode 8898, reward total was -9.0. running mean: -16.58809442806018, timestamp: 2022-08-20 02:23:37.062241\n",
      "resetting env. episode 8899, reward total was -16.0. running mean: -16.58221348377958, timestamp: 2022-08-20 02:23:43.601311\n",
      "resetting env. episode 8900, reward total was -15.0. running mean: -16.56639134894178, timestamp: 2022-08-20 02:23:49.845906\n",
      "resetting env. episode 8901, reward total was -15.0. running mean: -16.550727435452362, timestamp: 2022-08-20 02:23:54.205956\n",
      "resetting env. episode 8902, reward total was -17.0. running mean: -16.55522016109784, timestamp: 2022-08-20 02:24:00.137544\n",
      "resetting env. episode 8903, reward total was -15.0. running mean: -16.53966795948686, timestamp: 2022-08-20 02:24:06.695615\n",
      "resetting env. episode 8904, reward total was -19.0. running mean: -16.56427127989199, timestamp: 2022-08-20 02:24:10.374655\n",
      "resetting env. episode 8905, reward total was -15.0. running mean: -16.54862856709307, timestamp: 2022-08-20 02:24:16.447723\n",
      "resetting env. episode 8906, reward total was -18.0. running mean: -16.563142281422138, timestamp: 2022-08-20 02:24:21.557780\n",
      "resetting env. episode 8907, reward total was -19.0. running mean: -16.587510858607917, timestamp: 2022-08-20 02:24:27.857851\n",
      "resetting env. episode 8908, reward total was -17.0. running mean: -16.59163575002184, timestamp: 2022-08-20 02:24:32.013896\n",
      "resetting env. episode 8909, reward total was -17.0. running mean: -16.595719392521623, timestamp: 2022-08-20 02:24:37.526959\n",
      "resetting env. episode 8910, reward total was -17.0. running mean: -16.59976219859641, timestamp: 2022-08-20 02:24:42.015007\n",
      "resetting env. episode 8911, reward total was -11.0. running mean: -16.543764576610442, timestamp: 2022-08-20 02:24:47.025063\n",
      "resetting env. episode 8912, reward total was -15.0. running mean: -16.528326930844337, timestamp: 2022-08-20 02:24:53.256135\n",
      "resetting env. episode 8913, reward total was -17.0. running mean: -16.533043661535896, timestamp: 2022-08-20 02:24:58.690198\n",
      "resetting env. episode 8914, reward total was -16.0. running mean: -16.527713224920536, timestamp: 2022-08-20 02:25:03.985256\n",
      "resetting env. episode 8915, reward total was -13.0. running mean: -16.49243609267133, timestamp: 2022-08-20 02:25:11.826343\n",
      "resetting env. episode 8916, reward total was -18.0. running mean: -16.507511731744618, timestamp: 2022-08-20 02:25:16.161393\n",
      "resetting env. episode 8917, reward total was -15.0. running mean: -16.49243661442717, timestamp: 2022-08-20 02:25:21.830454\n",
      "resetting env. episode 8918, reward total was -17.0. running mean: -16.4975122482829, timestamp: 2022-08-20 02:25:27.775523\n",
      "resetting env. episode 8919, reward total was -19.0. running mean: -16.52253712580007, timestamp: 2022-08-20 02:25:33.363115\n",
      "resetting env. episode 8920, reward total was -18.0. running mean: -16.53731175454207, timestamp: 2022-08-20 02:25:38.449172\n",
      "resetting env. episode 8921, reward total was -19.0. running mean: -16.56193863699665, timestamp: 2022-08-20 02:25:43.850232\n",
      "resetting env. episode 8922, reward total was -11.0. running mean: -16.50631925062668, timestamp: 2022-08-20 02:25:49.576297\n",
      "resetting env. episode 8923, reward total was -17.0. running mean: -16.511256058120416, timestamp: 2022-08-20 02:25:55.202359\n",
      "resetting env. episode 8924, reward total was -18.0. running mean: -16.526143497539213, timestamp: 2022-08-20 02:26:01.355429\n",
      "resetting env. episode 8925, reward total was -17.0. running mean: -16.530882062563823, timestamp: 2022-08-20 02:26:06.388007\n",
      "resetting env. episode 8926, reward total was -18.0. running mean: -16.545573241938182, timestamp: 2022-08-20 02:26:10.587060\n",
      "resetting env. episode 8927, reward total was -17.0. running mean: -16.550117509518802, timestamp: 2022-08-20 02:26:15.543112\n",
      "resetting env. episode 8928, reward total was -20.0. running mean: -16.584616334423615, timestamp: 2022-08-20 02:26:19.714157\n",
      "resetting env. episode 8929, reward total was -16.0. running mean: -16.578770171079377, timestamp: 2022-08-20 02:26:26.195231\n",
      "resetting env. episode 8930, reward total was -13.0. running mean: -16.54298246936858, timestamp: 2022-08-20 02:26:32.535820\n",
      "resetting env. episode 8931, reward total was -15.0. running mean: -16.527552644674895, timestamp: 2022-08-20 02:26:38.494887\n",
      "resetting env. episode 8932, reward total was -17.0. running mean: -16.532277118228148, timestamp: 2022-08-20 02:26:44.054948\n",
      "resetting env. episode 8933, reward total was -17.0. running mean: -16.536954347045867, timestamp: 2022-08-20 02:26:49.675011\n",
      "resetting env. episode 8934, reward total was -18.0. running mean: -16.55158480357541, timestamp: 2022-08-20 02:26:55.546600\n",
      "resetting env. episode 8935, reward total was -11.0. running mean: -16.496068955539656, timestamp: 2022-08-20 02:27:02.713201\n",
      "resetting env. episode 8936, reward total was -19.0. running mean: -16.52110826598426, timestamp: 2022-08-20 02:27:07.674256\n",
      "resetting env. episode 8937, reward total was -19.0. running mean: -16.545897183324417, timestamp: 2022-08-20 02:27:12.519312\n",
      "resetting env. episode 8938, reward total was -14.0. running mean: -16.52043821149117, timestamp: 2022-08-20 02:27:18.770380\n",
      "resetting env. episode 8939, reward total was -18.0. running mean: -16.53523382937626, timestamp: 2022-08-20 02:27:24.801448\n",
      "resetting env. episode 8940, reward total was -16.0. running mean: -16.5298814910825, timestamp: 2022-08-20 02:27:31.573522\n",
      "resetting env. episode 8941, reward total was -15.0. running mean: -16.51458267617167, timestamp: 2022-08-20 02:27:36.583577\n",
      "resetting env. episode 8942, reward total was -13.0. running mean: -16.479436849409954, timestamp: 2022-08-20 02:27:43.252655\n",
      "resetting env. episode 8943, reward total was -13.0. running mean: -16.444642480915853, timestamp: 2022-08-20 02:27:50.052730\n",
      "resetting env. episode 8944, reward total was -18.0. running mean: -16.460196056106692, timestamp: 2022-08-20 02:27:55.649793\n",
      "resetting env. episode 8945, reward total was -15.0. running mean: -16.445594095545623, timestamp: 2022-08-20 02:28:01.415379\n",
      "resetting env. episode 8946, reward total was -17.0. running mean: -16.45113815459017, timestamp: 2022-08-20 02:28:06.449436\n",
      "resetting env. episode 8947, reward total was -17.0. running mean: -16.456626773044267, timestamp: 2022-08-20 02:28:12.055503\n",
      "resetting env. episode 8948, reward total was -18.0. running mean: -16.472060505313824, timestamp: 2022-08-20 02:28:16.141547\n",
      "resetting env. episode 8949, reward total was -17.0. running mean: -16.477339900260688, timestamp: 2022-08-20 02:28:20.943645\n",
      "resetting env. episode 8950, reward total was -15.0. running mean: -16.46256650125808, timestamp: 2022-08-20 02:28:26.829709\n",
      "resetting env. episode 8951, reward total was -18.0. running mean: -16.4779408362455, timestamp: 2022-08-20 02:28:31.495767\n",
      "resetting env. episode 8952, reward total was -15.0. running mean: -16.463161427883044, timestamp: 2022-08-20 02:28:37.938834\n",
      "resetting env. episode 8953, reward total was -18.0. running mean: -16.47852981360421, timestamp: 2022-08-20 02:28:44.024906\n",
      "resetting env. episode 8954, reward total was -16.0. running mean: -16.47374451546817, timestamp: 2022-08-20 02:28:49.235964\n",
      "resetting env. episode 8955, reward total was -16.0. running mean: -16.469007070313488, timestamp: 2022-08-20 02:28:53.410009\n",
      "resetting env. episode 8956, reward total was -18.0. running mean: -16.484316999610353, timestamp: 2022-08-20 02:28:58.956069\n",
      "resetting env. episode 8957, reward total was -20.0. running mean: -16.51947382961425, timestamp: 2022-08-20 02:29:03.672123\n",
      "resetting env. episode 8958, reward total was -11.0. running mean: -16.464279091318105, timestamp: 2022-08-20 02:29:09.381188\n",
      "resetting env. episode 8959, reward total was -14.0. running mean: -16.439636300404924, timestamp: 2022-08-20 02:29:16.177265\n",
      "resetting env. episode 8960, reward total was -21.0. running mean: -16.485239937400877, timestamp: 2022-08-20 02:29:19.738303\n",
      "resetting env. episode 8961, reward total was -19.0. running mean: -16.51038753802687, timestamp: 2022-08-20 02:29:26.286377\n",
      "resetting env. episode 8962, reward total was -19.0. running mean: -16.535283662646602, timestamp: 2022-08-20 02:29:31.475436\n",
      "resetting env. episode 8963, reward total was -18.0. running mean: -16.549930826020137, timestamp: 2022-08-20 02:29:36.938497\n",
      "resetting env. episode 8964, reward total was -18.0. running mean: -16.564431517759935, timestamp: 2022-08-20 02:29:41.154542\n",
      "resetting env. episode 8965, reward total was -16.0. running mean: -16.558787202582337, timestamp: 2022-08-20 02:29:47.032607\n",
      "resetting env. episode 8966, reward total was -18.0. running mean: -16.573199330556513, timestamp: 2022-08-20 02:29:51.973666\n",
      "resetting env. episode 8967, reward total was -18.0. running mean: -16.587467337250946, timestamp: 2022-08-20 02:29:57.698727\n",
      "resetting env. episode 8968, reward total was -19.0. running mean: -16.611592663878437, timestamp: 2022-08-20 02:30:03.339791\n",
      "resetting env. episode 8969, reward total was -16.0. running mean: -16.605476737239652, timestamp: 2022-08-20 02:30:08.828853\n",
      "resetting env. episode 8970, reward total was -17.0. running mean: -16.609421969867256, timestamp: 2022-08-20 02:30:15.946934\n",
      "resetting env. episode 8971, reward total was -15.0. running mean: -16.593327750168584, timestamp: 2022-08-20 02:30:21.614996\n",
      "resetting env. episode 8972, reward total was -18.0. running mean: -16.607394472666897, timestamp: 2022-08-20 02:30:26.937057\n",
      "resetting env. episode 8973, reward total was -21.0. running mean: -16.65132052794023, timestamp: 2022-08-20 02:30:32.520118\n",
      "resetting env. episode 8974, reward total was -18.0. running mean: -16.664807322660828, timestamp: 2022-08-20 02:30:37.369173\n",
      "resetting env. episode 8975, reward total was -11.0. running mean: -16.60815924943422, timestamp: 2022-08-20 02:30:43.258808\n",
      "resetting env. episode 8976, reward total was -16.0. running mean: -16.602077656939876, timestamp: 2022-08-20 02:30:50.513889\n",
      "resetting env. episode 8977, reward total was -17.0. running mean: -16.606056880370478, timestamp: 2022-08-20 02:30:55.758950\n",
      "resetting env. episode 8978, reward total was -15.0. running mean: -16.58999631156677, timestamp: 2022-08-20 02:31:02.755027\n",
      "resetting env. episode 8979, reward total was -18.0. running mean: -16.604096348451105, timestamp: 2022-08-20 02:31:07.997085\n",
      "resetting env. episode 8980, reward total was -19.0. running mean: -16.628055384966594, timestamp: 2022-08-20 02:31:14.337155\n",
      "resetting env. episode 8981, reward total was -17.0. running mean: -16.63177483111693, timestamp: 2022-08-20 02:31:18.920210\n",
      "resetting env. episode 8982, reward total was -17.0. running mean: -16.63545708280576, timestamp: 2022-08-20 02:31:23.778265\n",
      "resetting env. episode 8983, reward total was -16.0. running mean: -16.629102511977703, timestamp: 2022-08-20 02:31:29.403327\n",
      "resetting env. episode 8984, reward total was -18.0. running mean: -16.642811486857926, timestamp: 2022-08-20 02:31:34.079376\n",
      "resetting env. episode 8985, reward total was -16.0. running mean: -16.636383371989346, timestamp: 2022-08-20 02:31:40.542450\n",
      "resetting env. episode 8986, reward total was -17.0. running mean: -16.640019538269453, timestamp: 2022-08-20 02:31:45.633507\n",
      "resetting env. episode 8987, reward total was -14.0. running mean: -16.613619342886757, timestamp: 2022-08-20 02:31:52.030576\n",
      "resetting env. episode 8988, reward total was -15.0. running mean: -16.597483149457886, timestamp: 2022-08-20 02:31:57.888644\n",
      "resetting env. episode 8989, reward total was -19.0. running mean: -16.621508317963308, timestamp: 2022-08-20 02:32:03.387704\n",
      "resetting env. episode 8990, reward total was -17.0. running mean: -16.625293234783676, timestamp: 2022-08-20 02:32:09.562772\n",
      "resetting env. episode 8991, reward total was -19.0. running mean: -16.64904030243584, timestamp: 2022-08-20 02:32:13.843820\n",
      "resetting env. episode 8992, reward total was -15.0. running mean: -16.63254989941148, timestamp: 2022-08-20 02:32:19.497882\n",
      "resetting env. episode 8993, reward total was -17.0. running mean: -16.636224400417365, timestamp: 2022-08-20 02:32:25.692949\n",
      "resetting env. episode 8994, reward total was -12.0. running mean: -16.589862156413194, timestamp: 2022-08-20 02:32:32.144555\n",
      "resetting env. episode 8995, reward total was -16.0. running mean: -16.58396353484906, timestamp: 2022-08-20 02:32:37.631608\n",
      "resetting env. episode 8996, reward total was -16.0. running mean: -16.57812389950057, timestamp: 2022-08-20 02:32:43.996204\n",
      "resetting env. episode 8997, reward total was -16.0. running mean: -16.572342660505566, timestamp: 2022-08-20 02:32:48.781258\n",
      "resetting env. episode 8998, reward total was -12.0. running mean: -16.52661923390051, timestamp: 2022-08-20 02:32:53.874313\n",
      "resetting env. episode 8999, reward total was -15.0. running mean: -16.511353041561506, timestamp: 2022-08-20 02:32:59.697904\n",
      "resetting env. episode 9000, reward total was -19.0. running mean: -16.536239511145894, timestamp: 2022-08-20 02:33:04.123951\n",
      "resetting env. episode 9001, reward total was -15.0. running mean: -16.520877116034434, timestamp: 2022-08-20 02:33:09.182007\n",
      "resetting env. episode 9002, reward total was -17.0. running mean: -16.52566834487409, timestamp: 2022-08-20 02:33:15.491083\n",
      "resetting env. episode 9003, reward total was -18.0. running mean: -16.54041166142535, timestamp: 2022-08-20 02:33:20.218129\n",
      "resetting env. episode 9004, reward total was -20.0. running mean: -16.575007544811093, timestamp: 2022-08-20 02:33:25.545190\n",
      "resetting env. episode 9005, reward total was -13.0. running mean: -16.53925746936298, timestamp: 2022-08-20 02:33:33.072275\n",
      "resetting env. episode 9006, reward total was -18.0. running mean: -16.55386489466935, timestamp: 2022-08-20 02:33:39.637348\n",
      "resetting env. episode 9007, reward total was -15.0. running mean: -16.538326245722654, timestamp: 2022-08-20 02:33:47.291481\n",
      "resetting env. episode 9008, reward total was -16.0. running mean: -16.53294298326543, timestamp: 2022-08-20 02:33:53.911552\n",
      "resetting env. episode 9009, reward total was -19.0. running mean: -16.557613553432777, timestamp: 2022-08-20 02:33:59.990619\n",
      "resetting env. episode 9010, reward total was -21.0. running mean: -16.60203741789845, timestamp: 2022-08-20 02:34:07.145222\n",
      "resetting env. episode 9011, reward total was -18.0. running mean: -16.616017043719467, timestamp: 2022-08-20 02:34:14.552830\n",
      "resetting env. episode 9012, reward total was -17.0. running mean: -16.619856873282274, timestamp: 2022-08-20 02:34:23.648451\n",
      "resetting env. episode 9013, reward total was -17.0. running mean: -16.62365830454945, timestamp: 2022-08-20 02:34:31.878588\n",
      "resetting env. episode 9014, reward total was -18.0. running mean: -16.637421721503955, timestamp: 2022-08-20 02:34:38.368184\n",
      "resetting env. episode 9015, reward total was -16.0. running mean: -16.631047504288915, timestamp: 2022-08-20 02:34:45.564262\n",
      "resetting env. episode 9016, reward total was -12.0. running mean: -16.58473702924603, timestamp: 2022-08-20 02:34:54.150886\n",
      "resetting env. episode 9017, reward total was -16.0. running mean: -16.578889658953567, timestamp: 2022-08-20 02:35:00.765484\n",
      "resetting env. episode 9018, reward total was -13.0. running mean: -16.54310076236403, timestamp: 2022-08-20 02:35:09.494631\n",
      "resetting env. episode 9019, reward total was -17.0. running mean: -16.54766975474039, timestamp: 2022-08-20 02:35:16.855713\n",
      "resetting env. episode 9020, reward total was -17.0. running mean: -16.552193057192987, timestamp: 2022-08-20 02:35:25.393856\n",
      "resetting env. episode 9021, reward total was -15.0. running mean: -16.536671126621055, timestamp: 2022-08-20 02:35:33.023941\n",
      "resetting env. episode 9022, reward total was -19.0. running mean: -16.561304415354847, timestamp: 2022-08-20 02:35:40.302068\n",
      "resetting env. episode 9023, reward total was -19.0. running mean: -16.5856913712013, timestamp: 2022-08-20 02:35:48.291206\n",
      "resetting env. episode 9024, reward total was -14.0. running mean: -16.559834457489288, timestamp: 2022-08-20 02:35:55.789287\n",
      "resetting env. episode 9025, reward total was -17.0. running mean: -16.564236112914397, timestamp: 2022-08-20 02:36:04.005376\n",
      "resetting env. episode 9026, reward total was -11.0. running mean: -16.508593751785252, timestamp: 2022-08-20 02:36:13.151005\n",
      "resetting env. episode 9027, reward total was -15.0. running mean: -16.4935078142674, timestamp: 2022-08-20 02:36:22.465106\n",
      "resetting env. episode 9028, reward total was -18.0. running mean: -16.508572736124727, timestamp: 2022-08-20 02:36:28.329171\n",
      "resetting env. episode 9029, reward total was -15.0. running mean: -16.493487008763477, timestamp: 2022-08-20 02:36:36.879266\n",
      "resetting env. episode 9030, reward total was -12.0. running mean: -16.448552138675844, timestamp: 2022-08-20 02:36:44.141391\n",
      "resetting env. episode 9031, reward total was -19.0. running mean: -16.474066617289086, timestamp: 2022-08-20 02:36:51.509002\n",
      "resetting env. episode 9032, reward total was -13.0. running mean: -16.439325951116196, timestamp: 2022-08-20 02:36:59.720092\n",
      "resetting env. episode 9033, reward total was -12.0. running mean: -16.394932691605035, timestamp: 2022-08-20 02:37:07.303694\n",
      "resetting env. episode 9034, reward total was -17.0. running mean: -16.400983364688987, timestamp: 2022-08-20 02:37:13.630764\n",
      "resetting env. episode 9035, reward total was -15.0. running mean: -16.386973531042095, timestamp: 2022-08-20 02:37:22.399541\n",
      "resetting env. episode 9036, reward total was -15.0. running mean: -16.373103795731673, timestamp: 2022-08-20 02:37:29.432668\n",
      "resetting env. episode 9037, reward total was -16.0. running mean: -16.369372757774357, timestamp: 2022-08-20 02:37:37.948762\n",
      "resetting env. episode 9038, reward total was -18.0. running mean: -16.385679030196613, timestamp: 2022-08-20 02:37:45.112360\n",
      "resetting env. episode 9039, reward total was -19.0. running mean: -16.411822239894647, timestamp: 2022-08-20 02:37:51.608952\n",
      "resetting env. episode 9040, reward total was -15.0. running mean: -16.3977040174957, timestamp: 2022-08-20 02:38:00.310571\n",
      "resetting env. episode 9041, reward total was -17.0. running mean: -16.403726977320744, timestamp: 2022-08-20 02:38:07.392702\n",
      "resetting env. episode 9042, reward total was -18.0. running mean: -16.419689707547537, timestamp: 2022-08-20 02:38:13.827824\n",
      "resetting env. episode 9043, reward total was -16.0. running mean: -16.415492810472063, timestamp: 2022-08-20 02:38:22.361915\n",
      "resetting env. episode 9044, reward total was -18.0. running mean: -16.43133788236734, timestamp: 2022-08-20 02:38:29.699520\n",
      "resetting env. episode 9045, reward total was -16.0. running mean: -16.427024503543667, timestamp: 2022-08-20 02:38:35.626584\n",
      "resetting env. episode 9046, reward total was -12.0. running mean: -16.382754258508232, timestamp: 2022-08-20 02:38:42.006653\n",
      "resetting env. episode 9047, reward total was -17.0. running mean: -16.38892671592315, timestamp: 2022-08-20 02:38:47.519713\n",
      "resetting env. episode 9048, reward total was -17.0. running mean: -16.395037448763922, timestamp: 2022-08-20 02:38:52.846775\n",
      "resetting env. episode 9049, reward total was -13.0. running mean: -16.36108707427628, timestamp: 2022-08-20 02:38:57.791827\n",
      "resetting env. episode 9050, reward total was -18.0. running mean: -16.37747620353352, timestamp: 2022-08-20 02:39:03.551412\n",
      "resetting env. episode 9051, reward total was -14.0. running mean: -16.353701441498185, timestamp: 2022-08-20 02:39:09.470004\n",
      "resetting env. episode 9052, reward total was -16.0. running mean: -16.350164427083204, timestamp: 2022-08-20 02:39:14.658581\n",
      "resetting env. episode 9053, reward total was -17.0. running mean: -16.356662782812375, timestamp: 2022-08-20 02:39:21.845658\n",
      "resetting env. episode 9054, reward total was -16.0. running mean: -16.35309615498425, timestamp: 2022-08-20 02:39:27.510723\n",
      "resetting env. episode 9055, reward total was -15.0. running mean: -16.339565193434407, timestamp: 2022-08-20 02:39:33.553789\n",
      "resetting env. episode 9056, reward total was -16.0. running mean: -16.336169541500063, timestamp: 2022-08-20 02:39:39.471851\n",
      "resetting env. episode 9057, reward total was -15.0. running mean: -16.32280784608506, timestamp: 2022-08-20 02:39:45.146447\n",
      "resetting env. episode 9058, reward total was -13.0. running mean: -16.289579767624208, timestamp: 2022-08-20 02:39:52.893525\n",
      "resetting env. episode 9059, reward total was -12.0. running mean: -16.246683969947966, timestamp: 2022-08-20 02:39:58.440586\n",
      "resetting env. episode 9060, reward total was -18.0. running mean: -16.264217130248486, timestamp: 2022-08-20 02:40:03.270638\n",
      "resetting env. episode 9061, reward total was -15.0. running mean: -16.251574958946, timestamp: 2022-08-20 02:40:09.399709\n",
      "resetting env. episode 9062, reward total was -15.0. running mean: -16.23905920935654, timestamp: 2022-08-20 02:40:16.356829\n",
      "resetting env. episode 9063, reward total was -17.0. running mean: -16.246668617262976, timestamp: 2022-08-20 02:40:20.653401\n",
      "resetting env. episode 9064, reward total was -18.0. running mean: -16.264201931090348, timestamp: 2022-08-20 02:40:25.860460\n",
      "resetting env. episode 9065, reward total was -19.0. running mean: -16.291559911779444, timestamp: 2022-08-20 02:40:31.279520\n",
      "resetting env. episode 9066, reward total was -17.0. running mean: -16.29864431266165, timestamp: 2022-08-20 02:40:35.737571\n",
      "resetting env. episode 9067, reward total was -11.0. running mean: -16.245657869535034, timestamp: 2022-08-20 02:40:42.375641\n",
      "resetting env. episode 9068, reward total was -15.0. running mean: -16.23320129083968, timestamp: 2022-08-20 02:40:48.008710\n",
      "resetting env. episode 9069, reward total was -20.0. running mean: -16.270869277931283, timestamp: 2022-08-20 02:40:52.620756\n",
      "resetting env. episode 9070, reward total was -17.0. running mean: -16.278160585151973, timestamp: 2022-08-20 02:40:57.625331\n",
      "resetting env. episode 9071, reward total was -18.0. running mean: -16.29537897930045, timestamp: 2022-08-20 02:41:03.537401\n",
      "resetting env. episode 9072, reward total was -17.0. running mean: -16.30242518950745, timestamp: 2022-08-20 02:41:09.088463\n",
      "resetting env. episode 9073, reward total was -16.0. running mean: -16.299400937612376, timestamp: 2022-08-20 02:41:14.570521\n",
      "resetting env. episode 9074, reward total was -14.0. running mean: -16.276406928236252, timestamp: 2022-08-20 02:41:20.453588\n",
      "resetting env. episode 9075, reward total was -15.0. running mean: -16.263642858953887, timestamp: 2022-08-20 02:41:26.525654\n",
      "resetting env. episode 9076, reward total was -17.0. running mean: -16.27100643036435, timestamp: 2022-08-20 02:41:32.747724\n",
      "resetting env. episode 9077, reward total was -19.0. running mean: -16.298296366060708, timestamp: 2022-08-20 02:41:37.440776\n",
      "resetting env. episode 9078, reward total was -17.0. running mean: -16.305313402400103, timestamp: 2022-08-20 02:41:42.558831\n",
      "resetting env. episode 9079, reward total was -16.0. running mean: -16.302260268376102, timestamp: 2022-08-20 02:41:48.486899\n",
      "resetting env. episode 9080, reward total was -13.0. running mean: -16.26923766569234, timestamp: 2022-08-20 02:41:53.889956\n",
      "resetting env. episode 9081, reward total was -15.0. running mean: -16.256545289035415, timestamp: 2022-08-20 02:42:01.152038\n",
      "resetting env. episode 9082, reward total was -15.0. running mean: -16.24397983614506, timestamp: 2022-08-20 02:42:06.873100\n",
      "resetting env. episode 9083, reward total was -13.0. running mean: -16.211540037783607, timestamp: 2022-08-20 02:42:12.550164\n",
      "resetting env. episode 9084, reward total was -17.0. running mean: -16.219424637405773, timestamp: 2022-08-20 02:42:18.194227\n",
      "resetting env. episode 9085, reward total was -16.0. running mean: -16.217230391031716, timestamp: 2022-08-20 02:42:23.487289\n",
      "resetting env. episode 9086, reward total was -17.0. running mean: -16.2250580871214, timestamp: 2022-08-20 02:42:29.048347\n",
      "resetting env. episode 9087, reward total was -12.0. running mean: -16.18280750625019, timestamp: 2022-08-20 02:42:34.774461\n",
      "resetting env. episode 9088, reward total was -15.0. running mean: -16.170979431187686, timestamp: 2022-08-20 02:42:40.949530\n",
      "resetting env. episode 9089, reward total was -19.0. running mean: -16.19926963687581, timestamp: 2022-08-20 02:42:44.832572\n",
      "resetting env. episode 9090, reward total was -14.0. running mean: -16.17727694050705, timestamp: 2022-08-20 02:42:50.937640\n",
      "resetting env. episode 9091, reward total was -15.0. running mean: -16.165504171101976, timestamp: 2022-08-20 02:42:57.344234\n",
      "resetting env. episode 9092, reward total was -15.0. running mean: -16.153849129390956, timestamp: 2022-08-20 02:43:03.811313\n",
      "resetting env. episode 9093, reward total was -19.0. running mean: -16.182310638097047, timestamp: 2022-08-20 02:43:09.242368\n",
      "resetting env. episode 9094, reward total was -14.0. running mean: -16.160487531716075, timestamp: 2022-08-20 02:43:15.334954\n",
      "resetting env. episode 9095, reward total was -12.0. running mean: -16.118882656398913, timestamp: 2022-08-20 02:43:22.194033\n",
      "resetting env. episode 9096, reward total was -13.0. running mean: -16.087693829834922, timestamp: 2022-08-20 02:43:28.526633\n",
      "resetting env. episode 9097, reward total was -17.0. running mean: -16.096816891536573, timestamp: 2022-08-20 02:43:33.713691\n",
      "resetting env. episode 9098, reward total was -15.0. running mean: -16.085848722621208, timestamp: 2022-08-20 02:43:39.822755\n",
      "resetting env. episode 9099, reward total was -17.0. running mean: -16.094990235394995, timestamp: 2022-08-20 02:43:44.661811\n",
      "resetting env. episode 9100, reward total was -21.0. running mean: -16.144040333041044, timestamp: 2022-08-20 02:43:50.353875\n",
      "resetting env. episode 9101, reward total was -17.0. running mean: -16.152599929710636, timestamp: 2022-08-20 02:43:55.888938\n",
      "resetting env. episode 9102, reward total was -14.0. running mean: -16.131073930413528, timestamp: 2022-08-20 02:44:02.896015\n",
      "resetting env. episode 9103, reward total was -19.0. running mean: -16.159763191109395, timestamp: 2022-08-20 02:44:07.735077\n",
      "resetting env. episode 9104, reward total was -15.0. running mean: -16.1481655591983, timestamp: 2022-08-20 02:44:15.162152\n",
      "resetting env. episode 9105, reward total was -17.0. running mean: -16.156683903606318, timestamp: 2022-08-20 02:44:20.571213\n",
      "resetting env. episode 9106, reward total was -16.0. running mean: -16.155117064570256, timestamp: 2022-08-20 02:44:26.114276\n",
      "resetting env. episode 9107, reward total was -20.0. running mean: -16.193565893924553, timestamp: 2022-08-20 02:44:30.695330\n",
      "resetting env. episode 9108, reward total was -16.0. running mean: -16.191630234985308, timestamp: 2022-08-20 02:44:35.097376\n",
      "resetting env. episode 9109, reward total was -16.0. running mean: -16.189713932635456, timestamp: 2022-08-20 02:44:40.224432\n",
      "resetting env. episode 9110, reward total was -17.0. running mean: -16.1978167933091, timestamp: 2022-08-20 02:44:45.382489\n",
      "resetting env. episode 9111, reward total was -16.0. running mean: -16.19583862537601, timestamp: 2022-08-20 02:44:50.995551\n",
      "resetting env. episode 9112, reward total was -16.0. running mean: -16.193880239122247, timestamp: 2022-08-20 02:44:56.298609\n",
      "resetting env. episode 9113, reward total was -19.0. running mean: -16.221941436731026, timestamp: 2022-08-20 02:45:01.674670\n",
      "resetting env. episode 9114, reward total was -15.0. running mean: -16.209722022363714, timestamp: 2022-08-20 02:45:10.185293\n",
      "resetting env. episode 9115, reward total was -17.0. running mean: -16.21762480214008, timestamp: 2022-08-20 02:45:15.944348\n",
      "resetting env. episode 9116, reward total was -15.0. running mean: -16.20544855411868, timestamp: 2022-08-20 02:45:20.485399\n",
      "resetting env. episode 9117, reward total was -18.0. running mean: -16.22339406857749, timestamp: 2022-08-20 02:45:25.786460\n",
      "resetting env. episode 9118, reward total was -13.0. running mean: -16.191160127891717, timestamp: 2022-08-20 02:45:31.317520\n",
      "resetting env. episode 9119, reward total was -16.0. running mean: -16.1892485266128, timestamp: 2022-08-20 02:45:36.553577\n",
      "resetting env. episode 9120, reward total was -16.0. running mean: -16.18735604134667, timestamp: 2022-08-20 02:45:42.087648\n",
      "resetting env. episode 9121, reward total was -17.0. running mean: -16.195482480933205, timestamp: 2022-08-20 02:45:47.253696\n",
      "resetting env. episode 9122, reward total was -21.0. running mean: -16.243527656123874, timestamp: 2022-08-20 02:45:52.425756\n",
      "resetting env. episode 9123, reward total was -16.0. running mean: -16.241092379562634, timestamp: 2022-08-20 02:45:57.005805\n",
      "resetting env. episode 9124, reward total was -18.0. running mean: -16.258681455767007, timestamp: 2022-08-20 02:46:01.358856\n",
      "resetting env. episode 9125, reward total was -13.0. running mean: -16.226094641209336, timestamp: 2022-08-20 02:46:07.725448\n",
      "resetting env. episode 9126, reward total was -17.0. running mean: -16.233833694797244, timestamp: 2022-08-20 02:46:13.335511\n",
      "resetting env. episode 9127, reward total was -15.0. running mean: -16.22149535784927, timestamp: 2022-08-20 02:46:18.401565\n",
      "resetting env. episode 9128, reward total was -13.0. running mean: -16.18928040427078, timestamp: 2022-08-20 02:46:25.003639\n",
      "resetting env. episode 9129, reward total was -15.0. running mean: -16.17738760022807, timestamp: 2022-08-20 02:46:30.894705\n",
      "resetting env. episode 9130, reward total was -18.0. running mean: -16.195613724225787, timestamp: 2022-08-20 02:46:37.179774\n",
      "resetting env. episode 9131, reward total was -17.0. running mean: -16.20365758698353, timestamp: 2022-08-20 02:46:42.731834\n",
      "resetting env. episode 9132, reward total was -17.0. running mean: -16.2116210111137, timestamp: 2022-08-20 02:46:48.489423\n",
      "resetting env. episode 9133, reward total was -19.0. running mean: -16.239504801002564, timestamp: 2022-08-20 02:46:54.011489\n",
      "resetting env. episode 9134, reward total was -17.0. running mean: -16.24710975299254, timestamp: 2022-08-20 02:47:00.134555\n",
      "resetting env. episode 9135, reward total was -13.0. running mean: -16.21463865546261, timestamp: 2022-08-20 02:47:06.197621\n",
      "resetting env. episode 9136, reward total was -10.0. running mean: -16.152492268907988, timestamp: 2022-08-20 02:47:12.298686\n",
      "resetting env. episode 9137, reward total was -17.0. running mean: -16.160967346218907, timestamp: 2022-08-20 02:47:17.673747\n",
      "resetting env. episode 9138, reward total was -11.0. running mean: -16.10935767275672, timestamp: 2022-08-20 02:47:23.362810\n",
      "resetting env. episode 9139, reward total was -15.0. running mean: -16.09826409602915, timestamp: 2022-08-20 02:47:30.393416\n",
      "resetting env. episode 9140, reward total was -21.0. running mean: -16.14728145506886, timestamp: 2022-08-20 02:47:35.850473\n",
      "resetting env. episode 9141, reward total was -16.0. running mean: -16.145808640518172, timestamp: 2022-08-20 02:47:40.847531\n",
      "resetting env. episode 9142, reward total was -11.0. running mean: -16.094350554112992, timestamp: 2022-08-20 02:47:47.929608\n",
      "resetting env. episode 9143, reward total was -13.0. running mean: -16.06340704857186, timestamp: 2022-08-20 02:47:53.175666\n",
      "resetting env. episode 9144, reward total was -17.0. running mean: -16.072772978086142, timestamp: 2022-08-20 02:47:59.691739\n",
      "resetting env. episode 9145, reward total was -17.0. running mean: -16.08204524830528, timestamp: 2022-08-20 02:48:04.751797\n",
      "resetting env. episode 9146, reward total was -18.0. running mean: -16.10122479582223, timestamp: 2022-08-20 02:48:11.340867\n",
      "resetting env. episode 9147, reward total was -14.0. running mean: -16.080212547864008, timestamp: 2022-08-20 02:48:17.183933\n",
      "resetting env. episode 9148, reward total was -18.0. running mean: -16.09941042238537, timestamp: 2022-08-20 02:48:23.096998\n",
      "resetting env. episode 9149, reward total was -19.0. running mean: -16.128416318161516, timestamp: 2022-08-20 02:48:28.149055\n",
      "resetting env. episode 9150, reward total was -20.0. running mean: -16.1671321549799, timestamp: 2022-08-20 02:48:32.963106\n",
      "resetting env. episode 9151, reward total was -18.0. running mean: -16.1854608334301, timestamp: 2022-08-20 02:48:37.439158\n",
      "resetting env. episode 9152, reward total was -14.0. running mean: -16.163606225095798, timestamp: 2022-08-20 02:48:43.488272\n",
      "resetting env. episode 9153, reward total was -15.0. running mean: -16.151970162844837, timestamp: 2022-08-20 02:48:48.982345\n",
      "resetting env. episode 9154, reward total was -18.0. running mean: -16.17045046121639, timestamp: 2022-08-20 02:48:53.725387\n",
      "resetting env. episode 9155, reward total was -14.0. running mean: -16.148745956604227, timestamp: 2022-08-20 02:48:58.062440\n",
      "resetting env. episode 9156, reward total was -14.0. running mean: -16.127258497038184, timestamp: 2022-08-20 02:49:05.636519\n",
      "resetting env. episode 9157, reward total was -17.0. running mean: -16.135985912067802, timestamp: 2022-08-20 02:49:10.807581\n",
      "resetting env. episode 9158, reward total was -15.0. running mean: -16.124626052947125, timestamp: 2022-08-20 02:49:16.637164\n",
      "resetting env. episode 9159, reward total was -19.0. running mean: -16.153379792417653, timestamp: 2022-08-20 02:49:22.734232\n",
      "resetting env. episode 9160, reward total was -16.0. running mean: -16.151845994493474, timestamp: 2022-08-20 02:49:28.123291\n",
      "resetting env. episode 9161, reward total was -17.0. running mean: -16.16032753454854, timestamp: 2022-08-20 02:49:33.635350\n",
      "resetting env. episode 9162, reward total was -11.0. running mean: -16.108724259203054, timestamp: 2022-08-20 02:49:39.153411\n",
      "resetting env. episode 9163, reward total was -18.0. running mean: -16.127637016611025, timestamp: 2022-08-20 02:49:44.285470\n",
      "resetting env. episode 9164, reward total was -15.0. running mean: -16.116360646444914, timestamp: 2022-08-20 02:49:50.018058\n",
      "resetting env. episode 9165, reward total was -16.0. running mean: -16.115197039980465, timestamp: 2022-08-20 02:49:55.885116\n",
      "resetting env. episode 9166, reward total was -19.0. running mean: -16.14404506958066, timestamp: 2022-08-20 02:50:00.967705\n",
      "resetting env. episode 9167, reward total was -17.0. running mean: -16.152604618884855, timestamp: 2022-08-20 02:50:05.885756\n",
      "resetting env. episode 9168, reward total was -19.0. running mean: -16.181078572696006, timestamp: 2022-08-20 02:50:10.594804\n",
      "resetting env. episode 9169, reward total was -13.0. running mean: -16.149267786969045, timestamp: 2022-08-20 02:50:16.489878\n",
      "resetting env. episode 9170, reward total was -15.0. running mean: -16.137775109099355, timestamp: 2022-08-20 02:50:22.493457\n",
      "resetting env. episode 9171, reward total was -19.0. running mean: -16.16639735800836, timestamp: 2022-08-20 02:50:28.116518\n",
      "resetting env. episode 9172, reward total was -16.0. running mean: -16.164733384428278, timestamp: 2022-08-20 02:50:34.127585\n",
      "resetting env. episode 9173, reward total was -19.0. running mean: -16.193086050583997, timestamp: 2022-08-20 02:50:40.911658\n",
      "resetting env. episode 9174, reward total was -20.0. running mean: -16.231155190078155, timestamp: 2022-08-20 02:50:46.337717\n",
      "resetting env. episode 9175, reward total was -17.0. running mean: -16.238843638177375, timestamp: 2022-08-20 02:50:51.344775\n",
      "resetting env. episode 9176, reward total was -13.0. running mean: -16.2064552017956, timestamp: 2022-08-20 02:50:58.855855\n",
      "resetting env. episode 9177, reward total was -17.0. running mean: -16.214390649777645, timestamp: 2022-08-20 02:51:03.831433\n",
      "resetting env. episode 9178, reward total was -17.0. running mean: -16.22224674327987, timestamp: 2022-08-20 02:51:08.854488\n",
      "resetting env. episode 9179, reward total was -15.0. running mean: -16.210024275847072, timestamp: 2022-08-20 02:51:14.889553\n",
      "resetting env. episode 9180, reward total was -14.0. running mean: -16.187924033088603, timestamp: 2022-08-20 02:51:20.078610\n",
      "resetting env. episode 9181, reward total was -17.0. running mean: -16.196044792757718, timestamp: 2022-08-20 02:51:25.007193\n",
      "resetting env. episode 9182, reward total was -15.0. running mean: -16.18408434483014, timestamp: 2022-08-20 02:51:30.816259\n",
      "resetting env. episode 9183, reward total was -15.0. running mean: -16.172243501381836, timestamp: 2022-08-20 02:51:41.013370\n",
      "resetting env. episode 9184, reward total was -19.0. running mean: -16.20052106636802, timestamp: 2022-08-20 02:51:46.043427\n",
      "resetting env. episode 9185, reward total was -15.0. running mean: -16.18851585570434, timestamp: 2022-08-20 02:51:51.781487\n",
      "resetting env. episode 9186, reward total was -12.0. running mean: -16.146630697147295, timestamp: 2022-08-20 02:51:57.555551\n",
      "resetting env. episode 9187, reward total was -11.0. running mean: -16.09516439017582, timestamp: 2022-08-20 02:52:03.601615\n",
      "resetting env. episode 9188, reward total was -11.0. running mean: -16.044212746274063, timestamp: 2022-08-20 02:52:11.231702\n",
      "resetting env. episode 9189, reward total was -21.0. running mean: -16.093770618811323, timestamp: 2022-08-20 02:52:15.981754\n",
      "resetting env. episode 9190, reward total was -7.0. running mean: -16.00283291262321, timestamp: 2022-08-20 02:52:24.746849\n",
      "resetting env. episode 9191, reward total was -17.0. running mean: -16.012804583496976, timestamp: 2022-08-20 02:52:30.425911\n",
      "resetting env. episode 9192, reward total was -17.0. running mean: -16.022676537662008, timestamp: 2022-08-20 02:52:36.362980\n",
      "resetting env. episode 9193, reward total was -17.0. running mean: -16.03244977228539, timestamp: 2022-08-20 02:52:42.465042\n",
      "resetting env. episode 9194, reward total was -15.0. running mean: -16.022125274562534, timestamp: 2022-08-20 02:52:48.487109\n",
      "resetting env. episode 9195, reward total was -19.0. running mean: -16.05190402181691, timestamp: 2022-08-20 02:52:54.010173\n",
      "resetting env. episode 9196, reward total was -21.0. running mean: -16.10138498159874, timestamp: 2022-08-20 02:52:59.947761\n",
      "resetting env. episode 9197, reward total was -11.0. running mean: -16.050371131782754, timestamp: 2022-08-20 02:53:06.647836\n",
      "resetting env. episode 9198, reward total was -18.0. running mean: -16.069867420464927, timestamp: 2022-08-20 02:53:11.059405\n",
      "resetting env. episode 9199, reward total was -19.0. running mean: -16.09916874626028, timestamp: 2022-08-20 02:53:15.888460\n",
      "resetting env. episode 9200, reward total was -10.0. running mean: -16.038177058797675, timestamp: 2022-08-20 02:53:24.868554\n",
      "resetting env. episode 9201, reward total was -14.0. running mean: -16.017795288209697, timestamp: 2022-08-20 02:53:30.903632\n",
      "resetting env. episode 9202, reward total was -20.0. running mean: -16.0576173353276, timestamp: 2022-08-20 02:53:36.508681\n",
      "resetting env. episode 9203, reward total was -17.0. running mean: -16.067041161974323, timestamp: 2022-08-20 02:53:41.962743\n",
      "resetting env. episode 9204, reward total was -11.0. running mean: -16.01637075035458, timestamp: 2022-08-20 02:53:49.185820\n",
      "resetting env. episode 9205, reward total was -17.0. running mean: -16.026207042851034, timestamp: 2022-08-20 02:53:55.108891\n",
      "resetting env. episode 9206, reward total was -15.0. running mean: -16.015944972422524, timestamp: 2022-08-20 02:54:01.885958\n",
      "resetting env. episode 9207, reward total was -12.0. running mean: -15.975785522698297, timestamp: 2022-08-20 02:54:07.782022\n",
      "resetting env. episode 9208, reward total was -18.0. running mean: -15.996027667471314, timestamp: 2022-08-20 02:54:13.075081\n",
      "resetting env. episode 9209, reward total was -19.0. running mean: -16.0260673907966, timestamp: 2022-08-20 02:54:18.329141\n",
      "resetting env. episode 9210, reward total was -15.0. running mean: -16.015806716888633, timestamp: 2022-08-20 02:54:24.132199\n",
      "resetting env. episode 9211, reward total was -14.0. running mean: -15.995648649719747, timestamp: 2022-08-20 02:54:29.176256\n",
      "resetting env. episode 9212, reward total was -18.0. running mean: -16.01569216322255, timestamp: 2022-08-20 02:54:36.193334\n",
      "resetting env. episode 9213, reward total was -16.0. running mean: -16.015535241590324, timestamp: 2022-08-20 02:54:42.295403\n",
      "resetting env. episode 9214, reward total was -17.0. running mean: -16.02537988917442, timestamp: 2022-08-20 02:54:48.176988\n",
      "resetting env. episode 9215, reward total was -10.0. running mean: -15.965126090282675, timestamp: 2022-08-20 02:54:54.652058\n",
      "resetting env. episode 9216, reward total was -21.0. running mean: -16.015474829379848, timestamp: 2022-08-20 02:54:59.357107\n",
      "resetting env. episode 9217, reward total was -14.0. running mean: -15.99532008108605, timestamp: 2022-08-20 02:55:05.627178\n",
      "resetting env. episode 9218, reward total was -12.0. running mean: -15.955366880275188, timestamp: 2022-08-20 02:55:10.577229\n",
      "resetting env. episode 9219, reward total was -17.0. running mean: -15.965813211472435, timestamp: 2022-08-20 02:55:15.642285\n",
      "resetting env. episode 9220, reward total was -17.0. running mean: -15.97615507935771, timestamp: 2022-08-20 02:55:22.037356\n",
      "resetting env. episode 9221, reward total was -11.0. running mean: -15.926393528564132, timestamp: 2022-08-20 02:55:28.458424\n",
      "resetting env. episode 9222, reward total was -12.0. running mean: -15.88712959327849, timestamp: 2022-08-20 02:55:35.066496\n",
      "resetting env. episode 9223, reward total was -12.0. running mean: -15.848258297345703, timestamp: 2022-08-20 02:55:40.942560\n",
      "resetting env. episode 9224, reward total was -16.0. running mean: -15.849775714372246, timestamp: 2022-08-20 02:55:45.338607\n",
      "resetting env. episode 9225, reward total was -17.0. running mean: -15.861277957228523, timestamp: 2022-08-20 02:55:51.562675\n",
      "resetting env. episode 9226, reward total was -17.0. running mean: -15.872665177656238, timestamp: 2022-08-20 02:55:55.460720\n",
      "resetting env. episode 9227, reward total was -18.0. running mean: -15.893938525879674, timestamp: 2022-08-20 02:56:01.192782\n",
      "resetting env. episode 9228, reward total was -19.0. running mean: -15.924999140620876, timestamp: 2022-08-20 02:56:06.461838\n",
      "resetting env. episode 9229, reward total was -12.0. running mean: -15.885749149214666, timestamp: 2022-08-20 02:56:12.055429\n",
      "resetting env. episode 9230, reward total was -16.0. running mean: -15.886891657722519, timestamp: 2022-08-20 02:56:18.297489\n",
      "resetting env. episode 9231, reward total was -15.0. running mean: -15.878022741145294, timestamp: 2022-08-20 02:56:24.065556\n",
      "resetting env. episode 9232, reward total was -15.0. running mean: -15.869242513733841, timestamp: 2022-08-20 02:56:29.971616\n",
      "resetting env. episode 9233, reward total was -17.0. running mean: -15.880550088596502, timestamp: 2022-08-20 02:56:36.456689\n",
      "resetting env. episode 9234, reward total was -16.0. running mean: -15.881744587710537, timestamp: 2022-08-20 02:56:41.651746\n",
      "resetting env. episode 9235, reward total was -15.0. running mean: -15.872927141833433, timestamp: 2022-08-20 02:56:47.502811\n",
      "resetting env. episode 9236, reward total was -17.0. running mean: -15.884197870415099, timestamp: 2022-08-20 02:56:53.042874\n",
      "resetting env. episode 9237, reward total was -10.0. running mean: -15.825355891710947, timestamp: 2022-08-20 02:56:59.280942\n",
      "resetting env. episode 9238, reward total was -21.0. running mean: -15.877102332793838, timestamp: 2022-08-20 02:57:04.423997\n",
      "resetting env. episode 9239, reward total was -18.0. running mean: -15.898331309465899, timestamp: 2022-08-20 02:57:10.842068\n",
      "resetting env. episode 9240, reward total was -15.0. running mean: -15.88934799637124, timestamp: 2022-08-20 02:57:16.655656\n",
      "resetting env. episode 9241, reward total was -18.0. running mean: -15.910454516407528, timestamp: 2022-08-20 02:57:21.760718\n",
      "resetting env. episode 9242, reward total was -17.0. running mean: -15.921349971243453, timestamp: 2022-08-20 02:57:27.818782\n",
      "resetting env. episode 9243, reward total was -18.0. running mean: -15.942136471531018, timestamp: 2022-08-20 02:57:33.407841\n",
      "resetting env. episode 9244, reward total was -14.0. running mean: -15.922715106815708, timestamp: 2022-08-20 02:57:38.968904\n",
      "resetting env. episode 9245, reward total was -19.0. running mean: -15.953487955747551, timestamp: 2022-08-20 02:57:43.203948\n",
      "resetting env. episode 9246, reward total was -13.0. running mean: -15.923953076190076, timestamp: 2022-08-20 02:57:49.908550\n",
      "resetting env. episode 9247, reward total was -15.0. running mean: -15.914713545428175, timestamp: 2022-08-20 02:57:55.406611\n",
      "resetting env. episode 9248, reward total was -12.0. running mean: -15.875566409973892, timestamp: 2022-08-20 02:58:01.527678\n",
      "resetting env. episode 9249, reward total was -14.0. running mean: -15.856810745874153, timestamp: 2022-08-20 02:58:07.655742\n",
      "resetting env. episode 9250, reward total was -13.0. running mean: -15.828242638415412, timestamp: 2022-08-20 02:58:13.609810\n",
      "resetting env. episode 9251, reward total was -15.0. running mean: -15.819960212031258, timestamp: 2022-08-20 02:58:20.311885\n",
      "resetting env. episode 9252, reward total was -21.0. running mean: -15.871760609910947, timestamp: 2022-08-20 02:58:24.881935\n",
      "resetting env. episode 9253, reward total was -16.0. running mean: -15.873043003811837, timestamp: 2022-08-20 02:58:29.985992\n",
      "resetting env. episode 9254, reward total was -11.0. running mean: -15.824312573773717, timestamp: 2022-08-20 02:58:36.783068\n",
      "resetting env. episode 9255, reward total was -14.0. running mean: -15.80606944803598, timestamp: 2022-08-20 02:58:41.403119\n",
      "resetting env. episode 9256, reward total was -13.0. running mean: -15.778008753555621, timestamp: 2022-08-20 02:58:47.292184\n",
      "resetting env. episode 9257, reward total was -18.0. running mean: -15.800228666020065, timestamp: 2022-08-20 02:58:54.777275\n",
      "resetting env. episode 9258, reward total was -16.0. running mean: -15.802226379359864, timestamp: 2022-08-20 02:59:00.577332\n",
      "resetting env. episode 9259, reward total was -17.0. running mean: -15.814204115566264, timestamp: 2022-08-20 02:59:05.836391\n",
      "resetting env. episode 9260, reward total was -15.0. running mean: -15.806062074410601, timestamp: 2022-08-20 02:59:11.099447\n",
      "resetting env. episode 9261, reward total was -19.0. running mean: -15.838001453666495, timestamp: 2022-08-20 02:59:16.340505\n",
      "resetting env. episode 9262, reward total was -18.0. running mean: -15.85962143912983, timestamp: 2022-08-20 02:59:21.316562\n",
      "resetting env. episode 9263, reward total was -17.0. running mean: -15.871025224738531, timestamp: 2022-08-20 02:59:26.411618\n",
      "resetting env. episode 9264, reward total was -14.0. running mean: -15.852314972491147, timestamp: 2022-08-20 02:59:32.842690\n",
      "resetting env. episode 9265, reward total was -20.0. running mean: -15.893791822766234, timestamp: 2022-08-20 02:59:37.349740\n",
      "resetting env. episode 9266, reward total was -17.0. running mean: -15.904853904538571, timestamp: 2022-08-20 02:59:43.640809\n",
      "resetting env. episode 9267, reward total was -16.0. running mean: -15.905805365493185, timestamp: 2022-08-20 02:59:50.873889\n",
      "resetting env. episode 9268, reward total was -17.0. running mean: -15.916747311838252, timestamp: 2022-08-20 02:59:56.337949\n",
      "resetting env. episode 9269, reward total was -16.0. running mean: -15.91757983871987, timestamp: 2022-08-20 03:00:02.257015\n",
      "resetting env. episode 9270, reward total was -19.0. running mean: -15.94840404033267, timestamp: 2022-08-20 03:00:07.863077\n",
      "resetting env. episode 9271, reward total was -13.0. running mean: -15.918919999929345, timestamp: 2022-08-20 03:00:13.498141\n",
      "resetting env. episode 9272, reward total was -12.0. running mean: -15.879730799930051, timestamp: 2022-08-20 03:00:20.398218\n",
      "resetting env. episode 9273, reward total was -10.0. running mean: -15.82093349193075, timestamp: 2022-08-20 03:00:29.159360\n",
      "resetting env. episode 9274, reward total was -15.0. running mean: -15.812724157011443, timestamp: 2022-08-20 03:00:37.337972\n",
      "resetting env. episode 9275, reward total was -15.0. running mean: -15.804596915441328, timestamp: 2022-08-20 03:00:43.637043\n",
      "resetting env. episode 9276, reward total was -12.0. running mean: -15.766550946286914, timestamp: 2022-08-20 03:00:50.910123\n",
      "resetting env. episode 9277, reward total was -19.0. running mean: -15.798885436824044, timestamp: 2022-08-20 03:00:55.968180\n",
      "resetting env. episode 9278, reward total was -10.0. running mean: -15.740896582455804, timestamp: 2022-08-20 03:01:04.217271\n",
      "resetting env. episode 9279, reward total was -13.0. running mean: -15.713487616631246, timestamp: 2022-08-20 03:01:11.343875\n",
      "resetting env. episode 9280, reward total was -17.0. running mean: -15.726352740464934, timestamp: 2022-08-20 03:01:18.484475\n",
      "resetting env. episode 9281, reward total was -16.0. running mean: -15.729089213060284, timestamp: 2022-08-20 03:01:24.670546\n",
      "resetting env. episode 9282, reward total was -15.0. running mean: -15.72179832092968, timestamp: 2022-08-20 03:01:29.999603\n",
      "resetting env. episode 9283, reward total was -15.0. running mean: -15.714580337720385, timestamp: 2022-08-20 03:01:35.292182\n",
      "resetting env. episode 9284, reward total was -13.0. running mean: -15.687434534343181, timestamp: 2022-08-20 03:01:41.270247\n",
      "resetting env. episode 9285, reward total was -17.0. running mean: -15.700560188999749, timestamp: 2022-08-20 03:01:46.514312\n",
      "resetting env. episode 9286, reward total was -17.0. running mean: -15.713554587109751, timestamp: 2022-08-20 03:01:52.068367\n",
      "resetting env. episode 9287, reward total was -13.0. running mean: -15.686419041238654, timestamp: 2022-08-20 03:01:58.026434\n",
      "resetting env. episode 9288, reward total was -17.0. running mean: -15.699554850826267, timestamp: 2022-08-20 03:02:03.674017\n",
      "resetting env. episode 9289, reward total was -18.0. running mean: -15.722559302318004, timestamp: 2022-08-20 03:02:10.577094\n",
      "resetting env. episode 9290, reward total was -20.0. running mean: -15.765333709294824, timestamp: 2022-08-20 03:02:16.487160\n",
      "resetting env. episode 9291, reward total was -17.0. running mean: -15.777680372201875, timestamp: 2022-08-20 03:02:22.206224\n",
      "resetting env. episode 9292, reward total was -16.0. running mean: -15.779903568479856, timestamp: 2022-08-20 03:02:26.973276\n",
      "resetting env. episode 9293, reward total was -15.0. running mean: -15.772104532795058, timestamp: 2022-08-20 03:02:32.923860\n",
      "resetting env. episode 9294, reward total was -16.0. running mean: -15.774383487467109, timestamp: 2022-08-20 03:02:38.161918\n",
      "resetting env. episode 9295, reward total was -10.0. running mean: -15.716639652592438, timestamp: 2022-08-20 03:02:45.730004\n",
      "resetting env. episode 9296, reward total was -21.0. running mean: -15.769473256066513, timestamp: 2022-08-20 03:02:50.549057\n",
      "resetting env. episode 9297, reward total was -16.0. running mean: -15.771778523505848, timestamp: 2022-08-20 03:02:55.728117\n",
      "resetting env. episode 9298, reward total was -21.0. running mean: -15.82406073827079, timestamp: 2022-08-20 03:03:00.365167\n",
      "resetting env. episode 9299, reward total was -17.0. running mean: -15.83582013088808, timestamp: 2022-08-20 03:03:05.511223\n",
      "resetting env. episode 9300, reward total was -19.0. running mean: -15.8674619295792, timestamp: 2022-08-20 03:03:11.271286\n",
      "resetting env. episode 9301, reward total was -16.0. running mean: -15.868787310283407, timestamp: 2022-08-20 03:03:17.559357\n",
      "resetting env. episode 9302, reward total was -13.0. running mean: -15.840099437180573, timestamp: 2022-08-20 03:03:23.504422\n",
      "resetting env. episode 9303, reward total was -16.0. running mean: -15.841698442808767, timestamp: 2022-08-20 03:03:28.696043\n",
      "resetting env. episode 9304, reward total was -14.0. running mean: -15.823281458380679, timestamp: 2022-08-20 03:03:35.597121\n",
      "resetting env. episode 9305, reward total was -14.0. running mean: -15.805048643796873, timestamp: 2022-08-20 03:03:42.031193\n",
      "resetting env. episode 9306, reward total was -16.0. running mean: -15.806998157358905, timestamp: 2022-08-20 03:03:49.112272\n",
      "resetting env. episode 9307, reward total was -14.0. running mean: -15.788928175785315, timestamp: 2022-08-20 03:03:55.553341\n",
      "resetting env. episode 9308, reward total was -17.0. running mean: -15.801038894027462, timestamp: 2022-08-20 03:04:01.452410\n",
      "resetting env. episode 9309, reward total was -15.0. running mean: -15.793028505087188, timestamp: 2022-08-20 03:04:08.629486\n",
      "resetting env. episode 9310, reward total was -17.0. running mean: -15.805098220036315, timestamp: 2022-08-20 03:04:14.483551\n",
      "resetting env. episode 9311, reward total was -18.0. running mean: -15.827047237835952, timestamp: 2022-08-20 03:04:19.569609\n",
      "resetting env. episode 9312, reward total was -12.0. running mean: -15.788776765457591, timestamp: 2022-08-20 03:04:26.310685\n",
      "resetting env. episode 9313, reward total was -19.0. running mean: -15.820888997803014, timestamp: 2022-08-20 03:04:31.160737\n",
      "resetting env. episode 9314, reward total was -19.0. running mean: -15.852680107824982, timestamp: 2022-08-20 03:04:36.073792\n",
      "resetting env. episode 9315, reward total was -18.0. running mean: -15.874153306746733, timestamp: 2022-08-20 03:04:41.255850\n",
      "resetting env. episode 9316, reward total was -13.0. running mean: -15.845411773679267, timestamp: 2022-08-20 03:04:47.481921\n",
      "resetting env. episode 9317, reward total was -19.0. running mean: -15.876957655942473, timestamp: 2022-08-20 03:04:52.711977\n",
      "resetting env. episode 9318, reward total was -16.0. running mean: -15.878188079383047, timestamp: 2022-08-20 03:04:58.437570\n",
      "resetting env. episode 9319, reward total was -14.0. running mean: -15.859406198589218, timestamp: 2022-08-20 03:05:04.541636\n",
      "resetting env. episode 9320, reward total was -14.0. running mean: -15.840812136603326, timestamp: 2022-08-20 03:05:08.674683\n",
      "resetting env. episode 9321, reward total was -14.0. running mean: -15.822404015237293, timestamp: 2022-08-20 03:05:15.125758\n",
      "resetting env. episode 9322, reward total was -15.0. running mean: -15.81417997508492, timestamp: 2022-08-20 03:05:20.458813\n",
      "resetting env. episode 9323, reward total was -13.0. running mean: -15.786038175334072, timestamp: 2022-08-20 03:05:25.973876\n",
      "resetting env. episode 9324, reward total was -14.0. running mean: -15.768177793580731, timestamp: 2022-08-20 03:05:31.116936\n",
      "resetting env. episode 9325, reward total was -15.0. running mean: -15.760496015644925, timestamp: 2022-08-20 03:05:36.737993\n",
      "resetting env. episode 9326, reward total was -21.0. running mean: -15.812891055488477, timestamp: 2022-08-20 03:05:41.576047\n",
      "resetting env. episode 9327, reward total was -9.0. running mean: -15.744762144933592, timestamp: 2022-08-20 03:05:48.486125\n",
      "resetting env. episode 9328, reward total was -15.0. running mean: -15.737314523484256, timestamp: 2022-08-20 03:05:53.510180\n",
      "resetting env. episode 9329, reward total was -14.0. running mean: -15.719941378249414, timestamp: 2022-08-20 03:05:59.231242\n",
      "resetting env. episode 9330, reward total was -18.0. running mean: -15.74274196446692, timestamp: 2022-08-20 03:06:04.165298\n",
      "resetting env. episode 9331, reward total was -16.0. running mean: -15.74531454482225, timestamp: 2022-08-20 03:06:09.813362\n",
      "resetting env. episode 9332, reward total was -9.0. running mean: -15.677861399374027, timestamp: 2022-08-20 03:06:18.311509\n",
      "resetting env. episode 9333, reward total was -15.0. running mean: -15.671082785380287, timestamp: 2022-08-20 03:06:24.970581\n",
      "resetting env. episode 9334, reward total was -16.0. running mean: -15.674371957526484, timestamp: 2022-08-20 03:06:30.601645\n",
      "resetting env. episode 9335, reward total was -18.0. running mean: -15.697628237951218, timestamp: 2022-08-20 03:06:36.066703\n",
      "resetting env. episode 9336, reward total was -13.0. running mean: -15.670651955571707, timestamp: 2022-08-20 03:06:42.558775\n",
      "resetting env. episode 9337, reward total was -17.0. running mean: -15.68394543601599, timestamp: 2022-08-20 03:06:48.410840\n",
      "resetting env. episode 9338, reward total was -13.0. running mean: -15.65710598165583, timestamp: 2022-08-20 03:06:55.240915\n",
      "resetting env. episode 9339, reward total was -11.0. running mean: -15.610534921839271, timestamp: 2022-08-20 03:07:00.830977\n",
      "resetting env. episode 9340, reward total was -16.0. running mean: -15.614429572620878, timestamp: 2022-08-20 03:07:06.226036\n",
      "resetting env. episode 9341, reward total was -16.0. running mean: -15.61828527689467, timestamp: 2022-08-20 03:07:12.397103\n",
      "resetting env. episode 9342, reward total was -19.0. running mean: -15.652102424125722, timestamp: 2022-08-20 03:07:16.607149\n",
      "resetting env. episode 9343, reward total was -11.0. running mean: -15.605581399884464, timestamp: 2022-08-20 03:07:22.781219\n",
      "resetting env. episode 9344, reward total was -16.0. running mean: -15.609525585885619, timestamp: 2022-08-20 03:07:28.506803\n",
      "resetting env. episode 9345, reward total was -15.0. running mean: -15.603430330026763, timestamp: 2022-08-20 03:07:33.849861\n",
      "resetting env. episode 9346, reward total was -17.0. running mean: -15.617396026726494, timestamp: 2022-08-20 03:07:39.126918\n",
      "resetting env. episode 9347, reward total was -14.0. running mean: -15.60122206645923, timestamp: 2022-08-20 03:07:45.936996\n",
      "resetting env. episode 9348, reward total was -20.0. running mean: -15.645209845794636, timestamp: 2022-08-20 03:07:50.190042\n",
      "resetting env. episode 9349, reward total was -16.0. running mean: -15.64875774733669, timestamp: 2022-08-20 03:07:57.053117\n",
      "resetting env. episode 9350, reward total was -13.0. running mean: -15.622270169863324, timestamp: 2022-08-20 03:08:03.043182\n",
      "resetting env. episode 9351, reward total was -14.0. running mean: -15.606047468164691, timestamp: 2022-08-20 03:08:09.143786\n",
      "resetting env. episode 9352, reward total was -13.0. running mean: -15.579986993483045, timestamp: 2022-08-20 03:08:15.520857\n",
      "resetting env. episode 9353, reward total was -17.0. running mean: -15.594187123548215, timestamp: 2022-08-20 03:08:21.237919\n",
      "resetting env. episode 9354, reward total was -16.0. running mean: -15.598245252312733, timestamp: 2022-08-20 03:08:27.034983\n",
      "resetting env. episode 9355, reward total was -15.0. running mean: -15.592262799789605, timestamp: 2022-08-20 03:08:33.215577\n",
      "resetting env. episode 9356, reward total was -16.0. running mean: -15.59634017179171, timestamp: 2022-08-20 03:08:38.840638\n",
      "resetting env. episode 9357, reward total was -21.0. running mean: -15.650376770073793, timestamp: 2022-08-20 03:08:43.838214\n",
      "resetting env. episode 9358, reward total was -17.0. running mean: -15.663873002373055, timestamp: 2022-08-20 03:08:49.601277\n",
      "resetting env. episode 9359, reward total was -15.0. running mean: -15.657234272349324, timestamp: 2022-08-20 03:08:54.430330\n",
      "resetting env. episode 9360, reward total was -17.0. running mean: -15.670661929625831, timestamp: 2022-08-20 03:09:00.737400\n",
      "resetting env. episode 9361, reward total was -18.0. running mean: -15.693955310329573, timestamp: 2022-08-20 03:09:05.231448\n",
      "resetting env. episode 9362, reward total was -13.0. running mean: -15.667015757226277, timestamp: 2022-08-20 03:09:12.292526\n",
      "resetting env. episode 9363, reward total was -17.0. running mean: -15.680345599654014, timestamp: 2022-08-20 03:09:20.140613\n",
      "resetting env. episode 9364, reward total was -15.0. running mean: -15.673542143657475, timestamp: 2022-08-20 03:09:26.320680\n",
      "resetting env. episode 9365, reward total was -19.0. running mean: -15.706806722220898, timestamp: 2022-08-20 03:09:31.783741\n",
      "resetting env. episode 9366, reward total was -13.0. running mean: -15.67973865499869, timestamp: 2022-08-20 03:09:39.514870\n",
      "resetting env. episode 9367, reward total was -19.0. running mean: -15.712941268448702, timestamp: 2022-08-20 03:09:45.361934\n",
      "resetting env. episode 9368, reward total was -15.0. running mean: -15.705811855764216, timestamp: 2022-08-20 03:09:51.082996\n",
      "resetting env. episode 9369, reward total was -17.0. running mean: -15.718753737206573, timestamp: 2022-08-20 03:09:57.352595\n",
      "resetting env. episode 9370, reward total was -18.0. running mean: -15.741566199834507, timestamp: 2022-08-20 03:10:03.229659\n",
      "resetting env. episode 9371, reward total was -14.0. running mean: -15.724150537836163, timestamp: 2022-08-20 03:10:08.612718\n",
      "resetting env. episode 9372, reward total was -17.0. running mean: -15.7369090324578, timestamp: 2022-08-20 03:10:13.989300\n",
      "resetting env. episode 9373, reward total was -14.0. running mean: -15.719539942133222, timestamp: 2022-08-20 03:10:19.989365\n",
      "resetting env. episode 9374, reward total was -16.0. running mean: -15.72234454271189, timestamp: 2022-08-20 03:10:25.154422\n",
      "resetting env. episode 9375, reward total was -13.0. running mean: -15.69512109728477, timestamp: 2022-08-20 03:10:31.430490\n",
      "resetting env. episode 9376, reward total was -19.0. running mean: -15.728169886311923, timestamp: 2022-08-20 03:10:35.988538\n",
      "resetting env. episode 9377, reward total was -16.0. running mean: -15.730888187448803, timestamp: 2022-08-20 03:10:42.298607\n",
      "resetting env. episode 9378, reward total was -19.0. running mean: -15.763579305574314, timestamp: 2022-08-20 03:10:47.522667\n",
      "resetting env. episode 9379, reward total was -15.0. running mean: -15.755943512518572, timestamp: 2022-08-20 03:10:52.339718\n",
      "resetting env. episode 9380, reward total was -18.0. running mean: -15.778384077393385, timestamp: 2022-08-20 03:10:58.466306\n",
      "resetting env. episode 9381, reward total was -17.0. running mean: -15.79060023661945, timestamp: 2022-08-20 03:11:04.212365\n",
      "resetting env. episode 9382, reward total was -16.0. running mean: -15.792694234253256, timestamp: 2022-08-20 03:11:10.548435\n",
      "resetting env. episode 9383, reward total was -9.0. running mean: -15.724767291910723, timestamp: 2022-08-20 03:11:17.938516\n",
      "resetting env. episode 9384, reward total was -10.0. running mean: -15.667519618991616, timestamp: 2022-08-20 03:11:25.958603\n",
      "resetting env. episode 9385, reward total was -18.0. running mean: -15.6908444228017, timestamp: 2022-08-20 03:11:30.239649\n",
      "resetting env. episode 9386, reward total was -19.0. running mean: -15.723935978573682, timestamp: 2022-08-20 03:11:36.187715\n",
      "resetting env. episode 9387, reward total was -14.0. running mean: -15.706696618787944, timestamp: 2022-08-20 03:11:41.445771\n",
      "resetting env. episode 9388, reward total was -18.0. running mean: -15.729629652600064, timestamp: 2022-08-20 03:11:46.618829\n",
      "resetting env. episode 9389, reward total was -15.0. running mean: -15.722333356074063, timestamp: 2022-08-20 03:11:52.209890\n",
      "resetting env. episode 9390, reward total was -13.0. running mean: -15.695110022513324, timestamp: 2022-08-20 03:11:57.207943\n",
      "resetting env. episode 9391, reward total was -16.0. running mean: -15.69815892228819, timestamp: 2022-08-20 03:12:03.293010\n",
      "resetting env. episode 9392, reward total was -15.0. running mean: -15.691177333065308, timestamp: 2022-08-20 03:12:08.976071\n",
      "resetting env. episode 9393, reward total was -11.0. running mean: -15.644265559734654, timestamp: 2022-08-20 03:12:17.420164\n",
      "resetting env. episode 9394, reward total was -17.0. running mean: -15.657822904137307, timestamp: 2022-08-20 03:12:22.202216\n",
      "resetting env. episode 9395, reward total was -10.0. running mean: -15.601244675095932, timestamp: 2022-08-20 03:12:28.639289\n",
      "resetting env. episode 9396, reward total was -15.0. running mean: -15.595232228344972, timestamp: 2022-08-20 03:12:35.425884\n",
      "resetting env. episode 9397, reward total was -14.0. running mean: -15.579279906061522, timestamp: 2022-08-20 03:12:41.193946\n",
      "resetting env. episode 9398, reward total was -17.0. running mean: -15.593487107000907, timestamp: 2022-08-20 03:12:47.390543\n",
      "resetting env. episode 9399, reward total was -15.0. running mean: -15.587552235930898, timestamp: 2022-08-20 03:12:52.591593\n",
      "resetting env. episode 9400, reward total was -15.0. running mean: -15.58167671357159, timestamp: 2022-08-20 03:12:59.052666\n",
      "resetting env. episode 9401, reward total was -12.0. running mean: -15.545859946435872, timestamp: 2022-08-20 03:13:06.180742\n",
      "resetting env. episode 9402, reward total was -16.0. running mean: -15.550401346971514, timestamp: 2022-08-20 03:13:11.913804\n",
      "resetting env. episode 9403, reward total was -14.0. running mean: -15.5348973335018, timestamp: 2022-08-20 03:13:17.036860\n",
      "resetting env. episode 9404, reward total was -15.0. running mean: -15.529548360166782, timestamp: 2022-08-20 03:13:24.505944\n",
      "resetting env. episode 9405, reward total was -9.0. running mean: -15.464252876565114, timestamp: 2022-08-20 03:13:31.706023\n",
      "resetting env. episode 9406, reward total was -17.0. running mean: -15.479610347799463, timestamp: 2022-08-20 03:13:37.620085\n",
      "resetting env. episode 9407, reward total was -15.0. running mean: -15.474814244321468, timestamp: 2022-08-20 03:13:42.710140\n",
      "resetting env. episode 9408, reward total was -20.0. running mean: -15.520066101878253, timestamp: 2022-08-20 03:13:47.622195\n",
      "resetting env. episode 9409, reward total was -15.0. running mean: -15.51486544085947, timestamp: 2022-08-20 03:13:53.054255\n",
      "resetting env. episode 9410, reward total was -13.0. running mean: -15.489716786450876, timestamp: 2022-08-20 03:13:59.189323\n",
      "resetting env. episode 9411, reward total was -20.0. running mean: -15.534819618586367, timestamp: 2022-08-20 03:14:04.278378\n",
      "resetting env. episode 9412, reward total was -11.0. running mean: -15.489471422400502, timestamp: 2022-08-20 03:14:10.775451\n",
      "resetting env. episode 9413, reward total was -15.0. running mean: -15.484576708176498, timestamp: 2022-08-20 03:14:17.444524\n",
      "resetting env. episode 9414, reward total was -17.0. running mean: -15.499730941094732, timestamp: 2022-08-20 03:14:22.185575\n",
      "resetting env. episode 9415, reward total was -18.0. running mean: -15.524733631683784, timestamp: 2022-08-20 03:14:27.239633\n",
      "resetting env. episode 9416, reward total was -16.0. running mean: -15.529486295366945, timestamp: 2022-08-20 03:14:32.401691\n",
      "resetting env. episode 9417, reward total was -14.0. running mean: -15.514191432413277, timestamp: 2022-08-20 03:14:38.670281\n",
      "resetting env. episode 9418, reward total was -14.0. running mean: -15.499049518089144, timestamp: 2022-08-20 03:14:44.852347\n",
      "resetting env. episode 9419, reward total was -16.0. running mean: -15.504059022908253, timestamp: 2022-08-20 03:14:50.790414\n",
      "resetting env. episode 9420, reward total was -16.0. running mean: -15.50901843267917, timestamp: 2022-08-20 03:14:56.212474\n",
      "resetting env. episode 9421, reward total was -7.0. running mean: -15.423928248352379, timestamp: 2022-08-20 03:15:03.386554\n",
      "resetting env. episode 9422, reward total was -13.0. running mean: -15.399688965868856, timestamp: 2022-08-20 03:15:09.213147\n",
      "resetting env. episode 9423, reward total was -19.0. running mean: -15.435692076210167, timestamp: 2022-08-20 03:15:14.701250\n",
      "resetting env. episode 9424, reward total was -19.0. running mean: -15.471335155448065, timestamp: 2022-08-20 03:15:19.741307\n",
      "resetting env. episode 9425, reward total was -17.0. running mean: -15.486621803893584, timestamp: 2022-08-20 03:15:24.926364\n",
      "resetting env. episode 9426, reward total was -13.0. running mean: -15.461755585854648, timestamp: 2022-08-20 03:15:31.206491\n",
      "resetting env. episode 9427, reward total was -21.0. running mean: -15.517138029996103, timestamp: 2022-08-20 03:15:36.659550\n",
      "resetting env. episode 9428, reward total was -20.0. running mean: -15.56196664969614, timestamp: 2022-08-20 03:15:42.960622\n",
      "resetting env. episode 9429, reward total was -11.0. running mean: -15.516346983199178, timestamp: 2022-08-20 03:15:49.294692\n",
      "resetting env. episode 9430, reward total was -14.0. running mean: -15.501183513367186, timestamp: 2022-08-20 03:15:54.539749\n",
      "resetting env. episode 9431, reward total was -13.0. running mean: -15.476171678233515, timestamp: 2022-08-20 03:16:00.808818\n",
      "resetting env. episode 9432, reward total was -18.0. running mean: -15.501409961451179, timestamp: 2022-08-20 03:16:04.721868\n",
      "resetting env. episode 9433, reward total was -20.0. running mean: -15.546395861836666, timestamp: 2022-08-20 03:16:10.046445\n",
      "resetting env. episode 9434, reward total was -8.0. running mean: -15.4709319032183, timestamp: 2022-08-20 03:16:18.165533\n",
      "resetting env. episode 9435, reward total was -17.0. running mean: -15.486222584186118, timestamp: 2022-08-20 03:16:23.384592\n",
      "resetting env. episode 9436, reward total was -15.0. running mean: -15.481360358344256, timestamp: 2022-08-20 03:16:28.527648\n",
      "resetting env. episode 9437, reward total was -17.0. running mean: -15.496546754760812, timestamp: 2022-08-20 03:16:34.659718\n",
      "resetting env. episode 9438, reward total was -18.0. running mean: -15.521581287213204, timestamp: 2022-08-20 03:16:39.557778\n",
      "resetting env. episode 9439, reward total was -16.0. running mean: -15.526365474341072, timestamp: 2022-08-20 03:16:45.685839\n",
      "resetting env. episode 9440, reward total was -10.0. running mean: -15.47110181959766, timestamp: 2022-08-20 03:16:53.368923\n",
      "resetting env. episode 9441, reward total was -18.0. running mean: -15.496390801401683, timestamp: 2022-08-20 03:16:57.499970\n",
      "resetting env. episode 9442, reward total was -13.0. running mean: -15.471426893387667, timestamp: 2022-08-20 03:17:03.175032\n",
      "resetting env. episode 9443, reward total was -9.0. running mean: -15.40671262445379, timestamp: 2022-08-20 03:17:10.124110\n",
      "resetting env. episode 9444, reward total was -19.0. running mean: -15.442645498209252, timestamp: 2022-08-20 03:17:13.998153\n",
      "resetting env. episode 9445, reward total was -19.0. running mean: -15.47821904322716, timestamp: 2022-08-20 03:17:18.448203\n",
      "resetting env. episode 9446, reward total was -17.0. running mean: -15.493436852794888, timestamp: 2022-08-20 03:17:24.823275\n",
      "resetting env. episode 9447, reward total was -13.0. running mean: -15.46850248426694, timestamp: 2022-08-20 03:17:31.234349\n",
      "resetting env. episode 9448, reward total was -14.0. running mean: -15.453817459424272, timestamp: 2022-08-20 03:17:37.665422\n",
      "resetting env. episode 9449, reward total was -16.0. running mean: -15.459279284830028, timestamp: 2022-08-20 03:17:44.111491\n",
      "resetting env. episode 9450, reward total was -15.0. running mean: -15.454686491981729, timestamp: 2022-08-20 03:17:50.958567\n",
      "resetting env. episode 9451, reward total was -19.0. running mean: -15.490139627061911, timestamp: 2022-08-20 03:17:57.165637\n",
      "resetting env. episode 9452, reward total was -19.0. running mean: -15.525238230791292, timestamp: 2022-08-20 03:18:02.446697\n",
      "resetting env. episode 9453, reward total was -15.0. running mean: -15.51998584848338, timestamp: 2022-08-20 03:18:08.062757\n",
      "resetting env. episode 9454, reward total was -16.0. running mean: -15.524785989998547, timestamp: 2022-08-20 03:18:14.197828\n",
      "resetting env. episode 9455, reward total was -15.0. running mean: -15.519538130098562, timestamp: 2022-08-20 03:18:19.330887\n",
      "resetting env. episode 9456, reward total was -10.0. running mean: -15.464342748797575, timestamp: 2022-08-20 03:18:25.802958\n",
      "resetting env. episode 9457, reward total was -15.0. running mean: -15.4596993213096, timestamp: 2022-08-20 03:18:30.717020\n",
      "resetting env. episode 9458, reward total was -17.0. running mean: -15.475102328096504, timestamp: 2022-08-20 03:18:37.867093\n",
      "resetting env. episode 9459, reward total was -16.0. running mean: -15.480351304815539, timestamp: 2022-08-20 03:18:43.383153\n",
      "resetting env. episode 9460, reward total was -19.0. running mean: -15.515547791767382, timestamp: 2022-08-20 03:18:48.727214\n",
      "resetting env. episode 9461, reward total was -13.0. running mean: -15.490392313849709, timestamp: 2022-08-20 03:18:55.247287\n",
      "resetting env. episode 9462, reward total was -10.0. running mean: -15.43548839071121, timestamp: 2022-08-20 03:19:02.575374\n",
      "resetting env. episode 9463, reward total was -14.0. running mean: -15.421133506804098, timestamp: 2022-08-20 03:19:09.193968\n",
      "resetting env. episode 9464, reward total was -19.0. running mean: -15.456922171736057, timestamp: 2022-08-20 03:19:14.856030\n",
      "resetting env. episode 9465, reward total was -14.0. running mean: -15.442352950018696, timestamp: 2022-08-20 03:19:20.404093\n",
      "resetting env. episode 9466, reward total was -15.0. running mean: -15.43792942051851, timestamp: 2022-08-20 03:19:27.534175\n",
      "resetting env. episode 9467, reward total was -15.0. running mean: -15.433550126313325, timestamp: 2022-08-20 03:19:33.414240\n",
      "resetting env. episode 9468, reward total was -13.0. running mean: -15.409214625050192, timestamp: 2022-08-20 03:19:40.332316\n",
      "resetting env. episode 9469, reward total was -17.0. running mean: -15.42512247879969, timestamp: 2022-08-20 03:19:46.562385\n",
      "resetting env. episode 9470, reward total was -12.0. running mean: -15.390871254011692, timestamp: 2022-08-20 03:19:53.608464\n",
      "resetting env. episode 9471, reward total was -10.0. running mean: -15.336962541471575, timestamp: 2022-08-20 03:20:00.864546\n",
      "resetting env. episode 9472, reward total was -19.0. running mean: -15.37359291605686, timestamp: 2022-08-20 03:20:05.882600\n",
      "resetting env. episode 9473, reward total was -15.0. running mean: -15.369856986896291, timestamp: 2022-08-20 03:20:13.242682\n",
      "resetting env. episode 9474, reward total was -17.0. running mean: -15.386158417027328, timestamp: 2022-08-20 03:20:19.144748\n",
      "resetting env. episode 9475, reward total was -12.0. running mean: -15.352296832857053, timestamp: 2022-08-20 03:20:26.181826\n",
      "resetting env. episode 9476, reward total was -17.0. running mean: -15.368773864528483, timestamp: 2022-08-20 03:20:32.604896\n",
      "resetting env. episode 9477, reward total was -18.0. running mean: -15.395086125883198, timestamp: 2022-08-20 03:20:37.687474\n",
      "resetting env. episode 9478, reward total was -18.0. running mean: -15.421135264624366, timestamp: 2022-08-20 03:20:43.339539\n",
      "resetting env. episode 9479, reward total was -17.0. running mean: -15.436923911978123, timestamp: 2022-08-20 03:20:49.762609\n",
      "resetting env. episode 9480, reward total was -18.0. running mean: -15.462554672858342, timestamp: 2022-08-20 03:20:54.735663\n",
      "resetting env. episode 9481, reward total was -15.0. running mean: -15.45792912612976, timestamp: 2022-08-20 03:21:00.608728\n",
      "resetting env. episode 9482, reward total was -15.0. running mean: -15.453349834868462, timestamp: 2022-08-20 03:21:06.145796\n",
      "resetting env. episode 9483, reward total was -18.0. running mean: -15.478816336519778, timestamp: 2022-08-20 03:21:11.482849\n",
      "resetting env. episode 9484, reward total was -13.0. running mean: -15.45402817315458, timestamp: 2022-08-20 03:21:18.290925\n",
      "resetting env. episode 9485, reward total was -17.0. running mean: -15.469487891423034, timestamp: 2022-08-20 03:21:23.958989\n",
      "resetting env. episode 9486, reward total was -18.0. running mean: -15.494793012508802, timestamp: 2022-08-20 03:21:29.418570\n",
      "resetting env. episode 9487, reward total was -16.0. running mean: -15.499845082383715, timestamp: 2022-08-20 03:21:35.463638\n",
      "resetting env. episode 9488, reward total was -15.0. running mean: -15.494846631559877, timestamp: 2022-08-20 03:21:41.019700\n",
      "resetting env. episode 9489, reward total was -19.0. running mean: -15.529898165244278, timestamp: 2022-08-20 03:21:46.719812\n",
      "resetting env. episode 9490, reward total was -15.0. running mean: -15.524599183591835, timestamp: 2022-08-20 03:21:53.429882\n",
      "resetting env. episode 9491, reward total was -21.0. running mean: -15.579353191755917, timestamp: 2022-08-20 03:22:00.029958\n",
      "resetting env. episode 9492, reward total was -16.0. running mean: -15.583559659838357, timestamp: 2022-08-20 03:22:05.596021\n",
      "resetting env. episode 9493, reward total was -14.0. running mean: -15.567724063239975, timestamp: 2022-08-20 03:22:12.248092\n",
      "resetting env. episode 9494, reward total was -16.0. running mean: -15.572046822607575, timestamp: 2022-08-20 03:22:19.320175\n",
      "resetting env. episode 9495, reward total was -18.0. running mean: -15.5963263543815, timestamp: 2022-08-20 03:22:25.309240\n",
      "resetting env. episode 9496, reward total was -14.0. running mean: -15.580363090837684, timestamp: 2022-08-20 03:22:31.684309\n",
      "resetting env. episode 9497, reward total was -14.0. running mean: -15.564559459929308, timestamp: 2022-08-20 03:22:37.425374\n",
      "resetting env. episode 9498, reward total was -15.0. running mean: -15.558913865330014, timestamp: 2022-08-20 03:22:43.215437\n",
      "resetting env. episode 9499, reward total was -11.0. running mean: -15.513324726676714, timestamp: 2022-08-20 03:22:49.874033\n",
      "resetting env. episode 9500, reward total was -4.0. running mean: -15.398191479409945, timestamp: 2022-08-20 03:22:59.527139\n",
      "resetting env. episode 9501, reward total was -15.0. running mean: -15.394209564615846, timestamp: 2022-08-20 03:23:04.785200\n",
      "resetting env. episode 9502, reward total was -15.0. running mean: -15.390267468969688, timestamp: 2022-08-20 03:23:11.678276\n",
      "resetting env. episode 9503, reward total was -20.0. running mean: -15.43636479427999, timestamp: 2022-08-20 03:23:15.965323\n",
      "resetting env. episode 9504, reward total was -17.0. running mean: -15.45200114633719, timestamp: 2022-08-20 03:23:21.336382\n",
      "resetting env. episode 9505, reward total was -14.0. running mean: -15.437481134873819, timestamp: 2022-08-20 03:23:27.251972\n",
      "resetting env. episode 9506, reward total was -19.0. running mean: -15.47310632352508, timestamp: 2022-08-20 03:23:32.511030\n",
      "resetting env. episode 9507, reward total was -15.0. running mean: -15.468375260289829, timestamp: 2022-08-20 03:23:40.008114\n",
      "resetting env. episode 9508, reward total was -17.0. running mean: -15.483691507686931, timestamp: 2022-08-20 03:23:45.240170\n",
      "resetting env. episode 9509, reward total was -14.0. running mean: -15.468854592610063, timestamp: 2022-08-20 03:23:50.824232\n",
      "resetting env. episode 9510, reward total was -14.0. running mean: -15.454166046683962, timestamp: 2022-08-20 03:23:56.973299\n",
      "resetting env. episode 9511, reward total was -13.0. running mean: -15.429624386217123, timestamp: 2022-08-20 03:24:02.720363\n",
      "resetting env. episode 9512, reward total was -17.0. running mean: -15.44532814235495, timestamp: 2022-08-20 03:24:08.133425\n",
      "resetting env. episode 9513, reward total was -15.0. running mean: -15.440874860931402, timestamp: 2022-08-20 03:24:12.171469\n",
      "resetting env. episode 9514, reward total was -14.0. running mean: -15.426466112322089, timestamp: 2022-08-20 03:24:17.326533\n",
      "resetting env. episode 9515, reward total was -19.0. running mean: -15.462201451198867, timestamp: 2022-08-20 03:24:22.613583\n",
      "resetting env. episode 9516, reward total was -19.0. running mean: -15.497579436686877, timestamp: 2022-08-20 03:24:27.928170\n",
      "resetting env. episode 9517, reward total was -13.0. running mean: -15.472603642320008, timestamp: 2022-08-20 03:24:34.343754\n",
      "resetting env. episode 9518, reward total was -17.0. running mean: -15.487877605896808, timestamp: 2022-08-20 03:24:39.211811\n",
      "resetting env. episode 9519, reward total was -17.0. running mean: -15.50299882983784, timestamp: 2022-08-20 03:24:45.901881\n",
      "resetting env. episode 9520, reward total was -13.0. running mean: -15.477968841539461, timestamp: 2022-08-20 03:24:52.543956\n",
      "resetting env. episode 9521, reward total was -15.0. running mean: -15.473189153124066, timestamp: 2022-08-20 03:24:58.954072\n",
      "resetting env. episode 9522, reward total was -19.0. running mean: -15.508457261592824, timestamp: 2022-08-20 03:25:03.938126\n",
      "resetting env. episode 9523, reward total was -15.0. running mean: -15.503372688976896, timestamp: 2022-08-20 03:25:11.467209\n",
      "resetting env. episode 9524, reward total was -17.0. running mean: -15.518338962087126, timestamp: 2022-08-20 03:25:16.494265\n",
      "resetting env. episode 9525, reward total was -12.0. running mean: -15.483155572466254, timestamp: 2022-08-20 03:25:23.803344\n",
      "resetting env. episode 9526, reward total was -13.0. running mean: -15.458324016741592, timestamp: 2022-08-20 03:25:30.701422\n",
      "resetting env. episode 9527, reward total was -15.0. running mean: -15.453740776574177, timestamp: 2022-08-20 03:25:36.536010\n",
      "resetting env. episode 9528, reward total was -13.0. running mean: -15.429203368808436, timestamp: 2022-08-20 03:25:43.207081\n",
      "resetting env. episode 9529, reward total was -17.0. running mean: -15.44491133512035, timestamp: 2022-08-20 03:25:48.249139\n",
      "resetting env. episode 9530, reward total was -15.0. running mean: -15.440462221769147, timestamp: 2022-08-20 03:25:54.112247\n",
      "resetting env. episode 9531, reward total was -16.0. running mean: -15.446057599551455, timestamp: 2022-08-20 03:25:59.782311\n",
      "resetting env. episode 9532, reward total was -16.0. running mean: -15.45159702355594, timestamp: 2022-08-20 03:26:04.579364\n",
      "resetting env. episode 9533, reward total was -12.0. running mean: -15.41708105332038, timestamp: 2022-08-20 03:26:10.467428\n",
      "resetting env. episode 9534, reward total was -18.0. running mean: -15.442910242787177, timestamp: 2022-08-20 03:26:16.645498\n",
      "resetting env. episode 9535, reward total was -16.0. running mean: -15.448481140359304, timestamp: 2022-08-20 03:26:22.417563\n",
      "resetting env. episode 9536, reward total was -14.0. running mean: -15.433996328955711, timestamp: 2022-08-20 03:26:29.373636\n",
      "resetting env. episode 9537, reward total was -17.0. running mean: -15.449656365666154, timestamp: 2022-08-20 03:26:34.807698\n",
      "resetting env. episode 9538, reward total was -11.0. running mean: -15.405159802009493, timestamp: 2022-08-20 03:26:41.600297\n",
      "resetting env. episode 9539, reward total was -12.0. running mean: -15.371108203989397, timestamp: 2022-08-20 03:26:48.439896\n",
      "resetting env. episode 9540, reward total was -11.0. running mean: -15.327397121949502, timestamp: 2022-08-20 03:26:54.942970\n",
      "resetting env. episode 9541, reward total was -18.0. running mean: -15.354123150730008, timestamp: 2022-08-20 03:27:00.531030\n",
      "resetting env. episode 9542, reward total was -15.0. running mean: -15.350581919222707, timestamp: 2022-08-20 03:27:07.381104\n",
      "resetting env. episode 9543, reward total was -18.0. running mean: -15.377076100030479, timestamp: 2022-08-20 03:27:11.582150\n",
      "resetting env. episode 9544, reward total was -15.0. running mean: -15.373305339030175, timestamp: 2022-08-20 03:27:18.061752\n",
      "resetting env. episode 9545, reward total was -18.0. running mean: -15.399572285639872, timestamp: 2022-08-20 03:27:24.606817\n",
      "resetting env. episode 9546, reward total was -17.0. running mean: -15.415576562783473, timestamp: 2022-08-20 03:27:29.748875\n",
      "resetting env. episode 9547, reward total was -14.0. running mean: -15.40142079715564, timestamp: 2022-08-20 03:27:36.192945\n",
      "resetting env. episode 9548, reward total was -15.0. running mean: -15.397406589184083, timestamp: 2022-08-20 03:27:42.005006\n",
      "resetting env. episode 9549, reward total was -15.0. running mean: -15.393432523292242, timestamp: 2022-08-20 03:27:48.144074\n",
      "resetting env. episode 9550, reward total was -19.0. running mean: -15.429498198059319, timestamp: 2022-08-20 03:27:53.406657\n",
      "resetting env. episode 9551, reward total was -20.0. running mean: -15.475203216078725, timestamp: 2022-08-20 03:27:58.612715\n",
      "resetting env. episode 9552, reward total was -17.0. running mean: -15.490451183917937, timestamp: 2022-08-20 03:28:05.793795\n",
      "resetting env. episode 9553, reward total was -13.0. running mean: -15.465546672078759, timestamp: 2022-08-20 03:28:12.450866\n",
      "resetting env. episode 9554, reward total was -19.0. running mean: -15.50089120535797, timestamp: 2022-08-20 03:28:17.484921\n",
      "resetting env. episode 9555, reward total was -17.0. running mean: -15.51588229330439, timestamp: 2022-08-20 03:28:22.289499\n",
      "resetting env. episode 9556, reward total was -12.0. running mean: -15.480723470371345, timestamp: 2022-08-20 03:28:28.367563\n",
      "resetting env. episode 9557, reward total was -18.0. running mean: -15.50591623566763, timestamp: 2022-08-20 03:28:33.396618\n",
      "resetting env. episode 9558, reward total was -16.0. running mean: -15.510857073310953, timestamp: 2022-08-20 03:28:39.736688\n",
      "resetting env. episode 9559, reward total was -21.0. running mean: -15.565748502577845, timestamp: 2022-08-20 03:28:43.968734\n",
      "resetting env. episode 9560, reward total was -16.0. running mean: -15.570091017552066, timestamp: 2022-08-20 03:28:50.302801\n",
      "resetting env. episode 9561, reward total was -17.0. running mean: -15.584390107376546, timestamp: 2022-08-20 03:28:55.391858\n",
      "resetting env. episode 9562, reward total was -19.0. running mean: -15.61854620630278, timestamp: 2022-08-20 03:29:00.113912\n",
      "resetting env. episode 9563, reward total was -17.0. running mean: -15.632360744239751, timestamp: 2022-08-20 03:29:04.447480\n",
      "resetting env. episode 9564, reward total was -16.0. running mean: -15.636037136797354, timestamp: 2022-08-20 03:29:11.716561\n",
      "resetting env. episode 9565, reward total was -20.0. running mean: -15.67967676542938, timestamp: 2022-08-20 03:29:16.793618\n",
      "resetting env. episode 9566, reward total was -13.0. running mean: -15.652879997775086, timestamp: 2022-08-20 03:29:23.421689\n",
      "resetting env. episode 9567, reward total was -17.0. running mean: -15.666351197797335, timestamp: 2022-08-20 03:29:28.451742\n",
      "resetting env. episode 9568, reward total was -17.0. running mean: -15.679687685819362, timestamp: 2022-08-20 03:29:34.135805\n",
      "resetting env. episode 9569, reward total was -18.0. running mean: -15.702890808961168, timestamp: 2022-08-20 03:29:39.244861\n",
      "resetting env. episode 9570, reward total was -18.0. running mean: -15.725861900871557, timestamp: 2022-08-20 03:29:46.002935\n",
      "resetting env. episode 9571, reward total was -13.0. running mean: -15.698603281862843, timestamp: 2022-08-20 03:29:53.582020\n",
      "resetting env. episode 9572, reward total was -17.0. running mean: -15.711617249044213, timestamp: 2022-08-20 03:29:58.529070\n",
      "resetting env. episode 9573, reward total was -15.0. running mean: -15.704501076553772, timestamp: 2022-08-20 03:30:04.923142\n",
      "resetting env. episode 9574, reward total was -19.0. running mean: -15.737456065788233, timestamp: 2022-08-20 03:30:10.860205\n",
      "resetting env. episode 9575, reward total was -17.0. running mean: -15.750081505130352, timestamp: 2022-08-20 03:30:17.081272\n",
      "resetting env. episode 9576, reward total was -6.0. running mean: -15.652580690079049, timestamp: 2022-08-20 03:30:24.988883\n",
      "resetting env. episode 9577, reward total was -19.0. running mean: -15.686054883178258, timestamp: 2022-08-20 03:30:28.985928\n",
      "resetting env. episode 9578, reward total was -16.0. running mean: -15.689194334346475, timestamp: 2022-08-20 03:30:33.794978\n",
      "resetting env. episode 9579, reward total was -11.0. running mean: -15.642302391003009, timestamp: 2022-08-20 03:30:40.969062\n",
      "resetting env. episode 9580, reward total was -16.0. running mean: -15.645879367092979, timestamp: 2022-08-20 03:30:47.247124\n",
      "resetting env. episode 9581, reward total was -17.0. running mean: -15.659420573422048, timestamp: 2022-08-20 03:30:51.875177\n",
      "resetting env. episode 9582, reward total was -16.0. running mean: -15.662826367687828, timestamp: 2022-08-20 03:30:57.607243\n",
      "resetting env. episode 9583, reward total was -19.0. running mean: -15.696198104010948, timestamp: 2022-08-20 03:31:03.117299\n",
      "resetting env. episode 9584, reward total was -15.0. running mean: -15.689236122970838, timestamp: 2022-08-20 03:31:09.378371\n",
      "resetting env. episode 9585, reward total was -15.0. running mean: -15.68234376174113, timestamp: 2022-08-20 03:31:14.337947\n",
      "resetting env. episode 9586, reward total was -16.0. running mean: -15.685520324123718, timestamp: 2022-08-20 03:31:21.290026\n",
      "resetting env. episode 9587, reward total was -19.0. running mean: -15.71866512088248, timestamp: 2022-08-20 03:31:28.708109\n",
      "resetting env. episode 9588, reward total was -11.0. running mean: -15.671478469673655, timestamp: 2022-08-20 03:31:38.338214\n",
      "resetting env. episode 9589, reward total was -7.0. running mean: -15.584763684976918, timestamp: 2022-08-20 03:31:47.378316\n",
      "resetting env. episode 9590, reward total was -15.0. running mean: -15.57891604812715, timestamp: 2022-08-20 03:31:52.392371\n",
      "resetting env. episode 9591, reward total was -16.0. running mean: -15.583126887645879, timestamp: 2022-08-20 03:31:58.007432\n",
      "resetting env. episode 9592, reward total was -19.0. running mean: -15.61729561876942, timestamp: 2022-08-20 03:32:03.492493\n",
      "resetting env. episode 9593, reward total was -17.0. running mean: -15.631122662581726, timestamp: 2022-08-20 03:32:09.076557\n",
      "resetting env. episode 9594, reward total was -15.0. running mean: -15.624811435955909, timestamp: 2022-08-20 03:32:15.813152\n",
      "resetting env. episode 9595, reward total was -14.0. running mean: -15.60856332159635, timestamp: 2022-08-20 03:32:21.211214\n",
      "resetting env. episode 9596, reward total was -13.0. running mean: -15.582477688380386, timestamp: 2022-08-20 03:32:27.103277\n",
      "resetting env. episode 9597, reward total was -14.0. running mean: -15.566652911496583, timestamp: 2022-08-20 03:32:33.521870\n",
      "resetting env. episode 9598, reward total was -14.0. running mean: -15.550986382381618, timestamp: 2022-08-20 03:32:39.229934\n",
      "resetting env. episode 9599, reward total was -18.0. running mean: -15.575476518557801, timestamp: 2022-08-20 03:32:46.184011\n",
      "resetting env. episode 9600, reward total was -19.0. running mean: -15.609721753372222, timestamp: 2022-08-20 03:32:51.808072\n",
      "resetting env. episode 9601, reward total was -19.0. running mean: -15.6436245358385, timestamp: 2022-08-20 03:32:56.187123\n",
      "resetting env. episode 9602, reward total was -15.0. running mean: -15.637188290480115, timestamp: 2022-08-20 03:33:02.631196\n",
      "resetting env. episode 9603, reward total was -17.0. running mean: -15.650816407575313, timestamp: 2022-08-20 03:33:07.923777\n",
      "resetting env. episode 9604, reward total was -19.0. running mean: -15.68430824349956, timestamp: 2022-08-20 03:33:13.583841\n",
      "resetting env. episode 9605, reward total was -15.0. running mean: -15.677465161064564, timestamp: 2022-08-20 03:33:19.598906\n",
      "resetting env. episode 9606, reward total was -13.0. running mean: -15.65069050945392, timestamp: 2022-08-20 03:33:26.407985\n",
      "resetting env. episode 9607, reward total was -18.0. running mean: -15.67418360435938, timestamp: 2022-08-20 03:33:32.332050\n",
      "resetting env. episode 9608, reward total was -17.0. running mean: -15.687441768315786, timestamp: 2022-08-20 03:33:39.130649\n",
      "resetting env. episode 9609, reward total was -15.0. running mean: -15.680567350632629, timestamp: 2022-08-20 03:33:45.287717\n",
      "resetting env. episode 9610, reward total was -15.0. running mean: -15.673761677126302, timestamp: 2022-08-20 03:33:51.397785\n",
      "resetting env. episode 9611, reward total was -13.0. running mean: -15.64702406035504, timestamp: 2022-08-20 03:33:58.506876\n",
      "resetting env. episode 9612, reward total was -15.0. running mean: -15.64055381975149, timestamp: 2022-08-20 03:34:04.777936\n",
      "resetting env. episode 9613, reward total was -16.0. running mean: -15.644148281553976, timestamp: 2022-08-20 03:34:10.878007\n",
      "resetting env. episode 9614, reward total was -15.0. running mean: -15.637706798738437, timestamp: 2022-08-20 03:34:17.856082\n",
      "resetting env. episode 9615, reward total was -16.0. running mean: -15.641329730751053, timestamp: 2022-08-20 03:34:24.907160\n",
      "resetting env. episode 9616, reward total was -11.0. running mean: -15.594916433443542, timestamp: 2022-08-20 03:34:31.299756\n",
      "resetting env. episode 9617, reward total was -19.0. running mean: -15.628967269109106, timestamp: 2022-08-20 03:34:35.812807\n",
      "resetting env. episode 9618, reward total was -17.0. running mean: -15.642677596418014, timestamp: 2022-08-20 03:34:42.658884\n",
      "resetting env. episode 9619, reward total was -14.0. running mean: -15.626250820453835, timestamp: 2022-08-20 03:34:48.922954\n",
      "resetting env. episode 9620, reward total was -15.0. running mean: -15.619988312249298, timestamp: 2022-08-20 03:34:54.493539\n",
      "resetting env. episode 9621, reward total was -15.0. running mean: -15.613788429126805, timestamp: 2022-08-20 03:34:59.956601\n",
      "resetting env. episode 9622, reward total was -11.0. running mean: -15.567650544835535, timestamp: 2022-08-20 03:35:05.992670\n",
      "resetting env. episode 9623, reward total was -15.0. running mean: -15.56197403938718, timestamp: 2022-08-20 03:35:13.688275\n",
      "resetting env. episode 9624, reward total was -18.0. running mean: -15.586354298993308, timestamp: 2022-08-20 03:35:19.158336\n",
      "resetting env. episode 9625, reward total was -15.0. running mean: -15.580490756003375, timestamp: 2022-08-20 03:35:24.807927\n",
      "resetting env. episode 9626, reward total was -21.0. running mean: -15.634685848443342, timestamp: 2022-08-20 03:35:30.366989\n",
      "resetting env. episode 9627, reward total was -14.0. running mean: -15.61833898995891, timestamp: 2022-08-20 03:35:38.232075\n",
      "resetting env. episode 9628, reward total was -14.0. running mean: -15.602155600059321, timestamp: 2022-08-20 03:35:46.023688\n",
      "resetting env. episode 9629, reward total was -15.0. running mean: -15.596134044058727, timestamp: 2022-08-20 03:35:53.260771\n",
      "resetting env. episode 9630, reward total was -16.0. running mean: -15.60017270361814, timestamp: 2022-08-20 03:36:00.993377\n",
      "resetting env. episode 9631, reward total was -21.0. running mean: -15.654170976581959, timestamp: 2022-08-20 03:36:05.909432\n",
      "resetting env. episode 9632, reward total was -19.0. running mean: -15.687629266816138, timestamp: 2022-08-20 03:36:12.571508\n",
      "resetting env. episode 9633, reward total was -18.0. running mean: -15.710752974147976, timestamp: 2022-08-20 03:36:18.404574\n",
      "resetting env. episode 9634, reward total was -18.0. running mean: -15.733645444406497, timestamp: 2022-08-20 03:36:25.485180\n",
      "resetting env. episode 9635, reward total was -17.0. running mean: -15.746308989962431, timestamp: 2022-08-20 03:36:30.857238\n",
      "resetting env. episode 9636, reward total was -15.0. running mean: -15.738845900062808, timestamp: 2022-08-20 03:36:38.690330\n",
      "resetting env. episode 9637, reward total was -17.0. running mean: -15.751457441062179, timestamp: 2022-08-20 03:36:46.964946\n",
      "resetting env. episode 9638, reward total was -15.0. running mean: -15.743942866651558, timestamp: 2022-08-20 03:36:55.497040\n",
      "resetting env. episode 9639, reward total was -17.0. running mean: -15.756503437985042, timestamp: 2022-08-20 03:37:01.006105\n",
      "resetting env. episode 9640, reward total was -13.0. running mean: -15.728938403605193, timestamp: 2022-08-20 03:37:07.898179\n",
      "resetting env. episode 9641, reward total was -16.0. running mean: -15.731649019569142, timestamp: 2022-08-20 03:37:15.979269\n",
      "resetting env. episode 9642, reward total was -13.0. running mean: -15.70433252937345, timestamp: 2022-08-20 03:37:24.647369\n",
      "resetting env. episode 9643, reward total was -17.0. running mean: -15.717289204079716, timestamp: 2022-08-20 03:37:31.288441\n",
      "resetting env. episode 9644, reward total was -16.0. running mean: -15.720116312038918, timestamp: 2022-08-20 03:37:36.613500\n",
      "resetting env. episode 9645, reward total was -16.0. running mean: -15.72291514891853, timestamp: 2022-08-20 03:37:42.773570\n",
      "resetting env. episode 9646, reward total was -19.0. running mean: -15.755685997429344, timestamp: 2022-08-20 03:37:47.080144\n",
      "resetting env. episode 9647, reward total was -15.0. running mean: -15.74812913745505, timestamp: 2022-08-20 03:37:53.680215\n",
      "resetting env. episode 9648, reward total was -11.0. running mean: -15.7006478460805, timestamp: 2022-08-20 03:38:00.608810\n",
      "resetting env. episode 9649, reward total was -14.0. running mean: -15.683641367619696, timestamp: 2022-08-20 03:38:06.352923\n",
      "resetting env. episode 9650, reward total was -16.0. running mean: -15.686804953943499, timestamp: 2022-08-20 03:38:13.702006\n",
      "resetting env. episode 9651, reward total was -12.0. running mean: -15.649936904404063, timestamp: 2022-08-20 03:38:21.078613\n",
      "resetting env. episode 9652, reward total was -17.0. running mean: -15.663437535360023, timestamp: 2022-08-20 03:38:26.206201\n",
      "resetting env. episode 9653, reward total was -10.0. running mean: -15.606803160006422, timestamp: 2022-08-20 03:38:34.537816\n",
      "resetting env. episode 9654, reward total was -18.0. running mean: -15.630735128406357, timestamp: 2022-08-20 03:38:40.617884\n",
      "resetting env. episode 9655, reward total was -19.0. running mean: -15.664427777122294, timestamp: 2022-08-20 03:38:46.315952\n",
      "resetting env. episode 9656, reward total was -15.0. running mean: -15.657783499351071, timestamp: 2022-08-20 03:38:53.899036\n",
      "resetting env. episode 9657, reward total was -15.0. running mean: -15.65120566435756, timestamp: 2022-08-20 03:39:00.111630\n",
      "resetting env. episode 9658, reward total was -15.0. running mean: -15.644693607713984, timestamp: 2022-08-20 03:39:06.595705\n",
      "resetting env. episode 9659, reward total was -15.0. running mean: -15.638246671636844, timestamp: 2022-08-20 03:39:12.978773\n",
      "resetting env. episode 9660, reward total was -12.0. running mean: -15.601864204920474, timestamp: 2022-08-20 03:39:20.682859\n",
      "resetting env. episode 9661, reward total was -18.0. running mean: -15.62584556287127, timestamp: 2022-08-20 03:39:26.145921\n",
      "resetting env. episode 9662, reward total was -15.0. running mean: -15.619587107242557, timestamp: 2022-08-20 03:39:31.604981\n",
      "resetting env. episode 9663, reward total was -11.0. running mean: -15.573391236170131, timestamp: 2022-08-20 03:39:37.862051\n",
      "resetting env. episode 9664, reward total was -15.0. running mean: -15.56765732380843, timestamp: 2022-08-20 03:39:43.716117\n",
      "resetting env. episode 9665, reward total was -14.0. running mean: -15.551980750570346, timestamp: 2022-08-20 03:39:50.333191\n",
      "resetting env. episode 9666, reward total was -16.0. running mean: -15.556460943064643, timestamp: 2022-08-20 03:39:54.973240\n",
      "resetting env. episode 9667, reward total was -17.0. running mean: -15.570896333633996, timestamp: 2022-08-20 03:39:59.377289\n",
      "resetting env. episode 9668, reward total was -18.0. running mean: -15.595187370297657, timestamp: 2022-08-20 03:40:04.760351\n",
      "resetting env. episode 9669, reward total was -13.0. running mean: -15.56923549659468, timestamp: 2022-08-20 03:40:12.177432\n",
      "resetting env. episode 9670, reward total was -16.0. running mean: -15.573543141628734, timestamp: 2022-08-20 03:40:19.103512\n",
      "resetting env. episode 9671, reward total was -12.0. running mean: -15.537807710212446, timestamp: 2022-08-20 03:40:26.441593\n",
      "resetting env. episode 9672, reward total was -16.0. running mean: -15.542429633110322, timestamp: 2022-08-20 03:40:33.200665\n",
      "resetting env. episode 9673, reward total was -17.0. running mean: -15.557005336779218, timestamp: 2022-08-20 03:40:39.298732\n",
      "resetting env. episode 9674, reward total was -16.0. running mean: -15.561435283411425, timestamp: 2022-08-20 03:40:46.029808\n",
      "resetting env. episode 9675, reward total was -14.0. running mean: -15.545820930577312, timestamp: 2022-08-20 03:40:52.721881\n",
      "resetting env. episode 9676, reward total was -8.0. running mean: -15.470362721271538, timestamp: 2022-08-20 03:40:59.750959\n",
      "resetting env. episode 9677, reward total was -11.0. running mean: -15.425659094058823, timestamp: 2022-08-20 03:41:08.073053\n",
      "resetting env. episode 9678, reward total was -17.0. running mean: -15.441402503118233, timestamp: 2022-08-20 03:41:13.590115\n",
      "resetting env. episode 9679, reward total was -15.0. running mean: -15.436988478087052, timestamp: 2022-08-20 03:41:19.697179\n",
      "resetting env. episode 9680, reward total was -16.0. running mean: -15.442618593306182, timestamp: 2022-08-20 03:41:25.441250\n",
      "resetting env. episode 9681, reward total was -16.0. running mean: -15.44819240737312, timestamp: 2022-08-20 03:41:30.568301\n",
      "resetting env. episode 9682, reward total was -20.0. running mean: -15.493710483299388, timestamp: 2022-08-20 03:41:35.386356\n",
      "resetting env. episode 9683, reward total was -15.0. running mean: -15.488773378466394, timestamp: 2022-08-20 03:41:41.119417\n",
      "resetting env. episode 9684, reward total was -17.0. running mean: -15.50388564468173, timestamp: 2022-08-20 03:41:47.721492\n",
      "resetting env. episode 9685, reward total was -19.0. running mean: -15.538846788234913, timestamp: 2022-08-20 03:41:52.598545\n",
      "resetting env. episode 9686, reward total was -17.0. running mean: -15.553458320352563, timestamp: 2022-08-20 03:41:57.964606\n",
      "resetting env. episode 9687, reward total was -19.0. running mean: -15.587923737149037, timestamp: 2022-08-20 03:42:02.931664\n",
      "resetting env. episode 9688, reward total was -17.0. running mean: -15.602044499777547, timestamp: 2022-08-20 03:42:08.313722\n",
      "resetting env. episode 9689, reward total was -14.0. running mean: -15.586024054779772, timestamp: 2022-08-20 03:42:13.453780\n",
      "resetting env. episode 9690, reward total was -18.0. running mean: -15.610163814231974, timestamp: 2022-08-20 03:42:18.600834\n",
      "resetting env. episode 9691, reward total was -19.0. running mean: -15.644062176089655, timestamp: 2022-08-20 03:42:25.989916\n",
      "resetting env. episode 9692, reward total was -17.0. running mean: -15.657621554328758, timestamp: 2022-08-20 03:42:31.654981\n",
      "resetting env. episode 9693, reward total was -11.0. running mean: -15.61104533878547, timestamp: 2022-08-20 03:42:37.882051\n",
      "resetting env. episode 9694, reward total was -13.0. running mean: -15.584934885397615, timestamp: 2022-08-20 03:42:43.822115\n",
      "resetting env. episode 9695, reward total was -20.0. running mean: -15.629085536543638, timestamp: 2022-08-20 03:42:48.658167\n",
      "resetting env. episode 9696, reward total was -14.0. running mean: -15.612794681178203, timestamp: 2022-08-20 03:42:54.309233\n",
      "resetting env. episode 9697, reward total was -15.0. running mean: -15.60666673436642, timestamp: 2022-08-20 03:42:59.948292\n",
      "resetting env. episode 9698, reward total was -19.0. running mean: -15.640600067022756, timestamp: 2022-08-20 03:43:05.326351\n",
      "resetting env. episode 9699, reward total was -14.0. running mean: -15.62419406635253, timestamp: 2022-08-20 03:43:11.566419\n",
      "resetting env. episode 9700, reward total was -15.0. running mean: -15.617952125689005, timestamp: 2022-08-20 03:43:18.512495\n",
      "resetting env. episode 9701, reward total was -21.0. running mean: -15.671772604432116, timestamp: 2022-08-20 03:43:23.156550\n",
      "resetting env. episode 9702, reward total was -17.0. running mean: -15.685054878387794, timestamp: 2022-08-20 03:43:28.151602\n",
      "resetting env. episode 9703, reward total was -18.0. running mean: -15.708204329603916, timestamp: 2022-08-20 03:43:34.115670\n",
      "resetting env. episode 9704, reward total was -13.0. running mean: -15.681122286307877, timestamp: 2022-08-20 03:43:40.849743\n",
      "resetting env. episode 9705, reward total was -18.0. running mean: -15.704311063444798, timestamp: 2022-08-20 03:43:46.541803\n",
      "resetting env. episode 9706, reward total was -14.0. running mean: -15.68726795281035, timestamp: 2022-08-20 03:43:52.175866\n",
      "resetting env. episode 9707, reward total was -13.0. running mean: -15.660395273282248, timestamp: 2022-08-20 03:43:58.094933\n",
      "resetting env. episode 9708, reward total was -11.0. running mean: -15.613791320549424, timestamp: 2022-08-20 03:44:03.745995\n",
      "resetting env. episode 9709, reward total was -18.0. running mean: -15.63765340734393, timestamp: 2022-08-20 03:44:10.225068\n",
      "resetting env. episode 9710, reward total was -18.0. running mean: -15.66127687327049, timestamp: 2022-08-20 03:44:19.459168\n",
      "resetting env. episode 9711, reward total was -15.0. running mean: -15.654664104537785, timestamp: 2022-08-20 03:44:26.123241\n",
      "resetting env. episode 9712, reward total was -18.0. running mean: -15.678117463492407, timestamp: 2022-08-20 03:44:36.000351\n",
      "resetting env. episode 9713, reward total was -18.0. running mean: -15.701336288857483, timestamp: 2022-08-20 03:44:44.574443\n",
      "resetting env. episode 9714, reward total was -18.0. running mean: -15.724322925968908, timestamp: 2022-08-20 03:44:49.874502\n",
      "resetting env. episode 9715, reward total was -13.0. running mean: -15.697079696709219, timestamp: 2022-08-20 03:44:56.208573\n",
      "resetting env. episode 9716, reward total was -15.0. running mean: -15.690108899742127, timestamp: 2022-08-20 03:45:02.463640\n",
      "resetting env. episode 9717, reward total was -16.0. running mean: -15.693207810744704, timestamp: 2022-08-20 03:45:07.067692\n",
      "resetting env. episode 9718, reward total was -16.0. running mean: -15.696275732637258, timestamp: 2022-08-20 03:45:11.648744\n",
      "resetting env. episode 9719, reward total was -17.0. running mean: -15.709312975310885, timestamp: 2022-08-20 03:45:19.205823\n",
      "resetting env. episode 9720, reward total was -17.0. running mean: -15.722219845557776, timestamp: 2022-08-20 03:45:24.948888\n",
      "resetting env. episode 9721, reward total was -12.0. running mean: -15.684997647102197, timestamp: 2022-08-20 03:45:32.581972\n",
      "resetting env. episode 9722, reward total was -20.0. running mean: -15.728147670631174, timestamp: 2022-08-20 03:45:37.285023\n",
      "resetting env. episode 9723, reward total was -14.0. running mean: -15.710866193924863, timestamp: 2022-08-20 03:45:42.679084\n",
      "resetting env. episode 9724, reward total was -17.0. running mean: -15.723757531985614, timestamp: 2022-08-20 03:45:46.684127\n",
      "resetting env. episode 9725, reward total was -21.0. running mean: -15.776519956665759, timestamp: 2022-08-20 03:45:51.492177\n",
      "resetting env. episode 9726, reward total was -13.0. running mean: -15.748754757099102, timestamp: 2022-08-20 03:45:57.945249\n",
      "resetting env. episode 9727, reward total was -17.0. running mean: -15.76126720952811, timestamp: 2022-08-20 03:46:03.656311\n",
      "resetting env. episode 9728, reward total was -13.0. running mean: -15.73365453743283, timestamp: 2022-08-20 03:46:10.367384\n",
      "resetting env. episode 9729, reward total was -16.0. running mean: -15.736317992058503, timestamp: 2022-08-20 03:46:16.368450\n",
      "resetting env. episode 9730, reward total was -14.0. running mean: -15.718954812137918, timestamp: 2022-08-20 03:46:22.745254\n",
      "resetting env. episode 9731, reward total was -18.0. running mean: -15.741765264016538, timestamp: 2022-08-20 03:46:28.943321\n",
      "resetting env. episode 9732, reward total was -15.0. running mean: -15.734347611376373, timestamp: 2022-08-20 03:46:35.066386\n",
      "resetting env. episode 9733, reward total was -15.0. running mean: -15.727004135262609, timestamp: 2022-08-20 03:46:42.432470\n",
      "resetting env. episode 9734, reward total was -13.0. running mean: -15.699734093909983, timestamp: 2022-08-20 03:46:49.197061\n",
      "resetting env. episode 9735, reward total was -18.0. running mean: -15.722736752970883, timestamp: 2022-08-20 03:46:53.903115\n",
      "resetting env. episode 9736, reward total was -17.0. running mean: -15.735509385441175, timestamp: 2022-08-20 03:47:00.831193\n",
      "resetting env. episode 9737, reward total was -15.0. running mean: -15.728154291586764, timestamp: 2022-08-20 03:47:06.029249\n",
      "resetting env. episode 9738, reward total was -12.0. running mean: -15.690872748670895, timestamp: 2022-08-20 03:47:11.996318\n",
      "resetting env. episode 9739, reward total was -15.0. running mean: -15.683964021184186, timestamp: 2022-08-20 03:47:18.253384\n",
      "resetting env. episode 9740, reward total was -16.0. running mean: -15.687124380972344, timestamp: 2022-08-20 03:47:24.643455\n",
      "resetting env. episode 9741, reward total was -14.0. running mean: -15.670253137162621, timestamp: 2022-08-20 03:47:30.710523\n",
      "resetting env. episode 9742, reward total was -11.0. running mean: -15.623550605790994, timestamp: 2022-08-20 03:47:37.651598\n",
      "resetting env. episode 9743, reward total was -11.0. running mean: -15.577315099733083, timestamp: 2022-08-20 03:47:45.005680\n",
      "resetting env. episode 9744, reward total was -17.0. running mean: -15.591541948735752, timestamp: 2022-08-20 03:47:51.893753\n",
      "resetting env. episode 9745, reward total was -16.0. running mean: -15.595626529248396, timestamp: 2022-08-20 03:47:57.157821\n",
      "resetting env. episode 9746, reward total was -15.0. running mean: -15.589670263955911, timestamp: 2022-08-20 03:48:03.967886\n",
      "resetting env. episode 9747, reward total was -13.0. running mean: -15.563773561316353, timestamp: 2022-08-20 03:48:10.985963\n",
      "resetting env. episode 9748, reward total was -18.0. running mean: -15.588135825703189, timestamp: 2022-08-20 03:48:16.771028\n",
      "resetting env. episode 9749, reward total was -19.0. running mean: -15.622254467446156, timestamp: 2022-08-20 03:48:23.486102\n",
      "resetting env. episode 9750, reward total was -19.0. running mean: -15.656031922771694, timestamp: 2022-08-20 03:48:28.627159\n",
      "resetting env. episode 9751, reward total was -13.0. running mean: -15.629471603543978, timestamp: 2022-08-20 03:48:34.410226\n",
      "resetting env. episode 9752, reward total was -16.0. running mean: -15.633176887508538, timestamp: 2022-08-20 03:48:41.497304\n",
      "resetting env. episode 9753, reward total was -11.0. running mean: -15.586845118633452, timestamp: 2022-08-20 03:48:48.706386\n",
      "resetting env. episode 9754, reward total was -12.0. running mean: -15.550976667447117, timestamp: 2022-08-20 03:48:56.565470\n",
      "resetting env. episode 9755, reward total was -17.0. running mean: -15.565466900772645, timestamp: 2022-08-20 03:49:03.459546\n",
      "resetting env. episode 9756, reward total was -14.0. running mean: -15.54981223176492, timestamp: 2022-08-20 03:49:09.386612\n",
      "resetting env. episode 9757, reward total was -15.0. running mean: -15.54431410944727, timestamp: 2022-08-20 03:49:15.595205\n",
      "resetting env. episode 9758, reward total was -17.0. running mean: -15.558870968352798, timestamp: 2022-08-20 03:49:21.893273\n",
      "resetting env. episode 9759, reward total was -16.0. running mean: -15.56328225866927, timestamp: 2022-08-20 03:49:28.512871\n",
      "resetting env. episode 9760, reward total was -17.0. running mean: -15.577649436082577, timestamp: 2022-08-20 03:49:35.006940\n",
      "resetting env. episode 9761, reward total was -12.0. running mean: -15.541872941721751, timestamp: 2022-08-20 03:49:43.590038\n",
      "resetting env. episode 9762, reward total was -16.0. running mean: -15.546454212304534, timestamp: 2022-08-20 03:49:49.094098\n",
      "resetting env. episode 9763, reward total was -18.0. running mean: -15.570989670181488, timestamp: 2022-08-20 03:49:56.863183\n",
      "resetting env. episode 9764, reward total was -17.0. running mean: -15.585279773479673, timestamp: 2022-08-20 03:50:02.248771\n",
      "resetting env. episode 9765, reward total was -15.0. running mean: -15.579426975744877, timestamp: 2022-08-20 03:50:08.677841\n",
      "resetting env. episode 9766, reward total was -17.0. running mean: -15.593632705987428, timestamp: 2022-08-20 03:50:15.313915\n",
      "resetting env. episode 9767, reward total was -13.0. running mean: -15.567696378927554, timestamp: 2022-08-20 03:50:21.623513\n",
      "resetting env. episode 9768, reward total was -13.0. running mean: -15.54201941513828, timestamp: 2022-08-20 03:50:27.498579\n",
      "resetting env. episode 9769, reward total was -17.0. running mean: -15.556599220986897, timestamp: 2022-08-20 03:50:34.154654\n",
      "resetting env. episode 9770, reward total was -19.0. running mean: -15.591033228777027, timestamp: 2022-08-20 03:50:39.490713\n",
      "resetting env. episode 9771, reward total was -18.0. running mean: -15.615122896489256, timestamp: 2022-08-20 03:50:46.789796\n",
      "resetting env. episode 9772, reward total was -18.0. running mean: -15.638971667524363, timestamp: 2022-08-20 03:50:52.146854\n",
      "resetting env. episode 9773, reward total was -17.0. running mean: -15.652581950849118, timestamp: 2022-08-20 03:50:57.815918\n",
      "resetting env. episode 9774, reward total was -17.0. running mean: -15.666056131340627, timestamp: 2022-08-20 03:51:03.571983\n",
      "resetting env. episode 9775, reward total was -16.0. running mean: -15.66939557002722, timestamp: 2022-08-20 03:51:10.247061\n",
      "resetting env. episode 9776, reward total was -16.0. running mean: -15.672701614326948, timestamp: 2022-08-20 03:51:15.442118\n",
      "resetting env. episode 9777, reward total was -16.0. running mean: -15.675974598183679, timestamp: 2022-08-20 03:51:22.574196\n",
      "resetting env. episode 9778, reward total was -16.0. running mean: -15.679214852201842, timestamp: 2022-08-20 03:51:29.280272\n",
      "resetting env. episode 9779, reward total was -15.0. running mean: -15.672422703679823, timestamp: 2022-08-20 03:51:35.311337\n",
      "resetting env. episode 9780, reward total was -14.0. running mean: -15.655698476643025, timestamp: 2022-08-20 03:51:41.266404\n",
      "resetting env. episode 9781, reward total was -14.0. running mean: -15.639141491876595, timestamp: 2022-08-20 03:51:48.610014\n",
      "resetting env. episode 9782, reward total was -17.0. running mean: -15.65275007695783, timestamp: 2022-08-20 03:51:57.263111\n",
      "resetting env. episode 9783, reward total was -20.0. running mean: -15.69622257618825, timestamp: 2022-08-20 03:52:04.303187\n",
      "resetting env. episode 9784, reward total was -17.0. running mean: -15.709260350426367, timestamp: 2022-08-20 03:52:10.108253\n",
      "resetting env. episode 9785, reward total was -11.0. running mean: -15.662167746922103, timestamp: 2022-08-20 03:52:17.297335\n",
      "resetting env. episode 9786, reward total was -17.0. running mean: -15.675546069452881, timestamp: 2022-08-20 03:52:24.013409\n",
      "resetting env. episode 9787, reward total was -12.0. running mean: -15.638790608758352, timestamp: 2022-08-20 03:52:31.571493\n",
      "resetting env. episode 9788, reward total was -9.0. running mean: -15.572402702670768, timestamp: 2022-08-20 03:52:38.934106\n",
      "resetting env. episode 9789, reward total was -17.0. running mean: -15.58667867564406, timestamp: 2022-08-20 03:52:43.777159\n",
      "resetting env. episode 9790, reward total was -17.0. running mean: -15.60081188888762, timestamp: 2022-08-20 03:52:50.149751\n",
      "resetting env. episode 9791, reward total was -15.0. running mean: -15.594803769998745, timestamp: 2022-08-20 03:52:55.772823\n",
      "resetting env. episode 9792, reward total was -15.0. running mean: -15.588855732298757, timestamp: 2022-08-20 03:53:02.705891\n",
      "resetting env. episode 9793, reward total was -15.0. running mean: -15.58296717497577, timestamp: 2022-08-20 03:53:10.027974\n",
      "resetting env. episode 9794, reward total was -11.0. running mean: -15.537137503226012, timestamp: 2022-08-20 03:53:16.224045\n",
      "resetting env. episode 9795, reward total was -11.0. running mean: -15.49176612819375, timestamp: 2022-08-20 03:53:22.567118\n",
      "resetting env. episode 9796, reward total was -19.0. running mean: -15.526848466911813, timestamp: 2022-08-20 03:53:27.820699\n",
      "resetting env. episode 9797, reward total was -15.0. running mean: -15.521579982242695, timestamp: 2022-08-20 03:53:34.126772\n",
      "resetting env. episode 9798, reward total was -17.0. running mean: -15.536364182420268, timestamp: 2022-08-20 03:53:40.294840\n",
      "resetting env. episode 9799, reward total was -11.0. running mean: -15.491000540596065, timestamp: 2022-08-20 03:53:46.217907\n",
      "resetting env. episode 9800, reward total was -18.0. running mean: -15.516090535190104, timestamp: 2022-08-20 03:53:52.264505\n",
      "resetting env. episode 9801, reward total was -15.0. running mean: -15.510929629838204, timestamp: 2022-08-20 03:53:57.824572\n",
      "resetting env. episode 9802, reward total was -16.0. running mean: -15.515820333539821, timestamp: 2022-08-20 03:54:03.261630\n",
      "resetting env. episode 9803, reward total was -16.0. running mean: -15.520662130204423, timestamp: 2022-08-20 03:54:10.936239\n",
      "resetting env. episode 9804, reward total was -9.0. running mean: -15.455455508902379, timestamp: 2022-08-20 03:54:18.177839\n",
      "resetting env. episode 9805, reward total was -16.0. running mean: -15.460900953813354, timestamp: 2022-08-20 03:54:24.433910\n",
      "resetting env. episode 9806, reward total was -14.0. running mean: -15.44629194427522, timestamp: 2022-08-20 03:54:30.287976\n",
      "resetting env. episode 9807, reward total was -13.0. running mean: -15.42182902483247, timestamp: 2022-08-20 03:54:37.042052\n",
      "resetting env. episode 9808, reward total was -14.0. running mean: -15.407610734584145, timestamp: 2022-08-20 03:54:43.104116\n",
      "resetting env. episode 9809, reward total was -16.0. running mean: -15.413534627238302, timestamp: 2022-08-20 03:54:48.366700\n",
      "resetting env. episode 9810, reward total was -15.0. running mean: -15.40939928096592, timestamp: 2022-08-20 03:54:54.212761\n",
      "resetting env. episode 9811, reward total was -15.0. running mean: -15.40530528815626, timestamp: 2022-08-20 03:55:02.522377\n",
      "resetting env. episode 9812, reward total was -15.0. running mean: -15.401252235274697, timestamp: 2022-08-20 03:55:08.303485\n",
      "resetting env. episode 9813, reward total was -18.0. running mean: -15.42723971292195, timestamp: 2022-08-20 03:55:14.596079\n",
      "resetting env. episode 9814, reward total was -17.0. running mean: -15.44296731579273, timestamp: 2022-08-20 03:55:20.010671\n",
      "resetting env. episode 9815, reward total was -8.0. running mean: -15.368537642634802, timestamp: 2022-08-20 03:55:28.379758\n",
      "resetting env. episode 9816, reward total was -8.0. running mean: -15.294852266208455, timestamp: 2022-08-20 03:55:36.139844\n",
      "resetting env. episode 9817, reward total was -15.0. running mean: -15.29190374354637, timestamp: 2022-08-20 03:55:42.503916\n",
      "resetting env. episode 9818, reward total was -18.0. running mean: -15.318984706110907, timestamp: 2022-08-20 03:55:49.543993\n",
      "resetting env. episode 9819, reward total was -12.0. running mean: -15.285794859049798, timestamp: 2022-08-20 03:55:56.520591\n",
      "resetting env. episode 9820, reward total was -8.0. running mean: -15.2129369104593, timestamp: 2022-08-20 03:56:04.040675\n",
      "resetting env. episode 9821, reward total was -17.0. running mean: -15.230807541354707, timestamp: 2022-08-20 03:56:10.209745\n",
      "resetting env. episode 9822, reward total was -17.0. running mean: -15.24849946594116, timestamp: 2022-08-20 03:56:16.574815\n",
      "resetting env. episode 9823, reward total was -13.0. running mean: -15.226014471281749, timestamp: 2022-08-20 03:56:23.945899\n",
      "resetting env. episode 9824, reward total was -14.0. running mean: -15.213754326568932, timestamp: 2022-08-20 03:56:30.267969\n",
      "resetting env. episode 9825, reward total was -21.0. running mean: -15.271616783303243, timestamp: 2022-08-20 03:56:34.677017\n",
      "resetting env. episode 9826, reward total was -16.0. running mean: -15.27890061547021, timestamp: 2022-08-20 03:56:39.693598\n",
      "resetting env. episode 9827, reward total was -17.0. running mean: -15.296111609315508, timestamp: 2022-08-20 03:56:46.152198\n",
      "resetting env. episode 9828, reward total was -9.0. running mean: -15.233150493222352, timestamp: 2022-08-20 03:56:54.212284\n",
      "resetting env. episode 9829, reward total was -17.0. running mean: -15.250818988290128, timestamp: 2022-08-20 03:56:59.988348\n",
      "resetting env. episode 9830, reward total was -10.0. running mean: -15.198310798407226, timestamp: 2022-08-20 03:57:06.912949\n",
      "resetting env. episode 9831, reward total was -13.0. running mean: -15.176327690423154, timestamp: 2022-08-20 03:57:15.401045\n",
      "resetting env. episode 9832, reward total was -15.0. running mean: -15.174564413518922, timestamp: 2022-08-20 03:57:22.671125\n",
      "resetting env. episode 9833, reward total was -15.0. running mean: -15.172818769383733, timestamp: 2022-08-20 03:57:28.978718\n",
      "resetting env. episode 9834, reward total was -13.0. running mean: -15.151090581689896, timestamp: 2022-08-20 03:57:36.072799\n",
      "resetting env. episode 9835, reward total was -16.0. running mean: -15.159579675872997, timestamp: 2022-08-20 03:57:41.975913\n",
      "resetting env. episode 9836, reward total was -14.0. running mean: -15.147983879114268, timestamp: 2022-08-20 03:57:48.629033\n",
      "resetting env. episode 9837, reward total was -14.0. running mean: -15.136504040323125, timestamp: 2022-08-20 03:57:54.870103\n",
      "resetting env. episode 9838, reward total was -18.0. running mean: -15.165138999919893, timestamp: 2022-08-20 03:58:01.212223\n",
      "resetting env. episode 9839, reward total was -13.0. running mean: -15.143487609920696, timestamp: 2022-08-20 03:58:07.926867\n",
      "resetting env. episode 9840, reward total was -9.0. running mean: -15.082052733821488, timestamp: 2022-08-20 03:58:15.071998\n",
      "resetting env. episode 9841, reward total was -15.0. running mean: -15.081232206483273, timestamp: 2022-08-20 03:58:21.464067\n",
      "resetting env. episode 9842, reward total was -17.0. running mean: -15.10041988441844, timestamp: 2022-08-20 03:58:27.564137\n",
      "resetting env. episode 9843, reward total was -9.0. running mean: -15.039415685574255, timestamp: 2022-08-20 03:58:36.333234\n",
      "resetting env. episode 9844, reward total was -15.0. running mean: -15.039021528718512, timestamp: 2022-08-20 03:58:42.370303\n",
      "resetting env. episode 9845, reward total was -14.0. running mean: -15.028631313431328, timestamp: 2022-08-20 03:58:49.267376\n",
      "resetting env. episode 9846, reward total was -18.0. running mean: -15.058345000297015, timestamp: 2022-08-20 03:58:53.969429\n",
      "resetting env. episode 9847, reward total was -16.0. running mean: -15.067761550294044, timestamp: 2022-08-20 03:59:01.026509\n",
      "resetting env. episode 9848, reward total was -19.0. running mean: -15.107083934791103, timestamp: 2022-08-20 03:59:06.205564\n",
      "resetting env. episode 9849, reward total was -15.0. running mean: -15.106013095443192, timestamp: 2022-08-20 03:59:13.244644\n",
      "resetting env. episode 9850, reward total was -18.0. running mean: -15.13495296448876, timestamp: 2022-08-20 03:59:18.619701\n",
      "resetting env. episode 9851, reward total was -17.0. running mean: -15.153603434843872, timestamp: 2022-08-20 03:59:23.493753\n",
      "resetting env. episode 9852, reward total was -11.0. running mean: -15.112067400495432, timestamp: 2022-08-20 03:59:30.395832\n",
      "resetting env. episode 9853, reward total was -20.0. running mean: -15.160946726490478, timestamp: 2022-08-20 03:59:35.845937\n",
      "resetting env. episode 9854, reward total was -17.0. running mean: -15.179337259225573, timestamp: 2022-08-20 03:59:40.808515\n",
      "resetting env. episode 9855, reward total was -16.0. running mean: -15.187543886633318, timestamp: 2022-08-20 03:59:46.006572\n",
      "resetting env. episode 9856, reward total was -15.0. running mean: -15.185668447766984, timestamp: 2022-08-20 03:59:53.551654\n",
      "resetting env. episode 9857, reward total was -11.0. running mean: -15.143811763289314, timestamp: 2022-08-20 04:00:00.820735\n",
      "resetting env. episode 9858, reward total was -19.0. running mean: -15.182373645656421, timestamp: 2022-08-20 04:00:06.342794\n",
      "resetting env. episode 9859, reward total was -15.0. running mean: -15.180549909199858, timestamp: 2022-08-20 04:00:14.071879\n",
      "resetting env. episode 9860, reward total was -15.0. running mean: -15.178744410107859, timestamp: 2022-08-20 04:00:20.364958\n",
      "resetting env. episode 9861, reward total was -13.0. running mean: -15.156956966006781, timestamp: 2022-08-20 04:00:27.786550\n",
      "resetting env. episode 9862, reward total was -13.0. running mean: -15.135387396346713, timestamp: 2022-08-20 04:00:34.185620\n",
      "resetting env. episode 9863, reward total was -16.0. running mean: -15.144033522383246, timestamp: 2022-08-20 04:00:40.423210\n",
      "resetting env. episode 9864, reward total was -17.0. running mean: -15.162593187159414, timestamp: 2022-08-20 04:00:45.996277\n",
      "resetting env. episode 9865, reward total was -15.0. running mean: -15.16096725528782, timestamp: 2022-08-20 04:00:52.820349\n",
      "resetting env. episode 9866, reward total was -20.0. running mean: -15.209357582734942, timestamp: 2022-08-20 04:00:58.535414\n",
      "resetting env. episode 9867, reward total was -13.0. running mean: -15.187264006907593, timestamp: 2022-08-20 04:01:05.742492\n",
      "resetting env. episode 9868, reward total was -15.0. running mean: -15.185391366838518, timestamp: 2022-08-20 04:01:11.744560\n",
      "resetting env. episode 9869, reward total was -17.0. running mean: -15.203537453170133, timestamp: 2022-08-20 04:01:17.296142\n",
      "resetting env. episode 9870, reward total was -17.0. running mean: -15.221502078638432, timestamp: 2022-08-20 04:01:23.329733\n",
      "resetting env. episode 9871, reward total was -12.0. running mean: -15.189287057852047, timestamp: 2022-08-20 04:01:30.668816\n",
      "resetting env. episode 9872, reward total was -18.0. running mean: -15.217394187273525, timestamp: 2022-08-20 04:01:35.777870\n",
      "resetting env. episode 9873, reward total was -19.0. running mean: -15.255220245400789, timestamp: 2022-08-20 04:01:40.941931\n",
      "resetting env. episode 9874, reward total was -9.0. running mean: -15.192668042946782, timestamp: 2022-08-20 04:01:49.179017\n",
      "resetting env. episode 9875, reward total was -15.0. running mean: -15.190741362517313, timestamp: 2022-08-20 04:01:54.555075\n",
      "resetting env. episode 9876, reward total was -15.0. running mean: -15.18883394889214, timestamp: 2022-08-20 04:02:00.149135\n",
      "resetting env. episode 9877, reward total was -16.0. running mean: -15.196945609403219, timestamp: 2022-08-20 04:02:06.662209\n",
      "resetting env. episode 9878, reward total was -20.0. running mean: -15.244976153309185, timestamp: 2022-08-20 04:02:13.332278\n",
      "resetting env. episode 9879, reward total was -16.0. running mean: -15.252526391776094, timestamp: 2022-08-20 04:02:20.444359\n",
      "resetting env. episode 9880, reward total was -15.0. running mean: -15.250001127858333, timestamp: 2022-08-20 04:02:26.741428\n",
      "resetting env. episode 9881, reward total was -17.0. running mean: -15.26750111657975, timestamp: 2022-08-20 04:02:31.715483\n",
      "resetting env. episode 9882, reward total was -15.0. running mean: -15.264826105413952, timestamp: 2022-08-20 04:02:37.881550\n",
      "resetting env. episode 9883, reward total was -13.0. running mean: -15.242177844359814, timestamp: 2022-08-20 04:02:45.046627\n",
      "resetting env. episode 9884, reward total was -17.0. running mean: -15.259756065916216, timestamp: 2022-08-20 04:02:50.917214\n",
      "resetting env. episode 9885, reward total was -16.0. running mean: -15.267158505257054, timestamp: 2022-08-20 04:02:56.195275\n",
      "resetting env. episode 9886, reward total was -13.0. running mean: -15.244486920204483, timestamp: 2022-08-20 04:03:02.467393\n",
      "resetting env. episode 9887, reward total was -15.0. running mean: -15.24204205100244, timestamp: 2022-08-20 04:03:07.958451\n",
      "resetting env. episode 9888, reward total was -13.0. running mean: -15.219621630492416, timestamp: 2022-08-20 04:03:13.961518\n",
      "resetting env. episode 9889, reward total was -13.0. running mean: -15.197425414187492, timestamp: 2022-08-20 04:03:20.056586\n",
      "resetting env. episode 9890, reward total was -15.0. running mean: -15.195451160045618, timestamp: 2022-08-20 04:03:27.712666\n",
      "resetting env. episode 9891, reward total was -19.0. running mean: -15.233496648445161, timestamp: 2022-08-20 04:03:32.630724\n",
      "resetting env. episode 9892, reward total was -19.0. running mean: -15.27116168196071, timestamp: 2022-08-20 04:03:37.870779\n",
      "resetting env. episode 9893, reward total was -11.0. running mean: -15.228450065141102, timestamp: 2022-08-20 04:03:44.937859\n",
      "resetting env. episode 9894, reward total was -19.0. running mean: -15.26616556448969, timestamp: 2022-08-20 04:03:49.875908\n",
      "resetting env. episode 9895, reward total was -13.0. running mean: -15.243503908844794, timestamp: 2022-08-20 04:03:56.224980\n",
      "resetting env. episode 9896, reward total was -16.0. running mean: -15.251068869756345, timestamp: 2022-08-20 04:04:03.902064\n",
      "resetting env. episode 9897, reward total was -18.0. running mean: -15.27855818105878, timestamp: 2022-08-20 04:04:09.745128\n",
      "resetting env. episode 9898, reward total was -17.0. running mean: -15.295772599248192, timestamp: 2022-08-20 04:04:15.160188\n",
      "resetting env. episode 9899, reward total was -4.0. running mean: -15.182814873255708, timestamp: 2022-08-20 04:04:24.456286\n",
      "resetting env. episode 9900, reward total was -19.0. running mean: -15.22098672452315, timestamp: 2022-08-20 04:04:29.673342\n",
      "resetting env. episode 9901, reward total was -17.0. running mean: -15.23877685727792, timestamp: 2022-08-20 04:04:35.875411\n",
      "resetting env. episode 9902, reward total was -8.0. running mean: -15.16638908870514, timestamp: 2022-08-20 04:04:44.060501\n",
      "resetting env. episode 9903, reward total was -20.0. running mean: -15.214725197818087, timestamp: 2022-08-20 04:04:49.896091\n",
      "resetting env. episode 9904, reward total was -17.0. running mean: -15.232577945839905, timestamp: 2022-08-20 04:04:55.991155\n",
      "resetting env. episode 9905, reward total was -19.0. running mean: -15.270252166381505, timestamp: 2022-08-20 04:05:00.895212\n",
      "resetting env. episode 9906, reward total was -16.0. running mean: -15.27754964471769, timestamp: 2022-08-20 04:05:07.033275\n",
      "resetting env. episode 9907, reward total was -17.0. running mean: -15.294774148270513, timestamp: 2022-08-20 04:05:13.196346\n",
      "resetting env. episode 9908, reward total was -18.0. running mean: -15.321826406787807, timestamp: 2022-08-20 04:05:18.479402\n",
      "resetting env. episode 9909, reward total was -18.0. running mean: -15.348608142719929, timestamp: 2022-08-20 04:05:22.979453\n",
      "resetting env. episode 9910, reward total was -15.0. running mean: -15.345122061292729, timestamp: 2022-08-20 04:05:30.483535\n",
      "resetting env. episode 9911, reward total was -17.0. running mean: -15.361670840679801, timestamp: 2022-08-20 04:05:36.825654\n",
      "resetting env. episode 9912, reward total was -14.0. running mean: -15.348054132273004, timestamp: 2022-08-20 04:05:43.467725\n",
      "resetting env. episode 9913, reward total was -17.0. running mean: -15.364573590950274, timestamp: 2022-08-20 04:05:50.017797\n",
      "resetting env. episode 9914, reward total was -18.0. running mean: -15.39092785504077, timestamp: 2022-08-20 04:05:58.081409\n",
      "resetting env. episode 9915, reward total was -16.0. running mean: -15.397018576490362, timestamp: 2022-08-20 04:06:04.682479\n",
      "resetting env. episode 9916, reward total was -19.0. running mean: -15.433048390725459, timestamp: 2022-08-20 04:06:11.199553\n",
      "resetting env. episode 9917, reward total was -15.0. running mean: -15.428717906818203, timestamp: 2022-08-20 04:06:16.243131\n",
      "resetting env. episode 9918, reward total was -15.0. running mean: -15.424430727750021, timestamp: 2022-08-20 04:06:21.573714\n",
      "resetting env. episode 9919, reward total was -11.0. running mean: -15.380186420472521, timestamp: 2022-08-20 04:06:28.777793\n",
      "resetting env. episode 9920, reward total was -17.0. running mean: -15.396384556267796, timestamp: 2022-08-20 04:06:34.640859\n",
      "resetting env. episode 9921, reward total was -18.0. running mean: -15.422420710705117, timestamp: 2022-08-20 04:06:39.951915\n",
      "resetting env. episode 9922, reward total was -12.0. running mean: -15.388196503598065, timestamp: 2022-08-20 04:06:47.164999\n",
      "resetting env. episode 9923, reward total was -11.0. running mean: -15.344314538562084, timestamp: 2022-08-20 04:06:53.402066\n",
      "resetting env. episode 9924, reward total was -13.0. running mean: -15.320871393176464, timestamp: 2022-08-20 04:07:00.043140\n",
      "resetting env. episode 9925, reward total was -14.0. running mean: -15.3076626792447, timestamp: 2022-08-20 04:07:06.648211\n",
      "resetting env. episode 9926, reward total was -13.0. running mean: -15.284586052452253, timestamp: 2022-08-20 04:07:13.479290\n",
      "resetting env. episode 9927, reward total was -18.0. running mean: -15.311740191927731, timestamp: 2022-08-20 04:07:19.687355\n",
      "resetting env. episode 9928, reward total was -16.0. running mean: -15.318622790008453, timestamp: 2022-08-20 04:07:27.674447\n",
      "resetting env. episode 9929, reward total was -16.0. running mean: -15.325436562108369, timestamp: 2022-08-20 04:07:35.390531\n",
      "resetting env. episode 9930, reward total was -17.0. running mean: -15.342182196487284, timestamp: 2022-08-20 04:07:40.882592\n",
      "resetting env. episode 9931, reward total was -18.0. running mean: -15.368760374522411, timestamp: 2022-08-20 04:07:47.474666\n",
      "resetting env. episode 9932, reward total was -18.0. running mean: -15.395072770777187, timestamp: 2022-08-20 04:07:52.346719\n",
      "resetting env. episode 9933, reward total was -13.0. running mean: -15.371122043069416, timestamp: 2022-08-20 04:07:59.974805\n",
      "resetting env. episode 9934, reward total was -14.0. running mean: -15.357410822638723, timestamp: 2022-08-20 04:08:06.117873\n",
      "resetting env. episode 9935, reward total was -17.0. running mean: -15.373836714412336, timestamp: 2022-08-20 04:08:13.955960\n",
      "resetting env. episode 9936, reward total was -11.0. running mean: -15.330098347268212, timestamp: 2022-08-20 04:08:21.268040\n",
      "resetting env. episode 9937, reward total was -17.0. running mean: -15.34679736379553, timestamp: 2022-08-20 04:08:28.175118\n",
      "resetting env. episode 9938, reward total was -16.0. running mean: -15.353329390157574, timestamp: 2022-08-20 04:08:32.993175\n",
      "resetting env. episode 9939, reward total was -17.0. running mean: -15.369796096255998, timestamp: 2022-08-20 04:08:39.362242\n",
      "resetting env. episode 9940, reward total was -9.0. running mean: -15.306098135293437, timestamp: 2022-08-20 04:08:48.307340\n",
      "resetting env. episode 9941, reward total was -17.0. running mean: -15.323037153940502, timestamp: 2022-08-20 04:08:54.483414\n",
      "resetting env. episode 9942, reward total was -17.0. running mean: -15.339806782401098, timestamp: 2022-08-20 04:09:00.786006\n",
      "resetting env. episode 9943, reward total was -17.0. running mean: -15.356408714577087, timestamp: 2022-08-20 04:09:06.333065\n",
      "resetting env. episode 9944, reward total was -13.0. running mean: -15.332844627431317, timestamp: 2022-08-20 04:09:13.558143\n",
      "resetting env. episode 9945, reward total was -15.0. running mean: -15.329516181157004, timestamp: 2022-08-20 04:09:19.665214\n",
      "resetting env. episode 9946, reward total was -17.0. running mean: -15.346221019345434, timestamp: 2022-08-20 04:09:26.029285\n",
      "resetting env. episode 9947, reward total was -15.0. running mean: -15.342758809151979, timestamp: 2022-08-20 04:09:32.571405\n",
      "resetting env. episode 9948, reward total was -12.0. running mean: -15.309331221060459, timestamp: 2022-08-20 04:09:39.594004\n",
      "resetting env. episode 9949, reward total was -16.0. running mean: -15.316237908849855, timestamp: 2022-08-20 04:09:45.000066\n",
      "resetting env. episode 9950, reward total was -15.0. running mean: -15.313075529761356, timestamp: 2022-08-20 04:09:51.502136\n",
      "resetting env. episode 9951, reward total was -14.0. running mean: -15.299944774463743, timestamp: 2022-08-20 04:09:57.659207\n",
      "resetting env. episode 9952, reward total was -15.0. running mean: -15.296945326719106, timestamp: 2022-08-20 04:10:04.332279\n",
      "resetting env. episode 9953, reward total was -17.0. running mean: -15.313975873451914, timestamp: 2022-08-20 04:10:12.437369\n",
      "resetting env. episode 9954, reward total was -17.0. running mean: -15.330836114717394, timestamp: 2022-08-20 04:10:17.714430\n",
      "resetting env. episode 9955, reward total was -11.0. running mean: -15.28752775357022, timestamp: 2022-08-20 04:10:25.802042\n",
      "resetting env. episode 9956, reward total was -19.0. running mean: -15.324652476034517, timestamp: 2022-08-20 04:10:30.656097\n",
      "resetting env. episode 9957, reward total was -21.0. running mean: -15.381405951274173, timestamp: 2022-08-20 04:10:36.473160\n",
      "resetting env. episode 9958, reward total was -18.0. running mean: -15.407591891761431, timestamp: 2022-08-20 04:10:41.565218\n",
      "resetting env. episode 9959, reward total was -7.0. running mean: -15.323515972843817, timestamp: 2022-08-20 04:10:49.621308\n",
      "resetting env. episode 9960, reward total was -8.0. running mean: -15.250280813115378, timestamp: 2022-08-20 04:10:56.626913\n",
      "resetting env. episode 9961, reward total was -17.0. running mean: -15.267778004984224, timestamp: 2022-08-20 04:11:03.004981\n",
      "resetting env. episode 9962, reward total was -15.0. running mean: -15.265100224934383, timestamp: 2022-08-20 04:11:08.691042\n",
      "resetting env. episode 9963, reward total was -11.0. running mean: -15.222449222685038, timestamp: 2022-08-20 04:11:16.942134\n",
      "resetting env. episode 9964, reward total was -18.0. running mean: -15.250224730458187, timestamp: 2022-08-20 04:11:23.489733\n",
      "resetting env. episode 9965, reward total was -11.0. running mean: -15.207722483153605, timestamp: 2022-08-20 04:11:30.540810\n",
      "resetting env. episode 9966, reward total was -17.0. running mean: -15.225645258322068, timestamp: 2022-08-20 04:11:37.354883\n",
      "resetting env. episode 9967, reward total was -20.0. running mean: -15.273388805738847, timestamp: 2022-08-20 04:11:42.638942\n",
      "resetting env. episode 9968, reward total was -12.0. running mean: -15.240654917681457, timestamp: 2022-08-20 04:11:48.222004\n",
      "resetting env. episode 9969, reward total was -17.0. running mean: -15.258248368504642, timestamp: 2022-08-20 04:11:53.979066\n",
      "resetting env. episode 9970, reward total was -17.0. running mean: -15.275665884819595, timestamp: 2022-08-20 04:12:00.135133\n",
      "resetting env. episode 9971, reward total was -17.0. running mean: -15.2929092259714, timestamp: 2022-08-20 04:12:07.780218\n",
      "resetting env. episode 9972, reward total was -15.0. running mean: -15.289980133711685, timestamp: 2022-08-20 04:12:14.383813\n",
      "resetting env. episode 9973, reward total was -17.0. running mean: -15.307080332374568, timestamp: 2022-08-20 04:12:20.467879\n",
      "resetting env. episode 9974, reward total was -14.0. running mean: -15.294009529050822, timestamp: 2022-08-20 04:12:28.139491\n",
      "resetting env. episode 9975, reward total was -15.0. running mean: -15.291069433760313, timestamp: 2022-08-20 04:12:34.442559\n",
      "resetting env. episode 9976, reward total was -11.0. running mean: -15.24815873942271, timestamp: 2022-08-20 04:12:42.115645\n",
      "resetting env. episode 9977, reward total was -16.0. running mean: -15.255677152028483, timestamp: 2022-08-20 04:12:48.475714\n",
      "resetting env. episode 9978, reward total was -18.0. running mean: -15.283120380508198, timestamp: 2022-08-20 04:12:54.214777\n",
      "resetting env. episode 9979, reward total was -15.0. running mean: -15.280289176703116, timestamp: 2022-08-20 04:13:00.585850\n",
      "resetting env. episode 9980, reward total was -19.0. running mean: -15.317486284936084, timestamp: 2022-08-20 04:13:05.599901\n",
      "resetting env. episode 9981, reward total was -11.0. running mean: -15.274311422086722, timestamp: 2022-08-20 04:13:11.648550\n",
      "resetting env. episode 9982, reward total was -12.0. running mean: -15.241568307865855, timestamp: 2022-08-20 04:13:20.182642\n",
      "resetting env. episode 9983, reward total was -16.0. running mean: -15.249152624787197, timestamp: 2022-08-20 04:13:26.076709\n",
      "resetting env. episode 9984, reward total was -12.0. running mean: -15.216661098539324, timestamp: 2022-08-20 04:13:33.615835\n",
      "resetting env. episode 9985, reward total was -15.0. running mean: -15.214494487553932, timestamp: 2022-08-20 04:13:39.098896\n",
      "resetting env. episode 9986, reward total was -14.0. running mean: -15.202349542678393, timestamp: 2022-08-20 04:13:44.357950\n",
      "resetting env. episode 9987, reward total was -11.0. running mean: -15.160326047251608, timestamp: 2022-08-20 04:13:49.917593\n",
      "resetting env. episode 9988, reward total was -17.0. running mean: -15.178722786779092, timestamp: 2022-08-20 04:13:55.448652\n",
      "resetting env. episode 9989, reward total was -17.0. running mean: -15.196935558911301, timestamp: 2022-08-20 04:14:01.911726\n",
      "resetting env. episode 9990, reward total was -16.0. running mean: -15.204966203322188, timestamp: 2022-08-20 04:14:08.157792\n",
      "resetting env. episode 9991, reward total was -15.0. running mean: -15.202916541288966, timestamp: 2022-08-20 04:14:13.313848\n",
      "resetting env. episode 9992, reward total was -16.0. running mean: -15.210887375876077, timestamp: 2022-08-20 04:14:19.162914\n",
      "resetting env. episode 9993, reward total was -17.0. running mean: -15.228778502117315, timestamp: 2022-08-20 04:14:24.972982\n",
      "resetting env. episode 9994, reward total was -13.0. running mean: -15.206490717096143, timestamp: 2022-08-20 04:14:31.410047\n",
      "resetting env. episode 9995, reward total was -16.0. running mean: -15.214425809925181, timestamp: 2022-08-20 04:14:37.879122\n",
      "resetting env. episode 9996, reward total was -17.0. running mean: -15.23228155182593, timestamp: 2022-08-20 04:14:43.959185\n",
      "resetting env. episode 9997, reward total was -11.0. running mean: -15.18995873630767, timestamp: 2022-08-20 04:14:52.022276\n",
      "resetting env. episode 9998, reward total was -17.0. running mean: -15.208059148944592, timestamp: 2022-08-20 04:14:58.855352\n",
      "resetting env. episode 9999, reward total was -15.0. running mean: -15.205978557455147, timestamp: 2022-08-20 04:15:05.056416\n",
      "resetting env. episode 10000, reward total was -16.0. running mean: -15.213918771880595, timestamp: 2022-08-20 04:15:11.601490\n",
      "CPU times: total: 12h 4min 25s\n",
      "Wall time: 9h 49min 10s\n",
      "End time: 2022-08-20 04:15:11.646492\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "file_name = 'hist1_H400_E10000_last_.csv'\n",
    "%time hist1,hist_2 = train_model(env, model, total_episodes=10000)\n",
    "print(f'End time: {datetime.now()}')\n",
    "np.savetxt(file_name, hist1, delimiter =\",\", fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnQAAAGwCAYAAAAg+PjwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWwElEQVR4nO3dd3xTVeMG8CdNk6Zt2qZ70RZaoAKCKEtG2auCBRkqIOAWXvw5UN9Xxb3QVwU3r/qqqPiCiIMpUEBE9hAogsheLU0X6U6TJvf3R20hNEmzc9M+38+HD+295957mtO0T8+95xyJRqMRQEREREQ+y8/bFSAiIiIi5zDQEREREfk4BjoiIiIiH8dAR0REROTjGOiIiIiIfBwDHREREZGPY6AjIiIi8nEMdEREREQ+joGOiIiIyMcx0BERERH5OAY6J2m1Wpw6dQpardbbVaErsF3Eh20iPmwT8WGbiJMvtAsDnQsYDAZvV4HMYLuID9tEfNgm4sM2ESextwsDHREREZGPY6AjIiIi8nEMdEREREQ+joGOiIiIyMcx0BERERH5OAY6IiIiIh/n0UCXk5ODl156CePGjUNaWhpUKhVGjRplsfzZs2ehUqks/ps7d64Ha09EREQkTv6evNjq1asxb948yOVytG3bFsXFxTYdd+2115oNfv369XN1FYmIiIh8jkcD3dixY5GZmYlOnTqhpKQE6enpNh3XuXNnPPXUU26uHREREZFv8mig69ChgycvR0RERNQieDTQOSo/Px+ffvopysrKEB0djYyMDLRp08bb1SIiIiISBZ8IdL/88gt++eWXhs8lEgkmTpyI+fPnIzg42KZzuGtBXZ1OZ/I/iQPbRXzYJuLDNhEftolnCYKAxadqsD5Xh4QgKe5PV6B1iLRROXe3i0KhcPocog50QUFBeOKJJzBq1Ci0adMGgiDg4MGDePnll7F06VJUV1fj66+/tulceXl5bl1YV61Wu+3c5Di2i/iwTcSHbSI+bBPP+Py8Pxaclf/9mR7Lz1Rj0fXViJKbL++OdpFKpUhNTXX6PBKNRiPYc8CcOXPsSqgzZsxAWlpao+1qtRrp6eno27cvVq9ebU8VUFVVhQEDBuD48ePYvHkzunbt2uQx7uyhU6vViI2NhVxu4TuAPI7tIj5sE/Fhm4gP28RzBEHA9csvIb/aNAa93j0Yd7Yz7TFzd7t4pYdu4cKFqKystLl8VlaW2UDnjKCgINx222145ZVXsGvXLpsCnSteLGvkcrnbr0H2Y7uID9tEfNgm4sM2cb8KvbFRmAOAJ/dWYkZnldljxNwudge63Nxcd9TDbpGRkQDqeuuIiIiI7FFjsOsGpej57NJfe/fuBQAkJyd7uSZERETka85XuO+5em8QdaA7ePAgBKFxgl6xYgUWL14MlUqFoUOHeqFmRERE5Mu+P13t7Sq4lEdHuR47dgzz588HcHmQwvHjxzFz5syGMgsWLGj4+Omnn8aZM2fQo0cPJCQkwGAwICcnBzt27EBAQAA++ugjhIWFefJLICIiombA3PQkvsyjgU6tVmPx4sUm2woKCky2XRnobrvtNqxYsQJ79+5FcXExjEYj4uPjMW3aNDz44INo3769x+pOREREzYemxvIzdE/u0uC5bqFYcLgSi45XQu4HjIuW4uEkD1bQTnZPW0KmtFotzp8/j6SkJNGOfGmJ2C7iwzYRH7aJ+LBNPCf6y1zojfYd80VGCG5pG+qeCjlJ1M/QEREREbmDvWEOAO7dWu76irgIAx0RERGRDQwCUGsU541NBjoiIiJqUYxmZtCwlVhHxzLQERERUYuyv0jv8LFrz7lnKVFnMdARERFRi/LivjKHjx2UGODCmrgOAx0RERG1KP4Sx48dlSzO0ccMdERERNSiDE9yPJRFKsQ5ITEDHREREfk0QRBQY7B9oEOpzoE5SwAkBok3Nnl0pQgiIiIiZ50qq0X2BS2iFH4wCMArv5cht9KAvnEB+O+AcMQEWu9F++xopUPXVcqcuFfrZgx0RERE5DO2XKxB1toii/vu2VyClZnRVs9RUO1YD11EgHgDnXj7DomIiIiuMv2XYqv7f8vXoURrsFqmbahj/VkPdwx06DhPYKAjIiIin3Gppuln5Q6VWJ9nLtPBkao3xsgcOs4TeMuViIiIRO98RS3eOVRhU1mNznroU0jtv3V6S5zeoeM8hT10REREJGplOiNG/Vxk82CGXQU1DR8XaQ04VKKH4Yo1WH+7WGPuMKti5OJcw7UeAx0RERGJ2q8Xa3CuwvpzcVf6/lQ1BEHAM7tL0XZxPjKWFyDyyzwcL627FbuzQGd3HcQd5xjoiIiISOSe21NqV3l1tRFbLurwwWHTW7Q9fihwuA7tgsUd6RjoiIiISNROl9veOwcA8UF+uGtzidl9TY2ANSdEJkHfcPuP8yQGOiIiIhItvdH+nrHro+QoqTE/19wRTa3d5/uiXwhkIk9MIq8eERERtWT7i+x/3m3NOa3FfeVWlv26epnWEJkExdMT0C9OvNOV1OO0JURERCRaW/PtD3QA0D7MH8dKG/fGvZ1Tbrb8uDaBeK+vCu8cqsCJ0lqMSlZgfGog/CQSWJ/VThwY6IiIiEi0LlY59uyapVukewvNx7Mjl/RQyvzwzA2hDl3P23jLlYiIiETL0al8D1+y71m5ow48WycmDHREREQkWlEKz0SVAfEBHrmOu/CWKxEREYmOpsaISRuLsUPt2DN09vp0QLhHruMuDHREREQkOiNWF+IvM4Ma3CUmUNp0IRHjLVciIiISlQq90aNhrjlgoCMiIiJR+dcu+5b6IgY6IiIiEplvjld5uwo+h4GOiIiIWrQ2Ib79/BzAQEdEREQicUyjh+qLXJvKqqclYMXIKDzaWen0dU+XOzZ5sZgw0BEREZHXVdUa0fPHApvLB0gl6B8fgDGtA91YK9/BQEdERERet+BwpUPHqQIYZQAGOiIiIhKBl38vs7lsoPTygmAqufNRJiHI9+OQ738FRERE1KIYITR8HCp3dLXXy+5KD3b6HN7GQEdEREQ+ZXgrRcPHfhLnAp3MD7i9bZCzVfI6BjoiIiLyqrPl9q0Kce81zo9sBeqmK1k0OBJJSt9fCZWBjoiIiLzqzYPldpVPDTWdN+6xLo4FvP0T4jAiSdF0QR/AQEdERERetcjOlSFqDILJ5/d3UCI9zL5etn5xcrvKi53v9zESERGRzzpQpLP7mLgg0x662CAp1o+OxqZcLcr1AuICpbh1Q3HD/gApUHPV3MELMsIdqq9YMdARERGRVwiCgIErC+06ZnirAChljW8whsn9cEuby4MbNHclNnxcpDVgxpZL2JBbg9YhUrx5o6pZPDd3peb11RAREZHP2Flge++c3A/ITFbg3T7296xFKaRYNjwKtUYB/n7OT3MiRgx0RERE5BWrzmptLquelgCJk1OUNNcwB3BQBBEREXnJh4crbC7rbJhr7hjoiIiIiHwcAx0RERGJ2oD4AG9XQfQ8GuhycnLw0ksvYdy4cUhLS4NKpcKoUaOaPE6n0+GDDz7AwIED0apVK7Rq1Qq9e/fG448/7oFaExERkbe0DpFi2fBIb1dD9Dw6KGL16tWYN28e5HI52rZti+Li4iaP0Wg0GD9+PPbt24devXrhzjvvBACcPXsWP/zwA9566y0315qIiIi8oV2YP/aMi/V2NXyCRwPd2LFjkZmZiU6dOqGkpATp6elNHjNr1iz8/vvv+PTTTzFx4kSTfbW19q39RkREROIgCEKTZcakBHqgJs2DRwNdhw4d7Cq/Z88erF69GrfddlujMAcA/v6cdYWIiMgXrTrX9JQlk9sFNVmG6og6Ef3www8A6nr2iouLsWbNGhQWFiIxMRHDhg1DRESEl2tIRERE9hIEAVM3lVgtM6+3Cqmhoo4poiLqV+rAgQMAgJMnT+KBBx5AWVlZwz6lUon33nsP48aNs+lcWq3tkxfaQ6fTmfxP4sB2ER+2ifiwTcSnpbTJqXKD9f0TIxDkL3Hb7257ubtdFAqF0+cQdaArKioCADz//POYOHEinnzySahUKqxfvx6PP/44HnjgAbRv3x7XXnttk+fKy8uDwWD9G8gZarXabecmx7FdxIdtIj5sE/Fpzm1SbQBeOi6HtQhSfPECmh426XnuaBepVIrU1FSnz2N3oJszZ45dCXXGjBlIS0uz9zIAAKPRCADo2LEjFixY0DBL9K233ory8nI89thj+Pjjj/H+++83ea6EhASH6tAUnU4HtVqN2NhYyOVyt1yD7Md2ER+2ifiwTcSnubfJiTID7v2tHMfKrHewJCUleahGtvGFdrE70C1cuBCVlZU2l8/KynI40IWGhgIARo4c2WjJj8zMTDz22GPYv3+/TedyRXemNXK53O3XIPuxXcSHbSI+bBPxaW5tUqQ1oO3ifJvKrs6MgkIhzomExdwudge63Nxcd9TDrHbt2mH//v0ICwtrtK9+m1jurxMREZF5toY5ALg+SubGmjRfol76KyMjAwDw119/NdpXvy05OdmjdSIiIiL3CfIXdTQRLVG/amPGjEFkZCS+++47HD58uGG7TqfD3LlzAdRNaUJERETUknl0lOuxY8cwf/58AJdvlR4/fhwzZ85sKLNgwYKGj0NDQ/Huu+9i+vTpGDZsGLKysqBSqfDrr7/izz//xPDhwzFlyhRPfglEREREouPRQKdWq7F48WKTbQUFBSbbrgx0ADB69GisXr0ab731Fn7++WdUV1cjLS0NL774ImbNmgWpVOqRuhMREZH9DMaml/iqtyozyo01ad48GugyMjKg0WjsPu7GG2/EsmXLXF8hIiIicqvtatunOosIEPWTYKLGV46IiIjc5tk9pTaXlUqaLkPmMdARERGR2xwo1ttc1mD73Vm6CgMdERERuYUg2JfQ4gIZSxzFV46IiIjc4vYN9q3IGqHgQEdHMdARERGRW6y7UOPtKrQYDHRERETkdU92DfF2FXwaAx0RERF51fVRMvzftUpvV8OneXQeOiIiIvKuZaeqsPxMNWICpbivQzCuUcm8VpfwAAm+GhSJXjFyyDlniVMY6IiIiFqINw+U4dX95Q2ff3a0EgcmxKJ1iOfjwNqbonBjbIDHr9tc8ZYrERFRC7DybLVJmKs3a+slj9flzvZBDHMuxkBHRETUzOkMAqZuKjG7b1u+7Utz2WNzntbivjduVLnlmi0ZAx0REVEzt/6C5XDlLmPXmZ+Dbkq7IATweTmXY6AjIiJq5k6W1Vrdb7RzRQdnxAdy8mB3YKAjIiJq5prKawftWG/V+nUEnCqrxZlyywGyUwTHY7oDX1UiIqJm7vAl64Hto8MV+HRAhFPX+ORIBf65q7TJct2j5U5dh8xjDx0REVEzVlBtwHenqq2WWX7G+v6mbMrV2hTmACAigNHDHfiqEhERNWM/n2t6QITO6Nw1frIjEAb5c0CEOzDQERERNWMPb9e49fxFWgO+OlZlU9kOKn9IJAx07sBAR0RERA57ZJvG5rIvdg9zX0VaOAY6IiKiZkpncO90JAajgFU23NKtV1nr5L1dsoiBjoiIqJnaX2T7KhCCA3PRXag02FXezfmyRWOgIyIiaqY0OtsT1NImRsKa88ROjV3lM+K4fqu7MNARERE1U0c1tk8Y/MCWS3aff/2FGrvKB3KEq9sw0BERETVTz+8tc9u5d6jtC3MAIPdjoHMXBjoiIiICYN8gijcPlNt9/gAu4+o2DHREREQEAPjfibr55Iw2DJDYlGd/Dx3noHMfruVKREREAIBHtmvwyFUTET/aWYnnOX+c6LGHjoiISMSMgoBXfi+D6otcqL7IxXcnbVuVodbomjlC5h+qwP9ttX/AxNV4u9W9GOiIiIhEbGJ2Md46ePl5tfu2XMIXRyubPM6Vc/h+fdy2EGnNP68LdUFNyBIGOiIiIpHSGQRszG38rNqjOzRNH2ulh25QgvPzwcUF2hchJrcLcvqaZBkDHRERkUhtuWh54EGl3noX3Mv7zE9Z8o9OwViQEW53Xa5eSSK/2vYuwBUjoxAfxHuu7sRAR0REJFLWJgZed976GqqfWrgtu7tAhzgHwpXWvlW+GpybEo/+8Vwhwt04ypWIiEikukTKLe7bptZhXGpQQ8/ZlVOCaGst326t79jrES3DnkLbV5JI/iYPz90Qin1FeoTILE8/snhIBDbn1aBtmD9ubxuEEBn7jjyBgY6IiEikrI1UTQqW4rOjFXj3UAUq9QImpAbi1Z5h8PeTIL/acnda8N/Lb9kT5oC6IPisDStPZCYHIjM50K5zk/MY6IiIiESqxsrKDS9c9Yzcx39WIkTuh2duCMXc/ZaDl2smMyGxYT8oERGRSOnsnHqkfnqTb09WWyzjqvnpSFwY6IiIiETKWg+dNdaecbv7GiUAYEii6wcqDODgB69hoCMiIhKpVWct97RZojcKkFpZMjUzSQEAmNvT9ct5TWvPuea8hYGOiIhIpFactT41iTlfHK2ERme+Z6+jyh+qgLpf/e1VMqfqZk7rED6a7y0MdERERM3IP3eVWty3bHiUyed3pwe79NrXR7k+JJJtGOiIiIhaiIRg0wmFH+6sbFTm3T4qZI+Kduj8fhIr93rJrdg3SkRE1EKlhPjj4IRYLD1ZhVKdgDGtA9EjRo6LVQ4uC0Few0BHREQkQi/stXzr1JVSQvzxRNdQk21cd9X38JYrERGRCL1zqMKr19842rHbruQdHg10OTk5eOmllzBu3DikpaVBpVJh1KhRFsvPnDkTKpXK6r9///vfHvwKiIiI3G+3nctyuUO3aDnOTYm3uby1ue/I/Tx6y3X16tWYN28e5HI52rZti+LiYqvlR40aheTkZLP7PvjgA1RWVmLIkCHuqCoREZHXzD9s//xz7hAq98Px2+PQbkl+k2VTOGWJV3n01R87diwyMzPRqVMnlJSUID093Wr50aNHY/To0Y22HzhwAG+88QY6duyIbt26uau6REREXpEaIsUvF13bS/fHxFiHjosOtO15uqevD3Ho/OQaHg10HTp0cMl5vv76awDA1KlTXXI+IiIiMdE5uOSXNa2Ujv/Kf6BDMD7+s9JqmUEJCofPT87zuUER1dXV+O677xAQEIDbb7/d29UhIiKySa1RQFWt0aayOtuKecxT14eid6zc4v7lI6IQ6M9n6LzJ5254L1++HGVlZRg/fjzCw8NtPk6rtX/5FFvodDqT/0kc2C7iwzYRH7aJZxiMAhK/LTHZdvbWCASYWXC1vi02X3R9mzjze1AB4IdBSsQvKTG7PxB6aLWu71UUC3e/VxQK53s3fS7Q1d9unTZtml3H5eXlwWBw30SJarXabecmx7FdxIdtIj5sE/e6Y78CV98Q6728CMt7mA9Y+0v9oLYSjua0rUF3lREJAQKeOybHukLbfpWfP3/e5jpb8mgbf8w/3binznDpIs5bvyPbLLjjvSKVSpGamur0eewOdHPmzLEroc6YMQNpaWn2XsasU6dOYfv27UhJSUH//v3tOjYhIcEldbiaTqeDWq1GbGws5HLL3dHkWWwX8WGbiA/bxDP+2tp4Roe8Gj8kJSU12q7T6fDjX5csnisqQIKZ3eLh71fXu/dFkoAEC71mV3qwgwJJSZF21Nq828MN+OCsBvorbgn3ivbH9WmNv5bmxBfeK3YHuoULF6Ky0vYYnpWV5bJAt2jRIgiCgDvuuAMSO9eLc0V3pjVyudzt1yD7sV3Eh20iPmwT9xEEyz1tll7zn630uM2+LhTKoECTbefviEfSootW6zGwVbBL2jhdASwb5o9n9pTiTHktBsQHYF4fFRSKlrGyhJjfK3YHutzcXHfUo0kGgwGLFy+GVCrFlClTvFIHIiIie1yqsTy6QRAEuzsn/tFJ2WhbiMwPhybGovN3lm8Hmnlcz2EDEgLw25gY152QXMJnRrmuX78eFy9exNChQ912+5SIiMiVrA1WPVFW22ibtR49a5KamJIkQuEzv+7JQT7TwvWDIe644w4v14SIiMg6vVHAxlwtlpyoslhmweHGjy/tL2kc8my17qYos9ujFH64Nlzm8HnJN3h0lOuxY8cwf/58AJeHTx8/fhwzZ85sKLNgwYJGxxUUFGD9+vWIiYlBZmamZypLRETkgDcOlGHu/vImyxVqG8+88NJ+ywGwKb1iA7B+VBSGry5q2BYR4IcP+4VD6sc54po7jwY6tVqNxYsXm2wrKCgw2WYu0C1evBi1tbWYNGkS/P19bqYVIiJqIbbn19gU5gCgqrbx7dWdhY730AFAz5gAaO5KxPFSPXIrDegWLUeIzGduxpETPJqOMjIyoNFo7D7u4YcfxsMPP+z6ChEREbnQ2HVFTRf6W5mdy0G83ivM5rLtwmRoF8bbrC0Ju7uIiIhcxJ6MdqhE3/CxwSjguJlBEle6s32wo9WiFoCBjoiIyAvqH6Hbpa7BiDXWe/Ze6xkGBddKJSt4Y52IiMgFjlzSN13oKkZBaDLMAebnnyO6EgMdERGRC4xcU2j3MQeKmg6BaaEtYxUGcg4DHRERkQuU6eyfFPjOzU2vw6rkKFWyAb9LiIiInFRQ3XhOOVucq2j6OKWMz85R0xjoiIiInLQ5r8Zt51ZX2Te9CbVMDHREREROeueQbZMJO8Lcmq9EV2OgIyIictKRSwxd5F0MdEREREQ+joGOiIiIyMdxpQgiIqK/nS2vxZpzWqgC/DAqWYFQedP9HuV69w5aeLWn7Wu4UsvFQEdERARgd0ENxq4rRlVt3Xxy6WH+WHNTFCIV1if23W/D5MDOmNGBa7hS03jLlYiICMAbB8obwhwA/FVai6+OVZktW2sU8M3xSvyap0XWWstLd2nuSoTmrkQ83iXEoTr9MTEWUj/OQ0dNY6AjIiICsDG38VxyL+4rM1NOi6gv8zBrqwZj1hVbPN+wxICGj29vG2hXXWIDJTg9OR6tlLyRRrbhdwoREbV45ypsn3Zk/HrLIe5Kk9sFNXycFmr7r9uEACN+HxsNRQD7XMh2/G4hIqIW74M/Kmwqd+SS7c/LJQZffvZOIpHgpe6hNh1nwzgMokb4bUNERC3eJ39WWtz32dHLYa/PTwU2n1MpM/0V+1DnEHw9OAKT2wZZOKJO5xAu9UX2Y6AjIiKy4rEdpbhUY3/IahfW+DbrzSmB+CgjHCV3JuDmFIXZ48bHc9UJsh8DHRERURMe36GBIAhNF7yCzMroVD+JBF8PjkT/+ACT7VnJcnRQsoeO7MdBEURERE34/nQ1HrVj6pFWwdbnrqu3YmQU9hTosENdg/Yqf/SLBC7mahysJbVkDHRERNRiGQUBCV/n2VT262OWn7O72g/DI20u2yNGjh4xcgCAVqu1+TiiKzHQERFRi1NjEPDPnRp8aWHiYHM+tjJw4mrhnHKEPIzfcURE1OK8tK/MrjBnL7mUqzuQZzHQERFRi7PslPvCHAAEcLku8jAGOiIialGOafRQV7t3JGmAbWMiiFyGgY6IiFqMhX9VouePtk8O7CiJhD105FkMdERE1CLUGAQ8vbvU29UgcguOciUiomatQm/EmwfK8a6N67US+SIGOiIiarYEQcDon4twoFjvsWu+00flsWsR1eMtVyIiarYOFOs9GubCAyS4Mz3YY9cjqsdAR0REzdaac55beeHO9kE4NSneY9cjuhJvuRIRUbP15sFyu485NyUeyd9ctKnstjEx6BQhgyAIHNlKXsUeOiIior/J/YBQuR86hdvW3xEqrwtxDHPkbQx0REREf1syNBIAsDkrBrO7KBEbaP3XZIiMv0ZJHPidSEREBOA/GeEYnKgAAMj8JHiuWxj+uj0ey4ZFmi2fopQiTM6eORIHPkNHRETNwolSPbardUhRStEpQob9RbaPbtXclWhx39BWCszvrcKjOzQm25+5IZS3Wkk0GOiIiMjnrTpbjbs3l0DnwBKtv9wc3WSZu64JxsS0QKw4U40LlQYMTVTghmi5AzUlcg8GOiIi8nlP7NQ4FOYAIFJh29NHSpkfJrfjHHMkTnyGjoiIfFqJ1oCLVQ6mOQBB/rxtSr6PgY6IiHza96ernTo+MoC/Csn38buYiIh8VmG1AU/sLHXqHBzYQM0BAx0REfms5/aWOXW8lFmOmgkGOiIi8lmb85xbq/XUZK69Ss2DR0e55uTk4KeffsKBAwdw8OBBFBcXo2/fvli9erXFY6qrq/HZZ59h6dKlOHv2LARBQFJSEm655Rbcd999CAsL8+BXQEREYuLIYIgDE2IRIpMgUiF1Q42IvMOjgW716tWYN28e5HI52rZti+LiYqvl9Xo9br75ZuzduxedO3fG5MmTAQC//fYbXnnlFXz//ffYuHEjgoKCPFF9IiLykotVBgxaUYD8aiMmpAbik/7hDo9sbR3CGbuo+fHod/XYsWORmZmJTp06oaSkBOnp6VbLr1q1Cnv37sXo0aOxaNEik32TJ0/GmjVrsHz5ckyaNMmd1SYiIhcr0hpQYwASg5vuJVNXGdDh2/yGz5edqsayU9V4+voQu6+bEMQnjah58mig69Chg13lz5w5AwAYNmxYo30jRozAmjVrUFRU5IqqERGRBxRrDUhbnG+y7ehtcdhbqMN3p6qglPnhnvRgk1UY0r/Nv/o0AIDPj1baff0Xu/MxHWqeRN3vXB8As7OzMX36dJN969atg0QiQUZGhjeqRkREDmi/pHE4u+aqwPbN8SqsvSkKN8YGWD1XfrV9t1wlAAYkWD8nka8SdaAbMWIERo0ahVWrViEjIwP9+vUDUPcM3blz5/Duu++ia9euNp1Lq3VuJJQlOp3O5H8SB7aL+LBNxMfTbaI1CDAItpUduaYIPw4JRbCLVnGQ+QFvdA9GqEQPrVbvknO6A98n4uTudlEoFE6fQ9SBTiKR4Ouvv8ZLL72Ed999F4cOHWrYN2nSJAwcONDmc+Xl5cFgMLihlnXUarXbzk2OY7uID9tEfDzVJivUUgC295DdstHxOeYUfgJeSdehW5gBZ6v9kBJohNK/CufPO3xKj+L7RJzc0S5SqRSpqalOn8fuQDdnzhy7EuqMGTOQlpZm72UAAFVVVbjnnnuwb98+fPbZZw0BbvPmzXjyySexYcMGbNiwASkpKU2eKyEhwaE6NEWn00GtViM2NhZyubzpA8gj2C7iwzYRH0+3yao/SwHUuv06EgA7b45A3N8DIOx7etu7+D4RJ19oF7sD3cKFC1FZafuDqFlZWQ4Hunnz5uHnn3/G//73P9x0000N28eNG4eAgABMmTIFb7/9Nt57770mz+WK7kxr5HK5269B9mO7iA/bRHw81Sb7m5iqylXe6aNC6wjfns6K7xNxEnO72B3ocnNz3VEPs7KzswHA7MCH+m05OTkeqw8RETlGEGx8eM5JXSNlmJ4e7JFrEYmJqCfk0evrHlw1NwFx/baAAI5YIiISu5Nl7r/VCgADOYqVWihRB7pevXoBAF5//XUYjZeHpxsMBsydOxeA+d47IiISl025NR65jlIm6l9rRG7j0VGux44dw/z58wFcnkbk+PHjmDlzZkOZBQsWNHw8e/ZsrFmzBkuWLMHBgwcbwtuWLVtw9OhRpKWl4cEHH/TgV0BEROaoqwx4YV8Z/ijRo3u0DM93C4Mq4HK4evdQhUfqcbbcMz2BRGLj0UCnVquxePFik20FBQUm264MdElJSdi8eTPmzZuHjRs3YuHChZBIJEhOTsZDDz2E2bNnQ6VSear6RERkhsEoYPTaIhwvrQtTh0r0+PNSLdaOim4ok1vlvmmjrnSGgY5aKI8GuoyMDGg0GruOiY+Px5tvvumeChERkdN2F+oawly9nQU6HNPo0V4lg87W2YRd4IGOSo9di0hMRD2xMBERid+j2zVmtz+3twwGo4Bf8jzz/BzApb2o5WKgIyIipxzVmL/Nufa8e5ZctCaEgyKoheJ3PhEREZGPY6AjIiKHZV9wrhdudWYUQmQSl9TltrRAl5yHyBfxlisRETnkwa2XsOh4lVPn6BsXgL9uj8PBYj1kfhIMXVXo8Lk+6hfuVF2IfBkDHRER2a2g2uB0mMuIq1vkPMjfD71jA1BrdG40rNTPNT19RL6It1yJiMhu7ZfkO32OvnGmI1L9/ST4V9cQs2XTw/yxb1ws9o2LNbv/26GRTteHyJexh46IiLxiT6Gu0bYnu4YgMViK7AtatAqW4oGOSrQOMf1VVTw9AS/sK8PSk1VQyiT4v2tDMCJJ4alqE4kSAx0REXnFRTOrR0gkEkxrH4xp7YMtHif1k+DlHmF4qXsoJBLeZiUCeMuViIi8RFNjdOp4hjmiyxjoiIjILoLgmqW8nrkh1CXnISIGOiIistPXTo5urTeSz70RuQwDHRER2eWhbRqXnCdCIXXJeYiIgY6IiLxgTWaUt6tA1Kww0BERkc1qDK55fq7PVXPQEZFzGOiIiMhmr/1e5u0qEJEZDHRERGSzd/+ocPocs7soXVATIroSAx0REdnk4yPWw1yn8Kbnqo8M8MMd7SxPGkxEjuFKEURE1CSjIOBfu0qtlvm4fwT6LS8wu+++DsEIk/lhcrsgpIbyVw+Rq/FdRUREVgmCgO7fq62WiQjws9pD9+aNKhfXioiuxFuuRERk1cFiPU6VN1531aTMxFhIJBKMaxPooVoR0ZUY6IiIyKqBKwubLBMiq/t18qyZ5by2jolxeZ2IyBRvuRIRkUW/F+rsKt8m1B9Hb4vDz+e0qDEKGJWsQJKSv2qI3I3vMiIismj2Do3dx8QFSXHXNRzJSuRJvOVKREQWHSjWe7sKRGQD9tARETUTOoOArfk1UFcbkREnRyve6iRqMfhuJyJqBrS1Am5eW4g9hZd71JYMjcDIpLpRp7VGATvUOmRf0KJThAxjUlw3GjVFKXXZuYjIMQx0RETNwOsHykzCHADcvqEEpybFwU8iQev/XTTZ9wAuYdsoFeRWzikIgk3XfqAjl/Ii8jYGOiIiH6epMeKdQ+aX5UpdnG/xuL6rNdjTz/J5FxyptHrdQKkEU9oF4YEOHABB5G0MdEREPi77gtbhYzV6IMnCvqd3W17q69jtcQiV+UHhL3H42kTkOhzlSkTkg8r1RhiMdbdEZ/52yeHzDNsVhPwqo93HxQRKGeaIRIQ9dEREPmR/kQ6Drli54eFrlai17VE3i7ouv4TtY2XoGC5zsnZE5C3soSMi8hFGQTAJcwDw7h/mn52z1+ztGpPPf82zfBt3aGKAS65JRK7DHjoiIh+R48ZJfncWXF7ia/Z2DT7/y/KAiH904qhWIrFhoCMi8hF77FxX1V5GQUCZTrAa5gBgQDx76IjEhrdciYh8xMv7ytx6/pxifaP56q52Z/sgSP04GIJIbNhDR0QkcqfLanH992q3X2fgVc/nmfNMt1C314OI7MceOiIiERMEAePXF3m7Gg2iFFzmi0iMGOiIiETs+9PVOFVu8HY1iEjkGOiIiERq0fFK3PurY5MGbx0Tg3/3CnNpfT7tH+7S8xGR6/AZOiIikdmprsF7f1RgzTnHl/TqFO6PayNk+PFMNXaonR8d+2hnJSamBTl9HiJyD/bQERGJyOESPUauKXIqzAGARFI3EvXLQRGN9t3Rzr5gNqNjMJ7v7trePiJyLQY6IiIRyfy56ZGm9ogJlOLwrXEYlaxAslKKeb1VeL+vyq5zzLmBI1uJxI63XImIRKRM5+TCrACO3R5n8nlisBTfDIk02fbVoAhM+6WkyXOdmhSHEBn/9icSO4++S3NycvDSSy9h3LhxSEtLg0qlwqhRo6weo9Fo8Mwzz+D6669HTEwM0tLSMG3aNPz5558eqjURkW+JCWx6apGs1oFQya1PEHxjjBwRnKaEyCd4NNCtXr0a8+bNw9atWxEbG9tk+ZKSEgwZMgQffPABoqOjcd9992HQoEFYu3YthgwZgr1793qg1kREnnGuotau8r1i5OgRLTPZlj81webjX+8ebHX/JwM4qpXIV3j0luvYsWORmZmJTp06oaSkBOnp6VbLz507FydPnsSsWbPw6quvNmzfvXs3MjMz8eCDD2L79u3w8+PtACKy7FCJHm8fLMf5iloMT1Lg8S4hXl++qkJvhNYgQCGVQO4ngVwqQZfvbFsNIlkpxbpR0YgPcq73LNxKD92hibFIUvKpHCJf4dF3a4cOHewqv2bNGvj5+eGpp54y2d6zZ0+MHDkSq1evxtatW9G/f39XVpOImpG8SgNG/1yI0r+fTdtXpMelGiNe76XySn2MgoAnd5Xikz8rTbanhtgWzoqnJ7gsjAbLLJ+HYY7It4i6a0utViMyMhJKpbLRvpSUFADAli1bPF0tIvIhy89UN4S5ev85Uolao/ODDxwxd395ozAHwObVIFzZs6iQereXkohcR9R/gkVGRqKwsBAVFRWNQt3Zs2cBACdPnrTpXFqtc3M6WaLT6Uz+J3Fgu4iPt9rkqd2lZrevOV2O4Ylyj9Zlm1qPNw+WO3x8hFzi0p9lqYGWQ6S7fmaSdfzZJU7ubheFQuH0OUQd6IYOHYpvvvkGb7zxBl5++eWG7Xv37sW6desAAKWl5n9YXy0vLw8Gg/vWQ1SrbXv2hTyL7SI+nm8T85PozthWhl97V3u0Jq8dCgDg+HNvfVR6nD9/3nUVAhAhC0SJ3rSnblm3apdfh+zDn13i5I52kUqlSE1Ndfo8dge6OXPm2JVQZ8yYgbS0NHsvAwB4+umnsXHjRrz//vvYs2cPunfvDrVajeXLlyM9PR2HDx+2eUBEQoLtI7/sodPpoFarERsbC7ncs3/tk2VsF/HxRptsL9ADKDO7r8ogQVJSkkfqUW/f1mKnjn/khkgkhbvu73CdTod1vdR4+0IYlpzRAwB+yQxDB1VkE0eSu/Bnlzj5QrvY/ZNh4cKFqKxs/PyHJVlZWQ4HusTERGzatAlz587Fhg0bsG/fPiQmJuLpp59GcnIy7r77bkRFRdl0Lld0Z1ojl8vdfg2yH9tFfDzVJoIgYNxG6wHKk98bNQbnntlLD/NHt7jghiW9XOmd3qH4zyC+T8SEP7vEScztYnegy83NdUc9LEpISMD777/faPvcuXMBANdff71H60NEvuFkmX1zurlbqc7o8LEjkhSY11vlljBHRM2DqJ+hs8RgMOCHH36Av78/srKyvF0dIhKh/UV6q/sD7HyUrarWiI8OV8JfAoxtE4jWIfb9+Cx3cEkvzV2JDh1HRC2LqAOdXq9HbW0tAgMDG7YZjUY888wzOH78OP7xj38gPj7eizUkIrEK9Lfem1VjALS1AhRNlAOAfYU6DFlV2PD5C/vK8NOISAxMuHzrRW8UsK9Qh5hAKZKUUlTqBRgFAfdtuYSNuTUOfQ1ZKeK8tUNE4uPRQHfs2DHMnz8fwOUh8cePH8fMmTMbyixYsKDh44KCAvTu3RuDBg1CSkoKdDodNm3ahGPHjmHEiBF4/vnnPVl9IvIhW/ObDlGb8rS4KTmwyXJXhrl6Y9cVN/SenSqrxQ3fu37027t9ufQWEdnGo4FOrVZj8eLFJtsKCgpMtl0Z6EJDQ5GZmYldu3Zh3bp1kMlk6NChA9577z3ccccdXPKLiCz6z5GmB29N21SCojut39LU1Fh+9s1gFCD1k7glzN2dHozwAP6MIyLbeDTQZWRkQKPR2Fw+JCQEH3/8sfsqREQtWq1QtzRYQrDlB+rK9JYDXUWtgDAr66E66rthkRjWirdbich2on6GjojI3TouzcfZKfEI8pdg+ZlqaA0CboyRIz5IiskbS/DrRcu3bst0RhhcvIRYfJAfwxwR2Y2Bjoianf8cqbCrfNvFF2GlI86iMp2A1edcu0TWipG2za1JRHQlBjoialaOavR4cpdtSwLWcyTMAXVzy/2a59gI1np7x8XgpX1lSAiW4pHOIYgLcnxpMCJquRjoiKhZWX7Gc+uzlumNOFvh3ATGbcNk+Gowl9oiIudwCBURNStz95d77FrHNLU4csnxQNc9WubC2hBRS8ZAR0TkoOf2ljl8bL84OdbeFO3C2hBRS8ZbrkTUYvSKkWNXgc5r1z84IRbxQVLIpVyTlYhciz10RNQiqOQSfDrAuysvpIT4M8wRkVsw0BFRi5A9OhrJSn90jfTOc2u3pzW9xBgRkaMY6Iio2TAKlif5bRdWF+Qevy7E7fXoGO6PUNnlnjilvwQPdFS6/bpE1HLxGToiEqUag4BdBTrI/IBuUXKbblUuPWl+ypIRrQIaPh6a6NgqDA9dq8R7f9g2YXF4gB++HBSBZaeqYRCACamBuEbFEa1E5D4MdETkME2NEa/tL8OBIj26Rsnw9PWhUDm4oHxBtQEv7ivDbxdrIPeT4ETZ5elAgv0lyJkYi0iF9Ul3Z/x2yez2dRcuT/6r8HfsGbZ/dg2xOdC1CfFHuzAZnrqeIY6IPIOBjogcIggCxq8vwr4iPQBgd6EOvxfpkD0qGhKJ7aGpSGvAYzs0WH7G8hJalbUC0hbnIytFgTPlBrzSMwz94wMslncHpcz2oDq9fbAba0JE1BifoSMihxy+VNsQ5urtLdTjT43tE+0KgoApG0ushrkrrTirRU6JHllri3D/lhKbr/PmjWE2l3WFuCD+aCUiz+JPHSJyyJITVWa3L7aw/Wp7C3UIX5jn8LxwS09WQ1treRDEle5Md02P2YEJsTaVC3bwti4RkaMY6IjIIX4WMsv7f1Sgqtb8aveCAGRll0L1RS6Grip0ug5xX+fh7s0l0NYKOFtuuWdQdlVlV4yMsus67/dVAQBah/jjy0ERTZYP8uePViLyLP7UISKHFGnNhzYAuHap2uz2t0/JsLvIucXsr/bD6WrEfZ2H65aZv6Y5GXFyqOSNE2l8kB+Gt2r8bN7NKZfnkBvTOhCauxKtnj/A+tgNIiKX46AIInLI/6zcWi2pMUL1RS5e6RGKB6+9PO/btxfFMepTIpHgzJQEbMzVYvz6YgDAPdcE4/VeYZD5SbApV4ufz2uRFCzF5HZBZkfujmgVYDJ69urzExF5EgMdUQv0+v4yvH6gHACwY2wMOoTbF7Q+OWLb9B3P7CnDNSoZBiV4dkSqrYYkKsz2tg1OVGBwE/PVvdozDOsuFLirakREduEtV6IWQm8U8MLeuufX6sMcAPT+qQAnSvUWj9MZBBwv1aPWWDcA4Ux5Lf65q9Tm607ILkbWuiLklLj2Vqu3tQ0zH4KzUhybuJiIyBkMdEQtxH+OVOCdQ+Z71rr/UADBzLJZP52uRsxXeejxQwGivszDlos1WHTMtlGsV9qWr8Pz+yvtPs4VZnZ035xwazIbD674uH/TgyaIiFyNt1yJWgCDUcCze8qslglfmIfDt8YhMbjuif4LFbW4c7PpXG9Za4sQrXDs78AdBfb30AX7S1Bp49Qklsxw4xqqfeICcG5KPH4v0qFNiD9SQvgjlYi8gz99iJq5WqOAqZtsm4S367J8FE6ve6Zs0kbzxxRaGd3qKsduj0NMYF2wbLf4osPXfK+vyu0hK1Tuh4EJvM1KRN7FW65EzdyvF2vw83nbVmLQG9Fw6/VQieXn6tylVbAUORNjG8IcAGSPjnb4fNO4BBcRtRDsoSNq5j62cURqvWqDgIV/ef55t/f7qnBLm8BGa6a2DvHHiUlxWHyiCtpaAVPaBaPj0nyP14+ISMwY6IiauWwLc6VZcrrMgKd32z6Ktd5nA8Jxz6+X7D4OALaPjUFHK1OnRCmk+L8r5rOzxZnJ8Q7VhYjIF/GWK1EzZ++Qgr7LHZtbbXxqEIqnJ9h93JFb46yGOXMSgqz/6Jrc1vxkwEREzRV/4hE1Y0YzU5G4k9TSAq9WJATbv07WosGRFveNSFLgvb/XXiUiaikY6IiasX2FnhnYEHXFVCZf2bB4vbNuiJajb5y80fb8qQn4dmgk/B0IlkREvozP0BE1Y9vy7Xt+zlGfDbgc4m5OUWBYYgCyc9177dWZ0dihrsHuAh06qGQY2ioAflxDlYhaKPbQETVDgiAgt9KA3EqDxTKDXbi+6nWRl5+Bk0gk+G544xUUzJndxblJf3vHBuDhziEYnqRgmCOiFo2BjsiHCYKACr0R+VWXg1uNQcCD2zTotDQfnx61PP3II13sGzVqTZi8cZjaNibG6jFdImSY1cl9qzgQEbUkvOVK5INqDAJm79Dgm+OX11XtoPLHnxrbltf6ZnAE+scH4LluoXhpn/UlwWwhMdM71inC8sjVf3UNwePXhUDGZ92IiFyCPXREImYUBBwo0mHpySpU1V5e/uq5PaUmYQ6AzWEOADKT65aquivdvSsp5E1tPBdc7xh/PHV9KMMcEZELMdARiZS2VkDcV3kYuLIQ92+5hISvL2Lu/rretI//dG4lh/rnzcID/PDtUMtTgNQ7cmucQ9cJ8vfDwQmxuClZgc7hUoyL02Nhhutu9RIRUR0GOiKRWnisErqr1qR/40A5fs1z7ejREUkKPNct1GqZhGApUpTm54s7Ncl62EsJ8cf/hkQie6QKT7XVI0zOHztERK7Gn6xEXiZYmPz3yV3ml98as67IqeuNbR3YaJulW69v3RgGzV2JAICdt8Q22v9eXxUiFPZPDExERK7FQRFEHlAf2q4cPFChN2L2Dg3WndciMViK57uFYUSSwqS8O7zdO6zRtvAAP5yZHI9lp6rwS14N/tFJib5xptOaBPpLoLkrESdK9SjUGnFthAwhMv5NSEQkBgx0RG4kCAJuXluErfk6AMCd7YMwv48KEokEWWuL8HtR3UoOpbpa3LahGHvHxaBtmAzb1Tq31SnSQo+aKsAP93ZQ4t4O1qcSaRsmQ9vGmZCIiLyIf14TOaBcb8SPp6vw5V+VuFBheXRpm/9dbAhzALDwWBV6/FCAM+W1DWHuSp//VTfY4ZXfnZ9KhIiIWg720BHZqURrwM1ri3D4Ul2QC5NL8P3wKHSPNl1b1CgI0Oga3zo9UVaLrsvUZs/90eFKvNojDDvc1EM3IbXx83NEROT72ENHZKdvTlQ1hDkAKNUJGLqqsFG5h7ZpHDr/7RuKHTruhSZGqgLAmzeqHDo3ERGJG3voiOz07B7zt0NvWJaP3ydcnsJj0VUT/9pq3QXHpiV5pEsIHukSggq9EXsKdAgP8ENJjREv7itDj2g5XukRBoU/J/MlImqOGOiIXORUuQGaGiNUAZ7v+M6Iu3y7Vynzw6BERcPng6/4mIiImieP/ebR6/VYvnw5ZsyYgZ49eyIxMRGtWrXCkCFD8Nlnn8FgMFg8dunSpRg8eDASEhKQkpKC2267DQcOHPBU1YkavHWw3Or+XQV1z75V17pv2hFzHr+u6dutRETUfHks0J0+fRrTp0/HqlWr0LZtW9x7772YOHEi8vLy8Nhjj2Hy5Mlm59566623cP/996OwsBB33XUXxo4di+3bt2PEiBHYuXOnp6pPzYRRELD0ZBXeOliOTblau49vavTp7oK626WlVy/x4GapoZzcl4ioJfPYLVelUom33noLkyZNQnDw5VnpX3nlFYwePRrr1q3D8uXLMXbs2IZ9J0+exOuvv462bdti48aNCAurm/zqnnvuwbBhw/Dwww9jx44d8PPj2A6yzfRfSrDy7OUgN6NjMF7vpXLZ+d/OqcADHZXo+aP5UazOeLxLCN7KMd9DmKTk0xNERC2Zx5JQQkIC7r33XpMwBwDBwcGYNWsWAGDbtm0m+7755hvU1tbiscceawhzANClSxeMHz8ef/31F3bs2OH+ypPPqq4VcOSSHpdqjDhUojcJcwDwnyOVeGqXBjqDAKMguGSFhvZL8lFmZroSZz15fQhOT45vtP2/A8Jdfi0iIvItovizXiaTAQCkUtPbRlu3bgUADB48uNExQ4YMwf/+9z9s27YNffv2dX8lySXOlNdi5Zlq+PtJMKZ1IELlEhRpjUhRSk2WxXKWIAh46qgcG7aWNFl2wZFKLDhSabJt+YhIDEi4vAzXb/k6j99GvZq/nwThARIUT0/AqnNaXKoxYngrBRKCebuViKilE0WgW7RoEYDGwe3kyZNQKpWIjW28KHhaWlpDGVtotfY/L2ULnU5n8j9ZdqikFsPWXV5w/qndpovPb7kpDO3DXPMtueF8NTYUOX6uMeuKsWZYKJKVUgxYo0FxjWcHOVzt/nSFyffwiDgJACkAPbTaxitOiBHfK+LDNhEftok4ubtdFArnZyPweqBbuHAhsrOz0b9/fwwfPtxkX1lZGaKjo80eFxIS0lDGFnl5eVZH0jpLrXb9M1PNzYSdgQAs98L1X1OKPf0cm7vtavMOBaAu8Djupmz3L7/1xXVa3HXQ+ht5UGQt7o0qwfnzTfc2+gK+V8SHbSI+bBNxcke7SKVSpKamOn0euwPdnDlz7EqoM2bMaOhNu9ratWvxxBNPICkpCZ988om9VbFLQkKCW86r0+mgVqsRGxsLuVze9AEtWOnWpldAyEEMRiUFOH2t/TZcyxvO3xYBowBcqDSiTYgf/CQS3FxSjpXnzb+n3uoRjDvaNo955PheER+2ifiwTcTJF9rF7kC3cOFCVFZWNl3wb1lZWWYD3fr16zF9+nTExMRg5cqViIuLa1QmNDTUYg9ceXl5QxlbuKI70xq5XO72a7QErx6sxvh2YU0XBLApV4vvTlUjRCbBnenB6Bguc3PtnBcSVLeWatgVY4Me6uKHlecbLx0GAHd3CoOfC58tFAO+V8SHbSI+bBNxEnO72B3ocnNznb7ounXrMG3aNERGRmLlypVo3bq12XJpaWnYvXt3Qyq+Uv2zc5Z6/0hcDpXY9pzXdZFN/+VjFAQMWlmIg8WXz/nJn5XYeUsMrlGJN9TFBJofVN4t2nKdm1uYIyIi9/D4BG71YS48PBwrV660et+4fvTqpk2bGu3buHGjSRkSt6+O2darm19twKLjlfjmeCXKLIwq/eCPCpMwV+/hbRoAQKXeu6NRLXmhm/neZD+JBP/oFNxo+7+6hri7SkRE1Ex4NNBlZ2dj2rRpUKlUWLlyZZO9a1OmTIG/vz/efvttlJZeHhGZk5OD77//Hunp6ejdu7e7q012KNEasOREFdRVdQNQzlfUorDagANFtj13uUOtw4NbNZi1VYPkby7idFltozLvHKowe+yuAh0e3nYJvxd5btTnkzaGrpd7hGJS2yCL+1/rqcLrvS7fan6hW6jN5yYiIvLYKNdjx47hjjvuQE1NDfr164dly5Y1KpOcnIwpU6Y0fN62bVs8+eSTeOWVV9CvXz9kZWWhoqICP/zwAwDg3Xff5SoRIhK1MBeuXsJ0/qFyvNfXdOLckhrLPXBfHqvCl8csj5RdkxmFhGApjmr0uH2D86NG+8UHYF6gFLN3aMzuH5mkwJKhkTada0ZHJWZ0VDpdJyIiank8FujUajVqaurWufz+++/Nlunbt69JoAOAxx9/HMnJyViwYAE+//xzyGQy9O7dG08//TS6du3q7mqTjbbl17g8zAHAV8eqTALdmfLGPXa2GtNagT5xdSNoW4f4I29qPI5eqkVckBQdl+Y7dM4uETL0iZXjZFktPjzcuOfww34qh+tLRERkK48FuoyMDGg0GoeOvfXWW3Hrrbe6tkLkUqN+LnLr+XOKdfjPkUr874Tj89T937WmtzCD/P1wQ3TdIAzNXYkQBAHhC/NsPt+7fVQIldf1EL/aMwwvdA/F9vwa/JavQ68YOYYkBnBQAxEReYTXJxYm36A3Cnj/jwq8tK9uGpnEIClGJCkwPT0IE7PdO+fbP3dq8Mmftk+VY8n1kdZHwEokEpTcmYCRq4uwu9D8M38vdw+FKsAP/eIC0CbU9O0j85NgQIKiYckwIiIiT2GgoybpjQKivzTtucqtMuDzvyrx+V/OB62muCLMAYDUr+neMj+JBOtHRyO/yoAvj1XiYLEeBgEYEB+AUckKpITwLUNEROLD305kVY1BQOxXtt+GFKuciY3XA7YmLkiKf3W1bdJqIiIib+MQUbLKnWHu0c5K7B9vX9ByVLKSf7sQEVHzxUDXgl2qMWLhX5V4J6ccf15qPHebuyfovaNdMNqE+mPFyCi3Xid/qnvW8SUiIhILdluInMEooMPSfBRU14WrLwdFYEzrQKfPW6Q1oO3iy1N1vLCvDE9dH4IuETJ0jZIjPkiKWVs1Tl/Hkhe7hyItrO7br398AL4bFunw4AqlvwQXpibgbHktbttQjLwqA3pH++Pe2DJkpLeCwp8jTYmIqHljoBO5yKsGI0z/pQR3pQdhXm8VJE5MiTFydeNpRubuL2/4eNmwSPx0ptrh81sSKpPgmRtCcf9VE+gOa6XA7+NjccP3arvPuTkrGgCQEuKPnbfU3cLVarU4f77U2mFERETNBgOdiO1S15jd/sVfVSjXC/jvgAiHzlumM+KEmSW1rjTBhVOR9IiWYXVmNORS6wE0NdQfpybFIXWx7ZP8rsqMQtsw69OREBERNXcMdCJ1prwWI9ZYnqx32alqPNettuFh/7xKA7p9r0a1QcC4NoH474Bwi5PaPrj1klvqDACPdFbi+W6h2FOow28XdegSKbNrgt0IhdSmcv8dEI4JqZbXRiUiImpJOChChARBwJi1Ta+80OU7NX7N06JEa0DHpfmoNtStvfXD6WpEXLXigd4o4H/HK/H+oXKsOKt1qn7qaQl4rEvjNUd/GhGJF7qHQSKRoGdMAB67LgTDWinsXi1hVablQRID4gOguSuRYY6IiOgK7KEToU15NThbYbCp7Jh1lm+Nqr7IBVC3LNUPp6qwr6jxSFZHBEgleLZbGJ7tFoZaowB/GybstUe/uADsGxeLFWer8caBMmj/fin+kxGO29syyBEREV2NgU6Exq937VJac3a7bnDA3enBJp+7OszVSwvzx6NdQvBol5CmCxMREbVwDHQiUaE3otWii96uRpOevoEBi4iISGz4DJ0I5FYafCLMAUCUjYMWiIiIyHPYQ+dBRkHAtUvzkVdlRHyQHw5MiMPBYh2Gm5kTToz+sHM9VCIiIvIMBjoPqNQb8c6hCrx58PLEvRerjKJa9L5HtAx7Ci0PmvjvgHC04nqoREREosTf0G5mMApotegiBBec67thkSjVGXHvr66dR27fuNiGZbgEQcCQVYX4/e8RsV0iZNicFW331CNERETkOQx0bnbPr5dcEua2jYlBpwgZBEFwaaALkUkawhwASCQSbLo5xmXnJyIiIvfjoAg30hkEl62H2imibnkriUSCvKnxmN6+bj42uRMteI3KHycnxbuiekRERORF7KFzo0d3aFxynp9vMl05IcjfD+/2Dce7fcMBAFW1RmRfqFv3dWSSAgFSCQxGAUYA/n/fKV10vAqnymoxuV0Q2nHtUyIiomaFgc6Nvjle5dTxr/cKw+1pQVAFWO+GC/L3w5jWgSbbpH4SXDnByNT2phMCExERUfPBQOcmZ8trnTp+/ago9IwJcFFtiIiIqDljoHOTB7c6PnDhwh3xUMr4eCMRERHZhqnBTX7L19l9zKS2QTg1KY5hjoiIiOzC5OAG6iqDxX3/7hWGU5PiGm1fNiwSCzLCEcGltYiIiMhOvOXqYgeKdBi4stDi/vs6BEMikeDSnQnYmq9DrVHA9VHyJgc+EBEREVnCQOdi1sIcUDePXP3/GfEc9EBERETOY7eQC5XqjN6uAhEREbVADHQulPLNRav7R7RijxwRERG5HgOdB73cI8zbVSAiIqJmiIHORc6UWx7ZWq+9iktuERERkesx0LnIFrXe4r4OKn/svCXGg7UhIiKiloSjXF3kn3sqzW6PDfTDb2Ni4O8n8XCNiIiIqKVgD52bPdolhGGOiIiI3IqBzs3uTg/2dhWIiIiomWOgc4FqK+Mh5FL2zhEREZF7MdC5wN5S8y/juDaBHq4JERERtUQMdC6wPN/82JK2YRxzQkRERO7HQOckQRDwa4n54HZbapCHa0NEREQtEQOdk/YX11rclxwi9WBNiIiIqKVioHPSTdllFvfJOF0JEREReQADnZtEK/jSEhERkWcwdThBZxAs7vvl5mgP1oSIiIhaMgY6J+SUWF6/tZWSI1yJiIjIMxjonLD2nNbsds4/R0RERJ7ksW4kvV6PNWvW4Oeff8bvv/+O3NxcSCQSpKenY/LkybjzzjshlZqOCq2qqsJnn32GgwcP4uDBgzhx4gQEQcDBgweRkpLiqapb9Fep+R66O9pxuhIiIiLyHI8FutOnT2P69OlQKpXo378/MjMzUVZWhrVr1+Kxxx7D+vXrsWTJEkgkl0eGFhYW4tlnnwUAJCUlQaVS4dKlS56qcpNWnjXfQ9cnNsDDNSEiIqKWzGOBTqlU4q233sKkSZMQHHx5wfpXXnkFo0ePxrp167B8+XKMHTu2YV9kZCR+/PFHdO3aFeHh4Rg/fjw2btzoqSo7TOHP6UqIiIjIczz2DF1CQgLuvfdekzAHAMHBwZg1axYAYNu2bSb7lEolBg0ahPDwcE9V02YlWgMAILOVDF1CDF6uDREREbVkohiKKZPJAKDRM3SupNWavz3qqNwyAya0luMf7fwxOPvys3RhMonLr0X20+l0Jv+T97FNxIdtIj5sE3Fyd7soFAqnzyGKQLdo0SIAwODBg912jby8PBgMrutJEwzAE4mAXzXQOSQAh8rrwuj0xBqcP3/eZdch56jVam9Xga7CNhEfton4sE3EyR3tIpVKkZqa6vR5vB7oFi5ciOzsbPTv3x/Dhw9323USEhLcct6y6hocKq9o+PyBG2IRGcDZYLxNp9NBrVYjNjYWcrnc29UhsE3EiG0iPmwTcfKFdrE70M2ZM8euLscZM2YgLS3N7L61a9fiiSeeQFJSEj755BN7q2IXV3RnWjIx/hJWqGV4v184EsM4ZYmYyOVyt7Y92Y9tIj5sE/Fhm4iTmNvF7kC3cOFCVFZW2lw+KyvLbKBbv349pk+fjpiYGKxcuRJxcXH2VkU0piXW4t/9YhGu5ITCRERE5Hl2B7rc3FynL7pu3TpMmzYNkZGRWLlyJVq3bu30Ob0pTiEgkFOVEBERkZd4/GGv+jAXHh6OlStXuuRBQCIiIqKWzKOBLjs7G9OmTYNKpcLKlSstPltHRERERLbz2CjXY8eO4Y477kBNTQ369euHZcuWNSqTnJyMKVOmmGx75plnUFxcDAA4cuQIAODZZ59tmKB42rRp6N27t5trT0RERCReHgt0arUaNTU1AIDvv//ebJm+ffs2CnTLly9vNK/bihUrGj7u168fAx0RERG1aB4LdBkZGdBoNHYfd+jQIddXhoiIiKgZ4Qy4RERERD6OgY6IiIjIxzHQEREREfk4BjoiIiIiH8dAR0REROTjGOhcQCqVersKZAbbRXzYJuLDNhEftok4ib1dJBqNRvB2JYiIiIjIceyhIyIiIvJxDHREREREPo6BjoiIiMjHMdARERER+TgGOiIiIiIfx0BHRERE5OMY6IiIiIh8HAMdERERkY9joHPQ77//jokTJyI5ORkJCQkYOnQofvzxR29Xy6fk5eXho48+wi233IJrr70W0dHRaN++PaZOnYq9e/eaPaasrAxPP/00rr32WsTExKBz58549tlnUVFRYba80WjExx9/jD59+iAuLg5paWm45557cObMGYv12rhxI2666Sa0atUKSUlJGD16NH799VdXfMk+65133oFKpYJKpcKePXsa7We7eM7KlSsxduxYtGnTBrGxsejSpQvuueceXLhwwaQc28T9BEHAihUrMHr0aKSnpyM+Ph7du3fHI488YvZ1Y5u4zrfffotHHnkEAwcORExMDFQqFb755huL5cX42p84cQJ33nknUlNTERcXh759++Kzzz6DIDi23gNXinDAli1bMH78eCgUCowbNw5KpRIrVqzA+fPn8fLLL+P//u//vF1Fn/DCCy/gnXfeQZs2bdCvXz9ERUXh5MmTWL16NQRBwH//+1+MGzeuoXxlZSVGjhyJQ4cOYfDgwejSpQtycnKwadMm3HDDDVizZg0UCoXJNR566CF89dVX6NChA4YPH46LFy/ip59+QnBwMDZs2IC0tDST8t9++y0eeOABREVF4ZZbbgEA/PjjjyguLsbChQsxZswY978wInPkyBEMGjQI/v7+qKysRHZ2Nnr06NGwn+3iGYIg4NFHH8XChQvRpk0bDBkyBEqlEhcvXsS2bdvw6aefonfv3gDYJp4yZ84cfPjhh4iLi8NNN92EkJAQ/PHHH9i0aROUSiXWrVuHjh07AmCbuFrnzp1x/vx5REZGIigoCOfPn8eHH36IKVOmNCorxtf+6NGjGD58OLRaLcaOHYv4+HisX78ef/75J+677z68+eabdr8mDHR2qq2tRY8ePZCXl4fs7Gx06dIFAFBaWoohQ4bg3Llz2Lt3L5KTk71cU/FbsWIFIiIi0K9fP5Pt27dvx5gxYxAcHIy//voLAQEBAIDXXnsN//73v/HII4/ghRdeaChfHwyfe+45zJ49u2H7li1bkJWVhT59+uCnn36CXC4HAGRnZ2PixIkYPHgwfvjhh4byGo0G1113Hfz9/bFlyxYkJiYCAHJzc9G/f38AwIEDBxASEuKW10OM9Ho9hg4dCplMhtTUVCxdurRRoGO7eMaCBQvw1FNP4d5778Ubb7zRaF3J2tpa+Pv7A2CbeIJarUaHDh2QmJiIrVu3IiwsrGHfhx9+iDlz5mDKlCn48MMPAbBNXG3z5s1ITU1FcnIy5s+fjxdffNFioBPja3/TTTdh+/bt+O677zBs2DAAgE6nw5gxY7Bjxw6sX78ePXv2tOs14S1XO23ZsgWnT5/GhAkTGsIcAISFhWH27NnQ6XRYvHixF2voO7KyshqFOQDo06cPMjIyoNFocOTIEQB1vRNff/01lEolnnjiCZPyTzzxBJRKJb766iuT7fWfz5kzp+ENCQDDhg1Dv379sGnTJpw/f75h+08//YTS0lLcf//9DW9IAEhMTMR9992H4uJirFq1yvkv3Ie89dZbOHr0KD744AOzC1OzXTyjuroab7zxBlq3bo3XX3/dbFvUhzm2iWecO3cORqMRN954o0mYA4CRI0cCAIqKigCwTdxh4MCBNnWciPG1P3HiBLZv346MjIyGMAcAcrkcc+bMAQB8+eWXtrwMJhjo7LR161YAwODBgxvtGzJkCABg27ZtHq1TcySTyQCg4RfXyZMncfHiRfTq1QvBwcEmZYODg9GrVy+cOXPG5DmirVu3Ijg4GDfeeGOj85trK7atqQMHDuDtt9/Gv/71L1xzzTVmy7BdPGPTpk3QaDQYNWoUDAYDVqxYgfnz5+Pzzz/HqVOnTMqyTTwjLS0NcrkcO3fuRFlZmcm+tWvXAgAGDBgAgG3iTWJ87a2V7927N4KDgx1qKwY6O508eRIAGt0/B4DY2FgolcpGP2DJPufPn8fmzZsRFxeHTp06Abj8uqemppo9pn57fbnKykrk5+cjJSXFbG/G1eWv/Nhc29Zvu7J8c1ZTU4OZM2eic+fOePjhhy2WY7t4xoEDBwDU/YHTt29fTJs2DS+++CJmz56N7t2745lnnmkoyzbxjIiICDz//PO4cOECevbsidmzZ+P555/H+PHj8cILL+Dee+/F/fffD4Bt4k1ifO2t1UkqlSIlJQXnzp1DbW1tE1+dKX+7SlPDX2KhoaFm94eEhDT6a41sp9fr8cADD6CmpgYvvPBCwxuq/jW9+tZGvfr2qC/XVDtdXb6pY+qffWgpbfvaa6/h5MmT2Lx5s9kfavXYLp5Rf+vuww8/xHXXXYdNmzahffv2yMnJwSOPPIIPPvgAbdq0wT333MM28aBZs2YhISEBDz30ED7//POG7b1798aECRMaboOzTbxHjK99U3UKCQmB0WhERUUFVCqV2TLmsIeORMNoNOIf//gHtm/fjunTp+P222/3dpVapN27d+P999/H448/3jBCj7zLaDQCqHvG5ptvvsENN9wApVKJPn36YOHChfDz88MHH3zg5Vq2PG+88Qbuv/9+zJ49G4cPH8aFCxfw888/Q6vVYvTo0VizZo23q0gtCAOdncyl8yuVl5dbTPZkmdFoxKxZs/Ddd9/h1ltvxfz5803217+mpaWlZo+/+i+kptrJ3F9U1o4pLy9vVL45qq2txcyZM9GpUyc8+uijTZZnu3hG/dfXtWtXxMfHm+zr2LEjWrdujdOnT0Oj0bBNPGTz5s2YO3cu7rvvPjz66KNITEyEUqlE7969sWTJEshksoZb4WwT7xHja99UncrLyyGRSKBUKs3ut4SBzk7WnkVQq9WoqKiweK+ezKvvmVu8eDEmTJiABQsWwM/P9Fuz/nW39Hxi/fb6csHBwYiLi8PZs2dhMBiaLH/lx+ba1tozEs1JRUUFTp48iUOHDiE6OrphMmGVStUwenvYsGFQqVRYtWoV28VD2rVrB8DyLZr67Vqtlm3iIdnZ2QCAjIyMRvtiY2PRrl07nDp1ChUVFWwTLxLja2+tTgaDAWfPnkVKSkrDLXtbMdDZqW/fvgDqRp1dbePGjSZlqGn1YW7JkiUYN24cPv74Y7PPbKWlpSE+Ph67du1CZWWlyb7Kykrs2rULKSkpaNWqVcP2vn37orKyEjt37mx0vvq26tOnj0l5oGW3bUBAAKZOnWr2X/0PoczMTEydOhXJyclsFw+pDw3Hjh1rtE+v1+PUqVMIDg5GVFQU28RDdDodgMvPN16tuLgYfn5+kMlkbBMvEuNrb638jh07UFlZ6VBbMdDZacCAAWjdujWWLVuGnJychu2lpaWYN28e5HI5n/2yUf1t1iVLlmDs2LH45JNPLD6AL5FIMHXqVFRUVDSaQfvNN99ERUUFpk+fbrK9/vNXX3214YcvUPeX9datWzF48GCTeYxuueUWhIaG4pNPPkFubm7D9tzcXHz66aeIjIzE6NGjnf66xSwwMBDvv/++2X/1k1zOnj0b77//Prp06cJ28ZA2bdpg8ODBOHXqVKM5s+bPn4/S0lKMGjUK/v7+bBMPqZ/S4qOPPmp06+zzzz9Hbm4uevbsiYCAALaJF4nxtW/Xrh369OmD3377raGnF6j7I+HVV18FAEybNs3+r5UrRdiPS3+5xty5c/HGG29AqVRixowZZsPcqFGjGiZwrqysxIgRI/DHH39g8ODBuO6663Dw4MGG5VtWr16NwMBAk+OvXr4lPz8fP/74I4KDg5GdnY22bdualLe2fMsXX3yBsWPHuufF8AEzZ87E4sWLzS79xXZxv9OnT2P48OEoLCzEiBEj0K5dO+Tk5GDLli1ISkrChg0bEBsbC4Bt4gkGgwE333wztm/fjujoaGRmZiIsLAwHDx7Eli1bEBgYiFWrVqFbt24A2Cau9tVXX2HHjh0A6pYnPHjwIG688Ua0adMGQN1I4/pQJMbX/s8//8SIESOg1Wpxyy23IC4ujkt/ecu+ffswd+5c7N69G3q9Hh07dsSsWbNM1h4l6+oDgjVXL+VSWlqK119/HStXroRarUZsbCzGjh2Lf/3rX2aXtDEajfjkk0/w5ZdfNtyWGjhwIJ599tmGN/7VNmzYgLfffhs5OTmQSCS47rrr8MQTT2DgwIFOfb2+zlKgA9gunnLhwgW89tpr2LhxI0pKShAbG4vMzEz885//RHR0tElZton71dTU4KOPPsKPP/6IEydOQKfTISYmBv369cNjjz2G9PR0k/JsE9dp6vfHpEmTsGDBgobPxfjaHz9+HK+88gq2bNmCqqoqpKWl4e6778Y999wDiURi3wsCBjoiIiIin8dn6IiIiIh8HAMdERERkY9joCMiIiLycQx0RERERD6OgY6IiIjIxzHQEREREfk4BjoiIiIiH8dAR0REROTjGOiIiIiIfBwDHREREZGPY6AjIiIi8nEMdEREREQ+7v8B1eUDqs5NJb4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "def plot_graph2(data):\n",
    "    for line in data:\n",
    "        xs.append(float(line[0]))\n",
    "        ys.append(float(line[1]))\n",
    "        ax1.clear()\n",
    "        \n",
    "    ax1.plot(xs, ys)\n",
    "    plt.pause(1)\n",
    "    plt.show()\n",
    "\n",
    "plot_graph2(hist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHYCDYwhlVLV",
    "outputId": "44023870-3ed0-46f5-84e7-df559e94ffc0"
   },
   "outputs": [],
   "source": [
    "#%time hist2 = train_model(env, model, total_episodes=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "8fheN9DRlWXQ",
    "outputId": "23490ad9-3ac8-4899-824b-44400caa8afd"
   },
   "outputs": [],
   "source": [
    "#play_game(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AxOcQhIsKow",
    "outputId": "68d93a54-196d-4d91-a6f6-731aa0de23c4"
   },
   "outputs": [],
   "source": [
    "#%time hist3 = train_model(env, model, total_episodes=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "w2NblmwDsL3y",
    "outputId": "f3dc32bf-ab84-418d-b830-407510690d12"
   },
   "outputs": [],
   "source": [
    "#play_game(env, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "H=200 le-4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "83a8a37af132a2fa5bd73ffbd7034c1e5f9f9b0bef7ee17d2a911228df5d8f19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
