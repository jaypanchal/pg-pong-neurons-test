{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cWACPRL869I4"
   },
   "outputs": [],
   "source": [
    "# C0797202 JAY PANCHAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from memory_profiler) (5.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (1.23.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JSAnimation in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.3)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[accept-rom-license,atari] in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (1.23.2)\n",
      "Requirement already satisfied: ale-py~=0.7.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.7.5)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.28.1)\n",
      "Requirement already satisfied: click in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "UsageError: Line magic function `%%file` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install memory_profiler\n",
    "%load_ext memory_profiler\n",
    "%pip install gym\n",
    "%pip install JSAnimation\n",
    "%pip install matplotlib\n",
    "%pip install -U gym >= 0.21.0\n",
    "%pip install -U gym[atari,accept-rom-license]\n",
    "\n",
    "%%file training.py\n",
    "\n",
    "%%python -m memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wotUOa_e6edP"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "from matplotlib import animation\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R66_INeZ9nYX"
   },
   "source": [
    "## Initiating Ping Pong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtT2GyK_6edc",
    "outputId": "6ef17a84-3563-4157-caf3-2c50438190ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\envs\\registration.py:593: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "# Importing gym library and creating environment\n",
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRE6WmXQJ1Z0",
    "outputId": "41a4b484-4f7e-4fd6-fc69-e626adec0523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trwRXI-h6eeI",
    "outputId": "42368b9e-2477-41ef-fb42-30ced75282c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\jaypanchal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished without success, accumulated reward = -19.0\n"
     ]
    }
   ],
   "source": [
    "# Run a demo of the environment\n",
    "observation = env.reset()\n",
    "cumulated_reward = 0\n",
    "\n",
    "frames = []\n",
    "for t in range(1000):\n",
    "#     print(observation)\n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    # very stupid agent, just makes a random action within the allowd action space\n",
    "    action = env.action_space.sample()\n",
    "#     print(\"Action: {}\".format(t+1))    \n",
    "    observation, reward, done, info = env.step(action)\n",
    "#     print(reward)\n",
    "    cumulated_reward += reward\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
    "        break\n",
    "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3zZTecVWLLes"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
    "\n",
    "def prepro(I):\n",
    "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "  I = I[35:195] # crop\n",
    "  I = I[::2,::2,0] # downsample by factor of 2\n",
    "  I[I == 144] = 0 # erase background (background type 1)\n",
    "  I[I == 109] = 0 # erase background (background type 2)\n",
    "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "  return I.astype(np.float).ravel()\n",
    "\n",
    "def policy_forward(x):\n",
    "  h = np.dot(model['W1'], x)\n",
    "  h[h<0] = 0 # ReLU nonlinearity\n",
    "  logp = np.dot(model['W2'], h)\n",
    "  p = sigmoid(logp)\n",
    "  return p, h # return probability of taking action 2, and hidden state\n",
    "\n",
    "def model_step(model, observation, prev_x):\n",
    "  # preprocess the observation, set input to network to be difference image\n",
    "  cur_x = prepro(observation)\n",
    "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "  prev_x = cur_x\n",
    "  \n",
    "  # forward the policy network and sample an action from the returned probability\n",
    "  aprob, _ = policy_forward(x)\n",
    "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
    "  \n",
    "  return action, prev_x\n",
    "\n",
    "def play_game(env, model):\n",
    "  observation = env.reset()\n",
    "\n",
    "  frames = []\n",
    "  cumulated_reward = 0\n",
    "\n",
    "  prev_x = None # used in computing the difference frame\n",
    "\n",
    "  for t in range(1000):\n",
    "      frames.append(env.render(mode = 'rgb_array'))\n",
    "      action, prev_x = model_step(model, observation, prev_x)\n",
    "      observation, reward, done, info = env.step(action)\n",
    "      cumulated_reward += reward\n",
    "      if done:\n",
    "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
    "          break\n",
    "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
    "  display_frames_as_gif(frames)\n",
    "  env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gWvZQ7AQLQt"
   },
   "source": [
    "# Logic behind the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eqFm7hqcItWl"
   },
   "outputs": [],
   "source": [
    "# Init the model\n",
    "\n",
    "# number of neurons\n",
    "H = 200 \n",
    "\n",
    "# input dimensionality: 80x80 grid\n",
    "D = 80 * 80 \n",
    "\n",
    "model = {}\n",
    "def update_neurons(neurons = 200):\n",
    "    H = neurons\n",
    "    \n",
    "    # \"Xavier\" initialization\n",
    "    \n",
    "    model['W1'] = np.random.randn(H,D) / np.sqrt(D)\n",
    "    model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "update_neurons(H)\n",
    "\n",
    "# import pickle\n",
    "#  model = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TwjiwKisQM19"
   },
   "outputs": [],
   "source": [
    "\n",
    "# hyperparameters\n",
    "import sys\n",
    "\n",
    "\n",
    "batch_size = 10 # every how many episodes to do a param update?\n",
    "\n",
    "# learning_rate = 1e-4\n",
    "learning_rate = 1e-2\n",
    " \n",
    "# discount factor for reward\n",
    "gamma = 0.99 \n",
    "\n",
    "# decay factor for RMSProp leaky sum of grad^2\n",
    "decay_rate = 0.99 \n",
    "  \n",
    "# update buffers that add up gradients over a batch\n",
    "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } \n",
    "\n",
    "# rmsprop memory\n",
    "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } \n",
    "\n",
    "def discount_rewards(r):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "def policy_backward(epx, eph, epdlogp):\n",
    "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
    "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "  dh = np.outer(epdlogp, model['W2'])\n",
    "  dh[eph <= 0] = 0 # backpro prelu\n",
    "  dW1 = np.dot(dh.T, epx)\n",
    "  return {'W1':dW1, 'W2':dW2}\n",
    "\n",
    "\n",
    "def train_model(env, model, total_episodes = 100):\n",
    "  hist = []\n",
    "  hist_2 = []\n",
    "  observation = env.reset()\n",
    "\n",
    "  prev_x = None # used in computing the difference frame\n",
    "  xs,hs,dlogps,drs = [],[],[],[]\n",
    "  running_reward = None\n",
    "  reward_sum = 0\n",
    "  episode_number = 0\n",
    "\n",
    "  from datetime import datetime\n",
    "\n",
    "  now = datetime.now()\n",
    "  print(f'Start time: {now}')\n",
    "\n",
    "  last_export_time = now\n",
    "\n",
    "  while True:\n",
    "    # preprocess the observation, set input to network to be difference image\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # forward the policy network and sample an action from the returned probability\n",
    "    aprob, h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
    "\n",
    "    # record various intermediates (needed later for backprop)\n",
    "    xs.append(x) # observation\n",
    "    hs.append(h) # hidden state\n",
    "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
    "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
    "\n",
    "    # step the environment and get new measurements\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "    if done: # an episode finished\n",
    "      episode_number += 1\n",
    "\n",
    "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "      epx = np.vstack(xs)\n",
    "      eph = np.vstack(hs)\n",
    "      epdlogp = np.vstack(dlogps)\n",
    "      epr = np.vstack(drs)\n",
    "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
    "\n",
    "      # compute the discounted reward backwards through time\n",
    "      discounted_epr = discount_rewards(epr)\n",
    "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "      discounted_epr -= np.mean(discounted_epr)\n",
    "      discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
    "      grad = policy_backward(epx, eph, epdlogp)\n",
    "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
    "\n",
    "      # perform rmsprop parameter update every batch_size episodes\n",
    "      if episode_number % batch_size == 0:\n",
    "        for k,v in model.items():\n",
    "          g = grad_buffer[k] # gradient\n",
    "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
    "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
    "\n",
    "      # boring book-keeping\n",
    "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "      hist.append((episode_number, reward_sum, running_reward,datetime.now()))\n",
    "      hist_2.append((episode_number, running_reward))\n",
    "      \n",
    "      if ((datetime.now() - last_export_time).total_seconds() > 30):\n",
    "        file_name = 'hist1_'+ str(total_episodes) + '_H_200_LR10E2_.csv'\n",
    "        np.savetxt(file_name, hist, delimiter =\",\", fmt ='% s')\n",
    "        last_export_time = datetime.now()\n",
    "        \n",
    "      print (f'resetting env. episode {episode_number}, reward total was {reward_sum}. running mean: {running_reward}, timestamp: {datetime.now()}')\n",
    "            \n",
    "      reward_sum = 0\n",
    "      observation = env.reset() # reset env\n",
    "      prev_x = None\n",
    "\n",
    "      if running_reward > -11.95:\n",
    "        sys.exit()\n",
    "\n",
    "      if episode_number == total_episodes:\n",
    "        return hist, hist_2\n",
    "\n",
    "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
    "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6Ka_5Vl9Orm",
    "outputId": "75de5744-f8e4-4aea-c00f-2cb2977a38cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2022-08-20 06:48:03.180522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaypanchal\\AppData\\Local\\Temp\\ipykernel_1168\\1818632268.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return I.astype(np.float).ravel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode 1, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-20 06:48:04.865538\n",
      "resetting env. episode 2, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-20 06:48:06.079556\n",
      "resetting env. episode 3, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-20 06:48:07.667569\n",
      "resetting env. episode 4, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-20 06:48:08.793584\n",
      "resetting env. episode 5, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-20 06:48:10.217598\n",
      "resetting env. episode 6, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-20 06:48:11.386611\n",
      "resetting env. episode 7, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-20 06:48:12.664625\n",
      "resetting env. episode 8, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-20 06:48:13.871635\n",
      "resetting env. episode 9, reward total was -20.0. running mean: -20.99, timestamp: 2022-08-20 06:48:15.333655\n",
      "resetting env. episode 10, reward total was -20.0. running mean: -20.980099999999997, timestamp: 2022-08-20 06:48:16.793669\n",
      "resetting env. episode 11, reward total was -21.0. running mean: -20.980299, timestamp: 2022-08-20 06:48:17.871683\n",
      "resetting env. episode 12, reward total was -21.0. running mean: -20.98049601, timestamp: 2022-08-20 06:48:18.839696\n",
      "resetting env. episode 13, reward total was -21.0. running mean: -20.9806910499, timestamp: 2022-08-20 06:48:20.150707\n",
      "resetting env. episode 14, reward total was -21.0. running mean: -20.980884139401, timestamp: 2022-08-20 06:48:21.102718\n",
      "resetting env. episode 15, reward total was -21.0. running mean: -20.98107529800699, timestamp: 2022-08-20 06:48:22.343727\n",
      "resetting env. episode 16, reward total was -21.0. running mean: -20.98126454502692, timestamp: 2022-08-20 06:48:23.389740\n",
      "resetting env. episode 17, reward total was -21.0. running mean: -20.98145189957665, timestamp: 2022-08-20 06:48:24.539752\n",
      "resetting env. episode 18, reward total was -21.0. running mean: -20.981637380580885, timestamp: 2022-08-20 06:48:25.585767\n",
      "resetting env. episode 19, reward total was -21.0. running mean: -20.98182100677508, timestamp: 2022-08-20 06:48:26.776783\n",
      "resetting env. episode 20, reward total was -21.0. running mean: -20.982002796707327, timestamp: 2022-08-20 06:48:27.797790\n",
      "resetting env. episode 21, reward total was -21.0. running mean: -20.982182768740255, timestamp: 2022-08-20 06:48:28.922799\n",
      "resetting env. episode 22, reward total was -21.0. running mean: -20.982360941052853, timestamp: 2022-08-20 06:48:30.120813\n",
      "resetting env. episode 23, reward total was -21.0. running mean: -20.982537331642327, timestamp: 2022-08-20 06:48:31.134827\n",
      "resetting env. episode 24, reward total was -21.0. running mean: -20.982711958325904, timestamp: 2022-08-20 06:48:32.377836\n",
      "resetting env. episode 25, reward total was -21.0. running mean: -20.982884838742645, timestamp: 2022-08-20 06:48:33.386847\n",
      "resetting env. episode 26, reward total was -21.0. running mean: -20.98305599035522, timestamp: 2022-08-20 06:48:34.656860\n",
      "resetting env. episode 27, reward total was -21.0. running mean: -20.983225430451668, timestamp: 2022-08-20 06:48:35.999876\n",
      "resetting env. episode 28, reward total was -21.0. running mean: -20.983393176147153, timestamp: 2022-08-20 06:48:37.303890\n",
      "resetting env. episode 29, reward total was -21.0. running mean: -20.98355924438568, timestamp: 2022-08-20 06:48:38.338902\n",
      "resetting env. episode 30, reward total was -21.0. running mean: -20.983723651941826, timestamp: 2022-08-20 06:48:39.597912\n",
      "resetting env. episode 31, reward total was -21.0. running mean: -20.983886415422408, timestamp: 2022-08-20 06:48:40.693926\n",
      "resetting env. episode 32, reward total was -21.0. running mean: -20.984047551268183, timestamp: 2022-08-20 06:48:41.925940\n",
      "resetting env. episode 33, reward total was -21.0. running mean: -20.984207075755503, timestamp: 2022-08-20 06:48:43.170960\n",
      "resetting env. episode 34, reward total was -21.0. running mean: -20.984365004997947, timestamp: 2022-08-20 06:48:44.633968\n",
      "resetting env. episode 35, reward total was -21.0. running mean: -20.98452135494797, timestamp: 2022-08-20 06:48:45.968982\n",
      "resetting env. episode 36, reward total was -21.0. running mean: -20.98467614139849, timestamp: 2022-08-20 06:48:47.411002\n",
      "resetting env. episode 37, reward total was -21.0. running mean: -20.984829379984507, timestamp: 2022-08-20 06:48:48.585010\n",
      "resetting env. episode 38, reward total was -21.0. running mean: -20.984981086184664, timestamp: 2022-08-20 06:48:49.966028\n",
      "resetting env. episode 39, reward total was -21.0. running mean: -20.985131275322818, timestamp: 2022-08-20 06:48:50.987039\n",
      "resetting env. episode 40, reward total was -21.0. running mean: -20.98527996256959, timestamp: 2022-08-20 06:48:52.232049\n",
      "resetting env. episode 41, reward total was -21.0. running mean: -20.985427162943893, timestamp: 2022-08-20 06:48:53.271060\n",
      "resetting env. episode 42, reward total was -21.0. running mean: -20.985572891314455, timestamp: 2022-08-20 06:48:54.504076\n",
      "resetting env. episode 43, reward total was -21.0. running mean: -20.98571716240131, timestamp: 2022-08-20 06:48:55.506086\n",
      "resetting env. episode 44, reward total was -21.0. running mean: -20.9858599907773, timestamp: 2022-08-20 06:48:56.816098\n",
      "resetting env. episode 45, reward total was -21.0. running mean: -20.98600139086953, timestamp: 2022-08-20 06:48:57.821114\n",
      "resetting env. episode 46, reward total was -21.0. running mean: -20.986141376960834, timestamp: 2022-08-20 06:48:59.201125\n",
      "resetting env. episode 47, reward total was -21.0. running mean: -20.986279963191226, timestamp: 2022-08-20 06:49:00.305142\n",
      "resetting env. episode 48, reward total was -21.0. running mean: -20.986417163559313, timestamp: 2022-08-20 06:49:01.457153\n",
      "resetting env. episode 49, reward total was -21.0. running mean: -20.98655299192372, timestamp: 2022-08-20 06:49:02.525163\n",
      "resetting env. episode 50, reward total was -21.0. running mean: -20.986687462004483, timestamp: 2022-08-20 06:49:03.576175\n",
      "resetting env. episode 51, reward total was -21.0. running mean: -20.98682058738444, timestamp: 2022-08-20 06:49:05.151189\n",
      "resetting env. episode 52, reward total was -21.0. running mean: -20.986952381510594, timestamp: 2022-08-20 06:49:06.799210\n",
      "resetting env. episode 53, reward total was -21.0. running mean: -20.98708285769549, timestamp: 2022-08-20 06:49:07.971220\n",
      "resetting env. episode 54, reward total was -21.0. running mean: -20.987212029118535, timestamp: 2022-08-20 06:49:09.215237\n",
      "resetting env. episode 55, reward total was -21.0. running mean: -20.98733990882735, timestamp: 2022-08-20 06:49:10.561248\n",
      "resetting env. episode 56, reward total was -20.0. running mean: -20.977466509739077, timestamp: 2022-08-20 06:49:12.188278\n",
      "resetting env. episode 57, reward total was -21.0. running mean: -20.977691844641686, timestamp: 2022-08-20 06:49:13.603281\n",
      "resetting env. episode 58, reward total was -21.0. running mean: -20.97791492619527, timestamp: 2022-08-20 06:49:15.171299\n",
      "resetting env. episode 59, reward total was -21.0. running mean: -20.97813577693332, timestamp: 2022-08-20 06:49:17.100323\n",
      "resetting env. episode 60, reward total was -21.0. running mean: -20.97835441916399, timestamp: 2022-08-20 06:49:19.250344\n",
      "resetting env. episode 61, reward total was -21.0. running mean: -20.97857087497235, timestamp: 2022-08-20 06:49:20.337354\n",
      "resetting env. episode 62, reward total was -20.0. running mean: -20.968785166222624, timestamp: 2022-08-20 06:49:22.361378\n",
      "resetting env. episode 63, reward total was -21.0. running mean: -20.969097314560397, timestamp: 2022-08-20 06:49:24.016400\n",
      "resetting env. episode 64, reward total was -21.0. running mean: -20.969406341414793, timestamp: 2022-08-20 06:49:25.189416\n",
      "resetting env. episode 65, reward total was -21.0. running mean: -20.969712278000646, timestamp: 2022-08-20 06:49:26.354422\n",
      "resetting env. episode 66, reward total was -21.0. running mean: -20.97001515522064, timestamp: 2022-08-20 06:49:27.675433\n",
      "resetting env. episode 67, reward total was -21.0. running mean: -20.970315003668436, timestamp: 2022-08-20 06:49:28.868454\n",
      "resetting env. episode 68, reward total was -20.0. running mean: -20.96061185363175, timestamp: 2022-08-20 06:49:30.108459\n",
      "resetting env. episode 69, reward total was -21.0. running mean: -20.961005735095434, timestamp: 2022-08-20 06:49:32.555487\n",
      "resetting env. episode 70, reward total was -20.0. running mean: -20.95139567774448, timestamp: 2022-08-20 06:49:34.019504\n",
      "resetting env. episode 71, reward total was -21.0. running mean: -20.951881720967034, timestamp: 2022-08-20 06:49:35.008515\n",
      "resetting env. episode 72, reward total was -21.0. running mean: -20.952362903757365, timestamp: 2022-08-20 06:49:36.586531\n",
      "resetting env. episode 73, reward total was -21.0. running mean: -20.952839274719793, timestamp: 2022-08-20 06:49:38.123546\n",
      "resetting env. episode 74, reward total was -21.0. running mean: -20.953310881972595, timestamp: 2022-08-20 06:49:39.973567\n",
      "resetting env. episode 75, reward total was -21.0. running mean: -20.95377777315287, timestamp: 2022-08-20 06:49:41.306583\n",
      "resetting env. episode 76, reward total was -21.0. running mean: -20.95423999542134, timestamp: 2022-08-20 06:49:42.858120\n",
      "resetting env. episode 77, reward total was -20.0. running mean: -20.944697595467126, timestamp: 2022-08-20 06:49:44.436144\n",
      "resetting env. episode 78, reward total was -21.0. running mean: -20.945250619512457, timestamp: 2022-08-20 06:49:46.198160\n",
      "resetting env. episode 79, reward total was -21.0. running mean: -20.945798113317334, timestamp: 2022-08-20 06:49:48.179180\n",
      "resetting env. episode 80, reward total was -21.0. running mean: -20.94634013218416, timestamp: 2022-08-20 06:49:49.912195\n",
      "resetting env. episode 81, reward total was -21.0. running mean: -20.94687673086232, timestamp: 2022-08-20 06:49:51.430215\n",
      "resetting env. episode 82, reward total was -19.0. running mean: -20.927407963553698, timestamp: 2022-08-20 06:49:53.083230\n",
      "resetting env. episode 83, reward total was -20.0. running mean: -20.91813388391816, timestamp: 2022-08-20 06:49:54.744247\n",
      "resetting env. episode 84, reward total was -21.0. running mean: -20.918952545078977, timestamp: 2022-08-20 06:49:56.292268\n",
      "resetting env. episode 85, reward total was -21.0. running mean: -20.91976301962819, timestamp: 2022-08-20 06:49:57.966288\n",
      "resetting env. episode 86, reward total was -21.0. running mean: -20.920565389431907, timestamp: 2022-08-20 06:49:59.308299\n",
      "resetting env. episode 87, reward total was -20.0. running mean: -20.911359735537587, timestamp: 2022-08-20 06:50:00.496312\n",
      "resetting env. episode 88, reward total was -20.0. running mean: -20.90224613818221, timestamp: 2022-08-20 06:50:02.038333\n",
      "resetting env. episode 89, reward total was -19.0. running mean: -20.88322367680039, timestamp: 2022-08-20 06:50:03.906357\n",
      "resetting env. episode 90, reward total was -20.0. running mean: -20.874391440032387, timestamp: 2022-08-20 06:50:05.651368\n",
      "resetting env. episode 91, reward total was -21.0. running mean: -20.875647525632065, timestamp: 2022-08-20 06:50:06.875379\n",
      "resetting env. episode 92, reward total was -21.0. running mean: -20.876891050375743, timestamp: 2022-08-20 06:50:07.832389\n",
      "resetting env. episode 93, reward total was -21.0. running mean: -20.878122139871987, timestamp: 2022-08-20 06:50:08.949405\n",
      "resetting env. episode 94, reward total was -21.0. running mean: -20.879340918473268, timestamp: 2022-08-20 06:50:10.122420\n",
      "resetting env. episode 95, reward total was -21.0. running mean: -20.880547509288537, timestamp: 2022-08-20 06:50:11.134428\n",
      "resetting env. episode 96, reward total was -21.0. running mean: -20.881742034195653, timestamp: 2022-08-20 06:50:12.303442\n",
      "resetting env. episode 97, reward total was -21.0. running mean: -20.882924613853696, timestamp: 2022-08-20 06:50:13.255452\n",
      "resetting env. episode 98, reward total was -21.0. running mean: -20.884095367715158, timestamp: 2022-08-20 06:50:14.443465\n",
      "resetting env. episode 99, reward total was -21.0. running mean: -20.88525441403801, timestamp: 2022-08-20 06:50:15.441478\n",
      "resetting env. episode 100, reward total was -21.0. running mean: -20.88640186989763, timestamp: 2022-08-20 06:50:16.580486\n",
      "resetting env. episode 101, reward total was -21.0. running mean: -20.887537851198655, timestamp: 2022-08-20 06:50:17.612499\n",
      "resetting env. episode 102, reward total was -21.0. running mean: -20.88866247268667, timestamp: 2022-08-20 06:50:18.576505\n",
      "resetting env. episode 103, reward total was -21.0. running mean: -20.889775847959804, timestamp: 2022-08-20 06:50:19.791521\n",
      "resetting env. episode 104, reward total was -21.0. running mean: -20.890878089480207, timestamp: 2022-08-20 06:50:20.762528\n",
      "resetting env. episode 105, reward total was -21.0. running mean: -20.891969308585406, timestamp: 2022-08-20 06:50:21.926546\n",
      "resetting env. episode 106, reward total was -21.0. running mean: -20.893049615499553, timestamp: 2022-08-20 06:50:22.882552\n",
      "resetting env. episode 107, reward total was -21.0. running mean: -20.89411911934456, timestamp: 2022-08-20 06:50:23.909566\n",
      "resetting env. episode 108, reward total was -21.0. running mean: -20.895177928151114, timestamp: 2022-08-20 06:50:25.003575\n",
      "resetting env. episode 109, reward total was -21.0. running mean: -20.8962261488696, timestamp: 2022-08-20 06:50:25.989588\n",
      "resetting env. episode 110, reward total was -21.0. running mean: -20.897263887380905, timestamp: 2022-08-20 06:50:27.215601\n",
      "resetting env. episode 111, reward total was -21.0. running mean: -20.898291248507096, timestamp: 2022-08-20 06:50:28.175609\n",
      "resetting env. episode 112, reward total was -21.0. running mean: -20.899308336022028, timestamp: 2022-08-20 06:50:29.339624\n",
      "resetting env. episode 113, reward total was -21.0. running mean: -20.90031525266181, timestamp: 2022-08-20 06:50:30.326638\n",
      "resetting env. episode 114, reward total was -21.0. running mean: -20.90131210013519, timestamp: 2022-08-20 06:50:31.297647\n",
      "resetting env. episode 115, reward total was -21.0. running mean: -20.90229897913384, timestamp: 2022-08-20 06:50:32.606658\n",
      "resetting env. episode 116, reward total was -21.0. running mean: -20.9032759893425, timestamp: 2022-08-20 06:50:33.594671\n",
      "resetting env. episode 117, reward total was -21.0. running mean: -20.904243229449076, timestamp: 2022-08-20 06:50:34.805686\n",
      "resetting env. episode 118, reward total was -21.0. running mean: -20.905200797154585, timestamp: 2022-08-20 06:50:35.782695\n",
      "resetting env. episode 119, reward total was -21.0. running mean: -20.90614878918304, timestamp: 2022-08-20 06:50:37.018710\n",
      "resetting env. episode 120, reward total was -21.0. running mean: -20.90708730129121, timestamp: 2022-08-20 06:50:38.018720\n",
      "resetting env. episode 121, reward total was -21.0. running mean: -20.908016428278298, timestamp: 2022-08-20 06:50:39.059735\n",
      "resetting env. episode 122, reward total was -21.0. running mean: -20.908936263995514, timestamp: 2022-08-20 06:50:40.188744\n",
      "resetting env. episode 123, reward total was -21.0. running mean: -20.90984690135556, timestamp: 2022-08-20 06:50:41.148756\n",
      "resetting env. episode 124, reward total was -21.0. running mean: -20.910748432342007, timestamp: 2022-08-20 06:50:42.424768\n",
      "resetting env. episode 125, reward total was -21.0. running mean: -20.911640948018587, timestamp: 2022-08-20 06:50:43.460781\n",
      "resetting env. episode 126, reward total was -21.0. running mean: -20.912524538538403, timestamp: 2022-08-20 06:50:44.642794\n",
      "resetting env. episode 127, reward total was -21.0. running mean: -20.91339929315302, timestamp: 2022-08-20 06:50:45.611801\n",
      "resetting env. episode 128, reward total was -21.0. running mean: -20.91426530022149, timestamp: 2022-08-20 06:50:46.774815\n",
      "resetting env. episode 129, reward total was -21.0. running mean: -20.915122647219277, timestamp: 2022-08-20 06:50:47.975826\n",
      "resetting env. episode 130, reward total was -20.0. running mean: -20.905971420747083, timestamp: 2022-08-20 06:50:49.386846\n",
      "resetting env. episode 131, reward total was -21.0. running mean: -20.906911706539614, timestamp: 2022-08-20 06:50:50.493854\n",
      "resetting env. episode 132, reward total was -21.0. running mean: -20.907842589474217, timestamp: 2022-08-20 06:50:51.628387\n",
      "resetting env. episode 133, reward total was -20.0. running mean: -20.898764163579475, timestamp: 2022-08-20 06:50:52.953401\n",
      "resetting env. episode 134, reward total was -21.0. running mean: -20.899776521943682, timestamp: 2022-08-20 06:50:54.003415\n",
      "resetting env. episode 135, reward total was -21.0. running mean: -20.900778756724247, timestamp: 2022-08-20 06:50:55.407433\n",
      "resetting env. episode 136, reward total was -21.0. running mean: -20.901770969157006, timestamp: 2022-08-20 06:50:56.369439\n",
      "resetting env. episode 137, reward total was -18.0. running mean: -20.872753259465437, timestamp: 2022-08-20 06:50:58.300460\n",
      "resetting env. episode 138, reward total was -21.0. running mean: -20.874025726870784, timestamp: 2022-08-20 06:50:59.519475\n",
      "resetting env. episode 139, reward total was -21.0. running mean: -20.875285469602076, timestamp: 2022-08-20 06:51:00.552484\n",
      "resetting env. episode 140, reward total was -21.0. running mean: -20.876532614906058, timestamp: 2022-08-20 06:51:01.564495\n",
      "resetting env. episode 141, reward total was -21.0. running mean: -20.877767288757, timestamp: 2022-08-20 06:51:02.905509\n",
      "resetting env. episode 142, reward total was -21.0. running mean: -20.87898961586943, timestamp: 2022-08-20 06:51:03.938522\n",
      "resetting env. episode 143, reward total was -21.0. running mean: -20.880199719710735, timestamp: 2022-08-20 06:51:05.363535\n",
      "resetting env. episode 144, reward total was -21.0. running mean: -20.88139772251363, timestamp: 2022-08-20 06:51:06.324546\n",
      "resetting env. episode 145, reward total was -20.0. running mean: -20.87258374528849, timestamp: 2022-08-20 06:51:07.887570\n",
      "resetting env. episode 146, reward total was -21.0. running mean: -20.873857907835607, timestamp: 2022-08-20 06:51:08.932580\n",
      "resetting env. episode 147, reward total was -19.0. running mean: -20.85511932875725, timestamp: 2022-08-20 06:51:10.598598\n",
      "resetting env. episode 148, reward total was -21.0. running mean: -20.85656813546968, timestamp: 2022-08-20 06:51:12.074612\n",
      "resetting env. episode 149, reward total was -21.0. running mean: -20.858002454114985, timestamp: 2022-08-20 06:51:13.133621\n",
      "resetting env. episode 150, reward total was -21.0. running mean: -20.859422429573836, timestamp: 2022-08-20 06:51:14.207636\n",
      "resetting env. episode 151, reward total was -21.0. running mean: -20.8608282052781, timestamp: 2022-08-20 06:51:15.880656\n",
      "resetting env. episode 152, reward total was -21.0. running mean: -20.862219923225318, timestamp: 2022-08-20 06:51:17.626670\n",
      "resetting env. episode 153, reward total was -20.0. running mean: -20.853597723993065, timestamp: 2022-08-20 06:51:19.259690\n",
      "resetting env. episode 154, reward total was -20.0. running mean: -20.845061746753135, timestamp: 2022-08-20 06:51:20.812704\n",
      "resetting env. episode 155, reward total was -21.0. running mean: -20.846611129285606, timestamp: 2022-08-20 06:51:22.138720\n",
      "resetting env. episode 156, reward total was -21.0. running mean: -20.84814501799275, timestamp: 2022-08-20 06:51:23.735736\n",
      "resetting env. episode 157, reward total was -20.0. running mean: -20.83966356781282, timestamp: 2022-08-20 06:51:25.520755\n",
      "resetting env. episode 158, reward total was -21.0. running mean: -20.841266932134694, timestamp: 2022-08-20 06:51:26.640767\n",
      "resetting env. episode 159, reward total was -20.0. running mean: -20.832854262813346, timestamp: 2022-08-20 06:51:28.351788\n",
      "resetting env. episode 160, reward total was -21.0. running mean: -20.834525720185212, timestamp: 2022-08-20 06:51:29.941802\n",
      "resetting env. episode 161, reward total was -20.0. running mean: -20.82618046298336, timestamp: 2022-08-20 06:51:31.713824\n",
      "resetting env. episode 162, reward total was -21.0. running mean: -20.827918658353525, timestamp: 2022-08-20 06:51:33.224840\n",
      "resetting env. episode 163, reward total was -20.0. running mean: -20.81963947176999, timestamp: 2022-08-20 06:51:34.384852\n",
      "resetting env. episode 164, reward total was -21.0. running mean: -20.82144307705229, timestamp: 2022-08-20 06:51:36.142869\n",
      "resetting env. episode 165, reward total was -21.0. running mean: -20.82322864628177, timestamp: 2022-08-20 06:51:37.700886\n",
      "resetting env. episode 166, reward total was -21.0. running mean: -20.824996359818954, timestamp: 2022-08-20 06:51:39.098903\n",
      "resetting env. episode 167, reward total was -21.0. running mean: -20.826746396220766, timestamp: 2022-08-20 06:51:40.391916\n",
      "resetting env. episode 168, reward total was -21.0. running mean: -20.82847893225856, timestamp: 2022-08-20 06:51:41.430925\n",
      "resetting env. episode 169, reward total was -21.0. running mean: -20.830194142935973, timestamp: 2022-08-20 06:51:42.692943\n",
      "resetting env. episode 170, reward total was -21.0. running mean: -20.831892201506612, timestamp: 2022-08-20 06:51:43.990955\n",
      "resetting env. episode 171, reward total was -21.0. running mean: -20.833573279491546, timestamp: 2022-08-20 06:51:45.750972\n",
      "resetting env. episode 172, reward total was -21.0. running mean: -20.835237546696632, timestamp: 2022-08-20 06:51:46.798984\n",
      "resetting env. episode 173, reward total was -21.0. running mean: -20.836885171229667, timestamp: 2022-08-20 06:51:48.437007\n",
      "resetting env. episode 174, reward total was -21.0. running mean: -20.83851631951737, timestamp: 2022-08-20 06:51:49.469016\n",
      "resetting env. episode 175, reward total was -21.0. running mean: -20.840131156322197, timestamp: 2022-08-20 06:51:50.799030\n",
      "resetting env. episode 176, reward total was -21.0. running mean: -20.841729844758976, timestamp: 2022-08-20 06:51:52.056040\n",
      "resetting env. episode 177, reward total was -21.0. running mean: -20.843312546311388, timestamp: 2022-08-20 06:51:53.465059\n",
      "resetting env. episode 178, reward total was -20.0. running mean: -20.834879420848274, timestamp: 2022-08-20 06:51:54.677072\n",
      "resetting env. episode 179, reward total was -21.0. running mean: -20.836530626639792, timestamp: 2022-08-20 06:51:55.968082\n",
      "resetting env. episode 180, reward total was -21.0. running mean: -20.838165320373395, timestamp: 2022-08-20 06:51:57.201098\n",
      "resetting env. episode 181, reward total was -21.0. running mean: -20.839783667169662, timestamp: 2022-08-20 06:51:58.489111\n",
      "resetting env. episode 182, reward total was -21.0. running mean: -20.841385830497966, timestamp: 2022-08-20 06:52:00.291133\n",
      "resetting env. episode 183, reward total was -21.0. running mean: -20.842971972192988, timestamp: 2022-08-20 06:52:01.351142\n",
      "resetting env. episode 184, reward total was -21.0. running mean: -20.844542252471058, timestamp: 2022-08-20 06:52:02.878157\n",
      "resetting env. episode 185, reward total was -21.0. running mean: -20.846096829946347, timestamp: 2022-08-20 06:52:03.925169\n",
      "resetting env. episode 186, reward total was -21.0. running mean: -20.847635861646886, timestamp: 2022-08-20 06:52:05.253185\n",
      "resetting env. episode 187, reward total was -21.0. running mean: -20.849159503030418, timestamp: 2022-08-20 06:52:06.389195\n",
      "resetting env. episode 188, reward total was -21.0. running mean: -20.850667908000116, timestamp: 2022-08-20 06:52:07.603210\n",
      "resetting env. episode 189, reward total was -21.0. running mean: -20.852161228920114, timestamp: 2022-08-20 06:52:08.983743\n",
      "resetting env. episode 190, reward total was -21.0. running mean: -20.853639616630915, timestamp: 2022-08-20 06:52:10.648765\n",
      "resetting env. episode 191, reward total was -21.0. running mean: -20.855103220464606, timestamp: 2022-08-20 06:52:11.780779\n",
      "resetting env. episode 192, reward total was -21.0. running mean: -20.85655218825996, timestamp: 2022-08-20 06:52:13.107790\n",
      "resetting env. episode 193, reward total was -21.0. running mean: -20.85798666637736, timestamp: 2022-08-20 06:52:14.247802\n",
      "resetting env. episode 194, reward total was -21.0. running mean: -20.85940679971359, timestamp: 2022-08-20 06:52:15.398816\n",
      "resetting env. episode 195, reward total was -21.0. running mean: -20.860812731716454, timestamp: 2022-08-20 06:52:16.736829\n",
      "resetting env. episode 196, reward total was -21.0. running mean: -20.862204604399288, timestamp: 2022-08-20 06:52:17.839842\n",
      "resetting env. episode 197, reward total was -21.0. running mean: -20.863582558355297, timestamp: 2022-08-20 06:52:19.447861\n",
      "resetting env. episode 198, reward total was -21.0. running mean: -20.864946732771745, timestamp: 2022-08-20 06:52:20.682872\n",
      "resetting env. episode 199, reward total was -21.0. running mean: -20.86629726544403, timestamp: 2022-08-20 06:52:21.923886\n",
      "resetting env. episode 200, reward total was -21.0. running mean: -20.86763429278959, timestamp: 2022-08-20 06:52:23.746902\n",
      "resetting env. episode 201, reward total was -21.0. running mean: -20.868957949861695, timestamp: 2022-08-20 06:52:24.929915\n",
      "resetting env. episode 202, reward total was -21.0. running mean: -20.87026837036308, timestamp: 2022-08-20 06:52:26.264931\n",
      "resetting env. episode 203, reward total was -21.0. running mean: -20.871565686659448, timestamp: 2022-08-20 06:52:27.302941\n",
      "resetting env. episode 204, reward total was -21.0. running mean: -20.872850029792854, timestamp: 2022-08-20 06:52:28.793959\n",
      "resetting env. episode 205, reward total was -20.0. running mean: -20.864121529494923, timestamp: 2022-08-20 06:52:30.146981\n",
      "resetting env. episode 206, reward total was -21.0. running mean: -20.865480314199974, timestamp: 2022-08-20 06:52:31.393987\n",
      "resetting env. episode 207, reward total was -21.0. running mean: -20.866825511057975, timestamp: 2022-08-20 06:52:32.755002\n",
      "resetting env. episode 208, reward total was -21.0. running mean: -20.868157255947395, timestamp: 2022-08-20 06:52:34.622024\n",
      "resetting env. episode 209, reward total was -21.0. running mean: -20.869475683387922, timestamp: 2022-08-20 06:52:36.344040\n",
      "resetting env. episode 210, reward total was -21.0. running mean: -20.870780926554044, timestamp: 2022-08-20 06:52:37.404053\n",
      "resetting env. episode 211, reward total was -20.0. running mean: -20.862073117288503, timestamp: 2022-08-20 06:52:39.381073\n",
      "resetting env. episode 212, reward total was -21.0. running mean: -20.86345238611562, timestamp: 2022-08-20 06:52:40.806089\n",
      "resetting env. episode 213, reward total was -21.0. running mean: -20.864817862254462, timestamp: 2022-08-20 06:52:41.887104\n",
      "resetting env. episode 214, reward total was -20.0. running mean: -20.856169683631915, timestamp: 2022-08-20 06:52:43.320115\n",
      "resetting env. episode 215, reward total was -20.0. running mean: -20.847607986795595, timestamp: 2022-08-20 06:52:44.728130\n",
      "resetting env. episode 216, reward total was -21.0. running mean: -20.84913190692764, timestamp: 2022-08-20 06:52:46.224148\n",
      "resetting env. episode 217, reward total was -20.0. running mean: -20.84064058785836, timestamp: 2022-08-20 06:52:47.447160\n",
      "resetting env. episode 218, reward total was -21.0. running mean: -20.842234181979777, timestamp: 2022-08-20 06:52:48.861176\n",
      "resetting env. episode 219, reward total was -20.0. running mean: -20.833811840159978, timestamp: 2022-08-20 06:52:50.183196\n",
      "resetting env. episode 220, reward total was -21.0. running mean: -20.83547372175838, timestamp: 2022-08-20 06:52:51.601205\n",
      "resetting env. episode 221, reward total was -21.0. running mean: -20.837118984540798, timestamp: 2022-08-20 06:52:52.703222\n",
      "resetting env. episode 222, reward total was -21.0. running mean: -20.83874779469539, timestamp: 2022-08-20 06:52:53.969233\n",
      "resetting env. episode 223, reward total was -21.0. running mean: -20.840360316748438, timestamp: 2022-08-20 06:52:55.197246\n",
      "resetting env. episode 224, reward total was -21.0. running mean: -20.841956713580952, timestamp: 2022-08-20 06:52:56.455259\n",
      "resetting env. episode 225, reward total was -18.0. running mean: -20.813537146445142, timestamp: 2022-08-20 06:52:58.453281\n",
      "resetting env. episode 226, reward total was -20.0. running mean: -20.80540177498069, timestamp: 2022-08-20 06:52:59.701297\n",
      "resetting env. episode 227, reward total was -21.0. running mean: -20.807347757230886, timestamp: 2022-08-20 06:53:01.278317\n",
      "resetting env. episode 228, reward total was -21.0. running mean: -20.809274279658577, timestamp: 2022-08-20 06:53:02.994335\n",
      "resetting env. episode 229, reward total was -20.0. running mean: -20.80118153686199, timestamp: 2022-08-20 06:53:04.442355\n",
      "resetting env. episode 230, reward total was -21.0. running mean: -20.80316972149337, timestamp: 2022-08-20 06:53:06.061365\n",
      "resetting env. episode 231, reward total was -21.0. running mean: -20.805138024278435, timestamp: 2022-08-20 06:53:07.644383\n",
      "resetting env. episode 232, reward total was -21.0. running mean: -20.80708664403565, timestamp: 2022-08-20 06:53:08.983396\n",
      "resetting env. episode 233, reward total was -21.0. running mean: -20.809015777595295, timestamp: 2022-08-20 06:53:10.171406\n",
      "resetting env. episode 234, reward total was -21.0. running mean: -20.810925619819344, timestamp: 2022-08-20 06:53:11.452423\n",
      "resetting env. episode 235, reward total was -21.0. running mean: -20.812816363621153, timestamp: 2022-08-20 06:53:13.214443\n",
      "resetting env. episode 236, reward total was -21.0. running mean: -20.814688199984943, timestamp: 2022-08-20 06:53:14.712458\n",
      "resetting env. episode 237, reward total was -20.0. running mean: -20.806541317985094, timestamp: 2022-08-20 06:53:16.150473\n",
      "resetting env. episode 238, reward total was -21.0. running mean: -20.808475904805242, timestamp: 2022-08-20 06:53:17.261484\n",
      "resetting env. episode 239, reward total was -20.0. running mean: -20.80039114575719, timestamp: 2022-08-20 06:53:18.907502\n",
      "resetting env. episode 240, reward total was -18.0. running mean: -20.772387234299618, timestamp: 2022-08-20 06:53:20.317518\n",
      "resetting env. episode 241, reward total was -21.0. running mean: -20.774663361956623, timestamp: 2022-08-20 06:53:21.755536\n",
      "resetting env. episode 242, reward total was -21.0. running mean: -20.776916728337056, timestamp: 2022-08-20 06:53:22.919551\n",
      "resetting env. episode 243, reward total was -21.0. running mean: -20.779147561053687, timestamp: 2022-08-20 06:53:24.335560\n",
      "resetting env. episode 244, reward total was -21.0. running mean: -20.78135608544315, timestamp: 2022-08-20 06:53:25.592574\n",
      "resetting env. episode 245, reward total was -21.0. running mean: -20.783542524588718, timestamp: 2022-08-20 06:53:26.942593\n",
      "resetting env. episode 246, reward total was -21.0. running mean: -20.785707099342833, timestamp: 2022-08-20 06:53:28.042601\n",
      "resetting env. episode 247, reward total was -20.0. running mean: -20.777850028349405, timestamp: 2022-08-20 06:53:29.694622\n",
      "resetting env. episode 248, reward total was -21.0. running mean: -20.78007152806591, timestamp: 2022-08-20 06:53:30.708632\n",
      "resetting env. episode 249, reward total was -21.0. running mean: -20.782270812785253, timestamp: 2022-08-20 06:53:32.137645\n",
      "resetting env. episode 250, reward total was -21.0. running mean: -20.7844481046574, timestamp: 2022-08-20 06:53:33.185659\n",
      "resetting env. episode 251, reward total was -21.0. running mean: -20.786603623610826, timestamp: 2022-08-20 06:53:34.451670\n",
      "resetting env. episode 252, reward total was -21.0. running mean: -20.78873758737472, timestamp: 2022-08-20 06:53:36.313692\n",
      "resetting env. episode 253, reward total was -21.0. running mean: -20.790850211500974, timestamp: 2022-08-20 06:53:37.437704\n",
      "resetting env. episode 254, reward total was -21.0. running mean: -20.792941709385964, timestamp: 2022-08-20 06:53:38.611718\n",
      "resetting env. episode 255, reward total was -21.0. running mean: -20.795012292292107, timestamp: 2022-08-20 06:53:39.719733\n",
      "resetting env. episode 256, reward total was -21.0. running mean: -20.797062169369188, timestamp: 2022-08-20 06:53:41.422746\n",
      "resetting env. episode 257, reward total was -21.0. running mean: -20.799091547675495, timestamp: 2022-08-20 06:53:42.957764\n",
      "resetting env. episode 258, reward total was -21.0. running mean: -20.80110063219874, timestamp: 2022-08-20 06:53:44.202779\n",
      "resetting env. episode 259, reward total was -21.0. running mean: -20.80308962587675, timestamp: 2022-08-20 06:53:45.624790\n",
      "resetting env. episode 260, reward total was -21.0. running mean: -20.805058729617983, timestamp: 2022-08-20 06:53:47.502810\n",
      "resetting env. episode 261, reward total was -21.0. running mean: -20.807008142321802, timestamp: 2022-08-20 06:53:48.765828\n",
      "resetting env. episode 262, reward total was -21.0. running mean: -20.808938060898583, timestamp: 2022-08-20 06:53:49.999840\n",
      "resetting env. episode 263, reward total was -20.0. running mean: -20.800848680289597, timestamp: 2022-08-20 06:53:51.385859\n",
      "resetting env. episode 264, reward total was -21.0. running mean: -20.802840193486702, timestamp: 2022-08-20 06:53:53.263878\n",
      "resetting env. episode 265, reward total was -21.0. running mean: -20.804811791551835, timestamp: 2022-08-20 06:53:54.603892\n",
      "resetting env. episode 266, reward total was -21.0. running mean: -20.80676367363632, timestamp: 2022-08-20 06:53:55.620903\n",
      "resetting env. episode 267, reward total was -21.0. running mean: -20.808696036899956, timestamp: 2022-08-20 06:53:57.417918\n",
      "resetting env. episode 268, reward total was -21.0. running mean: -20.81060907653096, timestamp: 2022-08-20 06:53:58.484933\n",
      "resetting env. episode 269, reward total was -21.0. running mean: -20.81250298576565, timestamp: 2022-08-20 06:54:00.842955\n",
      "resetting env. episode 270, reward total was -21.0. running mean: -20.814377955907993, timestamp: 2022-08-20 06:54:02.149968\n",
      "resetting env. episode 271, reward total was -21.0. running mean: -20.816234176348914, timestamp: 2022-08-20 06:54:03.467983\n",
      "resetting env. episode 272, reward total was -21.0. running mean: -20.818071834585425, timestamp: 2022-08-20 06:54:04.951004\n",
      "resetting env. episode 273, reward total was -21.0. running mean: -20.81989111623957, timestamp: 2022-08-20 06:54:06.407020\n",
      "resetting env. episode 274, reward total was -21.0. running mean: -20.821692205077177, timestamp: 2022-08-20 06:54:07.521028\n",
      "resetting env. episode 275, reward total was -21.0. running mean: -20.823475283026404, timestamp: 2022-08-20 06:54:08.560041\n",
      "resetting env. episode 276, reward total was -21.0. running mean: -20.82524053019614, timestamp: 2022-08-20 06:54:09.822058\n",
      "resetting env. episode 277, reward total was -21.0. running mean: -20.82698812489418, timestamp: 2022-08-20 06:54:11.514073\n",
      "resetting env. episode 278, reward total was -21.0. running mean: -20.828718243645238, timestamp: 2022-08-20 06:54:13.692100\n",
      "resetting env. episode 279, reward total was -21.0. running mean: -20.830431061208785, timestamp: 2022-08-20 06:54:15.091117\n",
      "resetting env. episode 280, reward total was -21.0. running mean: -20.832126750596696, timestamp: 2022-08-20 06:54:16.308125\n",
      "resetting env. episode 281, reward total was -21.0. running mean: -20.83380548309073, timestamp: 2022-08-20 06:54:17.470135\n",
      "resetting env. episode 282, reward total was -21.0. running mean: -20.835467428259825, timestamp: 2022-08-20 06:54:18.594152\n",
      "resetting env. episode 283, reward total was -21.0. running mean: -20.837112753977227, timestamp: 2022-08-20 06:54:20.394170\n",
      "resetting env. episode 284, reward total was -21.0. running mean: -20.838741626437454, timestamp: 2022-08-20 06:54:22.275192\n",
      "resetting env. episode 285, reward total was -21.0. running mean: -20.84035421017308, timestamp: 2022-08-20 06:54:23.317198\n",
      "resetting env. episode 286, reward total was -21.0. running mean: -20.841950668071348, timestamp: 2022-08-20 06:54:25.304224\n",
      "resetting env. episode 287, reward total was -21.0. running mean: -20.843531161390636, timestamp: 2022-08-20 06:54:26.984243\n",
      "resetting env. episode 288, reward total was -21.0. running mean: -20.84509584977673, timestamp: 2022-08-20 06:54:28.414267\n",
      "resetting env. episode 289, reward total was -21.0. running mean: -20.846644891278963, timestamp: 2022-08-20 06:54:30.452277\n",
      "resetting env. episode 290, reward total was -21.0. running mean: -20.848178442366173, timestamp: 2022-08-20 06:54:31.704291\n",
      "resetting env. episode 291, reward total was -21.0. running mean: -20.849696657942513, timestamp: 2022-08-20 06:54:32.915305\n",
      "resetting env. episode 292, reward total was -21.0. running mean: -20.85119969136309, timestamp: 2022-08-20 06:54:34.598322\n",
      "resetting env. episode 293, reward total was -21.0. running mean: -20.852687694449457, timestamp: 2022-08-20 06:54:35.634333\n",
      "resetting env. episode 294, reward total was -21.0. running mean: -20.854160817504965, timestamp: 2022-08-20 06:54:36.910349\n",
      "resetting env. episode 295, reward total was -21.0. running mean: -20.855619209329916, timestamp: 2022-08-20 06:54:38.131360\n",
      "resetting env. episode 296, reward total was -21.0. running mean: -20.857063017236616, timestamp: 2022-08-20 06:54:40.484387\n",
      "resetting env. episode 297, reward total was -21.0. running mean: -20.85849238706425, timestamp: 2022-08-20 06:54:41.835401\n",
      "resetting env. episode 298, reward total was -21.0. running mean: -20.859907463193608, timestamp: 2022-08-20 06:54:43.051418\n",
      "resetting env. episode 299, reward total was -21.0. running mean: -20.86130838856167, timestamp: 2022-08-20 06:54:44.550433\n",
      "resetting env. episode 300, reward total was -20.0. running mean: -20.852695304676054, timestamp: 2022-08-20 06:54:47.629465\n",
      "resetting env. episode 301, reward total was -19.0. running mean: -20.834168351629295, timestamp: 2022-08-20 06:54:49.462484\n",
      "resetting env. episode 302, reward total was -21.0. running mean: -20.835826668113004, timestamp: 2022-08-20 06:54:50.811498\n",
      "resetting env. episode 303, reward total was -21.0. running mean: -20.837468401431874, timestamp: 2022-08-20 06:54:52.151513\n",
      "resetting env. episode 304, reward total was -21.0. running mean: -20.839093717417555, timestamp: 2022-08-20 06:54:53.261529\n",
      "resetting env. episode 305, reward total was -20.0. running mean: -20.830702780243378, timestamp: 2022-08-20 06:54:54.665543\n",
      "resetting env. episode 306, reward total was -21.0. running mean: -20.832395752440945, timestamp: 2022-08-20 06:54:56.495564\n",
      "resetting env. episode 307, reward total was -21.0. running mean: -20.834071794916536, timestamp: 2022-08-20 06:54:58.224580\n",
      "resetting env. episode 308, reward total was -21.0. running mean: -20.83573107696737, timestamp: 2022-08-20 06:54:59.522595\n",
      "resetting env. episode 309, reward total was -20.0. running mean: -20.827373766197695, timestamp: 2022-08-20 06:55:00.903613\n",
      "resetting env. episode 310, reward total was -21.0. running mean: -20.82910002853572, timestamp: 2022-08-20 06:55:02.191623\n",
      "resetting env. episode 311, reward total was -21.0. running mean: -20.830809028250364, timestamp: 2022-08-20 06:55:04.137646\n",
      "resetting env. episode 312, reward total was -21.0. running mean: -20.83250093796786, timestamp: 2022-08-20 06:55:06.004665\n",
      "resetting env. episode 313, reward total was -21.0. running mean: -20.834175928588184, timestamp: 2022-08-20 06:55:07.511682\n",
      "resetting env. episode 314, reward total was -21.0. running mean: -20.835834169302302, timestamp: 2022-08-20 06:55:08.725694\n",
      "resetting env. episode 315, reward total was -21.0. running mean: -20.83747582760928, timestamp: 2022-08-20 06:55:10.014712\n",
      "resetting env. episode 316, reward total was -21.0. running mean: -20.839101069333186, timestamp: 2022-08-20 06:55:11.141720\n",
      "resetting env. episode 317, reward total was -21.0. running mean: -20.840710058639853, timestamp: 2022-08-20 06:55:12.535738\n",
      "resetting env. episode 318, reward total was -20.0. running mean: -20.832302958053454, timestamp: 2022-08-20 06:55:13.622750\n",
      "resetting env. episode 319, reward total was -20.0. running mean: -20.82397992847292, timestamp: 2022-08-20 06:55:15.208768\n",
      "resetting env. episode 320, reward total was -21.0. running mean: -20.82574012918819, timestamp: 2022-08-20 06:55:16.261777\n",
      "resetting env. episode 321, reward total was -21.0. running mean: -20.82748272789631, timestamp: 2022-08-20 06:55:17.672793\n",
      "resetting env. episode 322, reward total was -21.0. running mean: -20.829207900617348, timestamp: 2022-08-20 06:55:18.982807\n",
      "resetting env. episode 323, reward total was -21.0. running mean: -20.830915821611175, timestamp: 2022-08-20 06:55:21.041834\n",
      "resetting env. episode 324, reward total was -21.0. running mean: -20.832606663395065, timestamp: 2022-08-20 06:55:22.593845\n",
      "resetting env. episode 325, reward total was -21.0. running mean: -20.834280596761115, timestamp: 2022-08-20 06:55:24.481868\n",
      "resetting env. episode 326, reward total was -21.0. running mean: -20.835937790793505, timestamp: 2022-08-20 06:55:25.811885\n",
      "resetting env. episode 327, reward total was -21.0. running mean: -20.83757841288557, timestamp: 2022-08-20 06:55:27.470906\n",
      "resetting env. episode 328, reward total was -21.0. running mean: -20.839202628756716, timestamp: 2022-08-20 06:55:28.902924\n",
      "resetting env. episode 329, reward total was -21.0. running mean: -20.84081060246915, timestamp: 2022-08-20 06:55:30.168929\n",
      "resetting env. episode 330, reward total was -21.0. running mean: -20.84240249644446, timestamp: 2022-08-20 06:55:31.307945\n",
      "resetting env. episode 331, reward total was -20.0. running mean: -20.833978471480016, timestamp: 2022-08-20 06:55:33.908969\n",
      "resetting env. episode 332, reward total was -21.0. running mean: -20.835638686765215, timestamp: 2022-08-20 06:55:35.363986\n",
      "resetting env. episode 333, reward total was -21.0. running mean: -20.837282299897563, timestamp: 2022-08-20 06:55:36.909009\n",
      "resetting env. episode 334, reward total was -21.0. running mean: -20.83890947689859, timestamp: 2022-08-20 06:55:38.101015\n",
      "resetting env. episode 335, reward total was -20.0. running mean: -20.830520382129603, timestamp: 2022-08-20 06:55:39.971040\n",
      "resetting env. episode 336, reward total was -21.0. running mean: -20.832215178308306, timestamp: 2022-08-20 06:55:41.003049\n",
      "resetting env. episode 337, reward total was -21.0. running mean: -20.833893026525224, timestamp: 2022-08-20 06:55:42.433590\n",
      "resetting env. episode 338, reward total was -21.0. running mean: -20.835554096259973, timestamp: 2022-08-20 06:55:43.631598\n",
      "resetting env. episode 339, reward total was -21.0. running mean: -20.837198555297373, timestamp: 2022-08-20 06:55:45.346620\n",
      "resetting env. episode 340, reward total was -21.0. running mean: -20.838826569744402, timestamp: 2022-08-20 06:55:46.488632\n",
      "resetting env. episode 341, reward total was -21.0. running mean: -20.84043830404696, timestamp: 2022-08-20 06:55:48.120653\n",
      "resetting env. episode 342, reward total was -21.0. running mean: -20.84203392100649, timestamp: 2022-08-20 06:55:49.153663\n",
      "resetting env. episode 343, reward total was -21.0. running mean: -20.843613581796426, timestamp: 2022-08-20 06:55:50.449673\n",
      "resetting env. episode 344, reward total was -21.0. running mean: -20.84517744597846, timestamp: 2022-08-20 06:55:51.730687\n",
      "resetting env. episode 345, reward total was -21.0. running mean: -20.846725671518676, timestamp: 2022-08-20 06:55:53.225710\n",
      "resetting env. episode 346, reward total was -20.0. running mean: -20.838258414803487, timestamp: 2022-08-20 06:55:54.512719\n",
      "resetting env. episode 347, reward total was -21.0. running mean: -20.839875830655455, timestamp: 2022-08-20 06:55:55.764732\n",
      "resetting env. episode 348, reward total was -20.0. running mean: -20.8314770723489, timestamp: 2022-08-20 06:55:56.841743\n",
      "resetting env. episode 349, reward total was -20.0. running mean: -20.82316230162541, timestamp: 2022-08-20 06:55:58.333761\n",
      "resetting env. episode 350, reward total was -20.0. running mean: -20.814930678609155, timestamp: 2022-08-20 06:55:59.943780\n",
      "resetting env. episode 351, reward total was -21.0. running mean: -20.816781371823065, timestamp: 2022-08-20 06:56:01.232793\n",
      "resetting env. episode 352, reward total was -21.0. running mean: -20.818613558104836, timestamp: 2022-08-20 06:56:02.408808\n",
      "resetting env. episode 353, reward total was -21.0. running mean: -20.82042742252379, timestamp: 2022-08-20 06:56:04.964835\n",
      "resetting env. episode 354, reward total was -21.0. running mean: -20.82222314829855, timestamp: 2022-08-20 06:56:06.241847\n",
      "resetting env. episode 355, reward total was -21.0. running mean: -20.824000916815567, timestamp: 2022-08-20 06:56:07.496864\n",
      "resetting env. episode 356, reward total was -21.0. running mean: -20.825760907647414, timestamp: 2022-08-20 06:56:08.918877\n",
      "resetting env. episode 357, reward total was -21.0. running mean: -20.82750329857094, timestamp: 2022-08-20 06:56:10.470898\n",
      "resetting env. episode 358, reward total was -21.0. running mean: -20.82922826558523, timestamp: 2022-08-20 06:56:11.514907\n",
      "resetting env. episode 359, reward total was -21.0. running mean: -20.83093598292938, timestamp: 2022-08-20 06:56:12.896926\n",
      "resetting env. episode 360, reward total was -21.0. running mean: -20.832626623100087, timestamp: 2022-08-20 06:56:14.358936\n",
      "resetting env. episode 361, reward total was -21.0. running mean: -20.834300356869086, timestamp: 2022-08-20 06:56:15.744952\n",
      "resetting env. episode 362, reward total was -21.0. running mean: -20.835957353300397, timestamp: 2022-08-20 06:56:16.817964\n",
      "resetting env. episode 363, reward total was -21.0. running mean: -20.837597779767393, timestamp: 2022-08-20 06:56:18.418986\n",
      "resetting env. episode 364, reward total was -19.0. running mean: -20.81922180196972, timestamp: 2022-08-20 06:56:19.953001\n",
      "resetting env. episode 365, reward total was -21.0. running mean: -20.821029583950025, timestamp: 2022-08-20 06:56:21.206011\n",
      "resetting env. episode 366, reward total was -21.0. running mean: -20.822819288110527, timestamp: 2022-08-20 06:56:22.295027\n",
      "resetting env. episode 367, reward total was -21.0. running mean: -20.824591095229422, timestamp: 2022-08-20 06:56:23.993044\n",
      "resetting env. episode 368, reward total was -21.0. running mean: -20.82634518427713, timestamp: 2022-08-20 06:56:25.583061\n",
      "resetting env. episode 369, reward total was -20.0. running mean: -20.818081732434358, timestamp: 2022-08-20 06:56:27.420082\n",
      "resetting env. episode 370, reward total was -19.0. running mean: -20.799900915110015, timestamp: 2022-08-20 06:56:28.994096\n",
      "resetting env. episode 371, reward total was -20.0. running mean: -20.791901905958916, timestamp: 2022-08-20 06:56:30.709118\n",
      "resetting env. episode 372, reward total was -21.0. running mean: -20.79398288689933, timestamp: 2022-08-20 06:56:31.992133\n",
      "resetting env. episode 373, reward total was -19.0. running mean: -20.776043058030336, timestamp: 2022-08-20 06:56:33.986152\n",
      "resetting env. episode 374, reward total was -21.0. running mean: -20.778282627450032, timestamp: 2022-08-20 06:56:35.304169\n",
      "resetting env. episode 375, reward total was -21.0. running mean: -20.780499801175534, timestamp: 2022-08-20 06:56:36.941184\n",
      "resetting env. episode 376, reward total was -20.0. running mean: -20.772694803163777, timestamp: 2022-08-20 06:56:39.133209\n",
      "resetting env. episode 377, reward total was -21.0. running mean: -20.77496785513214, timestamp: 2022-08-20 06:56:40.373225\n",
      "resetting env. episode 378, reward total was -21.0. running mean: -20.777218176580817, timestamp: 2022-08-20 06:56:42.098242\n",
      "resetting env. episode 379, reward total was -21.0. running mean: -20.77944599481501, timestamp: 2022-08-20 06:56:43.342257\n",
      "resetting env. episode 380, reward total was -21.0. running mean: -20.78165153486686, timestamp: 2022-08-20 06:56:44.412268\n",
      "resetting env. episode 381, reward total was -20.0. running mean: -20.77383501951819, timestamp: 2022-08-20 06:56:45.948285\n",
      "resetting env. episode 382, reward total was -21.0. running mean: -20.77609666932301, timestamp: 2022-08-20 06:56:48.018308\n",
      "resetting env. episode 383, reward total was -20.0. running mean: -20.76833570262978, timestamp: 2022-08-20 06:56:49.410328\n",
      "resetting env. episode 384, reward total was -21.0. running mean: -20.770652345603484, timestamp: 2022-08-20 06:56:50.715338\n",
      "resetting env. episode 385, reward total was -21.0. running mean: -20.77294582214745, timestamp: 2022-08-20 06:56:51.818352\n",
      "resetting env. episode 386, reward total was -21.0. running mean: -20.775216363925974, timestamp: 2022-08-20 06:56:53.139368\n",
      "resetting env. episode 387, reward total was -21.0. running mean: -20.777464200286715, timestamp: 2022-08-20 06:56:54.656380\n",
      "resetting env. episode 388, reward total was -21.0. running mean: -20.77968955828385, timestamp: 2022-08-20 06:56:56.632401\n",
      "resetting env. episode 389, reward total was -21.0. running mean: -20.78189266270101, timestamp: 2022-08-20 06:56:57.789416\n",
      "resetting env. episode 390, reward total was -21.0. running mean: -20.784073736074003, timestamp: 2022-08-20 06:56:59.493434\n",
      "resetting env. episode 391, reward total was -21.0. running mean: -20.786232998713263, timestamp: 2022-08-20 06:57:00.816448\n",
      "resetting env. episode 392, reward total was -21.0. running mean: -20.78837066872613, timestamp: 2022-08-20 06:57:02.121465\n",
      "resetting env. episode 393, reward total was -21.0. running mean: -20.79048696203887, timestamp: 2022-08-20 06:57:03.366477\n",
      "resetting env. episode 394, reward total was -21.0. running mean: -20.79258209241848, timestamp: 2022-08-20 06:57:04.881496\n",
      "resetting env. episode 395, reward total was -21.0. running mean: -20.794656271494297, timestamp: 2022-08-20 06:57:06.132505\n",
      "resetting env. episode 396, reward total was -21.0. running mean: -20.796709708779353, timestamp: 2022-08-20 06:57:07.256523\n",
      "resetting env. episode 397, reward total was -21.0. running mean: -20.798742611691562, timestamp: 2022-08-20 06:57:08.623533\n",
      "resetting env. episode 398, reward total was -21.0. running mean: -20.800755185574648, timestamp: 2022-08-20 06:57:09.655543\n",
      "resetting env. episode 399, reward total was -21.0. running mean: -20.8027476337189, timestamp: 2022-08-20 06:57:11.541566\n",
      "resetting env. episode 400, reward total was -20.0. running mean: -20.79472015738171, timestamp: 2022-08-20 06:57:13.119586\n",
      "resetting env. episode 401, reward total was -21.0. running mean: -20.796772955807896, timestamp: 2022-08-20 06:57:14.179597\n",
      "resetting env. episode 402, reward total was -21.0. running mean: -20.79880522624982, timestamp: 2022-08-20 06:57:15.237608\n",
      "resetting env. episode 403, reward total was -21.0. running mean: -20.800817173987323, timestamp: 2022-08-20 06:57:16.749626\n",
      "resetting env. episode 404, reward total was -21.0. running mean: -20.80280900224745, timestamp: 2022-08-20 06:57:18.096640\n",
      "resetting env. episode 405, reward total was -20.0. running mean: -20.794780912224976, timestamp: 2022-08-20 06:57:19.813659\n",
      "resetting env. episode 406, reward total was -21.0. running mean: -20.796833103102728, timestamp: 2022-08-20 06:57:21.378675\n",
      "resetting env. episode 407, reward total was -21.0. running mean: -20.798864772071703, timestamp: 2022-08-20 06:57:22.824692\n",
      "resetting env. episode 408, reward total was -21.0. running mean: -20.800876124350985, timestamp: 2022-08-20 06:57:24.277724\n",
      "resetting env. episode 409, reward total was -20.0. running mean: -20.792867363107476, timestamp: 2022-08-20 06:57:25.511721\n",
      "resetting env. episode 410, reward total was -21.0. running mean: -20.794938689476403, timestamp: 2022-08-20 06:57:26.915737\n",
      "resetting env. episode 411, reward total was -21.0. running mean: -20.79698930258164, timestamp: 2022-08-20 06:57:28.935756\n",
      "resetting env. episode 412, reward total was -20.0. running mean: -20.789019409555824, timestamp: 2022-08-20 06:57:30.189773\n",
      "resetting env. episode 413, reward total was -21.0. running mean: -20.791129215460266, timestamp: 2022-08-20 06:57:31.471788\n",
      "resetting env. episode 414, reward total was -21.0. running mean: -20.793217923305665, timestamp: 2022-08-20 06:57:33.083803\n",
      "resetting env. episode 415, reward total was -21.0. running mean: -20.795285744072608, timestamp: 2022-08-20 06:57:34.218815\n",
      "resetting env. episode 416, reward total was -21.0. running mean: -20.79733288663188, timestamp: 2022-08-20 06:57:35.324830\n",
      "resetting env. episode 417, reward total was -21.0. running mean: -20.799359557765563, timestamp: 2022-08-20 06:57:37.360849\n",
      "resetting env. episode 418, reward total was -21.0. running mean: -20.80136596218791, timestamp: 2022-08-20 06:57:38.782865\n",
      "resetting env. episode 419, reward total was -21.0. running mean: -20.80335230256603, timestamp: 2022-08-20 06:57:39.974884\n",
      "resetting env. episode 420, reward total was -21.0. running mean: -20.805318779540368, timestamp: 2022-08-20 06:57:41.281892\n",
      "resetting env. episode 421, reward total was -20.0. running mean: -20.797265591744964, timestamp: 2022-08-20 06:57:42.579907\n",
      "resetting env. episode 422, reward total was -21.0. running mean: -20.799292935827516, timestamp: 2022-08-20 06:57:44.437934\n",
      "resetting env. episode 423, reward total was -20.0. running mean: -20.79130000646924, timestamp: 2022-08-20 06:57:46.976956\n",
      "resetting env. episode 424, reward total was -21.0. running mean: -20.793387006404547, timestamp: 2022-08-20 06:57:48.212971\n",
      "resetting env. episode 425, reward total was -21.0. running mean: -20.7954531363405, timestamp: 2022-08-20 06:57:49.848990\n",
      "resetting env. episode 426, reward total was -21.0. running mean: -20.797498604977097, timestamp: 2022-08-20 06:57:51.733008\n",
      "resetting env. episode 427, reward total was -21.0. running mean: -20.799523618927328, timestamp: 2022-08-20 06:57:52.756025\n",
      "resetting env. episode 428, reward total was -21.0. running mean: -20.801528382738056, timestamp: 2022-08-20 06:57:54.370040\n",
      "resetting env. episode 429, reward total was -20.0. running mean: -20.793513098910676, timestamp: 2022-08-20 06:57:56.320060\n",
      "resetting env. episode 430, reward total was -21.0. running mean: -20.79557796792157, timestamp: 2022-08-20 06:57:57.460073\n",
      "resetting env. episode 431, reward total was -20.0. running mean: -20.787622188242352, timestamp: 2022-08-20 06:57:59.555097\n",
      "resetting env. episode 432, reward total was -20.0. running mean: -20.77974596635993, timestamp: 2022-08-20 06:58:00.849113\n",
      "resetting env. episode 433, reward total was -20.0. running mean: -20.77194850669633, timestamp: 2022-08-20 06:58:01.988124\n",
      "resetting env. episode 434, reward total was -20.0. running mean: -20.764229021629365, timestamp: 2022-08-20 06:58:03.109138\n",
      "resetting env. episode 435, reward total was -21.0. running mean: -20.76658673141307, timestamp: 2022-08-20 06:58:04.539153\n",
      "resetting env. episode 436, reward total was -21.0. running mean: -20.76892086409894, timestamp: 2022-08-20 06:58:05.714167\n",
      "resetting env. episode 437, reward total was -21.0. running mean: -20.771231655457953, timestamp: 2022-08-20 06:58:07.061179\n",
      "resetting env. episode 438, reward total was -21.0. running mean: -20.773519338903373, timestamp: 2022-08-20 06:58:08.228194\n",
      "resetting env. episode 439, reward total was -21.0. running mean: -20.77578414551434, timestamp: 2022-08-20 06:58:09.830210\n",
      "resetting env. episode 440, reward total was -21.0. running mean: -20.778026304059196, timestamp: 2022-08-20 06:58:11.442231\n",
      "resetting env. episode 441, reward total was -21.0. running mean: -20.780246041018604, timestamp: 2022-08-20 06:58:12.788244\n",
      "resetting env. episode 442, reward total was -21.0. running mean: -20.78244358060842, timestamp: 2022-08-20 06:58:14.441266\n",
      "resetting env. episode 443, reward total was -21.0. running mean: -20.784619144802335, timestamp: 2022-08-20 06:58:16.374286\n",
      "resetting env. episode 444, reward total was -21.0. running mean: -20.786772953354312, timestamp: 2022-08-20 06:58:17.402295\n",
      "resetting env. episode 445, reward total was -21.0. running mean: -20.78890522382077, timestamp: 2022-08-20 06:58:18.680309\n",
      "resetting env. episode 446, reward total was -20.0. running mean: -20.78101617158256, timestamp: 2022-08-20 06:58:19.975322\n",
      "resetting env. episode 447, reward total was -21.0. running mean: -20.783206009866735, timestamp: 2022-08-20 06:58:21.382338\n",
      "resetting env. episode 448, reward total was -21.0. running mean: -20.78537394976807, timestamp: 2022-08-20 06:58:22.795360\n",
      "resetting env. episode 449, reward total was -21.0. running mean: -20.78752021027039, timestamp: 2022-08-20 06:58:24.133368\n",
      "resetting env. episode 450, reward total was -21.0. running mean: -20.789645008167685, timestamp: 2022-08-20 06:58:25.264381\n",
      "resetting env. episode 451, reward total was -21.0. running mean: -20.79174855808601, timestamp: 2022-08-20 06:58:27.074408\n",
      "resetting env. episode 452, reward total was -21.0. running mean: -20.79383107250515, timestamp: 2022-08-20 06:58:28.932424\n",
      "resetting env. episode 453, reward total was -21.0. running mean: -20.7958927617801, timestamp: 2022-08-20 06:58:30.190436\n",
      "resetting env. episode 454, reward total was -21.0. running mean: -20.797933834162297, timestamp: 2022-08-20 06:58:31.423452\n",
      "resetting env. episode 455, reward total was -21.0. running mean: -20.799954495820675, timestamp: 2022-08-20 06:58:32.454461\n",
      "resetting env. episode 456, reward total was -20.0. running mean: -20.79195495086247, timestamp: 2022-08-20 06:58:33.904478\n",
      "resetting env. episode 457, reward total was -21.0. running mean: -20.794035401353845, timestamp: 2022-08-20 06:58:35.022494\n",
      "resetting env. episode 458, reward total was -20.0. running mean: -20.786095047340307, timestamp: 2022-08-20 06:58:36.639513\n",
      "resetting env. episode 459, reward total was -21.0. running mean: -20.788234096866905, timestamp: 2022-08-20 06:58:38.221530\n",
      "resetting env. episode 460, reward total was -21.0. running mean: -20.790351755898236, timestamp: 2022-08-20 06:58:39.693541\n",
      "resetting env. episode 461, reward total was -21.0. running mean: -20.792448238339254, timestamp: 2022-08-20 06:58:41.137560\n",
      "resetting env. episode 462, reward total was -21.0. running mean: -20.79452375595586, timestamp: 2022-08-20 06:58:42.387572\n",
      "resetting env. episode 463, reward total was -21.0. running mean: -20.796578518396302, timestamp: 2022-08-20 06:58:43.662592\n",
      "resetting env. episode 464, reward total was -20.0. running mean: -20.78861273321234, timestamp: 2022-08-20 06:58:45.003600\n",
      "resetting env. episode 465, reward total was -21.0. running mean: -20.790726605880216, timestamp: 2022-08-20 06:58:46.216618\n",
      "resetting env. episode 466, reward total was -21.0. running mean: -20.792819339821413, timestamp: 2022-08-20 06:58:47.434630\n",
      "resetting env. episode 467, reward total was -21.0. running mean: -20.7948911464232, timestamp: 2022-08-20 06:58:49.353652\n",
      "resetting env. episode 468, reward total was -21.0. running mean: -20.79694223495897, timestamp: 2022-08-20 06:58:50.466663\n",
      "resetting env. episode 469, reward total was -20.0. running mean: -20.78897281260938, timestamp: 2022-08-20 06:58:52.170687\n",
      "resetting env. episode 470, reward total was -21.0. running mean: -20.791083084483287, timestamp: 2022-08-20 06:58:53.220692\n",
      "resetting env. episode 471, reward total was -20.0. running mean: -20.78317225363845, timestamp: 2022-08-20 06:58:54.790712\n",
      "resetting env. episode 472, reward total was -21.0. running mean: -20.78534053110207, timestamp: 2022-08-20 06:58:56.289731\n",
      "resetting env. episode 473, reward total was -21.0. running mean: -20.78748712579105, timestamp: 2022-08-20 06:58:57.779744\n",
      "resetting env. episode 474, reward total was -20.0. running mean: -20.779612254533138, timestamp: 2022-08-20 06:58:59.546767\n",
      "resetting env. episode 475, reward total was -20.0. running mean: -20.771816131987805, timestamp: 2022-08-20 06:59:01.029783\n",
      "resetting env. episode 476, reward total was -21.0. running mean: -20.774097970667928, timestamp: 2022-08-20 06:59:02.317795\n",
      "resetting env. episode 477, reward total was -20.0. running mean: -20.76635699096125, timestamp: 2022-08-20 06:59:04.071815\n",
      "resetting env. episode 478, reward total was -20.0. running mean: -20.758693421051635, timestamp: 2022-08-20 06:59:05.286833\n",
      "resetting env. episode 479, reward total was -21.0. running mean: -20.76110648684112, timestamp: 2022-08-20 06:59:06.780374\n",
      "resetting env. episode 480, reward total was -21.0. running mean: -20.763495421972706, timestamp: 2022-08-20 06:59:07.831384\n",
      "resetting env. episode 481, reward total was -20.0. running mean: -20.755860467752978, timestamp: 2022-08-20 06:59:09.370398\n",
      "resetting env. episode 482, reward total was -20.0. running mean: -20.748301863075447, timestamp: 2022-08-20 06:59:10.832420\n",
      "resetting env. episode 483, reward total was -21.0. running mean: -20.750818844444694, timestamp: 2022-08-20 06:59:12.585439\n",
      "resetting env. episode 484, reward total was -21.0. running mean: -20.75331065600025, timestamp: 2022-08-20 06:59:13.676449\n",
      "resetting env. episode 485, reward total was -19.0. running mean: -20.735777549440247, timestamp: 2022-08-20 06:59:15.128478\n",
      "resetting env. episode 486, reward total was -21.0. running mean: -20.738419773945846, timestamp: 2022-08-20 06:59:16.975008\n",
      "resetting env. episode 487, reward total was -21.0. running mean: -20.74103557620639, timestamp: 2022-08-20 06:59:18.411022\n",
      "resetting env. episode 488, reward total was -21.0. running mean: -20.743625220444326, timestamp: 2022-08-20 06:59:19.786038\n",
      "resetting env. episode 489, reward total was -20.0. running mean: -20.736188968239883, timestamp: 2022-08-20 06:59:21.849062\n",
      "resetting env. episode 490, reward total was -19.0. running mean: -20.718827078557485, timestamp: 2022-08-20 06:59:23.254079\n",
      "resetting env. episode 491, reward total was -21.0. running mean: -20.72163880777191, timestamp: 2022-08-20 06:59:24.618092\n",
      "resetting env. episode 492, reward total was -21.0. running mean: -20.724422419694193, timestamp: 2022-08-20 06:59:25.886115\n",
      "resetting env. episode 493, reward total was -21.0. running mean: -20.727178195497252, timestamp: 2022-08-20 06:59:27.447126\n",
      "resetting env. episode 494, reward total was -21.0. running mean: -20.72990641354228, timestamp: 2022-08-20 06:59:28.546138\n",
      "resetting env. episode 495, reward total was -21.0. running mean: -20.73260734940686, timestamp: 2022-08-20 06:59:29.793150\n",
      "resetting env. episode 496, reward total was -21.0. running mean: -20.73528127591279, timestamp: 2022-08-20 06:59:31.058166\n",
      "resetting env. episode 497, reward total was -21.0. running mean: -20.73792846315366, timestamp: 2022-08-20 06:59:32.629186\n",
      "resetting env. episode 498, reward total was -21.0. running mean: -20.740549178522127, timestamp: 2022-08-20 06:59:34.266206\n",
      "resetting env. episode 499, reward total was -21.0. running mean: -20.743143686736907, timestamp: 2022-08-20 06:59:35.792219\n",
      "resetting env. episode 500, reward total was -21.0. running mean: -20.745712249869538, timestamp: 2022-08-20 06:59:37.626240\n",
      "resetting env. episode 501, reward total was -21.0. running mean: -20.748255127370843, timestamp: 2022-08-20 06:59:40.414273\n",
      "resetting env. episode 502, reward total was -20.0. running mean: -20.740772576097132, timestamp: 2022-08-20 06:59:42.249290\n",
      "resetting env. episode 503, reward total was -21.0. running mean: -20.74336485033616, timestamp: 2022-08-20 06:59:43.353306\n",
      "resetting env. episode 504, reward total was -21.0. running mean: -20.7459312018328, timestamp: 2022-08-20 06:59:44.631316\n",
      "resetting env. episode 505, reward total was -20.0. running mean: -20.73847188981447, timestamp: 2022-08-20 06:59:46.007332\n",
      "resetting env. episode 506, reward total was -21.0. running mean: -20.741087170916327, timestamp: 2022-08-20 06:59:47.296347\n",
      "resetting env. episode 507, reward total was -21.0. running mean: -20.743676299207163, timestamp: 2022-08-20 06:59:48.654361\n",
      "resetting env. episode 508, reward total was -21.0. running mean: -20.746239536215093, timestamp: 2022-08-20 06:59:50.014382\n",
      "resetting env. episode 509, reward total was -21.0. running mean: -20.748777140852944, timestamp: 2022-08-20 06:59:51.220396\n",
      "resetting env. episode 510, reward total was -21.0. running mean: -20.751289369444414, timestamp: 2022-08-20 06:59:53.271414\n",
      "resetting env. episode 511, reward total was -21.0. running mean: -20.75377647574997, timestamp: 2022-08-20 06:59:54.699428\n",
      "resetting env. episode 512, reward total was -20.0. running mean: -20.74623871099247, timestamp: 2022-08-20 06:59:56.022446\n",
      "resetting env. episode 513, reward total was -21.0. running mean: -20.748776323882545, timestamp: 2022-08-20 06:59:57.348463\n",
      "resetting env. episode 514, reward total was -21.0. running mean: -20.75128856064372, timestamp: 2022-08-20 06:59:58.579477\n",
      "resetting env. episode 515, reward total was -21.0. running mean: -20.753775675037282, timestamp: 2022-08-20 06:59:59.934493\n",
      "resetting env. episode 516, reward total was -21.0. running mean: -20.75623791828691, timestamp: 2022-08-20 07:00:01.684512\n",
      "resetting env. episode 517, reward total was -21.0. running mean: -20.758675539104043, timestamp: 2022-08-20 07:00:02.908521\n",
      "resetting env. episode 518, reward total was -21.0. running mean: -20.761088783713003, timestamp: 2022-08-20 07:00:04.182536\n",
      "resetting env. episode 519, reward total was -21.0. running mean: -20.763477895875873, timestamp: 2022-08-20 07:00:05.524552\n",
      "resetting env. episode 520, reward total was -21.0. running mean: -20.765843116917114, timestamp: 2022-08-20 07:00:06.881566\n",
      "resetting env. episode 521, reward total was -20.0. running mean: -20.758184685747942, timestamp: 2022-08-20 07:00:08.441583\n",
      "resetting env. episode 522, reward total was -21.0. running mean: -20.760602838890463, timestamp: 2022-08-20 07:00:09.735598\n",
      "resetting env. episode 523, reward total was -21.0. running mean: -20.76299681050156, timestamp: 2022-08-20 07:00:10.927611\n",
      "resetting env. episode 524, reward total was -21.0. running mean: -20.765366842396542, timestamp: 2022-08-20 07:00:12.406628\n",
      "resetting env. episode 525, reward total was -21.0. running mean: -20.767713173972577, timestamp: 2022-08-20 07:00:13.690642\n",
      "resetting env. episode 526, reward total was -21.0. running mean: -20.770036042232853, timestamp: 2022-08-20 07:00:15.361664\n",
      "resetting env. episode 527, reward total was -20.0. running mean: -20.762335681810523, timestamp: 2022-08-20 07:00:17.015680\n",
      "resetting env. episode 528, reward total was -21.0. running mean: -20.76471232499242, timestamp: 2022-08-20 07:00:18.307696\n",
      "resetting env. episode 529, reward total was -20.0. running mean: -20.757065201742495, timestamp: 2022-08-20 07:00:19.931714\n",
      "resetting env. episode 530, reward total was -21.0. running mean: -20.759494549725073, timestamp: 2022-08-20 07:00:21.597734\n",
      "resetting env. episode 531, reward total was -21.0. running mean: -20.76189960422782, timestamp: 2022-08-20 07:00:22.942752\n",
      "resetting env. episode 532, reward total was -21.0. running mean: -20.764280608185544, timestamp: 2022-08-20 07:00:24.170766\n",
      "resetting env. episode 533, reward total was -20.0. running mean: -20.756637802103686, timestamp: 2022-08-20 07:00:25.796781\n",
      "resetting env. episode 534, reward total was -21.0. running mean: -20.75907142408265, timestamp: 2022-08-20 07:00:26.937792\n",
      "resetting env. episode 535, reward total was -21.0. running mean: -20.761480709841823, timestamp: 2022-08-20 07:00:28.344806\n",
      "resetting env. episode 536, reward total was -21.0. running mean: -20.763865902743404, timestamp: 2022-08-20 07:00:29.370817\n",
      "resetting env. episode 537, reward total was -21.0. running mean: -20.76622724371597, timestamp: 2022-08-20 07:00:30.789833\n",
      "resetting env. episode 538, reward total was -21.0. running mean: -20.768564971278813, timestamp: 2022-08-20 07:00:31.828844\n",
      "resetting env. episode 539, reward total was -21.0. running mean: -20.770879321566024, timestamp: 2022-08-20 07:00:33.700868\n",
      "resetting env. episode 540, reward total was -20.0. running mean: -20.763170528350365, timestamp: 2022-08-20 07:00:34.984880\n",
      "resetting env. episode 541, reward total was -20.0. running mean: -20.75553882306686, timestamp: 2022-08-20 07:00:36.911903\n",
      "resetting env. episode 542, reward total was -21.0. running mean: -20.75798343483619, timestamp: 2022-08-20 07:00:38.404917\n",
      "resetting env. episode 543, reward total was -20.0. running mean: -20.75040360048783, timestamp: 2022-08-20 07:00:39.553933\n",
      "resetting env. episode 544, reward total was -21.0. running mean: -20.752899564482952, timestamp: 2022-08-20 07:00:41.119951\n",
      "resetting env. episode 545, reward total was -21.0. running mean: -20.755370568838124, timestamp: 2022-08-20 07:00:42.139960\n",
      "resetting env. episode 546, reward total was -21.0. running mean: -20.757816863149742, timestamp: 2022-08-20 07:00:43.574983\n",
      "resetting env. episode 547, reward total was -20.0. running mean: -20.750238694518245, timestamp: 2022-08-20 07:00:44.856990\n",
      "resetting env. episode 548, reward total was -21.0. running mean: -20.752736307573063, timestamp: 2022-08-20 07:00:46.614008\n",
      "resetting env. episode 549, reward total was -20.0. running mean: -20.74520894449733, timestamp: 2022-08-20 07:00:47.996029\n",
      "resetting env. episode 550, reward total was -21.0. running mean: -20.74775685505236, timestamp: 2022-08-20 07:00:49.123036\n",
      "resetting env. episode 551, reward total was -20.0. running mean: -20.740279286501835, timestamp: 2022-08-20 07:00:50.747054\n",
      "resetting env. episode 552, reward total was -21.0. running mean: -20.742876493636818, timestamp: 2022-08-20 07:00:51.791065\n",
      "resetting env. episode 553, reward total was -16.0. running mean: -20.69544772870045, timestamp: 2022-08-20 07:00:54.485096\n",
      "resetting env. episode 554, reward total was -20.0. running mean: -20.688493251413444, timestamp: 2022-08-20 07:00:55.898113\n",
      "resetting env. episode 555, reward total was -21.0. running mean: -20.69160831889931, timestamp: 2022-08-20 07:00:57.153128\n",
      "resetting env. episode 556, reward total was -21.0. running mean: -20.694692235710317, timestamp: 2022-08-20 07:00:58.418140\n",
      "resetting env. episode 557, reward total was -21.0. running mean: -20.697745313353213, timestamp: 2022-08-20 07:01:00.242162\n",
      "resetting env. episode 558, reward total was -21.0. running mean: -20.70076786021968, timestamp: 2022-08-20 07:01:01.444175\n",
      "resetting env. episode 559, reward total was -21.0. running mean: -20.703760181617486, timestamp: 2022-08-20 07:01:02.738190\n",
      "resetting env. episode 560, reward total was -20.0. running mean: -20.69672257980131, timestamp: 2022-08-20 07:01:04.257206\n",
      "resetting env. episode 561, reward total was -21.0. running mean: -20.699755354003297, timestamp: 2022-08-20 07:01:05.828224\n",
      "resetting env. episode 562, reward total was -20.0. running mean: -20.692757800463262, timestamp: 2022-08-20 07:01:07.026244\n",
      "resetting env. episode 563, reward total was -20.0. running mean: -20.68583022245863, timestamp: 2022-08-20 07:01:08.668253\n",
      "resetting env. episode 564, reward total was -20.0. running mean: -20.678971920234044, timestamp: 2022-08-20 07:01:10.518276\n",
      "resetting env. episode 565, reward total was -21.0. running mean: -20.682182201031704, timestamp: 2022-08-20 07:01:11.691291\n",
      "resetting env. episode 566, reward total was -21.0. running mean: -20.68536037902139, timestamp: 2022-08-20 07:01:13.060302\n",
      "resetting env. episode 567, reward total was -21.0. running mean: -20.688506775231176, timestamp: 2022-08-20 07:01:15.362328\n",
      "resetting env. episode 568, reward total was -19.0. running mean: -20.671621707478867, timestamp: 2022-08-20 07:01:17.049348\n",
      "resetting env. episode 569, reward total was -21.0. running mean: -20.67490549040408, timestamp: 2022-08-20 07:01:18.737365\n",
      "resetting env. episode 570, reward total was -20.0. running mean: -20.668156435500038, timestamp: 2022-08-20 07:01:19.903379\n",
      "resetting env. episode 571, reward total was -20.0. running mean: -20.661474871145035, timestamp: 2022-08-20 07:01:21.613399\n",
      "resetting env. episode 572, reward total was -21.0. running mean: -20.664860122433584, timestamp: 2022-08-20 07:01:23.325416\n",
      "resetting env. episode 573, reward total was -21.0. running mean: -20.668211521209248, timestamp: 2022-08-20 07:01:24.454428\n",
      "resetting env. episode 574, reward total was -20.0. running mean: -20.661529405997154, timestamp: 2022-08-20 07:01:26.278448\n",
      "resetting env. episode 575, reward total was -21.0. running mean: -20.664914111937183, timestamp: 2022-08-20 07:01:27.737468\n",
      "resetting env. episode 576, reward total was -21.0. running mean: -20.668264970817813, timestamp: 2022-08-20 07:01:29.809488\n",
      "resetting env. episode 577, reward total was -21.0. running mean: -20.671582321109636, timestamp: 2022-08-20 07:01:31.069502\n",
      "resetting env. episode 578, reward total was -21.0. running mean: -20.67486649789854, timestamp: 2022-08-20 07:01:32.873526\n",
      "resetting env. episode 579, reward total was -21.0. running mean: -20.678117832919558, timestamp: 2022-08-20 07:01:33.973534\n",
      "resetting env. episode 580, reward total was -21.0. running mean: -20.681336654590364, timestamp: 2022-08-20 07:01:35.438552\n",
      "resetting env. episode 581, reward total was -20.0. running mean: -20.67452328804446, timestamp: 2022-08-20 07:01:36.925570\n",
      "resetting env. episode 582, reward total was -21.0. running mean: -20.677778055164016, timestamp: 2022-08-20 07:01:38.425583\n",
      "resetting env. episode 583, reward total was -20.0. running mean: -20.671000274612375, timestamp: 2022-08-20 07:01:39.651598\n",
      "resetting env. episode 584, reward total was -21.0. running mean: -20.67429027186625, timestamp: 2022-08-20 07:01:41.409620\n",
      "resetting env. episode 585, reward total was -20.0. running mean: -20.667547369147588, timestamp: 2022-08-20 07:01:43.291638\n",
      "resetting env. episode 586, reward total was -20.0. running mean: -20.66087189545611, timestamp: 2022-08-20 07:01:44.638659\n",
      "resetting env. episode 587, reward total was -20.0. running mean: -20.654263176501548, timestamp: 2022-08-20 07:01:46.154674\n",
      "resetting env. episode 588, reward total was -20.0. running mean: -20.647720544736533, timestamp: 2022-08-20 07:01:48.224699\n",
      "resetting env. episode 589, reward total was -20.0. running mean: -20.641243339289165, timestamp: 2022-08-20 07:01:49.705711\n",
      "resetting env. episode 590, reward total was -19.0. running mean: -20.624830905896275, timestamp: 2022-08-20 07:01:51.993738\n",
      "resetting env. episode 591, reward total was -21.0. running mean: -20.62858259683731, timestamp: 2022-08-20 07:01:53.535753\n",
      "resetting env. episode 592, reward total was -20.0. running mean: -20.62229677086894, timestamp: 2022-08-20 07:01:54.688766\n",
      "resetting env. episode 593, reward total was -21.0. running mean: -20.62607380316025, timestamp: 2022-08-20 07:01:56.171784\n",
      "resetting env. episode 594, reward total was -21.0. running mean: -20.629813065128648, timestamp: 2022-08-20 07:01:57.509800\n",
      "resetting env. episode 595, reward total was -19.0. running mean: -20.61351493447736, timestamp: 2022-08-20 07:01:58.997819\n",
      "resetting env. episode 596, reward total was -21.0. running mean: -20.617379785132588, timestamp: 2022-08-20 07:02:00.503836\n",
      "resetting env. episode 597, reward total was -20.0. running mean: -20.61120598728126, timestamp: 2022-08-20 07:02:01.759848\n",
      "resetting env. episode 598, reward total was -21.0. running mean: -20.61509392740845, timestamp: 2022-08-20 07:02:03.582869\n",
      "resetting env. episode 599, reward total was -21.0. running mean: -20.618942988134364, timestamp: 2022-08-20 07:02:05.094887\n",
      "resetting env. episode 600, reward total was -21.0. running mean: -20.62275355825302, timestamp: 2022-08-20 07:02:07.090906\n",
      "resetting env. episode 601, reward total was -21.0. running mean: -20.62652602267049, timestamp: 2022-08-20 07:02:08.886928\n",
      "resetting env. episode 602, reward total was -21.0. running mean: -20.630260762443786, timestamp: 2022-08-20 07:02:10.219940\n",
      "resetting env. episode 603, reward total was -21.0. running mean: -20.63395815481935, timestamp: 2022-08-20 07:02:11.765482\n",
      "resetting env. episode 604, reward total was -21.0. running mean: -20.63761857327116, timestamp: 2022-08-20 07:02:12.803488\n",
      "resetting env. episode 605, reward total was -21.0. running mean: -20.641242387538448, timestamp: 2022-08-20 07:02:14.067503\n",
      "resetting env. episode 606, reward total was -21.0. running mean: -20.644829963663064, timestamp: 2022-08-20 07:02:15.307521\n",
      "resetting env. episode 607, reward total was -21.0. running mean: -20.648381664026434, timestamp: 2022-08-20 07:02:16.819532\n",
      "resetting env. episode 608, reward total was -21.0. running mean: -20.65189784738617, timestamp: 2022-08-20 07:02:18.005546\n",
      "resetting env. episode 609, reward total was -20.0. running mean: -20.645378868912307, timestamp: 2022-08-20 07:02:19.708570\n",
      "resetting env. episode 610, reward total was -21.0. running mean: -20.648925080223183, timestamp: 2022-08-20 07:02:20.924581\n",
      "resetting env. episode 611, reward total was -21.0. running mean: -20.652435829420952, timestamp: 2022-08-20 07:02:22.642600\n",
      "resetting env. episode 612, reward total was -20.0. running mean: -20.64591147112674, timestamp: 2022-08-20 07:02:24.681626\n",
      "resetting env. episode 613, reward total was -21.0. running mean: -20.649452356415473, timestamp: 2022-08-20 07:02:25.884638\n",
      "resetting env. episode 614, reward total was -21.0. running mean: -20.652957832851317, timestamp: 2022-08-20 07:02:27.584655\n",
      "resetting env. episode 615, reward total was -21.0. running mean: -20.656428254522805, timestamp: 2022-08-20 07:02:29.089677\n",
      "resetting env. episode 616, reward total was -21.0. running mean: -20.65986397197758, timestamp: 2022-08-20 07:02:30.449691\n",
      "resetting env. episode 617, reward total was -21.0. running mean: -20.663265332257804, timestamp: 2022-08-20 07:02:31.709706\n",
      "resetting env. episode 618, reward total was -21.0. running mean: -20.666632678935226, timestamp: 2022-08-20 07:02:32.837716\n",
      "resetting env. episode 619, reward total was -19.0. running mean: -20.649966352145874, timestamp: 2022-08-20 07:02:34.285733\n",
      "resetting env. episode 620, reward total was -20.0. running mean: -20.643466688624414, timestamp: 2022-08-20 07:02:35.542745\n",
      "resetting env. episode 621, reward total was -21.0. running mean: -20.64703202173817, timestamp: 2022-08-20 07:02:36.947758\n",
      "resetting env. episode 622, reward total was -21.0. running mean: -20.65056170152079, timestamp: 2022-08-20 07:02:38.086773\n",
      "resetting env. episode 623, reward total was -21.0. running mean: -20.654056084505584, timestamp: 2022-08-20 07:02:39.587791\n",
      "resetting env. episode 624, reward total was -20.0. running mean: -20.647515523660527, timestamp: 2022-08-20 07:02:41.359811\n",
      "resetting env. episode 625, reward total was -20.0. running mean: -20.64104036842392, timestamp: 2022-08-20 07:02:42.607823\n",
      "resetting env. episode 626, reward total was -21.0. running mean: -20.644629964739682, timestamp: 2022-08-20 07:02:43.965839\n",
      "resetting env. episode 627, reward total was -21.0. running mean: -20.648183665092287, timestamp: 2022-08-20 07:02:45.299852\n",
      "resetting env. episode 628, reward total was -21.0. running mean: -20.651701828441364, timestamp: 2022-08-20 07:02:46.553867\n",
      "resetting env. episode 629, reward total was -21.0. running mean: -20.65518481015695, timestamp: 2022-08-20 07:02:47.747883\n",
      "resetting env. episode 630, reward total was -21.0. running mean: -20.658632962055382, timestamp: 2022-08-20 07:02:49.132898\n",
      "resetting env. episode 631, reward total was -20.0. running mean: -20.65204663243483, timestamp: 2022-08-20 07:02:50.534912\n",
      "resetting env. episode 632, reward total was -21.0. running mean: -20.65552616611048, timestamp: 2022-08-20 07:02:52.397931\n",
      "resetting env. episode 633, reward total was -20.0. running mean: -20.648970904449374, timestamp: 2022-08-20 07:02:54.235954\n",
      "resetting env. episode 634, reward total was -21.0. running mean: -20.65248119540488, timestamp: 2022-08-20 07:02:55.617969\n",
      "resetting env. episode 635, reward total was -21.0. running mean: -20.65595638345083, timestamp: 2022-08-20 07:02:57.095984\n",
      "resetting env. episode 636, reward total was -21.0. running mean: -20.659396819616322, timestamp: 2022-08-20 07:02:58.438005\n",
      "resetting env. episode 637, reward total was -21.0. running mean: -20.66280285142016, timestamp: 2022-08-20 07:03:00.095020\n",
      "resetting env. episode 638, reward total was -21.0. running mean: -20.66617482290596, timestamp: 2022-08-20 07:03:01.821037\n",
      "resetting env. episode 639, reward total was -20.0. running mean: -20.659513074676898, timestamp: 2022-08-20 07:03:02.957054\n",
      "resetting env. episode 640, reward total was -21.0. running mean: -20.66291794393013, timestamp: 2022-08-20 07:03:05.029076\n",
      "resetting env. episode 641, reward total was -21.0. running mean: -20.66628876449083, timestamp: 2022-08-20 07:03:06.116088\n",
      "resetting env. episode 642, reward total was -19.0. running mean: -20.64962587684592, timestamp: 2022-08-20 07:03:07.901105\n",
      "resetting env. episode 643, reward total was -20.0. running mean: -20.64312961807746, timestamp: 2022-08-20 07:03:09.289120\n",
      "resetting env. episode 644, reward total was -21.0. running mean: -20.646698321896686, timestamp: 2022-08-20 07:03:10.889141\n",
      "resetting env. episode 645, reward total was -21.0. running mean: -20.65023133867772, timestamp: 2022-08-20 07:03:12.651158\n",
      "resetting env. episode 646, reward total was -21.0. running mean: -20.653729025290943, timestamp: 2022-08-20 07:03:13.985177\n",
      "resetting env. episode 647, reward total was -20.0. running mean: -20.64719173503803, timestamp: 2022-08-20 07:03:15.293188\n",
      "resetting env. episode 648, reward total was -21.0. running mean: -20.65071981768765, timestamp: 2022-08-20 07:03:16.715206\n",
      "resetting env. episode 649, reward total was -21.0. running mean: -20.654212619510776, timestamp: 2022-08-20 07:03:18.212223\n",
      "resetting env. episode 650, reward total was -21.0. running mean: -20.65767049331567, timestamp: 2022-08-20 07:03:19.982239\n",
      "resetting env. episode 651, reward total was -20.0. running mean: -20.651093788382514, timestamp: 2022-08-20 07:03:21.301258\n",
      "resetting env. episode 652, reward total was -20.0. running mean: -20.64458285049869, timestamp: 2022-08-20 07:03:22.726272\n",
      "resetting env. episode 653, reward total was -20.0. running mean: -20.638137021993703, timestamp: 2022-08-20 07:03:24.230295\n",
      "resetting env. episode 654, reward total was -20.0. running mean: -20.631755651773766, timestamp: 2022-08-20 07:03:25.950307\n",
      "resetting env. episode 655, reward total was -21.0. running mean: -20.635438095256028, timestamp: 2022-08-20 07:03:27.704333\n",
      "resetting env. episode 656, reward total was -21.0. running mean: -20.639083714303467, timestamp: 2022-08-20 07:03:28.991345\n",
      "resetting env. episode 657, reward total was -19.0. running mean: -20.622692877160432, timestamp: 2022-08-20 07:03:30.399359\n",
      "resetting env. episode 658, reward total was -21.0. running mean: -20.62646594838883, timestamp: 2022-08-20 07:03:31.765374\n",
      "resetting env. episode 659, reward total was -21.0. running mean: -20.630201288904942, timestamp: 2022-08-20 07:03:32.858385\n",
      "resetting env. episode 660, reward total was -21.0. running mean: -20.633899276015892, timestamp: 2022-08-20 07:03:34.578403\n",
      "resetting env. episode 661, reward total was -21.0. running mean: -20.637560283255734, timestamp: 2022-08-20 07:03:35.902420\n",
      "resetting env. episode 662, reward total was -21.0. running mean: -20.641184680423176, timestamp: 2022-08-20 07:03:37.156433\n",
      "resetting env. episode 663, reward total was -20.0. running mean: -20.634772833618943, timestamp: 2022-08-20 07:03:38.324449\n",
      "resetting env. episode 664, reward total was -18.0. running mean: -20.608425105282752, timestamp: 2022-08-20 07:03:40.137469\n",
      "resetting env. episode 665, reward total was -20.0. running mean: -20.602340854229922, timestamp: 2022-08-20 07:03:41.640486\n",
      "resetting env. episode 666, reward total was -21.0. running mean: -20.606317445687623, timestamp: 2022-08-20 07:03:43.387508\n",
      "resetting env. episode 667, reward total was -21.0. running mean: -20.610254271230747, timestamp: 2022-08-20 07:03:44.757518\n",
      "resetting env. episode 668, reward total was -21.0. running mean: -20.61415172851844, timestamp: 2022-08-20 07:03:46.083538\n",
      "resetting env. episode 669, reward total was -20.0. running mean: -20.608010211233253, timestamp: 2022-08-20 07:03:47.728552\n",
      "resetting env. episode 670, reward total was -19.0. running mean: -20.591930109120923, timestamp: 2022-08-20 07:03:49.321572\n",
      "resetting env. episode 671, reward total was -18.0. running mean: -20.566010808029713, timestamp: 2022-08-20 07:03:51.014598\n",
      "resetting env. episode 672, reward total was -18.0. running mean: -20.540350699949414, timestamp: 2022-08-20 07:03:52.892611\n",
      "resetting env. episode 673, reward total was -18.0. running mean: -20.51494719294992, timestamp: 2022-08-20 07:03:54.505628\n",
      "resetting env. episode 674, reward total was -19.0. running mean: -20.49979772102042, timestamp: 2022-08-20 07:03:55.816646\n",
      "resetting env. episode 675, reward total was -21.0. running mean: -20.504799743810217, timestamp: 2022-08-20 07:03:57.492661\n",
      "resetting env. episode 676, reward total was -21.0. running mean: -20.509751746372114, timestamp: 2022-08-20 07:03:59.039681\n",
      "resetting env. episode 677, reward total was -21.0. running mean: -20.514654228908395, timestamp: 2022-08-20 07:04:00.684696\n",
      "resetting env. episode 678, reward total was -19.0. running mean: -20.49950768661931, timestamp: 2022-08-20 07:04:02.319715\n",
      "resetting env. episode 679, reward total was -21.0. running mean: -20.504512609753117, timestamp: 2022-08-20 07:04:03.482729\n",
      "resetting env. episode 680, reward total was -21.0. running mean: -20.509467483655587, timestamp: 2022-08-20 07:04:04.994271\n",
      "resetting env. episode 681, reward total was -19.0. running mean: -20.494372808819033, timestamp: 2022-08-20 07:04:06.482291\n",
      "resetting env. episode 682, reward total was -21.0. running mean: -20.499429080730845, timestamp: 2022-08-20 07:04:07.740306\n",
      "resetting env. episode 683, reward total was -21.0. running mean: -20.504434789923536, timestamp: 2022-08-20 07:04:08.863312\n",
      "resetting env. episode 684, reward total was -19.0. running mean: -20.489390442024302, timestamp: 2022-08-20 07:04:10.528332\n",
      "resetting env. episode 685, reward total was -21.0. running mean: -20.49449653760406, timestamp: 2022-08-20 07:04:11.579344\n",
      "resetting env. episode 686, reward total was -21.0. running mean: -20.49955157222802, timestamp: 2022-08-20 07:04:12.748359\n",
      "resetting env. episode 687, reward total was -21.0. running mean: -20.50455605650574, timestamp: 2022-08-20 07:04:13.718370\n",
      "resetting env. episode 688, reward total was -21.0. running mean: -20.509510495940685, timestamp: 2022-08-20 07:04:15.000383\n",
      "resetting env. episode 689, reward total was -21.0. running mean: -20.514415390981277, timestamp: 2022-08-20 07:04:16.036394\n",
      "resetting env. episode 690, reward total was -21.0. running mean: -20.519271237071464, timestamp: 2022-08-20 07:04:17.217408\n",
      "resetting env. episode 691, reward total was -20.0. running mean: -20.51407852470075, timestamp: 2022-08-20 07:04:18.478422\n",
      "resetting env. episode 692, reward total was -21.0. running mean: -20.518937739453744, timestamp: 2022-08-20 07:04:19.639437\n",
      "resetting env. episode 693, reward total was -21.0. running mean: -20.52374836205921, timestamp: 2022-08-20 07:04:20.715444\n",
      "resetting env. episode 694, reward total was -20.0. running mean: -20.518510878438615, timestamp: 2022-08-20 07:04:22.318463\n",
      "resetting env. episode 695, reward total was -21.0. running mean: -20.523325769654228, timestamp: 2022-08-20 07:04:23.290474\n",
      "resetting env. episode 696, reward total was -21.0. running mean: -20.528092511957688, timestamp: 2022-08-20 07:04:24.382486\n",
      "resetting env. episode 697, reward total was -21.0. running mean: -20.53281158683811, timestamp: 2022-08-20 07:04:25.578499\n",
      "resetting env. episode 698, reward total was -21.0. running mean: -20.53748347096973, timestamp: 2022-08-20 07:04:26.562513\n",
      "resetting env. episode 699, reward total was -21.0. running mean: -20.542108636260032, timestamp: 2022-08-20 07:04:28.125529\n",
      "resetting env. episode 700, reward total was -18.0. running mean: -20.51668754989743, timestamp: 2022-08-20 07:04:29.785547\n",
      "resetting env. episode 701, reward total was -21.0. running mean: -20.521520674398456, timestamp: 2022-08-20 07:04:30.952562\n",
      "resetting env. episode 702, reward total was -21.0. running mean: -20.52630546765447, timestamp: 2022-08-20 07:04:32.328578\n",
      "resetting env. episode 703, reward total was -21.0. running mean: -20.531042412977925, timestamp: 2022-08-20 07:04:33.383592\n",
      "resetting env. episode 704, reward total was -21.0. running mean: -20.535731988848145, timestamp: 2022-08-20 07:04:34.504600\n",
      "resetting env. episode 705, reward total was -21.0. running mean: -20.540374668959664, timestamp: 2022-08-20 07:04:35.766618\n",
      "resetting env. episode 706, reward total was -21.0. running mean: -20.544970922270068, timestamp: 2022-08-20 07:04:36.780624\n",
      "resetting env. episode 707, reward total was -20.0. running mean: -20.539521213047365, timestamp: 2022-08-20 07:04:38.334646\n",
      "resetting env. episode 708, reward total was -21.0. running mean: -20.544126000916894, timestamp: 2022-08-20 07:04:39.388656\n",
      "resetting env. episode 709, reward total was -20.0. running mean: -20.538684740907723, timestamp: 2022-08-20 07:04:41.112672\n",
      "resetting env. episode 710, reward total was -21.0. running mean: -20.543297893498647, timestamp: 2022-08-20 07:04:42.715693\n",
      "resetting env. episode 711, reward total was -20.0. running mean: -20.53786491456366, timestamp: 2022-08-20 07:04:43.938717\n",
      "resetting env. episode 712, reward total was -21.0. running mean: -20.542486265418024, timestamp: 2022-08-20 07:04:45.192722\n",
      "resetting env. episode 713, reward total was -19.0. running mean: -20.527061402763845, timestamp: 2022-08-20 07:04:46.708735\n",
      "resetting env. episode 714, reward total was -17.0. running mean: -20.491790788736207, timestamp: 2022-08-20 07:04:48.689767\n",
      "resetting env. episode 715, reward total was -21.0. running mean: -20.496872880848844, timestamp: 2022-08-20 07:04:49.721774\n",
      "resetting env. episode 716, reward total was -20.0. running mean: -20.491904152040355, timestamp: 2022-08-20 07:04:51.351788\n",
      "resetting env. episode 717, reward total was -21.0. running mean: -20.49698511051995, timestamp: 2022-08-20 07:04:52.767806\n",
      "resetting env. episode 718, reward total was -20.0. running mean: -20.49201525941475, timestamp: 2022-08-20 07:04:54.332821\n",
      "resetting env. episode 719, reward total was -21.0. running mean: -20.497095106820602, timestamp: 2022-08-20 07:04:55.748841\n",
      "resetting env. episode 720, reward total was -21.0. running mean: -20.502124155752398, timestamp: 2022-08-20 07:04:56.890850\n",
      "resetting env. episode 721, reward total was -17.0. running mean: -20.467102914194875, timestamp: 2022-08-20 07:04:58.812873\n",
      "resetting env. episode 722, reward total was -19.0. running mean: -20.452431885052928, timestamp: 2022-08-20 07:05:00.964901\n",
      "resetting env. episode 723, reward total was -19.0. running mean: -20.437907566202398, timestamp: 2022-08-20 07:05:02.827917\n",
      "resetting env. episode 724, reward total was -20.0. running mean: -20.433528490540372, timestamp: 2022-08-20 07:05:04.620937\n",
      "resetting env. episode 725, reward total was -20.0. running mean: -20.429193205634967, timestamp: 2022-08-20 07:05:06.352956\n",
      "resetting env. episode 726, reward total was -18.0. running mean: -20.404901273578616, timestamp: 2022-08-20 07:05:08.228977\n",
      "resetting env. episode 727, reward total was -20.0. running mean: -20.40085226084283, timestamp: 2022-08-20 07:05:09.551994\n",
      "resetting env. episode 728, reward total was -21.0. running mean: -20.4068437382344, timestamp: 2022-08-20 07:05:10.912012\n",
      "resetting env. episode 729, reward total was -19.0. running mean: -20.39277530085206, timestamp: 2022-08-20 07:05:12.266023\n",
      "resetting env. episode 730, reward total was -20.0. running mean: -20.388847547843536, timestamp: 2022-08-20 07:05:13.955041\n",
      "resetting env. episode 731, reward total was -21.0. running mean: -20.3949590723651, timestamp: 2022-08-20 07:05:15.614063\n",
      "resetting env. episode 732, reward total was -20.0. running mean: -20.391009481641447, timestamp: 2022-08-20 07:05:17.254079\n",
      "resetting env. episode 733, reward total was -21.0. running mean: -20.397099386825033, timestamp: 2022-08-20 07:05:18.698095\n",
      "resetting env. episode 734, reward total was -21.0. running mean: -20.403128392956784, timestamp: 2022-08-20 07:05:19.803108\n",
      "resetting env. episode 735, reward total was -21.0. running mean: -20.40909710902722, timestamp: 2022-08-20 07:05:21.560128\n",
      "resetting env. episode 736, reward total was -20.0. running mean: -20.405006137936944, timestamp: 2022-08-20 07:05:23.295148\n",
      "resetting env. episode 737, reward total was -21.0. running mean: -20.410956076557575, timestamp: 2022-08-20 07:05:24.332165\n",
      "resetting env. episode 738, reward total was -19.0. running mean: -20.396846515792, timestamp: 2022-08-20 07:05:26.073181\n",
      "resetting env. episode 739, reward total was -20.0. running mean: -20.392878050634078, timestamp: 2022-08-20 07:05:27.563197\n",
      "resetting env. episode 740, reward total was -20.0. running mean: -20.388949270127736, timestamp: 2022-08-20 07:05:29.403217\n",
      "resetting env. episode 741, reward total was -20.0. running mean: -20.385059777426456, timestamp: 2022-08-20 07:05:31.050239\n",
      "resetting env. episode 742, reward total was -20.0. running mean: -20.381209179652192, timestamp: 2022-08-20 07:05:32.665255\n",
      "resetting env. episode 743, reward total was -21.0. running mean: -20.38739708785567, timestamp: 2022-08-20 07:05:34.337273\n",
      "resetting env. episode 744, reward total was -19.0. running mean: -20.373523116977115, timestamp: 2022-08-20 07:05:35.967292\n",
      "resetting env. episode 745, reward total was -21.0. running mean: -20.379787885807342, timestamp: 2022-08-20 07:05:37.457312\n",
      "resetting env. episode 746, reward total was -19.0. running mean: -20.36599000694927, timestamp: 2022-08-20 07:05:39.222330\n",
      "resetting env. episode 747, reward total was -19.0. running mean: -20.35233010687978, timestamp: 2022-08-20 07:05:40.957347\n",
      "resetting env. episode 748, reward total was -19.0. running mean: -20.338806805810982, timestamp: 2022-08-20 07:05:42.430365\n",
      "resetting env. episode 749, reward total was -21.0. running mean: -20.345418737752873, timestamp: 2022-08-20 07:05:43.849383\n",
      "resetting env. episode 750, reward total was -18.0. running mean: -20.321964550375345, timestamp: 2022-08-20 07:05:45.517401\n",
      "resetting env. episode 751, reward total was -20.0. running mean: -20.31874490487159, timestamp: 2022-08-20 07:05:47.390424\n",
      "resetting env. episode 752, reward total was -21.0. running mean: -20.325557455822874, timestamp: 2022-08-20 07:05:48.881440\n",
      "resetting env. episode 753, reward total was -20.0. running mean: -20.322301881264647, timestamp: 2022-08-20 07:05:50.681458\n",
      "resetting env. episode 754, reward total was -20.0. running mean: -20.319078862452, timestamp: 2022-08-20 07:05:52.524478\n",
      "resetting env. episode 755, reward total was -18.0. running mean: -20.295888073827477, timestamp: 2022-08-20 07:05:54.371498\n",
      "resetting env. episode 756, reward total was -21.0. running mean: -20.302929193089202, timestamp: 2022-08-20 07:05:55.553513\n",
      "resetting env. episode 757, reward total was -19.0. running mean: -20.28989990115831, timestamp: 2022-08-20 07:05:57.140527\n",
      "resetting env. episode 758, reward total was -20.0. running mean: -20.287000902146726, timestamp: 2022-08-20 07:05:59.051549\n",
      "resetting env. episode 759, reward total was -20.0. running mean: -20.28413089312526, timestamp: 2022-08-20 07:06:01.111576\n",
      "resetting env. episode 760, reward total was -21.0. running mean: -20.291289584194008, timestamp: 2022-08-20 07:06:02.451586\n",
      "resetting env. episode 761, reward total was -20.0. running mean: -20.288376688352066, timestamp: 2022-08-20 07:06:04.015604\n",
      "resetting env. episode 762, reward total was -18.0. running mean: -20.265492921468546, timestamp: 2022-08-20 07:06:05.769627\n",
      "resetting env. episode 763, reward total was -16.0. running mean: -20.22283799225386, timestamp: 2022-08-20 07:06:07.873652\n",
      "resetting env. episode 764, reward total was -21.0. running mean: -20.230609612331325, timestamp: 2022-08-20 07:06:09.424668\n",
      "resetting env. episode 765, reward total was -21.0. running mean: -20.238303516208013, timestamp: 2022-08-20 07:06:11.301691\n",
      "resetting env. episode 766, reward total was -19.0. running mean: -20.225920481045936, timestamp: 2022-08-20 07:06:12.827705\n",
      "resetting env. episode 767, reward total was -19.0. running mean: -20.213661276235477, timestamp: 2022-08-20 07:06:14.950732\n",
      "resetting env. episode 768, reward total was -19.0. running mean: -20.201524663473123, timestamp: 2022-08-20 07:06:16.812759\n",
      "resetting env. episode 769, reward total was -21.0. running mean: -20.209509416838394, timestamp: 2022-08-20 07:06:17.850763\n",
      "resetting env. episode 770, reward total was -17.0. running mean: -20.17741432267001, timestamp: 2022-08-20 07:06:19.766780\n",
      "resetting env. episode 771, reward total was -21.0. running mean: -20.18564017944331, timestamp: 2022-08-20 07:06:21.049799\n",
      "resetting env. episode 772, reward total was -21.0. running mean: -20.19378377764888, timestamp: 2022-08-20 07:06:22.114810\n",
      "resetting env. episode 773, reward total was -20.0. running mean: -20.19184593987239, timestamp: 2022-08-20 07:06:23.879831\n",
      "resetting env. episode 774, reward total was -21.0. running mean: -20.19992748047367, timestamp: 2022-08-20 07:06:24.903843\n",
      "resetting env. episode 775, reward total was -21.0. running mean: -20.20792820566893, timestamp: 2022-08-20 07:06:26.291855\n",
      "resetting env. episode 776, reward total was -21.0. running mean: -20.215848923612242, timestamp: 2022-08-20 07:06:27.667870\n",
      "resetting env. episode 777, reward total was -19.0. running mean: -20.20369043437612, timestamp: 2022-08-20 07:06:29.505891\n",
      "resetting env. episode 778, reward total was -21.0. running mean: -20.21165353003236, timestamp: 2022-08-20 07:06:30.754907\n",
      "resetting env. episode 779, reward total was -21.0. running mean: -20.21953699473204, timestamp: 2022-08-20 07:06:32.189924\n",
      "resetting env. episode 780, reward total was -20.0. running mean: -20.217341624784716, timestamp: 2022-08-20 07:06:34.512952\n",
      "resetting env. episode 781, reward total was -19.0. running mean: -20.20516820853687, timestamp: 2022-08-20 07:06:36.235967\n",
      "resetting env. episode 782, reward total was -21.0. running mean: -20.2131165264515, timestamp: 2022-08-20 07:06:37.547981\n",
      "resetting env. episode 783, reward total was -21.0. running mean: -20.220985361186987, timestamp: 2022-08-20 07:06:39.144000\n",
      "resetting env. episode 784, reward total was -21.0. running mean: -20.22877550757512, timestamp: 2022-08-20 07:06:40.735017\n",
      "resetting env. episode 785, reward total was -21.0. running mean: -20.236487752499368, timestamp: 2022-08-20 07:06:42.625038\n",
      "resetting env. episode 786, reward total was -17.0. running mean: -20.204122874974377, timestamp: 2022-08-20 07:06:44.439058\n",
      "resetting env. episode 787, reward total was -21.0. running mean: -20.212081646224632, timestamp: 2022-08-20 07:06:45.629070\n",
      "resetting env. episode 788, reward total was -19.0. running mean: -20.199960829762386, timestamp: 2022-08-20 07:06:47.710096\n",
      "resetting env. episode 789, reward total was -21.0. running mean: -20.207961221464764, timestamp: 2022-08-20 07:06:48.816109\n",
      "resetting env. episode 790, reward total was -20.0. running mean: -20.205881609250117, timestamp: 2022-08-20 07:06:50.580125\n",
      "resetting env. episode 791, reward total was -21.0. running mean: -20.213822793157615, timestamp: 2022-08-20 07:06:52.846152\n",
      "resetting env. episode 792, reward total was -18.0. running mean: -20.191684565226037, timestamp: 2022-08-20 07:06:54.938180\n",
      "resetting env. episode 793, reward total was -21.0. running mean: -20.199767719573778, timestamp: 2022-08-20 07:06:55.961191\n",
      "resetting env. episode 794, reward total was -19.0. running mean: -20.18777004237804, timestamp: 2022-08-20 07:06:58.246215\n",
      "resetting env. episode 795, reward total was -20.0. running mean: -20.18589234195426, timestamp: 2022-08-20 07:07:00.008237\n",
      "resetting env. episode 796, reward total was -20.0. running mean: -20.184033418534717, timestamp: 2022-08-20 07:07:02.127255\n",
      "resetting env. episode 797, reward total was -21.0. running mean: -20.19219308434937, timestamp: 2022-08-20 07:07:03.238267\n",
      "resetting env. episode 798, reward total was -18.0. running mean: -20.170271153505876, timestamp: 2022-08-20 07:07:05.135289\n",
      "resetting env. episode 799, reward total was -21.0. running mean: -20.178568441970818, timestamp: 2022-08-20 07:07:06.561310\n",
      "resetting env. episode 800, reward total was -20.0. running mean: -20.17678275755111, timestamp: 2022-08-20 07:07:07.864319\n",
      "resetting env. episode 801, reward total was -20.0. running mean: -20.175014929975596, timestamp: 2022-08-20 07:07:09.385337\n",
      "resetting env. episode 802, reward total was -19.0. running mean: -20.163264780675842, timestamp: 2022-08-20 07:07:10.980354\n",
      "resetting env. episode 803, reward total was -21.0. running mean: -20.171632132869085, timestamp: 2022-08-20 07:07:12.655373\n",
      "resetting env. episode 804, reward total was -21.0. running mean: -20.179915811540393, timestamp: 2022-08-20 07:07:13.699385\n",
      "resetting env. episode 805, reward total was -21.0. running mean: -20.18811665342499, timestamp: 2022-08-20 07:07:15.167405\n",
      "resetting env. episode 806, reward total was -19.0. running mean: -20.176235486890743, timestamp: 2022-08-20 07:07:16.921421\n",
      "resetting env. episode 807, reward total was -20.0. running mean: -20.174473132021834, timestamp: 2022-08-20 07:07:18.829446\n",
      "resetting env. episode 808, reward total was -20.0. running mean: -20.172728400701615, timestamp: 2022-08-20 07:07:20.254462\n",
      "resetting env. episode 809, reward total was -21.0. running mean: -20.1810011166946, timestamp: 2022-08-20 07:07:21.765478\n",
      "resetting env. episode 810, reward total was -21.0. running mean: -20.189191105527655, timestamp: 2022-08-20 07:07:23.573497\n",
      "resetting env. episode 811, reward total was -21.0. running mean: -20.19729919447238, timestamp: 2022-08-20 07:07:25.082513\n",
      "resetting env. episode 812, reward total was -20.0. running mean: -20.195326202527653, timestamp: 2022-08-20 07:07:26.600532\n",
      "resetting env. episode 813, reward total was -20.0. running mean: -20.193372940502375, timestamp: 2022-08-20 07:07:28.142552\n",
      "resetting env. episode 814, reward total was -20.0. running mean: -20.19143921109735, timestamp: 2022-08-20 07:07:30.146575\n",
      "resetting env. episode 815, reward total was -21.0. running mean: -20.199524818986376, timestamp: 2022-08-20 07:07:31.468586\n",
      "resetting env. episode 816, reward total was -21.0. running mean: -20.207529570796513, timestamp: 2022-08-20 07:07:33.550608\n",
      "resetting env. episode 817, reward total was -20.0. running mean: -20.20545427508855, timestamp: 2022-08-20 07:07:35.777634\n",
      "resetting env. episode 818, reward total was -21.0. running mean: -20.213399732337663, timestamp: 2022-08-20 07:07:37.094652\n",
      "resetting env. episode 819, reward total was -21.0. running mean: -20.22126573501429, timestamp: 2022-08-20 07:07:38.846667\n",
      "resetting env. episode 820, reward total was -18.0. running mean: -20.199053077664146, timestamp: 2022-08-20 07:07:40.571687\n",
      "resetting env. episode 821, reward total was -20.0. running mean: -20.197062546887505, timestamp: 2022-08-20 07:07:42.162710\n",
      "resetting env. episode 822, reward total was -21.0. running mean: -20.20509192141863, timestamp: 2022-08-20 07:07:43.889727\n",
      "resetting env. episode 823, reward total was -20.0. running mean: -20.203041002204444, timestamp: 2022-08-20 07:07:45.825746\n",
      "resetting env. episode 824, reward total was -20.0. running mean: -20.2010105921824, timestamp: 2022-08-20 07:07:47.293762\n",
      "resetting env. episode 825, reward total was -21.0. running mean: -20.209000486260575, timestamp: 2022-08-20 07:07:48.349773\n",
      "resetting env. episode 826, reward total was -21.0. running mean: -20.21691048139797, timestamp: 2022-08-20 07:07:50.235799\n",
      "resetting env. episode 827, reward total was -19.0. running mean: -20.204741376583993, timestamp: 2022-08-20 07:07:51.511812\n",
      "resetting env. episode 828, reward total was -21.0. running mean: -20.212693962818154, timestamp: 2022-08-20 07:07:53.695833\n",
      "resetting env. episode 829, reward total was -20.0. running mean: -20.21056702318997, timestamp: 2022-08-20 07:07:55.391857\n",
      "resetting env. episode 830, reward total was -21.0. running mean: -20.21846135295807, timestamp: 2022-08-20 07:07:57.693879\n",
      "resetting env. episode 831, reward total was -21.0. running mean: -20.22627673942849, timestamp: 2022-08-20 07:07:59.203897\n",
      "resetting env. episode 832, reward total was -21.0. running mean: -20.234013972034205, timestamp: 2022-08-20 07:08:00.729918\n",
      "resetting env. episode 833, reward total was -20.0. running mean: -20.231673832313863, timestamp: 2022-08-20 07:08:02.144933\n",
      "resetting env. episode 834, reward total was -21.0. running mean: -20.239357093990726, timestamp: 2022-08-20 07:08:03.497945\n",
      "resetting env. episode 835, reward total was -20.0. running mean: -20.236963523050818, timestamp: 2022-08-20 07:08:05.831970\n",
      "resetting env. episode 836, reward total was -20.0. running mean: -20.23459388782031, timestamp: 2022-08-20 07:08:07.505989\n",
      "resetting env. episode 837, reward total was -21.0. running mean: -20.242247948942108, timestamp: 2022-08-20 07:08:09.479014\n",
      "resetting env. episode 838, reward total was -21.0. running mean: -20.249825469452688, timestamp: 2022-08-20 07:08:10.628022\n",
      "resetting env. episode 839, reward total was -21.0. running mean: -20.257327214758163, timestamp: 2022-08-20 07:08:11.754037\n",
      "resetting env. episode 840, reward total was -21.0. running mean: -20.264753942610582, timestamp: 2022-08-20 07:08:13.147051\n",
      "resetting env. episode 841, reward total was -20.0. running mean: -20.262106403184475, timestamp: 2022-08-20 07:08:15.120081\n",
      "resetting env. episode 842, reward total was -19.0. running mean: -20.24948533915263, timestamp: 2022-08-20 07:08:16.570091\n",
      "resetting env. episode 843, reward total was -20.0. running mean: -20.246990485761103, timestamp: 2022-08-20 07:08:18.237111\n",
      "resetting env. episode 844, reward total was -21.0. running mean: -20.254520580903492, timestamp: 2022-08-20 07:08:20.040128\n",
      "resetting env. episode 845, reward total was -20.0. running mean: -20.251975375094457, timestamp: 2022-08-20 07:08:21.698150\n",
      "resetting env. episode 846, reward total was -20.0. running mean: -20.24945562134351, timestamp: 2022-08-20 07:08:23.348165\n",
      "resetting env. episode 847, reward total was -19.0. running mean: -20.236961065130078, timestamp: 2022-08-20 07:08:25.100189\n",
      "resetting env. episode 848, reward total was -20.0. running mean: -20.234591454478778, timestamp: 2022-08-20 07:08:27.164211\n",
      "resetting env. episode 849, reward total was -20.0. running mean: -20.232245539933988, timestamp: 2022-08-20 07:08:29.117234\n",
      "resetting env. episode 850, reward total was -21.0. running mean: -20.23992308453465, timestamp: 2022-08-20 07:08:31.002252\n",
      "resetting env. episode 851, reward total was -19.0. running mean: -20.227523853689302, timestamp: 2022-08-20 07:08:32.967797\n",
      "resetting env. episode 852, reward total was -19.0. running mean: -20.21524861515241, timestamp: 2022-08-20 07:08:34.592816\n",
      "resetting env. episode 853, reward total was -19.0. running mean: -20.203096129000887, timestamp: 2022-08-20 07:08:36.444837\n",
      "resetting env. episode 854, reward total was -20.0. running mean: -20.201065167710876, timestamp: 2022-08-20 07:08:38.360856\n",
      "resetting env. episode 855, reward total was -21.0. running mean: -20.209054516033767, timestamp: 2022-08-20 07:08:39.967877\n",
      "resetting env. episode 856, reward total was -21.0. running mean: -20.21696397087343, timestamp: 2022-08-20 07:08:41.119891\n",
      "resetting env. episode 857, reward total was -19.0. running mean: -20.204794331164695, timestamp: 2022-08-20 07:08:43.217911\n",
      "resetting env. episode 858, reward total was -21.0. running mean: -20.21274638785305, timestamp: 2022-08-20 07:08:44.386928\n",
      "resetting env. episode 859, reward total was -20.0. running mean: -20.21061892397452, timestamp: 2022-08-20 07:08:45.908942\n",
      "resetting env. episode 860, reward total was -20.0. running mean: -20.20851273473477, timestamp: 2022-08-20 07:08:47.550961\n",
      "resetting env. episode 861, reward total was -21.0. running mean: -20.216427607387423, timestamp: 2022-08-20 07:08:48.819972\n",
      "resetting env. episode 862, reward total was -20.0. running mean: -20.21426333131355, timestamp: 2022-08-20 07:08:50.895997\n",
      "resetting env. episode 863, reward total was -21.0. running mean: -20.222120698000413, timestamp: 2022-08-20 07:08:52.416016\n",
      "resetting env. episode 864, reward total was -20.0. running mean: -20.21989949102041, timestamp: 2022-08-20 07:08:54.021037\n",
      "resetting env. episode 865, reward total was -21.0. running mean: -20.227700496110206, timestamp: 2022-08-20 07:08:55.702055\n",
      "resetting env. episode 866, reward total was -21.0. running mean: -20.235423491149103, timestamp: 2022-08-20 07:08:56.730062\n",
      "resetting env. episode 867, reward total was -21.0. running mean: -20.24306925623761, timestamp: 2022-08-20 07:08:58.158078\n",
      "resetting env. episode 868, reward total was -21.0. running mean: -20.250638563675235, timestamp: 2022-08-20 07:08:59.738096\n",
      "resetting env. episode 869, reward total was -19.0. running mean: -20.238132178038484, timestamp: 2022-08-20 07:09:01.552118\n",
      "resetting env. episode 870, reward total was -21.0. running mean: -20.2457508562581, timestamp: 2022-08-20 07:09:02.995133\n",
      "resetting env. episode 871, reward total was -21.0. running mean: -20.253293347695518, timestamp: 2022-08-20 07:09:04.315149\n",
      "resetting env. episode 872, reward total was -19.0. running mean: -20.240760414218563, timestamp: 2022-08-20 07:09:06.806177\n",
      "resetting env. episode 873, reward total was -21.0. running mean: -20.24835281007638, timestamp: 2022-08-20 07:09:08.971203\n",
      "resetting env. episode 874, reward total was -21.0. running mean: -20.255869281975617, timestamp: 2022-08-20 07:09:10.274218\n",
      "resetting env. episode 875, reward total was -19.0. running mean: -20.24331058915586, timestamp: 2022-08-20 07:09:11.742237\n",
      "resetting env. episode 876, reward total was -21.0. running mean: -20.250877483264304, timestamp: 2022-08-20 07:09:13.082252\n",
      "resetting env. episode 877, reward total was -20.0. running mean: -20.24836870843166, timestamp: 2022-08-20 07:09:14.304260\n",
      "resetting env. episode 878, reward total was -21.0. running mean: -20.255885021347343, timestamp: 2022-08-20 07:09:16.124283\n",
      "resetting env. episode 879, reward total was -21.0. running mean: -20.26332617113387, timestamp: 2022-08-20 07:09:17.163291\n",
      "resetting env. episode 880, reward total was -21.0. running mean: -20.270692909422532, timestamp: 2022-08-20 07:09:19.035315\n",
      "resetting env. episode 881, reward total was -21.0. running mean: -20.277985980328307, timestamp: 2022-08-20 07:09:20.995334\n",
      "resetting env. episode 882, reward total was -21.0. running mean: -20.285206120525025, timestamp: 2022-08-20 07:09:22.290352\n",
      "resetting env. episode 883, reward total was -21.0. running mean: -20.292354059319777, timestamp: 2022-08-20 07:09:23.877370\n",
      "resetting env. episode 884, reward total was -21.0. running mean: -20.29943051872658, timestamp: 2022-08-20 07:09:25.784392\n",
      "resetting env. episode 885, reward total was -19.0. running mean: -20.286436213539318, timestamp: 2022-08-20 07:09:28.019414\n",
      "resetting env. episode 886, reward total was -21.0. running mean: -20.293571851403925, timestamp: 2022-08-20 07:09:29.066425\n",
      "resetting env. episode 887, reward total was -21.0. running mean: -20.30063613288989, timestamp: 2022-08-20 07:09:30.297441\n",
      "resetting env. episode 888, reward total was -19.0. running mean: -20.28762977156099, timestamp: 2022-08-20 07:09:31.792456\n",
      "resetting env. episode 889, reward total was -20.0. running mean: -20.28475347384538, timestamp: 2022-08-20 07:09:33.574477\n",
      "resetting env. episode 890, reward total was -21.0. running mean: -20.29190593910693, timestamp: 2022-08-20 07:09:34.635490\n",
      "resetting env. episode 891, reward total was -21.0. running mean: -20.29898687971586, timestamp: 2022-08-20 07:09:35.901504\n",
      "resetting env. episode 892, reward total was -21.0. running mean: -20.305997010918702, timestamp: 2022-08-20 07:09:37.324517\n",
      "resetting env. episode 893, reward total was -20.0. running mean: -20.302937040809514, timestamp: 2022-08-20 07:09:38.825536\n",
      "resetting env. episode 894, reward total was -21.0. running mean: -20.30990767040142, timestamp: 2022-08-20 07:09:40.424555\n",
      "resetting env. episode 895, reward total was -21.0. running mean: -20.316808593697406, timestamp: 2022-08-20 07:09:42.525577\n",
      "resetting env. episode 896, reward total was -21.0. running mean: -20.323640507760434, timestamp: 2022-08-20 07:09:44.009593\n",
      "resetting env. episode 897, reward total was -21.0. running mean: -20.33040410268283, timestamp: 2022-08-20 07:09:45.115606\n",
      "resetting env. episode 898, reward total was -21.0. running mean: -20.337100061656002, timestamp: 2022-08-20 07:09:46.788623\n",
      "resetting env. episode 899, reward total was -20.0. running mean: -20.333729061039442, timestamp: 2022-08-20 07:09:48.074639\n",
      "resetting env. episode 900, reward total was -20.0. running mean: -20.330391770429046, timestamp: 2022-08-20 07:09:49.651658\n",
      "resetting env. episode 901, reward total was -21.0. running mean: -20.337087852724757, timestamp: 2022-08-20 07:09:51.321676\n",
      "resetting env. episode 902, reward total was -20.0. running mean: -20.333716974197507, timestamp: 2022-08-20 07:09:53.089698\n",
      "resetting env. episode 903, reward total was -19.0. running mean: -20.320379804455534, timestamp: 2022-08-20 07:09:54.414713\n",
      "resetting env. episode 904, reward total was -21.0. running mean: -20.32717600641098, timestamp: 2022-08-20 07:09:56.165729\n",
      "resetting env. episode 905, reward total was -21.0. running mean: -20.333904246346872, timestamp: 2022-08-20 07:09:57.529746\n",
      "resetting env. episode 906, reward total was -21.0. running mean: -20.340565203883404, timestamp: 2022-08-20 07:09:58.808759\n",
      "resetting env. episode 907, reward total was -21.0. running mean: -20.34715955184457, timestamp: 2022-08-20 07:09:59.915773\n",
      "resetting env. episode 908, reward total was -21.0. running mean: -20.353687956326123, timestamp: 2022-08-20 07:10:01.708792\n",
      "resetting env. episode 909, reward total was -20.0. running mean: -20.35015107676286, timestamp: 2022-08-20 07:10:03.124809\n",
      "resetting env. episode 910, reward total was -21.0. running mean: -20.35664956599523, timestamp: 2022-08-20 07:10:04.483823\n",
      "resetting env. episode 911, reward total was -21.0. running mean: -20.36308307033528, timestamp: 2022-08-20 07:10:05.782839\n",
      "resetting env. episode 912, reward total was -21.0. running mean: -20.369452239631926, timestamp: 2022-08-20 07:10:06.954852\n",
      "resetting env. episode 913, reward total was -21.0. running mean: -20.375757717235608, timestamp: 2022-08-20 07:10:08.660869\n",
      "resetting env. episode 914, reward total was -21.0. running mean: -20.38200014006325, timestamp: 2022-08-20 07:10:09.874883\n",
      "resetting env. episode 915, reward total was -20.0. running mean: -20.378180138662618, timestamp: 2022-08-20 07:10:11.185899\n",
      "resetting env. episode 916, reward total was -21.0. running mean: -20.384398337275993, timestamp: 2022-08-20 07:10:12.849918\n",
      "resetting env. episode 917, reward total was -20.0. running mean: -20.380554353903232, timestamp: 2022-08-20 07:10:14.233937\n",
      "resetting env. episode 918, reward total was -21.0. running mean: -20.3867488103642, timestamp: 2022-08-20 07:10:15.440951\n",
      "resetting env. episode 919, reward total was -20.0. running mean: -20.382881322260555, timestamp: 2022-08-20 07:10:16.817963\n",
      "resetting env. episode 920, reward total was -20.0. running mean: -20.379052509037948, timestamp: 2022-08-20 07:10:18.275980\n",
      "resetting env. episode 921, reward total was -21.0. running mean: -20.38526198394757, timestamp: 2022-08-20 07:10:19.781996\n",
      "resetting env. episode 922, reward total was -21.0. running mean: -20.391409364108092, timestamp: 2022-08-20 07:10:21.096011\n",
      "resetting env. episode 923, reward total was -21.0. running mean: -20.39749527046701, timestamp: 2022-08-20 07:10:22.509025\n",
      "resetting env. episode 924, reward total was -21.0. running mean: -20.403520317762343, timestamp: 2022-08-20 07:10:23.780038\n",
      "resetting env. episode 925, reward total was -21.0. running mean: -20.40948511458472, timestamp: 2022-08-20 07:10:25.358056\n",
      "resetting env. episode 926, reward total was -21.0. running mean: -20.415390263438873, timestamp: 2022-08-20 07:10:26.699073\n",
      "resetting env. episode 927, reward total was -21.0. running mean: -20.421236360804485, timestamp: 2022-08-20 07:10:28.890095\n",
      "resetting env. episode 928, reward total was -21.0. running mean: -20.427023997196443, timestamp: 2022-08-20 07:10:30.098109\n",
      "resetting env. episode 929, reward total was -21.0. running mean: -20.43275375722448, timestamp: 2022-08-20 07:10:31.363124\n",
      "resetting env. episode 930, reward total was -20.0. running mean: -20.428426219652234, timestamp: 2022-08-20 07:10:32.715137\n",
      "resetting env. episode 931, reward total was -21.0. running mean: -20.43414195745571, timestamp: 2022-08-20 07:10:34.118154\n",
      "resetting env. episode 932, reward total was -20.0. running mean: -20.429800537881153, timestamp: 2022-08-20 07:10:35.283170\n",
      "resetting env. episode 933, reward total was -21.0. running mean: -20.43550253250234, timestamp: 2022-08-20 07:10:36.850187\n",
      "resetting env. episode 934, reward total was -21.0. running mean: -20.441147507177316, timestamp: 2022-08-20 07:10:37.980199\n",
      "resetting env. episode 935, reward total was -19.0. running mean: -20.426736032105545, timestamp: 2022-08-20 07:10:39.441216\n",
      "resetting env. episode 936, reward total was -21.0. running mean: -20.43246867178449, timestamp: 2022-08-20 07:10:40.468230\n",
      "resetting env. episode 937, reward total was -21.0. running mean: -20.438143985066645, timestamp: 2022-08-20 07:10:41.743241\n",
      "resetting env. episode 938, reward total was -21.0. running mean: -20.44376254521598, timestamp: 2022-08-20 07:10:43.005257\n",
      "resetting env. episode 939, reward total was -21.0. running mean: -20.449324919763818, timestamp: 2022-08-20 07:10:44.943280\n",
      "resetting env. episode 940, reward total was -21.0. running mean: -20.45483167056618, timestamp: 2022-08-20 07:10:46.617293\n",
      "resetting env. episode 941, reward total was -21.0. running mean: -20.460283353860518, timestamp: 2022-08-20 07:10:47.719307\n",
      "resetting env. episode 942, reward total was -19.0. running mean: -20.445680520321915, timestamp: 2022-08-20 07:10:49.547328\n",
      "resetting env. episode 943, reward total was -21.0. running mean: -20.451223715118697, timestamp: 2022-08-20 07:10:51.472353\n",
      "resetting env. episode 944, reward total was -21.0. running mean: -20.45671147796751, timestamp: 2022-08-20 07:10:52.572361\n",
      "resetting env. episode 945, reward total was -21.0. running mean: -20.462144363187836, timestamp: 2022-08-20 07:10:54.067381\n",
      "resetting env. episode 946, reward total was -21.0. running mean: -20.467522919555957, timestamp: 2022-08-20 07:10:55.664397\n",
      "resetting env. episode 947, reward total was -21.0. running mean: -20.4728476903604, timestamp: 2022-08-20 07:10:57.009415\n",
      "resetting env. episode 948, reward total was -21.0. running mean: -20.478119213456797, timestamp: 2022-08-20 07:10:58.463436\n",
      "resetting env. episode 949, reward total was -21.0. running mean: -20.48333802132223, timestamp: 2022-08-20 07:11:00.038445\n",
      "resetting env. episode 950, reward total was -19.0. running mean: -20.468504641109007, timestamp: 2022-08-20 07:11:02.269468\n",
      "resetting env. episode 951, reward total was -20.0. running mean: -20.463819594697917, timestamp: 2022-08-20 07:11:03.395488\n",
      "resetting env. episode 952, reward total was -21.0. running mean: -20.469181398750937, timestamp: 2022-08-20 07:11:04.657498\n",
      "resetting env. episode 953, reward total was -21.0. running mean: -20.47448958476343, timestamp: 2022-08-20 07:11:05.708511\n",
      "resetting env. episode 954, reward total was -21.0. running mean: -20.479744688915794, timestamp: 2022-08-20 07:11:07.274526\n",
      "resetting env. episode 955, reward total was -20.0. running mean: -20.474947242026634, timestamp: 2022-08-20 07:11:10.019558\n",
      "resetting env. episode 956, reward total was -21.0. running mean: -20.480197769606367, timestamp: 2022-08-20 07:11:11.354574\n",
      "resetting env. episode 957, reward total was -21.0. running mean: -20.485395791910303, timestamp: 2022-08-20 07:11:12.580586\n",
      "resetting env. episode 958, reward total was -19.0. running mean: -20.470541833991202, timestamp: 2022-08-20 07:11:14.274603\n",
      "resetting env. episode 959, reward total was -20.0. running mean: -20.46583641565129, timestamp: 2022-08-20 07:11:16.189628\n",
      "resetting env. episode 960, reward total was -21.0. running mean: -20.47117805149478, timestamp: 2022-08-20 07:11:17.956644\n",
      "resetting env. episode 961, reward total was -20.0. running mean: -20.46646627097983, timestamp: 2022-08-20 07:11:20.518675\n",
      "resetting env. episode 962, reward total was -21.0. running mean: -20.47180160827003, timestamp: 2022-08-20 07:11:22.422694\n",
      "resetting env. episode 963, reward total was -20.0. running mean: -20.46708359218733, timestamp: 2022-08-20 07:11:23.600708\n",
      "resetting env. episode 964, reward total was -21.0. running mean: -20.472412756265456, timestamp: 2022-08-20 07:11:25.512259\n",
      "resetting env. episode 965, reward total was -21.0. running mean: -20.4776886287028, timestamp: 2022-08-20 07:11:27.152276\n",
      "resetting env. episode 966, reward total was -21.0. running mean: -20.482911742415773, timestamp: 2022-08-20 07:11:28.282289\n",
      "resetting env. episode 967, reward total was -21.0. running mean: -20.488082624991616, timestamp: 2022-08-20 07:11:30.442312\n",
      "resetting env. episode 968, reward total was -21.0. running mean: -20.4932017987417, timestamp: 2022-08-20 07:11:31.601326\n",
      "resetting env. episode 969, reward total was -21.0. running mean: -20.498269780754285, timestamp: 2022-08-20 07:11:32.834340\n",
      "resetting env. episode 970, reward total was -21.0. running mean: -20.50328708294674, timestamp: 2022-08-20 07:11:34.429359\n",
      "resetting env. episode 971, reward total was -21.0. running mean: -20.508254212117276, timestamp: 2022-08-20 07:11:35.499373\n",
      "resetting env. episode 972, reward total was -21.0. running mean: -20.513171669996105, timestamp: 2022-08-20 07:11:36.713386\n",
      "resetting env. episode 973, reward total was -21.0. running mean: -20.518039953296146, timestamp: 2022-08-20 07:11:37.862396\n",
      "resetting env. episode 974, reward total was -21.0. running mean: -20.522859553763187, timestamp: 2022-08-20 07:11:38.995411\n",
      "resetting env. episode 975, reward total was -21.0. running mean: -20.527630958225554, timestamp: 2022-08-20 07:11:40.756427\n",
      "resetting env. episode 976, reward total was -21.0. running mean: -20.5323546486433, timestamp: 2022-08-20 07:11:43.278460\n",
      "resetting env. episode 977, reward total was -21.0. running mean: -20.537031102156867, timestamp: 2022-08-20 07:11:44.962480\n",
      "resetting env. episode 978, reward total was -21.0. running mean: -20.5416607911353, timestamp: 2022-08-20 07:11:46.166489\n",
      "resetting env. episode 979, reward total was -20.0. running mean: -20.536244183223946, timestamp: 2022-08-20 07:11:47.481502\n",
      "resetting env. episode 980, reward total was -21.0. running mean: -20.540881741391708, timestamp: 2022-08-20 07:11:49.513528\n",
      "resetting env. episode 981, reward total was -21.0. running mean: -20.54547292397779, timestamp: 2022-08-20 07:11:50.646544\n",
      "resetting env. episode 982, reward total was -21.0. running mean: -20.550018194738012, timestamp: 2022-08-20 07:11:51.721556\n",
      "resetting env. episode 983, reward total was -21.0. running mean: -20.554518012790634, timestamp: 2022-08-20 07:11:53.271572\n",
      "resetting env. episode 984, reward total was -21.0. running mean: -20.55897283266273, timestamp: 2022-08-20 07:11:54.540586\n",
      "resetting env. episode 985, reward total was -20.0. running mean: -20.5533831043361, timestamp: 2022-08-20 07:11:56.307607\n",
      "resetting env. episode 986, reward total was -20.0. running mean: -20.547849273292737, timestamp: 2022-08-20 07:11:58.191623\n",
      "resetting env. episode 987, reward total was -20.0. running mean: -20.54237078055981, timestamp: 2022-08-20 07:11:59.372639\n",
      "resetting env. episode 988, reward total was -20.0. running mean: -20.536947072754213, timestamp: 2022-08-20 07:12:00.886653\n",
      "resetting env. episode 989, reward total was -21.0. running mean: -20.54157760202667, timestamp: 2022-08-20 07:12:03.272685\n",
      "resetting env. episode 990, reward total was -21.0. running mean: -20.546161826006404, timestamp: 2022-08-20 07:12:04.662700\n",
      "resetting env. episode 991, reward total was -21.0. running mean: -20.550700207746342, timestamp: 2022-08-20 07:12:06.075717\n",
      "resetting env. episode 992, reward total was -21.0. running mean: -20.55519320566888, timestamp: 2022-08-20 07:12:07.899731\n",
      "resetting env. episode 993, reward total was -21.0. running mean: -20.55964127361219, timestamp: 2022-08-20 07:12:08.948744\n",
      "resetting env. episode 994, reward total was -21.0. running mean: -20.56404486087607, timestamp: 2022-08-20 07:12:10.626765\n",
      "resetting env. episode 995, reward total was -21.0. running mean: -20.56840441226731, timestamp: 2022-08-20 07:12:11.837779\n",
      "resetting env. episode 996, reward total was -19.0. running mean: -20.552720368144637, timestamp: 2022-08-20 07:12:13.370325\n",
      "resetting env. episode 997, reward total was -21.0. running mean: -20.557193164463193, timestamp: 2022-08-20 07:12:15.327344\n",
      "resetting env. episode 998, reward total was -21.0. running mean: -20.561621232818563, timestamp: 2022-08-20 07:12:16.519357\n",
      "resetting env. episode 999, reward total was -21.0. running mean: -20.56600502049038, timestamp: 2022-08-20 07:12:17.947373\n",
      "resetting env. episode 1000, reward total was -21.0. running mean: -20.570344970285475, timestamp: 2022-08-20 07:12:19.081387\n",
      "resetting env. episode 1001, reward total was -21.0. running mean: -20.57464152058262, timestamp: 2022-08-20 07:12:20.586405\n",
      "resetting env. episode 1002, reward total was -21.0. running mean: -20.578895105376795, timestamp: 2022-08-20 07:12:21.657416\n",
      "resetting env. episode 1003, reward total was -21.0. running mean: -20.583106154323026, timestamp: 2022-08-20 07:12:23.263431\n",
      "resetting env. episode 1004, reward total was -21.0. running mean: -20.587275092779798, timestamp: 2022-08-20 07:12:24.944453\n",
      "resetting env. episode 1005, reward total was -21.0. running mean: -20.591402341852, timestamp: 2022-08-20 07:12:26.009474\n",
      "resetting env. episode 1006, reward total was -21.0. running mean: -20.595488318433482, timestamp: 2022-08-20 07:12:27.355481\n",
      "resetting env. episode 1007, reward total was -21.0. running mean: -20.599533435249146, timestamp: 2022-08-20 07:12:28.455495\n",
      "resetting env. episode 1008, reward total was -21.0. running mean: -20.603538100896657, timestamp: 2022-08-20 07:12:29.901509\n",
      "resetting env. episode 1009, reward total was -21.0. running mean: -20.60750271988769, timestamp: 2022-08-20 07:12:31.551527\n",
      "resetting env. episode 1010, reward total was -21.0. running mean: -20.611427692688814, timestamp: 2022-08-20 07:12:32.922543\n",
      "resetting env. episode 1011, reward total was -21.0. running mean: -20.615313415761925, timestamp: 2022-08-20 07:12:34.068554\n",
      "resetting env. episode 1012, reward total was -21.0. running mean: -20.619160281604305, timestamp: 2022-08-20 07:12:35.642571\n",
      "resetting env. episode 1013, reward total was -20.0. running mean: -20.61296867878826, timestamp: 2022-08-20 07:12:36.731585\n",
      "resetting env. episode 1014, reward total was -20.0. running mean: -20.606838992000377, timestamp: 2022-08-20 07:12:38.510604\n",
      "resetting env. episode 1015, reward total was -21.0. running mean: -20.610770602080375, timestamp: 2022-08-20 07:12:40.368630\n",
      "resetting env. episode 1016, reward total was -21.0. running mean: -20.61466289605957, timestamp: 2022-08-20 07:12:41.573639\n",
      "resetting env. episode 1017, reward total was -21.0. running mean: -20.618516267098975, timestamp: 2022-08-20 07:12:43.090657\n",
      "resetting env. episode 1018, reward total was -21.0. running mean: -20.622331104427985, timestamp: 2022-08-20 07:12:44.131672\n",
      "resetting env. episode 1019, reward total was -21.0. running mean: -20.626107793383706, timestamp: 2022-08-20 07:12:45.797689\n",
      "resetting env. episode 1020, reward total was -21.0. running mean: -20.62984671544987, timestamp: 2022-08-20 07:12:46.854697\n",
      "resetting env. episode 1021, reward total was -21.0. running mean: -20.63354824829537, timestamp: 2022-08-20 07:12:48.350717\n",
      "resetting env. episode 1022, reward total was -21.0. running mean: -20.637212765812418, timestamp: 2022-08-20 07:12:49.469732\n",
      "resetting env. episode 1023, reward total was -21.0. running mean: -20.640840638154295, timestamp: 2022-08-20 07:12:52.275762\n",
      "resetting env. episode 1024, reward total was -20.0. running mean: -20.634432231772752, timestamp: 2022-08-20 07:12:53.540774\n",
      "resetting env. episode 1025, reward total was -21.0. running mean: -20.638087909455024, timestamp: 2022-08-20 07:12:54.580788\n",
      "resetting env. episode 1026, reward total was -21.0. running mean: -20.641707030360475, timestamp: 2022-08-20 07:12:55.840801\n",
      "resetting env. episode 1027, reward total was -21.0. running mean: -20.64528996005687, timestamp: 2022-08-20 07:12:57.118813\n",
      "resetting env. episode 1028, reward total was -20.0. running mean: -20.6388370604563, timestamp: 2022-08-20 07:12:58.740835\n",
      "resetting env. episode 1029, reward total was -21.0. running mean: -20.642448689851737, timestamp: 2022-08-20 07:13:00.788855\n",
      "resetting env. episode 1030, reward total was -20.0. running mean: -20.63602420295322, timestamp: 2022-08-20 07:13:02.357876\n",
      "resetting env. episode 1031, reward total was -21.0. running mean: -20.639663960923688, timestamp: 2022-08-20 07:13:03.758892\n",
      "resetting env. episode 1032, reward total was -21.0. running mean: -20.64326732131445, timestamp: 2022-08-20 07:13:05.357910\n",
      "resetting env. episode 1033, reward total was -21.0. running mean: -20.646834648101308, timestamp: 2022-08-20 07:13:06.573923\n",
      "resetting env. episode 1034, reward total was -21.0. running mean: -20.650366301620295, timestamp: 2022-08-20 07:13:07.796938\n",
      "resetting env. episode 1035, reward total was -20.0. running mean: -20.64386263860409, timestamp: 2022-08-20 07:13:09.023948\n",
      "resetting env. episode 1036, reward total was -21.0. running mean: -20.64742401221805, timestamp: 2022-08-20 07:13:10.791968\n",
      "resetting env. episode 1037, reward total was -21.0. running mean: -20.65094977209587, timestamp: 2022-08-20 07:13:11.917981\n",
      "resetting env. episode 1038, reward total was -21.0. running mean: -20.654440274374913, timestamp: 2022-08-20 07:13:13.505003\n",
      "resetting env. episode 1039, reward total was -21.0. running mean: -20.657895871631165, timestamp: 2022-08-20 07:13:14.743014\n",
      "resetting env. episode 1040, reward total was -21.0. running mean: -20.661316912914856, timestamp: 2022-08-20 07:13:16.263029\n",
      "resetting env. episode 1041, reward total was -20.0. running mean: -20.654703743785706, timestamp: 2022-08-20 07:13:17.942052\n",
      "resetting env. episode 1042, reward total was -21.0. running mean: -20.65815670634785, timestamp: 2022-08-20 07:13:19.398067\n",
      "resetting env. episode 1043, reward total was -21.0. running mean: -20.661575139284373, timestamp: 2022-08-20 07:13:20.963084\n",
      "resetting env. episode 1044, reward total was -21.0. running mean: -20.664959387891532, timestamp: 2022-08-20 07:13:22.275099\n",
      "resetting env. episode 1045, reward total was -21.0. running mean: -20.668309794012618, timestamp: 2022-08-20 07:13:23.837117\n",
      "resetting env. episode 1046, reward total was -20.0. running mean: -20.661626696072492, timestamp: 2022-08-20 07:13:24.918132\n",
      "resetting env. episode 1047, reward total was -20.0. running mean: -20.655010429111766, timestamp: 2022-08-20 07:13:26.549673\n",
      "resetting env. episode 1048, reward total was -21.0. running mean: -20.65846032482065, timestamp: 2022-08-20 07:13:27.577682\n",
      "resetting env. episode 1049, reward total was -21.0. running mean: -20.661875721572443, timestamp: 2022-08-20 07:13:29.322705\n",
      "resetting env. episode 1050, reward total was -21.0. running mean: -20.66525696435672, timestamp: 2022-08-20 07:13:30.715722\n",
      "resetting env. episode 1051, reward total was -21.0. running mean: -20.668604394713153, timestamp: 2022-08-20 07:13:32.637743\n",
      "resetting env. episode 1052, reward total was -21.0. running mean: -20.67191835076602, timestamp: 2022-08-20 07:13:34.516764\n",
      "resetting env. episode 1053, reward total was -20.0. running mean: -20.665199167258358, timestamp: 2022-08-20 07:13:35.894781\n",
      "resetting env. episode 1054, reward total was -21.0. running mean: -20.668547175585775, timestamp: 2022-08-20 07:13:37.060790\n",
      "resetting env. episode 1055, reward total was -20.0. running mean: -20.661861703829917, timestamp: 2022-08-20 07:13:38.478810\n",
      "resetting env. episode 1056, reward total was -21.0. running mean: -20.66524308679162, timestamp: 2022-08-20 07:13:39.867824\n",
      "resetting env. episode 1057, reward total was -21.0. running mean: -20.668590655923705, timestamp: 2022-08-20 07:13:41.357844\n",
      "resetting env. episode 1058, reward total was -21.0. running mean: -20.67190474936447, timestamp: 2022-08-20 07:13:42.660854\n",
      "resetting env. episode 1059, reward total was -21.0. running mean: -20.675185701870824, timestamp: 2022-08-20 07:13:44.059869\n",
      "resetting env. episode 1060, reward total was -21.0. running mean: -20.678433844852115, timestamp: 2022-08-20 07:13:45.616889\n",
      "resetting env. episode 1061, reward total was -20.0. running mean: -20.671649506403593, timestamp: 2022-08-20 07:13:47.034904\n",
      "resetting env. episode 1062, reward total was -20.0. running mean: -20.664933011339556, timestamp: 2022-08-20 07:13:48.623925\n",
      "resetting env. episode 1063, reward total was -21.0. running mean: -20.66828368122616, timestamp: 2022-08-20 07:13:49.832941\n",
      "resetting env. episode 1064, reward total was -21.0. running mean: -20.6716008444139, timestamp: 2022-08-20 07:13:51.513958\n",
      "resetting env. episode 1065, reward total was -21.0. running mean: -20.67488483596976, timestamp: 2022-08-20 07:13:52.640980\n",
      "resetting env. episode 1066, reward total was -21.0. running mean: -20.678135987610062, timestamp: 2022-08-20 07:13:54.415997\n",
      "resetting env. episode 1067, reward total was -21.0. running mean: -20.681354627733963, timestamp: 2022-08-20 07:13:55.449005\n",
      "resetting env. episode 1068, reward total was -21.0. running mean: -20.684541081456626, timestamp: 2022-08-20 07:13:56.857027\n",
      "resetting env. episode 1069, reward total was -21.0. running mean: -20.68769567064206, timestamp: 2022-08-20 07:13:58.115033\n",
      "resetting env. episode 1070, reward total was -21.0. running mean: -20.69081871393564, timestamp: 2022-08-20 07:13:59.629051\n",
      "resetting env. episode 1071, reward total was -20.0. running mean: -20.683910526796286, timestamp: 2022-08-20 07:14:01.109067\n",
      "resetting env. episode 1072, reward total was -21.0. running mean: -20.687071421528323, timestamp: 2022-08-20 07:14:02.249082\n",
      "resetting env. episode 1073, reward total was -21.0. running mean: -20.69020070731304, timestamp: 2022-08-20 07:14:03.284095\n",
      "resetting env. episode 1074, reward total was -21.0. running mean: -20.69329870023991, timestamp: 2022-08-20 07:14:05.394115\n",
      "resetting env. episode 1075, reward total was -21.0. running mean: -20.696365713237512, timestamp: 2022-08-20 07:14:07.438141\n",
      "resetting env. episode 1076, reward total was -21.0. running mean: -20.699402056105136, timestamp: 2022-08-20 07:14:08.706158\n",
      "resetting env. episode 1077, reward total was -21.0. running mean: -20.702408035544085, timestamp: 2022-08-20 07:14:10.099170\n",
      "resetting env. episode 1078, reward total was -21.0. running mean: -20.705383955188644, timestamp: 2022-08-20 07:14:11.701188\n",
      "resetting env. episode 1079, reward total was -21.0. running mean: -20.70833011563676, timestamp: 2022-08-20 07:14:12.881202\n",
      "resetting env. episode 1080, reward total was -20.0. running mean: -20.701246814480392, timestamp: 2022-08-20 07:14:14.756225\n",
      "resetting env. episode 1081, reward total was -21.0. running mean: -20.70423434633559, timestamp: 2022-08-20 07:14:15.813238\n",
      "resetting env. episode 1082, reward total was -21.0. running mean: -20.707192002872233, timestamp: 2022-08-20 07:14:17.247252\n",
      "resetting env. episode 1083, reward total was -21.0. running mean: -20.710120082843513, timestamp: 2022-08-20 07:14:19.170277\n",
      "resetting env. episode 1084, reward total was -20.0. running mean: -20.703018882015076, timestamp: 2022-08-20 07:14:20.399292\n",
      "resetting env. episode 1085, reward total was -21.0. running mean: -20.705988693194925, timestamp: 2022-08-20 07:14:21.821304\n",
      "resetting env. episode 1086, reward total was -21.0. running mean: -20.708928806262975, timestamp: 2022-08-20 07:14:23.235321\n",
      "resetting env. episode 1087, reward total was -21.0. running mean: -20.711839518200346, timestamp: 2022-08-20 07:14:24.517336\n",
      "resetting env. episode 1088, reward total was -20.0. running mean: -20.70472112301834, timestamp: 2022-08-20 07:14:25.750352\n",
      "resetting env. episode 1089, reward total was -21.0. running mean: -20.70767391178816, timestamp: 2022-08-20 07:14:27.441373\n",
      "resetting env. episode 1090, reward total was -21.0. running mean: -20.71059717267028, timestamp: 2022-08-20 07:14:28.708383\n",
      "resetting env. episode 1091, reward total was -21.0. running mean: -20.713491200943576, timestamp: 2022-08-20 07:14:30.045926\n",
      "resetting env. episode 1092, reward total was -21.0. running mean: -20.71635628893414, timestamp: 2022-08-20 07:14:31.417944\n",
      "resetting env. episode 1093, reward total was -21.0. running mean: -20.7191927260448, timestamp: 2022-08-20 07:14:32.847962\n",
      "resetting env. episode 1094, reward total was -20.0. running mean: -20.71200079878435, timestamp: 2022-08-20 07:14:34.232978\n",
      "resetting env. episode 1095, reward total was -21.0. running mean: -20.714880790796506, timestamp: 2022-08-20 07:14:35.277989\n",
      "resetting env. episode 1096, reward total was -20.0. running mean: -20.70773198288854, timestamp: 2022-08-20 07:14:36.984008\n",
      "resetting env. episode 1097, reward total was -21.0. running mean: -20.710654663059653, timestamp: 2022-08-20 07:14:38.115023\n",
      "resetting env. episode 1098, reward total was -21.0. running mean: -20.713548116429056, timestamp: 2022-08-20 07:14:39.436033\n",
      "resetting env. episode 1099, reward total was -21.0. running mean: -20.716412635264767, timestamp: 2022-08-20 07:14:40.560049\n",
      "resetting env. episode 1100, reward total was -21.0. running mean: -20.71924850891212, timestamp: 2022-08-20 07:14:41.874063\n",
      "resetting env. episode 1101, reward total was -21.0. running mean: -20.722056023823, timestamp: 2022-08-20 07:14:43.083076\n",
      "resetting env. episode 1102, reward total was -21.0. running mean: -20.72483546358477, timestamp: 2022-08-20 07:14:44.663094\n",
      "resetting env. episode 1103, reward total was -21.0. running mean: -20.727587108948924, timestamp: 2022-08-20 07:14:45.775108\n",
      "resetting env. episode 1104, reward total was -21.0. running mean: -20.730311237859436, timestamp: 2022-08-20 07:14:47.242123\n",
      "resetting env. episode 1105, reward total was -20.0. running mean: -20.723008125480842, timestamp: 2022-08-20 07:14:48.343139\n",
      "resetting env. episode 1106, reward total was -21.0. running mean: -20.725778044226033, timestamp: 2022-08-20 07:14:49.960155\n",
      "resetting env. episode 1107, reward total was -21.0. running mean: -20.72852026378377, timestamp: 2022-08-20 07:14:51.041167\n",
      "resetting env. episode 1108, reward total was -21.0. running mean: -20.731235061145934, timestamp: 2022-08-20 07:14:52.479184\n",
      "resetting env. episode 1109, reward total was -21.0. running mean: -20.733922710534475, timestamp: 2022-08-20 07:14:53.944203\n",
      "resetting env. episode 1110, reward total was -21.0. running mean: -20.736583483429133, timestamp: 2022-08-20 07:14:55.643224\n",
      "resetting env. episode 1111, reward total was -21.0. running mean: -20.739217648594842, timestamp: 2022-08-20 07:14:56.911240\n",
      "resetting env. episode 1112, reward total was -21.0. running mean: -20.741825472108893, timestamp: 2022-08-20 07:14:57.942250\n",
      "resetting env. episode 1113, reward total was -21.0. running mean: -20.744407217387806, timestamp: 2022-08-20 07:14:59.207260\n",
      "resetting env. episode 1114, reward total was -21.0. running mean: -20.74696314521393, timestamp: 2022-08-20 07:15:00.976281\n",
      "resetting env. episode 1115, reward total was -21.0. running mean: -20.74949351376179, timestamp: 2022-08-20 07:15:02.599300\n",
      "resetting env. episode 1116, reward total was -21.0. running mean: -20.751998578624175, timestamp: 2022-08-20 07:15:03.628313\n",
      "resetting env. episode 1117, reward total was -21.0. running mean: -20.754478592837934, timestamp: 2022-08-20 07:15:05.111333\n",
      "resetting env. episode 1118, reward total was -20.0. running mean: -20.746933806909553, timestamp: 2022-08-20 07:15:06.190344\n",
      "resetting env. episode 1119, reward total was -20.0. running mean: -20.739464468840456, timestamp: 2022-08-20 07:15:07.776360\n",
      "resetting env. episode 1120, reward total was -21.0. running mean: -20.74206982415205, timestamp: 2022-08-20 07:15:08.975375\n",
      "resetting env. episode 1121, reward total was -21.0. running mean: -20.74464912591053, timestamp: 2022-08-20 07:15:10.246391\n",
      "resetting env. episode 1122, reward total was -21.0. running mean: -20.747202634651426, timestamp: 2022-08-20 07:15:11.394405\n",
      "resetting env. episode 1123, reward total was -21.0. running mean: -20.749730608304912, timestamp: 2022-08-20 07:15:14.398439\n",
      "resetting env. episode 1124, reward total was -21.0. running mean: -20.752233302221864, timestamp: 2022-08-20 07:15:15.956452\n",
      "resetting env. episode 1125, reward total was -20.0. running mean: -20.744710969199645, timestamp: 2022-08-20 07:15:17.304470\n",
      "resetting env. episode 1126, reward total was -21.0. running mean: -20.747263859507648, timestamp: 2022-08-20 07:15:18.452483\n",
      "resetting env. episode 1127, reward total was -20.0. running mean: -20.73979122091257, timestamp: 2022-08-20 07:15:20.334504\n",
      "resetting env. episode 1128, reward total was -19.0. running mean: -20.722393308703445, timestamp: 2022-08-20 07:15:21.975529\n",
      "resetting env. episode 1129, reward total was -21.0. running mean: -20.72516937561641, timestamp: 2022-08-20 07:15:23.251538\n",
      "resetting env. episode 1130, reward total was -21.0. running mean: -20.727917681860248, timestamp: 2022-08-20 07:15:24.728554\n",
      "resetting env. episode 1131, reward total was -20.0. running mean: -20.720638505041645, timestamp: 2022-08-20 07:15:25.890571\n",
      "resetting env. episode 1132, reward total was -21.0. running mean: -20.72343211999123, timestamp: 2022-08-20 07:15:27.245584\n",
      "resetting env. episode 1133, reward total was -21.0. running mean: -20.72619779879132, timestamp: 2022-08-20 07:15:28.443597\n",
      "resetting env. episode 1134, reward total was -21.0. running mean: -20.728935820803407, timestamp: 2022-08-20 07:15:30.307618\n",
      "resetting env. episode 1135, reward total was -21.0. running mean: -20.731646462595375, timestamp: 2022-08-20 07:15:31.776637\n",
      "resetting env. episode 1136, reward total was -21.0. running mean: -20.73432999796942, timestamp: 2022-08-20 07:15:33.037653\n",
      "resetting env. episode 1137, reward total was -21.0. running mean: -20.736986697989728, timestamp: 2022-08-20 07:15:34.775671\n",
      "resetting env. episode 1138, reward total was -21.0. running mean: -20.739616831009833, timestamp: 2022-08-20 07:15:36.030686\n",
      "resetting env. episode 1139, reward total was -21.0. running mean: -20.742220662699737, timestamp: 2022-08-20 07:15:37.407702\n",
      "resetting env. episode 1140, reward total was -21.0. running mean: -20.74479845607274, timestamp: 2022-08-20 07:15:38.477714\n",
      "resetting env. episode 1141, reward total was -19.0. running mean: -20.727350471512015, timestamp: 2022-08-20 07:15:41.187749\n",
      "resetting env. episode 1142, reward total was -21.0. running mean: -20.730076966796894, timestamp: 2022-08-20 07:15:42.517760\n",
      "resetting env. episode 1143, reward total was -20.0. running mean: -20.722776197128923, timestamp: 2022-08-20 07:15:43.838774\n",
      "resetting env. episode 1144, reward total was -21.0. running mean: -20.725548435157634, timestamp: 2022-08-20 07:15:45.522795\n",
      "resetting env. episode 1145, reward total was -21.0. running mean: -20.728292950806058, timestamp: 2022-08-20 07:15:46.949813\n",
      "resetting env. episode 1146, reward total was -21.0. running mean: -20.731010021297998, timestamp: 2022-08-20 07:15:48.164830\n",
      "resetting env. episode 1147, reward total was -21.0. running mean: -20.73369992108502, timestamp: 2022-08-20 07:15:49.317840\n",
      "resetting env. episode 1148, reward total was -21.0. running mean: -20.73636292187417, timestamp: 2022-08-20 07:15:50.528852\n",
      "resetting env. episode 1149, reward total was -21.0. running mean: -20.738999292655432, timestamp: 2022-08-20 07:15:52.497873\n",
      "resetting env. episode 1150, reward total was -21.0. running mean: -20.74160929972888, timestamp: 2022-08-20 07:15:53.769892\n",
      "resetting env. episode 1151, reward total was -21.0. running mean: -20.74419320673159, timestamp: 2022-08-20 07:15:55.122904\n",
      "resetting env. episode 1152, reward total was -21.0. running mean: -20.746751274664277, timestamp: 2022-08-20 07:15:56.222920\n",
      "resetting env. episode 1153, reward total was -19.0. running mean: -20.729283761917635, timestamp: 2022-08-20 07:15:58.036939\n",
      "resetting env. episode 1154, reward total was -20.0. running mean: -20.721990924298456, timestamp: 2022-08-20 07:15:59.216956\n",
      "resetting env. episode 1155, reward total was -21.0. running mean: -20.724771015055474, timestamp: 2022-08-20 07:16:00.924976\n",
      "resetting env. episode 1156, reward total was -21.0. running mean: -20.72752330490492, timestamp: 2022-08-20 07:16:02.483002\n",
      "resetting env. episode 1157, reward total was -21.0. running mean: -20.730248071855872, timestamp: 2022-08-20 07:16:03.665006\n",
      "resetting env. episode 1158, reward total was -21.0. running mean: -20.732945591137312, timestamp: 2022-08-20 07:16:05.237019\n",
      "resetting env. episode 1159, reward total was -20.0. running mean: -20.725616135225938, timestamp: 2022-08-20 07:16:06.412033\n",
      "resetting env. episode 1160, reward total was -21.0. running mean: -20.72835997387368, timestamp: 2022-08-20 07:16:08.010053\n",
      "resetting env. episode 1161, reward total was -21.0. running mean: -20.731076374134943, timestamp: 2022-08-20 07:16:09.114065\n",
      "resetting env. episode 1162, reward total was -21.0. running mean: -20.733765610393593, timestamp: 2022-08-20 07:16:10.857089\n",
      "resetting env. episode 1163, reward total was -21.0. running mean: -20.73642795428966, timestamp: 2022-08-20 07:16:12.173102\n",
      "resetting env. episode 1164, reward total was -21.0. running mean: -20.739063674746763, timestamp: 2022-08-20 07:16:13.322124\n",
      "resetting env. episode 1165, reward total was -21.0. running mean: -20.741673037999295, timestamp: 2022-08-20 07:16:14.700134\n",
      "resetting env. episode 1166, reward total was -21.0. running mean: -20.744256307619303, timestamp: 2022-08-20 07:16:15.940145\n",
      "resetting env. episode 1167, reward total was -20.0. running mean: -20.73681374454311, timestamp: 2022-08-20 07:16:17.399160\n",
      "resetting env. episode 1168, reward total was -19.0. running mean: -20.71944560709768, timestamp: 2022-08-20 07:16:18.793185\n",
      "resetting env. episode 1169, reward total was -21.0. running mean: -20.722251151026704, timestamp: 2022-08-20 07:16:20.447201\n",
      "resetting env. episode 1170, reward total was -21.0. running mean: -20.725028639516438, timestamp: 2022-08-20 07:16:21.715211\n",
      "resetting env. episode 1171, reward total was -20.0. running mean: -20.717778353121272, timestamp: 2022-08-20 07:16:23.121227\n",
      "resetting env. episode 1172, reward total was -21.0. running mean: -20.72060056959006, timestamp: 2022-08-20 07:16:24.738249\n",
      "resetting env. episode 1173, reward total was -21.0. running mean: -20.72339456389416, timestamp: 2022-08-20 07:16:25.905265\n",
      "resetting env. episode 1174, reward total was -21.0. running mean: -20.72616061825522, timestamp: 2022-08-20 07:16:27.580280\n",
      "resetting env. episode 1175, reward total was -21.0. running mean: -20.72889901207267, timestamp: 2022-08-20 07:16:28.703292\n",
      "resetting env. episode 1176, reward total was -18.0. running mean: -20.701610021951943, timestamp: 2022-08-20 07:16:30.818318\n",
      "resetting env. episode 1177, reward total was -21.0. running mean: -20.704593921732425, timestamp: 2022-08-20 07:16:32.578338\n",
      "resetting env. episode 1178, reward total was -21.0. running mean: -20.707547982515102, timestamp: 2022-08-20 07:16:33.850354\n",
      "resetting env. episode 1179, reward total was -19.0. running mean: -20.690472502689953, timestamp: 2022-08-20 07:16:35.554373\n",
      "resetting env. episode 1180, reward total was -21.0. running mean: -20.693567777663056, timestamp: 2022-08-20 07:16:36.764387\n",
      "resetting env. episode 1181, reward total was -21.0. running mean: -20.696632099886425, timestamp: 2022-08-20 07:16:38.049400\n",
      "resetting env. episode 1182, reward total was -21.0. running mean: -20.69966577888756, timestamp: 2022-08-20 07:16:39.541420\n",
      "resetting env. episode 1183, reward total was -21.0. running mean: -20.702669121098687, timestamp: 2022-08-20 07:16:40.806432\n",
      "resetting env. episode 1184, reward total was -21.0. running mean: -20.7056424298877, timestamp: 2022-08-20 07:16:41.826443\n",
      "resetting env. episode 1185, reward total was -21.0. running mean: -20.708586005588824, timestamp: 2022-08-20 07:16:43.100459\n",
      "resetting env. episode 1186, reward total was -21.0. running mean: -20.711500145532938, timestamp: 2022-08-20 07:16:44.335483\n",
      "resetting env. episode 1187, reward total was -20.0. running mean: -20.70438514407761, timestamp: 2022-08-20 07:16:45.761490\n",
      "resetting env. episode 1188, reward total was -20.0. running mean: -20.697341292636832, timestamp: 2022-08-20 07:16:47.831512\n",
      "resetting env. episode 1189, reward total was -21.0. running mean: -20.700367879710463, timestamp: 2022-08-20 07:16:50.337547\n",
      "resetting env. episode 1190, reward total was -21.0. running mean: -20.70336420091336, timestamp: 2022-08-20 07:16:51.499558\n",
      "resetting env. episode 1191, reward total was -19.0. running mean: -20.686330558904228, timestamp: 2022-08-20 07:16:53.005578\n",
      "resetting env. episode 1192, reward total was -21.0. running mean: -20.689467253315186, timestamp: 2022-08-20 07:16:54.186588\n",
      "resetting env. episode 1193, reward total was -21.0. running mean: -20.692572580782034, timestamp: 2022-08-20 07:16:55.617607\n",
      "resetting env. episode 1194, reward total was -21.0. running mean: -20.695646854974214, timestamp: 2022-08-20 07:16:56.728617\n",
      "resetting env. episode 1195, reward total was -21.0. running mean: -20.698690386424474, timestamp: 2022-08-20 07:16:58.031635\n",
      "resetting env. episode 1196, reward total was -21.0. running mean: -20.70170348256023, timestamp: 2022-08-20 07:16:59.327657\n",
      "resetting env. episode 1197, reward total was -20.0. running mean: -20.694686447734625, timestamp: 2022-08-20 07:17:00.707664\n",
      "resetting env. episode 1198, reward total was -21.0. running mean: -20.69773958325728, timestamp: 2022-08-20 07:17:01.766676\n",
      "resetting env. episode 1199, reward total was -21.0. running mean: -20.700762187424708, timestamp: 2022-08-20 07:17:03.745701\n",
      "resetting env. episode 1200, reward total was -20.0. running mean: -20.69375456555046, timestamp: 2022-08-20 07:17:05.432729\n",
      "resetting env. episode 1201, reward total was -21.0. running mean: -20.696817019894954, timestamp: 2022-08-20 07:17:06.862734\n",
      "resetting env. episode 1202, reward total was -21.0. running mean: -20.699848849696007, timestamp: 2022-08-20 07:17:08.257752\n",
      "resetting env. episode 1203, reward total was -19.0. running mean: -20.682850361199048, timestamp: 2022-08-20 07:17:10.077774\n",
      "resetting env. episode 1204, reward total was -21.0. running mean: -20.686021857587058, timestamp: 2022-08-20 07:17:11.120786\n",
      "resetting env. episode 1205, reward total was -19.0. running mean: -20.66916163901119, timestamp: 2022-08-20 07:17:12.590802\n",
      "resetting env. episode 1206, reward total was -21.0. running mean: -20.672470022621077, timestamp: 2022-08-20 07:17:13.954817\n",
      "resetting env. episode 1207, reward total was -21.0. running mean: -20.675745322394867, timestamp: 2022-08-20 07:17:16.007844\n",
      "resetting env. episode 1208, reward total was -21.0. running mean: -20.678987869170918, timestamp: 2022-08-20 07:17:17.237854\n",
      "resetting env. episode 1209, reward total was -19.0. running mean: -20.66219799047921, timestamp: 2022-08-20 07:17:18.627876\n",
      "resetting env. episode 1210, reward total was -20.0. running mean: -20.655576010574418, timestamp: 2022-08-20 07:17:20.158890\n",
      "resetting env. episode 1211, reward total was -21.0. running mean: -20.659020250468675, timestamp: 2022-08-20 07:17:21.800907\n",
      "resetting env. episode 1212, reward total was -21.0. running mean: -20.66243004796399, timestamp: 2022-08-20 07:17:23.515928\n",
      "resetting env. episode 1213, reward total was -21.0. running mean: -20.665805747484352, timestamp: 2022-08-20 07:17:25.360954\n",
      "resetting env. episode 1214, reward total was -20.0. running mean: -20.659147690009508, timestamp: 2022-08-20 07:17:26.637966\n",
      "resetting env. episode 1215, reward total was -21.0. running mean: -20.662556213109415, timestamp: 2022-08-20 07:17:27.880980\n",
      "resetting env. episode 1216, reward total was -20.0. running mean: -20.65593065097832, timestamp: 2022-08-20 07:17:29.129994\n",
      "resetting env. episode 1217, reward total was -21.0. running mean: -20.659371344468536, timestamp: 2022-08-20 07:17:30.550010\n",
      "resetting env. episode 1218, reward total was -21.0. running mean: -20.66277763102385, timestamp: 2022-08-20 07:17:31.962026\n",
      "resetting env. episode 1219, reward total was -21.0. running mean: -20.666149854713613, timestamp: 2022-08-20 07:17:33.313045\n",
      "resetting env. episode 1220, reward total was -21.0. running mean: -20.66948835616648, timestamp: 2022-08-20 07:17:34.726056\n",
      "resetting env. episode 1221, reward total was -21.0. running mean: -20.672793472604816, timestamp: 2022-08-20 07:17:35.978075\n",
      "resetting env. episode 1222, reward total was -21.0. running mean: -20.67606553787877, timestamp: 2022-08-20 07:17:37.151085\n",
      "resetting env. episode 1223, reward total was -21.0. running mean: -20.679304882499984, timestamp: 2022-08-20 07:17:38.673103\n",
      "resetting env. episode 1224, reward total was -21.0. running mean: -20.682511833674987, timestamp: 2022-08-20 07:17:39.711119\n",
      "resetting env. episode 1225, reward total was -20.0. running mean: -20.675686715338237, timestamp: 2022-08-20 07:17:41.728140\n",
      "resetting env. episode 1226, reward total was -20.0. running mean: -20.668929848184852, timestamp: 2022-08-20 07:17:43.172156\n",
      "resetting env. episode 1227, reward total was -21.0. running mean: -20.672240549703005, timestamp: 2022-08-20 07:17:44.414169\n",
      "resetting env. episode 1228, reward total was -20.0. running mean: -20.665518144205976, timestamp: 2022-08-20 07:17:45.817188\n",
      "resetting env. episode 1229, reward total was -21.0. running mean: -20.668862962763917, timestamp: 2022-08-20 07:17:46.911199\n",
      "resetting env. episode 1230, reward total was -20.0. running mean: -20.662174333136278, timestamp: 2022-08-20 07:17:48.209215\n",
      "resetting env. episode 1231, reward total was -21.0. running mean: -20.665552589804914, timestamp: 2022-08-20 07:17:49.573230\n",
      "resetting env. episode 1232, reward total was -20.0. running mean: -20.658897063906863, timestamp: 2022-08-20 07:17:51.188250\n",
      "resetting env. episode 1233, reward total was -21.0. running mean: -20.662308093267796, timestamp: 2022-08-20 07:17:52.225266\n",
      "resetting env. episode 1234, reward total was -21.0. running mean: -20.665685012335118, timestamp: 2022-08-20 07:17:53.966281\n",
      "resetting env. episode 1235, reward total was -21.0. running mean: -20.669028162211767, timestamp: 2022-08-20 07:17:55.443300\n",
      "resetting env. episode 1236, reward total was -20.0. running mean: -20.662337880589646, timestamp: 2022-08-20 07:17:56.929319\n",
      "resetting env. episode 1237, reward total was -21.0. running mean: -20.66571450178375, timestamp: 2022-08-20 07:17:58.896339\n",
      "resetting env. episode 1238, reward total was -21.0. running mean: -20.66905735676591, timestamp: 2022-08-20 07:17:59.931354\n",
      "resetting env. episode 1239, reward total was -21.0. running mean: -20.672366783198253, timestamp: 2022-08-20 07:18:01.233365\n",
      "resetting env. episode 1240, reward total was -21.0. running mean: -20.67564311536627, timestamp: 2022-08-20 07:18:03.731393\n",
      "resetting env. episode 1241, reward total was -21.0. running mean: -20.678886684212607, timestamp: 2022-08-20 07:18:04.839406\n",
      "resetting env. episode 1242, reward total was -21.0. running mean: -20.682097817370483, timestamp: 2022-08-20 07:18:06.523428\n",
      "resetting env. episode 1243, reward total was -21.0. running mean: -20.685276839196778, timestamp: 2022-08-20 07:18:07.774444\n",
      "resetting env. episode 1244, reward total was -21.0. running mean: -20.68842407080481, timestamp: 2022-08-20 07:18:10.037467\n",
      "resetting env. episode 1245, reward total was -21.0. running mean: -20.69153983009676, timestamp: 2022-08-20 07:18:11.390488\n",
      "resetting env. episode 1246, reward total was -21.0. running mean: -20.694624431795795, timestamp: 2022-08-20 07:18:12.511498\n",
      "resetting env. episode 1247, reward total was -21.0. running mean: -20.697678187477837, timestamp: 2022-08-20 07:18:13.853517\n",
      "resetting env. episode 1248, reward total was -20.0. running mean: -20.690701405603058, timestamp: 2022-08-20 07:18:15.794535\n",
      "resetting env. episode 1249, reward total was -21.0. running mean: -20.693794391547026, timestamp: 2022-08-20 07:18:16.851548\n",
      "resetting env. episode 1250, reward total was -21.0. running mean: -20.696856447631557, timestamp: 2022-08-20 07:18:18.302562\n",
      "resetting env. episode 1251, reward total was -21.0. running mean: -20.69988788315524, timestamp: 2022-08-20 07:18:19.544578\n",
      "resetting env. episode 1252, reward total was -21.0. running mean: -20.70288900432369, timestamp: 2022-08-20 07:18:22.189611\n",
      "resetting env. episode 1253, reward total was -19.0. running mean: -20.685860114280455, timestamp: 2022-08-20 07:18:23.855632\n",
      "resetting env. episode 1254, reward total was -21.0. running mean: -20.68900151313765, timestamp: 2022-08-20 07:18:25.296647\n",
      "resetting env. episode 1255, reward total was -21.0. running mean: -20.692111498006273, timestamp: 2022-08-20 07:18:26.644665\n",
      "resetting env. episode 1256, reward total was -21.0. running mean: -20.695190383026212, timestamp: 2022-08-20 07:18:28.105680\n",
      "resetting env. episode 1257, reward total was -18.0. running mean: -20.66823847919595, timestamp: 2022-08-20 07:18:29.634699\n",
      "resetting env. episode 1258, reward total was -21.0. running mean: -20.67155609440399, timestamp: 2022-08-20 07:18:31.055713\n",
      "resetting env. episode 1259, reward total was -21.0. running mean: -20.67484053345995, timestamp: 2022-08-20 07:18:32.406247\n",
      "resetting env. episode 1260, reward total was -21.0. running mean: -20.67809212812535, timestamp: 2022-08-20 07:18:33.828265\n",
      "resetting env. episode 1261, reward total was -19.0. running mean: -20.661311206844097, timestamp: 2022-08-20 07:18:35.236279\n",
      "resetting env. episode 1262, reward total was -21.0. running mean: -20.664698094775655, timestamp: 2022-08-20 07:18:37.032305\n",
      "resetting env. episode 1263, reward total was -20.0. running mean: -20.6580511138279, timestamp: 2022-08-20 07:18:38.708319\n",
      "resetting env. episode 1264, reward total was -21.0. running mean: -20.66147060268962, timestamp: 2022-08-20 07:18:41.219348\n",
      "resetting env. episode 1265, reward total was -21.0. running mean: -20.664855896662722, timestamp: 2022-08-20 07:18:42.684371\n",
      "resetting env. episode 1266, reward total was -20.0. running mean: -20.658207337696094, timestamp: 2022-08-20 07:18:44.143383\n",
      "resetting env. episode 1267, reward total was -21.0. running mean: -20.661625264319134, timestamp: 2022-08-20 07:18:46.158406\n",
      "resetting env. episode 1268, reward total was -21.0. running mean: -20.665009011675945, timestamp: 2022-08-20 07:18:47.583423\n",
      "resetting env. episode 1269, reward total was -21.0. running mean: -20.668358921559186, timestamp: 2022-08-20 07:18:49.767451\n",
      "resetting env. episode 1270, reward total was -20.0. running mean: -20.66167533234359, timestamp: 2022-08-20 07:18:51.329466\n",
      "resetting env. episode 1271, reward total was -21.0. running mean: -20.665058579020155, timestamp: 2022-08-20 07:18:53.811496\n",
      "resetting env. episode 1272, reward total was -18.0. running mean: -20.638407993229954, timestamp: 2022-08-20 07:18:55.314516\n",
      "resetting env. episode 1273, reward total was -19.0. running mean: -20.622023913297657, timestamp: 2022-08-20 07:18:57.331535\n",
      "resetting env. episode 1274, reward total was -21.0. running mean: -20.62580367416468, timestamp: 2022-08-20 07:18:59.221558\n",
      "resetting env. episode 1275, reward total was -21.0. running mean: -20.629545637423032, timestamp: 2022-08-20 07:19:01.005581\n",
      "resetting env. episode 1276, reward total was -20.0. running mean: -20.6232501810488, timestamp: 2022-08-20 07:19:02.419597\n",
      "resetting env. episode 1277, reward total was -19.0. running mean: -20.607017679238314, timestamp: 2022-08-20 07:19:04.394620\n",
      "resetting env. episode 1278, reward total was -21.0. running mean: -20.61094750244593, timestamp: 2022-08-20 07:19:06.333642\n",
      "resetting env. episode 1279, reward total was -20.0. running mean: -20.604838027421472, timestamp: 2022-08-20 07:19:07.567659\n",
      "resetting env. episode 1280, reward total was -21.0. running mean: -20.60878964714726, timestamp: 2022-08-20 07:19:09.015671\n",
      "resetting env. episode 1281, reward total was -19.0. running mean: -20.592701750675786, timestamp: 2022-08-20 07:19:10.390689\n",
      "resetting env. episode 1282, reward total was -21.0. running mean: -20.596774733169028, timestamp: 2022-08-20 07:19:12.151717\n",
      "resetting env. episode 1283, reward total was -19.0. running mean: -20.580806985837338, timestamp: 2022-08-20 07:19:13.899731\n",
      "resetting env. episode 1284, reward total was -20.0. running mean: -20.574998915978963, timestamp: 2022-08-20 07:19:15.270744\n",
      "resetting env. episode 1285, reward total was -21.0. running mean: -20.579248926819172, timestamp: 2022-08-20 07:19:16.980764\n",
      "resetting env. episode 1286, reward total was -18.0. running mean: -20.55345643755098, timestamp: 2022-08-20 07:19:18.561782\n",
      "resetting env. episode 1287, reward total was -21.0. running mean: -20.55792187317547, timestamp: 2022-08-20 07:19:19.697800\n",
      "resetting env. episode 1288, reward total was -19.0. running mean: -20.542342654443715, timestamp: 2022-08-20 07:19:21.748824\n",
      "resetting env. episode 1289, reward total was -21.0. running mean: -20.546919227899277, timestamp: 2022-08-20 07:19:23.293840\n",
      "resetting env. episode 1290, reward total was -20.0. running mean: -20.541450035620283, timestamp: 2022-08-20 07:19:25.356860\n",
      "resetting env. episode 1291, reward total was -19.0. running mean: -20.526035535264082, timestamp: 2022-08-20 07:19:27.602888\n",
      "resetting env. episode 1292, reward total was -20.0. running mean: -20.52077517991144, timestamp: 2022-08-20 07:19:29.011905\n",
      "resetting env. episode 1293, reward total was -20.0. running mean: -20.515567428112323, timestamp: 2022-08-20 07:19:30.640927\n",
      "resetting env. episode 1294, reward total was -20.0. running mean: -20.5104117538312, timestamp: 2022-08-20 07:19:32.270990\n",
      "resetting env. episode 1295, reward total was -20.0. running mean: -20.505307636292887, timestamp: 2022-08-20 07:19:34.085023\n",
      "resetting env. episode 1296, reward total was -21.0. running mean: -20.510254559929958, timestamp: 2022-08-20 07:19:35.328025\n",
      "resetting env. episode 1297, reward total was -19.0. running mean: -20.49515201433066, timestamp: 2022-08-20 07:19:37.308049\n",
      "resetting env. episode 1298, reward total was -20.0. running mean: -20.490200494187352, timestamp: 2022-08-20 07:19:38.706074\n",
      "resetting env. episode 1299, reward total was -21.0. running mean: -20.495298489245478, timestamp: 2022-08-20 07:19:40.222089\n",
      "resetting env. episode 1300, reward total was -21.0. running mean: -20.500345504353024, timestamp: 2022-08-20 07:19:41.641098\n",
      "resetting env. episode 1301, reward total was -18.0. running mean: -20.475342049309493, timestamp: 2022-08-20 07:19:43.389120\n",
      "resetting env. episode 1302, reward total was -21.0. running mean: -20.4805886288164, timestamp: 2022-08-20 07:19:45.311145\n",
      "resetting env. episode 1303, reward total was -19.0. running mean: -20.465782742528237, timestamp: 2022-08-20 07:19:47.049167\n",
      "resetting env. episode 1304, reward total was -21.0. running mean: -20.471124915102955, timestamp: 2022-08-20 07:19:48.486181\n",
      "resetting env. episode 1305, reward total was -20.0. running mean: -20.466413665951926, timestamp: 2022-08-20 07:19:49.904196\n",
      "resetting env. episode 1306, reward total was -21.0. running mean: -20.471749529292406, timestamp: 2022-08-20 07:19:51.451222\n",
      "resetting env. episode 1307, reward total was -18.0. running mean: -20.44703203399948, timestamp: 2022-08-20 07:19:53.239237\n",
      "resetting env. episode 1308, reward total was -19.0. running mean: -20.43256171365949, timestamp: 2022-08-20 07:19:55.022256\n",
      "resetting env. episode 1309, reward total was -21.0. running mean: -20.438236096522893, timestamp: 2022-08-20 07:19:56.923279\n",
      "resetting env. episode 1310, reward total was -20.0. running mean: -20.433853735557662, timestamp: 2022-08-20 07:19:58.270293\n",
      "resetting env. episode 1311, reward total was -21.0. running mean: -20.439515198202088, timestamp: 2022-08-20 07:20:00.169318\n",
      "resetting env. episode 1312, reward total was -19.0. running mean: -20.42512004622007, timestamp: 2022-08-20 07:20:02.528344\n",
      "resetting env. episode 1313, reward total was -18.0. running mean: -20.400868845757866, timestamp: 2022-08-20 07:20:04.355365\n",
      "resetting env. episode 1314, reward total was -21.0. running mean: -20.40686015730029, timestamp: 2022-08-20 07:20:05.633379\n",
      "resetting env. episode 1315, reward total was -21.0. running mean: -20.41279155572729, timestamp: 2022-08-20 07:20:07.113399\n",
      "resetting env. episode 1316, reward total was -20.0. running mean: -20.408663640170015, timestamp: 2022-08-20 07:20:08.725418\n",
      "resetting env. episode 1317, reward total was -20.0. running mean: -20.404577003768313, timestamp: 2022-08-20 07:20:10.771441\n",
      "resetting env. episode 1318, reward total was -21.0. running mean: -20.41053123373063, timestamp: 2022-08-20 07:20:12.282459\n",
      "resetting env. episode 1319, reward total was -20.0. running mean: -20.40642592139332, timestamp: 2022-08-20 07:20:13.684477\n",
      "resetting env. episode 1320, reward total was -21.0. running mean: -20.41236166217939, timestamp: 2022-08-20 07:20:15.576500\n",
      "resetting env. episode 1321, reward total was -21.0. running mean: -20.418238045557597, timestamp: 2022-08-20 07:20:17.369519\n",
      "resetting env. episode 1322, reward total was -21.0. running mean: -20.42405566510202, timestamp: 2022-08-20 07:20:18.846537\n",
      "resetting env. episode 1323, reward total was -19.0. running mean: -20.409815108451003, timestamp: 2022-08-20 07:20:20.358553\n",
      "resetting env. episode 1324, reward total was -21.0. running mean: -20.415716957366495, timestamp: 2022-08-20 07:20:21.640570\n",
      "resetting env. episode 1325, reward total was -19.0. running mean: -20.40155978779283, timestamp: 2022-08-20 07:20:23.437592\n",
      "resetting env. episode 1326, reward total was -21.0. running mean: -20.407544189914905, timestamp: 2022-08-20 07:20:24.702605\n",
      "resetting env. episode 1327, reward total was -21.0. running mean: -20.413468748015756, timestamp: 2022-08-20 07:20:25.798618\n",
      "resetting env. episode 1328, reward total was -20.0. running mean: -20.4093340605356, timestamp: 2022-08-20 07:20:27.266635\n",
      "resetting env. episode 1329, reward total was -21.0. running mean: -20.415240719930242, timestamp: 2022-08-20 07:20:28.621651\n",
      "resetting env. episode 1330, reward total was -20.0. running mean: -20.41108831273094, timestamp: 2022-08-20 07:20:30.512672\n",
      "resetting env. episode 1331, reward total was -19.0. running mean: -20.39697742960363, timestamp: 2022-08-20 07:20:32.052695\n",
      "resetting env. episode 1332, reward total was -21.0. running mean: -20.403007655307594, timestamp: 2022-08-20 07:20:34.159714\n",
      "resetting env. episode 1333, reward total was -18.0. running mean: -20.37897757875452, timestamp: 2022-08-20 07:20:36.091738\n",
      "resetting env. episode 1334, reward total was -17.0. running mean: -20.345187802966976, timestamp: 2022-08-20 07:20:37.919757\n",
      "resetting env. episode 1335, reward total was -21.0. running mean: -20.351735924937305, timestamp: 2022-08-20 07:20:39.309775\n",
      "resetting env. episode 1336, reward total was -20.0. running mean: -20.34821856568793, timestamp: 2022-08-20 07:20:40.480789\n",
      "resetting env. episode 1337, reward total was -21.0. running mean: -20.35473638003105, timestamp: 2022-08-20 07:20:42.290811\n",
      "resetting env. episode 1338, reward total was -19.0. running mean: -20.34118901623074, timestamp: 2022-08-20 07:20:43.915830\n",
      "resetting env. episode 1339, reward total was -21.0. running mean: -20.347777126068433, timestamp: 2022-08-20 07:20:45.940852\n",
      "resetting env. episode 1340, reward total was -20.0. running mean: -20.34429935480775, timestamp: 2022-08-20 07:20:48.176878\n",
      "resetting env. episode 1341, reward total was -21.0. running mean: -20.350856361259673, timestamp: 2022-08-20 07:20:49.745898\n",
      "resetting env. episode 1342, reward total was -20.0. running mean: -20.347347797647075, timestamp: 2022-08-20 07:20:51.359918\n",
      "resetting env. episode 1343, reward total was -21.0. running mean: -20.353874319670606, timestamp: 2022-08-20 07:20:52.985935\n",
      "resetting env. episode 1344, reward total was -20.0. running mean: -20.3503355764739, timestamp: 2022-08-20 07:20:54.283951\n",
      "resetting env. episode 1345, reward total was -19.0. running mean: -20.336832220709162, timestamp: 2022-08-20 07:20:56.044971\n",
      "resetting env. episode 1346, reward total was -21.0. running mean: -20.343463898502073, timestamp: 2022-08-20 07:20:58.051991\n",
      "resetting env. episode 1347, reward total was -20.0. running mean: -20.340029259517053, timestamp: 2022-08-20 07:20:59.530011\n",
      "resetting env. episode 1348, reward total was -19.0. running mean: -20.326628966921884, timestamp: 2022-08-20 07:21:01.045026\n",
      "resetting env. episode 1349, reward total was -21.0. running mean: -20.333362677252666, timestamp: 2022-08-20 07:21:02.830048\n",
      "resetting env. episode 1350, reward total was -19.0. running mean: -20.32002905048014, timestamp: 2022-08-20 07:21:04.762071\n",
      "resetting env. episode 1351, reward total was -20.0. running mean: -20.316828759975337, timestamp: 2022-08-20 07:21:06.376090\n",
      "resetting env. episode 1352, reward total was -17.0. running mean: -20.283660472375587, timestamp: 2022-08-20 07:21:08.660118\n",
      "resetting env. episode 1353, reward total was -19.0. running mean: -20.27082386765183, timestamp: 2022-08-20 07:21:10.721148\n",
      "resetting env. episode 1354, reward total was -18.0. running mean: -20.248115628975313, timestamp: 2022-08-20 07:21:12.549163\n",
      "resetting env. episode 1355, reward total was -21.0. running mean: -20.25563447268556, timestamp: 2022-08-20 07:21:13.800177\n",
      "resetting env. episode 1356, reward total was -20.0. running mean: -20.253078127958705, timestamp: 2022-08-20 07:21:15.405198\n",
      "resetting env. episode 1357, reward total was -20.0. running mean: -20.250547346679117, timestamp: 2022-08-20 07:21:16.622207\n",
      "resetting env. episode 1358, reward total was -21.0. running mean: -20.258041873212328, timestamp: 2022-08-20 07:21:18.518230\n",
      "resetting env. episode 1359, reward total was -20.0. running mean: -20.255461454480205, timestamp: 2022-08-20 07:21:20.156249\n",
      "resetting env. episode 1360, reward total was -21.0. running mean: -20.262906839935404, timestamp: 2022-08-20 07:21:21.837270\n",
      "resetting env. episode 1361, reward total was -21.0. running mean: -20.27027777153605, timestamp: 2022-08-20 07:21:23.309285\n",
      "resetting env. episode 1362, reward total was -21.0. running mean: -20.277574993820693, timestamp: 2022-08-20 07:21:24.848304\n",
      "resetting env. episode 1363, reward total was -19.0. running mean: -20.264799243882486, timestamp: 2022-08-20 07:21:26.311320\n",
      "resetting env. episode 1364, reward total was -19.0. running mean: -20.252151251443664, timestamp: 2022-08-20 07:21:28.431345\n",
      "resetting env. episode 1365, reward total was -20.0. running mean: -20.249629738929226, timestamp: 2022-08-20 07:21:30.299366\n",
      "resetting env. episode 1366, reward total was -21.0. running mean: -20.257133441539935, timestamp: 2022-08-20 07:21:31.916386\n",
      "resetting env. episode 1367, reward total was -20.0. running mean: -20.254562107124535, timestamp: 2022-08-20 07:21:33.742405\n",
      "resetting env. episode 1368, reward total was -17.0. running mean: -20.222016486053292, timestamp: 2022-08-20 07:21:35.782432\n",
      "resetting env. episode 1369, reward total was -20.0. running mean: -20.219796321192756, timestamp: 2022-08-20 07:21:37.427450\n",
      "resetting env. episode 1370, reward total was -21.0. running mean: -20.22759835798083, timestamp: 2022-08-20 07:21:38.895469\n",
      "resetting env. episode 1371, reward total was -19.0. running mean: -20.215322374401023, timestamp: 2022-08-20 07:21:40.963490\n",
      "resetting env. episode 1372, reward total was -21.0. running mean: -20.223169150657014, timestamp: 2022-08-20 07:21:42.593510\n",
      "resetting env. episode 1373, reward total was -20.0. running mean: -20.220937459150445, timestamp: 2022-08-20 07:21:44.131529\n",
      "resetting env. episode 1374, reward total was -20.0. running mean: -20.21872808455894, timestamp: 2022-08-20 07:21:45.730546\n",
      "resetting env. episode 1375, reward total was -19.0. running mean: -20.206540803713352, timestamp: 2022-08-20 07:21:47.752569\n",
      "resetting env. episode 1376, reward total was -16.0. running mean: -20.16447539567622, timestamp: 2022-08-20 07:21:50.392599\n",
      "resetting env. episode 1377, reward total was -21.0. running mean: -20.172830641719457, timestamp: 2022-08-20 07:21:51.820620\n",
      "resetting env. episode 1378, reward total was -21.0. running mean: -20.181102335302263, timestamp: 2022-08-20 07:21:53.311637\n",
      "resetting env. episode 1379, reward total was -17.0. running mean: -20.14929131194924, timestamp: 2022-08-20 07:21:55.539660\n",
      "resetting env. episode 1380, reward total was -18.0. running mean: -20.12779839882975, timestamp: 2022-08-20 07:21:57.458681\n",
      "resetting env. episode 1381, reward total was -20.0. running mean: -20.12652041484145, timestamp: 2022-08-20 07:21:58.794697\n",
      "resetting env. episode 1382, reward total was -21.0. running mean: -20.13525521069304, timestamp: 2022-08-20 07:22:00.435715\n",
      "resetting env. episode 1383, reward total was -21.0. running mean: -20.14390265858611, timestamp: 2022-08-20 07:22:01.861734\n",
      "resetting env. episode 1384, reward total was -19.0. running mean: -20.13246363200025, timestamp: 2022-08-20 07:22:03.424749\n",
      "resetting env. episode 1385, reward total was -18.0. running mean: -20.111138995680246, timestamp: 2022-08-20 07:22:05.503775\n",
      "resetting env. episode 1386, reward total was -19.0. running mean: -20.100027605723444, timestamp: 2022-08-20 07:22:06.837791\n",
      "resetting env. episode 1387, reward total was -21.0. running mean: -20.10902732966621, timestamp: 2022-08-20 07:22:08.341813\n",
      "resetting env. episode 1388, reward total was -18.0. running mean: -20.087937056369547, timestamp: 2022-08-20 07:22:10.250831\n",
      "resetting env. episode 1389, reward total was -19.0. running mean: -20.077057685805855, timestamp: 2022-08-20 07:22:12.459857\n",
      "resetting env. episode 1390, reward total was -18.0. running mean: -20.056287108947796, timestamp: 2022-08-20 07:22:14.432881\n",
      "resetting env. episode 1391, reward total was -19.0. running mean: -20.04572423785832, timestamp: 2022-08-20 07:22:16.282906\n",
      "resetting env. episode 1392, reward total was -18.0. running mean: -20.025266995479736, timestamp: 2022-08-20 07:22:18.217922\n",
      "resetting env. episode 1393, reward total was -20.0. running mean: -20.02501432552494, timestamp: 2022-08-20 07:22:20.213949\n",
      "resetting env. episode 1394, reward total was -19.0. running mean: -20.01476418226969, timestamp: 2022-08-20 07:22:22.173970\n",
      "resetting env. episode 1395, reward total was -21.0. running mean: -20.024616540446996, timestamp: 2022-08-20 07:22:23.879995\n",
      "resetting env. episode 1396, reward total was -20.0. running mean: -20.024370375042526, timestamp: 2022-08-20 07:22:25.479008\n",
      "resetting env. episode 1397, reward total was -20.0. running mean: -20.024126671292098, timestamp: 2022-08-20 07:22:27.213030\n",
      "resetting env. episode 1398, reward total was -18.0. running mean: -20.003885404579176, timestamp: 2022-08-20 07:22:29.286051\n",
      "resetting env. episode 1399, reward total was -21.0. running mean: -20.013846550533383, timestamp: 2022-08-20 07:22:30.937077\n",
      "resetting env. episode 1400, reward total was -16.0. running mean: -19.97370808502805, timestamp: 2022-08-20 07:22:33.217099\n",
      "resetting env. episode 1401, reward total was -21.0. running mean: -19.98397100417777, timestamp: 2022-08-20 07:22:34.491112\n",
      "resetting env. episode 1402, reward total was -19.0. running mean: -19.974131294135994, timestamp: 2022-08-20 07:22:36.423138\n",
      "resetting env. episode 1403, reward total was -21.0. running mean: -19.984389981194635, timestamp: 2022-08-20 07:22:37.917152\n",
      "resetting env. episode 1404, reward total was -20.0. running mean: -19.98454608138269, timestamp: 2022-08-20 07:22:39.433167\n",
      "resetting env. episode 1405, reward total was -20.0. running mean: -19.984700620568862, timestamp: 2022-08-20 07:22:41.103188\n",
      "resetting env. episode 1406, reward total was -18.0. running mean: -19.96485361436317, timestamp: 2022-08-20 07:22:43.353214\n",
      "resetting env. episode 1407, reward total was -18.0. running mean: -19.94520507821954, timestamp: 2022-08-20 07:22:44.985233\n",
      "resetting env. episode 1408, reward total was -21.0. running mean: -19.955753027437346, timestamp: 2022-08-20 07:22:46.564253\n",
      "resetting env. episode 1409, reward total was -19.0. running mean: -19.946195497162975, timestamp: 2022-08-20 07:22:48.693278\n",
      "resetting env. episode 1410, reward total was -21.0. running mean: -19.956733542191348, timestamp: 2022-08-20 07:22:50.000290\n",
      "resetting env. episode 1411, reward total was -21.0. running mean: -19.967166206769434, timestamp: 2022-08-20 07:22:51.642310\n",
      "resetting env. episode 1412, reward total was -20.0. running mean: -19.96749454470174, timestamp: 2022-08-20 07:22:52.867326\n",
      "resetting env. episode 1413, reward total was -18.0. running mean: -19.94781959925472, timestamp: 2022-08-20 07:22:54.643344\n",
      "resetting env. episode 1414, reward total was -19.0. running mean: -19.938341403262175, timestamp: 2022-08-20 07:22:56.760368\n",
      "resetting env. episode 1415, reward total was -19.0. running mean: -19.928957989229556, timestamp: 2022-08-20 07:22:58.884397\n",
      "resetting env. episode 1416, reward total was -21.0. running mean: -19.939668409337262, timestamp: 2022-08-20 07:23:00.091407\n",
      "resetting env. episode 1417, reward total was -20.0. running mean: -19.94027172524389, timestamp: 2022-08-20 07:23:01.668426\n",
      "resetting env. episode 1418, reward total was -19.0. running mean: -19.93086900799145, timestamp: 2022-08-20 07:23:03.252445\n",
      "resetting env. episode 1419, reward total was -19.0. running mean: -19.92156031791154, timestamp: 2022-08-20 07:23:05.059466\n",
      "resetting env. episode 1420, reward total was -18.0. running mean: -19.902344714732422, timestamp: 2022-08-20 07:23:07.204494\n",
      "resetting env. episode 1421, reward total was -17.0. running mean: -19.873321267585098, timestamp: 2022-08-20 07:23:09.248523\n",
      "resetting env. episode 1422, reward total was -21.0. running mean: -19.884588054909248, timestamp: 2022-08-20 07:23:11.069539\n",
      "resetting env. episode 1423, reward total was -20.0. running mean: -19.885742174360153, timestamp: 2022-08-20 07:23:12.596554\n",
      "resetting env. episode 1424, reward total was -19.0. running mean: -19.876884752616554, timestamp: 2022-08-20 07:23:14.229574\n",
      "resetting env. episode 1425, reward total was -19.0. running mean: -19.86811590509039, timestamp: 2022-08-20 07:23:15.936595\n",
      "resetting env. episode 1426, reward total was -19.0. running mean: -19.85943474603949, timestamp: 2022-08-20 07:23:18.158621\n",
      "resetting env. episode 1427, reward total was -17.0. running mean: -19.830840398579095, timestamp: 2022-08-20 07:23:20.303644\n",
      "resetting env. episode 1428, reward total was -20.0. running mean: -19.832531994593303, timestamp: 2022-08-20 07:23:22.121664\n",
      "resetting env. episode 1429, reward total was -21.0. running mean: -19.84420667464737, timestamp: 2022-08-20 07:23:23.492682\n",
      "resetting env. episode 1430, reward total was -20.0. running mean: -19.845764607900897, timestamp: 2022-08-20 07:23:25.421707\n",
      "resetting env. episode 1431, reward total was -17.0. running mean: -19.817306961821888, timestamp: 2022-08-20 07:23:27.869732\n",
      "resetting env. episode 1432, reward total was -19.0. running mean: -19.809133892203672, timestamp: 2022-08-20 07:23:29.951759\n",
      "resetting env. episode 1433, reward total was -20.0. running mean: -19.811042553281634, timestamp: 2022-08-20 07:23:31.432773\n",
      "resetting env. episode 1434, reward total was -21.0. running mean: -19.822932127748818, timestamp: 2022-08-20 07:23:32.761791\n",
      "resetting env. episode 1435, reward total was -15.0. running mean: -19.77470280647133, timestamp: 2022-08-20 07:23:34.947813\n",
      "resetting env. episode 1436, reward total was -21.0. running mean: -19.786955778406615, timestamp: 2022-08-20 07:23:36.758836\n",
      "resetting env. episode 1437, reward total was -20.0. running mean: -19.789086220622547, timestamp: 2022-08-20 07:23:38.333853\n",
      "resetting env. episode 1438, reward total was -18.0. running mean: -19.77119535841632, timestamp: 2022-08-20 07:23:40.201875\n",
      "resetting env. episode 1439, reward total was -20.0. running mean: -19.773483404832156, timestamp: 2022-08-20 07:23:41.910894\n",
      "resetting env. episode 1440, reward total was -19.0. running mean: -19.765748570783835, timestamp: 2022-08-20 07:23:43.983922\n",
      "resetting env. episode 1441, reward total was -21.0. running mean: -19.778091085075996, timestamp: 2022-08-20 07:23:46.014945\n",
      "resetting env. episode 1442, reward total was -18.0. running mean: -19.760310174225236, timestamp: 2022-08-20 07:23:48.737984\n",
      "resetting env. episode 1443, reward total was -21.0. running mean: -19.772707072482984, timestamp: 2022-08-20 07:23:50.298992\n",
      "resetting env. episode 1444, reward total was -21.0. running mean: -19.784980001758154, timestamp: 2022-08-20 07:23:52.043015\n",
      "resetting env. episode 1445, reward total was -20.0. running mean: -19.78713020174057, timestamp: 2022-08-20 07:23:54.441041\n",
      "resetting env. episode 1446, reward total was -20.0. running mean: -19.789258899723166, timestamp: 2022-08-20 07:23:55.891059\n",
      "resetting env. episode 1447, reward total was -20.0. running mean: -19.791366310725934, timestamp: 2022-08-20 07:23:57.606080\n",
      "resetting env. episode 1448, reward total was -19.0. running mean: -19.783452647618677, timestamp: 2022-08-20 07:23:59.247103\n",
      "resetting env. episode 1449, reward total was -16.0. running mean: -19.745618121142492, timestamp: 2022-08-20 07:24:01.756127\n",
      "resetting env. episode 1450, reward total was -21.0. running mean: -19.758161939931068, timestamp: 2022-08-20 07:24:03.304145\n",
      "resetting env. episode 1451, reward total was -18.0. running mean: -19.740580320531755, timestamp: 2022-08-20 07:24:05.166166\n",
      "resetting env. episode 1452, reward total was -18.0. running mean: -19.723174517326438, timestamp: 2022-08-20 07:24:07.018198\n",
      "resetting env. episode 1453, reward total was -19.0. running mean: -19.715942772153173, timestamp: 2022-08-20 07:24:08.532207\n",
      "resetting env. episode 1454, reward total was -21.0. running mean: -19.728783344431644, timestamp: 2022-08-20 07:24:10.258228\n",
      "resetting env. episode 1455, reward total was -21.0. running mean: -19.741495510987328, timestamp: 2022-08-20 07:24:12.253248\n",
      "resetting env. episode 1456, reward total was -18.0. running mean: -19.724080555877453, timestamp: 2022-08-20 07:24:13.655263\n",
      "resetting env. episode 1457, reward total was -20.0. running mean: -19.72683975031868, timestamp: 2022-08-20 07:24:15.438289\n",
      "resetting env. episode 1458, reward total was -20.0. running mean: -19.72957135281549, timestamp: 2022-08-20 07:24:16.890307\n",
      "resetting env. episode 1459, reward total was -21.0. running mean: -19.742275639287335, timestamp: 2022-08-20 07:24:18.822328\n",
      "resetting env. episode 1460, reward total was -21.0. running mean: -19.75485288289446, timestamp: 2022-08-20 07:24:21.102353\n",
      "resetting env. episode 1461, reward total was -18.0. running mean: -19.737304354065515, timestamp: 2022-08-20 07:24:22.768380\n",
      "resetting env. episode 1462, reward total was -21.0. running mean: -19.74993131052486, timestamp: 2022-08-20 07:24:24.606392\n",
      "resetting env. episode 1463, reward total was -17.0. running mean: -19.722431997419616, timestamp: 2022-08-20 07:24:26.527415\n",
      "resetting env. episode 1464, reward total was -21.0. running mean: -19.73520767744542, timestamp: 2022-08-20 07:24:28.511439\n",
      "resetting env. episode 1465, reward total was -20.0. running mean: -19.737855600670965, timestamp: 2022-08-20 07:24:30.666461\n",
      "resetting env. episode 1466, reward total was -21.0. running mean: -19.750477044664255, timestamp: 2022-08-20 07:24:32.340481\n",
      "resetting env. episode 1467, reward total was -21.0. running mean: -19.762972274217613, timestamp: 2022-08-20 07:24:33.374494\n",
      "resetting env. episode 1468, reward total was -21.0. running mean: -19.77534255147544, timestamp: 2022-08-20 07:24:35.516518\n",
      "resetting env. episode 1469, reward total was -20.0. running mean: -19.777589125960684, timestamp: 2022-08-20 07:24:37.037536\n",
      "resetting env. episode 1470, reward total was -19.0. running mean: -19.76981323470108, timestamp: 2022-08-20 07:24:38.742554\n",
      "resetting env. episode 1471, reward total was -21.0. running mean: -19.78211510235407, timestamp: 2022-08-20 07:24:40.229573\n",
      "resetting env. episode 1472, reward total was -21.0. running mean: -19.79429395133053, timestamp: 2022-08-20 07:24:41.753593\n",
      "resetting env. episode 1473, reward total was -20.0. running mean: -19.796351011817226, timestamp: 2022-08-20 07:24:43.226610\n",
      "resetting env. episode 1474, reward total was -21.0. running mean: -19.808387501699055, timestamp: 2022-08-20 07:24:44.934632\n",
      "resetting env. episode 1475, reward total was -21.0. running mean: -19.820303626682065, timestamp: 2022-08-20 07:24:46.147642\n",
      "resetting env. episode 1476, reward total was -19.0. running mean: -19.812100590415245, timestamp: 2022-08-20 07:24:47.800662\n",
      "resetting env. episode 1477, reward total was -21.0. running mean: -19.823979584511093, timestamp: 2022-08-20 07:24:48.911678\n",
      "resetting env. episode 1478, reward total was -19.0. running mean: -19.815739788665983, timestamp: 2022-08-20 07:24:52.009713\n",
      "resetting env. episode 1479, reward total was -21.0. running mean: -19.827582390779323, timestamp: 2022-08-20 07:24:54.615741\n",
      "resetting env. episode 1480, reward total was -21.0. running mean: -19.83930656687153, timestamp: 2022-08-20 07:24:56.396759\n",
      "resetting env. episode 1481, reward total was -21.0. running mean: -19.850913501202818, timestamp: 2022-08-20 07:24:57.789779\n",
      "resetting env. episode 1482, reward total was -17.0. running mean: -19.822404366190792, timestamp: 2022-08-20 07:25:00.026807\n",
      "resetting env. episode 1483, reward total was -21.0. running mean: -19.834180322528884, timestamp: 2022-08-20 07:25:01.266816\n",
      "resetting env. episode 1484, reward total was -20.0. running mean: -19.835838519303593, timestamp: 2022-08-20 07:25:03.447843\n",
      "resetting env. episode 1485, reward total was -20.0. running mean: -19.837480134110557, timestamp: 2022-08-20 07:25:05.252863\n",
      "resetting env. episode 1486, reward total was -21.0. running mean: -19.84910533276945, timestamp: 2022-08-20 07:25:06.800883\n",
      "resetting env. episode 1487, reward total was -20.0. running mean: -19.850614279441757, timestamp: 2022-08-20 07:25:08.226898\n",
      "resetting env. episode 1488, reward total was -18.0. running mean: -19.83210813664734, timestamp: 2022-08-20 07:25:10.058924\n",
      "resetting env. episode 1489, reward total was -20.0. running mean: -19.833787055280865, timestamp: 2022-08-20 07:25:11.446937\n",
      "resetting env. episode 1490, reward total was -21.0. running mean: -19.845449184728057, timestamp: 2022-08-20 07:25:13.815962\n",
      "resetting env. episode 1491, reward total was -21.0. running mean: -19.85699469288078, timestamp: 2022-08-20 07:25:15.156980\n",
      "resetting env. episode 1492, reward total was -21.0. running mean: -19.868424745951973, timestamp: 2022-08-20 07:25:16.615994\n",
      "resetting env. episode 1493, reward total was -15.0. running mean: -19.81974049849245, timestamp: 2022-08-20 07:25:18.989028\n",
      "resetting env. episode 1494, reward total was -21.0. running mean: -19.831543093507527, timestamp: 2022-08-20 07:25:20.847049\n",
      "resetting env. episode 1495, reward total was -20.0. running mean: -19.83322766257245, timestamp: 2022-08-20 07:25:22.531065\n",
      "resetting env. episode 1496, reward total was -19.0. running mean: -19.82489538594673, timestamp: 2022-08-20 07:25:24.051081\n",
      "resetting env. episode 1497, reward total was -19.0. running mean: -19.81664643208726, timestamp: 2022-08-20 07:25:26.203106\n",
      "resetting env. episode 1498, reward total was -18.0. running mean: -19.798479967766387, timestamp: 2022-08-20 07:25:28.767135\n",
      "resetting env. episode 1499, reward total was -21.0. running mean: -19.810495168088725, timestamp: 2022-08-20 07:25:30.207156\n",
      "resetting env. episode 1500, reward total was -21.0. running mean: -19.82239021640784, timestamp: 2022-08-20 07:25:31.636691\n",
      "resetting env. episode 1501, reward total was -19.0. running mean: -19.814166314243764, timestamp: 2022-08-20 07:25:33.174712\n",
      "resetting env. episode 1502, reward total was -21.0. running mean: -19.826024651101328, timestamp: 2022-08-20 07:25:35.156730\n",
      "resetting env. episode 1503, reward total was -20.0. running mean: -19.827764404590315, timestamp: 2022-08-20 07:25:36.748751\n",
      "resetting env. episode 1504, reward total was -20.0. running mean: -19.829486760544413, timestamp: 2022-08-20 07:25:38.292771\n",
      "resetting env. episode 1505, reward total was -21.0. running mean: -19.84119189293897, timestamp: 2022-08-20 07:25:39.893788\n",
      "resetting env. episode 1506, reward total was -21.0. running mean: -19.85277997400958, timestamp: 2022-08-20 07:25:41.340801\n",
      "resetting env. episode 1507, reward total was -21.0. running mean: -19.864252174269485, timestamp: 2022-08-20 07:25:42.984826\n",
      "resetting env. episode 1508, reward total was -20.0. running mean: -19.86560965252679, timestamp: 2022-08-20 07:25:44.621842\n",
      "resetting env. episode 1509, reward total was -19.0. running mean: -19.85695355600152, timestamp: 2022-08-20 07:25:46.862865\n",
      "resetting env. episode 1510, reward total was -17.0. running mean: -19.828384020441508, timestamp: 2022-08-20 07:25:49.026891\n",
      "resetting env. episode 1511, reward total was -18.0. running mean: -19.810100180237093, timestamp: 2022-08-20 07:25:50.712911\n",
      "resetting env. episode 1512, reward total was -18.0. running mean: -19.791999178434722, timestamp: 2022-08-20 07:25:53.038940\n",
      "resetting env. episode 1513, reward total was -20.0. running mean: -19.794079186650375, timestamp: 2022-08-20 07:25:54.343956\n",
      "resetting env. episode 1514, reward total was -19.0. running mean: -19.786138394783872, timestamp: 2022-08-20 07:25:56.447981\n",
      "resetting env. episode 1515, reward total was -21.0. running mean: -19.798277010836035, timestamp: 2022-08-20 07:25:58.237997\n",
      "resetting env. episode 1516, reward total was -20.0. running mean: -19.800294240727673, timestamp: 2022-08-20 07:25:59.785019\n",
      "resetting env. episode 1517, reward total was -20.0. running mean: -19.802291298320394, timestamp: 2022-08-20 07:26:01.204032\n",
      "resetting env. episode 1518, reward total was -18.0. running mean: -19.78426838533719, timestamp: 2022-08-20 07:26:03.692064\n",
      "resetting env. episode 1519, reward total was -17.0. running mean: -19.756425701483817, timestamp: 2022-08-20 07:26:05.798088\n",
      "resetting env. episode 1520, reward total was -19.0. running mean: -19.74886144446898, timestamp: 2022-08-20 07:26:08.129113\n",
      "resetting env. episode 1521, reward total was -21.0. running mean: -19.76137283002429, timestamp: 2022-08-20 07:26:09.328130\n",
      "resetting env. episode 1522, reward total was -21.0. running mean: -19.773759101724046, timestamp: 2022-08-20 07:26:10.985146\n",
      "resetting env. episode 1523, reward total was -20.0. running mean: -19.776021510706805, timestamp: 2022-08-20 07:26:13.208175\n",
      "resetting env. episode 1524, reward total was -21.0. running mean: -19.78826129559974, timestamp: 2022-08-20 07:26:15.030200\n",
      "resetting env. episode 1525, reward total was -20.0. running mean: -19.79037868264374, timestamp: 2022-08-20 07:26:16.479213\n",
      "resetting env. episode 1526, reward total was -17.0. running mean: -19.762474895817306, timestamp: 2022-08-20 07:26:18.660237\n",
      "resetting env. episode 1527, reward total was -21.0. running mean: -19.774850146859134, timestamp: 2022-08-20 07:26:20.326253\n",
      "resetting env. episode 1528, reward total was -18.0. running mean: -19.75710164539054, timestamp: 2022-08-20 07:26:22.647281\n",
      "resetting env. episode 1529, reward total was -17.0. running mean: -19.729530628936637, timestamp: 2022-08-20 07:26:25.020311\n",
      "resetting env. episode 1530, reward total was -18.0. running mean: -19.71223532264727, timestamp: 2022-08-20 07:26:27.127333\n",
      "resetting env. episode 1531, reward total was -20.0. running mean: -19.715112969420797, timestamp: 2022-08-20 07:26:29.280359\n",
      "resetting env. episode 1532, reward total was -19.0. running mean: -19.70796183972659, timestamp: 2022-08-20 07:26:31.224384\n",
      "resetting env. episode 1533, reward total was -21.0. running mean: -19.720882221329326, timestamp: 2022-08-20 07:26:33.723413\n",
      "resetting env. episode 1534, reward total was -18.0. running mean: -19.70367339911603, timestamp: 2022-08-20 07:26:36.158440\n",
      "resetting env. episode 1535, reward total was -19.0. running mean: -19.69663666512487, timestamp: 2022-08-20 07:26:38.163461\n",
      "resetting env. episode 1536, reward total was -19.0. running mean: -19.689670298473622, timestamp: 2022-08-20 07:26:40.170486\n",
      "resetting env. episode 1537, reward total was -17.0. running mean: -19.662773595488886, timestamp: 2022-08-20 07:26:42.200512\n",
      "resetting env. episode 1538, reward total was -20.0. running mean: -19.666145859533998, timestamp: 2022-08-20 07:26:44.042530\n",
      "resetting env. episode 1539, reward total was -21.0. running mean: -19.67948440093866, timestamp: 2022-08-20 07:26:45.734550\n",
      "resetting env. episode 1540, reward total was -17.0. running mean: -19.652689556929275, timestamp: 2022-08-20 07:26:47.963574\n",
      "resetting env. episode 1541, reward total was -18.0. running mean: -19.636162661359982, timestamp: 2022-08-20 07:26:49.901599\n",
      "resetting env. episode 1542, reward total was -19.0. running mean: -19.629801034746382, timestamp: 2022-08-20 07:26:51.747620\n",
      "resetting env. episode 1543, reward total was -19.0. running mean: -19.623503024398918, timestamp: 2022-08-20 07:26:53.417636\n",
      "resetting env. episode 1544, reward total was -20.0. running mean: -19.627267994154927, timestamp: 2022-08-20 07:26:55.649663\n",
      "resetting env. episode 1545, reward total was -17.0. running mean: -19.600995314213378, timestamp: 2022-08-20 07:26:57.720687\n",
      "resetting env. episode 1546, reward total was -21.0. running mean: -19.614985361071245, timestamp: 2022-08-20 07:26:59.269706\n",
      "resetting env. episode 1547, reward total was -19.0. running mean: -19.608835507460533, timestamp: 2022-08-20 07:27:01.268733\n",
      "resetting env. episode 1548, reward total was -21.0. running mean: -19.62274715238593, timestamp: 2022-08-20 07:27:02.672746\n",
      "resetting env. episode 1549, reward total was -18.0. running mean: -19.60651968086207, timestamp: 2022-08-20 07:27:04.395774\n",
      "resetting env. episode 1550, reward total was -20.0. running mean: -19.61045448405345, timestamp: 2022-08-20 07:27:06.466786\n",
      "resetting env. episode 1551, reward total was -19.0. running mean: -19.604349939212916, timestamp: 2022-08-20 07:27:08.253807\n",
      "resetting env. episode 1552, reward total was -20.0. running mean: -19.608306439820787, timestamp: 2022-08-20 07:27:09.896832\n",
      "resetting env. episode 1553, reward total was -20.0. running mean: -19.612223375422577, timestamp: 2022-08-20 07:27:11.376844\n",
      "resetting env. episode 1554, reward total was -21.0. running mean: -19.62610114166835, timestamp: 2022-08-20 07:27:12.871863\n",
      "resetting env. episode 1555, reward total was -18.0. running mean: -19.609840130251666, timestamp: 2022-08-20 07:27:14.637883\n",
      "resetting env. episode 1556, reward total was -17.0. running mean: -19.58374172894915, timestamp: 2022-08-20 07:27:16.800910\n",
      "resetting env. episode 1557, reward total was -18.0. running mean: -19.567904311659657, timestamp: 2022-08-20 07:27:18.460924\n",
      "resetting env. episode 1558, reward total was -21.0. running mean: -19.58222526854306, timestamp: 2022-08-20 07:27:19.982946\n",
      "resetting env. episode 1559, reward total was -21.0. running mean: -19.59640301585763, timestamp: 2022-08-20 07:27:21.266956\n",
      "resetting env. episode 1560, reward total was -17.0. running mean: -19.570438985699052, timestamp: 2022-08-20 07:27:23.448983\n",
      "resetting env. episode 1561, reward total was -18.0. running mean: -19.55473459584206, timestamp: 2022-08-20 07:27:25.012002\n",
      "resetting env. episode 1562, reward total was -21.0. running mean: -19.56918724988364, timestamp: 2022-08-20 07:27:26.453016\n",
      "resetting env. episode 1563, reward total was -21.0. running mean: -19.583495377384804, timestamp: 2022-08-20 07:27:27.939038\n",
      "resetting env. episode 1564, reward total was -17.0. running mean: -19.557660423610958, timestamp: 2022-08-20 07:27:30.369067\n",
      "resetting env. episode 1565, reward total was -20.0. running mean: -19.56208381937485, timestamp: 2022-08-20 07:27:31.910079\n",
      "resetting env. episode 1566, reward total was -20.0. running mean: -19.5664629811811, timestamp: 2022-08-20 07:27:33.869102\n",
      "resetting env. episode 1567, reward total was -18.0. running mean: -19.550798351369288, timestamp: 2022-08-20 07:27:35.871127\n",
      "resetting env. episode 1568, reward total was -20.0. running mean: -19.555290367855594, timestamp: 2022-08-20 07:27:37.357144\n",
      "resetting env. episode 1569, reward total was -15.0. running mean: -19.509737464177036, timestamp: 2022-08-20 07:27:39.758170\n",
      "resetting env. episode 1570, reward total was -21.0. running mean: -19.524640089535268, timestamp: 2022-08-20 07:27:41.106187\n",
      "resetting env. episode 1571, reward total was -21.0. running mean: -19.539393688639915, timestamp: 2022-08-20 07:27:42.447202\n",
      "resetting env. episode 1572, reward total was -21.0. running mean: -19.553999751753516, timestamp: 2022-08-20 07:27:43.874218\n",
      "resetting env. episode 1573, reward total was -17.0. running mean: -19.528459754235982, timestamp: 2022-08-20 07:27:46.118243\n",
      "resetting env. episode 1574, reward total was -20.0. running mean: -19.53317515669362, timestamp: 2022-08-20 07:27:47.657265\n",
      "resetting env. episode 1575, reward total was -16.0. running mean: -19.497843405126684, timestamp: 2022-08-20 07:27:49.842288\n",
      "resetting env. episode 1576, reward total was -19.0. running mean: -19.492864971075416, timestamp: 2022-08-20 07:27:51.532306\n",
      "resetting env. episode 1577, reward total was -21.0. running mean: -19.507936321364664, timestamp: 2022-08-20 07:27:53.191327\n",
      "resetting env. episode 1578, reward total was -15.0. running mean: -19.462856958151015, timestamp: 2022-08-20 07:27:55.437353\n",
      "resetting env. episode 1579, reward total was -21.0. running mean: -19.478228388569505, timestamp: 2022-08-20 07:27:57.220372\n",
      "resetting env. episode 1580, reward total was -19.0. running mean: -19.473446104683813, timestamp: 2022-08-20 07:27:59.165395\n",
      "resetting env. episode 1581, reward total was -21.0. running mean: -19.488711643636975, timestamp: 2022-08-20 07:28:00.373408\n",
      "resetting env. episode 1582, reward total was -21.0. running mean: -19.503824527200607, timestamp: 2022-08-20 07:28:02.435436\n",
      "resetting env. episode 1583, reward total was -19.0. running mean: -19.498786281928602, timestamp: 2022-08-20 07:28:04.561458\n",
      "resetting env. episode 1584, reward total was -19.0. running mean: -19.493798419109318, timestamp: 2022-08-20 07:28:06.314478\n",
      "resetting env. episode 1585, reward total was -20.0. running mean: -19.498860434918225, timestamp: 2022-08-20 07:28:07.575492\n",
      "resetting env. episode 1586, reward total was -19.0. running mean: -19.493871830569045, timestamp: 2022-08-20 07:28:09.513515\n",
      "resetting env. episode 1587, reward total was -20.0. running mean: -19.498933112263355, timestamp: 2022-08-20 07:28:11.135535\n",
      "resetting env. episode 1588, reward total was -20.0. running mean: -19.50394378114072, timestamp: 2022-08-20 07:28:12.703556\n",
      "resetting env. episode 1589, reward total was -20.0. running mean: -19.508904343329313, timestamp: 2022-08-20 07:28:14.566576\n",
      "resetting env. episode 1590, reward total was -21.0. running mean: -19.52381529989602, timestamp: 2022-08-20 07:28:16.092593\n",
      "resetting env. episode 1591, reward total was -21.0. running mean: -19.53857714689706, timestamp: 2022-08-20 07:28:17.802617\n",
      "resetting env. episode 1592, reward total was -21.0. running mean: -19.553191375428092, timestamp: 2022-08-20 07:28:19.323631\n",
      "resetting env. episode 1593, reward total was -20.0. running mean: -19.55765946167381, timestamp: 2022-08-20 07:28:20.479643\n",
      "resetting env. episode 1594, reward total was -17.0. running mean: -19.532082867057074, timestamp: 2022-08-20 07:28:22.804675\n",
      "resetting env. episode 1595, reward total was -21.0. running mean: -19.546762038386504, timestamp: 2022-08-20 07:28:25.007693\n",
      "resetting env. episode 1596, reward total was -17.0. running mean: -19.52129441800264, timestamp: 2022-08-20 07:28:27.087718\n",
      "resetting env. episode 1597, reward total was -21.0. running mean: -19.536081473822613, timestamp: 2022-08-20 07:28:29.047741\n",
      "resetting env. episode 1598, reward total was -20.0. running mean: -19.540720659084386, timestamp: 2022-08-20 07:28:30.207755\n",
      "resetting env. episode 1599, reward total was -16.0. running mean: -19.505313452493542, timestamp: 2022-08-20 07:28:32.651784\n",
      "resetting env. episode 1600, reward total was -19.0. running mean: -19.500260317968607, timestamp: 2022-08-20 07:28:34.549805\n",
      "resetting env. episode 1601, reward total was -21.0. running mean: -19.515257714788923, timestamp: 2022-08-20 07:28:36.066825\n",
      "resetting env. episode 1602, reward total was -21.0. running mean: -19.530105137641034, timestamp: 2022-08-20 07:28:37.746844\n",
      "resetting env. episode 1603, reward total was -21.0. running mean: -19.544804086264623, timestamp: 2022-08-20 07:28:39.434868\n",
      "resetting env. episode 1604, reward total was -17.0. running mean: -19.519356045401977, timestamp: 2022-08-20 07:28:41.646888\n",
      "resetting env. episode 1605, reward total was -17.0. running mean: -19.49416248494796, timestamp: 2022-08-20 07:28:43.091904\n",
      "resetting env. episode 1606, reward total was -20.0. running mean: -19.49922086009848, timestamp: 2022-08-20 07:28:44.953929\n",
      "resetting env. episode 1607, reward total was -21.0. running mean: -19.514228651497493, timestamp: 2022-08-20 07:28:46.397942\n",
      "resetting env. episode 1608, reward total was -19.0. running mean: -19.50908636498252, timestamp: 2022-08-20 07:28:48.680970\n",
      "resetting env. episode 1609, reward total was -19.0. running mean: -19.503995501332696, timestamp: 2022-08-20 07:28:50.939995\n",
      "resetting env. episode 1610, reward total was -20.0. running mean: -19.508955546319367, timestamp: 2022-08-20 07:28:52.517014\n",
      "resetting env. episode 1611, reward total was -18.0. running mean: -19.493865990856172, timestamp: 2022-08-20 07:28:54.539038\n",
      "resetting env. episode 1612, reward total was -19.0. running mean: -19.48892733094761, timestamp: 2022-08-20 07:28:56.254058\n",
      "resetting env. episode 1613, reward total was -18.0. running mean: -19.474038057638133, timestamp: 2022-08-20 07:28:58.301082\n",
      "resetting env. episode 1614, reward total was -19.0. running mean: -19.469297677061753, timestamp: 2022-08-20 07:29:00.048103\n",
      "resetting env. episode 1615, reward total was -18.0. running mean: -19.454604700291135, timestamp: 2022-08-20 07:29:02.369127\n",
      "resetting env. episode 1616, reward total was -21.0. running mean: -19.470058653288223, timestamp: 2022-08-20 07:29:03.845147\n",
      "resetting env. episode 1617, reward total was -17.0. running mean: -19.445358066755343, timestamp: 2022-08-20 07:29:05.831167\n",
      "resetting env. episode 1618, reward total was -21.0. running mean: -19.46090448608779, timestamp: 2022-08-20 07:29:07.636191\n",
      "resetting env. episode 1619, reward total was -13.0. running mean: -19.39629544122691, timestamp: 2022-08-20 07:29:10.274221\n",
      "resetting env. episode 1620, reward total was -17.0. running mean: -19.372332486814642, timestamp: 2022-08-20 07:29:12.536245\n",
      "resetting env. episode 1621, reward total was -21.0. running mean: -19.388609161946498, timestamp: 2022-08-20 07:29:14.319269\n",
      "resetting env. episode 1622, reward total was -15.0. running mean: -19.34472307032703, timestamp: 2022-08-20 07:29:16.494300\n",
      "resetting env. episode 1623, reward total was -19.0. running mean: -19.341275839623762, timestamp: 2022-08-20 07:29:18.408314\n",
      "resetting env. episode 1624, reward total was -21.0. running mean: -19.357863081227524, timestamp: 2022-08-20 07:29:20.127336\n",
      "resetting env. episode 1625, reward total was -20.0. running mean: -19.364284450415248, timestamp: 2022-08-20 07:29:21.811353\n",
      "resetting env. episode 1626, reward total was -18.0. running mean: -19.350641605911093, timestamp: 2022-08-20 07:29:23.544377\n",
      "resetting env. episode 1627, reward total was -17.0. running mean: -19.327135189851983, timestamp: 2022-08-20 07:29:25.999403\n",
      "resetting env. episode 1628, reward total was -18.0. running mean: -19.313863837953463, timestamp: 2022-08-20 07:29:27.689423\n",
      "resetting env. episode 1629, reward total was -20.0. running mean: -19.32072519957393, timestamp: 2022-08-20 07:29:29.215441\n",
      "resetting env. episode 1630, reward total was -21.0. running mean: -19.33751794757819, timestamp: 2022-08-20 07:29:30.769458\n",
      "resetting env. episode 1631, reward total was -21.0. running mean: -19.354142768102406, timestamp: 2022-08-20 07:29:32.812484\n",
      "resetting env. episode 1632, reward total was -20.0. running mean: -19.360601340421383, timestamp: 2022-08-20 07:29:34.572502\n",
      "resetting env. episode 1633, reward total was -21.0. running mean: -19.37699532701717, timestamp: 2022-08-20 07:29:35.941517\n",
      "resetting env. episode 1634, reward total was -17.0. running mean: -19.353225373746998, timestamp: 2022-08-20 07:29:38.181546\n",
      "resetting env. episode 1635, reward total was -20.0. running mean: -19.359693120009528, timestamp: 2022-08-20 07:29:39.919565\n",
      "resetting env. episode 1636, reward total was -20.0. running mean: -19.366096188809433, timestamp: 2022-08-20 07:29:41.554585\n",
      "resetting env. episode 1637, reward total was -21.0. running mean: -19.382435226921338, timestamp: 2022-08-20 07:29:43.245608\n",
      "resetting env. episode 1638, reward total was -19.0. running mean: -19.378610874652125, timestamp: 2022-08-20 07:29:45.275626\n",
      "resetting env. episode 1639, reward total was -18.0. running mean: -19.364824765905603, timestamp: 2022-08-20 07:29:47.228650\n",
      "resetting env. episode 1640, reward total was -21.0. running mean: -19.381176518246548, timestamp: 2022-08-20 07:29:48.567667\n",
      "resetting env. episode 1641, reward total was -21.0. running mean: -19.397364753064082, timestamp: 2022-08-20 07:29:49.816678\n",
      "resetting env. episode 1642, reward total was -20.0. running mean: -19.40339110553344, timestamp: 2022-08-20 07:29:51.511702\n",
      "resetting env. episode 1643, reward total was -19.0. running mean: -19.399357194478107, timestamp: 2022-08-20 07:29:53.174723\n",
      "resetting env. episode 1644, reward total was -15.0. running mean: -19.355363622533325, timestamp: 2022-08-20 07:29:55.252745\n",
      "resetting env. episode 1645, reward total was -21.0. running mean: -19.37180998630799, timestamp: 2022-08-20 07:29:56.446760\n",
      "resetting env. episode 1646, reward total was -19.0. running mean: -19.368091886444912, timestamp: 2022-08-20 07:29:57.881775\n",
      "resetting env. episode 1647, reward total was -19.0. running mean: -19.364410967580465, timestamp: 2022-08-20 07:29:59.502794\n",
      "resetting env. episode 1648, reward total was -20.0. running mean: -19.37076685790466, timestamp: 2022-08-20 07:30:00.927811\n",
      "resetting env. episode 1649, reward total was -15.0. running mean: -19.32705918932561, timestamp: 2022-08-20 07:30:03.256841\n",
      "resetting env. episode 1650, reward total was -21.0. running mean: -19.343788597432354, timestamp: 2022-08-20 07:30:04.845857\n",
      "resetting env. episode 1651, reward total was -19.0. running mean: -19.340350711458033, timestamp: 2022-08-20 07:30:06.679883\n",
      "resetting env. episode 1652, reward total was -20.0. running mean: -19.34694720434345, timestamp: 2022-08-20 07:30:08.033895\n",
      "resetting env. episode 1653, reward total was -21.0. running mean: -19.363477732300016, timestamp: 2022-08-20 07:30:09.716911\n",
      "resetting env. episode 1654, reward total was -18.0. running mean: -19.349842954977014, timestamp: 2022-08-20 07:30:11.742941\n",
      "resetting env. episode 1655, reward total was -17.0. running mean: -19.326344525427245, timestamp: 2022-08-20 07:30:13.576957\n",
      "resetting env. episode 1656, reward total was -17.0. running mean: -19.303081080172973, timestamp: 2022-08-20 07:30:15.948986\n",
      "resetting env. episode 1657, reward total was -16.0. running mean: -19.270050269371243, timestamp: 2022-08-20 07:30:18.036014\n",
      "resetting env. episode 1658, reward total was -18.0. running mean: -19.25734976667753, timestamp: 2022-08-20 07:30:19.994033\n",
      "resetting env. episode 1659, reward total was -21.0. running mean: -19.274776269010758, timestamp: 2022-08-20 07:30:21.123045\n",
      "resetting env. episode 1660, reward total was -20.0. running mean: -19.28202850632065, timestamp: 2022-08-20 07:30:22.895068\n",
      "resetting env. episode 1661, reward total was -20.0. running mean: -19.289208221257443, timestamp: 2022-08-20 07:30:24.584087\n",
      "resetting env. episode 1662, reward total was -15.0. running mean: -19.24631613904487, timestamp: 2022-08-20 07:30:26.844119\n",
      "resetting env. episode 1663, reward total was -18.0. running mean: -19.23385297765442, timestamp: 2022-08-20 07:30:28.549134\n",
      "resetting env. episode 1664, reward total was -21.0. running mean: -19.251514447877874, timestamp: 2022-08-20 07:30:30.135151\n",
      "resetting env. episode 1665, reward total was -20.0. running mean: -19.258999303399094, timestamp: 2022-08-20 07:30:32.002175\n",
      "resetting env. episode 1666, reward total was -21.0. running mean: -19.276409310365104, timestamp: 2022-08-20 07:30:33.733195\n",
      "resetting env. episode 1667, reward total was -19.0. running mean: -19.273645217261453, timestamp: 2022-08-20 07:30:35.859217\n",
      "resetting env. episode 1668, reward total was -19.0. running mean: -19.27090876508884, timestamp: 2022-08-20 07:30:37.694239\n",
      "resetting env. episode 1669, reward total was -17.0. running mean: -19.248199677437952, timestamp: 2022-08-20 07:30:39.767267\n",
      "resetting env. episode 1670, reward total was -18.0. running mean: -19.235717680663573, timestamp: 2022-08-20 07:30:42.010292\n",
      "resetting env. episode 1671, reward total was -20.0. running mean: -19.243360503856938, timestamp: 2022-08-20 07:30:43.519311\n",
      "resetting env. episode 1672, reward total was -19.0. running mean: -19.24092689881837, timestamp: 2022-08-20 07:30:45.503330\n",
      "resetting env. episode 1673, reward total was -20.0. running mean: -19.248517629830186, timestamp: 2022-08-20 07:30:47.027351\n",
      "resetting env. episode 1674, reward total was -16.0. running mean: -19.216032453531884, timestamp: 2022-08-20 07:30:49.416379\n",
      "resetting env. episode 1675, reward total was -16.0. running mean: -19.183872128996565, timestamp: 2022-08-20 07:30:51.749407\n",
      "resetting env. episode 1676, reward total was -21.0. running mean: -19.2020334077066, timestamp: 2022-08-20 07:30:53.633428\n",
      "resetting env. episode 1677, reward total was -19.0. running mean: -19.200013073629535, timestamp: 2022-08-20 07:30:55.690452\n",
      "resetting env. episode 1678, reward total was -18.0. running mean: -19.188012942893238, timestamp: 2022-08-20 07:30:57.526472\n",
      "resetting env. episode 1679, reward total was -17.0. running mean: -19.16613281346431, timestamp: 2022-08-20 07:30:59.367496\n",
      "resetting env. episode 1680, reward total was -19.0. running mean: -19.164471485329667, timestamp: 2022-08-20 07:31:01.239514\n",
      "resetting env. episode 1681, reward total was -21.0. running mean: -19.18282677047637, timestamp: 2022-08-20 07:31:03.068536\n",
      "resetting env. episode 1682, reward total was -19.0. running mean: -19.180998502771608, timestamp: 2022-08-20 07:31:05.109564\n",
      "resetting env. episode 1683, reward total was -20.0. running mean: -19.18918851774389, timestamp: 2022-08-20 07:31:06.956584\n",
      "resetting env. episode 1684, reward total was -20.0. running mean: -19.19729663256645, timestamp: 2022-08-20 07:31:08.713603\n",
      "resetting env. episode 1685, reward total was -21.0. running mean: -19.215323666240785, timestamp: 2022-08-20 07:31:10.575628\n",
      "resetting env. episode 1686, reward total was -19.0. running mean: -19.21317042957838, timestamp: 2022-08-20 07:31:12.379645\n",
      "resetting env. episode 1687, reward total was -19.0. running mean: -19.2110387252826, timestamp: 2022-08-20 07:31:13.942664\n",
      "resetting env. episode 1688, reward total was -20.0. running mean: -19.218928338029773, timestamp: 2022-08-20 07:31:15.942687\n",
      "resetting env. episode 1689, reward total was -21.0. running mean: -19.236739054649476, timestamp: 2022-08-20 07:31:17.905710\n",
      "resetting env. episode 1690, reward total was -20.0. running mean: -19.24437166410298, timestamp: 2022-08-20 07:31:19.622731\n",
      "resetting env. episode 1691, reward total was -20.0. running mean: -19.25192794746195, timestamp: 2022-08-20 07:31:21.543755\n",
      "resetting env. episode 1692, reward total was -19.0. running mean: -19.249408667987332, timestamp: 2022-08-20 07:31:23.435780\n",
      "resetting env. episode 1693, reward total was -17.0. running mean: -19.22691458130746, timestamp: 2022-08-20 07:31:25.571807\n",
      "resetting env. episode 1694, reward total was -19.0. running mean: -19.224645435494388, timestamp: 2022-08-20 07:31:27.620826\n",
      "resetting env. episode 1695, reward total was -21.0. running mean: -19.242398981139445, timestamp: 2022-08-20 07:31:29.198844\n",
      "resetting env. episode 1696, reward total was -20.0. running mean: -19.24997499132805, timestamp: 2022-08-20 07:31:30.923863\n",
      "resetting env. episode 1697, reward total was -16.0. running mean: -19.217475241414768, timestamp: 2022-08-20 07:31:33.304896\n",
      "resetting env. episode 1698, reward total was -16.0. running mean: -19.18530048900062, timestamp: 2022-08-20 07:31:35.888929\n",
      "resetting env. episode 1699, reward total was -18.0. running mean: -19.173447484110614, timestamp: 2022-08-20 07:31:37.720944\n",
      "resetting env. episode 1700, reward total was -20.0. running mean: -19.181713009269508, timestamp: 2022-08-20 07:31:39.313962\n",
      "resetting env. episode 1701, reward total was -20.0. running mean: -19.189895879176813, timestamp: 2022-08-20 07:31:41.400988\n",
      "resetting env. episode 1702, reward total was -21.0. running mean: -19.207996920385046, timestamp: 2022-08-20 07:31:43.726018\n",
      "resetting env. episode 1703, reward total was -18.0. running mean: -19.195916951181196, timestamp: 2022-08-20 07:31:45.964041\n",
      "resetting env. episode 1704, reward total was -20.0. running mean: -19.203957781669384, timestamp: 2022-08-20 07:31:47.734067\n",
      "resetting env. episode 1705, reward total was -21.0. running mean: -19.22191820385269, timestamp: 2022-08-20 07:31:49.386088\n",
      "resetting env. episode 1706, reward total was -19.0. running mean: -19.219699021814165, timestamp: 2022-08-20 07:31:51.451111\n",
      "resetting env. episode 1707, reward total was -19.0. running mean: -19.217502031596023, timestamp: 2022-08-20 07:31:53.263130\n",
      "resetting env. episode 1708, reward total was -19.0. running mean: -19.215327011280063, timestamp: 2022-08-20 07:31:55.165151\n",
      "resetting env. episode 1709, reward total was -16.0. running mean: -19.183173741167263, timestamp: 2022-08-20 07:31:56.987174\n",
      "resetting env. episode 1710, reward total was -20.0. running mean: -19.19134200375559, timestamp: 2022-08-20 07:31:58.708197\n",
      "resetting env. episode 1711, reward total was -19.0. running mean: -19.189428583718037, timestamp: 2022-08-20 07:32:00.606215\n",
      "resetting env. episode 1712, reward total was -20.0. running mean: -19.197534297880857, timestamp: 2022-08-20 07:32:02.509240\n",
      "resetting env. episode 1713, reward total was -19.0. running mean: -19.19555895490205, timestamp: 2022-08-20 07:32:05.033267\n",
      "resetting env. episode 1714, reward total was -19.0. running mean: -19.19360336535303, timestamp: 2022-08-20 07:32:06.978293\n",
      "resetting env. episode 1715, reward total was -20.0. running mean: -19.2016673316995, timestamp: 2022-08-20 07:32:08.744309\n",
      "resetting env. episode 1716, reward total was -18.0. running mean: -19.189650658382504, timestamp: 2022-08-20 07:32:10.529332\n",
      "resetting env. episode 1717, reward total was -17.0. running mean: -19.167754151798682, timestamp: 2022-08-20 07:32:12.381364\n",
      "resetting env. episode 1718, reward total was -19.0. running mean: -19.166076610280697, timestamp: 2022-08-20 07:32:14.270378\n",
      "resetting env. episode 1719, reward total was -21.0. running mean: -19.18441584417789, timestamp: 2022-08-20 07:32:16.023398\n",
      "resetting env. episode 1720, reward total was -16.0. running mean: -19.152571685736113, timestamp: 2022-08-20 07:32:18.559426\n",
      "resetting env. episode 1721, reward total was -20.0. running mean: -19.161045968878753, timestamp: 2022-08-20 07:32:20.527457\n",
      "resetting env. episode 1722, reward total was -20.0. running mean: -19.169435509189963, timestamp: 2022-08-20 07:32:22.277473\n",
      "resetting env. episode 1723, reward total was -20.0. running mean: -19.17774115409806, timestamp: 2022-08-20 07:32:24.178492\n",
      "resetting env. episode 1724, reward total was -19.0. running mean: -19.175963742557084, timestamp: 2022-08-20 07:32:26.149515\n",
      "resetting env. episode 1725, reward total was -20.0. running mean: -19.184204105131514, timestamp: 2022-08-20 07:32:27.820536\n",
      "resetting env. episode 1726, reward total was -19.0. running mean: -19.1823620640802, timestamp: 2022-08-20 07:32:29.667558\n",
      "resetting env. episode 1727, reward total was -16.0. running mean: -19.150538443439398, timestamp: 2022-08-20 07:32:32.136589\n",
      "resetting env. episode 1728, reward total was -18.0. running mean: -19.139033059005005, timestamp: 2022-08-20 07:32:34.410613\n",
      "resetting env. episode 1729, reward total was -18.0. running mean: -19.127642728414955, timestamp: 2022-08-20 07:32:36.528639\n",
      "resetting env. episode 1730, reward total was -21.0. running mean: -19.146366301130804, timestamp: 2022-08-20 07:32:38.347661\n",
      "resetting env. episode 1731, reward total was -19.0. running mean: -19.144902638119497, timestamp: 2022-08-20 07:32:39.835679\n",
      "resetting env. episode 1732, reward total was -19.0. running mean: -19.143453611738302, timestamp: 2022-08-20 07:32:41.573700\n",
      "resetting env. episode 1733, reward total was -21.0. running mean: -19.16201907562092, timestamp: 2022-08-20 07:32:43.154720\n",
      "resetting env. episode 1734, reward total was -21.0. running mean: -19.18039888486471, timestamp: 2022-08-20 07:32:44.373730\n",
      "resetting env. episode 1735, reward total was -21.0. running mean: -19.198594896016065, timestamp: 2022-08-20 07:32:46.126751\n",
      "resetting env. episode 1736, reward total was -20.0. running mean: -19.206608947055905, timestamp: 2022-08-20 07:32:47.375769\n",
      "resetting env. episode 1737, reward total was -19.0. running mean: -19.20454285758535, timestamp: 2022-08-20 07:32:49.127786\n",
      "resetting env. episode 1738, reward total was -17.0. running mean: -19.182497429009498, timestamp: 2022-08-20 07:32:50.880808\n",
      "resetting env. episode 1739, reward total was -21.0. running mean: -19.200672454719403, timestamp: 2022-08-20 07:32:52.009826\n",
      "resetting env. episode 1740, reward total was -17.0. running mean: -19.17866573017221, timestamp: 2022-08-20 07:32:54.548849\n",
      "resetting env. episode 1741, reward total was -21.0. running mean: -19.196879072870487, timestamp: 2022-08-20 07:32:55.877867\n",
      "resetting env. episode 1742, reward total was -21.0. running mean: -19.214910282141783, timestamp: 2022-08-20 07:32:57.060885\n",
      "resetting env. episode 1743, reward total was -20.0. running mean: -19.222761179320365, timestamp: 2022-08-20 07:32:58.665901\n",
      "resetting env. episode 1744, reward total was -20.0. running mean: -19.23053356752716, timestamp: 2022-08-20 07:33:00.163919\n",
      "resetting env. episode 1745, reward total was -17.0. running mean: -19.20822823185189, timestamp: 2022-08-20 07:33:02.126942\n",
      "resetting env. episode 1746, reward total was -21.0. running mean: -19.22614594953337, timestamp: 2022-08-20 07:33:03.422955\n",
      "resetting env. episode 1747, reward total was -20.0. running mean: -19.233884490038037, timestamp: 2022-08-20 07:33:05.214981\n",
      "resetting env. episode 1748, reward total was -20.0. running mean: -19.241545645137656, timestamp: 2022-08-20 07:33:06.796999\n",
      "resetting env. episode 1749, reward total was -21.0. running mean: -19.259130188686278, timestamp: 2022-08-20 07:33:08.268015\n",
      "resetting env. episode 1750, reward total was -21.0. running mean: -19.276538886799415, timestamp: 2022-08-20 07:33:09.366025\n",
      "resetting env. episode 1751, reward total was -17.0. running mean: -19.253773497931423, timestamp: 2022-08-20 07:33:11.862058\n",
      "resetting env. episode 1752, reward total was -20.0. running mean: -19.261235762952108, timestamp: 2022-08-20 07:33:13.731077\n",
      "resetting env. episode 1753, reward total was -21.0. running mean: -19.278623405322588, timestamp: 2022-08-20 07:33:14.946094\n",
      "resetting env. episode 1754, reward total was -17.0. running mean: -19.255837171269363, timestamp: 2022-08-20 07:33:17.297122\n",
      "resetting env. episode 1755, reward total was -20.0. running mean: -19.26327879955667, timestamp: 2022-08-20 07:33:18.886144\n",
      "resetting env. episode 1756, reward total was -21.0. running mean: -19.280646011561103, timestamp: 2022-08-20 07:33:19.992151\n",
      "resetting env. episode 1757, reward total was -15.0. running mean: -19.23783955144549, timestamp: 2022-08-20 07:33:22.088176\n",
      "resetting env. episode 1758, reward total was -19.0. running mean: -19.235461155931034, timestamp: 2022-08-20 07:33:23.719198\n",
      "resetting env. episode 1759, reward total was -21.0. running mean: -19.253106544371725, timestamp: 2022-08-20 07:33:25.829224\n",
      "resetting env. episode 1760, reward total was -20.0. running mean: -19.260575478928008, timestamp: 2022-08-20 07:33:27.031237\n",
      "resetting env. episode 1761, reward total was -20.0. running mean: -19.267969724138727, timestamp: 2022-08-20 07:33:29.443268\n",
      "resetting env. episode 1762, reward total was -18.0. running mean: -19.255290026897338, timestamp: 2022-08-20 07:33:31.939293\n",
      "resetting env. episode 1763, reward total was -20.0. running mean: -19.262737126628362, timestamp: 2022-08-20 07:33:33.265310\n",
      "resetting env. episode 1764, reward total was -18.0. running mean: -19.25010975536208, timestamp: 2022-08-20 07:33:35.321332\n",
      "resetting env. episode 1765, reward total was -20.0. running mean: -19.257608657808458, timestamp: 2022-08-20 07:33:37.014353\n",
      "resetting env. episode 1766, reward total was -18.0. running mean: -19.24503257123037, timestamp: 2022-08-20 07:33:38.735377\n",
      "resetting env. episode 1767, reward total was -20.0. running mean: -19.252582245518067, timestamp: 2022-08-20 07:33:40.674398\n",
      "resetting env. episode 1768, reward total was -20.0. running mean: -19.260056423062885, timestamp: 2022-08-20 07:33:42.588418\n",
      "resetting env. episode 1769, reward total was -21.0. running mean: -19.277455858832255, timestamp: 2022-08-20 07:33:43.824432\n",
      "resetting env. episode 1770, reward total was -20.0. running mean: -19.284681300243932, timestamp: 2022-08-20 07:33:45.138447\n",
      "resetting env. episode 1771, reward total was -19.0. running mean: -19.281834487241493, timestamp: 2022-08-20 07:33:47.649479\n",
      "resetting env. episode 1772, reward total was -20.0. running mean: -19.28901614236908, timestamp: 2022-08-20 07:33:49.276497\n",
      "resetting env. episode 1773, reward total was -19.0. running mean: -19.28612598094539, timestamp: 2022-08-20 07:33:51.437528\n",
      "resetting env. episode 1774, reward total was -21.0. running mean: -19.303264721135935, timestamp: 2022-08-20 07:33:52.546537\n",
      "resetting env. episode 1775, reward total was -21.0. running mean: -19.320232073924576, timestamp: 2022-08-20 07:33:54.442561\n",
      "resetting env. episode 1776, reward total was -19.0. running mean: -19.31702975318533, timestamp: 2022-08-20 07:33:56.469583\n",
      "resetting env. episode 1777, reward total was -19.0. running mean: -19.31385945565348, timestamp: 2022-08-20 07:33:58.461606\n",
      "resetting env. episode 1778, reward total was -20.0. running mean: -19.32072086109694, timestamp: 2022-08-20 07:34:00.380630\n",
      "resetting env. episode 1779, reward total was -19.0. running mean: -19.31751365248597, timestamp: 2022-08-20 07:34:02.090652\n",
      "resetting env. episode 1780, reward total was -19.0. running mean: -19.31433851596111, timestamp: 2022-08-20 07:34:03.986672\n",
      "resetting env. episode 1781, reward total was -21.0. running mean: -19.3311951308015, timestamp: 2022-08-20 07:34:05.668694\n",
      "resetting env. episode 1782, reward total was -20.0. running mean: -19.337883179493485, timestamp: 2022-08-20 07:34:07.547713\n",
      "resetting env. episode 1783, reward total was -19.0. running mean: -19.33450434769855, timestamp: 2022-08-20 07:34:09.337739\n",
      "resetting env. episode 1784, reward total was -21.0. running mean: -19.351159304221568, timestamp: 2022-08-20 07:34:11.375760\n",
      "resetting env. episode 1785, reward total was -21.0. running mean: -19.36764771117935, timestamp: 2022-08-20 07:34:12.494772\n",
      "resetting env. episode 1786, reward total was -20.0. running mean: -19.373971234067557, timestamp: 2022-08-20 07:34:14.149794\n",
      "resetting env. episode 1787, reward total was -19.0. running mean: -19.370231521726883, timestamp: 2022-08-20 07:34:15.963814\n",
      "resetting env. episode 1788, reward total was -19.0. running mean: -19.366529206509615, timestamp: 2022-08-20 07:34:17.928836\n",
      "resetting env. episode 1789, reward total was -14.0. running mean: -19.31286391444452, timestamp: 2022-08-20 07:34:20.104860\n",
      "resetting env. episode 1790, reward total was -21.0. running mean: -19.329735275300077, timestamp: 2022-08-20 07:34:21.876881\n",
      "resetting env. episode 1791, reward total was -19.0. running mean: -19.32643792254708, timestamp: 2022-08-20 07:34:23.098895\n",
      "resetting env. episode 1792, reward total was -19.0. running mean: -19.32317354332161, timestamp: 2022-08-20 07:34:24.716915\n",
      "resetting env. episode 1793, reward total was -18.0. running mean: -19.309941807888393, timestamp: 2022-08-20 07:34:26.946942\n",
      "resetting env. episode 1794, reward total was -21.0. running mean: -19.32684238980951, timestamp: 2022-08-20 07:34:27.976957\n",
      "resetting env. episode 1795, reward total was -19.0. running mean: -19.323573965911415, timestamp: 2022-08-20 07:34:29.870975\n",
      "resetting env. episode 1796, reward total was -21.0. running mean: -19.3403382262523, timestamp: 2022-08-20 07:34:30.990996\n",
      "resetting env. episode 1797, reward total was -20.0. running mean: -19.346934843989775, timestamp: 2022-08-20 07:34:34.041027\n",
      "resetting env. episode 1798, reward total was -19.0. running mean: -19.34346549554988, timestamp: 2022-08-20 07:34:35.836046\n",
      "resetting env. episode 1799, reward total was -21.0. running mean: -19.36003084059438, timestamp: 2022-08-20 07:34:37.274066\n",
      "resetting env. episode 1800, reward total was -18.0. running mean: -19.346430532188435, timestamp: 2022-08-20 07:34:39.223089\n",
      "resetting env. episode 1801, reward total was -21.0. running mean: -19.36296622686655, timestamp: 2022-08-20 07:34:40.429107\n",
      "resetting env. episode 1802, reward total was -19.0. running mean: -19.359336564597886, timestamp: 2022-08-20 07:34:42.168120\n",
      "resetting env. episode 1803, reward total was -21.0. running mean: -19.37574319895191, timestamp: 2022-08-20 07:34:43.964142\n",
      "resetting env. episode 1804, reward total was -21.0. running mean: -19.391985766962392, timestamp: 2022-08-20 07:34:45.337158\n",
      "resetting env. episode 1805, reward total was -20.0. running mean: -19.398065909292768, timestamp: 2022-08-20 07:34:46.862179\n",
      "resetting env. episode 1806, reward total was -21.0. running mean: -19.41408525019984, timestamp: 2022-08-20 07:34:49.036206\n",
      "resetting env. episode 1807, reward total was -19.0. running mean: -19.409944397697842, timestamp: 2022-08-20 07:34:50.692227\n",
      "resetting env. episode 1808, reward total was -20.0. running mean: -19.415844953720864, timestamp: 2022-08-20 07:34:53.355257\n",
      "resetting env. episode 1809, reward total was -20.0. running mean: -19.421686504183654, timestamp: 2022-08-20 07:34:54.896271\n",
      "resetting env. episode 1810, reward total was -20.0. running mean: -19.427469639141815, timestamp: 2022-08-20 07:34:57.559302\n",
      "resetting env. episode 1811, reward total was -21.0. running mean: -19.4431949427504, timestamp: 2022-08-20 07:35:00.021333\n",
      "resetting env. episode 1812, reward total was -20.0. running mean: -19.448762993322894, timestamp: 2022-08-20 07:35:01.815356\n",
      "resetting env. episode 1813, reward total was -21.0. running mean: -19.464275363389667, timestamp: 2022-08-20 07:35:03.094372\n",
      "resetting env. episode 1814, reward total was -21.0. running mean: -19.47963260975577, timestamp: 2022-08-20 07:35:04.371384\n",
      "resetting env. episode 1815, reward total was -20.0. running mean: -19.484836283658215, timestamp: 2022-08-20 07:35:05.974409\n",
      "resetting env. episode 1816, reward total was -19.0. running mean: -19.479987920821635, timestamp: 2022-08-20 07:35:08.594435\n",
      "resetting env. episode 1817, reward total was -21.0. running mean: -19.49518804161342, timestamp: 2022-08-20 07:35:09.860451\n",
      "resetting env. episode 1818, reward total was -21.0. running mean: -19.510236161197287, timestamp: 2022-08-20 07:35:11.387470\n",
      "resetting env. episode 1819, reward total was -18.0. running mean: -19.495133799585314, timestamp: 2022-08-20 07:35:13.002490\n",
      "resetting env. episode 1820, reward total was -21.0. running mean: -19.510182461589462, timestamp: 2022-08-20 07:35:14.593504\n",
      "resetting env. episode 1821, reward total was -21.0. running mean: -19.52508063697357, timestamp: 2022-08-20 07:35:15.850519\n",
      "resetting env. episode 1822, reward total was -21.0. running mean: -19.539829830603836, timestamp: 2022-08-20 07:35:17.126537\n",
      "resetting env. episode 1823, reward total was -21.0. running mean: -19.554431532297798, timestamp: 2022-08-20 07:35:18.274549\n",
      "resetting env. episode 1824, reward total was -21.0. running mean: -19.568887216974822, timestamp: 2022-08-20 07:35:19.820571\n",
      "resetting env. episode 1825, reward total was -21.0. running mean: -19.583198344805076, timestamp: 2022-08-20 07:35:21.550591\n",
      "resetting env. episode 1826, reward total was -21.0. running mean: -19.597366361357025, timestamp: 2022-08-20 07:35:23.469611\n",
      "resetting env. episode 1827, reward total was -21.0. running mean: -19.611392697743455, timestamp: 2022-08-20 07:35:25.242631\n",
      "resetting env. episode 1828, reward total was -21.0. running mean: -19.62527877076602, timestamp: 2022-08-20 07:35:26.432646\n",
      "resetting env. episode 1829, reward total was -20.0. running mean: -19.62902598305836, timestamp: 2022-08-20 07:35:27.887664\n",
      "resetting env. episode 1830, reward total was -21.0. running mean: -19.642735723227776, timestamp: 2022-08-20 07:35:29.549684\n",
      "resetting env. episode 1831, reward total was -20.0. running mean: -19.6463083659955, timestamp: 2022-08-20 07:35:30.999706\n",
      "resetting env. episode 1832, reward total was -18.0. running mean: -19.62984528233554, timestamp: 2022-08-20 07:35:33.026725\n",
      "resetting env. episode 1833, reward total was -21.0. running mean: -19.643546829512186, timestamp: 2022-08-20 07:35:35.025754\n",
      "resetting env. episode 1834, reward total was -19.0. running mean: -19.637111361217066, timestamp: 2022-08-20 07:35:36.453765\n",
      "resetting env. episode 1835, reward total was -21.0. running mean: -19.650740247604897, timestamp: 2022-08-20 07:35:37.947782\n",
      "resetting env. episode 1836, reward total was -20.0. running mean: -19.65423284512885, timestamp: 2022-08-20 07:35:39.663803\n",
      "resetting env. episode 1837, reward total was -20.0. running mean: -19.657690516677558, timestamp: 2022-08-20 07:35:40.970824\n",
      "resetting env. episode 1838, reward total was -20.0. running mean: -19.661113611510782, timestamp: 2022-08-20 07:35:42.844842\n",
      "resetting env. episode 1839, reward total was -18.0. running mean: -19.644502475395672, timestamp: 2022-08-20 07:35:44.566863\n",
      "resetting env. episode 1840, reward total was -18.0. running mean: -19.628057450641716, timestamp: 2022-08-20 07:35:46.715890\n",
      "resetting env. episode 1841, reward total was -21.0. running mean: -19.6417768761353, timestamp: 2022-08-20 07:35:47.824899\n",
      "resetting env. episode 1842, reward total was -20.0. running mean: -19.645359107373945, timestamp: 2022-08-20 07:35:49.886927\n",
      "resetting env. episode 1843, reward total was -21.0. running mean: -19.658905516300205, timestamp: 2022-08-20 07:35:51.288944\n",
      "resetting env. episode 1844, reward total was -21.0. running mean: -19.672316461137203, timestamp: 2022-08-20 07:35:52.630957\n",
      "resetting env. episode 1845, reward total was -20.0. running mean: -19.67559329652583, timestamp: 2022-08-20 07:35:53.724972\n",
      "resetting env. episode 1846, reward total was -21.0. running mean: -19.68883736356057, timestamp: 2022-08-20 07:35:55.395995\n",
      "resetting env. episode 1847, reward total was -20.0. running mean: -19.691948989924963, timestamp: 2022-08-20 07:35:57.069013\n",
      "resetting env. episode 1848, reward total was -21.0. running mean: -19.705029500025713, timestamp: 2022-08-20 07:35:58.162029\n",
      "resetting env. episode 1849, reward total was -20.0. running mean: -19.707979205025456, timestamp: 2022-08-20 07:36:00.348054\n",
      "resetting env. episode 1850, reward total was -20.0. running mean: -19.710899412975202, timestamp: 2022-08-20 07:36:02.470074\n",
      "resetting env. episode 1851, reward total was -21.0. running mean: -19.72379041884545, timestamp: 2022-08-20 07:36:03.517090\n",
      "resetting env. episode 1852, reward total was -21.0. running mean: -19.736552514656996, timestamp: 2022-08-20 07:36:04.809101\n",
      "resetting env. episode 1853, reward total was -21.0. running mean: -19.749186989510427, timestamp: 2022-08-20 07:36:05.990118\n",
      "resetting env. episode 1854, reward total was -21.0. running mean: -19.761695119615325, timestamp: 2022-08-20 07:36:07.262133\n",
      "resetting env. episode 1855, reward total was -20.0. running mean: -19.76407816841917, timestamp: 2022-08-20 07:36:09.709163\n",
      "resetting env. episode 1856, reward total was -21.0. running mean: -19.77643738673498, timestamp: 2022-08-20 07:36:11.060177\n",
      "resetting env. episode 1857, reward total was -21.0. running mean: -19.78867301286763, timestamp: 2022-08-20 07:36:12.696198\n",
      "resetting env. episode 1858, reward total was -21.0. running mean: -19.800786282738954, timestamp: 2022-08-20 07:36:13.885211\n",
      "resetting env. episode 1859, reward total was -21.0. running mean: -19.812778419911567, timestamp: 2022-08-20 07:36:15.418233\n",
      "resetting env. episode 1860, reward total was -21.0. running mean: -19.82465063571245, timestamp: 2022-08-20 07:36:16.642246\n",
      "resetting env. episode 1861, reward total was -20.0. running mean: -19.826404129355325, timestamp: 2022-08-20 07:36:18.138263\n",
      "resetting env. episode 1862, reward total was -21.0. running mean: -19.838140088061774, timestamp: 2022-08-20 07:36:19.285280\n",
      "resetting env. episode 1863, reward total was -21.0. running mean: -19.849758687181158, timestamp: 2022-08-20 07:36:20.758293\n",
      "resetting env. episode 1864, reward total was -20.0. running mean: -19.851261100309344, timestamp: 2022-08-20 07:36:22.081309\n",
      "resetting env. episode 1865, reward total was -21.0. running mean: -19.862748489306252, timestamp: 2022-08-20 07:36:23.334326\n",
      "resetting env. episode 1866, reward total was -20.0. running mean: -19.86412100441319, timestamp: 2022-08-20 07:36:24.821342\n",
      "resetting env. episode 1867, reward total was -18.0. running mean: -19.845479794369055, timestamp: 2022-08-20 07:36:26.276361\n",
      "resetting env. episode 1868, reward total was -21.0. running mean: -19.857024996425366, timestamp: 2022-08-20 07:36:27.854382\n",
      "resetting env. episode 1869, reward total was -21.0. running mean: -19.868454746461115, timestamp: 2022-08-20 07:36:29.039391\n",
      "resetting env. episode 1870, reward total was -19.0. running mean: -19.859770198996504, timestamp: 2022-08-20 07:36:30.961413\n",
      "resetting env. episode 1871, reward total was -20.0. running mean: -19.86117249700654, timestamp: 2022-08-20 07:36:32.731435\n",
      "resetting env. episode 1872, reward total was -21.0. running mean: -19.872560772036476, timestamp: 2022-08-20 07:36:33.851449\n",
      "resetting env. episode 1873, reward total was -21.0. running mean: -19.88383516431611, timestamp: 2022-08-20 07:36:35.500468\n",
      "resetting env. episode 1874, reward total was -21.0. running mean: -19.89499681267295, timestamp: 2022-08-20 07:36:36.684486\n",
      "resetting env. episode 1875, reward total was -21.0. running mean: -19.90604684454622, timestamp: 2022-08-20 07:36:38.119499\n",
      "resetting env. episode 1876, reward total was -21.0. running mean: -19.91698637610076, timestamp: 2022-08-20 07:36:39.244513\n",
      "resetting env. episode 1877, reward total was -21.0. running mean: -19.927816512339753, timestamp: 2022-08-20 07:36:40.549529\n",
      "resetting env. episode 1878, reward total was -21.0. running mean: -19.938538347216355, timestamp: 2022-08-20 07:36:41.850543\n",
      "resetting env. episode 1879, reward total was -21.0. running mean: -19.949152963744194, timestamp: 2022-08-20 07:36:43.262561\n",
      "resetting env. episode 1880, reward total was -20.0. running mean: -19.94966143410675, timestamp: 2022-08-20 07:36:44.361573\n",
      "resetting env. episode 1881, reward total was -21.0. running mean: -19.960164819765684, timestamp: 2022-08-20 07:36:46.028599\n",
      "resetting env. episode 1882, reward total was -21.0. running mean: -19.970563171568028, timestamp: 2022-08-20 07:36:47.061605\n",
      "resetting env. episode 1883, reward total was -21.0. running mean: -19.980857539852348, timestamp: 2022-08-20 07:36:48.663623\n",
      "resetting env. episode 1884, reward total was -21.0. running mean: -19.991048964453825, timestamp: 2022-08-20 07:36:49.850641\n",
      "resetting env. episode 1885, reward total was -21.0. running mean: -20.001138474809288, timestamp: 2022-08-20 07:36:51.324657\n",
      "resetting env. episode 1886, reward total was -21.0. running mean: -20.011127090061194, timestamp: 2022-08-20 07:36:52.960680\n",
      "resetting env. episode 1887, reward total was -20.0. running mean: -20.01101581916058, timestamp: 2022-08-20 07:36:54.060689\n",
      "resetting env. episode 1888, reward total was -21.0. running mean: -20.020905660968975, timestamp: 2022-08-20 07:36:55.496705\n",
      "resetting env. episode 1889, reward total was -21.0. running mean: -20.030696604359285, timestamp: 2022-08-20 07:36:56.800720\n",
      "resetting env. episode 1890, reward total was -20.0. running mean: -20.03038963831569, timestamp: 2022-08-20 07:36:58.290740\n",
      "resetting env. episode 1891, reward total was -21.0. running mean: -20.040085741932533, timestamp: 2022-08-20 07:37:00.176763\n",
      "resetting env. episode 1892, reward total was -21.0. running mean: -20.04968488451321, timestamp: 2022-08-20 07:37:01.340773\n",
      "resetting env. episode 1893, reward total was -21.0. running mean: -20.059188035668075, timestamp: 2022-08-20 07:37:02.451790\n",
      "resetting env. episode 1894, reward total was -21.0. running mean: -20.068596155311397, timestamp: 2022-08-20 07:37:04.061808\n",
      "resetting env. episode 1895, reward total was -21.0. running mean: -20.077910193758285, timestamp: 2022-08-20 07:37:05.622825\n",
      "resetting env. episode 1896, reward total was -21.0. running mean: -20.0871310918207, timestamp: 2022-08-20 07:37:06.687841\n",
      "resetting env. episode 1897, reward total was -19.0. running mean: -20.076259780902497, timestamp: 2022-08-20 07:37:08.189854\n",
      "resetting env. episode 1898, reward total was -21.0. running mean: -20.085497183093473, timestamp: 2022-08-20 07:37:09.618875\n",
      "resetting env. episode 1899, reward total was -21.0. running mean: -20.09464221126254, timestamp: 2022-08-20 07:37:11.460893\n",
      "resetting env. episode 1900, reward total was -20.0. running mean: -20.093695789149912, timestamp: 2022-08-20 07:37:12.701911\n",
      "resetting env. episode 1901, reward total was -21.0. running mean: -20.102758831258413, timestamp: 2022-08-20 07:37:13.839921\n",
      "resetting env. episode 1902, reward total was -21.0. running mean: -20.11173124294583, timestamp: 2022-08-20 07:37:15.297940\n",
      "resetting env. episode 1903, reward total was -20.0. running mean: -20.11061393051637, timestamp: 2022-08-20 07:37:16.879956\n",
      "resetting env. episode 1904, reward total was -21.0. running mean: -20.119507791211205, timestamp: 2022-08-20 07:37:18.154972\n",
      "resetting env. episode 1905, reward total was -21.0. running mean: -20.128312713299096, timestamp: 2022-08-20 07:37:19.767994\n",
      "resetting env. episode 1906, reward total was -21.0. running mean: -20.137029586166104, timestamp: 2022-08-20 07:37:21.135008\n",
      "resetting env. episode 1907, reward total was -18.0. running mean: -20.115659290304443, timestamp: 2022-08-20 07:37:23.197032\n",
      "resetting env. episode 1908, reward total was -21.0. running mean: -20.1245026974014, timestamp: 2022-08-20 07:37:24.392049\n",
      "resetting env. episode 1909, reward total was -21.0. running mean: -20.133257670427387, timestamp: 2022-08-20 07:37:25.739066\n",
      "resetting env. episode 1910, reward total was -21.0. running mean: -20.141925093723113, timestamp: 2022-08-20 07:37:26.813074\n",
      "resetting env. episode 1911, reward total was -21.0. running mean: -20.150505842785883, timestamp: 2022-08-20 07:37:28.386094\n",
      "resetting env. episode 1912, reward total was -21.0. running mean: -20.159000784358025, timestamp: 2022-08-20 07:37:29.691108\n",
      "resetting env. episode 1913, reward total was -21.0. running mean: -20.167410776514444, timestamp: 2022-08-20 07:37:31.192126\n",
      "resetting env. episode 1914, reward total was -21.0. running mean: -20.175736668749302, timestamp: 2022-08-20 07:37:33.078149\n",
      "resetting env. episode 1915, reward total was -21.0. running mean: -20.18397930206181, timestamp: 2022-08-20 07:37:34.496165\n",
      "resetting env. episode 1916, reward total was -20.0. running mean: -20.182139509041193, timestamp: 2022-08-20 07:37:36.101190\n",
      "resetting env. episode 1917, reward total was -20.0. running mean: -20.18031811395078, timestamp: 2022-08-20 07:37:37.248197\n",
      "resetting env. episode 1918, reward total was -20.0. running mean: -20.17851493281127, timestamp: 2022-08-20 07:37:38.662219\n",
      "resetting env. episode 1919, reward total was -20.0. running mean: -20.176729783483157, timestamp: 2022-08-20 07:37:39.984231\n",
      "resetting env. episode 1920, reward total was -21.0. running mean: -20.184962485648327, timestamp: 2022-08-20 07:37:41.749253\n",
      "resetting env. episode 1921, reward total was -21.0. running mean: -20.193112860791846, timestamp: 2022-08-20 07:37:43.370270\n",
      "resetting env. episode 1922, reward total was -20.0. running mean: -20.191181732183928, timestamp: 2022-08-20 07:37:44.691290\n",
      "resetting env. episode 1923, reward total was -21.0. running mean: -20.19926991486209, timestamp: 2022-08-20 07:37:46.136303\n",
      "resetting env. episode 1924, reward total was -19.0. running mean: -20.18727721571347, timestamp: 2022-08-20 07:37:47.691322\n",
      "resetting env. episode 1925, reward total was -21.0. running mean: -20.195404443556335, timestamp: 2022-08-20 07:37:49.127338\n",
      "resetting env. episode 1926, reward total was -21.0. running mean: -20.203450399120772, timestamp: 2022-08-20 07:37:50.238351\n",
      "resetting env. episode 1927, reward total was -21.0. running mean: -20.211415895129566, timestamp: 2022-08-20 07:37:52.439380\n",
      "resetting env. episode 1928, reward total was -21.0. running mean: -20.21930173617827, timestamp: 2022-08-20 07:37:54.060398\n",
      "resetting env. episode 1929, reward total was -20.0. running mean: -20.217108718816487, timestamp: 2022-08-20 07:37:55.521416\n",
      "resetting env. episode 1930, reward total was -21.0. running mean: -20.224937631628322, timestamp: 2022-08-20 07:37:57.076431\n",
      "resetting env. episode 1931, reward total was -20.0. running mean: -20.222688255312036, timestamp: 2022-08-20 07:37:58.701451\n",
      "resetting env. episode 1932, reward total was -21.0. running mean: -20.230461372758917, timestamp: 2022-08-20 07:37:59.909471\n",
      "resetting env. episode 1933, reward total was -21.0. running mean: -20.23815675903133, timestamp: 2022-08-20 07:38:01.523008\n",
      "resetting env. episode 1934, reward total was -21.0. running mean: -20.245775191441016, timestamp: 2022-08-20 07:38:02.992027\n",
      "resetting env. episode 1935, reward total was -21.0. running mean: -20.253317439526608, timestamp: 2022-08-20 07:38:04.128037\n",
      "resetting env. episode 1936, reward total was -21.0. running mean: -20.260784265131342, timestamp: 2022-08-20 07:38:05.359055\n",
      "resetting env. episode 1937, reward total was -21.0. running mean: -20.26817642248003, timestamp: 2022-08-20 07:38:06.521066\n",
      "resetting env. episode 1938, reward total was -20.0. running mean: -20.26549465825523, timestamp: 2022-08-20 07:38:07.833084\n",
      "resetting env. episode 1939, reward total was -20.0. running mean: -20.262839711672676, timestamp: 2022-08-20 07:38:09.211097\n",
      "resetting env. episode 1940, reward total was -18.0. running mean: -20.24021131455595, timestamp: 2022-08-20 07:38:10.885121\n",
      "resetting env. episode 1941, reward total was -21.0. running mean: -20.24780920141039, timestamp: 2022-08-20 07:38:12.409141\n",
      "resetting env. episode 1942, reward total was -18.0. running mean: -20.225331109396286, timestamp: 2022-08-20 07:38:14.291162\n",
      "resetting env. episode 1943, reward total was -21.0. running mean: -20.233077798302325, timestamp: 2022-08-20 07:38:16.171182\n",
      "resetting env. episode 1944, reward total was -20.0. running mean: -20.230747020319303, timestamp: 2022-08-20 07:38:17.725198\n",
      "resetting env. episode 1945, reward total was -21.0. running mean: -20.23843955011611, timestamp: 2022-08-20 07:38:19.574223\n",
      "resetting env. episode 1946, reward total was -21.0. running mean: -20.246055154614947, timestamp: 2022-08-20 07:38:21.322239\n",
      "resetting env. episode 1947, reward total was -19.0. running mean: -20.2335946030688, timestamp: 2022-08-20 07:38:23.402267\n",
      "resetting env. episode 1948, reward total was -20.0. running mean: -20.231258657038108, timestamp: 2022-08-20 07:38:24.701285\n",
      "resetting env. episode 1949, reward total was -19.0. running mean: -20.218946070467727, timestamp: 2022-08-20 07:38:26.300302\n",
      "resetting env. episode 1950, reward total was -20.0. running mean: -20.21675660976305, timestamp: 2022-08-20 07:38:27.744316\n",
      "resetting env. episode 1951, reward total was -20.0. running mean: -20.214589043665416, timestamp: 2022-08-20 07:38:29.369336\n",
      "resetting env. episode 1952, reward total was -21.0. running mean: -20.222443153228763, timestamp: 2022-08-20 07:38:30.633353\n",
      "resetting env. episode 1953, reward total was -20.0. running mean: -20.220218721696476, timestamp: 2022-08-20 07:38:32.034367\n",
      "resetting env. episode 1954, reward total was -20.0. running mean: -20.21801653447951, timestamp: 2022-08-20 07:38:33.387382\n",
      "resetting env. episode 1955, reward total was -20.0. running mean: -20.215836369134713, timestamp: 2022-08-20 07:38:34.719398\n",
      "resetting env. episode 1956, reward total was -20.0. running mean: -20.213678005443366, timestamp: 2022-08-20 07:38:36.475419\n",
      "resetting env. episode 1957, reward total was -20.0. running mean: -20.21154122538893, timestamp: 2022-08-20 07:38:38.023440\n",
      "resetting env. episode 1958, reward total was -21.0. running mean: -20.219425813135043, timestamp: 2022-08-20 07:38:39.426457\n",
      "resetting env. episode 1959, reward total was -21.0. running mean: -20.227231555003694, timestamp: 2022-08-20 07:38:40.762471\n",
      "resetting env. episode 1960, reward total was -20.0. running mean: -20.224959239453657, timestamp: 2022-08-20 07:38:42.064488\n",
      "resetting env. episode 1961, reward total was -21.0. running mean: -20.23270964705912, timestamp: 2022-08-20 07:38:43.900508\n",
      "resetting env. episode 1962, reward total was -21.0. running mean: -20.24038255058853, timestamp: 2022-08-20 07:38:45.179526\n",
      "resetting env. episode 1963, reward total was -18.0. running mean: -20.217978725082645, timestamp: 2022-08-20 07:38:46.875542\n",
      "resetting env. episode 1964, reward total was -20.0. running mean: -20.215798937831817, timestamp: 2022-08-20 07:38:49.305574\n",
      "resetting env. episode 1965, reward total was -20.0. running mean: -20.2136409484535, timestamp: 2022-08-20 07:38:50.971596\n",
      "resetting env. episode 1966, reward total was -21.0. running mean: -20.221504538968965, timestamp: 2022-08-20 07:38:52.841614\n",
      "resetting env. episode 1967, reward total was -21.0. running mean: -20.229289493579277, timestamp: 2022-08-20 07:38:54.130630\n",
      "resetting env. episode 1968, reward total was -21.0. running mean: -20.236996598643483, timestamp: 2022-08-20 07:38:56.092656\n",
      "resetting env. episode 1969, reward total was -20.0. running mean: -20.234626632657047, timestamp: 2022-08-20 07:38:57.559671\n",
      "resetting env. episode 1970, reward total was -21.0. running mean: -20.242280366330476, timestamp: 2022-08-20 07:38:58.915687\n",
      "resetting env. episode 1971, reward total was -21.0. running mean: -20.249857562667174, timestamp: 2022-08-20 07:39:00.522706\n",
      "resetting env. episode 1972, reward total was -21.0. running mean: -20.257358987040504, timestamp: 2022-08-20 07:39:01.874725\n",
      "resetting env. episode 1973, reward total was -21.0. running mean: -20.2647853971701, timestamp: 2022-08-20 07:39:03.528744\n",
      "resetting env. episode 1974, reward total was -20.0. running mean: -20.2621375431984, timestamp: 2022-08-20 07:39:04.973759\n",
      "resetting env. episode 1975, reward total was -19.0. running mean: -20.249516167766416, timestamp: 2022-08-20 07:39:07.038788\n",
      "resetting env. episode 1976, reward total was -21.0. running mean: -20.257021006088753, timestamp: 2022-08-20 07:39:09.313811\n",
      "resetting env. episode 1977, reward total was -21.0. running mean: -20.264450796027866, timestamp: 2022-08-20 07:39:10.915830\n",
      "resetting env. episode 1978, reward total was -20.0. running mean: -20.261806288067586, timestamp: 2022-08-20 07:39:12.589850\n",
      "resetting env. episode 1979, reward total was -19.0. running mean: -20.24918822518691, timestamp: 2022-08-20 07:39:14.721879\n",
      "resetting env. episode 1980, reward total was -21.0. running mean: -20.25669634293504, timestamp: 2022-08-20 07:39:15.861889\n",
      "resetting env. episode 1981, reward total was -21.0. running mean: -20.26412937950569, timestamp: 2022-08-20 07:39:17.731911\n",
      "resetting env. episode 1982, reward total was -21.0. running mean: -20.271488085710633, timestamp: 2022-08-20 07:39:19.844935\n",
      "resetting env. episode 1983, reward total was -19.0. running mean: -20.25877320485353, timestamp: 2022-08-20 07:39:21.950960\n",
      "resetting env. episode 1984, reward total was -21.0. running mean: -20.266185472804995, timestamp: 2022-08-20 07:39:23.247976\n",
      "resetting env. episode 1985, reward total was -17.0. running mean: -20.233523618076948, timestamp: 2022-08-20 07:39:25.420007\n",
      "resetting env. episode 1986, reward total was -18.0. running mean: -20.21118838189618, timestamp: 2022-08-20 07:39:27.442025\n",
      "resetting env. episode 1987, reward total was -21.0. running mean: -20.219076498077218, timestamp: 2022-08-20 07:39:29.295051\n",
      "resetting env. episode 1988, reward total was -20.0. running mean: -20.216885733096444, timestamp: 2022-08-20 07:39:31.807078\n",
      "resetting env. episode 1989, reward total was -19.0. running mean: -20.20471687576548, timestamp: 2022-08-20 07:39:33.858106\n",
      "resetting env. episode 1990, reward total was -20.0. running mean: -20.202669707007825, timestamp: 2022-08-20 07:39:36.456134\n",
      "resetting env. episode 1991, reward total was -18.0. running mean: -20.180643009937747, timestamp: 2022-08-20 07:39:38.771164\n",
      "resetting env. episode 1992, reward total was -21.0. running mean: -20.18883657983837, timestamp: 2022-08-20 07:39:40.491186\n",
      "resetting env. episode 1993, reward total was -20.0. running mean: -20.186948214039983, timestamp: 2022-08-20 07:39:42.047205\n",
      "resetting env. episode 1994, reward total was -19.0. running mean: -20.175078731899585, timestamp: 2022-08-20 07:39:43.390215\n",
      "resetting env. episode 1995, reward total was -20.0. running mean: -20.17332794458059, timestamp: 2022-08-20 07:39:44.902233\n",
      "resetting env. episode 1996, reward total was -20.0. running mean: -20.17159466513478, timestamp: 2022-08-20 07:39:46.472252\n",
      "resetting env. episode 1997, reward total was -18.0. running mean: -20.149878718483432, timestamp: 2022-08-20 07:39:48.365277\n",
      "resetting env. episode 1998, reward total was -19.0. running mean: -20.138379931298598, timestamp: 2022-08-20 07:39:51.664314\n",
      "resetting env. episode 1999, reward total was -21.0. running mean: -20.146996131985613, timestamp: 2022-08-20 07:39:52.950328\n",
      "resetting env. episode 2000, reward total was -21.0. running mean: -20.15552617066576, timestamp: 2022-08-20 07:39:54.272345\n",
      "resetting env. episode 2001, reward total was -21.0. running mean: -20.1639709089591, timestamp: 2022-08-20 07:39:55.488360\n",
      "resetting env. episode 2002, reward total was -20.0. running mean: -20.16233119986951, timestamp: 2022-08-20 07:39:57.556383\n",
      "resetting env. episode 2003, reward total was -20.0. running mean: -20.160707887870814, timestamp: 2022-08-20 07:39:59.048403\n",
      "resetting env. episode 2004, reward total was -20.0. running mean: -20.159100808992104, timestamp: 2022-08-20 07:40:01.591432\n",
      "resetting env. episode 2005, reward total was -18.0. running mean: -20.137509800902183, timestamp: 2022-08-20 07:40:03.486453\n",
      "resetting env. episode 2006, reward total was -20.0. running mean: -20.13613470289316, timestamp: 2022-08-20 07:40:05.091474\n",
      "resetting env. episode 2007, reward total was -19.0. running mean: -20.124773355864228, timestamp: 2022-08-20 07:40:07.035495\n",
      "resetting env. episode 2008, reward total was -19.0. running mean: -20.113525622305588, timestamp: 2022-08-20 07:40:08.604515\n",
      "resetting env. episode 2009, reward total was -18.0. running mean: -20.09239036608253, timestamp: 2022-08-20 07:40:10.297534\n",
      "resetting env. episode 2010, reward total was -21.0. running mean: -20.101466462421705, timestamp: 2022-08-20 07:40:11.627551\n",
      "resetting env. episode 2011, reward total was -21.0. running mean: -20.110451797797488, timestamp: 2022-08-20 07:40:13.429572\n",
      "resetting env. episode 2012, reward total was -21.0. running mean: -20.119347279819515, timestamp: 2022-08-20 07:40:15.090590\n",
      "resetting env. episode 2013, reward total was -20.0. running mean: -20.11815380702132, timestamp: 2022-08-20 07:40:16.979612\n",
      "resetting env. episode 2014, reward total was -19.0. running mean: -20.106972268951107, timestamp: 2022-08-20 07:40:19.260641\n",
      "resetting env. episode 2015, reward total was -19.0. running mean: -20.0959025462616, timestamp: 2022-08-20 07:40:20.784661\n",
      "resetting env. episode 2016, reward total was -20.0. running mean: -20.09494352079898, timestamp: 2022-08-20 07:40:22.589679\n",
      "resetting env. episode 2017, reward total was -19.0. running mean: -20.083994085590994, timestamp: 2022-08-20 07:40:24.608703\n",
      "resetting env. episode 2018, reward total was -19.0. running mean: -20.073154144735085, timestamp: 2022-08-20 07:40:26.172721\n",
      "resetting env. episode 2019, reward total was -21.0. running mean: -20.082422603287736, timestamp: 2022-08-20 07:40:28.719760\n",
      "resetting env. episode 2020, reward total was -17.0. running mean: -20.05159837725486, timestamp: 2022-08-20 07:40:30.482775\n",
      "resetting env. episode 2021, reward total was -18.0. running mean: -20.03108239348231, timestamp: 2022-08-20 07:40:32.254794\n",
      "resetting env. episode 2022, reward total was -20.0. running mean: -20.030771569547486, timestamp: 2022-08-20 07:40:34.436819\n",
      "resetting env. episode 2023, reward total was -19.0. running mean: -20.02046385385201, timestamp: 2022-08-20 07:40:36.188843\n",
      "resetting env. episode 2024, reward total was -21.0. running mean: -20.030259215313492, timestamp: 2022-08-20 07:40:37.607375\n",
      "resetting env. episode 2025, reward total was -18.0. running mean: -20.009956623160356, timestamp: 2022-08-20 07:40:39.675404\n",
      "resetting env. episode 2026, reward total was -20.0. running mean: -20.00985705692875, timestamp: 2022-08-20 07:40:41.456422\n",
      "resetting env. episode 2027, reward total was -19.0. running mean: -19.999758486359465, timestamp: 2022-08-20 07:40:42.985442\n",
      "resetting env. episode 2028, reward total was -17.0. running mean: -19.96976090149587, timestamp: 2022-08-20 07:40:45.616470\n",
      "resetting env. episode 2029, reward total was -19.0. running mean: -19.960063292480914, timestamp: 2022-08-20 07:40:47.224491\n",
      "resetting env. episode 2030, reward total was -20.0. running mean: -19.960462659556104, timestamp: 2022-08-20 07:40:48.630506\n",
      "resetting env. episode 2031, reward total was -19.0. running mean: -19.950858032960543, timestamp: 2022-08-20 07:40:50.563529\n",
      "resetting env. episode 2032, reward total was -21.0. running mean: -19.961349452630937, timestamp: 2022-08-20 07:40:51.846544\n",
      "resetting env. episode 2033, reward total was -19.0. running mean: -19.951735958104628, timestamp: 2022-08-20 07:40:53.562571\n",
      "resetting env. episode 2034, reward total was -21.0. running mean: -19.96221859852358, timestamp: 2022-08-20 07:40:55.473586\n",
      "resetting env. episode 2035, reward total was -21.0. running mean: -19.972596412538344, timestamp: 2022-08-20 07:40:57.317609\n",
      "resetting env. episode 2036, reward total was -20.0. running mean: -19.97287044841296, timestamp: 2022-08-20 07:40:59.017633\n",
      "resetting env. episode 2037, reward total was -20.0. running mean: -19.973141743928828, timestamp: 2022-08-20 07:41:01.228656\n",
      "resetting env. episode 2038, reward total was -20.0. running mean: -19.97341032648954, timestamp: 2022-08-20 07:41:02.934721\n",
      "resetting env. episode 2039, reward total was -20.0. running mean: -19.973676223224643, timestamp: 2022-08-20 07:41:04.115734\n",
      "resetting env. episode 2040, reward total was -21.0. running mean: -19.9839394609924, timestamp: 2022-08-20 07:41:06.044755\n",
      "resetting env. episode 2041, reward total was -16.0. running mean: -19.944100066382475, timestamp: 2022-08-20 07:41:08.144778\n",
      "resetting env. episode 2042, reward total was -21.0. running mean: -19.95465906571865, timestamp: 2022-08-20 07:41:10.128803\n",
      "resetting env. episode 2043, reward total was -19.0. running mean: -19.945112475061467, timestamp: 2022-08-20 07:41:11.728820\n",
      "resetting env. episode 2044, reward total was -21.0. running mean: -19.955661350310855, timestamp: 2022-08-20 07:41:13.077835\n",
      "resetting env. episode 2045, reward total was -21.0. running mean: -19.966104736807747, timestamp: 2022-08-20 07:41:14.522854\n",
      "resetting env. episode 2046, reward total was -19.0. running mean: -19.95644368943967, timestamp: 2022-08-20 07:41:16.297872\n",
      "resetting env. episode 2047, reward total was -21.0. running mean: -19.966879252545272, timestamp: 2022-08-20 07:41:17.802892\n",
      "resetting env. episode 2048, reward total was -20.0. running mean: -19.967210460019817, timestamp: 2022-08-20 07:41:19.040910\n",
      "resetting env. episode 2049, reward total was -19.0. running mean: -19.957538355419622, timestamp: 2022-08-20 07:41:21.141931\n",
      "resetting env. episode 2050, reward total was -19.0. running mean: -19.947962971865426, timestamp: 2022-08-20 07:41:23.145960\n",
      "resetting env. episode 2051, reward total was -19.0. running mean: -19.93848334214677, timestamp: 2022-08-20 07:41:24.984979\n",
      "resetting env. episode 2052, reward total was -21.0. running mean: -19.949098508725303, timestamp: 2022-08-20 07:41:26.470994\n",
      "resetting env. episode 2053, reward total was -18.0. running mean: -19.92960752363805, timestamp: 2022-08-20 07:41:28.689020\n",
      "resetting env. episode 2054, reward total was -19.0. running mean: -19.920311448401673, timestamp: 2022-08-20 07:41:30.904046\n",
      "resetting env. episode 2055, reward total was -17.0. running mean: -19.891108333917657, timestamp: 2022-08-20 07:41:32.875068\n",
      "resetting env. episode 2056, reward total was -21.0. running mean: -19.90219725057848, timestamp: 2022-08-20 07:41:34.465088\n",
      "resetting env. episode 2057, reward total was -21.0. running mean: -19.913175278072696, timestamp: 2022-08-20 07:41:36.412121\n",
      "resetting env. episode 2058, reward total was -20.0. running mean: -19.91404352529197, timestamp: 2022-08-20 07:41:38.595137\n",
      "resetting env. episode 2059, reward total was -18.0. running mean: -19.894903090039048, timestamp: 2022-08-20 07:41:41.361169\n",
      "resetting env. episode 2060, reward total was -18.0. running mean: -19.875954059138657, timestamp: 2022-08-20 07:41:43.467194\n",
      "resetting env. episode 2061, reward total was -20.0. running mean: -19.87719451854727, timestamp: 2022-08-20 07:41:45.200218\n",
      "resetting env. episode 2062, reward total was -16.0. running mean: -19.838422573361797, timestamp: 2022-08-20 07:41:46.980238\n",
      "resetting env. episode 2063, reward total was -21.0. running mean: -19.85003834762818, timestamp: 2022-08-20 07:41:48.390256\n",
      "resetting env. episode 2064, reward total was -21.0. running mean: -19.861537964151896, timestamp: 2022-08-20 07:41:50.404801\n",
      "resetting env. episode 2065, reward total was -17.0. running mean: -19.832922584510378, timestamp: 2022-08-20 07:41:52.184342\n",
      "resetting env. episode 2066, reward total was -20.0. running mean: -19.834593358665273, timestamp: 2022-08-20 07:41:54.666372\n",
      "resetting env. episode 2067, reward total was -19.0. running mean: -19.826247425078623, timestamp: 2022-08-20 07:41:57.382404\n",
      "resetting env. episode 2068, reward total was -20.0. running mean: -19.827984950827837, timestamp: 2022-08-20 07:41:59.248424\n",
      "resetting env. episode 2069, reward total was -19.0. running mean: -19.81970510131956, timestamp: 2022-08-20 07:42:01.610454\n",
      "resetting env. episode 2070, reward total was -21.0. running mean: -19.831508050306365, timestamp: 2022-08-20 07:42:03.348472\n",
      "resetting env. episode 2071, reward total was -18.0. running mean: -19.8131929698033, timestamp: 2022-08-20 07:42:05.605501\n",
      "resetting env. episode 2072, reward total was -19.0. running mean: -19.80506104010527, timestamp: 2022-08-20 07:42:07.004516\n",
      "resetting env. episode 2073, reward total was -20.0. running mean: -19.807010429704214, timestamp: 2022-08-20 07:42:08.448533\n",
      "resetting env. episode 2074, reward total was -20.0. running mean: -19.80894032540717, timestamp: 2022-08-20 07:42:09.898552\n",
      "resetting env. episode 2075, reward total was -21.0. running mean: -19.8208509221531, timestamp: 2022-08-20 07:42:11.628571\n",
      "resetting env. episode 2076, reward total was -19.0. running mean: -19.81264241293157, timestamp: 2022-08-20 07:42:13.222590\n",
      "resetting env. episode 2077, reward total was -21.0. running mean: -19.824515988802254, timestamp: 2022-08-20 07:42:14.248600\n",
      "resetting env. episode 2078, reward total was -20.0. running mean: -19.826270828914232, timestamp: 2022-08-20 07:42:16.356627\n",
      "resetting env. episode 2079, reward total was -20.0. running mean: -19.82800812062509, timestamp: 2022-08-20 07:42:17.604641\n",
      "resetting env. episode 2080, reward total was -20.0. running mean: -19.82972803941884, timestamp: 2022-08-20 07:42:19.740669\n",
      "resetting env. episode 2081, reward total was -20.0. running mean: -19.83143075902465, timestamp: 2022-08-20 07:42:21.612691\n",
      "resetting env. episode 2082, reward total was -20.0. running mean: -19.8331164514344, timestamp: 2022-08-20 07:42:23.272708\n",
      "resetting env. episode 2083, reward total was -21.0. running mean: -19.844785286920057, timestamp: 2022-08-20 07:42:24.860732\n",
      "resetting env. episode 2084, reward total was -20.0. running mean: -19.846337434050856, timestamp: 2022-08-20 07:42:26.403746\n",
      "resetting env. episode 2085, reward total was -21.0. running mean: -19.857874059710348, timestamp: 2022-08-20 07:42:27.791762\n",
      "resetting env. episode 2086, reward total was -18.0. running mean: -19.839295319113244, timestamp: 2022-08-20 07:42:29.486786\n",
      "resetting env. episode 2087, reward total was -18.0. running mean: -19.820902365922112, timestamp: 2022-08-20 07:42:31.584808\n",
      "resetting env. episode 2088, reward total was -20.0. running mean: -19.82269334226289, timestamp: 2022-08-20 07:42:33.261827\n",
      "resetting env. episode 2089, reward total was -19.0. running mean: -19.814466408840264, timestamp: 2022-08-20 07:42:35.038851\n",
      "resetting env. episode 2090, reward total was -21.0. running mean: -19.826321744751862, timestamp: 2022-08-20 07:42:36.411861\n",
      "resetting env. episode 2091, reward total was -15.0. running mean: -19.778058527304342, timestamp: 2022-08-20 07:42:38.657889\n",
      "resetting env. episode 2092, reward total was -20.0. running mean: -19.780277942031297, timestamp: 2022-08-20 07:42:40.056905\n",
      "resetting env. episode 2093, reward total was -20.0. running mean: -19.782475162610982, timestamp: 2022-08-20 07:42:42.025926\n",
      "resetting env. episode 2094, reward total was -20.0. running mean: -19.78465041098487, timestamp: 2022-08-20 07:42:44.156955\n",
      "resetting env. episode 2095, reward total was -20.0. running mean: -19.786803906875022, timestamp: 2022-08-20 07:42:45.814975\n",
      "resetting env. episode 2096, reward total was -21.0. running mean: -19.79893586780627, timestamp: 2022-08-20 07:42:47.103988\n",
      "resetting env. episode 2097, reward total was -21.0. running mean: -19.81094650912821, timestamp: 2022-08-20 07:42:48.669009\n",
      "resetting env. episode 2098, reward total was -19.0. running mean: -19.80283704403693, timestamp: 2022-08-20 07:42:50.268030\n",
      "resetting env. episode 2099, reward total was -19.0. running mean: -19.794808673596563, timestamp: 2022-08-20 07:42:52.601053\n",
      "resetting env. episode 2100, reward total was -19.0. running mean: -19.7868605868606, timestamp: 2022-08-20 07:42:54.197072\n",
      "resetting env. episode 2101, reward total was -19.0. running mean: -19.778991980991993, timestamp: 2022-08-20 07:42:55.820091\n",
      "resetting env. episode 2102, reward total was -21.0. running mean: -19.791202061182073, timestamp: 2022-08-20 07:42:57.555112\n",
      "resetting env. episode 2103, reward total was -18.0. running mean: -19.773290040570252, timestamp: 2022-08-20 07:42:59.587136\n",
      "resetting env. episode 2104, reward total was -21.0. running mean: -19.78555714016455, timestamp: 2022-08-20 07:43:01.049152\n",
      "resetting env. episode 2105, reward total was -18.0. running mean: -19.767701568762902, timestamp: 2022-08-20 07:43:03.570182\n",
      "resetting env. episode 2106, reward total was -20.0. running mean: -19.770024553075274, timestamp: 2022-08-20 07:43:05.549205\n",
      "resetting env. episode 2107, reward total was -17.0. running mean: -19.74232430754452, timestamp: 2022-08-20 07:43:10.493264\n",
      "resetting env. episode 2108, reward total was -20.0. running mean: -19.744901064469076, timestamp: 2022-08-20 07:43:11.896280\n",
      "resetting env. episode 2109, reward total was -20.0. running mean: -19.747452053824386, timestamp: 2022-08-20 07:43:14.014303\n",
      "resetting env. episode 2110, reward total was -20.0. running mean: -19.749977533286142, timestamp: 2022-08-20 07:43:15.419319\n",
      "resetting env. episode 2111, reward total was -21.0. running mean: -19.76247775795328, timestamp: 2022-08-20 07:43:16.852340\n",
      "resetting env. episode 2112, reward total was -20.0. running mean: -19.764852980373746, timestamp: 2022-08-20 07:43:19.394366\n",
      "resetting env. episode 2113, reward total was -19.0. running mean: -19.75720445057001, timestamp: 2022-08-20 07:43:21.131388\n",
      "resetting env. episode 2114, reward total was -21.0. running mean: -19.76963240606431, timestamp: 2022-08-20 07:43:22.728403\n",
      "resetting env. episode 2115, reward total was -21.0. running mean: -19.781936082003668, timestamp: 2022-08-20 07:43:24.448424\n",
      "resetting env. episode 2116, reward total was -21.0. running mean: -19.79411672118363, timestamp: 2022-08-20 07:43:25.548438\n",
      "resetting env. episode 2117, reward total was -21.0. running mean: -19.806175553971794, timestamp: 2022-08-20 07:43:27.548463\n",
      "resetting env. episode 2118, reward total was -17.0. running mean: -19.778113798432077, timestamp: 2022-08-20 07:43:30.833502\n",
      "resetting env. episode 2119, reward total was -20.0. running mean: -19.780332660447755, timestamp: 2022-08-20 07:43:32.507518\n",
      "resetting env. episode 2120, reward total was -20.0. running mean: -19.782529333843275, timestamp: 2022-08-20 07:43:33.705536\n",
      "resetting env. episode 2121, reward total was -20.0. running mean: -19.78470404050484, timestamp: 2022-08-20 07:43:36.048561\n",
      "resetting env. episode 2122, reward total was -21.0. running mean: -19.796857000099795, timestamp: 2022-08-20 07:43:37.399580\n",
      "resetting env. episode 2123, reward total was -21.0. running mean: -19.808888430098797, timestamp: 2022-08-20 07:43:39.391127\n",
      "resetting env. episode 2124, reward total was -21.0. running mean: -19.82079954579781, timestamp: 2022-08-20 07:43:40.595140\n",
      "resetting env. episode 2125, reward total was -20.0. running mean: -19.822591550339833, timestamp: 2022-08-20 07:43:42.679165\n",
      "resetting env. episode 2126, reward total was -20.0. running mean: -19.824365634836433, timestamp: 2022-08-20 07:43:43.957181\n",
      "resetting env. episode 2127, reward total was -17.0. running mean: -19.79612197848807, timestamp: 2022-08-20 07:43:46.028205\n",
      "resetting env. episode 2128, reward total was -21.0. running mean: -19.808160758703192, timestamp: 2022-08-20 07:43:47.575223\n",
      "resetting env. episode 2129, reward total was -21.0. running mean: -19.82007915111616, timestamp: 2022-08-20 07:43:49.062242\n",
      "resetting env. episode 2130, reward total was -21.0. running mean: -19.831878359605, timestamp: 2022-08-20 07:43:50.450258\n",
      "resetting env. episode 2131, reward total was -20.0. running mean: -19.83355957600895, timestamp: 2022-08-20 07:43:52.744283\n",
      "resetting env. episode 2132, reward total was -21.0. running mean: -19.84522398024886, timestamp: 2022-08-20 07:43:54.474311\n",
      "resetting env. episode 2133, reward total was -21.0. running mean: -19.856771740446373, timestamp: 2022-08-20 07:43:55.548317\n",
      "resetting env. episode 2134, reward total was -21.0. running mean: -19.86820402304191, timestamp: 2022-08-20 07:43:56.896335\n",
      "resetting env. episode 2135, reward total was -19.0. running mean: -19.85952198281149, timestamp: 2022-08-20 07:43:58.310352\n",
      "resetting env. episode 2136, reward total was -21.0. running mean: -19.870926762983377, timestamp: 2022-08-20 07:43:59.722365\n",
      "resetting env. episode 2137, reward total was -20.0. running mean: -19.872217495353542, timestamp: 2022-08-20 07:44:01.444385\n",
      "resetting env. episode 2138, reward total was -20.0. running mean: -19.873495320400007, timestamp: 2022-08-20 07:44:03.404412\n",
      "resetting env. episode 2139, reward total was -20.0. running mean: -19.874760367196007, timestamp: 2022-08-20 07:44:06.619447\n",
      "resetting env. episode 2140, reward total was -20.0. running mean: -19.876012763524045, timestamp: 2022-08-20 07:44:08.495471\n",
      "resetting env. episode 2141, reward total was -21.0. running mean: -19.887252635888807, timestamp: 2022-08-20 07:44:09.862486\n",
      "resetting env. episode 2142, reward total was -20.0. running mean: -19.88838010952992, timestamp: 2022-08-20 07:44:11.176501\n",
      "resetting env. episode 2143, reward total was -21.0. running mean: -19.89949630843462, timestamp: 2022-08-20 07:44:12.754522\n",
      "resetting env. episode 2144, reward total was -20.0. running mean: -19.900501345350275, timestamp: 2022-08-20 07:44:14.691544\n",
      "resetting env. episode 2145, reward total was -20.0. running mean: -19.90149633189677, timestamp: 2022-08-20 07:44:16.093562\n",
      "resetting env. episode 2146, reward total was -21.0. running mean: -19.9124813685778, timestamp: 2022-08-20 07:44:17.349575\n",
      "resetting env. episode 2147, reward total was -21.0. running mean: -19.923356554892024, timestamp: 2022-08-20 07:44:18.752592\n",
      "resetting env. episode 2148, reward total was -21.0. running mean: -19.934122989343106, timestamp: 2022-08-20 07:44:20.254613\n",
      "resetting env. episode 2149, reward total was -20.0. running mean: -19.934781759449674, timestamp: 2022-08-20 07:44:21.601625\n",
      "resetting env. episode 2150, reward total was -20.0. running mean: -19.935433941855177, timestamp: 2022-08-20 07:44:23.493648\n",
      "resetting env. episode 2151, reward total was -21.0. running mean: -19.946079602436626, timestamp: 2022-08-20 07:44:25.073670\n",
      "resetting env. episode 2152, reward total was -18.0. running mean: -19.92661880641226, timestamp: 2022-08-20 07:44:26.556684\n",
      "resetting env. episode 2153, reward total was -20.0. running mean: -19.927352618348138, timestamp: 2022-08-20 07:44:28.383704\n",
      "resetting env. episode 2154, reward total was -19.0. running mean: -19.918079092164657, timestamp: 2022-08-20 07:44:30.591731\n",
      "resetting env. episode 2155, reward total was -19.0. running mean: -19.90889830124301, timestamp: 2022-08-20 07:44:32.857759\n",
      "resetting env. episode 2156, reward total was -21.0. running mean: -19.91980931823058, timestamp: 2022-08-20 07:44:34.146773\n",
      "resetting env. episode 2157, reward total was -19.0. running mean: -19.910611225048275, timestamp: 2022-08-20 07:44:36.018793\n",
      "resetting env. episode 2158, reward total was -21.0. running mean: -19.921505112797792, timestamp: 2022-08-20 07:44:37.600814\n",
      "resetting env. episode 2159, reward total was -20.0. running mean: -19.922290061669813, timestamp: 2022-08-20 07:44:39.109833\n",
      "resetting env. episode 2160, reward total was -19.0. running mean: -19.913067161053117, timestamp: 2022-08-20 07:44:40.797849\n",
      "resetting env. episode 2161, reward total was -21.0. running mean: -19.923936489442585, timestamp: 2022-08-20 07:44:42.078873\n",
      "resetting env. episode 2162, reward total was -16.0. running mean: -19.88469712454816, timestamp: 2022-08-20 07:44:44.011893\n",
      "resetting env. episode 2163, reward total was -20.0. running mean: -19.88585015330268, timestamp: 2022-08-20 07:44:45.324907\n",
      "resetting env. episode 2164, reward total was -18.0. running mean: -19.866991651769652, timestamp: 2022-08-20 07:44:47.617932\n",
      "resetting env. episode 2165, reward total was -21.0. running mean: -19.878321735251955, timestamp: 2022-08-20 07:44:48.820946\n",
      "resetting env. episode 2166, reward total was -17.0. running mean: -19.849538517899436, timestamp: 2022-08-20 07:44:51.484975\n",
      "resetting env. episode 2167, reward total was -20.0. running mean: -19.85104313272044, timestamp: 2022-08-20 07:44:53.542001\n",
      "resetting env. episode 2168, reward total was -21.0. running mean: -19.86253270139324, timestamp: 2022-08-20 07:44:54.809027\n",
      "resetting env. episode 2169, reward total was -21.0. running mean: -19.873907374379307, timestamp: 2022-08-20 07:44:55.920027\n",
      "resetting env. episode 2170, reward total was -21.0. running mean: -19.885168300635513, timestamp: 2022-08-20 07:44:57.098042\n",
      "resetting env. episode 2171, reward total was -21.0. running mean: -19.896316617629157, timestamp: 2022-08-20 07:44:58.553059\n",
      "resetting env. episode 2172, reward total was -20.0. running mean: -19.897353451452865, timestamp: 2022-08-20 07:45:00.066080\n",
      "resetting env. episode 2173, reward total was -21.0. running mean: -19.908379916938337, timestamp: 2022-08-20 07:45:01.192089\n",
      "resetting env. episode 2174, reward total was -20.0. running mean: -19.909296117768953, timestamp: 2022-08-20 07:45:03.049109\n",
      "resetting env. episode 2175, reward total was -19.0. running mean: -19.900203156591264, timestamp: 2022-08-20 07:45:04.688131\n",
      "resetting env. episode 2176, reward total was -21.0. running mean: -19.91120112502535, timestamp: 2022-08-20 07:45:05.911145\n",
      "resetting env. episode 2177, reward total was -20.0. running mean: -19.912089113775096, timestamp: 2022-08-20 07:45:07.360164\n",
      "resetting env. episode 2178, reward total was -21.0. running mean: -19.922968222637344, timestamp: 2022-08-20 07:45:08.536175\n",
      "resetting env. episode 2179, reward total was -21.0. running mean: -19.93373854041097, timestamp: 2022-08-20 07:45:09.814193\n",
      "resetting env. episode 2180, reward total was -20.0. running mean: -19.93440115500686, timestamp: 2022-08-20 07:45:10.985205\n",
      "resetting env. episode 2181, reward total was -20.0. running mean: -19.935057143456792, timestamp: 2022-08-20 07:45:12.686225\n",
      "resetting env. episode 2182, reward total was -21.0. running mean: -19.945706572022225, timestamp: 2022-08-20 07:45:13.739235\n",
      "resetting env. episode 2183, reward total was -21.0. running mean: -19.956249506302004, timestamp: 2022-08-20 07:45:15.233254\n",
      "resetting env. episode 2184, reward total was -21.0. running mean: -19.966687011238985, timestamp: 2022-08-20 07:45:16.652271\n",
      "resetting env. episode 2185, reward total was -21.0. running mean: -19.977020141126594, timestamp: 2022-08-20 07:45:17.906288\n",
      "resetting env. episode 2186, reward total was -19.0. running mean: -19.96724993971533, timestamp: 2022-08-20 07:45:19.413302\n",
      "resetting env. episode 2187, reward total was -21.0. running mean: -19.97757744031818, timestamp: 2022-08-20 07:45:20.676320\n",
      "resetting env. episode 2188, reward total was -21.0. running mean: -19.987801665914997, timestamp: 2022-08-20 07:45:23.508349\n",
      "resetting env. episode 2189, reward total was -19.0. running mean: -19.97792364925585, timestamp: 2022-08-20 07:45:25.699376\n",
      "resetting env. episode 2190, reward total was -20.0. running mean: -19.97814441276329, timestamp: 2022-08-20 07:45:27.055395\n",
      "resetting env. episode 2191, reward total was -20.0. running mean: -19.978362968635654, timestamp: 2022-08-20 07:45:29.142417\n",
      "resetting env. episode 2192, reward total was -20.0. running mean: -19.978579338949295, timestamp: 2022-08-20 07:45:30.930440\n",
      "resetting env. episode 2193, reward total was -21.0. running mean: -19.9887935455598, timestamp: 2022-08-20 07:45:32.339456\n",
      "resetting env. episode 2194, reward total was -19.0. running mean: -19.978905610104203, timestamp: 2022-08-20 07:45:34.931485\n",
      "resetting env. episode 2195, reward total was -21.0. running mean: -19.98911655400316, timestamp: 2022-08-20 07:45:36.295501\n",
      "resetting env. episode 2196, reward total was -20.0. running mean: -19.98922538846313, timestamp: 2022-08-20 07:45:38.530527\n",
      "resetting env. episode 2197, reward total was -20.0. running mean: -19.989333134578498, timestamp: 2022-08-20 07:45:40.520552\n",
      "resetting env. episode 2198, reward total was -20.0. running mean: -19.989439803232713, timestamp: 2022-08-20 07:45:42.544576\n",
      "resetting env. episode 2199, reward total was -19.0. running mean: -19.979545405200387, timestamp: 2022-08-20 07:45:44.158594\n",
      "resetting env. episode 2200, reward total was -21.0. running mean: -19.989749951148383, timestamp: 2022-08-20 07:45:45.507606\n",
      "resetting env. episode 2201, reward total was -21.0. running mean: -19.9998524516369, timestamp: 2022-08-20 07:45:46.618621\n",
      "resetting env. episode 2202, reward total was -20.0. running mean: -19.99985392712053, timestamp: 2022-08-20 07:45:47.988637\n",
      "resetting env. episode 2203, reward total was -21.0. running mean: -20.009855387849324, timestamp: 2022-08-20 07:45:49.076653\n",
      "resetting env. episode 2204, reward total was -19.0. running mean: -19.99975683397083, timestamp: 2022-08-20 07:45:50.899674\n",
      "resetting env. episode 2205, reward total was -21.0. running mean: -20.009759265631125, timestamp: 2022-08-20 07:45:52.083684\n",
      "resetting env. episode 2206, reward total was -21.0. running mean: -20.019661672974813, timestamp: 2022-08-20 07:45:53.422701\n",
      "resetting env. episode 2207, reward total was -20.0. running mean: -20.019465056245064, timestamp: 2022-08-20 07:45:55.734730\n",
      "resetting env. episode 2208, reward total was -21.0. running mean: -20.029270405682613, timestamp: 2022-08-20 07:45:58.094755\n",
      "resetting env. episode 2209, reward total was -20.0. running mean: -20.028977701625784, timestamp: 2022-08-20 07:45:59.797778\n",
      "resetting env. episode 2210, reward total was -20.0. running mean: -20.028687924609525, timestamp: 2022-08-20 07:46:01.526799\n",
      "resetting env. episode 2211, reward total was -16.0. running mean: -19.988401045363428, timestamp: 2022-08-20 07:46:04.261833\n",
      "resetting env. episode 2212, reward total was -20.0. running mean: -19.988517034909794, timestamp: 2022-08-20 07:46:05.654848\n",
      "resetting env. episode 2213, reward total was -19.0. running mean: -19.978631864560697, timestamp: 2022-08-20 07:46:08.146874\n",
      "resetting env. episode 2214, reward total was -21.0. running mean: -19.98884554591509, timestamp: 2022-08-20 07:46:09.182891\n",
      "resetting env. episode 2215, reward total was -20.0. running mean: -19.988957090455937, timestamp: 2022-08-20 07:46:10.722906\n",
      "resetting env. episode 2216, reward total was -21.0. running mean: -19.999067519551378, timestamp: 2022-08-20 07:46:12.355929\n",
      "resetting env. episode 2217, reward total was -21.0. running mean: -20.009076844355864, timestamp: 2022-08-20 07:46:14.302958\n",
      "resetting env. episode 2218, reward total was -19.0. running mean: -19.998986075912306, timestamp: 2022-08-20 07:46:17.576988\n",
      "resetting env. episode 2219, reward total was -20.0. running mean: -19.99899621515318, timestamp: 2022-08-20 07:46:19.140007\n",
      "resetting env. episode 2220, reward total was -20.0. running mean: -19.99900625300165, timestamp: 2022-08-20 07:46:20.524023\n",
      "resetting env. episode 2221, reward total was -19.0. running mean: -19.989016190471634, timestamp: 2022-08-20 07:46:22.296041\n",
      "resetting env. episode 2222, reward total was -21.0. running mean: -19.99912602856692, timestamp: 2022-08-20 07:46:23.684057\n",
      "resetting env. episode 2223, reward total was -20.0. running mean: -19.999134768281248, timestamp: 2022-08-20 07:46:25.090075\n",
      "resetting env. episode 2224, reward total was -16.0. running mean: -19.959143420598437, timestamp: 2022-08-20 07:46:27.414105\n",
      "resetting env. episode 2225, reward total was -21.0. running mean: -19.969551986392453, timestamp: 2022-08-20 07:46:29.422131\n",
      "resetting env. episode 2226, reward total was -21.0. running mean: -19.979856466528528, timestamp: 2022-08-20 07:46:31.088147\n",
      "resetting env. episode 2227, reward total was -20.0. running mean: -19.98005790186324, timestamp: 2022-08-20 07:46:32.625164\n",
      "resetting env. episode 2228, reward total was -20.0. running mean: -19.980257322844608, timestamp: 2022-08-20 07:46:34.513186\n",
      "resetting env. episode 2229, reward total was -21.0. running mean: -19.990454749616163, timestamp: 2022-08-20 07:46:36.495209\n",
      "resetting env. episode 2230, reward total was -20.0. running mean: -19.99055020212, timestamp: 2022-08-20 07:46:38.220230\n",
      "resetting env. episode 2231, reward total was -21.0. running mean: -20.000644700098803, timestamp: 2022-08-20 07:46:40.148254\n",
      "resetting env. episode 2232, reward total was -21.0. running mean: -20.010638253097817, timestamp: 2022-08-20 07:46:41.426269\n",
      "resetting env. episode 2233, reward total was -21.0. running mean: -20.02053187056684, timestamp: 2022-08-20 07:46:42.890286\n",
      "resetting env. episode 2234, reward total was -21.0. running mean: -20.03032655186117, timestamp: 2022-08-20 07:46:44.604306\n",
      "resetting env. episode 2235, reward total was -21.0. running mean: -20.040023286342556, timestamp: 2022-08-20 07:46:46.752336\n",
      "resetting env. episode 2236, reward total was -21.0. running mean: -20.04962305347913, timestamp: 2022-08-20 07:46:48.158355\n",
      "resetting env. episode 2237, reward total was -21.0. running mean: -20.05912682294434, timestamp: 2022-08-20 07:46:49.253361\n",
      "resetting env. episode 2238, reward total was -21.0. running mean: -20.068535554714895, timestamp: 2022-08-20 07:46:50.433375\n",
      "resetting env. episode 2239, reward total was -19.0. running mean: -20.057850199167746, timestamp: 2022-08-20 07:46:53.250407\n",
      "resetting env. episode 2240, reward total was -21.0. running mean: -20.067271697176068, timestamp: 2022-08-20 07:46:54.419422\n",
      "resetting env. episode 2241, reward total was -19.0. running mean: -20.05659898020431, timestamp: 2022-08-20 07:46:56.263444\n",
      "resetting env. episode 2242, reward total was -20.0. running mean: -20.056032990402265, timestamp: 2022-08-20 07:46:57.393462\n",
      "resetting env. episode 2243, reward total was -21.0. running mean: -20.065472660498244, timestamp: 2022-08-20 07:46:58.834478\n",
      "resetting env. episode 2244, reward total was -19.0. running mean: -20.05481793389326, timestamp: 2022-08-20 07:47:00.425493\n",
      "resetting env. episode 2245, reward total was -20.0. running mean: -20.054269754554326, timestamp: 2022-08-20 07:47:01.770511\n",
      "resetting env. episode 2246, reward total was -21.0. running mean: -20.063727057008784, timestamp: 2022-08-20 07:47:02.813523\n",
      "resetting env. episode 2247, reward total was -19.0. running mean: -20.053089786438697, timestamp: 2022-08-20 07:47:04.401540\n",
      "resetting env. episode 2248, reward total was -21.0. running mean: -20.062558888574312, timestamp: 2022-08-20 07:47:06.220561\n",
      "resetting env. episode 2249, reward total was -21.0. running mean: -20.07193329968857, timestamp: 2022-08-20 07:47:07.282574\n",
      "resetting env. episode 2250, reward total was -21.0. running mean: -20.081213966691685, timestamp: 2022-08-20 07:47:08.611590\n",
      "resetting env. episode 2251, reward total was -20.0. running mean: -20.08040182702477, timestamp: 2022-08-20 07:47:09.907605\n",
      "resetting env. episode 2252, reward total was -20.0. running mean: -20.07959780875452, timestamp: 2022-08-20 07:47:11.756626\n",
      "resetting env. episode 2253, reward total was -20.0. running mean: -20.078801830666976, timestamp: 2022-08-20 07:47:13.388649\n",
      "resetting env. episode 2254, reward total was -17.0. running mean: -20.048013812360306, timestamp: 2022-08-20 07:47:16.081679\n",
      "resetting env. episode 2255, reward total was -21.0. running mean: -20.057533674236705, timestamp: 2022-08-20 07:47:17.126690\n",
      "resetting env. episode 2256, reward total was -19.0. running mean: -20.04695833749434, timestamp: 2022-08-20 07:47:18.940711\n",
      "resetting env. episode 2257, reward total was -20.0. running mean: -20.046488754119395, timestamp: 2022-08-20 07:47:20.312727\n",
      "resetting env. episode 2258, reward total was -20.0. running mean: -20.0460238665782, timestamp: 2022-08-20 07:47:21.885748\n",
      "resetting env. episode 2259, reward total was -20.0. running mean: -20.045563627912415, timestamp: 2022-08-20 07:47:23.808770\n",
      "resetting env. episode 2260, reward total was -20.0. running mean: -20.04510799163329, timestamp: 2022-08-20 07:47:25.709794\n",
      "resetting env. episode 2261, reward total was -21.0. running mean: -20.054656911716958, timestamp: 2022-08-20 07:47:26.959810\n",
      "resetting env. episode 2262, reward total was -21.0. running mean: -20.06411034259979, timestamp: 2022-08-20 07:47:28.566829\n",
      "resetting env. episode 2263, reward total was -21.0. running mean: -20.073469239173793, timestamp: 2022-08-20 07:47:29.675840\n",
      "resetting env. episode 2264, reward total was -21.0. running mean: -20.082734546782056, timestamp: 2022-08-20 07:47:31.422861\n",
      "resetting env. episode 2265, reward total was -21.0. running mean: -20.091907201314235, timestamp: 2022-08-20 07:47:32.952881\n",
      "resetting env. episode 2266, reward total was -21.0. running mean: -20.100988129301093, timestamp: 2022-08-20 07:47:34.519898\n",
      "resetting env. episode 2267, reward total was -21.0. running mean: -20.109978248008083, timestamp: 2022-08-20 07:47:36.011917\n",
      "resetting env. episode 2268, reward total was -20.0. running mean: -20.108878465528, timestamp: 2022-08-20 07:47:37.470932\n",
      "resetting env. episode 2269, reward total was -21.0. running mean: -20.117789680872722, timestamp: 2022-08-20 07:47:38.854953\n",
      "resetting env. episode 2270, reward total was -21.0. running mean: -20.126611784063996, timestamp: 2022-08-20 07:47:40.028965\n",
      "resetting env. episode 2271, reward total was -21.0. running mean: -20.13534566622336, timestamp: 2022-08-20 07:47:42.158988\n",
      "resetting env. episode 2272, reward total was -21.0. running mean: -20.143992209561127, timestamp: 2022-08-20 07:47:45.282028\n",
      "resetting env. episode 2273, reward total was -19.0. running mean: -20.132552287465515, timestamp: 2022-08-20 07:47:46.809044\n",
      "resetting env. episode 2274, reward total was -19.0. running mean: -20.121226764590862, timestamp: 2022-08-20 07:47:48.146061\n",
      "resetting env. episode 2275, reward total was -19.0. running mean: -20.110014496944956, timestamp: 2022-08-20 07:47:50.600092\n",
      "resetting env. episode 2276, reward total was -21.0. running mean: -20.11891435197551, timestamp: 2022-08-20 07:47:51.980119\n",
      "resetting env. episode 2277, reward total was -21.0. running mean: -20.127725208455754, timestamp: 2022-08-20 07:47:53.162120\n",
      "resetting env. episode 2278, reward total was -21.0. running mean: -20.136447956371196, timestamp: 2022-08-20 07:47:54.832141\n",
      "resetting env. episode 2279, reward total was -21.0. running mean: -20.145083476807486, timestamp: 2022-08-20 07:47:57.465175\n",
      "resetting env. episode 2280, reward total was -20.0. running mean: -20.14363264203941, timestamp: 2022-08-20 07:47:58.915190\n",
      "resetting env. episode 2281, reward total was -21.0. running mean: -20.152196315619015, timestamp: 2022-08-20 07:48:00.600210\n",
      "resetting env. episode 2282, reward total was -21.0. running mean: -20.160674352462827, timestamp: 2022-08-20 07:48:01.924230\n",
      "resetting env. episode 2283, reward total was -21.0. running mean: -20.1690676089382, timestamp: 2022-08-20 07:48:03.408248\n",
      "resetting env. episode 2284, reward total was -21.0. running mean: -20.17737693284882, timestamp: 2022-08-20 07:48:04.897266\n",
      "resetting env. episode 2285, reward total was -20.0. running mean: -20.17560316352033, timestamp: 2022-08-20 07:48:06.075280\n",
      "resetting env. episode 2286, reward total was -20.0. running mean: -20.173847131885125, timestamp: 2022-08-20 07:48:07.667295\n",
      "resetting env. episode 2287, reward total was -21.0. running mean: -20.182108660566275, timestamp: 2022-08-20 07:48:08.839310\n",
      "resetting env. episode 2288, reward total was -20.0. running mean: -20.180287573960612, timestamp: 2022-08-20 07:48:10.719858\n",
      "resetting env. episode 2289, reward total was -20.0. running mean: -20.178484698221006, timestamp: 2022-08-20 07:48:12.333876\n",
      "resetting env. episode 2290, reward total was -20.0. running mean: -20.176699851238794, timestamp: 2022-08-20 07:48:13.653891\n",
      "resetting env. episode 2291, reward total was -20.0. running mean: -20.174932852726407, timestamp: 2022-08-20 07:48:15.044907\n",
      "resetting env. episode 2292, reward total was -19.0. running mean: -20.163183524199145, timestamp: 2022-08-20 07:48:16.717930\n",
      "resetting env. episode 2293, reward total was -20.0. running mean: -20.161551688957154, timestamp: 2022-08-20 07:48:18.470952\n",
      "resetting env. episode 2294, reward total was -21.0. running mean: -20.169936172067583, timestamp: 2022-08-20 07:48:19.731964\n",
      "resetting env. episode 2295, reward total was -21.0. running mean: -20.17823681034691, timestamp: 2022-08-20 07:48:20.766974\n",
      "resetting env. episode 2296, reward total was -21.0. running mean: -20.18645444224344, timestamp: 2022-08-20 07:48:22.197992\n",
      "resetting env. episode 2297, reward total was -19.0. running mean: -20.174589897821008, timestamp: 2022-08-20 07:48:25.215036\n",
      "resetting env. episode 2298, reward total was -19.0. running mean: -20.1628439988428, timestamp: 2022-08-20 07:48:27.469059\n",
      "resetting env. episode 2299, reward total was -19.0. running mean: -20.15121555885437, timestamp: 2022-08-20 07:48:29.175076\n",
      "resetting env. episode 2300, reward total was -21.0. running mean: -20.15970340326583, timestamp: 2022-08-20 07:48:30.350617\n",
      "resetting env. episode 2301, reward total was -20.0. running mean: -20.15810636923317, timestamp: 2022-08-20 07:48:31.859638\n",
      "resetting env. episode 2302, reward total was -18.0. running mean: -20.13652530554084, timestamp: 2022-08-20 07:48:33.852665\n",
      "resetting env. episode 2303, reward total was -20.0. running mean: -20.135160052485432, timestamp: 2022-08-20 07:48:35.598682\n",
      "resetting env. episode 2304, reward total was -20.0. running mean: -20.133808451960576, timestamp: 2022-08-20 07:48:36.954699\n",
      "resetting env. episode 2305, reward total was -21.0. running mean: -20.14247036744097, timestamp: 2022-08-20 07:48:38.085710\n",
      "resetting env. episode 2306, reward total was -20.0. running mean: -20.141045663766562, timestamp: 2022-08-20 07:48:39.488729\n",
      "resetting env. episode 2307, reward total was -21.0. running mean: -20.149635207128895, timestamp: 2022-08-20 07:48:40.924745\n",
      "resetting env. episode 2308, reward total was -16.0. running mean: -20.108138855057607, timestamp: 2022-08-20 07:48:43.977783\n",
      "resetting env. episode 2309, reward total was -18.0. running mean: -20.08705746650703, timestamp: 2022-08-20 07:48:45.832806\n",
      "resetting env. episode 2310, reward total was -21.0. running mean: -20.09618689184196, timestamp: 2022-08-20 07:48:47.366821\n",
      "resetting env. episode 2311, reward total was -20.0. running mean: -20.09522502292354, timestamp: 2022-08-20 07:48:48.693838\n",
      "resetting env. episode 2312, reward total was -20.0. running mean: -20.094272772694303, timestamp: 2022-08-20 07:48:51.023866\n",
      "resetting env. episode 2313, reward total was -21.0. running mean: -20.10333004496736, timestamp: 2022-08-20 07:48:52.479883\n",
      "resetting env. episode 2314, reward total was -20.0. running mean: -20.102296744517687, timestamp: 2022-08-20 07:48:54.169905\n",
      "resetting env. episode 2315, reward total was -20.0. running mean: -20.10127377707251, timestamp: 2022-08-20 07:48:55.788927\n",
      "resetting env. episode 2316, reward total was -21.0. running mean: -20.110261039301786, timestamp: 2022-08-20 07:48:57.433942\n",
      "resetting env. episode 2317, reward total was -20.0. running mean: -20.109158428908767, timestamp: 2022-08-20 07:48:58.504959\n",
      "resetting env. episode 2318, reward total was -21.0. running mean: -20.11806684461968, timestamp: 2022-08-20 07:49:01.289989\n",
      "resetting env. episode 2319, reward total was -21.0. running mean: -20.126886176173482, timestamp: 2022-08-20 07:49:02.951014\n",
      "resetting env. episode 2320, reward total was -19.0. running mean: -20.115617314411747, timestamp: 2022-08-20 07:49:04.601032\n",
      "resetting env. episode 2321, reward total was -19.0. running mean: -20.10446114126763, timestamp: 2022-08-20 07:49:06.202047\n",
      "resetting env. episode 2322, reward total was -18.0. running mean: -20.083416529854954, timestamp: 2022-08-20 07:49:09.023084\n",
      "resetting env. episode 2323, reward total was -19.0. running mean: -20.072582364556407, timestamp: 2022-08-20 07:49:10.873109\n",
      "resetting env. episode 2324, reward total was -18.0. running mean: -20.051856540910844, timestamp: 2022-08-20 07:49:12.967132\n",
      "resetting env. episode 2325, reward total was -21.0. running mean: -20.061337975501736, timestamp: 2022-08-20 07:49:14.078145\n",
      "resetting env. episode 2326, reward total was -20.0. running mean: -20.060724595746716, timestamp: 2022-08-20 07:49:15.892691\n",
      "resetting env. episode 2327, reward total was -19.0. running mean: -20.05011734978925, timestamp: 2022-08-20 07:49:17.525711\n",
      "resetting env. episode 2328, reward total was -21.0. running mean: -20.059616176291357, timestamp: 2022-08-20 07:49:18.902725\n",
      "resetting env. episode 2329, reward total was -17.0. running mean: -20.029020014528445, timestamp: 2022-08-20 07:49:21.514760\n",
      "resetting env. episode 2330, reward total was -20.0. running mean: -20.02872981438316, timestamp: 2022-08-20 07:49:22.911773\n",
      "resetting env. episode 2331, reward total was -21.0. running mean: -20.03844251623933, timestamp: 2022-08-20 07:49:24.253790\n",
      "resetting env. episode 2332, reward total was -15.0. running mean: -19.988058091076933, timestamp: 2022-08-20 07:49:26.720822\n",
      "resetting env. episode 2333, reward total was -21.0. running mean: -19.998177510166165, timestamp: 2022-08-20 07:49:28.297839\n",
      "resetting env. episode 2334, reward total was -20.0. running mean: -19.998195735064503, timestamp: 2022-08-20 07:49:29.502854\n",
      "resetting env. episode 2335, reward total was -20.0. running mean: -19.998213777713858, timestamp: 2022-08-20 07:49:31.591879\n",
      "resetting env. episode 2336, reward total was -21.0. running mean: -20.00823163993672, timestamp: 2022-08-20 07:49:33.005898\n",
      "resetting env. episode 2337, reward total was -19.0. running mean: -19.998149323537355, timestamp: 2022-08-20 07:49:35.002920\n",
      "resetting env. episode 2338, reward total was -19.0. running mean: -19.988167830301983, timestamp: 2022-08-20 07:49:36.451937\n",
      "resetting env. episode 2339, reward total was -18.0. running mean: -19.968286151998964, timestamp: 2022-08-20 07:49:40.131981\n",
      "resetting env. episode 2340, reward total was -20.0. running mean: -19.968603290478974, timestamp: 2022-08-20 07:49:41.289995\n",
      "resetting env. episode 2341, reward total was -20.0. running mean: -19.968917257574184, timestamp: 2022-08-20 07:49:43.692023\n",
      "resetting env. episode 2342, reward total was -21.0. running mean: -19.979228084998443, timestamp: 2022-08-20 07:49:45.038042\n",
      "resetting env. episode 2343, reward total was -19.0. running mean: -19.96943580414846, timestamp: 2022-08-20 07:49:46.755066\n",
      "resetting env. episode 2344, reward total was -20.0. running mean: -19.969741446106976, timestamp: 2022-08-20 07:49:48.449080\n",
      "resetting env. episode 2345, reward total was -19.0. running mean: -19.960044031645907, timestamp: 2022-08-20 07:49:50.651108\n",
      "resetting env. episode 2346, reward total was -20.0. running mean: -19.960443591329447, timestamp: 2022-08-20 07:49:51.975129\n",
      "resetting env. episode 2347, reward total was -20.0. running mean: -19.960839155416153, timestamp: 2022-08-20 07:49:53.832144\n",
      "resetting env. episode 2348, reward total was -20.0. running mean: -19.96123076386199, timestamp: 2022-08-20 07:49:55.460167\n",
      "resetting env. episode 2349, reward total was -20.0. running mean: -19.96161845622337, timestamp: 2022-08-20 07:49:57.476193\n",
      "resetting env. episode 2350, reward total was -18.0. running mean: -19.942002271661135, timestamp: 2022-08-20 07:49:59.204211\n",
      "resetting env. episode 2351, reward total was -18.0. running mean: -19.922582248944522, timestamp: 2022-08-20 07:50:00.858234\n",
      "resetting env. episode 2352, reward total was -20.0. running mean: -19.923356426455076, timestamp: 2022-08-20 07:50:02.106244\n",
      "resetting env. episode 2353, reward total was -20.0. running mean: -19.924122862190526, timestamp: 2022-08-20 07:50:04.290271\n",
      "resetting env. episode 2354, reward total was -20.0. running mean: -19.92488163356862, timestamp: 2022-08-20 07:50:05.730290\n",
      "resetting env. episode 2355, reward total was -19.0. running mean: -19.915632817232936, timestamp: 2022-08-20 07:50:06.955304\n",
      "resetting env. episode 2356, reward total was -17.0. running mean: -19.88647648906061, timestamp: 2022-08-20 07:50:09.566335\n",
      "resetting env. episode 2357, reward total was -21.0. running mean: -19.897611724170005, timestamp: 2022-08-20 07:50:11.188353\n",
      "resetting env. episode 2358, reward total was -21.0. running mean: -19.908635606928307, timestamp: 2022-08-20 07:50:12.698374\n",
      "resetting env. episode 2359, reward total was -19.0. running mean: -19.899549250859025, timestamp: 2022-08-20 07:50:14.423396\n",
      "resetting env. episode 2360, reward total was -21.0. running mean: -19.910553758350435, timestamp: 2022-08-20 07:50:15.799410\n",
      "resetting env. episode 2361, reward total was -21.0. running mean: -19.92144822076693, timestamp: 2022-08-20 07:50:16.967427\n",
      "resetting env. episode 2362, reward total was -18.0. running mean: -19.90223373855926, timestamp: 2022-08-20 07:50:19.473458\n",
      "resetting env. episode 2363, reward total was -20.0. running mean: -19.903211401173667, timestamp: 2022-08-20 07:50:21.238476\n",
      "resetting env. episode 2364, reward total was -21.0. running mean: -19.914179287161932, timestamp: 2022-08-20 07:50:22.488489\n",
      "resetting env. episode 2365, reward total was -18.0. running mean: -19.895037494290314, timestamp: 2022-08-20 07:50:24.829524\n",
      "resetting env. episode 2366, reward total was -20.0. running mean: -19.89608711934741, timestamp: 2022-08-20 07:50:26.502542\n",
      "resetting env. episode 2367, reward total was -21.0. running mean: -19.907126248153936, timestamp: 2022-08-20 07:50:28.487561\n",
      "resetting env. episode 2368, reward total was -20.0. running mean: -19.908054985672397, timestamp: 2022-08-20 07:50:29.724578\n",
      "resetting env. episode 2369, reward total was -21.0. running mean: -19.918974435815674, timestamp: 2022-08-20 07:50:31.365596\n",
      "resetting env. episode 2370, reward total was -19.0. running mean: -19.909784691457517, timestamp: 2022-08-20 07:50:32.894617\n",
      "resetting env. episode 2371, reward total was -20.0. running mean: -19.91068684454294, timestamp: 2022-08-20 07:50:34.435633\n",
      "resetting env. episode 2372, reward total was -20.0. running mean: -19.91157997609751, timestamp: 2022-08-20 07:50:36.454660\n",
      "resetting env. episode 2373, reward total was -20.0. running mean: -19.912464176336535, timestamp: 2022-08-20 07:50:38.209679\n",
      "resetting env. episode 2374, reward total was -21.0. running mean: -19.92333953457317, timestamp: 2022-08-20 07:50:39.565696\n",
      "resetting env. episode 2375, reward total was -16.0. running mean: -19.884106139227438, timestamp: 2022-08-20 07:50:42.725736\n",
      "resetting env. episode 2376, reward total was -20.0. running mean: -19.88526507783516, timestamp: 2022-08-20 07:50:44.418759\n",
      "resetting env. episode 2377, reward total was -21.0. running mean: -19.89641242705681, timestamp: 2022-08-20 07:50:45.780773\n",
      "resetting env. episode 2378, reward total was -19.0. running mean: -19.887448302786243, timestamp: 2022-08-20 07:50:48.076801\n",
      "resetting env. episode 2379, reward total was -21.0. running mean: -19.898573819758383, timestamp: 2022-08-20 07:50:49.636817\n",
      "resetting env. episode 2380, reward total was -18.0. running mean: -19.879588081560797, timestamp: 2022-08-20 07:50:51.431838\n",
      "resetting env. episode 2381, reward total was -20.0. running mean: -19.880792200745187, timestamp: 2022-08-20 07:50:52.978859\n",
      "resetting env. episode 2382, reward total was -19.0. running mean: -19.871984278737738, timestamp: 2022-08-20 07:50:54.821886\n",
      "resetting env. episode 2383, reward total was -18.0. running mean: -19.85326443595036, timestamp: 2022-08-20 07:50:56.822905\n",
      "resetting env. episode 2384, reward total was -20.0. running mean: -19.854731791590858, timestamp: 2022-08-20 07:50:58.816928\n",
      "resetting env. episode 2385, reward total was -21.0. running mean: -19.86618447367495, timestamp: 2022-08-20 07:51:00.885954\n",
      "resetting env. episode 2386, reward total was -21.0. running mean: -19.8775226289382, timestamp: 2022-08-20 07:51:03.274987\n",
      "resetting env. episode 2387, reward total was -20.0. running mean: -19.878747402648816, timestamp: 2022-08-20 07:51:04.597999\n",
      "resetting env. episode 2388, reward total was -20.0. running mean: -19.879959928622327, timestamp: 2022-08-20 07:51:06.673028\n",
      "resetting env. episode 2389, reward total was -20.0. running mean: -19.881160329336105, timestamp: 2022-08-20 07:51:08.731053\n",
      "resetting env. episode 2390, reward total was -19.0. running mean: -19.872348726042745, timestamp: 2022-08-20 07:51:11.365082\n",
      "resetting env. episode 2391, reward total was -19.0. running mean: -19.86362523878232, timestamp: 2022-08-20 07:51:13.598107\n",
      "resetting env. episode 2392, reward total was -20.0. running mean: -19.864988986394494, timestamp: 2022-08-20 07:51:15.623133\n",
      "resetting env. episode 2393, reward total was -21.0. running mean: -19.87633909653055, timestamp: 2022-08-20 07:51:18.092165\n",
      "resetting env. episode 2394, reward total was -20.0. running mean: -19.877575705565246, timestamp: 2022-08-20 07:51:19.798184\n",
      "resetting env. episode 2395, reward total was -19.0. running mean: -19.868799948509594, timestamp: 2022-08-20 07:51:21.546204\n",
      "resetting env. episode 2396, reward total was -21.0. running mean: -19.8801119490245, timestamp: 2022-08-20 07:51:22.605218\n",
      "resetting env. episode 2397, reward total was -20.0. running mean: -19.881310829534254, timestamp: 2022-08-20 07:51:24.158234\n",
      "resetting env. episode 2398, reward total was -21.0. running mean: -19.89249772123891, timestamp: 2022-08-20 07:51:26.221259\n",
      "resetting env. episode 2399, reward total was -20.0. running mean: -19.89357274402652, timestamp: 2022-08-20 07:51:27.369273\n",
      "resetting env. episode 2400, reward total was -20.0. running mean: -19.894637016586255, timestamp: 2022-08-20 07:51:28.854294\n",
      "resetting env. episode 2401, reward total was -20.0. running mean: -19.89569064642039, timestamp: 2022-08-20 07:51:30.823318\n",
      "resetting env. episode 2402, reward total was -20.0. running mean: -19.896733739956186, timestamp: 2022-08-20 07:51:32.337333\n",
      "resetting env. episode 2403, reward total was -18.0. running mean: -19.877766402556624, timestamp: 2022-08-20 07:51:34.219359\n",
      "resetting env. episode 2404, reward total was -21.0. running mean: -19.888988738531058, timestamp: 2022-08-20 07:51:35.931380\n",
      "resetting env. episode 2405, reward total was -21.0. running mean: -19.90009885114575, timestamp: 2022-08-20 07:51:37.373398\n",
      "resetting env. episode 2406, reward total was -19.0. running mean: -19.891097862634293, timestamp: 2022-08-20 07:51:39.266423\n",
      "resetting env. episode 2407, reward total was -19.0. running mean: -19.88218688400795, timestamp: 2022-08-20 07:51:41.147441\n",
      "resetting env. episode 2408, reward total was -19.0. running mean: -19.87336501516787, timestamp: 2022-08-20 07:51:42.928465\n",
      "resetting env. episode 2409, reward total was -19.0. running mean: -19.864631365016194, timestamp: 2022-08-20 07:51:45.831499\n",
      "resetting env. episode 2410, reward total was -21.0. running mean: -19.875985051366033, timestamp: 2022-08-20 07:51:47.280517\n",
      "resetting env. episode 2411, reward total was -19.0. running mean: -19.867225200852374, timestamp: 2022-08-20 07:51:49.514541\n",
      "resetting env. episode 2412, reward total was -17.0. running mean: -19.83855294884385, timestamp: 2022-08-20 07:51:51.714571\n",
      "resetting env. episode 2413, reward total was -18.0. running mean: -19.820167419355414, timestamp: 2022-08-20 07:51:53.420589\n",
      "resetting env. episode 2414, reward total was -21.0. running mean: -19.83196574516186, timestamp: 2022-08-20 07:51:54.454601\n",
      "resetting env. episode 2415, reward total was -18.0. running mean: -19.81364608771024, timestamp: 2022-08-20 07:51:56.623629\n",
      "resetting env. episode 2416, reward total was -18.0. running mean: -19.795509626833137, timestamp: 2022-08-20 07:51:58.685654\n",
      "resetting env. episode 2417, reward total was -21.0. running mean: -19.807554530564808, timestamp: 2022-08-20 07:52:00.733678\n",
      "resetting env. episode 2418, reward total was -19.0. running mean: -19.79947898525916, timestamp: 2022-08-20 07:52:03.617714\n",
      "resetting env. episode 2419, reward total was -20.0. running mean: -19.80148419540657, timestamp: 2022-08-20 07:52:06.131742\n",
      "resetting env. episode 2420, reward total was -17.0. running mean: -19.773469353452505, timestamp: 2022-08-20 07:52:08.142769\n",
      "resetting env. episode 2421, reward total was -18.0. running mean: -19.75573465991798, timestamp: 2022-08-20 07:52:10.051790\n",
      "resetting env. episode 2422, reward total was -21.0. running mean: -19.7681773133188, timestamp: 2022-08-20 07:52:11.777812\n",
      "resetting env. episode 2423, reward total was -20.0. running mean: -19.770495540185614, timestamp: 2022-08-20 07:52:14.024844\n",
      "resetting env. episode 2424, reward total was -20.0. running mean: -19.772790584783756, timestamp: 2022-08-20 07:52:15.743866\n",
      "resetting env. episode 2425, reward total was -21.0. running mean: -19.78506267893592, timestamp: 2022-08-20 07:52:17.383879\n",
      "resetting env. episode 2426, reward total was -21.0. running mean: -19.79721205214656, timestamp: 2022-08-20 07:52:19.374905\n",
      "resetting env. episode 2427, reward total was -19.0. running mean: -19.789239931625094, timestamp: 2022-08-20 07:52:21.431928\n",
      "resetting env. episode 2428, reward total was -20.0. running mean: -19.79134753230884, timestamp: 2022-08-20 07:52:23.709957\n",
      "resetting env. episode 2429, reward total was -20.0. running mean: -19.793434056985753, timestamp: 2022-08-20 07:52:25.423981\n",
      "resetting env. episode 2430, reward total was -18.0. running mean: -19.775499716415894, timestamp: 2022-08-20 07:52:27.314999\n",
      "resetting env. episode 2431, reward total was -20.0. running mean: -19.777744719251732, timestamp: 2022-08-20 07:52:29.471030\n",
      "resetting env. episode 2432, reward total was -19.0. running mean: -19.769967272059215, timestamp: 2022-08-20 07:52:31.074047\n",
      "resetting env. episode 2433, reward total was -19.0. running mean: -19.762267599338625, timestamp: 2022-08-20 07:52:33.323074\n",
      "resetting env. episode 2434, reward total was -20.0. running mean: -19.764644923345237, timestamp: 2022-08-20 07:52:34.893092\n",
      "resetting env. episode 2435, reward total was -19.0. running mean: -19.756998474111786, timestamp: 2022-08-20 07:52:36.642110\n",
      "resetting env. episode 2436, reward total was -20.0. running mean: -19.759428489370666, timestamp: 2022-08-20 07:52:38.499137\n",
      "resetting env. episode 2437, reward total was -20.0. running mean: -19.76183420447696, timestamp: 2022-08-20 07:52:39.974151\n",
      "resetting env. episode 2438, reward total was -18.0. running mean: -19.74421586243219, timestamp: 2022-08-20 07:52:42.173184\n",
      "resetting env. episode 2439, reward total was -18.0. running mean: -19.726773703807865, timestamp: 2022-08-20 07:52:44.374207\n",
      "resetting env. episode 2440, reward total was -20.0. running mean: -19.729505966769786, timestamp: 2022-08-20 07:52:46.295231\n",
      "resetting env. episode 2441, reward total was -18.0. running mean: -19.712210907102087, timestamp: 2022-08-20 07:52:48.474255\n",
      "resetting env. episode 2442, reward total was -21.0. running mean: -19.725088798031067, timestamp: 2022-08-20 07:52:50.929286\n",
      "resetting env. episode 2443, reward total was -21.0. running mean: -19.737837910050757, timestamp: 2022-08-20 07:52:52.262300\n",
      "resetting env. episode 2444, reward total was -21.0. running mean: -19.750459530950252, timestamp: 2022-08-20 07:52:54.252325\n",
      "resetting env. episode 2445, reward total was -19.0. running mean: -19.74295493564075, timestamp: 2022-08-20 07:52:55.751344\n",
      "resetting env. episode 2446, reward total was -21.0. running mean: -19.755525386284344, timestamp: 2022-08-20 07:52:57.707369\n",
      "resetting env. episode 2447, reward total was -21.0. running mean: -19.7679701324215, timestamp: 2022-08-20 07:52:59.419384\n",
      "resetting env. episode 2448, reward total was -18.0. running mean: -19.750290431097284, timestamp: 2022-08-20 07:53:01.921414\n",
      "resetting env. episode 2449, reward total was -20.0. running mean: -19.75278752678631, timestamp: 2022-08-20 07:53:03.921438\n",
      "resetting env. episode 2450, reward total was -18.0. running mean: -19.735259651518447, timestamp: 2022-08-20 07:53:05.548461\n",
      "resetting env. episode 2451, reward total was -20.0. running mean: -19.737907055003262, timestamp: 2022-08-20 07:53:07.417481\n",
      "resetting env. episode 2452, reward total was -21.0. running mean: -19.75052798445323, timestamp: 2022-08-20 07:53:08.897504\n",
      "resetting env. episode 2453, reward total was -20.0. running mean: -19.7530227046087, timestamp: 2022-08-20 07:53:10.926527\n",
      "resetting env. episode 2454, reward total was -18.0. running mean: -19.735492477562612, timestamp: 2022-08-20 07:53:13.005553\n",
      "resetting env. episode 2455, reward total was -19.0. running mean: -19.728137552786986, timestamp: 2022-08-20 07:53:14.818574\n",
      "resetting env. episode 2456, reward total was -21.0. running mean: -19.74085617725912, timestamp: 2022-08-20 07:53:16.092589\n",
      "resetting env. episode 2457, reward total was -19.0. running mean: -19.73344761548653, timestamp: 2022-08-20 07:53:17.932613\n",
      "resetting env. episode 2458, reward total was -19.0. running mean: -19.726113139331666, timestamp: 2022-08-20 07:53:19.773631\n",
      "resetting env. episode 2459, reward total was -19.0. running mean: -19.71885200793835, timestamp: 2022-08-20 07:53:22.186669\n",
      "resetting env. episode 2460, reward total was -18.0. running mean: -19.701663487858966, timestamp: 2022-08-20 07:53:24.688691\n",
      "resetting env. episode 2461, reward total was -20.0. running mean: -19.704646852980375, timestamp: 2022-08-20 07:53:26.697716\n",
      "resetting env. episode 2462, reward total was -17.0. running mean: -19.67760038445057, timestamp: 2022-08-20 07:53:29.375746\n",
      "resetting env. episode 2463, reward total was -20.0. running mean: -19.680824380606065, timestamp: 2022-08-20 07:53:31.206768\n",
      "resetting env. episode 2464, reward total was -21.0. running mean: -19.694016136800006, timestamp: 2022-08-20 07:53:32.704790\n",
      "resetting env. episode 2465, reward total was -20.0. running mean: -19.697075975432004, timestamp: 2022-08-20 07:53:35.104813\n",
      "resetting env. episode 2466, reward total was -20.0. running mean: -19.700105215677684, timestamp: 2022-08-20 07:53:36.641831\n",
      "resetting env. episode 2467, reward total was -19.0. running mean: -19.693104163520907, timestamp: 2022-08-20 07:53:38.075858\n",
      "resetting env. episode 2468, reward total was -18.0. running mean: -19.676173121885697, timestamp: 2022-08-20 07:53:40.338880\n",
      "resetting env. episode 2469, reward total was -21.0. running mean: -19.68941139066684, timestamp: 2022-08-20 07:53:41.571889\n",
      "resetting env. episode 2470, reward total was -20.0. running mean: -19.69251727676017, timestamp: 2022-08-20 07:53:42.684905\n",
      "resetting env. episode 2471, reward total was -20.0. running mean: -19.695592103992567, timestamp: 2022-08-20 07:53:44.211922\n",
      "resetting env. episode 2472, reward total was -19.0. running mean: -19.688636182952642, timestamp: 2022-08-20 07:53:46.616953\n",
      "resetting env. episode 2473, reward total was -20.0. running mean: -19.691749821123114, timestamp: 2022-08-20 07:53:48.376972\n",
      "resetting env. episode 2474, reward total was -20.0. running mean: -19.694832322911882, timestamp: 2022-08-20 07:53:49.863990\n",
      "resetting env. episode 2475, reward total was -20.0. running mean: -19.697883999682762, timestamp: 2022-08-20 07:53:51.346010\n",
      "resetting env. episode 2476, reward total was -18.0. running mean: -19.680905159685935, timestamp: 2022-08-20 07:53:53.837041\n",
      "resetting env. episode 2477, reward total was -19.0. running mean: -19.674096108089078, timestamp: 2022-08-20 07:53:55.313059\n",
      "resetting env. episode 2478, reward total was -19.0. running mean: -19.667355147008188, timestamp: 2022-08-20 07:53:57.265079\n",
      "resetting env. episode 2479, reward total was -21.0. running mean: -19.680681595538108, timestamp: 2022-08-20 07:53:58.976102\n",
      "resetting env. episode 2480, reward total was -19.0. running mean: -19.67387477958273, timestamp: 2022-08-20 07:54:01.033643\n",
      "resetting env. episode 2481, reward total was -18.0. running mean: -19.6571360317869, timestamp: 2022-08-20 07:54:02.983668\n",
      "resetting env. episode 2482, reward total was -18.0. running mean: -19.640564671469033, timestamp: 2022-08-20 07:54:04.880692\n",
      "resetting env. episode 2483, reward total was -21.0. running mean: -19.654159024754343, timestamp: 2022-08-20 07:54:05.986707\n",
      "resetting env. episode 2484, reward total was -20.0. running mean: -19.657617434506797, timestamp: 2022-08-20 07:54:08.472737\n",
      "resetting env. episode 2485, reward total was -20.0. running mean: -19.661041260161728, timestamp: 2022-08-20 07:54:10.391760\n",
      "resetting env. episode 2486, reward total was -21.0. running mean: -19.67443084756011, timestamp: 2022-08-20 07:54:11.900778\n",
      "resetting env. episode 2487, reward total was -20.0. running mean: -19.677686539084508, timestamp: 2022-08-20 07:54:13.689795\n",
      "resetting env. episode 2488, reward total was -20.0. running mean: -19.680909673693662, timestamp: 2022-08-20 07:54:15.345818\n",
      "resetting env. episode 2489, reward total was -19.0. running mean: -19.674100576956725, timestamp: 2022-08-20 07:54:17.478845\n",
      "resetting env. episode 2490, reward total was -19.0. running mean: -19.66735957118716, timestamp: 2022-08-20 07:54:19.146863\n",
      "resetting env. episode 2491, reward total was -17.0. running mean: -19.64068597547529, timestamp: 2022-08-20 07:54:21.525892\n",
      "resetting env. episode 2492, reward total was -20.0. running mean: -19.644279115720536, timestamp: 2022-08-20 07:54:23.653918\n",
      "resetting env. episode 2493, reward total was -20.0. running mean: -19.64783632456333, timestamp: 2022-08-20 07:54:25.580940\n",
      "resetting env. episode 2494, reward total was -20.0. running mean: -19.651357961317697, timestamp: 2022-08-20 07:54:27.469964\n",
      "resetting env. episode 2495, reward total was -20.0. running mean: -19.654844381704518, timestamp: 2022-08-20 07:54:28.977981\n",
      "resetting env. episode 2496, reward total was -21.0. running mean: -19.66829593788747, timestamp: 2022-08-20 07:54:31.387012\n",
      "resetting env. episode 2497, reward total was -20.0. running mean: -19.671612978508595, timestamp: 2022-08-20 07:54:32.897028\n",
      "resetting env. episode 2498, reward total was -20.0. running mean: -19.67489684872351, timestamp: 2022-08-20 07:54:34.980052\n",
      "resetting env. episode 2499, reward total was -19.0. running mean: -19.668147880236276, timestamp: 2022-08-20 07:54:36.788080\n",
      "resetting env. episode 2500, reward total was -20.0. running mean: -19.671466401433914, timestamp: 2022-08-20 07:54:38.871100\n",
      "resetting env. episode 2501, reward total was -17.0. running mean: -19.644751737419575, timestamp: 2022-08-20 07:54:40.682123\n",
      "resetting env. episode 2502, reward total was -18.0. running mean: -19.62830422004538, timestamp: 2022-08-20 07:54:42.788147\n",
      "resetting env. episode 2503, reward total was -21.0. running mean: -19.642021177844928, timestamp: 2022-08-20 07:54:44.140165\n",
      "resetting env. episode 2504, reward total was -18.0. running mean: -19.62560096606648, timestamp: 2022-08-20 07:54:46.049191\n",
      "resetting env. episode 2505, reward total was -20.0. running mean: -19.629344956405813, timestamp: 2022-08-20 07:54:47.899208\n",
      "resetting env. episode 2506, reward total was -19.0. running mean: -19.623051506841755, timestamp: 2022-08-20 07:54:50.562243\n",
      "resetting env. episode 2507, reward total was -20.0. running mean: -19.626820991773336, timestamp: 2022-08-20 07:54:52.236261\n",
      "resetting env. episode 2508, reward total was -21.0. running mean: -19.640552781855604, timestamp: 2022-08-20 07:54:53.608279\n",
      "resetting env. episode 2509, reward total was -16.0. running mean: -19.60414725403705, timestamp: 2022-08-20 07:54:55.762307\n",
      "resetting env. episode 2510, reward total was -17.0. running mean: -19.578105781496678, timestamp: 2022-08-20 07:54:58.078333\n",
      "resetting env. episode 2511, reward total was -18.0. running mean: -19.562324723681712, timestamp: 2022-08-20 07:55:00.181358\n",
      "resetting env. episode 2512, reward total was -19.0. running mean: -19.556701476444896, timestamp: 2022-08-20 07:55:02.079386\n",
      "resetting env. episode 2513, reward total was -20.0. running mean: -19.561134461680446, timestamp: 2022-08-20 07:55:03.293399\n",
      "resetting env. episode 2514, reward total was -18.0. running mean: -19.54552311706364, timestamp: 2022-08-20 07:55:05.723426\n",
      "resetting env. episode 2515, reward total was -21.0. running mean: -19.560067885893005, timestamp: 2022-08-20 07:55:07.754461\n",
      "resetting env. episode 2516, reward total was -21.0. running mean: -19.574467207034075, timestamp: 2022-08-20 07:55:09.975478\n",
      "resetting env. episode 2517, reward total was -18.0. running mean: -19.558722534963735, timestamp: 2022-08-20 07:55:11.556496\n",
      "resetting env. episode 2518, reward total was -19.0. running mean: -19.5531353096141, timestamp: 2022-08-20 07:55:14.249528\n",
      "resetting env. episode 2519, reward total was -20.0. running mean: -19.55760395651796, timestamp: 2022-08-20 07:55:16.117551\n",
      "resetting env. episode 2520, reward total was -20.0. running mean: -19.56202791695278, timestamp: 2022-08-20 07:55:18.213578\n",
      "resetting env. episode 2521, reward total was -19.0. running mean: -19.556407637783252, timestamp: 2022-08-20 07:55:20.085604\n",
      "resetting env. episode 2522, reward total was -17.0. running mean: -19.530843561405423, timestamp: 2022-08-20 07:55:22.232625\n",
      "resetting env. episode 2523, reward total was -21.0. running mean: -19.545535125791368, timestamp: 2022-08-20 07:55:23.522640\n",
      "resetting env. episode 2524, reward total was -18.0. running mean: -19.530079774533455, timestamp: 2022-08-20 07:55:25.450668\n",
      "resetting env. episode 2525, reward total was -20.0. running mean: -19.534778976788118, timestamp: 2022-08-20 07:55:27.243686\n",
      "resetting env. episode 2526, reward total was -20.0. running mean: -19.539431187020234, timestamp: 2022-08-20 07:55:28.511700\n",
      "resetting env. episode 2527, reward total was -21.0. running mean: -19.554036875150032, timestamp: 2022-08-20 07:55:30.241720\n",
      "resetting env. episode 2528, reward total was -20.0. running mean: -19.55849650639853, timestamp: 2022-08-20 07:55:31.981745\n",
      "resetting env. episode 2529, reward total was -16.0. running mean: -19.522911541334544, timestamp: 2022-08-20 07:55:34.499775\n",
      "resetting env. episode 2530, reward total was -19.0. running mean: -19.5176824259212, timestamp: 2022-08-20 07:55:36.860801\n",
      "resetting env. episode 2531, reward total was -20.0. running mean: -19.522505601661987, timestamp: 2022-08-20 07:55:38.510822\n",
      "resetting env. episode 2532, reward total was -20.0. running mean: -19.527280545645365, timestamp: 2022-08-20 07:55:40.197841\n",
      "resetting env. episode 2533, reward total was -21.0. running mean: -19.54200774018891, timestamp: 2022-08-20 07:55:42.243869\n",
      "resetting env. episode 2534, reward total was -19.0. running mean: -19.536587662787024, timestamp: 2022-08-20 07:55:44.107900\n",
      "resetting env. episode 2535, reward total was -21.0. running mean: -19.551221786159154, timestamp: 2022-08-20 07:55:45.606908\n",
      "resetting env. episode 2536, reward total was -19.0. running mean: -19.545709568297564, timestamp: 2022-08-20 07:55:47.843982\n",
      "resetting env. episode 2537, reward total was -18.0. running mean: -19.53025247261459, timestamp: 2022-08-20 07:55:49.914009\n",
      "resetting env. episode 2538, reward total was -20.0. running mean: -19.534949947888443, timestamp: 2022-08-20 07:55:51.445025\n",
      "resetting env. episode 2539, reward total was -19.0. running mean: -19.52960044840956, timestamp: 2022-08-20 07:55:53.343050\n",
      "resetting env. episode 2540, reward total was -21.0. running mean: -19.544304443925466, timestamp: 2022-08-20 07:55:55.058069\n",
      "resetting env. episode 2541, reward total was -21.0. running mean: -19.55886139948621, timestamp: 2022-08-20 07:55:56.475086\n",
      "resetting env. episode 2542, reward total was -18.0. running mean: -19.54327278549135, timestamp: 2022-08-20 07:55:58.487112\n",
      "resetting env. episode 2543, reward total was -20.0. running mean: -19.547840057636435, timestamp: 2022-08-20 07:55:59.915130\n",
      "resetting env. episode 2544, reward total was -19.0. running mean: -19.542361657060074, timestamp: 2022-08-20 07:56:01.572148\n",
      "resetting env. episode 2545, reward total was -21.0. running mean: -19.556938040489474, timestamp: 2022-08-20 07:56:03.406173\n",
      "resetting env. episode 2546, reward total was -20.0. running mean: -19.56136866008458, timestamp: 2022-08-20 07:56:05.809205\n",
      "resetting env. episode 2547, reward total was -21.0. running mean: -19.575754973483733, timestamp: 2022-08-20 07:56:07.162221\n",
      "resetting env. episode 2548, reward total was -20.0. running mean: -19.579997423748896, timestamp: 2022-08-20 07:56:09.595249\n",
      "resetting env. episode 2549, reward total was -20.0. running mean: -19.584197449511407, timestamp: 2022-08-20 07:56:11.648271\n",
      "resetting env. episode 2550, reward total was -18.0. running mean: -19.568355475016293, timestamp: 2022-08-20 07:56:13.512293\n",
      "resetting env. episode 2551, reward total was -19.0. running mean: -19.56267192026613, timestamp: 2022-08-20 07:56:15.860320\n",
      "resetting env. episode 2552, reward total was -20.0. running mean: -19.56704520106347, timestamp: 2022-08-20 07:56:18.221347\n",
      "resetting env. episode 2553, reward total was -18.0. running mean: -19.551374749052833, timestamp: 2022-08-20 07:56:20.251376\n",
      "resetting env. episode 2554, reward total was -20.0. running mean: -19.555861001562302, timestamp: 2022-08-20 07:56:22.732402\n",
      "resetting env. episode 2555, reward total was -19.0. running mean: -19.55030239154668, timestamp: 2022-08-20 07:56:24.536425\n",
      "resetting env. episode 2556, reward total was -19.0. running mean: -19.544799367631214, timestamp: 2022-08-20 07:56:26.295445\n",
      "resetting env. episode 2557, reward total was -18.0. running mean: -19.529351373954903, timestamp: 2022-08-20 07:56:28.827480\n",
      "resetting env. episode 2558, reward total was -18.0. running mean: -19.514057860215352, timestamp: 2022-08-20 07:56:30.447494\n",
      "resetting env. episode 2559, reward total was -14.0. running mean: -19.4589172816132, timestamp: 2022-08-20 07:56:33.793535\n",
      "resetting env. episode 2560, reward total was -20.0. running mean: -19.464328108797066, timestamp: 2022-08-20 07:56:35.361555\n",
      "resetting env. episode 2561, reward total was -21.0. running mean: -19.479684827709097, timestamp: 2022-08-20 07:56:37.119574\n",
      "resetting env. episode 2562, reward total was -20.0. running mean: -19.484887979432006, timestamp: 2022-08-20 07:56:39.775606\n",
      "resetting env. episode 2563, reward total was -20.0. running mean: -19.490039099637684, timestamp: 2022-08-20 07:56:41.807632\n",
      "resetting env. episode 2564, reward total was -21.0. running mean: -19.505138708641308, timestamp: 2022-08-20 07:56:43.297649\n",
      "resetting env. episode 2565, reward total was -20.0. running mean: -19.510087321554895, timestamp: 2022-08-20 07:56:45.511678\n",
      "resetting env. episode 2566, reward total was -18.0. running mean: -19.494986448339347, timestamp: 2022-08-20 07:56:47.242699\n",
      "resetting env. episode 2567, reward total was -18.0. running mean: -19.480036583855952, timestamp: 2022-08-20 07:56:49.346721\n",
      "resetting env. episode 2568, reward total was -16.0. running mean: -19.445236218017392, timestamp: 2022-08-20 07:56:51.429752\n",
      "resetting env. episode 2569, reward total was -19.0. running mean: -19.440783855837218, timestamp: 2022-08-20 07:56:53.154767\n",
      "resetting env. episode 2570, reward total was -17.0. running mean: -19.416376017278846, timestamp: 2022-08-20 07:56:54.926790\n",
      "resetting env. episode 2571, reward total was -20.0. running mean: -19.422212257106057, timestamp: 2022-08-20 07:56:56.888810\n",
      "resetting env. episode 2572, reward total was -21.0. running mean: -19.437990134535, timestamp: 2022-08-20 07:56:58.660833\n",
      "resetting env. episode 2573, reward total was -19.0. running mean: -19.43361023318965, timestamp: 2022-08-20 07:57:00.768862\n",
      "resetting env. episode 2574, reward total was -19.0. running mean: -19.429274130857756, timestamp: 2022-08-20 07:57:02.742884\n",
      "resetting env. episode 2575, reward total was -21.0. running mean: -19.44498138954918, timestamp: 2022-08-20 07:57:04.023896\n",
      "resetting env. episode 2576, reward total was -15.0. running mean: -19.400531575653687, timestamp: 2022-08-20 07:57:06.790931\n",
      "resetting env. episode 2577, reward total was -18.0. running mean: -19.38652625989715, timestamp: 2022-08-20 07:57:09.298963\n",
      "resetting env. episode 2578, reward total was -15.0. running mean: -19.342660997298175, timestamp: 2022-08-20 07:57:12.318996\n",
      "resetting env. episode 2579, reward total was -20.0. running mean: -19.349234387325193, timestamp: 2022-08-20 07:57:14.163019\n",
      "resetting env. episode 2580, reward total was -18.0. running mean: -19.33574204345194, timestamp: 2022-08-20 07:57:16.081044\n",
      "resetting env. episode 2581, reward total was -21.0. running mean: -19.35238462301742, timestamp: 2022-08-20 07:57:17.566062\n",
      "resetting env. episode 2582, reward total was -18.0. running mean: -19.338860776787246, timestamp: 2022-08-20 07:57:19.915088\n",
      "resetting env. episode 2583, reward total was -20.0. running mean: -19.345472169019374, timestamp: 2022-08-20 07:57:21.633112\n",
      "resetting env. episode 2584, reward total was -15.0. running mean: -19.302017447329177, timestamp: 2022-08-20 07:57:24.522148\n",
      "resetting env. episode 2585, reward total was -21.0. running mean: -19.318997272855885, timestamp: 2022-08-20 07:57:26.879174\n",
      "resetting env. episode 2586, reward total was -21.0. running mean: -19.33580730012733, timestamp: 2022-08-20 07:57:28.243190\n",
      "resetting env. episode 2587, reward total was -19.0. running mean: -19.332449227126055, timestamp: 2022-08-20 07:57:29.947215\n",
      "resetting env. episode 2588, reward total was -21.0. running mean: -19.349124734854794, timestamp: 2022-08-20 07:57:32.204240\n",
      "resetting env. episode 2589, reward total was -20.0. running mean: -19.355633487506246, timestamp: 2022-08-20 07:57:33.888256\n",
      "resetting env. episode 2590, reward total was -19.0. running mean: -19.352077152631185, timestamp: 2022-08-20 07:57:35.483277\n",
      "resetting env. episode 2591, reward total was -21.0. running mean: -19.368556381104874, timestamp: 2022-08-20 07:57:36.910291\n",
      "resetting env. episode 2592, reward total was -21.0. running mean: -19.384870817293827, timestamp: 2022-08-20 07:57:39.261319\n",
      "resetting env. episode 2593, reward total was -19.0. running mean: -19.381022109120888, timestamp: 2022-08-20 07:57:41.180344\n",
      "resetting env. episode 2594, reward total was -14.0. running mean: -19.32721188802968, timestamp: 2022-08-20 07:57:44.599384\n",
      "resetting env. episode 2595, reward total was -19.0. running mean: -19.323939769149383, timestamp: 2022-08-20 07:57:46.725411\n",
      "resetting env. episode 2596, reward total was -16.0. running mean: -19.29070037145789, timestamp: 2022-08-20 07:57:49.322446\n",
      "resetting env. episode 2597, reward total was -20.0. running mean: -19.29779336774331, timestamp: 2022-08-20 07:57:50.551457\n",
      "resetting env. episode 2598, reward total was -21.0. running mean: -19.314815434065878, timestamp: 2022-08-20 07:57:51.988474\n",
      "resetting env. episode 2599, reward total was -18.0. running mean: -19.30166727972522, timestamp: 2022-08-20 07:57:54.111496\n",
      "resetting env. episode 2600, reward total was -20.0. running mean: -19.308650606927966, timestamp: 2022-08-20 07:57:56.254527\n",
      "resetting env. episode 2601, reward total was -19.0. running mean: -19.30556410085869, timestamp: 2022-08-20 07:57:57.932550\n",
      "resetting env. episode 2602, reward total was -17.0. running mean: -19.282508459850103, timestamp: 2022-08-20 07:57:59.887569\n",
      "resetting env. episode 2603, reward total was -19.0. running mean: -19.279683375251604, timestamp: 2022-08-20 07:58:02.619604\n",
      "resetting env. episode 2604, reward total was -15.0. running mean: -19.236886541499086, timestamp: 2022-08-20 07:58:05.471634\n",
      "resetting env. episode 2605, reward total was -18.0. running mean: -19.224517676084094, timestamp: 2022-08-20 07:58:07.658663\n",
      "resetting env. episode 2606, reward total was -19.0. running mean: -19.222272499323253, timestamp: 2022-08-20 07:58:09.866687\n",
      "resetting env. episode 2607, reward total was -18.0. running mean: -19.21004977433002, timestamp: 2022-08-20 07:58:12.342723\n",
      "resetting env. episode 2608, reward total was -20.0. running mean: -19.21794927658672, timestamp: 2022-08-20 07:58:14.099738\n",
      "resetting env. episode 2609, reward total was -20.0. running mean: -19.22576978382085, timestamp: 2022-08-20 07:58:15.733761\n",
      "resetting env. episode 2610, reward total was -19.0. running mean: -19.223512085982644, timestamp: 2022-08-20 07:58:17.333780\n",
      "resetting env. episode 2611, reward total was -19.0. running mean: -19.22127696512282, timestamp: 2022-08-20 07:58:19.588805\n",
      "resetting env. episode 2612, reward total was -20.0. running mean: -19.22906419547159, timestamp: 2022-08-20 07:58:21.988836\n",
      "resetting env. episode 2613, reward total was -20.0. running mean: -19.236773553516873, timestamp: 2022-08-20 07:58:23.873861\n",
      "resetting env. episode 2614, reward total was -20.0. running mean: -19.244405817981704, timestamp: 2022-08-20 07:58:25.261873\n",
      "resetting env. episode 2615, reward total was -21.0. running mean: -19.26196175980189, timestamp: 2022-08-20 07:58:26.641900\n",
      "resetting env. episode 2616, reward total was -19.0. running mean: -19.25934214220387, timestamp: 2022-08-20 07:58:29.081920\n",
      "resetting env. episode 2617, reward total was -17.0. running mean: -19.236748720781833, timestamp: 2022-08-20 07:58:31.479950\n",
      "resetting env. episode 2618, reward total was -20.0. running mean: -19.244381233574014, timestamp: 2022-08-20 07:58:32.694965\n",
      "resetting env. episode 2619, reward total was -20.0. running mean: -19.251937421238274, timestamp: 2022-08-20 07:58:35.211993\n",
      "resetting env. episode 2620, reward total was -20.0. running mean: -19.25941804702589, timestamp: 2022-08-20 07:58:37.168019\n",
      "resetting env. episode 2621, reward total was -18.0. running mean: -19.24682386655563, timestamp: 2022-08-20 07:58:39.456046\n",
      "resetting env. episode 2622, reward total was -21.0. running mean: -19.264355627890076, timestamp: 2022-08-20 07:58:40.863062\n",
      "resetting env. episode 2623, reward total was -17.0. running mean: -19.241712071611175, timestamp: 2022-08-20 07:58:43.137088\n",
      "resetting env. episode 2624, reward total was -16.0. running mean: -19.209294950895064, timestamp: 2022-08-20 07:58:45.800123\n",
      "resetting env. episode 2625, reward total was -20.0. running mean: -19.217202001386113, timestamp: 2022-08-20 07:58:47.154136\n",
      "resetting env. episode 2626, reward total was -21.0. running mean: -19.235029981372254, timestamp: 2022-08-20 07:58:49.271163\n",
      "resetting env. episode 2627, reward total was -19.0. running mean: -19.232679681558533, timestamp: 2022-08-20 07:58:50.663178\n",
      "resetting env. episode 2628, reward total was -21.0. running mean: -19.25035288474295, timestamp: 2022-08-20 07:58:53.450216\n",
      "resetting env. episode 2629, reward total was -19.0. running mean: -19.24784935589552, timestamp: 2022-08-20 07:58:55.649240\n",
      "resetting env. episode 2630, reward total was -19.0. running mean: -19.245370862336568, timestamp: 2022-08-20 07:58:57.726265\n",
      "resetting env. episode 2631, reward total was -17.0. running mean: -19.222917153713205, timestamp: 2022-08-20 07:59:00.278294\n",
      "resetting env. episode 2632, reward total was -16.0. running mean: -19.190687982176073, timestamp: 2022-08-20 07:59:02.835325\n",
      "resetting env. episode 2633, reward total was -21.0. running mean: -19.208781102354312, timestamp: 2022-08-20 07:59:05.579357\n",
      "resetting env. episode 2634, reward total was -21.0. running mean: -19.22669329133077, timestamp: 2022-08-20 07:59:07.826389\n",
      "resetting env. episode 2635, reward total was -18.0. running mean: -19.21442635841746, timestamp: 2022-08-20 07:59:10.024414\n",
      "resetting env. episode 2636, reward total was -21.0. running mean: -19.232282094833284, timestamp: 2022-08-20 07:59:12.452443\n",
      "resetting env. episode 2637, reward total was -18.0. running mean: -19.21995927388495, timestamp: 2022-08-20 07:59:14.164463\n",
      "resetting env. episode 2638, reward total was -20.0. running mean: -19.2277596811461, timestamp: 2022-08-20 07:59:16.359488\n",
      "resetting env. episode 2639, reward total was -21.0. running mean: -19.24548208433464, timestamp: 2022-08-20 07:59:18.167513\n",
      "resetting env. episode 2640, reward total was -16.0. running mean: -19.213027263491295, timestamp: 2022-08-20 07:59:20.769543\n",
      "resetting env. episode 2641, reward total was -20.0. running mean: -19.22089699085638, timestamp: 2022-08-20 07:59:22.918568\n",
      "resetting env. episode 2642, reward total was -21.0. running mean: -19.23868802094782, timestamp: 2022-08-20 07:59:25.336598\n",
      "resetting env. episode 2643, reward total was -17.0. running mean: -19.21630114073834, timestamp: 2022-08-20 07:59:28.055633\n",
      "resetting env. episode 2644, reward total was -21.0. running mean: -19.234138129330958, timestamp: 2022-08-20 07:59:29.343645\n",
      "resetting env. episode 2645, reward total was -20.0. running mean: -19.241796748037647, timestamp: 2022-08-20 07:59:30.732658\n",
      "resetting env. episode 2646, reward total was -21.0. running mean: -19.25937878055727, timestamp: 2022-08-20 07:59:32.526684\n",
      "resetting env. episode 2647, reward total was -20.0. running mean: -19.266784992751695, timestamp: 2022-08-20 07:59:34.245707\n",
      "resetting env. episode 2648, reward total was -21.0. running mean: -19.28411714282418, timestamp: 2022-08-20 07:59:35.712722\n",
      "resetting env. episode 2649, reward total was -19.0. running mean: -19.28127597139594, timestamp: 2022-08-20 07:59:37.850744\n",
      "resetting env. episode 2650, reward total was -20.0. running mean: -19.28846321168198, timestamp: 2022-08-20 07:59:39.423768\n",
      "resetting env. episode 2651, reward total was -18.0. running mean: -19.27557857956516, timestamp: 2022-08-20 07:59:41.391791\n",
      "resetting env. episode 2652, reward total was -16.0. running mean: -19.24282279376951, timestamp: 2022-08-20 07:59:43.543814\n",
      "resetting env. episode 2653, reward total was -20.0. running mean: -19.25039456583181, timestamp: 2022-08-20 07:59:45.246833\n",
      "resetting env. episode 2654, reward total was -18.0. running mean: -19.23789062017349, timestamp: 2022-08-20 07:59:47.413861\n",
      "resetting env. episode 2655, reward total was -21.0. running mean: -19.255511713971757, timestamp: 2022-08-20 07:59:50.635898\n",
      "resetting env. episode 2656, reward total was -19.0. running mean: -19.25295659683204, timestamp: 2022-08-20 07:59:52.343919\n",
      "resetting env. episode 2657, reward total was -20.0. running mean: -19.260427030863717, timestamp: 2022-08-20 07:59:54.099939\n",
      "resetting env. episode 2658, reward total was -18.0. running mean: -19.247822760555078, timestamp: 2022-08-20 07:59:55.867961\n",
      "resetting env. episode 2659, reward total was -21.0. running mean: -19.265344532949527, timestamp: 2022-08-20 07:59:58.398992\n",
      "resetting env. episode 2660, reward total was -19.0. running mean: -19.262691087620034, timestamp: 2022-08-20 08:00:00.661021\n",
      "resetting env. episode 2661, reward total was -19.0. running mean: -19.260064176743835, timestamp: 2022-08-20 08:00:02.840050\n",
      "resetting env. episode 2662, reward total was -20.0. running mean: -19.267463534976397, timestamp: 2022-08-20 08:00:04.986073\n",
      "resetting env. episode 2663, reward total was -21.0. running mean: -19.284788899626633, timestamp: 2022-08-20 08:00:06.576091\n",
      "resetting env. episode 2664, reward total was -17.0. running mean: -19.26194101063037, timestamp: 2022-08-20 08:00:09.140125\n",
      "resetting env. episode 2665, reward total was -21.0. running mean: -19.279321600524067, timestamp: 2022-08-20 08:00:10.829139\n",
      "resetting env. episode 2666, reward total was -19.0. running mean: -19.276528384518826, timestamp: 2022-08-20 08:00:13.300170\n",
      "resetting env. episode 2667, reward total was -20.0. running mean: -19.28376310067364, timestamp: 2022-08-20 08:00:15.205192\n",
      "resetting env. episode 2668, reward total was -20.0. running mean: -19.290925469666902, timestamp: 2022-08-20 08:00:17.495225\n",
      "resetting env. episode 2669, reward total was -21.0. running mean: -19.308016214970234, timestamp: 2022-08-20 08:00:18.703235\n",
      "resetting env. episode 2670, reward total was -16.0. running mean: -19.274936052820532, timestamp: 2022-08-20 08:00:21.035263\n",
      "resetting env. episode 2671, reward total was -18.0. running mean: -19.262186692292328, timestamp: 2022-08-20 08:00:23.729298\n",
      "resetting env. episode 2672, reward total was -20.0. running mean: -19.269564825369404, timestamp: 2022-08-20 08:00:26.394329\n",
      "resetting env. episode 2673, reward total was -19.0. running mean: -19.266869177115712, timestamp: 2022-08-20 08:00:28.829357\n",
      "resetting env. episode 2674, reward total was -21.0. running mean: -19.284200485344556, timestamp: 2022-08-20 08:00:30.727379\n",
      "resetting env. episode 2675, reward total was -21.0. running mean: -19.30135848049111, timestamp: 2022-08-20 08:00:33.567414\n",
      "resetting env. episode 2676, reward total was -20.0. running mean: -19.308344895686197, timestamp: 2022-08-20 08:00:35.795441\n",
      "resetting env. episode 2677, reward total was -21.0. running mean: -19.325261446729336, timestamp: 2022-08-20 08:00:37.346460\n",
      "resetting env. episode 2678, reward total was -19.0. running mean: -19.322008832262043, timestamp: 2022-08-20 08:00:39.333482\n",
      "resetting env. episode 2679, reward total was -21.0. running mean: -19.33878874393942, timestamp: 2022-08-20 08:00:41.245504\n",
      "resetting env. episode 2680, reward total was -20.0. running mean: -19.345400856500028, timestamp: 2022-08-20 08:00:43.358529\n",
      "resetting env. episode 2681, reward total was -21.0. running mean: -19.361946847935027, timestamp: 2022-08-20 08:00:45.756561\n",
      "resetting env. episode 2682, reward total was -20.0. running mean: -19.368327379455675, timestamp: 2022-08-20 08:00:47.404585\n",
      "resetting env. episode 2683, reward total was -19.0. running mean: -19.364644105661117, timestamp: 2022-08-20 08:00:49.167600\n",
      "resetting env. episode 2684, reward total was -19.0. running mean: -19.360997664604508, timestamp: 2022-08-20 08:00:51.277627\n",
      "resetting env. episode 2685, reward total was -20.0. running mean: -19.367387687958463, timestamp: 2022-08-20 08:00:52.779646\n",
      "resetting env. episode 2686, reward total was -21.0. running mean: -19.383713811078877, timestamp: 2022-08-20 08:00:54.969672\n",
      "resetting env. episode 2687, reward total was -17.0. running mean: -19.35987667296809, timestamp: 2022-08-20 08:00:57.023696\n",
      "resetting env. episode 2688, reward total was -20.0. running mean: -19.366277906238405, timestamp: 2022-08-20 08:00:58.653717\n",
      "resetting env. episode 2689, reward total was -21.0. running mean: -19.38261512717602, timestamp: 2022-08-20 08:00:59.717728\n",
      "resetting env. episode 2690, reward total was -19.0. running mean: -19.37878897590426, timestamp: 2022-08-20 08:01:02.014279\n",
      "resetting env. episode 2691, reward total was -20.0. running mean: -19.385001086145216, timestamp: 2022-08-20 08:01:04.362310\n",
      "resetting env. episode 2692, reward total was -20.0. running mean: -19.391151075283762, timestamp: 2022-08-20 08:01:06.325329\n",
      "resetting env. episode 2693, reward total was -19.0. running mean: -19.387239564530926, timestamp: 2022-08-20 08:01:09.200370\n",
      "resetting env. episode 2694, reward total was -20.0. running mean: -19.393367168885614, timestamp: 2022-08-20 08:01:11.504396\n",
      "resetting env. episode 2695, reward total was -19.0. running mean: -19.38943349719676, timestamp: 2022-08-20 08:01:13.418412\n",
      "resetting env. episode 2696, reward total was -20.0. running mean: -19.39553916222479, timestamp: 2022-08-20 08:01:14.740430\n",
      "resetting env. episode 2697, reward total was -19.0. running mean: -19.391583770602544, timestamp: 2022-08-20 08:01:16.807459\n",
      "resetting env. episode 2698, reward total was -20.0. running mean: -19.397667932896518, timestamp: 2022-08-20 08:01:19.296483\n",
      "resetting env. episode 2699, reward total was -20.0. running mean: -19.40369125356755, timestamp: 2022-08-20 08:01:21.241511\n",
      "resetting env. episode 2700, reward total was -17.0. running mean: -19.379654341031877, timestamp: 2022-08-20 08:01:23.424533\n",
      "resetting env. episode 2701, reward total was -20.0. running mean: -19.385857797621558, timestamp: 2022-08-20 08:01:25.482559\n",
      "resetting env. episode 2702, reward total was -19.0. running mean: -19.381999219645344, timestamp: 2022-08-20 08:01:27.851588\n",
      "resetting env. episode 2703, reward total was -12.0. running mean: -19.308179227448893, timestamp: 2022-08-20 08:01:31.355626\n",
      "resetting env. episode 2704, reward total was -18.0. running mean: -19.2950974351744, timestamp: 2022-08-20 08:01:34.000663\n",
      "resetting env. episode 2705, reward total was -20.0. running mean: -19.302146460822655, timestamp: 2022-08-20 08:01:35.246679\n",
      "resetting env. episode 2706, reward total was -19.0. running mean: -19.29912499621443, timestamp: 2022-08-20 08:01:37.054695\n",
      "resetting env. episode 2707, reward total was -16.0. running mean: -19.266133746252287, timestamp: 2022-08-20 08:01:39.764725\n",
      "resetting env. episode 2708, reward total was -17.0. running mean: -19.243472408789764, timestamp: 2022-08-20 08:01:41.773281\n",
      "resetting env. episode 2709, reward total was -21.0. running mean: -19.261037684701865, timestamp: 2022-08-20 08:01:43.204296\n",
      "resetting env. episode 2710, reward total was -20.0. running mean: -19.268427307854846, timestamp: 2022-08-20 08:01:44.797310\n",
      "resetting env. episode 2711, reward total was -19.0. running mean: -19.2657430347763, timestamp: 2022-08-20 08:01:46.944341\n",
      "resetting env. episode 2712, reward total was -20.0. running mean: -19.273085604428537, timestamp: 2022-08-20 08:01:48.249354\n",
      "resetting env. episode 2713, reward total was -19.0. running mean: -19.270354748384253, timestamp: 2022-08-20 08:01:50.337382\n",
      "resetting env. episode 2714, reward total was -18.0. running mean: -19.257651200900412, timestamp: 2022-08-20 08:01:52.482408\n",
      "resetting env. episode 2715, reward total was -16.0. running mean: -19.225074688891407, timestamp: 2022-08-20 08:01:54.991432\n",
      "resetting env. episode 2716, reward total was -21.0. running mean: -19.242823942002495, timestamp: 2022-08-20 08:01:56.393448\n",
      "resetting env. episode 2717, reward total was -17.0. running mean: -19.220395702582472, timestamp: 2022-08-20 08:01:58.796478\n",
      "resetting env. episode 2718, reward total was -20.0. running mean: -19.228191745556646, timestamp: 2022-08-20 08:02:00.144497\n",
      "resetting env. episode 2719, reward total was -19.0. running mean: -19.22590982810108, timestamp: 2022-08-20 08:02:01.948515\n",
      "resetting env. episode 2720, reward total was -21.0. running mean: -19.24365072982007, timestamp: 2022-08-20 08:02:04.243541\n",
      "resetting env. episode 2721, reward total was -18.0. running mean: -19.23121422252187, timestamp: 2022-08-20 08:02:07.150579\n",
      "resetting env. episode 2722, reward total was -20.0. running mean: -19.23890208029665, timestamp: 2022-08-20 08:02:08.780604\n",
      "resetting env. episode 2723, reward total was -19.0. running mean: -19.236513059493685, timestamp: 2022-08-20 08:02:10.649622\n",
      "resetting env. episode 2724, reward total was -18.0. running mean: -19.22414792889875, timestamp: 2022-08-20 08:02:12.826648\n",
      "resetting env. episode 2725, reward total was -19.0. running mean: -19.22190644960976, timestamp: 2022-08-20 08:02:15.070673\n",
      "resetting env. episode 2726, reward total was -20.0. running mean: -19.229687385113664, timestamp: 2022-08-20 08:02:17.326705\n",
      "resetting env. episode 2727, reward total was -19.0. running mean: -19.227390511262527, timestamp: 2022-08-20 08:02:20.260734\n",
      "resetting env. episode 2728, reward total was -17.0. running mean: -19.205116606149904, timestamp: 2022-08-20 08:02:22.584763\n",
      "resetting env. episode 2729, reward total was -19.0. running mean: -19.203065440088405, timestamp: 2022-08-20 08:02:24.119783\n",
      "resetting env. episode 2730, reward total was -18.0. running mean: -19.19103478568752, timestamp: 2022-08-20 08:02:25.786803\n",
      "resetting env. episode 2731, reward total was -19.0. running mean: -19.189124437830646, timestamp: 2022-08-20 08:02:27.964828\n",
      "resetting env. episode 2732, reward total was -19.0. running mean: -19.18723319345234, timestamp: 2022-08-20 08:02:29.604847\n",
      "resetting env. episode 2733, reward total was -20.0. running mean: -19.195360861517816, timestamp: 2022-08-20 08:02:31.611871\n",
      "resetting env. episode 2734, reward total was -19.0. running mean: -19.193407252902638, timestamp: 2022-08-20 08:02:33.812900\n",
      "resetting env. episode 2735, reward total was -21.0. running mean: -19.211473180373613, timestamp: 2022-08-20 08:02:34.945910\n",
      "resetting env. episode 2736, reward total was -20.0. running mean: -19.219358448569874, timestamp: 2022-08-20 08:02:36.729934\n",
      "resetting env. episode 2737, reward total was -19.0. running mean: -19.217164864084175, timestamp: 2022-08-20 08:02:38.616958\n",
      "resetting env. episode 2738, reward total was -16.0. running mean: -19.184993215443335, timestamp: 2022-08-20 08:02:40.656981\n",
      "resetting env. episode 2739, reward total was -20.0. running mean: -19.1931432832889, timestamp: 2022-08-20 08:02:42.752005\n",
      "resetting env. episode 2740, reward total was -18.0. running mean: -19.181211850456013, timestamp: 2022-08-20 08:02:44.739027\n",
      "resetting env. episode 2741, reward total was -17.0. running mean: -19.159399731951453, timestamp: 2022-08-20 08:02:47.149056\n",
      "resetting env. episode 2742, reward total was -19.0. running mean: -19.15780573463194, timestamp: 2022-08-20 08:02:49.182085\n",
      "resetting env. episode 2743, reward total was -20.0. running mean: -19.16622767728562, timestamp: 2022-08-20 08:02:51.099107\n",
      "resetting env. episode 2744, reward total was -15.0. running mean: -19.12456540051276, timestamp: 2022-08-20 08:02:53.626137\n",
      "resetting env. episode 2745, reward total was -19.0. running mean: -19.123319746507633, timestamp: 2022-08-20 08:02:55.424156\n",
      "resetting env. episode 2746, reward total was -16.0. running mean: -19.092086549042556, timestamp: 2022-08-20 08:02:57.989187\n",
      "resetting env. episode 2747, reward total was -19.0. running mean: -19.09116568355213, timestamp: 2022-08-20 08:03:00.273220\n",
      "resetting env. episode 2748, reward total was -18.0. running mean: -19.08025402671661, timestamp: 2022-08-20 08:03:02.396242\n",
      "resetting env. episode 2749, reward total was -20.0. running mean: -19.08945148644944, timestamp: 2022-08-20 08:03:03.656255\n",
      "resetting env. episode 2750, reward total was -18.0. running mean: -19.078556971584945, timestamp: 2022-08-20 08:03:05.569281\n",
      "resetting env. episode 2751, reward total was -17.0. running mean: -19.057771401869097, timestamp: 2022-08-20 08:03:07.704303\n",
      "resetting env. episode 2752, reward total was -20.0. running mean: -19.067193687850406, timestamp: 2022-08-20 08:03:09.812330\n",
      "resetting env. episode 2753, reward total was -20.0. running mean: -19.0765217509719, timestamp: 2022-08-20 08:03:11.792356\n",
      "resetting env. episode 2754, reward total was -20.0. running mean: -19.08575653346218, timestamp: 2022-08-20 08:03:13.262370\n",
      "resetting env. episode 2755, reward total was -20.0. running mean: -19.09489896812756, timestamp: 2022-08-20 08:03:14.805388\n",
      "resetting env. episode 2756, reward total was -19.0. running mean: -19.093949978446286, timestamp: 2022-08-20 08:03:17.057415\n",
      "resetting env. episode 2757, reward total was -12.0. running mean: -19.023010478661824, timestamp: 2022-08-20 08:03:19.500444\n",
      "resetting env. episode 2758, reward total was -19.0. running mean: -19.022780373875207, timestamp: 2022-08-20 08:03:21.881477\n",
      "resetting env. episode 2759, reward total was -20.0. running mean: -19.032552570136453, timestamp: 2022-08-20 08:03:23.399495\n",
      "resetting env. episode 2760, reward total was -21.0. running mean: -19.05222704443509, timestamp: 2022-08-20 08:03:25.394519\n",
      "resetting env. episode 2761, reward total was -20.0. running mean: -19.061704773990737, timestamp: 2022-08-20 08:03:27.229538\n",
      "resetting env. episode 2762, reward total was -20.0. running mean: -19.07108772625083, timestamp: 2022-08-20 08:03:28.867561\n",
      "resetting env. episode 2763, reward total was -19.0. running mean: -19.070376848988325, timestamp: 2022-08-20 08:03:30.996588\n",
      "resetting env. episode 2764, reward total was -17.0. running mean: -19.049673080498444, timestamp: 2022-08-20 08:03:33.482618\n",
      "resetting env. episode 2765, reward total was -19.0. running mean: -19.04917634969346, timestamp: 2022-08-20 08:03:35.778643\n",
      "resetting env. episode 2766, reward total was -19.0. running mean: -19.048684586196526, timestamp: 2022-08-20 08:03:38.056671\n",
      "resetting env. episode 2767, reward total was -18.0. running mean: -19.03819774033456, timestamp: 2022-08-20 08:03:40.039694\n",
      "resetting env. episode 2768, reward total was -16.0. running mean: -19.007815762931216, timestamp: 2022-08-20 08:03:42.549723\n",
      "resetting env. episode 2769, reward total was -18.0. running mean: -18.997737605301904, timestamp: 2022-08-20 08:03:44.701747\n",
      "resetting env. episode 2770, reward total was -19.0. running mean: -18.997760229248886, timestamp: 2022-08-20 08:03:47.470783\n",
      "resetting env. episode 2771, reward total was -21.0. running mean: -19.017782626956397, timestamp: 2022-08-20 08:03:49.004801\n",
      "resetting env. episode 2772, reward total was -17.0. running mean: -18.997604800686833, timestamp: 2022-08-20 08:03:51.585834\n",
      "resetting env. episode 2773, reward total was -21.0. running mean: -19.017628752679965, timestamp: 2022-08-20 08:03:53.283857\n",
      "resetting env. episode 2774, reward total was -19.0. running mean: -19.017452465153166, timestamp: 2022-08-20 08:03:55.435880\n",
      "resetting env. episode 2775, reward total was -18.0. running mean: -19.007277940501634, timestamp: 2022-08-20 08:03:57.721908\n",
      "resetting env. episode 2776, reward total was -21.0. running mean: -19.027205161096617, timestamp: 2022-08-20 08:04:00.057935\n",
      "resetting env. episode 2777, reward total was -18.0. running mean: -19.016933109485652, timestamp: 2022-08-20 08:04:02.172959\n",
      "resetting env. episode 2778, reward total was -20.0. running mean: -19.026763778390794, timestamp: 2022-08-20 08:04:03.900981\n",
      "resetting env. episode 2779, reward total was -17.0. running mean: -19.006496140606888, timestamp: 2022-08-20 08:04:06.311012\n",
      "resetting env. episode 2780, reward total was -21.0. running mean: -19.02643117920082, timestamp: 2022-08-20 08:04:08.689040\n",
      "resetting env. episode 2781, reward total was -17.0. running mean: -19.006166867408812, timestamp: 2022-08-20 08:04:10.728063\n",
      "resetting env. episode 2782, reward total was -20.0. running mean: -19.016105198734724, timestamp: 2022-08-20 08:04:12.551607\n",
      "resetting env. episode 2783, reward total was -21.0. running mean: -19.03594414674738, timestamp: 2022-08-20 08:04:14.140629\n",
      "resetting env. episode 2784, reward total was -19.0. running mean: -19.035584705279906, timestamp: 2022-08-20 08:04:16.667658\n",
      "resetting env. episode 2785, reward total was -19.0. running mean: -19.035228858227107, timestamp: 2022-08-20 08:04:19.258690\n",
      "resetting env. episode 2786, reward total was -18.0. running mean: -19.024876569644835, timestamp: 2022-08-20 08:04:21.358718\n",
      "resetting env. episode 2787, reward total was -18.0. running mean: -19.014627803948386, timestamp: 2022-08-20 08:04:24.053746\n",
      "resetting env. episode 2788, reward total was -21.0. running mean: -19.0344815259089, timestamp: 2022-08-20 08:04:26.164779\n",
      "resetting env. episode 2789, reward total was -21.0. running mean: -19.054136710649814, timestamp: 2022-08-20 08:04:27.821791\n",
      "resetting env. episode 2790, reward total was -20.0. running mean: -19.063595343543316, timestamp: 2022-08-20 08:04:29.535815\n",
      "resetting env. episode 2791, reward total was -17.0. running mean: -19.042959390107885, timestamp: 2022-08-20 08:04:31.393834\n",
      "resetting env. episode 2792, reward total was -17.0. running mean: -19.022529796206808, timestamp: 2022-08-20 08:04:33.439860\n",
      "resetting env. episode 2793, reward total was -19.0. running mean: -19.02230449824474, timestamp: 2022-08-20 08:04:35.309888\n",
      "resetting env. episode 2794, reward total was -20.0. running mean: -19.032081453262293, timestamp: 2022-08-20 08:04:37.193905\n",
      "resetting env. episode 2795, reward total was -20.0. running mean: -19.04176063872967, timestamp: 2022-08-20 08:04:38.910929\n",
      "resetting env. episode 2796, reward total was -19.0. running mean: -19.041343032342375, timestamp: 2022-08-20 08:04:40.977952\n",
      "resetting env. episode 2797, reward total was -21.0. running mean: -19.060929602018952, timestamp: 2022-08-20 08:04:42.376972\n",
      "resetting env. episode 2798, reward total was -21.0. running mean: -19.080320305998764, timestamp: 2022-08-20 08:04:44.270991\n",
      "resetting env. episode 2799, reward total was -20.0. running mean: -19.089517102938775, timestamp: 2022-08-20 08:04:45.984016\n",
      "resetting env. episode 2800, reward total was -19.0. running mean: -19.088621931909387, timestamp: 2022-08-20 08:04:47.997036\n",
      "resetting env. episode 2801, reward total was -18.0. running mean: -19.077735712590293, timestamp: 2022-08-20 08:04:50.236063\n",
      "resetting env. episode 2802, reward total was -21.0. running mean: -19.09695835546439, timestamp: 2022-08-20 08:04:52.446092\n",
      "resetting env. episode 2803, reward total was -20.0. running mean: -19.105988771909747, timestamp: 2022-08-20 08:04:54.029113\n",
      "resetting env. episode 2804, reward total was -18.0. running mean: -19.094928884190647, timestamp: 2022-08-20 08:04:56.194134\n",
      "resetting env. episode 2805, reward total was -20.0. running mean: -19.10397959534874, timestamp: 2022-08-20 08:04:58.197163\n",
      "resetting env. episode 2806, reward total was -21.0. running mean: -19.122939799395255, timestamp: 2022-08-20 08:05:00.295185\n",
      "resetting env. episode 2807, reward total was -19.0. running mean: -19.1217104014013, timestamp: 2022-08-20 08:05:02.449213\n",
      "resetting env. episode 2808, reward total was -17.0. running mean: -19.100493297387292, timestamp: 2022-08-20 08:05:04.515242\n",
      "resetting env. episode 2809, reward total was -21.0. running mean: -19.11948836441342, timestamp: 2022-08-20 08:05:06.427259\n",
      "resetting env. episode 2810, reward total was -20.0. running mean: -19.128293480769287, timestamp: 2022-08-20 08:05:08.080280\n",
      "resetting env. episode 2811, reward total was -17.0. running mean: -19.107010545961597, timestamp: 2022-08-20 08:05:10.893312\n",
      "resetting env. episode 2812, reward total was -18.0. running mean: -19.09594044050198, timestamp: 2022-08-20 08:05:12.823337\n",
      "resetting env. episode 2813, reward total was -18.0. running mean: -19.08498103609696, timestamp: 2022-08-20 08:05:15.018365\n",
      "resetting env. episode 2814, reward total was -15.0. running mean: -19.04413122573599, timestamp: 2022-08-20 08:05:17.572394\n",
      "resetting env. episode 2815, reward total was -20.0. running mean: -19.053689913478628, timestamp: 2022-08-20 08:05:19.197412\n",
      "resetting env. episode 2816, reward total was -16.0. running mean: -19.02315301434384, timestamp: 2022-08-20 08:05:21.850446\n",
      "resetting env. episode 2817, reward total was -19.0. running mean: -19.022921484200403, timestamp: 2022-08-20 08:05:23.794469\n",
      "resetting env. episode 2818, reward total was -19.0. running mean: -19.022692269358398, timestamp: 2022-08-20 08:05:25.378488\n",
      "resetting env. episode 2819, reward total was -21.0. running mean: -19.042465346664816, timestamp: 2022-08-20 08:05:26.651505\n",
      "resetting env. episode 2820, reward total was -16.0. running mean: -19.012040693198166, timestamp: 2022-08-20 08:05:28.836533\n",
      "resetting env. episode 2821, reward total was -19.0. running mean: -19.011920286266186, timestamp: 2022-08-20 08:05:31.409564\n",
      "resetting env. episode 2822, reward total was -20.0. running mean: -19.021801083403524, timestamp: 2022-08-20 08:05:33.429590\n",
      "resetting env. episode 2823, reward total was -18.0. running mean: -19.01158307256949, timestamp: 2022-08-20 08:05:36.034618\n",
      "resetting env. episode 2824, reward total was -21.0. running mean: -19.031467241843796, timestamp: 2022-08-20 08:05:38.121648\n",
      "resetting env. episode 2825, reward total was -19.0. running mean: -19.03115256942536, timestamp: 2022-08-20 08:05:40.489672\n",
      "resetting env. episode 2826, reward total was -17.0. running mean: -19.01084104373111, timestamp: 2022-08-20 08:05:42.744702\n",
      "resetting env. episode 2827, reward total was -19.0. running mean: -19.0107326332938, timestamp: 2022-08-20 08:05:44.395719\n",
      "resetting env. episode 2828, reward total was -19.0. running mean: -19.01062530696086, timestamp: 2022-08-20 08:05:46.532744\n",
      "resetting env. episode 2829, reward total was -17.0. running mean: -18.990519053891255, timestamp: 2022-08-20 08:05:48.816775\n",
      "resetting env. episode 2830, reward total was -18.0. running mean: -18.980613863352342, timestamp: 2022-08-20 08:05:50.873795\n",
      "resetting env. episode 2831, reward total was -17.0. running mean: -18.96080772471882, timestamp: 2022-08-20 08:05:53.089829\n",
      "resetting env. episode 2832, reward total was -18.0. running mean: -18.95119964747163, timestamp: 2022-08-20 08:05:55.489857\n",
      "resetting env. episode 2833, reward total was -21.0. running mean: -18.971687650996913, timestamp: 2022-08-20 08:05:56.628871\n",
      "resetting env. episode 2834, reward total was -21.0. running mean: -18.991970774486944, timestamp: 2022-08-20 08:05:59.029896\n",
      "resetting env. episode 2835, reward total was -20.0. running mean: -19.002051066742073, timestamp: 2022-08-20 08:06:01.538926\n",
      "resetting env. episode 2836, reward total was -19.0. running mean: -19.002030556074654, timestamp: 2022-08-20 08:06:03.740475\n",
      "resetting env. episode 2837, reward total was -21.0. running mean: -19.022010250513908, timestamp: 2022-08-20 08:06:05.841507\n",
      "resetting env. episode 2838, reward total was -19.0. running mean: -19.02179014800877, timestamp: 2022-08-20 08:06:07.729532\n",
      "resetting env. episode 2839, reward total was -20.0. running mean: -19.03157224652868, timestamp: 2022-08-20 08:06:09.859548\n",
      "resetting env. episode 2840, reward total was -21.0. running mean: -19.051256524063394, timestamp: 2022-08-20 08:06:11.698572\n",
      "resetting env. episode 2841, reward total was -18.0. running mean: -19.04074395882276, timestamp: 2022-08-20 08:06:13.585594\n",
      "resetting env. episode 2842, reward total was -20.0. running mean: -19.05033651923453, timestamp: 2022-08-20 08:06:15.845623\n",
      "resetting env. episode 2843, reward total was -19.0. running mean: -19.049833154042187, timestamp: 2022-08-20 08:06:17.660648\n",
      "resetting env. episode 2844, reward total was -20.0. running mean: -19.059334822501764, timestamp: 2022-08-20 08:06:19.304665\n",
      "resetting env. episode 2845, reward total was -19.0. running mean: -19.058741474276747, timestamp: 2022-08-20 08:06:21.699698\n",
      "resetting env. episode 2846, reward total was -20.0. running mean: -19.068154059533978, timestamp: 2022-08-20 08:06:24.039724\n",
      "resetting env. episode 2847, reward total was -20.0. running mean: -19.077472518938638, timestamp: 2022-08-20 08:06:26.467771\n",
      "resetting env. episode 2848, reward total was -20.0. running mean: -19.086697793749252, timestamp: 2022-08-20 08:06:28.187773\n",
      "resetting env. episode 2849, reward total was -20.0. running mean: -19.09583081581176, timestamp: 2022-08-20 08:06:29.655793\n",
      "resetting env. episode 2850, reward total was -17.0. running mean: -19.074872507653645, timestamp: 2022-08-20 08:06:32.558346\n",
      "resetting env. episode 2851, reward total was -18.0. running mean: -19.06412378257711, timestamp: 2022-08-20 08:06:34.663375\n",
      "resetting env. episode 2852, reward total was -20.0. running mean: -19.073482544751336, timestamp: 2022-08-20 08:06:36.155390\n",
      "resetting env. episode 2853, reward total was -20.0. running mean: -19.08274771930382, timestamp: 2022-08-20 08:06:38.174419\n",
      "resetting env. episode 2854, reward total was -19.0. running mean: -19.081920242110783, timestamp: 2022-08-20 08:06:40.578447\n",
      "resetting env. episode 2855, reward total was -16.0. running mean: -19.051101039689676, timestamp: 2022-08-20 08:06:43.616483\n",
      "resetting env. episode 2856, reward total was -20.0. running mean: -19.06059002929278, timestamp: 2022-08-20 08:06:45.406506\n",
      "resetting env. episode 2857, reward total was -19.0. running mean: -19.05998412899985, timestamp: 2022-08-20 08:06:47.744537\n",
      "resetting env. episode 2858, reward total was -17.0. running mean: -19.039384287709854, timestamp: 2022-08-20 08:06:50.298568\n",
      "resetting env. episode 2859, reward total was -20.0. running mean: -19.048990444832754, timestamp: 2022-08-20 08:06:52.299587\n",
      "resetting env. episode 2860, reward total was -20.0. running mean: -19.058500540384426, timestamp: 2022-08-20 08:06:54.173609\n",
      "resetting env. episode 2861, reward total was -21.0. running mean: -19.077915534980583, timestamp: 2022-08-20 08:06:55.549628\n",
      "resetting env. episode 2862, reward total was -20.0. running mean: -19.087136379630778, timestamp: 2022-08-20 08:06:57.178648\n",
      "resetting env. episode 2863, reward total was -21.0. running mean: -19.10626501583447, timestamp: 2022-08-20 08:06:58.532667\n",
      "resetting env. episode 2864, reward total was -21.0. running mean: -19.125202365676127, timestamp: 2022-08-20 08:07:00.538689\n",
      "resetting env. episode 2865, reward total was -17.0. running mean: -19.103950342019367, timestamp: 2022-08-20 08:07:03.221724\n",
      "resetting env. episode 2866, reward total was -16.0. running mean: -19.072910838599174, timestamp: 2022-08-20 08:07:06.204763\n",
      "resetting env. episode 2867, reward total was -18.0. running mean: -19.062181730213183, timestamp: 2022-08-20 08:07:08.866792\n",
      "resetting env. episode 2868, reward total was -20.0. running mean: -19.07155991291105, timestamp: 2022-08-20 08:07:10.995815\n",
      "resetting env. episode 2869, reward total was -20.0. running mean: -19.080844313781938, timestamp: 2022-08-20 08:07:12.637837\n",
      "resetting env. episode 2870, reward total was -20.0. running mean: -19.09003587064412, timestamp: 2022-08-20 08:07:14.239858\n",
      "resetting env. episode 2871, reward total was -21.0. running mean: -19.10913551193768, timestamp: 2022-08-20 08:07:16.192882\n",
      "resetting env. episode 2872, reward total was -17.0. running mean: -19.088044156818306, timestamp: 2022-08-20 08:07:18.417907\n",
      "resetting env. episode 2873, reward total was -21.0. running mean: -19.107163715250124, timestamp: 2022-08-20 08:07:20.385930\n",
      "resetting env. episode 2874, reward total was -18.0. running mean: -19.096092078097623, timestamp: 2022-08-20 08:07:23.215970\n",
      "resetting env. episode 2875, reward total was -20.0. running mean: -19.105131157316645, timestamp: 2022-08-20 08:07:25.168992\n",
      "resetting env. episode 2876, reward total was -21.0. running mean: -19.12407984574348, timestamp: 2022-08-20 08:07:27.268017\n",
      "resetting env. episode 2877, reward total was -21.0. running mean: -19.142839047286046, timestamp: 2022-08-20 08:07:29.741046\n",
      "resetting env. episode 2878, reward total was -21.0. running mean: -19.161410656813185, timestamp: 2022-08-20 08:07:31.287063\n",
      "resetting env. episode 2879, reward total was -20.0. running mean: -19.169796550245053, timestamp: 2022-08-20 08:07:33.215091\n",
      "resetting env. episode 2880, reward total was -18.0. running mean: -19.158098584742604, timestamp: 2022-08-20 08:07:35.375114\n",
      "resetting env. episode 2881, reward total was -19.0. running mean: -19.156517598895178, timestamp: 2022-08-20 08:07:37.207139\n",
      "resetting env. episode 2882, reward total was -16.0. running mean: -19.124952422906226, timestamp: 2022-08-20 08:07:39.702169\n",
      "resetting env. episode 2883, reward total was -19.0. running mean: -19.123702898677166, timestamp: 2022-08-20 08:07:41.565712\n",
      "resetting env. episode 2884, reward total was -19.0. running mean: -19.122465869690394, timestamp: 2022-08-20 08:07:43.942740\n",
      "resetting env. episode 2885, reward total was -21.0. running mean: -19.141241210993492, timestamp: 2022-08-20 08:07:46.563773\n",
      "resetting env. episode 2886, reward total was -21.0. running mean: -19.15982879888356, timestamp: 2022-08-20 08:07:48.365794\n",
      "resetting env. episode 2887, reward total was -19.0. running mean: -19.158230510894725, timestamp: 2022-08-20 08:07:51.097828\n",
      "resetting env. episode 2888, reward total was -21.0. running mean: -19.176648205785778, timestamp: 2022-08-20 08:07:52.879850\n",
      "resetting env. episode 2889, reward total was -19.0. running mean: -19.17488172372792, timestamp: 2022-08-20 08:07:54.711876\n",
      "resetting env. episode 2890, reward total was -18.0. running mean: -19.16313290649064, timestamp: 2022-08-20 08:07:56.588894\n",
      "resetting env. episode 2891, reward total was -18.0. running mean: -19.151501577425734, timestamp: 2022-08-20 08:07:58.491918\n",
      "resetting env. episode 2892, reward total was -18.0. running mean: -19.139986561651476, timestamp: 2022-08-20 08:08:00.772950\n",
      "resetting env. episode 2893, reward total was -20.0. running mean: -19.14858669603496, timestamp: 2022-08-20 08:08:02.713972\n",
      "resetting env. episode 2894, reward total was -21.0. running mean: -19.167100829074613, timestamp: 2022-08-20 08:08:04.441995\n",
      "resetting env. episode 2895, reward total was -21.0. running mean: -19.185429820783867, timestamp: 2022-08-20 08:08:06.278014\n",
      "resetting env. episode 2896, reward total was -18.0. running mean: -19.173575522576026, timestamp: 2022-08-20 08:08:09.217049\n",
      "resetting env. episode 2897, reward total was -18.0. running mean: -19.161839767350266, timestamp: 2022-08-20 08:08:11.512079\n",
      "resetting env. episode 2898, reward total was -21.0. running mean: -19.180221369676765, timestamp: 2022-08-20 08:08:13.105096\n",
      "resetting env. episode 2899, reward total was -18.0. running mean: -19.168419155979997, timestamp: 2022-08-20 08:08:14.704115\n",
      "resetting env. episode 2900, reward total was -20.0. running mean: -19.176734964420195, timestamp: 2022-08-20 08:08:17.179147\n",
      "resetting env. episode 2901, reward total was -21.0. running mean: -19.194967614775994, timestamp: 2022-08-20 08:08:18.990171\n",
      "resetting env. episode 2902, reward total was -17.0. running mean: -19.173017938628234, timestamp: 2022-08-20 08:08:21.155199\n",
      "resetting env. episode 2903, reward total was -19.0. running mean: -19.171287759241952, timestamp: 2022-08-20 08:08:22.747216\n",
      "resetting env. episode 2904, reward total was -19.0. running mean: -19.169574881649535, timestamp: 2022-08-20 08:08:24.324234\n",
      "resetting env. episode 2905, reward total was -19.0. running mean: -19.16787913283304, timestamp: 2022-08-20 08:08:26.214257\n",
      "resetting env. episode 2906, reward total was -21.0. running mean: -19.18620034150471, timestamp: 2022-08-20 08:08:28.325282\n",
      "resetting env. episode 2907, reward total was -21.0. running mean: -19.204338338089663, timestamp: 2022-08-20 08:08:29.950307\n",
      "resetting env. episode 2908, reward total was -20.0. running mean: -19.212294954708764, timestamp: 2022-08-20 08:08:31.737329\n",
      "resetting env. episode 2909, reward total was -21.0. running mean: -19.230172005161677, timestamp: 2022-08-20 08:08:33.512351\n",
      "resetting env. episode 2910, reward total was -19.0. running mean: -19.22787028511006, timestamp: 2022-08-20 08:08:34.730363\n",
      "resetting env. episode 2911, reward total was -21.0. running mean: -19.24559158225896, timestamp: 2022-08-20 08:08:36.161382\n",
      "resetting env. episode 2912, reward total was -20.0. running mean: -19.25313566643637, timestamp: 2022-08-20 08:08:38.678410\n",
      "resetting env. episode 2913, reward total was -20.0. running mean: -19.260604309772006, timestamp: 2022-08-20 08:08:40.034426\n",
      "resetting env. episode 2914, reward total was -18.0. running mean: -19.247998266674287, timestamp: 2022-08-20 08:08:42.906462\n",
      "resetting env. episode 2915, reward total was -18.0. running mean: -19.235518284007544, timestamp: 2022-08-20 08:08:44.669480\n",
      "resetting env. episode 2916, reward total was -21.0. running mean: -19.25316310116747, timestamp: 2022-08-20 08:08:47.020509\n",
      "resetting env. episode 2917, reward total was -19.0. running mean: -19.250631470155795, timestamp: 2022-08-20 08:08:48.671535\n",
      "resetting env. episode 2918, reward total was -15.0. running mean: -19.208125155454237, timestamp: 2022-08-20 08:08:51.534565\n",
      "resetting env. episode 2919, reward total was -17.0. running mean: -19.186043903899694, timestamp: 2022-08-20 08:08:53.150589\n",
      "resetting env. episode 2920, reward total was -19.0. running mean: -19.1841834648607, timestamp: 2022-08-20 08:08:54.618602\n",
      "resetting env. episode 2921, reward total was -19.0. running mean: -19.182341630212093, timestamp: 2022-08-20 08:08:56.484625\n",
      "resetting env. episode 2922, reward total was -20.0. running mean: -19.19051821390997, timestamp: 2022-08-20 08:08:57.988647\n",
      "resetting env. episode 2923, reward total was -18.0. running mean: -19.178613031770873, timestamp: 2022-08-20 08:09:00.125674\n",
      "resetting env. episode 2924, reward total was -18.0. running mean: -19.166826901453163, timestamp: 2022-08-20 08:09:02.302696\n",
      "resetting env. episode 2925, reward total was -18.0. running mean: -19.15515863243863, timestamp: 2022-08-20 08:09:04.695727\n",
      "resetting env. episode 2926, reward total was -20.0. running mean: -19.163607046114244, timestamp: 2022-08-20 08:09:06.222751\n",
      "resetting env. episode 2927, reward total was -17.0. running mean: -19.141970975653102, timestamp: 2022-08-20 08:09:08.420774\n",
      "resetting env. episode 2928, reward total was -20.0. running mean: -19.15055126589657, timestamp: 2022-08-20 08:09:09.604786\n",
      "resetting env. episode 2929, reward total was -20.0. running mean: -19.159045753237603, timestamp: 2022-08-20 08:09:11.833818\n",
      "resetting env. episode 2930, reward total was -19.0. running mean: -19.157455295705226, timestamp: 2022-08-20 08:09:13.486833\n",
      "resetting env. episode 2931, reward total was -16.0. running mean: -19.125880742748173, timestamp: 2022-08-20 08:09:16.347870\n",
      "resetting env. episode 2932, reward total was -19.0. running mean: -19.124621935320693, timestamp: 2022-08-20 08:09:18.027887\n",
      "resetting env. episode 2933, reward total was -21.0. running mean: -19.143375715967487, timestamp: 2022-08-20 08:09:19.919911\n",
      "resetting env. episode 2934, reward total was -19.0. running mean: -19.141941958807813, timestamp: 2022-08-20 08:09:21.950938\n",
      "resetting env. episode 2935, reward total was -20.0. running mean: -19.150522539219732, timestamp: 2022-08-20 08:09:24.596969\n",
      "resetting env. episode 2936, reward total was -21.0. running mean: -19.169017313827535, timestamp: 2022-08-20 08:09:26.063991\n",
      "resetting env. episode 2937, reward total was -21.0. running mean: -19.18732714068926, timestamp: 2022-08-20 08:09:28.341015\n",
      "resetting env. episode 2938, reward total was -19.0. running mean: -19.185453869282366, timestamp: 2022-08-20 08:09:30.203042\n",
      "resetting env. episode 2939, reward total was -20.0. running mean: -19.193599330589542, timestamp: 2022-08-20 08:09:32.304063\n",
      "resetting env. episode 2940, reward total was -20.0. running mean: -19.201663337283644, timestamp: 2022-08-20 08:09:34.324614\n",
      "resetting env. episode 2941, reward total was -21.0. running mean: -19.219646703910808, timestamp: 2022-08-20 08:09:35.501626\n",
      "resetting env. episode 2942, reward total was -18.0. running mean: -19.2074502368717, timestamp: 2022-08-20 08:09:38.065657\n",
      "resetting env. episode 2943, reward total was -16.0. running mean: -19.175375734502982, timestamp: 2022-08-20 08:09:40.094682\n",
      "resetting env. episode 2944, reward total was -20.0. running mean: -19.18362197715795, timestamp: 2022-08-20 08:09:41.812703\n",
      "resetting env. episode 2945, reward total was -20.0. running mean: -19.19178575738637, timestamp: 2022-08-20 08:09:43.374723\n",
      "resetting env. episode 2946, reward total was -19.0. running mean: -19.18986789981251, timestamp: 2022-08-20 08:09:44.890744\n",
      "resetting env. episode 2947, reward total was -21.0. running mean: -19.207969220814384, timestamp: 2022-08-20 08:09:46.017757\n",
      "resetting env. episode 2948, reward total was -19.0. running mean: -19.205889528606242, timestamp: 2022-08-20 08:09:47.784776\n",
      "resetting env. episode 2949, reward total was -17.0. running mean: -19.18383063332018, timestamp: 2022-08-20 08:09:50.314810\n",
      "resetting env. episode 2950, reward total was -21.0. running mean: -19.20199232698698, timestamp: 2022-08-20 08:09:52.679836\n",
      "resetting env. episode 2951, reward total was -21.0. running mean: -19.219972403717108, timestamp: 2022-08-20 08:09:54.837862\n",
      "resetting env. episode 2952, reward total was -18.0. running mean: -19.207772679679938, timestamp: 2022-08-20 08:09:56.678887\n",
      "resetting env. episode 2953, reward total was -21.0. running mean: -19.22569495288314, timestamp: 2022-08-20 08:09:58.418909\n",
      "resetting env. episode 2954, reward total was -19.0. running mean: -19.223438003354307, timestamp: 2022-08-20 08:10:00.122930\n",
      "resetting env. episode 2955, reward total was -19.0. running mean: -19.221203623320765, timestamp: 2022-08-20 08:10:02.745963\n",
      "resetting env. episode 2956, reward total was -19.0. running mean: -19.218991587087558, timestamp: 2022-08-20 08:10:04.353982\n",
      "resetting env. episode 2957, reward total was -17.0. running mean: -19.196801671216683, timestamp: 2022-08-20 08:10:06.273001\n",
      "resetting env. episode 2958, reward total was -20.0. running mean: -19.204833654504515, timestamp: 2022-08-20 08:10:07.909026\n",
      "resetting env. episode 2959, reward total was -19.0. running mean: -19.20278531795947, timestamp: 2022-08-20 08:10:09.705572\n",
      "resetting env. episode 2960, reward total was -21.0. running mean: -19.220757464779876, timestamp: 2022-08-20 08:10:11.218587\n",
      "resetting env. episode 2961, reward total was -21.0. running mean: -19.238549890132077, timestamp: 2022-08-20 08:10:13.481615\n",
      "resetting env. episode 2962, reward total was -18.0. running mean: -19.226164391230757, timestamp: 2022-08-20 08:10:16.231649\n",
      "resetting env. episode 2963, reward total was -18.0. running mean: -19.21390274731845, timestamp: 2022-08-20 08:10:18.967209\n",
      "resetting env. episode 2964, reward total was -20.0. running mean: -19.221763719845264, timestamp: 2022-08-20 08:10:21.132236\n",
      "resetting env. episode 2965, reward total was -19.0. running mean: -19.21954608264681, timestamp: 2022-08-20 08:10:22.913258\n",
      "resetting env. episode 2966, reward total was -19.0. running mean: -19.217350621820344, timestamp: 2022-08-20 08:10:25.092286\n",
      "resetting env. episode 2967, reward total was -20.0. running mean: -19.22517711560214, timestamp: 2022-08-20 08:10:26.627305\n",
      "resetting env. episode 2968, reward total was -19.0. running mean: -19.222925344446118, timestamp: 2022-08-20 08:10:28.984332\n",
      "resetting env. episode 2969, reward total was -20.0. running mean: -19.230696091001654, timestamp: 2022-08-20 08:10:30.699352\n",
      "resetting env. episode 2970, reward total was -19.0. running mean: -19.22838913009164, timestamp: 2022-08-20 08:10:32.046369\n",
      "resetting env. episode 2971, reward total was -18.0. running mean: -19.21610523879072, timestamp: 2022-08-20 08:10:34.465398\n",
      "resetting env. episode 2972, reward total was -20.0. running mean: -19.223944186402814, timestamp: 2022-08-20 08:10:36.522422\n",
      "resetting env. episode 2973, reward total was -20.0. running mean: -19.231704744538785, timestamp: 2022-08-20 08:10:38.243444\n",
      "resetting env. episode 2974, reward total was -18.0. running mean: -19.219387697093396, timestamp: 2022-08-20 08:10:41.402484\n",
      "resetting env. episode 2975, reward total was -21.0. running mean: -19.237193820122464, timestamp: 2022-08-20 08:10:43.740511\n",
      "resetting env. episode 2976, reward total was -19.0. running mean: -19.23482188192124, timestamp: 2022-08-20 08:10:46.768548\n",
      "resetting env. episode 2977, reward total was -20.0. running mean: -19.242473663102025, timestamp: 2022-08-20 08:10:48.433569\n",
      "resetting env. episode 2978, reward total was -18.0. running mean: -19.230048926471003, timestamp: 2022-08-20 08:10:50.768600\n",
      "resetting env. episode 2979, reward total was -18.0. running mean: -19.217748437206293, timestamp: 2022-08-20 08:10:53.262164\n",
      "resetting env. episode 2980, reward total was -20.0. running mean: -19.22557095283423, timestamp: 2022-08-20 08:10:54.756180\n",
      "resetting env. episode 2981, reward total was -19.0. running mean: -19.223315243305887, timestamp: 2022-08-20 08:10:56.547202\n",
      "resetting env. episode 2982, reward total was -21.0. running mean: -19.24108209087283, timestamp: 2022-08-20 08:10:58.607227\n",
      "resetting env. episode 2983, reward total was -21.0. running mean: -19.2586712699641, timestamp: 2022-08-20 08:11:00.948256\n",
      "resetting env. episode 2984, reward total was -18.0. running mean: -19.24608455726446, timestamp: 2022-08-20 08:11:02.699278\n",
      "resetting env. episode 2985, reward total was -20.0. running mean: -19.253623711691816, timestamp: 2022-08-20 08:11:04.326295\n",
      "resetting env. episode 2986, reward total was -20.0. running mean: -19.261087474574897, timestamp: 2022-08-20 08:11:06.541325\n",
      "resetting env. episode 2987, reward total was -18.0. running mean: -19.248476599829146, timestamp: 2022-08-20 08:11:09.122355\n",
      "resetting env. episode 2988, reward total was -21.0. running mean: -19.265991833830856, timestamp: 2022-08-20 08:11:10.339370\n",
      "resetting env. episode 2989, reward total was -19.0. running mean: -19.26333191549255, timestamp: 2022-08-20 08:11:13.012402\n",
      "resetting env. episode 2990, reward total was -21.0. running mean: -19.280698596337626, timestamp: 2022-08-20 08:11:14.972427\n",
      "resetting env. episode 2991, reward total was -16.0. running mean: -19.24789161037425, timestamp: 2022-08-20 08:11:17.397464\n",
      "resetting env. episode 2992, reward total was -20.0. running mean: -19.255412694270508, timestamp: 2022-08-20 08:11:19.140480\n",
      "resetting env. episode 2993, reward total was -17.0. running mean: -19.232858567327803, timestamp: 2022-08-20 08:11:21.662509\n",
      "resetting env. episode 2994, reward total was -20.0. running mean: -19.240529981654525, timestamp: 2022-08-20 08:11:23.870534\n",
      "resetting env. episode 2995, reward total was -18.0. running mean: -19.22812468183798, timestamp: 2022-08-20 08:11:26.306571\n",
      "resetting env. episode 2996, reward total was -19.0. running mean: -19.225843435019602, timestamp: 2022-08-20 08:11:28.169589\n",
      "resetting env. episode 2997, reward total was -15.0. running mean: -19.183585000669403, timestamp: 2022-08-20 08:11:30.522618\n",
      "resetting env. episode 2998, reward total was -19.0. running mean: -19.18174915066271, timestamp: 2022-08-20 08:11:32.687641\n",
      "resetting env. episode 2999, reward total was -20.0. running mean: -19.189931659156084, timestamp: 2022-08-20 08:11:34.347661\n",
      "resetting env. episode 3000, reward total was -20.0. running mean: -19.198032342564524, timestamp: 2022-08-20 08:11:36.719690\n",
      "resetting env. episode 3001, reward total was -17.0. running mean: -19.17605201913888, timestamp: 2022-08-20 08:11:38.963721\n",
      "resetting env. episode 3002, reward total was -20.0. running mean: -19.18429149894749, timestamp: 2022-08-20 08:11:40.687741\n",
      "resetting env. episode 3003, reward total was -20.0. running mean: -19.192448583958015, timestamp: 2022-08-20 08:11:43.351776\n",
      "resetting env. episode 3004, reward total was -20.0. running mean: -19.200524098118436, timestamp: 2022-08-20 08:11:45.142793\n",
      "resetting env. episode 3005, reward total was -16.0. running mean: -19.16851885713725, timestamp: 2022-08-20 08:11:47.873828\n",
      "resetting env. episode 3006, reward total was -21.0. running mean: -19.18683366856588, timestamp: 2022-08-20 08:11:50.247858\n",
      "resetting env. episode 3007, reward total was -19.0. running mean: -19.18496533188022, timestamp: 2022-08-20 08:11:52.640889\n",
      "resetting env. episode 3008, reward total was -19.0. running mean: -19.18311567856142, timestamp: 2022-08-20 08:11:54.710911\n",
      "resetting env. episode 3009, reward total was -17.0. running mean: -19.16128452177581, timestamp: 2022-08-20 08:11:57.097939\n",
      "resetting env. episode 3010, reward total was -18.0. running mean: -19.14967167655805, timestamp: 2022-08-20 08:11:58.891962\n",
      "resetting env. episode 3011, reward total was -17.0. running mean: -19.12817495979247, timestamp: 2022-08-20 08:12:01.089989\n",
      "resetting env. episode 3012, reward total was -17.0. running mean: -19.10689321019455, timestamp: 2022-08-20 08:12:03.645023\n",
      "resetting env. episode 3013, reward total was -17.0. running mean: -19.085824278092606, timestamp: 2022-08-20 08:12:06.189053\n",
      "resetting env. episode 3014, reward total was -19.0. running mean: -19.08496603531168, timestamp: 2022-08-20 08:12:08.064077\n",
      "resetting env. episode 3015, reward total was -21.0. running mean: -19.104116374958565, timestamp: 2022-08-20 08:12:09.806094\n",
      "resetting env. episode 3016, reward total was -17.0. running mean: -19.083075211208982, timestamp: 2022-08-20 08:12:13.213141\n",
      "resetting env. episode 3017, reward total was -21.0. running mean: -19.102244459096895, timestamp: 2022-08-20 08:12:15.412167\n",
      "resetting env. episode 3018, reward total was -18.0. running mean: -19.091222014505924, timestamp: 2022-08-20 08:12:17.826194\n",
      "resetting env. episode 3019, reward total was -19.0. running mean: -19.090309794360866, timestamp: 2022-08-20 08:12:20.032221\n",
      "resetting env. episode 3020, reward total was -19.0. running mean: -19.08940669641726, timestamp: 2022-08-20 08:12:22.812255\n",
      "resetting env. episode 3021, reward total was -17.0. running mean: -19.06851262945309, timestamp: 2022-08-20 08:12:24.841279\n",
      "resetting env. episode 3022, reward total was -20.0. running mean: -19.077827503158556, timestamp: 2022-08-20 08:12:27.369312\n",
      "resetting env. episode 3023, reward total was -20.0. running mean: -19.08704922812697, timestamp: 2022-08-20 08:12:29.831343\n",
      "resetting env. episode 3024, reward total was -15.0. running mean: -19.046178735845697, timestamp: 2022-08-20 08:12:31.966365\n",
      "resetting env. episode 3025, reward total was -19.0. running mean: -19.04571694848724, timestamp: 2022-08-20 08:12:33.711387\n",
      "resetting env. episode 3026, reward total was -20.0. running mean: -19.055259779002366, timestamp: 2022-08-20 08:12:35.587409\n",
      "resetting env. episode 3027, reward total was -17.0. running mean: -19.034707181212344, timestamp: 2022-08-20 08:12:38.081449\n",
      "resetting env. episode 3028, reward total was -20.0. running mean: -19.04436010940022, timestamp: 2022-08-20 08:12:40.014467\n",
      "resetting env. episode 3029, reward total was -20.0. running mean: -19.053916508306216, timestamp: 2022-08-20 08:12:42.252490\n",
      "resetting env. episode 3030, reward total was -18.0. running mean: -19.043377343223153, timestamp: 2022-08-20 08:12:44.084515\n",
      "resetting env. episode 3031, reward total was -18.0. running mean: -19.03294356979092, timestamp: 2022-08-20 08:12:46.357068\n",
      "resetting env. episode 3032, reward total was -19.0. running mean: -19.032614134093013, timestamp: 2022-08-20 08:12:48.757092\n",
      "resetting env. episode 3033, reward total was -17.0. running mean: -19.012287992752086, timestamp: 2022-08-20 08:12:51.227124\n",
      "resetting env. episode 3034, reward total was -18.0. running mean: -19.002165112824564, timestamp: 2022-08-20 08:12:53.713153\n",
      "resetting env. episode 3035, reward total was -19.0. running mean: -19.00214346169632, timestamp: 2022-08-20 08:12:55.743179\n",
      "resetting env. episode 3036, reward total was -19.0. running mean: -19.00212202707936, timestamp: 2022-08-20 08:12:58.248208\n",
      "resetting env. episode 3037, reward total was -18.0. running mean: -18.992100806808565, timestamp: 2022-08-20 08:13:00.597240\n",
      "resetting env. episode 3038, reward total was -20.0. running mean: -19.002179798740478, timestamp: 2022-08-20 08:13:02.632263\n",
      "resetting env. episode 3039, reward total was -19.0. running mean: -19.002158000753074, timestamp: 2022-08-20 08:13:04.838290\n",
      "resetting env. episode 3040, reward total was -17.0. running mean: -18.982136420745544, timestamp: 2022-08-20 08:13:07.263320\n",
      "resetting env. episode 3041, reward total was -18.0. running mean: -18.972315056538086, timestamp: 2022-08-20 08:13:09.641880\n",
      "resetting env. episode 3042, reward total was -21.0. running mean: -18.992591905972706, timestamp: 2022-08-20 08:13:11.452901\n",
      "resetting env. episode 3043, reward total was -20.0. running mean: -19.002665986912977, timestamp: 2022-08-20 08:13:13.661926\n",
      "resetting env. episode 3044, reward total was -21.0. running mean: -19.022639327043848, timestamp: 2022-08-20 08:13:15.850955\n",
      "resetting env. episode 3045, reward total was -20.0. running mean: -19.032412933773408, timestamp: 2022-08-20 08:13:18.284984\n",
      "resetting env. episode 3046, reward total was -17.0. running mean: -19.012088804435674, timestamp: 2022-08-20 08:13:20.218544\n",
      "resetting env. episode 3047, reward total was -21.0. running mean: -19.031967916391316, timestamp: 2022-08-20 08:13:21.996561\n",
      "resetting env. episode 3048, reward total was -20.0. running mean: -19.041648237227403, timestamp: 2022-08-20 08:13:23.619580\n",
      "resetting env. episode 3049, reward total was -19.0. running mean: -19.04123175485513, timestamp: 2022-08-20 08:13:25.279600\n",
      "resetting env. episode 3050, reward total was -16.0. running mean: -19.010819437306576, timestamp: 2022-08-20 08:13:27.557628\n",
      "resetting env. episode 3051, reward total was -17.0. running mean: -18.99071124293351, timestamp: 2022-08-20 08:13:29.808656\n",
      "resetting env. episode 3052, reward total was -18.0. running mean: -18.980804130504175, timestamp: 2022-08-20 08:13:32.835693\n",
      "resetting env. episode 3053, reward total was -19.0. running mean: -18.980996089199135, timestamp: 2022-08-20 08:13:36.302738\n",
      "resetting env. episode 3054, reward total was -19.0. running mean: -18.981186128307144, timestamp: 2022-08-20 08:13:38.641764\n",
      "resetting env. episode 3055, reward total was -18.0. running mean: -18.97137426702407, timestamp: 2022-08-20 08:13:41.468798\n",
      "resetting env. episode 3056, reward total was -18.0. running mean: -18.96166052435383, timestamp: 2022-08-20 08:13:45.403847\n",
      "resetting env. episode 3057, reward total was -20.0. running mean: -18.97204391911029, timestamp: 2022-08-20 08:13:48.117878\n",
      "resetting env. episode 3058, reward total was -13.0. running mean: -18.912323479919188, timestamp: 2022-08-20 08:13:51.564919\n",
      "resetting env. episode 3059, reward total was -18.0. running mean: -18.903200245119994, timestamp: 2022-08-20 08:13:54.917960\n",
      "resetting env. episode 3060, reward total was -17.0. running mean: -18.884168242668796, timestamp: 2022-08-20 08:13:58.004996\n",
      "resetting env. episode 3061, reward total was -20.0. running mean: -18.895326560242108, timestamp: 2022-08-20 08:14:00.283027\n",
      "resetting env. episode 3062, reward total was -17.0. running mean: -18.876373294639688, timestamp: 2022-08-20 08:14:03.808067\n",
      "resetting env. episode 3063, reward total was -17.0. running mean: -18.85760956169329, timestamp: 2022-08-20 08:14:06.714103\n",
      "resetting env. episode 3064, reward total was -15.0. running mean: -18.819033466076355, timestamp: 2022-08-20 08:14:10.124146\n",
      "resetting env. episode 3065, reward total was -17.0. running mean: -18.800843131415593, timestamp: 2022-08-20 08:14:13.644188\n",
      "resetting env. episode 3066, reward total was -18.0. running mean: -18.792834700101437, timestamp: 2022-08-20 08:14:16.841224\n",
      "resetting env. episode 3067, reward total was -18.0. running mean: -18.78490635310042, timestamp: 2022-08-20 08:14:20.249269\n",
      "resetting env. episode 3068, reward total was -21.0. running mean: -18.807057289569418, timestamp: 2022-08-20 08:14:22.717822\n",
      "resetting env. episode 3069, reward total was -19.0. running mean: -18.808986716673726, timestamp: 2022-08-20 08:14:25.723384\n",
      "resetting env. episode 3070, reward total was -20.0. running mean: -18.820896849506987, timestamp: 2022-08-20 08:14:28.313415\n",
      "resetting env. episode 3071, reward total was -20.0. running mean: -18.832687881011918, timestamp: 2022-08-20 08:14:30.558441\n",
      "resetting env. episode 3072, reward total was -21.0. running mean: -18.8543610022018, timestamp: 2022-08-20 08:14:32.512466\n",
      "resetting env. episode 3073, reward total was -21.0. running mean: -18.87581739217978, timestamp: 2022-08-20 08:14:34.904497\n",
      "resetting env. episode 3074, reward total was -21.0. running mean: -18.897059218257983, timestamp: 2022-08-20 08:14:36.781519\n",
      "resetting env. episode 3075, reward total was -17.0. running mean: -18.878088626075403, timestamp: 2022-08-20 08:14:39.552553\n",
      "resetting env. episode 3076, reward total was -17.0. running mean: -18.85930773981465, timestamp: 2022-08-20 08:14:43.162595\n",
      "resetting env. episode 3077, reward total was -15.0. running mean: -18.820714662416503, timestamp: 2022-08-20 08:14:46.514637\n",
      "resetting env. episode 3078, reward total was -15.0. running mean: -18.782507515792336, timestamp: 2022-08-20 08:14:49.782676\n",
      "resetting env. episode 3079, reward total was -19.0. running mean: -18.784682440634413, timestamp: 2022-08-20 08:14:52.176708\n",
      "resetting env. episode 3080, reward total was -15.0. running mean: -18.74683561622807, timestamp: 2022-08-20 08:14:55.655748\n",
      "resetting env. episode 3081, reward total was -19.0. running mean: -18.74936726006579, timestamp: 2022-08-20 08:14:58.365783\n",
      "resetting env. episode 3082, reward total was -16.0. running mean: -18.72187358746513, timestamp: 2022-08-20 08:15:02.323356\n",
      "resetting env. episode 3083, reward total was -20.0. running mean: -18.734654851590477, timestamp: 2022-08-20 08:15:04.756386\n",
      "resetting env. episode 3084, reward total was -21.0. running mean: -18.757308303074574, timestamp: 2022-08-20 08:15:06.617407\n",
      "resetting env. episode 3085, reward total was -19.0. running mean: -18.75973522004383, timestamp: 2022-08-20 08:15:09.913446\n",
      "resetting env. episode 3086, reward total was -21.0. running mean: -18.782137867843392, timestamp: 2022-08-20 08:15:13.292487\n",
      "resetting env. episode 3087, reward total was -19.0. running mean: -18.784316489164958, timestamp: 2022-08-20 08:15:17.139536\n",
      "resetting env. episode 3088, reward total was -18.0. running mean: -18.776473324273308, timestamp: 2022-08-20 08:15:20.156573\n",
      "resetting env. episode 3089, reward total was -16.0. running mean: -18.748708591030574, timestamp: 2022-08-20 08:15:23.630613\n",
      "resetting env. episode 3090, reward total was -19.0. running mean: -18.75122150512027, timestamp: 2022-08-20 08:15:26.520649\n",
      "resetting env. episode 3091, reward total was -15.0. running mean: -18.713709290069065, timestamp: 2022-08-20 08:15:29.732690\n",
      "resetting env. episode 3092, reward total was -16.0. running mean: -18.686572197168374, timestamp: 2022-08-20 08:15:34.257747\n",
      "resetting env. episode 3093, reward total was -18.0. running mean: -18.67970647519669, timestamp: 2022-08-20 08:15:37.342782\n",
      "resetting env. episode 3094, reward total was -20.0. running mean: -18.69290941044472, timestamp: 2022-08-20 08:15:41.048826\n",
      "resetting env. episode 3095, reward total was -20.0. running mean: -18.705980316340273, timestamp: 2022-08-20 08:15:43.647859\n",
      "resetting env. episode 3096, reward total was -19.0. running mean: -18.70892051317687, timestamp: 2022-08-20 08:15:46.020412\n",
      "resetting env. episode 3097, reward total was -21.0. running mean: -18.731831308045102, timestamp: 2022-08-20 08:15:48.556444\n",
      "resetting env. episode 3098, reward total was -20.0. running mean: -18.74451299496465, timestamp: 2022-08-20 08:15:51.445477\n",
      "resetting env. episode 3099, reward total was -20.0. running mean: -18.757067865015003, timestamp: 2022-08-20 08:15:53.171501\n",
      "resetting env. episode 3100, reward total was -17.0. running mean: -18.739497186364854, timestamp: 2022-08-20 08:15:56.775063\n",
      "resetting env. episode 3101, reward total was -20.0. running mean: -18.752102214501203, timestamp: 2022-08-20 08:15:59.911103\n",
      "resetting env. episode 3102, reward total was -21.0. running mean: -18.77458119235619, timestamp: 2022-08-20 08:16:02.515134\n",
      "resetting env. episode 3103, reward total was -19.0. running mean: -18.77683538043263, timestamp: 2022-08-20 08:16:05.034164\n",
      "resetting env. episode 3104, reward total was -21.0. running mean: -18.799067026628304, timestamp: 2022-08-20 08:16:07.527196\n",
      "resetting env. episode 3105, reward total was -20.0. running mean: -18.81107635636202, timestamp: 2022-08-20 08:16:10.381227\n",
      "resetting env. episode 3106, reward total was -19.0. running mean: -18.8129655927984, timestamp: 2022-08-20 08:16:13.339265\n",
      "resetting env. episode 3107, reward total was -18.0. running mean: -18.804835936870415, timestamp: 2022-08-20 08:16:15.817297\n",
      "resetting env. episode 3108, reward total was -21.0. running mean: -18.82678757750171, timestamp: 2022-08-20 08:16:18.414328\n",
      "resetting env. episode 3109, reward total was -17.0. running mean: -18.808519701726695, timestamp: 2022-08-20 08:16:21.516372\n",
      "resetting env. episode 3110, reward total was -19.0. running mean: -18.81043450470943, timestamp: 2022-08-20 08:16:24.292397\n",
      "resetting env. episode 3111, reward total was -21.0. running mean: -18.832330159662337, timestamp: 2022-08-20 08:16:27.971445\n",
      "resetting env. episode 3112, reward total was -19.0. running mean: -18.834006858065717, timestamp: 2022-08-20 08:16:30.793477\n",
      "resetting env. episode 3113, reward total was -18.0. running mean: -18.82566678948506, timestamp: 2022-08-20 08:16:35.039050\n",
      "resetting env. episode 3114, reward total was -18.0. running mean: -18.817410121590207, timestamp: 2022-08-20 08:16:38.823099\n",
      "resetting env. episode 3115, reward total was -20.0. running mean: -18.829236020374303, timestamp: 2022-08-20 08:16:41.524131\n",
      "resetting env. episode 3116, reward total was -17.0. running mean: -18.81094366017056, timestamp: 2022-08-20 08:16:43.929159\n",
      "resetting env. episode 3117, reward total was -18.0. running mean: -18.802834223568855, timestamp: 2022-08-20 08:16:47.830209\n",
      "resetting env. episode 3118, reward total was -20.0. running mean: -18.814805881333164, timestamp: 2022-08-20 08:16:49.727228\n",
      "resetting env. episode 3119, reward total was -19.0. running mean: -18.816657822519833, timestamp: 2022-08-20 08:16:52.456261\n",
      "resetting env. episode 3120, reward total was -19.0. running mean: -18.818491244294634, timestamp: 2022-08-20 08:16:56.030307\n",
      "resetting env. episode 3121, reward total was -18.0. running mean: -18.810306331851688, timestamp: 2022-08-20 08:16:59.229344\n",
      "resetting env. episode 3122, reward total was -17.0. running mean: -18.79220326853317, timestamp: 2022-08-20 08:17:01.834377\n",
      "resetting env. episode 3123, reward total was -19.0. running mean: -18.79428123584784, timestamp: 2022-08-20 08:17:05.821422\n",
      "resetting env. episode 3124, reward total was -20.0. running mean: -18.80633842348936, timestamp: 2022-08-20 08:17:08.647459\n",
      "resetting env. episode 3125, reward total was -18.0. running mean: -18.798275039254467, timestamp: 2022-08-20 08:17:11.526494\n",
      "resetting env. episode 3126, reward total was -19.0. running mean: -18.80029228886192, timestamp: 2022-08-20 08:17:13.644519\n",
      "resetting env. episode 3127, reward total was -20.0. running mean: -18.812289365973303, timestamp: 2022-08-20 08:17:16.051548\n",
      "resetting env. episode 3128, reward total was -17.0. running mean: -18.79416647231357, timestamp: 2022-08-20 08:17:19.201587\n",
      "resetting env. episode 3129, reward total was -20.0. running mean: -18.806224807590432, timestamp: 2022-08-20 08:17:20.838126\n",
      "resetting env. episode 3130, reward total was -15.0. running mean: -18.768162559514526, timestamp: 2022-08-20 08:17:23.460158\n",
      "resetting env. episode 3131, reward total was -18.0. running mean: -18.76048093391938, timestamp: 2022-08-20 08:17:26.019187\n",
      "resetting env. episode 3132, reward total was -20.0. running mean: -18.772876124580183, timestamp: 2022-08-20 08:17:28.222214\n",
      "resetting env. episode 3133, reward total was -19.0. running mean: -18.775147363334383, timestamp: 2022-08-20 08:17:30.146242\n",
      "resetting env. episode 3134, reward total was -13.0. running mean: -18.717395889701038, timestamp: 2022-08-20 08:17:32.774794\n",
      "resetting env. episode 3135, reward total was -19.0. running mean: -18.72022193080403, timestamp: 2022-08-20 08:17:35.088821\n",
      "resetting env. episode 3136, reward total was -19.0. running mean: -18.72301971149599, timestamp: 2022-08-20 08:17:37.158848\n",
      "resetting env. episode 3137, reward total was -19.0. running mean: -18.72578951438103, timestamp: 2022-08-20 08:17:38.858879\n",
      "resetting env. episode 3138, reward total was -19.0. running mean: -18.72853161923722, timestamp: 2022-08-20 08:17:40.815890\n",
      "resetting env. episode 3139, reward total was -18.0. running mean: -18.721246303044847, timestamp: 2022-08-20 08:17:43.551926\n",
      "resetting env. episode 3140, reward total was -20.0. running mean: -18.734033840014398, timestamp: 2022-08-20 08:17:45.145942\n",
      "resetting env. episode 3141, reward total was -18.0. running mean: -18.726693501614253, timestamp: 2022-08-20 08:17:47.104966\n",
      "resetting env. episode 3142, reward total was -18.0. running mean: -18.71942656659811, timestamp: 2022-08-20 08:17:49.984004\n",
      "resetting env. episode 3143, reward total was -18.0. running mean: -18.71223230093213, timestamp: 2022-08-20 08:17:52.344034\n",
      "resetting env. episode 3144, reward total was -18.0. running mean: -18.705109977922806, timestamp: 2022-08-20 08:17:54.810062\n",
      "resetting env. episode 3145, reward total was -17.0. running mean: -18.68805887814358, timestamp: 2022-08-20 08:17:56.918084\n",
      "resetting env. episode 3146, reward total was -21.0. running mean: -18.711178289362145, timestamp: 2022-08-20 08:17:59.130112\n",
      "resetting env. episode 3147, reward total was -18.0. running mean: -18.704066506468525, timestamp: 2022-08-20 08:18:01.591142\n",
      "resetting env. episode 3148, reward total was -21.0. running mean: -18.72702584140384, timestamp: 2022-08-20 08:18:03.454165\n",
      "resetting env. episode 3149, reward total was -15.0. running mean: -18.6897555829898, timestamp: 2022-08-20 08:18:05.718193\n",
      "resetting env. episode 3150, reward total was -15.0. running mean: -18.6528580271599, timestamp: 2022-08-20 08:18:09.062231\n",
      "resetting env. episode 3151, reward total was -19.0. running mean: -18.656329446888304, timestamp: 2022-08-20 08:18:10.909256\n",
      "resetting env. episode 3152, reward total was -21.0. running mean: -18.679766152419422, timestamp: 2022-08-20 08:18:12.564275\n",
      "resetting env. episode 3153, reward total was -17.0. running mean: -18.662968490895228, timestamp: 2022-08-20 08:18:14.584299\n",
      "resetting env. episode 3154, reward total was -16.0. running mean: -18.636338805986277, timestamp: 2022-08-20 08:18:16.757330\n",
      "resetting env. episode 3155, reward total was -21.0. running mean: -18.659975417926415, timestamp: 2022-08-20 08:18:18.941349\n",
      "resetting env. episode 3156, reward total was -14.0. running mean: -18.61337566374715, timestamp: 2022-08-20 08:18:22.053387\n",
      "resetting env. episode 3157, reward total was -21.0. running mean: -18.63724190710968, timestamp: 2022-08-20 08:18:24.881426\n",
      "resetting env. episode 3158, reward total was -18.0. running mean: -18.63086948803858, timestamp: 2022-08-20 08:18:26.993453\n",
      "resetting env. episode 3159, reward total was -18.0. running mean: -18.624560793158196, timestamp: 2022-08-20 08:18:29.542479\n",
      "resetting env. episode 3160, reward total was -18.0. running mean: -18.618315185226614, timestamp: 2022-08-20 08:18:32.387512\n",
      "resetting env. episode 3161, reward total was -15.0. running mean: -18.582132033374346, timestamp: 2022-08-20 08:18:35.562549\n",
      "resetting env. episode 3162, reward total was -21.0. running mean: -18.606310713040603, timestamp: 2022-08-20 08:18:37.909581\n",
      "resetting env. episode 3163, reward total was -18.0. running mean: -18.600247605910198, timestamp: 2022-08-20 08:18:40.446612\n",
      "resetting env. episode 3164, reward total was -20.0. running mean: -18.614245129851096, timestamp: 2022-08-20 08:18:42.360633\n",
      "resetting env. episode 3165, reward total was -15.0. running mean: -18.578102678552582, timestamp: 2022-08-20 08:18:45.010666\n",
      "resetting env. episode 3166, reward total was -20.0. running mean: -18.592321651767055, timestamp: 2022-08-20 08:18:47.342691\n",
      "resetting env. episode 3167, reward total was -16.0. running mean: -18.566398435249383, timestamp: 2022-08-20 08:18:50.098724\n",
      "resetting env. episode 3168, reward total was -16.0. running mean: -18.54073445089689, timestamp: 2022-08-20 08:18:52.434756\n",
      "resetting env. episode 3169, reward total was -15.0. running mean: -18.505327106387917, timestamp: 2022-08-20 08:18:54.752779\n",
      "resetting env. episode 3170, reward total was -19.0. running mean: -18.51027383532404, timestamp: 2022-08-20 08:18:57.065808\n",
      "resetting env. episode 3171, reward total was -20.0. running mean: -18.525171096970798, timestamp: 2022-08-20 08:18:58.994831\n",
      "resetting env. episode 3172, reward total was -20.0. running mean: -18.53991938600109, timestamp: 2022-08-20 08:19:00.756855\n",
      "resetting env. episode 3173, reward total was -21.0. running mean: -18.564520192141078, timestamp: 2022-08-20 08:19:02.022872\n",
      "resetting env. episode 3174, reward total was -15.0. running mean: -18.528874990219666, timestamp: 2022-08-20 08:19:04.710900\n",
      "resetting env. episode 3175, reward total was -16.0. running mean: -18.50358624031747, timestamp: 2022-08-20 08:19:07.217928\n",
      "resetting env. episode 3176, reward total was -19.0. running mean: -18.508550377914297, timestamp: 2022-08-20 08:19:09.154958\n",
      "resetting env. episode 3177, reward total was -19.0. running mean: -18.513464874135156, timestamp: 2022-08-20 08:19:11.098976\n",
      "resetting env. episode 3178, reward total was -19.0. running mean: -18.518330225393807, timestamp: 2022-08-20 08:19:13.553007\n",
      "resetting env. episode 3179, reward total was -18.0. running mean: -18.513146923139868, timestamp: 2022-08-20 08:19:15.530029\n",
      "resetting env. episode 3180, reward total was -16.0. running mean: -18.488015453908467, timestamp: 2022-08-20 08:19:18.393067\n",
      "resetting env. episode 3181, reward total was -20.0. running mean: -18.503135299369383, timestamp: 2022-08-20 08:19:20.420088\n",
      "resetting env. episode 3182, reward total was -17.0. running mean: -18.48810394637569, timestamp: 2022-08-20 08:19:23.441133\n",
      "resetting env. episode 3183, reward total was -18.0. running mean: -18.483222906911934, timestamp: 2022-08-20 08:19:25.158146\n",
      "resetting env. episode 3184, reward total was -18.0. running mean: -18.478390677842814, timestamp: 2022-08-20 08:19:27.259171\n",
      "resetting env. episode 3185, reward total was -20.0. running mean: -18.493606771064385, timestamp: 2022-08-20 08:19:29.098193\n",
      "resetting env. episode 3186, reward total was -18.0. running mean: -18.48867070335374, timestamp: 2022-08-20 08:19:31.295226\n",
      "resetting env. episode 3187, reward total was -19.0. running mean: -18.493783996320204, timestamp: 2022-08-20 08:19:34.200833\n",
      "resetting env. episode 3188, reward total was -19.0. running mean: -18.498846156357004, timestamp: 2022-08-20 08:19:36.334857\n",
      "resetting env. episode 3189, reward total was -17.0. running mean: -18.483857694793436, timestamp: 2022-08-20 08:19:38.651885\n",
      "resetting env. episode 3190, reward total was -21.0. running mean: -18.5090191178455, timestamp: 2022-08-20 08:19:40.172905\n",
      "resetting env. episode 3191, reward total was -15.0. running mean: -18.473928926667043, timestamp: 2022-08-20 08:19:42.845936\n",
      "resetting env. episode 3192, reward total was -21.0. running mean: -18.499189637400374, timestamp: 2022-08-20 08:19:44.831962\n",
      "resetting env. episode 3193, reward total was -21.0. running mean: -18.52419774102637, timestamp: 2022-08-20 08:19:46.660984\n",
      "resetting env. episode 3194, reward total was -20.0. running mean: -18.538955763616105, timestamp: 2022-08-20 08:19:49.543016\n",
      "resetting env. episode 3195, reward total was -19.0. running mean: -18.543566205979946, timestamp: 2022-08-20 08:19:51.626045\n",
      "resetting env. episode 3196, reward total was -20.0. running mean: -18.558130543920146, timestamp: 2022-08-20 08:19:54.097073\n",
      "resetting env. episode 3197, reward total was -20.0. running mean: -18.572549238480946, timestamp: 2022-08-20 08:19:55.656096\n",
      "resetting env. episode 3198, reward total was -18.0. running mean: -18.566823746096137, timestamp: 2022-08-20 08:19:58.046126\n",
      "resetting env. episode 3199, reward total was -21.0. running mean: -18.591155508635175, timestamp: 2022-08-20 08:20:00.642155\n",
      "resetting env. episode 3200, reward total was -18.0. running mean: -18.585243953548822, timestamp: 2022-08-20 08:20:03.104180\n",
      "resetting env. episode 3201, reward total was -17.0. running mean: -18.569391514013336, timestamp: 2022-08-20 08:20:05.298210\n",
      "resetting env. episode 3202, reward total was -19.0. running mean: -18.573697598873203, timestamp: 2022-08-20 08:20:07.687237\n",
      "resetting env. episode 3203, reward total was -21.0. running mean: -18.59796062288447, timestamp: 2022-08-20 08:20:10.159267\n",
      "resetting env. episode 3204, reward total was -21.0. running mean: -18.621981016655628, timestamp: 2022-08-20 08:20:12.055299\n",
      "resetting env. episode 3205, reward total was -21.0. running mean: -18.645761206489073, timestamp: 2022-08-20 08:20:14.538321\n",
      "resetting env. episode 3206, reward total was -19.0. running mean: -18.649303594424183, timestamp: 2022-08-20 08:20:16.805353\n",
      "resetting env. episode 3207, reward total was -19.0. running mean: -18.652810558479942, timestamp: 2022-08-20 08:20:19.118378\n",
      "resetting env. episode 3208, reward total was -20.0. running mean: -18.666282452895143, timestamp: 2022-08-20 08:20:21.493406\n",
      "resetting env. episode 3209, reward total was -19.0. running mean: -18.669619628366192, timestamp: 2022-08-20 08:20:23.736955\n",
      "resetting env. episode 3210, reward total was -21.0. running mean: -18.69292343208253, timestamp: 2022-08-20 08:20:25.632979\n",
      "resetting env. episode 3211, reward total was -20.0. running mean: -18.705994197761704, timestamp: 2022-08-20 08:20:27.283997\n",
      "resetting env. episode 3212, reward total was -19.0. running mean: -18.70893425578409, timestamp: 2022-08-20 08:20:29.746030\n",
      "resetting env. episode 3213, reward total was -21.0. running mean: -18.73184491322625, timestamp: 2022-08-20 08:20:31.899059\n",
      "resetting env. episode 3214, reward total was -21.0. running mean: -18.75452646409399, timestamp: 2022-08-20 08:20:33.848076\n",
      "resetting env. episode 3215, reward total was -18.0. running mean: -18.74698119945305, timestamp: 2022-08-20 08:20:36.095105\n",
      "resetting env. episode 3216, reward total was -16.0. running mean: -18.719511387458518, timestamp: 2022-08-20 08:20:38.289130\n",
      "resetting env. episode 3217, reward total was -18.0. running mean: -18.71231627358393, timestamp: 2022-08-20 08:20:40.886163\n",
      "resetting env. episode 3218, reward total was -16.0. running mean: -18.68519311084809, timestamp: 2022-08-20 08:20:43.885199\n",
      "resetting env. episode 3219, reward total was -17.0. running mean: -18.66834117973961, timestamp: 2022-08-20 08:20:46.210232\n",
      "resetting env. episode 3220, reward total was -17.0. running mean: -18.651657767942215, timestamp: 2022-08-20 08:20:48.611780\n",
      "resetting env. episode 3221, reward total was -19.0. running mean: -18.655141190262793, timestamp: 2022-08-20 08:20:50.695804\n",
      "resetting env. episode 3222, reward total was -20.0. running mean: -18.668589778360165, timestamp: 2022-08-20 08:20:53.008829\n",
      "resetting env. episode 3223, reward total was -19.0. running mean: -18.671903880576565, timestamp: 2022-08-20 08:20:55.144858\n",
      "resetting env. episode 3224, reward total was -17.0. running mean: -18.6551848417708, timestamp: 2022-08-20 08:20:56.841882\n",
      "resetting env. episode 3225, reward total was -19.0. running mean: -18.658632993353095, timestamp: 2022-08-20 08:20:59.174906\n",
      "resetting env. episode 3226, reward total was -19.0. running mean: -18.662046663419567, timestamp: 2022-08-20 08:21:01.238932\n",
      "resetting env. episode 3227, reward total was -19.0. running mean: -18.665426196785372, timestamp: 2022-08-20 08:21:03.645962\n",
      "resetting env. episode 3228, reward total was -18.0. running mean: -18.65877193481752, timestamp: 2022-08-20 08:21:05.706986\n",
      "resetting env. episode 3229, reward total was -18.0. running mean: -18.652184215469344, timestamp: 2022-08-20 08:21:08.254015\n",
      "resetting env. episode 3230, reward total was -20.0. running mean: -18.66566237331465, timestamp: 2022-08-20 08:21:10.789045\n",
      "resetting env. episode 3231, reward total was -20.0. running mean: -18.679005749581503, timestamp: 2022-08-20 08:21:12.916073\n",
      "resetting env. episode 3232, reward total was -20.0. running mean: -18.692215692085686, timestamp: 2022-08-20 08:21:14.904096\n",
      "resetting env. episode 3233, reward total was -17.0. running mean: -18.67529353516483, timestamp: 2022-08-20 08:21:17.129124\n",
      "resetting env. episode 3234, reward total was -19.0. running mean: -18.678540599813182, timestamp: 2022-08-20 08:21:19.444151\n",
      "resetting env. episode 3235, reward total was -16.0. running mean: -18.65175519381505, timestamp: 2022-08-20 08:21:22.370187\n",
      "resetting env. episode 3236, reward total was -19.0. running mean: -18.655237641876898, timestamp: 2022-08-20 08:21:24.604216\n",
      "resetting env. episode 3237, reward total was -19.0. running mean: -18.65868526545813, timestamp: 2022-08-20 08:21:26.920247\n",
      "resetting env. episode 3238, reward total was -17.0. running mean: -18.64209841280355, timestamp: 2022-08-20 08:21:29.964285\n",
      "resetting env. episode 3239, reward total was -17.0. running mean: -18.625677428675516, timestamp: 2022-08-20 08:21:31.885303\n",
      "resetting env. episode 3240, reward total was -20.0. running mean: -18.63942065438876, timestamp: 2022-08-20 08:21:33.609327\n",
      "resetting env. episode 3241, reward total was -17.0. running mean: -18.623026447844875, timestamp: 2022-08-20 08:21:35.626353\n",
      "resetting env. episode 3242, reward total was -21.0. running mean: -18.646796183366426, timestamp: 2022-08-20 08:21:37.338370\n",
      "resetting env. episode 3243, reward total was -20.0. running mean: -18.66032822153276, timestamp: 2022-08-20 08:21:39.105396\n",
      "resetting env. episode 3244, reward total was -18.0. running mean: -18.653724939317435, timestamp: 2022-08-20 08:21:41.435425\n",
      "resetting env. episode 3245, reward total was -17.0. running mean: -18.63718768992426, timestamp: 2022-08-20 08:21:43.276968\n",
      "resetting env. episode 3246, reward total was -16.0. running mean: -18.610815813025017, timestamp: 2022-08-20 08:21:45.243992\n",
      "resetting env. episode 3247, reward total was -19.0. running mean: -18.61470765489477, timestamp: 2022-08-20 08:21:47.219016\n",
      "resetting env. episode 3248, reward total was -17.0. running mean: -18.598560578345822, timestamp: 2022-08-20 08:21:49.746048\n",
      "resetting env. episode 3249, reward total was -18.0. running mean: -18.592574972562364, timestamp: 2022-08-20 08:21:52.201077\n",
      "resetting env. episode 3250, reward total was -20.0. running mean: -18.60664922283674, timestamp: 2022-08-20 08:21:54.240101\n",
      "resetting env. episode 3251, reward total was -14.0. running mean: -18.560582730608374, timestamp: 2022-08-20 08:21:57.020139\n",
      "resetting env. episode 3252, reward total was -20.0. running mean: -18.57497690330229, timestamp: 2022-08-20 08:21:59.351165\n",
      "resetting env. episode 3253, reward total was -16.0. running mean: -18.549227134269266, timestamp: 2022-08-20 08:22:01.962201\n",
      "resetting env. episode 3254, reward total was -14.0. running mean: -18.503734862926574, timestamp: 2022-08-20 08:22:04.910234\n",
      "resetting env. episode 3255, reward total was -17.0. running mean: -18.48869751429731, timestamp: 2022-08-20 08:22:07.091261\n",
      "resetting env. episode 3256, reward total was -17.0. running mean: -18.47381053915434, timestamp: 2022-08-20 08:22:09.735292\n",
      "resetting env. episode 3257, reward total was -18.0. running mean: -18.469072433762797, timestamp: 2022-08-20 08:22:11.936323\n",
      "resetting env. episode 3258, reward total was -20.0. running mean: -18.48438170942517, timestamp: 2022-08-20 08:22:14.224346\n",
      "resetting env. episode 3259, reward total was -19.0. running mean: -18.48953789233092, timestamp: 2022-08-20 08:22:16.503373\n",
      "resetting env. episode 3260, reward total was -18.0. running mean: -18.48464251340761, timestamp: 2022-08-20 08:22:18.684402\n",
      "resetting env. episode 3261, reward total was -19.0. running mean: -18.489796088273536, timestamp: 2022-08-20 08:22:20.647424\n",
      "resetting env. episode 3262, reward total was -15.0. running mean: -18.4548981273908, timestamp: 2022-08-20 08:22:22.970454\n",
      "resetting env. episode 3263, reward total was -18.0. running mean: -18.45034914611689, timestamp: 2022-08-20 08:22:25.002477\n",
      "resetting env. episode 3264, reward total was -15.0. running mean: -18.41584565465572, timestamp: 2022-08-20 08:22:27.430510\n",
      "resetting env. episode 3265, reward total was -20.0. running mean: -18.43168719810916, timestamp: 2022-08-20 08:22:29.979542\n",
      "resetting env. episode 3266, reward total was -18.0. running mean: -18.427370326128067, timestamp: 2022-08-20 08:22:31.848565\n",
      "resetting env. episode 3267, reward total was -17.0. running mean: -18.41309662286679, timestamp: 2022-08-20 08:22:33.691589\n",
      "resetting env. episode 3268, reward total was -18.0. running mean: -18.40896565663812, timestamp: 2022-08-20 08:22:35.865657\n",
      "resetting env. episode 3269, reward total was -19.0. running mean: -18.41487600007174, timestamp: 2022-08-20 08:22:37.765686\n",
      "resetting env. episode 3270, reward total was -17.0. running mean: -18.400727240071024, timestamp: 2022-08-20 08:22:39.697706\n",
      "resetting env. episode 3271, reward total was -17.0. running mean: -18.386719967670317, timestamp: 2022-08-20 08:22:41.916732\n",
      "resetting env. episode 3272, reward total was -20.0. running mean: -18.40285276799361, timestamp: 2022-08-20 08:22:43.885810\n",
      "resetting env. episode 3273, reward total was -19.0. running mean: -18.408824240313677, timestamp: 2022-08-20 08:22:46.135835\n",
      "resetting env. episode 3274, reward total was -18.0. running mean: -18.40473599791054, timestamp: 2022-08-20 08:22:49.090870\n",
      "resetting env. episode 3275, reward total was -16.0. running mean: -18.380688637931435, timestamp: 2022-08-20 08:22:52.069910\n",
      "resetting env. episode 3276, reward total was -16.0. running mean: -18.35688175155212, timestamp: 2022-08-20 08:22:54.449939\n",
      "resetting env. episode 3277, reward total was -20.0. running mean: -18.373312934036598, timestamp: 2022-08-20 08:22:56.166958\n",
      "resetting env. episode 3278, reward total was -20.0. running mean: -18.38957980469623, timestamp: 2022-08-20 08:22:58.408989\n",
      "resetting env. episode 3279, reward total was -19.0. running mean: -18.39568400664927, timestamp: 2022-08-20 08:23:00.617014\n",
      "resetting env. episode 3280, reward total was -18.0. running mean: -18.391727166582776, timestamp: 2022-08-20 08:23:03.574049\n",
      "resetting env. episode 3281, reward total was -18.0. running mean: -18.38780989491695, timestamp: 2022-08-20 08:23:06.512087\n",
      "resetting env. episode 3282, reward total was -17.0. running mean: -18.37393179596778, timestamp: 2022-08-20 08:23:09.824127\n",
      "resetting env. episode 3283, reward total was -21.0. running mean: -18.400192478008105, timestamp: 2022-08-20 08:23:11.667150\n",
      "resetting env. episode 3284, reward total was -19.0. running mean: -18.406190553228026, timestamp: 2022-08-20 08:23:13.908176\n",
      "resetting env. episode 3285, reward total was -20.0. running mean: -18.422128647695743, timestamp: 2022-08-20 08:23:16.827211\n",
      "resetting env. episode 3286, reward total was -18.0. running mean: -18.417907361218784, timestamp: 2022-08-20 08:23:19.916254\n",
      "resetting env. episode 3287, reward total was -16.0. running mean: -18.393728287606596, timestamp: 2022-08-20 08:23:22.678285\n",
      "resetting env. episode 3288, reward total was -17.0. running mean: -18.37979100473053, timestamp: 2022-08-20 08:23:25.039314\n",
      "resetting env. episode 3289, reward total was -17.0. running mean: -18.365993094683226, timestamp: 2022-08-20 08:23:28.014353\n",
      "resetting env. episode 3290, reward total was -19.0. running mean: -18.372333163736396, timestamp: 2022-08-20 08:23:30.675384\n",
      "resetting env. episode 3291, reward total was -18.0. running mean: -18.368609832099033, timestamp: 2022-08-20 08:23:32.471407\n",
      "resetting env. episode 3292, reward total was -19.0. running mean: -18.374923733778044, timestamp: 2022-08-20 08:23:34.328428\n",
      "resetting env. episode 3293, reward total was -18.0. running mean: -18.37117449644026, timestamp: 2022-08-20 08:23:36.608457\n",
      "resetting env. episode 3294, reward total was -17.0. running mean: -18.35746275147586, timestamp: 2022-08-20 08:23:38.780488\n",
      "resetting env. episode 3295, reward total was -19.0. running mean: -18.363888123961104, timestamp: 2022-08-20 08:23:41.224516\n",
      "resetting env. episode 3296, reward total was -17.0. running mean: -18.350249242721496, timestamp: 2022-08-20 08:23:43.597543\n",
      "resetting env. episode 3297, reward total was -20.0. running mean: -18.36674675029428, timestamp: 2022-08-20 08:23:46.011571\n",
      "resetting env. episode 3298, reward total was -19.0. running mean: -18.373079282791338, timestamp: 2022-08-20 08:23:48.160600\n",
      "resetting env. episode 3299, reward total was -21.0. running mean: -18.399348489963426, timestamp: 2022-08-20 08:23:50.685630\n",
      "resetting env. episode 3300, reward total was -21.0. running mean: -18.425355005063793, timestamp: 2022-08-20 08:23:52.856655\n",
      "resetting env. episode 3301, reward total was -19.0. running mean: -18.431101455013156, timestamp: 2022-08-20 08:23:55.178687\n",
      "resetting env. episode 3302, reward total was -21.0. running mean: -18.456790440463024, timestamp: 2022-08-20 08:23:57.002710\n",
      "resetting env. episode 3303, reward total was -19.0. running mean: -18.462222536058395, timestamp: 2022-08-20 08:23:58.610728\n",
      "resetting env. episode 3304, reward total was -18.0. running mean: -18.45760031069781, timestamp: 2022-08-20 08:24:01.031761\n",
      "resetting env. episode 3305, reward total was -20.0. running mean: -18.47302430759083, timestamp: 2022-08-20 08:24:02.466777\n",
      "resetting env. episode 3306, reward total was -20.0. running mean: -18.48829406451492, timestamp: 2022-08-20 08:24:04.177799\n",
      "resetting env. episode 3307, reward total was -19.0. running mean: -18.493411123869773, timestamp: 2022-08-20 08:24:06.772829\n",
      "resetting env. episode 3308, reward total was -15.0. running mean: -18.458477012631075, timestamp: 2022-08-20 08:24:09.321860\n",
      "resetting env. episode 3309, reward total was -15.0. running mean: -18.423892242504763, timestamp: 2022-08-20 08:24:11.708887\n",
      "resetting env. episode 3310, reward total was -17.0. running mean: -18.409653320079716, timestamp: 2022-08-20 08:24:14.218921\n",
      "resetting env. episode 3311, reward total was -19.0. running mean: -18.41555678687892, timestamp: 2022-08-20 08:24:17.040958\n",
      "resetting env. episode 3312, reward total was -16.0. running mean: -18.39140121901013, timestamp: 2022-08-20 08:24:19.414983\n",
      "resetting env. episode 3313, reward total was -21.0. running mean: -18.41748720682003, timestamp: 2022-08-20 08:24:21.141007\n",
      "resetting env. episode 3314, reward total was -17.0. running mean: -18.40331233475183, timestamp: 2022-08-20 08:24:23.814038\n",
      "resetting env. episode 3315, reward total was -21.0. running mean: -18.429279211404314, timestamp: 2022-08-20 08:24:25.705060\n",
      "resetting env. episode 3316, reward total was -17.0. running mean: -18.414986419290273, timestamp: 2022-08-20 08:24:28.117093\n",
      "resetting env. episode 3317, reward total was -17.0. running mean: -18.40083655509737, timestamp: 2022-08-20 08:24:30.530121\n",
      "resetting env. episode 3318, reward total was -16.0. running mean: -18.376828189546398, timestamp: 2022-08-20 08:24:32.492146\n",
      "resetting env. episode 3319, reward total was -20.0. running mean: -18.393059907650933, timestamp: 2022-08-20 08:24:34.496173\n",
      "resetting env. episode 3320, reward total was -20.0. running mean: -18.40912930857442, timestamp: 2022-08-20 08:24:36.259189\n",
      "resetting env. episode 3321, reward total was -14.0. running mean: -18.36503801548868, timestamp: 2022-08-20 08:24:38.986224\n",
      "resetting env. episode 3322, reward total was -20.0. running mean: -18.38138763533379, timestamp: 2022-08-20 08:24:41.432254\n",
      "resetting env. episode 3323, reward total was -18.0. running mean: -18.377573758980454, timestamp: 2022-08-20 08:24:43.238278\n",
      "resetting env. episode 3324, reward total was -18.0. running mean: -18.373798021390648, timestamp: 2022-08-20 08:24:45.421304\n",
      "resetting env. episode 3325, reward total was -21.0. running mean: -18.400060041176744, timestamp: 2022-08-20 08:24:47.494331\n",
      "resetting env. episode 3326, reward total was -19.0. running mean: -18.406059440764977, timestamp: 2022-08-20 08:24:49.859358\n",
      "resetting env. episode 3327, reward total was -21.0. running mean: -18.431998846357327, timestamp: 2022-08-20 08:24:51.966382\n",
      "resetting env. episode 3328, reward total was -14.0. running mean: -18.387678857893754, timestamp: 2022-08-20 08:24:54.766419\n",
      "resetting env. episode 3329, reward total was -14.0. running mean: -18.343802069314815, timestamp: 2022-08-20 08:24:57.366448\n",
      "resetting env. episode 3330, reward total was -20.0. running mean: -18.360364048621665, timestamp: 2022-08-20 08:24:59.345477\n",
      "resetting env. episode 3331, reward total was -15.0. running mean: -18.326760408135446, timestamp: 2022-08-20 08:25:02.109507\n",
      "resetting env. episode 3332, reward total was -20.0. running mean: -18.34349280405409, timestamp: 2022-08-20 08:25:04.048535\n",
      "resetting env. episode 3333, reward total was -15.0. running mean: -18.31005787601355, timestamp: 2022-08-20 08:25:07.380573\n",
      "resetting env. episode 3334, reward total was -17.0. running mean: -18.296957297253414, timestamp: 2022-08-20 08:25:10.124612\n",
      "resetting env. episode 3335, reward total was -19.0. running mean: -18.30398772428088, timestamp: 2022-08-20 08:25:12.410638\n",
      "resetting env. episode 3336, reward total was -19.0. running mean: -18.310947847038072, timestamp: 2022-08-20 08:25:14.564662\n",
      "resetting env. episode 3337, reward total was -19.0. running mean: -18.317838368567692, timestamp: 2022-08-20 08:25:16.479687\n",
      "resetting env. episode 3338, reward total was -18.0. running mean: -18.314659984882013, timestamp: 2022-08-20 08:25:18.525709\n",
      "resetting env. episode 3339, reward total was -18.0. running mean: -18.31151338503319, timestamp: 2022-08-20 08:25:20.879737\n",
      "resetting env. episode 3340, reward total was -19.0. running mean: -18.31839825118286, timestamp: 2022-08-20 08:25:23.135765\n",
      "resetting env. episode 3341, reward total was -17.0. running mean: -18.305214268671033, timestamp: 2022-08-20 08:25:25.977326\n",
      "resetting env. episode 3342, reward total was -21.0. running mean: -18.332162125984322, timestamp: 2022-08-20 08:25:27.901349\n",
      "resetting env. episode 3343, reward total was -17.0. running mean: -18.31884050472448, timestamp: 2022-08-20 08:25:30.247379\n",
      "resetting env. episode 3344, reward total was -18.0. running mean: -18.315652099677237, timestamp: 2022-08-20 08:25:32.807413\n",
      "resetting env. episode 3345, reward total was -14.0. running mean: -18.272495578680466, timestamp: 2022-08-20 08:25:36.148451\n",
      "resetting env. episode 3346, reward total was -16.0. running mean: -18.24977062289366, timestamp: 2022-08-20 08:25:38.455492\n",
      "resetting env. episode 3347, reward total was -21.0. running mean: -18.277272916664725, timestamp: 2022-08-20 08:25:40.722508\n",
      "resetting env. episode 3348, reward total was -21.0. running mean: -18.30450018749808, timestamp: 2022-08-20 08:25:43.048538\n",
      "resetting env. episode 3349, reward total was -15.0. running mean: -18.271455185623097, timestamp: 2022-08-20 08:25:46.211575\n",
      "resetting env. episode 3350, reward total was -16.0. running mean: -18.248740633766865, timestamp: 2022-08-20 08:25:48.499605\n",
      "resetting env. episode 3351, reward total was -18.0. running mean: -18.246253227429197, timestamp: 2022-08-20 08:25:50.450628\n",
      "resetting env. episode 3352, reward total was -17.0. running mean: -18.233790695154905, timestamp: 2022-08-20 08:25:53.060661\n",
      "resetting env. episode 3353, reward total was -18.0. running mean: -18.231452788203356, timestamp: 2022-08-20 08:25:55.397689\n",
      "resetting env. episode 3354, reward total was -17.0. running mean: -18.219138260321323, timestamp: 2022-08-20 08:25:57.492716\n",
      "resetting env. episode 3355, reward total was -19.0. running mean: -18.22694687771811, timestamp: 2022-08-20 08:25:59.516742\n",
      "resetting env. episode 3356, reward total was -20.0. running mean: -18.244677408940927, timestamp: 2022-08-20 08:26:02.040771\n",
      "resetting env. episode 3357, reward total was -17.0. running mean: -18.23223063485152, timestamp: 2022-08-20 08:26:04.666803\n",
      "resetting env. episode 3358, reward total was -20.0. running mean: -18.249908328503004, timestamp: 2022-08-20 08:26:06.591827\n",
      "resetting env. episode 3359, reward total was -19.0. running mean: -18.257409245217975, timestamp: 2022-08-20 08:26:08.924860\n",
      "resetting env. episode 3360, reward total was -17.0. running mean: -18.2448351527658, timestamp: 2022-08-20 08:26:11.102881\n",
      "resetting env. episode 3361, reward total was -17.0. running mean: -18.232386801238142, timestamp: 2022-08-20 08:26:13.658916\n",
      "resetting env. episode 3362, reward total was -14.0. running mean: -18.19006293322576, timestamp: 2022-08-20 08:26:16.628476\n",
      "resetting env. episode 3363, reward total was -20.0. running mean: -18.208162303893502, timestamp: 2022-08-20 08:26:18.726506\n",
      "resetting env. episode 3364, reward total was -17.0. running mean: -18.196080680854568, timestamp: 2022-08-20 08:26:20.875527\n",
      "resetting env. episode 3365, reward total was -20.0. running mean: -18.21411987404602, timestamp: 2022-08-20 08:26:22.505549\n",
      "resetting env. episode 3366, reward total was -16.0. running mean: -18.19197867530556, timestamp: 2022-08-20 08:26:25.036579\n",
      "resetting env. episode 3367, reward total was -19.0. running mean: -18.200058888552505, timestamp: 2022-08-20 08:26:27.161605\n",
      "resetting env. episode 3368, reward total was -13.0. running mean: -18.148058299666978, timestamp: 2022-08-20 08:26:30.285645\n",
      "resetting env. episode 3369, reward total was -20.0. running mean: -18.166577716670307, timestamp: 2022-08-20 08:26:32.769676\n",
      "resetting env. episode 3370, reward total was -18.0. running mean: -18.164911939503604, timestamp: 2022-08-20 08:26:36.288718\n",
      "resetting env. episode 3371, reward total was -19.0. running mean: -18.17326282010857, timestamp: 2022-08-20 08:26:38.127742\n",
      "resetting env. episode 3372, reward total was -19.0. running mean: -18.181530191907484, timestamp: 2022-08-20 08:26:40.229767\n",
      "resetting env. episode 3373, reward total was -18.0. running mean: -18.179714889988407, timestamp: 2022-08-20 08:26:42.287796\n",
      "resetting env. episode 3374, reward total was -18.0. running mean: -18.17791774108852, timestamp: 2022-08-20 08:26:44.522823\n",
      "resetting env. episode 3375, reward total was -19.0. running mean: -18.186138563677638, timestamp: 2022-08-20 08:26:46.634845\n",
      "resetting env. episode 3376, reward total was -9.0. running mean: -18.094277178040862, timestamp: 2022-08-20 08:26:49.971885\n",
      "resetting env. episode 3377, reward total was -18.0. running mean: -18.093334406260453, timestamp: 2022-08-20 08:26:52.594919\n",
      "resetting env. episode 3378, reward total was -17.0. running mean: -18.08240106219785, timestamp: 2022-08-20 08:26:55.001947\n",
      "resetting env. episode 3379, reward total was -20.0. running mean: -18.10157705157587, timestamp: 2022-08-20 08:26:57.043973\n",
      "resetting env. episode 3380, reward total was -20.0. running mean: -18.12056128106011, timestamp: 2022-08-20 08:26:59.607006\n",
      "resetting env. episode 3381, reward total was -21.0. running mean: -18.14935566824951, timestamp: 2022-08-20 08:27:01.611030\n",
      "resetting env. episode 3382, reward total was -17.0. running mean: -18.137862111567017, timestamp: 2022-08-20 08:27:04.144067\n",
      "resetting env. episode 3383, reward total was -20.0. running mean: -18.156483490451347, timestamp: 2022-08-20 08:27:05.997086\n",
      "resetting env. episode 3384, reward total was -20.0. running mean: -18.174918655546833, timestamp: 2022-08-20 08:27:08.041109\n",
      "resetting env. episode 3385, reward total was -18.0. running mean: -18.173169468991365, timestamp: 2022-08-20 08:27:10.753145\n",
      "resetting env. episode 3386, reward total was -13.0. running mean: -18.121437774301448, timestamp: 2022-08-20 08:27:14.205186\n",
      "resetting env. episode 3387, reward total was -20.0. running mean: -18.140223396558433, timestamp: 2022-08-20 08:27:16.127210\n",
      "resetting env. episode 3388, reward total was -18.0. running mean: -18.138821162592848, timestamp: 2022-08-20 08:27:18.471237\n",
      "resetting env. episode 3389, reward total was -19.0. running mean: -18.14743295096692, timestamp: 2022-08-20 08:27:20.426261\n",
      "resetting env. episode 3390, reward total was -18.0. running mean: -18.14595862145725, timestamp: 2022-08-20 08:27:22.731288\n",
      "resetting env. episode 3391, reward total was -20.0. running mean: -18.164499035242677, timestamp: 2022-08-20 08:27:25.235323\n",
      "resetting env. episode 3392, reward total was -16.0. running mean: -18.14285404489025, timestamp: 2022-08-20 08:27:27.809354\n",
      "resetting env. episode 3393, reward total was -20.0. running mean: -18.161425504441347, timestamp: 2022-08-20 08:27:30.270382\n",
      "resetting env. episode 3394, reward total was -19.0. running mean: -18.169811249396936, timestamp: 2022-08-20 08:27:32.938419\n",
      "resetting env. episode 3395, reward total was -18.0. running mean: -18.168113136902967, timestamp: 2022-08-20 08:27:35.676448\n",
      "resetting env. episode 3396, reward total was -18.0. running mean: -18.166432005533938, timestamp: 2022-08-20 08:27:38.136524\n",
      "resetting env. episode 3397, reward total was -18.0. running mean: -18.164767685478598, timestamp: 2022-08-20 08:27:40.920558\n",
      "resetting env. episode 3398, reward total was -18.0. running mean: -18.16312000862381, timestamp: 2022-08-20 08:27:43.258587\n",
      "resetting env. episode 3399, reward total was -19.0. running mean: -18.171488808537575, timestamp: 2022-08-20 08:27:46.082631\n",
      "resetting env. episode 3400, reward total was -21.0. running mean: -18.1997739204522, timestamp: 2022-08-20 08:27:48.348649\n",
      "resetting env. episode 3401, reward total was -20.0. running mean: -18.217776181247675, timestamp: 2022-08-20 08:27:50.671680\n",
      "resetting env. episode 3402, reward total was -16.0. running mean: -18.1955984194352, timestamp: 2022-08-20 08:27:53.657716\n",
      "resetting env. episode 3403, reward total was -16.0. running mean: -18.173642435240847, timestamp: 2022-08-20 08:27:55.946749\n",
      "resetting env. episode 3404, reward total was -17.0. running mean: -18.16190601088844, timestamp: 2022-08-20 08:27:59.664789\n",
      "resetting env. episode 3405, reward total was -19.0. running mean: -18.170286950779555, timestamp: 2022-08-20 08:28:02.031831\n",
      "resetting env. episode 3406, reward total was -21.0. running mean: -18.19858408127176, timestamp: 2022-08-20 08:28:03.954841\n",
      "resetting env. episode 3407, reward total was -20.0. running mean: -18.216598240459042, timestamp: 2022-08-20 08:28:06.183869\n",
      "resetting env. episode 3408, reward total was -21.0. running mean: -18.244432258054452, timestamp: 2022-08-20 08:28:08.104898\n",
      "resetting env. episode 3409, reward total was -20.0. running mean: -18.261987935473908, timestamp: 2022-08-20 08:28:10.307922\n",
      "resetting env. episode 3410, reward total was -18.0. running mean: -18.25936805611917, timestamp: 2022-08-20 08:28:12.756951\n",
      "resetting env. episode 3411, reward total was -20.0. running mean: -18.276774375557977, timestamp: 2022-08-20 08:28:14.514974\n",
      "resetting env. episode 3412, reward total was -16.0. running mean: -18.254006631802397, timestamp: 2022-08-20 08:28:17.005001\n",
      "resetting env. episode 3413, reward total was -20.0. running mean: -18.271466565484374, timestamp: 2022-08-20 08:28:18.857029\n",
      "resetting env. episode 3414, reward total was -21.0. running mean: -18.298751899829533, timestamp: 2022-08-20 08:28:20.949051\n",
      "resetting env. episode 3415, reward total was -16.0. running mean: -18.275764380831237, timestamp: 2022-08-20 08:28:23.650087\n",
      "resetting env. episode 3416, reward total was -17.0. running mean: -18.263006737022927, timestamp: 2022-08-20 08:28:25.936113\n",
      "resetting env. episode 3417, reward total was -18.0. running mean: -18.260376669652697, timestamp: 2022-08-20 08:28:28.427145\n",
      "resetting env. episode 3418, reward total was -21.0. running mean: -18.28777290295617, timestamp: 2022-08-20 08:28:30.145165\n",
      "resetting env. episode 3419, reward total was -21.0. running mean: -18.314895173926608, timestamp: 2022-08-20 08:28:32.265194\n",
      "resetting env. episode 3420, reward total was -18.0. running mean: -18.31174622218734, timestamp: 2022-08-20 08:28:34.823223\n",
      "resetting env. episode 3421, reward total was -20.0. running mean: -18.32862875996547, timestamp: 2022-08-20 08:28:36.764250\n",
      "resetting env. episode 3422, reward total was -17.0. running mean: -18.315342472365817, timestamp: 2022-08-20 08:28:39.567280\n",
      "resetting env. episode 3423, reward total was -16.0. running mean: -18.292189047642157, timestamp: 2022-08-20 08:28:42.533321\n",
      "resetting env. episode 3424, reward total was -17.0. running mean: -18.279267157165737, timestamp: 2022-08-20 08:28:45.993362\n",
      "resetting env. episode 3425, reward total was -19.0. running mean: -18.28647448559408, timestamp: 2022-08-20 08:28:47.767383\n",
      "resetting env. episode 3426, reward total was -20.0. running mean: -18.30360974073814, timestamp: 2022-08-20 08:28:50.663419\n",
      "resetting env. episode 3427, reward total was -19.0. running mean: -18.31057364333076, timestamp: 2022-08-20 08:28:52.592441\n",
      "resetting env. episode 3428, reward total was -20.0. running mean: -18.32746790689745, timestamp: 2022-08-20 08:28:55.517479\n",
      "resetting env. episode 3429, reward total was -19.0. running mean: -18.334193227828475, timestamp: 2022-08-20 08:28:57.731506\n",
      "resetting env. episode 3430, reward total was -21.0. running mean: -18.36085129555019, timestamp: 2022-08-20 08:28:59.960535\n",
      "resetting env. episode 3431, reward total was -19.0. running mean: -18.36724278259469, timestamp: 2022-08-20 08:29:02.555564\n",
      "resetting env. episode 3432, reward total was -16.0. running mean: -18.343570354768744, timestamp: 2022-08-20 08:29:04.963595\n",
      "resetting env. episode 3433, reward total was -16.0. running mean: -18.320134651221057, timestamp: 2022-08-20 08:29:07.788627\n",
      "resetting env. episode 3434, reward total was -17.0. running mean: -18.30693330470885, timestamp: 2022-08-20 08:29:10.337658\n",
      "resetting env. episode 3435, reward total was -18.0. running mean: -18.30386397166176, timestamp: 2022-08-20 08:29:12.925690\n",
      "resetting env. episode 3436, reward total was -17.0. running mean: -18.290825331945143, timestamp: 2022-08-20 08:29:15.124718\n",
      "resetting env. episode 3437, reward total was -19.0. running mean: -18.297917078625694, timestamp: 2022-08-20 08:29:16.840744\n",
      "resetting env. episode 3438, reward total was -17.0. running mean: -18.28493790783944, timestamp: 2022-08-20 08:29:19.471769\n",
      "resetting env. episode 3439, reward total was -20.0. running mean: -18.302088528761043, timestamp: 2022-08-20 08:29:21.666798\n",
      "resetting env. episode 3440, reward total was -18.0. running mean: -18.299067643473432, timestamp: 2022-08-20 08:29:23.442820\n",
      "resetting env. episode 3441, reward total was -20.0. running mean: -18.316076967038697, timestamp: 2022-08-20 08:29:25.651849\n",
      "resetting env. episode 3442, reward total was -18.0. running mean: -18.31291619736831, timestamp: 2022-08-20 08:29:27.986883\n",
      "resetting env. episode 3443, reward total was -19.0. running mean: -18.31978703539463, timestamp: 2022-08-20 08:29:29.873900\n",
      "resetting env. episode 3444, reward total was -18.0. running mean: -18.316589165040682, timestamp: 2022-08-20 08:29:32.422929\n",
      "resetting env. episode 3445, reward total was -20.0. running mean: -18.333423273390274, timestamp: 2022-08-20 08:29:34.518956\n",
      "resetting env. episode 3446, reward total was -18.0. running mean: -18.33008904065637, timestamp: 2022-08-20 08:29:37.019995\n",
      "resetting env. episode 3447, reward total was -19.0. running mean: -18.33678815024981, timestamp: 2022-08-20 08:29:38.949013\n",
      "resetting env. episode 3448, reward total was -15.0. running mean: -18.30342026874731, timestamp: 2022-08-20 08:29:41.722045\n",
      "resetting env. episode 3449, reward total was -15.0. running mean: -18.270386066059835, timestamp: 2022-08-20 08:29:44.398082\n",
      "resetting env. episode 3450, reward total was -21.0. running mean: -18.297682205399237, timestamp: 2022-08-20 08:29:46.109099\n",
      "resetting env. episode 3451, reward total was -18.0. running mean: -18.294705383345246, timestamp: 2022-08-20 08:29:48.757135\n",
      "resetting env. episode 3452, reward total was -15.0. running mean: -18.261758329511792, timestamp: 2022-08-20 08:29:52.015172\n",
      "resetting env. episode 3453, reward total was -19.0. running mean: -18.269140746216674, timestamp: 2022-08-20 08:29:54.623208\n",
      "resetting env. episode 3454, reward total was -15.0. running mean: -18.236449338754507, timestamp: 2022-08-20 08:29:57.238241\n",
      "resetting env. episode 3455, reward total was -18.0. running mean: -18.23408484536696, timestamp: 2022-08-20 08:29:58.811258\n",
      "resetting env. episode 3456, reward total was -19.0. running mean: -18.241743996913293, timestamp: 2022-08-20 08:30:01.222286\n",
      "resetting env. episode 3457, reward total was -18.0. running mean: -18.23932655694416, timestamp: 2022-08-20 08:30:03.347310\n",
      "resetting env. episode 3458, reward total was -14.0. running mean: -18.19693329137472, timestamp: 2022-08-20 08:30:06.332347\n",
      "resetting env. episode 3459, reward total was -21.0. running mean: -18.22496395846097, timestamp: 2022-08-20 08:30:07.896367\n",
      "resetting env. episode 3460, reward total was -19.0. running mean: -18.23271431887636, timestamp: 2022-08-20 08:30:09.943437\n",
      "resetting env. episode 3461, reward total was -15.0. running mean: -18.200387175687595, timestamp: 2022-08-20 08:30:12.563468\n",
      "resetting env. episode 3462, reward total was -20.0. running mean: -18.218383303930718, timestamp: 2022-08-20 08:30:13.880488\n",
      "resetting env. episode 3463, reward total was -20.0. running mean: -18.23619947089141, timestamp: 2022-08-20 08:30:15.718507\n",
      "resetting env. episode 3464, reward total was -19.0. running mean: -18.2438374761825, timestamp: 2022-08-20 08:30:18.105534\n",
      "resetting env. episode 3465, reward total was -19.0. running mean: -18.251399101420674, timestamp: 2022-08-20 08:30:20.247562\n",
      "resetting env. episode 3466, reward total was -15.0. running mean: -18.218885110406465, timestamp: 2022-08-20 08:30:23.380598\n",
      "resetting env. episode 3467, reward total was -19.0. running mean: -18.2266962593024, timestamp: 2022-08-20 08:30:25.915641\n",
      "resetting env. episode 3468, reward total was -20.0. running mean: -18.244429296709377, timestamp: 2022-08-20 08:30:28.373661\n",
      "resetting env. episode 3469, reward total was -18.0. running mean: -18.241985003742283, timestamp: 2022-08-20 08:30:31.078693\n",
      "resetting env. episode 3470, reward total was -19.0. running mean: -18.24956515370486, timestamp: 2022-08-20 08:30:33.588726\n",
      "resetting env. episode 3471, reward total was -15.0. running mean: -18.21706950216781, timestamp: 2022-08-20 08:30:36.728762\n",
      "resetting env. episode 3472, reward total was -21.0. running mean: -18.244898807146132, timestamp: 2022-08-20 08:30:38.506784\n",
      "resetting env. episode 3473, reward total was -18.0. running mean: -18.242449819074672, timestamp: 2022-08-20 08:30:41.122871\n",
      "resetting env. episode 3474, reward total was -16.0. running mean: -18.220025320883924, timestamp: 2022-08-20 08:30:43.892901\n",
      "resetting env. episode 3475, reward total was -20.0. running mean: -18.237825067675082, timestamp: 2022-08-20 08:30:45.912925\n",
      "resetting env. episode 3476, reward total was -16.0. running mean: -18.21544681699833, timestamp: 2022-08-20 08:30:48.116953\n",
      "resetting env. episode 3477, reward total was -18.0. running mean: -18.213292348828347, timestamp: 2022-08-20 08:30:50.061976\n",
      "resetting env. episode 3478, reward total was -16.0. running mean: -18.191159425340064, timestamp: 2022-08-20 08:30:52.408005\n",
      "resetting env. episode 3479, reward total was -17.0. running mean: -18.179247831086666, timestamp: 2022-08-20 08:30:55.283041\n",
      "resetting env. episode 3480, reward total was -18.0. running mean: -18.177455352775798, timestamp: 2022-08-20 08:30:57.702591\n",
      "resetting env. episode 3481, reward total was -20.0. running mean: -18.195680799248038, timestamp: 2022-08-20 08:30:59.736617\n",
      "resetting env. episode 3482, reward total was -21.0. running mean: -18.223723991255557, timestamp: 2022-08-20 08:31:01.944650\n",
      "resetting env. episode 3483, reward total was -20.0. running mean: -18.241486751343, timestamp: 2022-08-20 08:31:03.733664\n",
      "resetting env. episode 3484, reward total was -17.0. running mean: -18.229071883829572, timestamp: 2022-08-20 08:31:05.708689\n",
      "resetting env. episode 3485, reward total was -21.0. running mean: -18.256781164991278, timestamp: 2022-08-20 08:31:07.735717\n",
      "resetting env. episode 3486, reward total was -21.0. running mean: -18.284213353341364, timestamp: 2022-08-20 08:31:09.747738\n",
      "resetting env. episode 3487, reward total was -21.0. running mean: -18.311371219807953, timestamp: 2022-08-20 08:31:11.722763\n",
      "resetting env. episode 3488, reward total was -20.0. running mean: -18.328257507609873, timestamp: 2022-08-20 08:31:13.559786\n",
      "resetting env. episode 3489, reward total was -16.0. running mean: -18.304974932533774, timestamp: 2022-08-20 08:31:16.464821\n",
      "resetting env. episode 3490, reward total was -16.0. running mean: -18.281925183208436, timestamp: 2022-08-20 08:31:18.914851\n",
      "resetting env. episode 3491, reward total was -18.0. running mean: -18.27910593137635, timestamp: 2022-08-20 08:31:21.500885\n",
      "resetting env. episode 3492, reward total was -19.0. running mean: -18.286314872062587, timestamp: 2022-08-20 08:31:23.800915\n",
      "resetting env. episode 3493, reward total was -19.0. running mean: -18.293451723341963, timestamp: 2022-08-20 08:31:26.276944\n",
      "resetting env. episode 3494, reward total was -21.0. running mean: -18.320517206108544, timestamp: 2022-08-20 08:31:28.574972\n",
      "resetting env. episode 3495, reward total was -19.0. running mean: -18.32731203404746, timestamp: 2022-08-20 08:31:30.348992\n",
      "resetting env. episode 3496, reward total was -16.0. running mean: -18.304038913706986, timestamp: 2022-08-20 08:31:32.315018\n",
      "resetting env. episode 3497, reward total was -21.0. running mean: -18.330998524569917, timestamp: 2022-08-20 08:31:34.112038\n",
      "resetting env. episode 3498, reward total was -19.0. running mean: -18.33768853932422, timestamp: 2022-08-20 08:31:36.285067\n",
      "resetting env. episode 3499, reward total was -19.0. running mean: -18.344311653930976, timestamp: 2022-08-20 08:31:38.717096\n",
      "resetting env. episode 3500, reward total was -14.0. running mean: -18.30086853739167, timestamp: 2022-08-20 08:31:41.216130\n",
      "resetting env. episode 3501, reward total was -19.0. running mean: -18.307859852017753, timestamp: 2022-08-20 08:31:43.276153\n",
      "resetting env. episode 3502, reward total was -20.0. running mean: -18.324781253497573, timestamp: 2022-08-20 08:31:45.813185\n",
      "resetting env. episode 3503, reward total was -20.0. running mean: -18.341533440962596, timestamp: 2022-08-20 08:31:48.415213\n",
      "resetting env. episode 3504, reward total was -21.0. running mean: -18.36811810655297, timestamp: 2022-08-20 08:31:50.852245\n",
      "resetting env. episode 3505, reward total was -16.0. running mean: -18.34443692548744, timestamp: 2022-08-20 08:31:53.255276\n",
      "resetting env. episode 3506, reward total was -19.0. running mean: -18.350992556232566, timestamp: 2022-08-20 08:31:56.270311\n",
      "resetting env. episode 3507, reward total was -15.0. running mean: -18.317482630670238, timestamp: 2022-08-20 08:31:59.245353\n",
      "resetting env. episode 3508, reward total was -17.0. running mean: -18.304307804363535, timestamp: 2022-08-20 08:32:02.186389\n",
      "resetting env. episode 3509, reward total was -21.0. running mean: -18.3312647263199, timestamp: 2022-08-20 08:32:04.016406\n",
      "resetting env. episode 3510, reward total was -19.0. running mean: -18.337952079056702, timestamp: 2022-08-20 08:32:05.734431\n",
      "resetting env. episode 3511, reward total was -20.0. running mean: -18.354572558266135, timestamp: 2022-08-20 08:32:07.502453\n",
      "resetting env. episode 3512, reward total was -15.0. running mean: -18.321026832683472, timestamp: 2022-08-20 08:32:10.228483\n",
      "resetting env. episode 3513, reward total was -19.0. running mean: -18.327816564356638, timestamp: 2022-08-20 08:32:12.308510\n",
      "resetting env. episode 3514, reward total was -12.0. running mean: -18.26453839871307, timestamp: 2022-08-20 08:32:15.458068\n",
      "resetting env. episode 3515, reward total was -13.0. running mean: -18.21189301472594, timestamp: 2022-08-20 08:32:18.157104\n",
      "resetting env. episode 3516, reward total was -20.0. running mean: -18.229774084578683, timestamp: 2022-08-20 08:32:20.239131\n",
      "resetting env. episode 3517, reward total was -18.0. running mean: -18.227476343732896, timestamp: 2022-08-20 08:32:22.600154\n",
      "resetting env. episode 3518, reward total was -16.0. running mean: -18.205201580295565, timestamp: 2022-08-20 08:32:24.952186\n",
      "resetting env. episode 3519, reward total was -20.0. running mean: -18.22314956449261, timestamp: 2022-08-20 08:32:27.495740\n",
      "resetting env. episode 3520, reward total was -21.0. running mean: -18.25091806884768, timestamp: 2022-08-20 08:32:29.418764\n",
      "resetting env. episode 3521, reward total was -21.0. running mean: -18.278408888159206, timestamp: 2022-08-20 08:32:31.076784\n",
      "resetting env. episode 3522, reward total was -16.0. running mean: -18.255624799277612, timestamp: 2022-08-20 08:32:33.974818\n",
      "resetting env. episode 3523, reward total was -21.0. running mean: -18.28306855128484, timestamp: 2022-08-20 08:32:36.696853\n",
      "resetting env. episode 3524, reward total was -12.0. running mean: -18.220237865771992, timestamp: 2022-08-20 08:32:39.886894\n",
      "resetting env. episode 3525, reward total was -18.0. running mean: -18.21803548711427, timestamp: 2022-08-20 08:32:42.154970\n",
      "resetting env. episode 3526, reward total was -14.0. running mean: -18.17585513224313, timestamp: 2022-08-20 08:32:45.024008\n",
      "resetting env. episode 3527, reward total was -16.0. running mean: -18.154096580920697, timestamp: 2022-08-20 08:32:47.498039\n",
      "resetting env. episode 3528, reward total was -20.0. running mean: -18.172555615111488, timestamp: 2022-08-20 08:32:49.600059\n",
      "resetting env. episode 3529, reward total was -19.0. running mean: -18.180830058960375, timestamp: 2022-08-20 08:32:52.640097\n",
      "resetting env. episode 3530, reward total was -20.0. running mean: -18.19902175837077, timestamp: 2022-08-20 08:32:54.677120\n",
      "resetting env. episode 3531, reward total was -21.0. running mean: -18.227031540787063, timestamp: 2022-08-20 08:32:56.672146\n",
      "resetting env. episode 3532, reward total was -15.0. running mean: -18.194761225379192, timestamp: 2022-08-20 08:32:59.122177\n",
      "resetting env. episode 3533, reward total was -18.0. running mean: -18.1928136131254, timestamp: 2022-08-20 08:33:01.451209\n",
      "resetting env. episode 3534, reward total was -19.0. running mean: -18.200885476994145, timestamp: 2022-08-20 08:33:04.002238\n",
      "resetting env. episode 3535, reward total was -17.0. running mean: -18.188876622224207, timestamp: 2022-08-20 08:33:06.595267\n",
      "resetting env. episode 3536, reward total was -18.0. running mean: -18.186987856001963, timestamp: 2022-08-20 08:33:09.017297\n",
      "resetting env. episode 3537, reward total was -19.0. running mean: -18.195117977441946, timestamp: 2022-08-20 08:33:10.963324\n",
      "resetting env. episode 3538, reward total was -17.0. running mean: -18.18316679766753, timestamp: 2022-08-20 08:33:13.149350\n",
      "resetting env. episode 3539, reward total was -19.0. running mean: -18.191335129690856, timestamp: 2022-08-20 08:33:16.540394\n",
      "resetting env. episode 3540, reward total was -18.0. running mean: -18.189421778393946, timestamp: 2022-08-20 08:33:19.061420\n",
      "resetting env. episode 3541, reward total was -19.0. running mean: -18.19752756061001, timestamp: 2022-08-20 08:33:21.392452\n",
      "resetting env. episode 3542, reward total was -15.0. running mean: -18.16555228500391, timestamp: 2022-08-20 08:33:24.199482\n",
      "resetting env. episode 3543, reward total was -18.0. running mean: -18.16389676215387, timestamp: 2022-08-20 08:33:26.148508\n",
      "resetting env. episode 3544, reward total was -18.0. running mean: -18.16225779453233, timestamp: 2022-08-20 08:33:28.319532\n",
      "resetting env. episode 3545, reward total was -16.0. running mean: -18.140635216587008, timestamp: 2022-08-20 08:33:30.951565\n",
      "resetting env. episode 3546, reward total was -21.0. running mean: -18.16922886442114, timestamp: 2022-08-20 08:33:32.976588\n",
      "resetting env. episode 3547, reward total was -21.0. running mean: -18.19753657577693, timestamp: 2022-08-20 08:33:34.978613\n",
      "resetting env. episode 3548, reward total was -17.0. running mean: -18.185561210019163, timestamp: 2022-08-20 08:33:37.767646\n",
      "resetting env. episode 3549, reward total was -18.0. running mean: -18.18370559791897, timestamp: 2022-08-20 08:33:40.207677\n",
      "resetting env. episode 3550, reward total was -18.0. running mean: -18.181868541939778, timestamp: 2022-08-20 08:33:43.033712\n",
      "resetting env. episode 3551, reward total was -17.0. running mean: -18.170049856520382, timestamp: 2022-08-20 08:33:45.874746\n",
      "resetting env. episode 3552, reward total was -20.0. running mean: -18.18834935795518, timestamp: 2022-08-20 08:33:48.029772\n",
      "resetting env. episode 3553, reward total was -17.0. running mean: -18.17646586437563, timestamp: 2022-08-20 08:33:51.101812\n",
      "resetting env. episode 3554, reward total was -17.0. running mean: -18.164701205731873, timestamp: 2022-08-20 08:33:53.610841\n",
      "resetting env. episode 3555, reward total was -18.0. running mean: -18.163054193674554, timestamp: 2022-08-20 08:33:55.909868\n",
      "resetting env. episode 3556, reward total was -18.0. running mean: -18.16142365173781, timestamp: 2022-08-20 08:33:58.111901\n",
      "resetting env. episode 3557, reward total was -17.0. running mean: -18.14980941522043, timestamp: 2022-08-20 08:34:00.688926\n",
      "resetting env. episode 3558, reward total was -21.0. running mean: -18.17831132106823, timestamp: 2022-08-20 08:34:02.364947\n",
      "resetting env. episode 3559, reward total was -21.0. running mean: -18.20652820785755, timestamp: 2022-08-20 08:34:04.504977\n",
      "resetting env. episode 3560, reward total was -18.0. running mean: -18.204462925778973, timestamp: 2022-08-20 08:34:06.440996\n",
      "resetting env. episode 3561, reward total was -18.0. running mean: -18.202418296521184, timestamp: 2022-08-20 08:34:08.288546\n",
      "resetting env. episode 3562, reward total was -13.0. running mean: -18.150394113555972, timestamp: 2022-08-20 08:34:11.800588\n",
      "resetting env. episode 3563, reward total was -20.0. running mean: -18.16889017242041, timestamp: 2022-08-20 08:34:13.412608\n",
      "resetting env. episode 3564, reward total was -20.0. running mean: -18.187201270696207, timestamp: 2022-08-20 08:34:15.293635\n",
      "resetting env. episode 3565, reward total was -20.0. running mean: -18.205329257989245, timestamp: 2022-08-20 08:34:17.775657\n",
      "resetting env. episode 3566, reward total was -19.0. running mean: -18.213275965409352, timestamp: 2022-08-20 08:34:19.625685\n",
      "resetting env. episode 3567, reward total was -18.0. running mean: -18.211143205755256, timestamp: 2022-08-20 08:34:21.830708\n",
      "resetting env. episode 3568, reward total was -14.0. running mean: -18.169031773697704, timestamp: 2022-08-20 08:34:24.889746\n",
      "resetting env. episode 3569, reward total was -15.0. running mean: -18.137341455960726, timestamp: 2022-08-20 08:34:27.419779\n",
      "resetting env. episode 3570, reward total was -16.0. running mean: -18.115968041401118, timestamp: 2022-08-20 08:34:30.269814\n",
      "resetting env. episode 3571, reward total was -21.0. running mean: -18.144808360987106, timestamp: 2022-08-20 08:34:32.485841\n",
      "resetting env. episode 3572, reward total was -19.0. running mean: -18.153360277377235, timestamp: 2022-08-20 08:34:34.353861\n",
      "resetting env. episode 3573, reward total was -19.0. running mean: -18.161826674603464, timestamp: 2022-08-20 08:34:36.287885\n",
      "resetting env. episode 3574, reward total was -17.0. running mean: -18.15020840785743, timestamp: 2022-08-20 08:34:38.563912\n",
      "resetting env. episode 3575, reward total was -20.0. running mean: -18.168706323778856, timestamp: 2022-08-20 08:34:40.502935\n",
      "resetting env. episode 3576, reward total was -17.0. running mean: -18.15701926054107, timestamp: 2022-08-20 08:34:42.730964\n",
      "resetting env. episode 3577, reward total was -18.0. running mean: -18.15544906793566, timestamp: 2022-08-20 08:34:45.384994\n",
      "resetting env. episode 3578, reward total was -19.0. running mean: -18.163894577256304, timestamp: 2022-08-20 08:34:47.247020\n",
      "resetting env. episode 3579, reward total was -19.0. running mean: -18.172255631483743, timestamp: 2022-08-20 08:34:49.224042\n",
      "resetting env. episode 3580, reward total was -21.0. running mean: -18.200533075168906, timestamp: 2022-08-20 08:34:51.624070\n",
      "resetting env. episode 3581, reward total was -20.0. running mean: -18.218527744417216, timestamp: 2022-08-20 08:34:53.875101\n",
      "resetting env. episode 3582, reward total was -19.0. running mean: -18.226342466973044, timestamp: 2022-08-20 08:34:55.852121\n",
      "resetting env. episode 3583, reward total was -13.0. running mean: -18.174079042303312, timestamp: 2022-08-20 08:34:58.787161\n",
      "resetting env. episode 3584, reward total was -18.0. running mean: -18.172338251880277, timestamp: 2022-08-20 08:35:01.982198\n",
      "resetting env. episode 3585, reward total was -17.0. running mean: -18.160614869361474, timestamp: 2022-08-20 08:35:04.213224\n",
      "resetting env. episode 3586, reward total was -12.0. running mean: -18.09900872066786, timestamp: 2022-08-20 08:35:07.053260\n",
      "resetting env. episode 3587, reward total was -16.0. running mean: -18.07801863346118, timestamp: 2022-08-20 08:35:09.447287\n",
      "resetting env. episode 3588, reward total was -18.0. running mean: -18.077238447126568, timestamp: 2022-08-20 08:35:11.562312\n",
      "resetting env. episode 3589, reward total was -17.0. running mean: -18.066466062655305, timestamp: 2022-08-20 08:35:13.855338\n",
      "resetting env. episode 3590, reward total was -16.0. running mean: -18.04580140202875, timestamp: 2022-08-20 08:35:16.630375\n",
      "resetting env. episode 3591, reward total was -16.0. running mean: -18.025343388008462, timestamp: 2022-08-20 08:35:19.401406\n",
      "resetting env. episode 3592, reward total was -17.0. running mean: -18.015089954128378, timestamp: 2022-08-20 08:35:22.440447\n",
      "resetting env. episode 3593, reward total was -19.0. running mean: -18.024939054587094, timestamp: 2022-08-20 08:35:24.635471\n",
      "resetting env. episode 3594, reward total was -19.0. running mean: -18.034689664041224, timestamp: 2022-08-20 08:35:26.372491\n",
      "resetting env. episode 3595, reward total was -16.0. running mean: -18.014342767400812, timestamp: 2022-08-20 08:35:29.533528\n",
      "resetting env. episode 3596, reward total was -19.0. running mean: -18.024199339726806, timestamp: 2022-08-20 08:35:31.484559\n",
      "resetting env. episode 3597, reward total was -17.0. running mean: -18.01395734632954, timestamp: 2022-08-20 08:35:34.054588\n",
      "resetting env. episode 3598, reward total was -19.0. running mean: -18.023817772866245, timestamp: 2022-08-20 08:35:36.073608\n",
      "resetting env. episode 3599, reward total was -17.0. running mean: -18.013579595137585, timestamp: 2022-08-20 08:35:38.887641\n",
      "resetting env. episode 3600, reward total was -16.0. running mean: -17.99344379918621, timestamp: 2022-08-20 08:35:41.680675\n",
      "resetting env. episode 3601, reward total was -19.0. running mean: -18.00350936119435, timestamp: 2022-08-20 08:35:44.449711\n",
      "resetting env. episode 3602, reward total was -16.0. running mean: -17.983474267582405, timestamp: 2022-08-20 08:35:47.878752\n",
      "resetting env. episode 3603, reward total was -16.0. running mean: -17.963639524906583, timestamp: 2022-08-20 08:35:50.448782\n",
      "resetting env. episode 3604, reward total was -19.0. running mean: -17.97400312965752, timestamp: 2022-08-20 08:35:53.407819\n",
      "resetting env. episode 3605, reward total was -15.0. running mean: -17.944263098360942, timestamp: 2022-08-20 08:35:56.292853\n",
      "resetting env. episode 3606, reward total was -17.0. running mean: -17.934820467377335, timestamp: 2022-08-20 08:35:58.920410\n",
      "resetting env. episode 3607, reward total was -20.0. running mean: -17.955472262703562, timestamp: 2022-08-20 08:36:00.539433\n",
      "resetting env. episode 3608, reward total was -19.0. running mean: -17.96591754007653, timestamp: 2022-08-20 08:36:02.518452\n",
      "resetting env. episode 3609, reward total was -17.0. running mean: -17.956258364675765, timestamp: 2022-08-20 08:36:05.033485\n",
      "resetting env. episode 3610, reward total was -21.0. running mean: -17.98669578102901, timestamp: 2022-08-20 08:36:07.386513\n",
      "resetting env. episode 3611, reward total was -17.0. running mean: -17.97682882321872, timestamp: 2022-08-20 08:36:09.306535\n",
      "resetting env. episode 3612, reward total was -19.0. running mean: -17.987060534986536, timestamp: 2022-08-20 08:36:12.020568\n",
      "resetting env. episode 3613, reward total was -20.0. running mean: -18.00718992963667, timestamp: 2022-08-20 08:36:14.170594\n",
      "resetting env. episode 3614, reward total was -19.0. running mean: -18.017118030340306, timestamp: 2022-08-20 08:36:15.791615\n",
      "resetting env. episode 3615, reward total was -19.0. running mean: -18.026946850036904, timestamp: 2022-08-20 08:36:18.228644\n",
      "resetting env. episode 3616, reward total was -19.0. running mean: -18.036677381536535, timestamp: 2022-08-20 08:36:20.599673\n",
      "resetting env. episode 3617, reward total was -20.0. running mean: -18.05631060772117, timestamp: 2022-08-20 08:36:23.098706\n",
      "resetting env. episode 3618, reward total was -18.0. running mean: -18.055747501643957, timestamp: 2022-08-20 08:36:25.399734\n",
      "resetting env. episode 3619, reward total was -17.0. running mean: -18.04519002662752, timestamp: 2022-08-20 08:36:28.194765\n",
      "resetting env. episode 3620, reward total was -19.0. running mean: -18.054738126361247, timestamp: 2022-08-20 08:36:30.795319\n",
      "resetting env. episode 3621, reward total was -19.0. running mean: -18.064190745097637, timestamp: 2022-08-20 08:36:32.861347\n",
      "resetting env. episode 3622, reward total was -17.0. running mean: -18.053548837646662, timestamp: 2022-08-20 08:36:35.400376\n",
      "resetting env. episode 3623, reward total was -20.0. running mean: -18.073013349270195, timestamp: 2022-08-20 08:36:37.588401\n",
      "resetting env. episode 3624, reward total was -12.0. running mean: -18.012283215777494, timestamp: 2022-08-20 08:36:40.895440\n",
      "resetting env. episode 3625, reward total was -19.0. running mean: -18.02216038361972, timestamp: 2022-08-20 08:36:43.228470\n",
      "resetting env. episode 3626, reward total was -15.0. running mean: -17.99193877978352, timestamp: 2022-08-20 08:36:46.017505\n",
      "resetting env. episode 3627, reward total was -19.0. running mean: -18.002019391985687, timestamp: 2022-08-20 08:36:48.271532\n",
      "resetting env. episode 3628, reward total was -18.0. running mean: -18.00199919806583, timestamp: 2022-08-20 08:36:51.015563\n",
      "resetting env. episode 3629, reward total was -21.0. running mean: -18.031979206085172, timestamp: 2022-08-20 08:36:52.931588\n",
      "resetting env. episode 3630, reward total was -16.0. running mean: -18.01165941402432, timestamp: 2022-08-20 08:36:55.784622\n",
      "resetting env. episode 3631, reward total was -18.0. running mean: -18.011542819884074, timestamp: 2022-08-20 08:36:58.231652\n",
      "resetting env. episode 3632, reward total was -20.0. running mean: -18.03142739168523, timestamp: 2022-08-20 08:37:00.587682\n",
      "resetting env. episode 3633, reward total was -15.0. running mean: -18.001113117768377, timestamp: 2022-08-20 08:37:03.410717\n",
      "resetting env. episode 3634, reward total was -17.0. running mean: -17.991101986590696, timestamp: 2022-08-20 08:37:05.613743\n",
      "resetting env. episode 3635, reward total was -15.0. running mean: -17.961190966724786, timestamp: 2022-08-20 08:37:08.020773\n",
      "resetting env. episode 3636, reward total was -19.0. running mean: -17.97157905705754, timestamp: 2022-08-20 08:37:10.731333\n",
      "resetting env. episode 3637, reward total was -19.0. running mean: -17.981863266486965, timestamp: 2022-08-20 08:37:13.207361\n",
      "resetting env. episode 3638, reward total was -18.0. running mean: -17.982044633822095, timestamp: 2022-08-20 08:37:15.593392\n",
      "resetting env. episode 3639, reward total was -20.0. running mean: -18.002224187483872, timestamp: 2022-08-20 08:37:17.391417\n",
      "resetting env. episode 3640, reward total was -17.0. running mean: -17.992201945609036, timestamp: 2022-08-20 08:37:19.728440\n",
      "resetting env. episode 3641, reward total was -17.0. running mean: -17.98227992615295, timestamp: 2022-08-20 08:37:22.262473\n",
      "resetting env. episode 3642, reward total was -16.0. running mean: -17.96245712689142, timestamp: 2022-08-20 08:37:25.218513\n",
      "resetting env. episode 3643, reward total was -17.0. running mean: -17.952832555622507, timestamp: 2022-08-20 08:37:27.674539\n",
      "resetting env. episode 3644, reward total was -16.0. running mean: -17.93330423006628, timestamp: 2022-08-20 08:37:30.017567\n",
      "resetting env. episode 3645, reward total was -18.0. running mean: -17.933971187765618, timestamp: 2022-08-20 08:37:33.046608\n",
      "resetting env. episode 3646, reward total was -18.0. running mean: -17.93463147588796, timestamp: 2022-08-20 08:37:35.671637\n",
      "resetting env. episode 3647, reward total was -17.0. running mean: -17.925285161129082, timestamp: 2022-08-20 08:37:37.983666\n",
      "resetting env. episode 3648, reward total was -19.0. running mean: -17.936032309517792, timestamp: 2022-08-20 08:37:40.040689\n",
      "resetting env. episode 3649, reward total was -19.0. running mean: -17.946671986422615, timestamp: 2022-08-20 08:37:42.327722\n",
      "resetting env. episode 3650, reward total was -18.0. running mean: -17.947205266558388, timestamp: 2022-08-20 08:37:44.844751\n",
      "resetting env. episode 3651, reward total was -21.0. running mean: -17.977733213892805, timestamp: 2022-08-20 08:37:46.391766\n",
      "resetting env. episode 3652, reward total was -17.0. running mean: -17.967955881753877, timestamp: 2022-08-20 08:37:49.131802\n",
      "resetting env. episode 3653, reward total was -17.0. running mean: -17.95827632293634, timestamp: 2022-08-20 08:37:51.980837\n",
      "resetting env. episode 3654, reward total was -16.0. running mean: -17.938693559706977, timestamp: 2022-08-20 08:37:54.117862\n",
      "resetting env. episode 3655, reward total was -18.0. running mean: -17.939306624109907, timestamp: 2022-08-20 08:37:56.477892\n",
      "resetting env. episode 3656, reward total was -16.0. running mean: -17.919913557868806, timestamp: 2022-08-20 08:37:58.991920\n",
      "resetting env. episode 3657, reward total was -14.0. running mean: -17.88071442229012, timestamp: 2022-08-20 08:38:01.523957\n",
      "resetting env. episode 3658, reward total was -17.0. running mean: -17.87190727806722, timestamp: 2022-08-20 08:38:03.611977\n",
      "resetting env. episode 3659, reward total was -20.0. running mean: -17.893188205286545, timestamp: 2022-08-20 08:38:06.052008\n",
      "resetting env. episode 3660, reward total was -20.0. running mean: -17.91425632323368, timestamp: 2022-08-20 08:38:08.139033\n",
      "resetting env. episode 3661, reward total was -17.0. running mean: -17.905113760001345, timestamp: 2022-08-20 08:38:10.386107\n",
      "resetting env. episode 3662, reward total was -19.0. running mean: -17.916062622401334, timestamp: 2022-08-20 08:38:12.996144\n",
      "resetting env. episode 3663, reward total was -17.0. running mean: -17.90690199617732, timestamp: 2022-08-20 08:38:16.007174\n",
      "resetting env. episode 3664, reward total was -15.0. running mean: -17.877832976215547, timestamp: 2022-08-20 08:38:18.720207\n",
      "resetting env. episode 3665, reward total was -16.0. running mean: -17.85905464645339, timestamp: 2022-08-20 08:38:21.374243\n",
      "resetting env. episode 3666, reward total was -17.0. running mean: -17.85046409998886, timestamp: 2022-08-20 08:38:23.875274\n",
      "resetting env. episode 3667, reward total was -15.0. running mean: -17.821959458988967, timestamp: 2022-08-20 08:38:26.300300\n",
      "resetting env. episode 3668, reward total was -16.0. running mean: -17.803739864399077, timestamp: 2022-08-20 08:38:28.414327\n",
      "resetting env. episode 3669, reward total was -18.0. running mean: -17.805702465755086, timestamp: 2022-08-20 08:38:30.251349\n",
      "resetting env. episode 3670, reward total was -19.0. running mean: -17.817645441097536, timestamp: 2022-08-20 08:38:32.419376\n",
      "resetting env. episode 3671, reward total was -18.0. running mean: -17.81946898668656, timestamp: 2022-08-20 08:38:35.368937\n",
      "resetting env. episode 3672, reward total was -20.0. running mean: -17.84127429681969, timestamp: 2022-08-20 08:38:38.176968\n",
      "resetting env. episode 3673, reward total was -18.0. running mean: -17.842861553851492, timestamp: 2022-08-20 08:38:40.462997\n",
      "resetting env. episode 3674, reward total was -14.0. running mean: -17.804432938312978, timestamp: 2022-08-20 08:38:43.104038\n",
      "resetting env. episode 3675, reward total was -17.0. running mean: -17.79638860892985, timestamp: 2022-08-20 08:38:45.549064\n",
      "resetting env. episode 3676, reward total was -15.0. running mean: -17.76842472284055, timestamp: 2022-08-20 08:38:48.440098\n",
      "resetting env. episode 3677, reward total was -16.0. running mean: -17.750740475612144, timestamp: 2022-08-20 08:38:50.906127\n",
      "resetting env. episode 3678, reward total was -19.0. running mean: -17.763233070856025, timestamp: 2022-08-20 08:38:52.704147\n",
      "resetting env. episode 3679, reward total was -16.0. running mean: -17.745600740147463, timestamp: 2022-08-20 08:38:55.701184\n",
      "resetting env. episode 3680, reward total was -17.0. running mean: -17.73814473274599, timestamp: 2022-08-20 08:38:57.995211\n",
      "resetting env. episode 3681, reward total was -19.0. running mean: -17.750763285418532, timestamp: 2022-08-20 08:39:00.088238\n",
      "resetting env. episode 3682, reward total was -17.0. running mean: -17.743255652564347, timestamp: 2022-08-20 08:39:02.714318\n",
      "resetting env. episode 3683, reward total was -16.0. running mean: -17.725823096038702, timestamp: 2022-08-20 08:39:05.400352\n",
      "resetting env. episode 3684, reward total was -18.0. running mean: -17.728564865078315, timestamp: 2022-08-20 08:39:07.914906\n",
      "resetting env. episode 3685, reward total was -20.0. running mean: -17.75127921642753, timestamp: 2022-08-20 08:39:10.115931\n",
      "resetting env. episode 3686, reward total was -16.0. running mean: -17.733766424263255, timestamp: 2022-08-20 08:39:12.371966\n",
      "resetting env. episode 3687, reward total was -19.0. running mean: -17.746428760020624, timestamp: 2022-08-20 08:39:15.912002\n",
      "resetting env. episode 3688, reward total was -13.0. running mean: -17.698964472420418, timestamp: 2022-08-20 08:39:18.567030\n",
      "resetting env. episode 3689, reward total was -19.0. running mean: -17.711974827696213, timestamp: 2022-08-20 08:39:21.407066\n",
      "resetting env. episode 3690, reward total was -17.0. running mean: -17.704855079419254, timestamp: 2022-08-20 08:39:24.344105\n",
      "resetting env. episode 3691, reward total was -18.0. running mean: -17.70780652862506, timestamp: 2022-08-20 08:39:26.462125\n",
      "resetting env. episode 3692, reward total was -19.0. running mean: -17.720728463338812, timestamp: 2022-08-20 08:39:29.157161\n",
      "resetting env. episode 3693, reward total was -18.0. running mean: -17.723521178705422, timestamp: 2022-08-20 08:39:31.206188\n",
      "resetting env. episode 3694, reward total was -20.0. running mean: -17.746285966918368, timestamp: 2022-08-20 08:39:33.074210\n",
      "resetting env. episode 3695, reward total was -21.0. running mean: -17.778823107249185, timestamp: 2022-08-20 08:39:35.358243\n",
      "resetting env. episode 3696, reward total was -17.0. running mean: -17.771034876176696, timestamp: 2022-08-20 08:39:37.247263\n",
      "resetting env. episode 3697, reward total was -19.0. running mean: -17.78332452741493, timestamp: 2022-08-20 08:39:39.584288\n",
      "resetting env. episode 3698, reward total was -18.0. running mean: -17.78549128214078, timestamp: 2022-08-20 08:39:42.313322\n",
      "resetting env. episode 3699, reward total was -16.0. running mean: -17.76763636931937, timestamp: 2022-08-20 08:39:45.001355\n",
      "resetting env. episode 3700, reward total was -17.0. running mean: -17.759960005626176, timestamp: 2022-08-20 08:39:47.856390\n",
      "resetting env. episode 3701, reward total was -18.0. running mean: -17.762360405569915, timestamp: 2022-08-20 08:39:50.318418\n",
      "resetting env. episode 3702, reward total was -17.0. running mean: -17.754736801514216, timestamp: 2022-08-20 08:39:52.721452\n",
      "resetting env. episode 3703, reward total was -15.0. running mean: -17.727189433499074, timestamp: 2022-08-20 08:39:55.644488\n",
      "resetting env. episode 3704, reward total was -20.0. running mean: -17.749917539164084, timestamp: 2022-08-20 08:39:58.635521\n",
      "resetting env. episode 3705, reward total was -18.0. running mean: -17.752418363772442, timestamp: 2022-08-20 08:40:00.931549\n",
      "resetting env. episode 3706, reward total was -19.0. running mean: -17.764894180134718, timestamp: 2022-08-20 08:40:02.810575\n",
      "resetting env. episode 3707, reward total was -17.0. running mean: -17.757245238333372, timestamp: 2022-08-20 08:40:05.321602\n",
      "resetting env. episode 3708, reward total was -18.0. running mean: -17.759672785950038, timestamp: 2022-08-20 08:40:07.378627\n",
      "resetting env. episode 3709, reward total was -18.0. running mean: -17.762076058090535, timestamp: 2022-08-20 08:40:09.962665\n",
      "resetting env. episode 3710, reward total was -18.0. running mean: -17.76445529750963, timestamp: 2022-08-20 08:40:12.375693\n",
      "resetting env. episode 3711, reward total was -18.0. running mean: -17.766810744534535, timestamp: 2022-08-20 08:40:15.151723\n",
      "resetting env. episode 3712, reward total was -18.0. running mean: -17.76914263708919, timestamp: 2022-08-20 08:40:17.418751\n",
      "resetting env. episode 3713, reward total was -16.0. running mean: -17.751451210718297, timestamp: 2022-08-20 08:40:20.085786\n",
      "resetting env. episode 3714, reward total was -21.0. running mean: -17.783936698611114, timestamp: 2022-08-20 08:40:22.639816\n",
      "resetting env. episode 3715, reward total was -19.0. running mean: -17.796097331625006, timestamp: 2022-08-20 08:40:24.583841\n",
      "resetting env. episode 3716, reward total was -18.0. running mean: -17.798136358308756, timestamp: 2022-08-20 08:40:26.738864\n",
      "resetting env. episode 3717, reward total was -20.0. running mean: -17.82015499472567, timestamp: 2022-08-20 08:40:29.854908\n",
      "resetting env. episode 3718, reward total was -13.0. running mean: -17.77195344477841, timestamp: 2022-08-20 08:40:32.541942\n",
      "resetting env. episode 3719, reward total was -17.0. running mean: -17.764233910330628, timestamp: 2022-08-20 08:40:35.455976\n",
      "resetting env. episode 3720, reward total was -18.0. running mean: -17.76659157122732, timestamp: 2022-08-20 08:40:37.708000\n",
      "resetting env. episode 3721, reward total was -10.0. running mean: -17.688925655515046, timestamp: 2022-08-20 08:40:41.167046\n",
      "resetting env. episode 3722, reward total was -20.0. running mean: -17.712036398959896, timestamp: 2022-08-20 08:40:43.335072\n",
      "resetting env. episode 3723, reward total was -18.0. running mean: -17.714916034970297, timestamp: 2022-08-20 08:40:45.545619\n",
      "resetting env. episode 3724, reward total was -19.0. running mean: -17.727766874620595, timestamp: 2022-08-20 08:40:48.049650\n",
      "resetting env. episode 3725, reward total was -18.0. running mean: -17.730489205874388, timestamp: 2022-08-20 08:40:50.578682\n",
      "resetting env. episode 3726, reward total was -15.0. running mean: -17.703184313815644, timestamp: 2022-08-20 08:40:53.888724\n",
      "resetting env. episode 3727, reward total was -21.0. running mean: -17.73615247067749, timestamp: 2022-08-20 08:40:55.634744\n",
      "resetting env. episode 3728, reward total was -19.0. running mean: -17.748790945970715, timestamp: 2022-08-20 08:40:57.577768\n",
      "resetting env. episode 3729, reward total was -15.0. running mean: -17.721303036511006, timestamp: 2022-08-20 08:41:00.207803\n",
      "resetting env. episode 3730, reward total was -20.0. running mean: -17.744090006145896, timestamp: 2022-08-20 08:41:02.322826\n",
      "resetting env. episode 3731, reward total was -19.0. running mean: -17.75664910608444, timestamp: 2022-08-20 08:41:05.076860\n",
      "resetting env. episode 3732, reward total was -17.0. running mean: -17.749082615023596, timestamp: 2022-08-20 08:41:07.498893\n",
      "resetting env. episode 3733, reward total was -14.0. running mean: -17.71159178887336, timestamp: 2022-08-20 08:41:09.804922\n",
      "resetting env. episode 3734, reward total was -16.0. running mean: -17.694475870984625, timestamp: 2022-08-20 08:41:12.397954\n",
      "resetting env. episode 3735, reward total was -20.0. running mean: -17.717531112274777, timestamp: 2022-08-20 08:41:14.362973\n",
      "resetting env. episode 3736, reward total was -16.0. running mean: -17.70035580115203, timestamp: 2022-08-20 08:41:16.616004\n",
      "resetting env. episode 3737, reward total was -21.0. running mean: -17.73335224314051, timestamp: 2022-08-20 08:41:18.961032\n",
      "resetting env. episode 3738, reward total was -18.0. running mean: -17.736018720709104, timestamp: 2022-08-20 08:41:21.055061\n",
      "resetting env. episode 3739, reward total was -19.0. running mean: -17.748658533502013, timestamp: 2022-08-20 08:41:22.871083\n",
      "resetting env. episode 3740, reward total was -19.0. running mean: -17.761171948166993, timestamp: 2022-08-20 08:41:24.851104\n",
      "resetting env. episode 3741, reward total was -18.0. running mean: -17.76356022868532, timestamp: 2022-08-20 08:41:27.322132\n",
      "resetting env. episode 3742, reward total was -20.0. running mean: -17.78592462639847, timestamp: 2022-08-20 08:41:29.341158\n",
      "resetting env. episode 3743, reward total was -18.0. running mean: -17.788065380134483, timestamp: 2022-08-20 08:41:31.772188\n",
      "resetting env. episode 3744, reward total was -17.0. running mean: -17.78018472633314, timestamp: 2022-08-20 08:41:34.599223\n",
      "resetting env. episode 3745, reward total was -16.0. running mean: -17.762382879069808, timestamp: 2022-08-20 08:41:36.946253\n",
      "resetting env. episode 3746, reward total was -19.0. running mean: -17.774759050279112, timestamp: 2022-08-20 08:41:38.488270\n",
      "resetting env. episode 3747, reward total was -20.0. running mean: -17.79701145977632, timestamp: 2022-08-20 08:41:40.542300\n",
      "resetting env. episode 3748, reward total was -15.0. running mean: -17.769041345178557, timestamp: 2022-08-20 08:41:43.547333\n",
      "resetting env. episode 3749, reward total was -20.0. running mean: -17.79135093172677, timestamp: 2022-08-20 08:41:45.659361\n",
      "resetting env. episode 3750, reward total was -20.0. running mean: -17.813437422409503, timestamp: 2022-08-20 08:41:47.546383\n",
      "resetting env. episode 3751, reward total was -20.0. running mean: -17.83530304818541, timestamp: 2022-08-20 08:41:49.587407\n",
      "resetting env. episode 3752, reward total was -20.0. running mean: -17.856950017703554, timestamp: 2022-08-20 08:41:51.078430\n",
      "resetting env. episode 3753, reward total was -17.0. running mean: -17.848380517526518, timestamp: 2022-08-20 08:41:53.581458\n",
      "resetting env. episode 3754, reward total was -20.0. running mean: -17.869896712351252, timestamp: 2022-08-20 08:41:55.580482\n",
      "resetting env. episode 3755, reward total was -17.0. running mean: -17.86119774522774, timestamp: 2022-08-20 08:41:58.356517\n",
      "resetting env. episode 3756, reward total was -20.0. running mean: -17.882585767775463, timestamp: 2022-08-20 08:42:00.398544\n",
      "resetting env. episode 3757, reward total was -18.0. running mean: -17.88375991009771, timestamp: 2022-08-20 08:42:02.238565\n",
      "resetting env. episode 3758, reward total was -16.0. running mean: -17.864922310996732, timestamp: 2022-08-20 08:42:04.089585\n",
      "resetting env. episode 3759, reward total was -15.0. running mean: -17.836273087886763, timestamp: 2022-08-20 08:42:06.526617\n",
      "resetting env. episode 3760, reward total was -21.0. running mean: -17.867910357007897, timestamp: 2022-08-20 08:42:08.760647\n",
      "resetting env. episode 3761, reward total was -20.0. running mean: -17.889231253437817, timestamp: 2022-08-20 08:42:10.462664\n",
      "resetting env. episode 3762, reward total was -15.0. running mean: -17.860338940903436, timestamp: 2022-08-20 08:42:13.223704\n",
      "resetting env. episode 3763, reward total was -20.0. running mean: -17.8817355514944, timestamp: 2022-08-20 08:42:15.009719\n",
      "resetting env. episode 3764, reward total was -21.0. running mean: -17.912918195979458, timestamp: 2022-08-20 08:42:16.482739\n",
      "resetting env. episode 3765, reward total was -18.0. running mean: -17.913789014019663, timestamp: 2022-08-20 08:42:18.724770\n",
      "resetting env. episode 3766, reward total was -20.0. running mean: -17.934651123879465, timestamp: 2022-08-20 08:42:20.665789\n",
      "resetting env. episode 3767, reward total was -16.0. running mean: -17.91530461264067, timestamp: 2022-08-20 08:42:23.658828\n",
      "resetting env. episode 3768, reward total was -19.0. running mean: -17.926151566514267, timestamp: 2022-08-20 08:42:25.923861\n",
      "resetting env. episode 3769, reward total was -19.0. running mean: -17.936890050849126, timestamp: 2022-08-20 08:42:28.414887\n",
      "resetting env. episode 3770, reward total was -21.0. running mean: -17.967521150340634, timestamp: 2022-08-20 08:42:30.068904\n",
      "resetting env. episode 3771, reward total was -21.0. running mean: -17.997845938837226, timestamp: 2022-08-20 08:42:32.387937\n",
      "resetting env. episode 3772, reward total was -14.0. running mean: -17.957867479448854, timestamp: 2022-08-20 08:42:35.251970\n",
      "resetting env. episode 3773, reward total was -20.0. running mean: -17.978288804654365, timestamp: 2022-08-20 08:42:36.751988\n",
      "resetting env. episode 3774, reward total was -19.0. running mean: -17.988505916607824, timestamp: 2022-08-20 08:42:38.666011\n",
      "resetting env. episode 3775, reward total was -18.0. running mean: -17.988620857441745, timestamp: 2022-08-20 08:42:40.759040\n",
      "resetting env. episode 3776, reward total was -21.0. running mean: -18.01873464886733, timestamp: 2022-08-20 08:42:43.138069\n",
      "resetting env. episode 3777, reward total was -11.0. running mean: -17.948547302378657, timestamp: 2022-08-20 08:42:46.427108\n",
      "resetting env. episode 3778, reward total was -17.0. running mean: -17.939061829354873, timestamp: 2022-08-20 08:42:49.308146\n",
      "resetting env. episode 3779, reward total was -21.0. running mean: -17.969671211061325, timestamp: 2022-08-20 08:42:50.891163\n",
      "resetting env. episode 3780, reward total was -19.0. running mean: -17.979974498950714, timestamp: 2022-08-20 08:42:53.210188\n",
      "resetting env. episode 3781, reward total was -20.0. running mean: -18.000174753961208, timestamp: 2022-08-20 08:42:54.841210\n",
      "resetting env. episode 3782, reward total was -18.0. running mean: -18.000173006421594, timestamp: 2022-08-20 08:42:57.963250\n",
      "resetting env. episode 3783, reward total was -18.0. running mean: -18.000171276357378, timestamp: 2022-08-20 08:42:59.483271\n",
      "resetting env. episode 3784, reward total was -20.0. running mean: -18.020169563593804, timestamp: 2022-08-20 08:43:01.157287\n",
      "resetting env. episode 3785, reward total was -18.0. running mean: -18.019967867957867, timestamp: 2022-08-20 08:43:03.844325\n",
      "resetting env. episode 3786, reward total was -16.0. running mean: -17.99976818927829, timestamp: 2022-08-20 08:43:05.984356\n",
      "resetting env. episode 3787, reward total was -20.0. running mean: -18.019770507385505, timestamp: 2022-08-20 08:43:07.654368\n",
      "resetting env. episode 3788, reward total was -20.0. running mean: -18.03957280231165, timestamp: 2022-08-20 08:43:09.715397\n",
      "resetting env. episode 3789, reward total was -18.0. running mean: -18.03917707428853, timestamp: 2022-08-20 08:43:12.350429\n",
      "resetting env. episode 3790, reward total was -19.0. running mean: -18.048785303545646, timestamp: 2022-08-20 08:43:14.476974\n",
      "resetting env. episode 3791, reward total was -19.0. running mean: -18.058297450510192, timestamp: 2022-08-20 08:43:16.115002\n",
      "resetting env. episode 3792, reward total was -19.0. running mean: -18.06771447600509, timestamp: 2022-08-20 08:43:17.789015\n",
      "resetting env. episode 3793, reward total was -19.0. running mean: -18.07703733124504, timestamp: 2022-08-20 08:43:20.111047\n",
      "resetting env. episode 3794, reward total was -21.0. running mean: -18.10626695793259, timestamp: 2022-08-20 08:43:22.359075\n",
      "resetting env. episode 3795, reward total was -19.0. running mean: -18.115204288353265, timestamp: 2022-08-20 08:43:25.469115\n",
      "resetting env. episode 3796, reward total was -19.0. running mean: -18.124052245469734, timestamp: 2022-08-20 08:43:28.181150\n",
      "resetting env. episode 3797, reward total was -19.0. running mean: -18.13281172301504, timestamp: 2022-08-20 08:43:29.847169\n",
      "resetting env. episode 3798, reward total was -18.0. running mean: -18.131483605784886, timestamp: 2022-08-20 08:43:32.460196\n",
      "resetting env. episode 3799, reward total was -18.0. running mean: -18.13016876972704, timestamp: 2022-08-20 08:43:34.779226\n",
      "resetting env. episode 3800, reward total was -21.0. running mean: -18.15886708202977, timestamp: 2022-08-20 08:43:36.281244\n",
      "resetting env. episode 3801, reward total was -18.0. running mean: -18.15727841120947, timestamp: 2022-08-20 08:43:38.807276\n",
      "resetting env. episode 3802, reward total was -19.0. running mean: -18.165705627097378, timestamp: 2022-08-20 08:43:41.010302\n",
      "resetting env. episode 3803, reward total was -18.0. running mean: -18.164048570826402, timestamp: 2022-08-20 08:43:43.613334\n",
      "resetting env. episode 3804, reward total was -18.0. running mean: -18.162408085118138, timestamp: 2022-08-20 08:43:45.715361\n",
      "resetting env. episode 3805, reward total was -19.0. running mean: -18.170784004266956, timestamp: 2022-08-20 08:43:48.352394\n",
      "resetting env. episode 3806, reward total was -21.0. running mean: -18.199076164224287, timestamp: 2022-08-20 08:43:50.392419\n",
      "resetting env. episode 3807, reward total was -17.0. running mean: -18.187085402582046, timestamp: 2022-08-20 08:43:52.415441\n",
      "resetting env. episode 3808, reward total was -21.0. running mean: -18.215214548556226, timestamp: 2022-08-20 08:43:53.690459\n",
      "resetting env. episode 3809, reward total was -17.0. running mean: -18.203062403070664, timestamp: 2022-08-20 08:43:56.258491\n",
      "resetting env. episode 3810, reward total was -20.0. running mean: -18.221031779039958, timestamp: 2022-08-20 08:43:57.838506\n",
      "resetting env. episode 3811, reward total was -20.0. running mean: -18.238821461249557, timestamp: 2022-08-20 08:43:59.631533\n",
      "resetting env. episode 3812, reward total was -16.0. running mean: -18.216433246637063, timestamp: 2022-08-20 08:44:02.527565\n",
      "resetting env. episode 3813, reward total was -15.0. running mean: -18.18426891417069, timestamp: 2022-08-20 08:44:04.593592\n",
      "resetting env. episode 3814, reward total was -18.0. running mean: -18.182426225028983, timestamp: 2022-08-20 08:44:07.737629\n",
      "resetting env. episode 3815, reward total was -21.0. running mean: -18.210601962778693, timestamp: 2022-08-20 08:44:10.046656\n",
      "resetting env. episode 3816, reward total was -20.0. running mean: -18.228495943150904, timestamp: 2022-08-20 08:44:12.649689\n",
      "resetting env. episode 3817, reward total was -21.0. running mean: -18.256210983719395, timestamp: 2022-08-20 08:44:13.837703\n",
      "resetting env. episode 3818, reward total was -18.0. running mean: -18.253648873882202, timestamp: 2022-08-20 08:44:16.287735\n",
      "resetting env. episode 3819, reward total was -19.0. running mean: -18.26111238514338, timestamp: 2022-08-20 08:44:18.659764\n",
      "resetting env. episode 3820, reward total was -19.0. running mean: -18.26850126129195, timestamp: 2022-08-20 08:44:21.053792\n",
      "resetting env. episode 3821, reward total was -20.0. running mean: -18.28581624867903, timestamp: 2022-08-20 08:44:23.409822\n",
      "resetting env. episode 3822, reward total was -18.0. running mean: -18.282958086192238, timestamp: 2022-08-20 08:44:25.765847\n",
      "resetting env. episode 3823, reward total was -13.0. running mean: -18.230128505330313, timestamp: 2022-08-20 08:44:28.643884\n",
      "resetting env. episode 3824, reward total was -18.0. running mean: -18.22782722027701, timestamp: 2022-08-20 08:44:30.604907\n",
      "resetting env. episode 3825, reward total was -14.0. running mean: -18.185548948074242, timestamp: 2022-08-20 08:44:33.169943\n",
      "resetting env. episode 3826, reward total was -16.0. running mean: -18.1636934585935, timestamp: 2022-08-20 08:44:35.727969\n",
      "resetting env. episode 3827, reward total was -19.0. running mean: -18.172056524007566, timestamp: 2022-08-20 08:44:37.966997\n",
      "resetting env. episode 3828, reward total was -21.0. running mean: -18.20033595876749, timestamp: 2022-08-20 08:44:40.017024\n",
      "resetting env. episode 3829, reward total was -21.0. running mean: -18.228332599179815, timestamp: 2022-08-20 08:44:41.586043\n",
      "resetting env. episode 3830, reward total was -14.0. running mean: -18.18604927318802, timestamp: 2022-08-20 08:44:44.683079\n",
      "resetting env. episode 3831, reward total was -17.0. running mean: -18.17418878045614, timestamp: 2022-08-20 08:44:47.088113\n",
      "resetting env. episode 3832, reward total was -17.0. running mean: -18.16244689265158, timestamp: 2022-08-20 08:44:49.612140\n",
      "resetting env. episode 3833, reward total was -19.0. running mean: -18.170822423725067, timestamp: 2022-08-20 08:44:52.457177\n",
      "resetting env. episode 3834, reward total was -21.0. running mean: -18.199114199487816, timestamp: 2022-08-20 08:44:54.122200\n",
      "resetting env. episode 3835, reward total was -17.0. running mean: -18.18712305749294, timestamp: 2022-08-20 08:44:56.527224\n",
      "resetting env. episode 3836, reward total was -17.0. running mean: -18.17525182691801, timestamp: 2022-08-20 08:44:58.776253\n",
      "resetting env. episode 3837, reward total was -17.0. running mean: -18.16349930864883, timestamp: 2022-08-20 08:45:01.324284\n",
      "resetting env. episode 3838, reward total was -20.0. running mean: -18.18186431556234, timestamp: 2022-08-20 08:45:03.177310\n",
      "resetting env. episode 3839, reward total was -15.0. running mean: -18.150045672406716, timestamp: 2022-08-20 08:45:05.403336\n",
      "resetting env. episode 3840, reward total was -21.0. running mean: -18.17854521568265, timestamp: 2022-08-20 08:45:07.590362\n",
      "resetting env. episode 3841, reward total was -18.0. running mean: -18.176759763525823, timestamp: 2022-08-20 08:45:09.954394\n",
      "resetting env. episode 3842, reward total was -18.0. running mean: -18.174992165890565, timestamp: 2022-08-20 08:45:12.334423\n",
      "resetting env. episode 3843, reward total was -15.0. running mean: -18.143242244231658, timestamp: 2022-08-20 08:45:16.253468\n",
      "resetting env. episode 3844, reward total was -20.0. running mean: -18.16180982178934, timestamp: 2022-08-20 08:45:17.826487\n",
      "resetting env. episode 3845, reward total was -16.0. running mean: -18.140191723571448, timestamp: 2022-08-20 08:45:20.989526\n",
      "resetting env. episode 3846, reward total was -19.0. running mean: -18.148789806335735, timestamp: 2022-08-20 08:45:23.708559\n",
      "resetting env. episode 3847, reward total was -20.0. running mean: -18.16730190827238, timestamp: 2022-08-20 08:45:25.531583\n",
      "resetting env. episode 3848, reward total was -15.0. running mean: -18.135628889189654, timestamp: 2022-08-20 08:45:28.833621\n",
      "resetting env. episode 3849, reward total was -19.0. running mean: -18.144272600297757, timestamp: 2022-08-20 08:45:30.365645\n",
      "resetting env. episode 3850, reward total was -19.0. running mean: -18.15282987429478, timestamp: 2022-08-20 08:45:32.968672\n",
      "resetting env. episode 3851, reward total was -16.0. running mean: -18.131301575551834, timestamp: 2022-08-20 08:45:36.138711\n",
      "resetting env. episode 3852, reward total was -18.0. running mean: -18.129988559796317, timestamp: 2022-08-20 08:45:38.657744\n",
      "resetting env. episode 3853, reward total was -20.0. running mean: -18.148688674198354, timestamp: 2022-08-20 08:45:40.381763\n",
      "resetting env. episode 3854, reward total was -19.0. running mean: -18.157201787456373, timestamp: 2022-08-20 08:45:42.080785\n",
      "resetting env. episode 3855, reward total was -19.0. running mean: -18.16562976958181, timestamp: 2022-08-20 08:45:44.704818\n",
      "resetting env. episode 3856, reward total was -20.0. running mean: -18.18397347188599, timestamp: 2022-08-20 08:45:46.615841\n",
      "resetting env. episode 3857, reward total was -21.0. running mean: -18.212133737167132, timestamp: 2022-08-20 08:45:47.906855\n",
      "resetting env. episode 3858, reward total was -20.0. running mean: -18.23001239979546, timestamp: 2022-08-20 08:45:50.101884\n",
      "resetting env. episode 3859, reward total was -18.0. running mean: -18.227712275797504, timestamp: 2022-08-20 08:45:52.391912\n",
      "resetting env. episode 3860, reward total was -18.0. running mean: -18.22543515303953, timestamp: 2022-08-20 08:45:55.024943\n",
      "resetting env. episode 3861, reward total was -19.0. running mean: -18.233180801509135, timestamp: 2022-08-20 08:45:57.844978\n",
      "resetting env. episode 3862, reward total was -20.0. running mean: -18.250848993494042, timestamp: 2022-08-20 08:45:59.702000\n",
      "resetting env. episode 3863, reward total was -19.0. running mean: -18.258340503559104, timestamp: 2022-08-20 08:46:01.966030\n",
      "resetting env. episode 3864, reward total was -15.0. running mean: -18.225757098523513, timestamp: 2022-08-20 08:46:05.012066\n",
      "resetting env. episode 3865, reward total was -18.0. running mean: -18.223499527538277, timestamp: 2022-08-20 08:46:07.259095\n",
      "resetting env. episode 3866, reward total was -13.0. running mean: -18.171264532262892, timestamp: 2022-08-20 08:46:10.204138\n",
      "resetting env. episode 3867, reward total was -17.0. running mean: -18.159551886940264, timestamp: 2022-08-20 08:46:13.064173\n",
      "resetting env. episode 3868, reward total was -18.0. running mean: -18.15795636807086, timestamp: 2022-08-20 08:46:15.339201\n",
      "resetting env. episode 3869, reward total was -15.0. running mean: -18.126376804390148, timestamp: 2022-08-20 08:46:17.994227\n",
      "resetting env. episode 3870, reward total was -14.0. running mean: -18.085113036346247, timestamp: 2022-08-20 08:46:20.624257\n",
      "resetting env. episode 3871, reward total was -18.0. running mean: -18.084261905982785, timestamp: 2022-08-20 08:46:22.895290\n",
      "resetting env. episode 3872, reward total was -16.0. running mean: -18.063419286922958, timestamp: 2022-08-20 08:46:25.578320\n",
      "resetting env. episode 3873, reward total was -17.0. running mean: -18.05278509405373, timestamp: 2022-08-20 08:46:27.963352\n",
      "resetting env. episode 3874, reward total was -14.0. running mean: -18.01225724311319, timestamp: 2022-08-20 08:46:30.717383\n",
      "resetting env. episode 3875, reward total was -18.0. running mean: -18.01213467068206, timestamp: 2022-08-20 08:46:33.386421\n",
      "resetting env. episode 3876, reward total was -18.0. running mean: -18.01201332397524, timestamp: 2022-08-20 08:46:36.127451\n",
      "resetting env. episode 3877, reward total was -20.0. running mean: -18.031893190735484, timestamp: 2022-08-20 08:46:38.344477\n",
      "resetting env. episode 3878, reward total was -19.0. running mean: -18.04157425882813, timestamp: 2022-08-20 08:46:40.727510\n",
      "resetting env. episode 3879, reward total was -18.0. running mean: -18.04115851623985, timestamp: 2022-08-20 08:46:43.658542\n",
      "resetting env. episode 3880, reward total was -18.0. running mean: -18.04074693107745, timestamp: 2022-08-20 08:46:46.271575\n",
      "resetting env. episode 3881, reward total was -13.0. running mean: -17.990339461766673, timestamp: 2022-08-20 08:46:49.087609\n",
      "resetting env. episode 3882, reward total was -17.0. running mean: -17.980436067149007, timestamp: 2022-08-20 08:46:51.544643\n",
      "resetting env. episode 3883, reward total was -19.0. running mean: -17.99063170647752, timestamp: 2022-08-20 08:46:53.914670\n",
      "resetting env. episode 3884, reward total was -18.0. running mean: -17.99072538941274, timestamp: 2022-08-20 08:46:55.889698\n",
      "resetting env. episode 3885, reward total was -17.0. running mean: -17.980818135518614, timestamp: 2022-08-20 08:46:58.422722\n",
      "resetting env. episode 3886, reward total was -19.0. running mean: -17.99100995416343, timestamp: 2022-08-20 08:47:00.896753\n",
      "resetting env. episode 3887, reward total was -19.0. running mean: -18.0010998546218, timestamp: 2022-08-20 08:47:03.110780\n",
      "resetting env. episode 3888, reward total was -16.0. running mean: -17.98108885607558, timestamp: 2022-08-20 08:47:05.451809\n",
      "resetting env. episode 3889, reward total was -18.0. running mean: -17.981277967514824, timestamp: 2022-08-20 08:47:08.148845\n",
      "resetting env. episode 3890, reward total was -12.0. running mean: -17.921465187839676, timestamp: 2022-08-20 08:47:11.201876\n",
      "resetting env. episode 3891, reward total was -21.0. running mean: -17.95225053596128, timestamp: 2022-08-20 08:47:13.184905\n",
      "resetting env. episode 3892, reward total was -17.0. running mean: -17.942728030601668, timestamp: 2022-08-20 08:47:15.786936\n",
      "resetting env. episode 3893, reward total was -17.0. running mean: -17.933300750295654, timestamp: 2022-08-20 08:47:18.136965\n",
      "resetting env. episode 3894, reward total was -13.0. running mean: -17.883967742792695, timestamp: 2022-08-20 08:47:20.462993\n",
      "resetting env. episode 3895, reward total was -17.0. running mean: -17.87512806536477, timestamp: 2022-08-20 08:47:23.204028\n",
      "resetting env. episode 3896, reward total was -19.0. running mean: -17.886376784711125, timestamp: 2022-08-20 08:47:25.650056\n",
      "resetting env. episode 3897, reward total was -18.0. running mean: -17.887513016864013, timestamp: 2022-08-20 08:47:28.226087\n",
      "resetting env. episode 3898, reward total was -20.0. running mean: -17.90863788669537, timestamp: 2022-08-20 08:47:30.596118\n",
      "resetting env. episode 3899, reward total was -19.0. running mean: -17.919551507828416, timestamp: 2022-08-20 08:47:32.977145\n",
      "resetting env. episode 3900, reward total was -18.0. running mean: -17.92035599275013, timestamp: 2022-08-20 08:47:35.653178\n",
      "resetting env. episode 3901, reward total was -19.0. running mean: -17.931152432822632, timestamp: 2022-08-20 08:47:38.165208\n",
      "resetting env. episode 3902, reward total was -17.0. running mean: -17.921840908494406, timestamp: 2022-08-20 08:47:40.312233\n",
      "resetting env. episode 3903, reward total was -21.0. running mean: -17.952622499409465, timestamp: 2022-08-20 08:47:42.681261\n",
      "resetting env. episode 3904, reward total was -17.0. running mean: -17.94309627441537, timestamp: 2022-08-20 08:47:45.802300\n",
      "resetting env. episode 3905, reward total was -19.0. running mean: -17.95366531167122, timestamp: 2022-08-20 08:47:48.218331\n",
      "resetting env. episode 3906, reward total was -18.0. running mean: -17.954128658554506, timestamp: 2022-08-20 08:47:50.809363\n",
      "resetting env. episode 3907, reward total was -15.0. running mean: -17.924587371968958, timestamp: 2022-08-20 08:47:54.091402\n",
      "resetting env. episode 3908, reward total was -18.0. running mean: -17.925341498249267, timestamp: 2022-08-20 08:47:55.912425\n",
      "resetting env. episode 3909, reward total was -19.0. running mean: -17.936088083266775, timestamp: 2022-08-20 08:47:58.327457\n",
      "resetting env. episode 3910, reward total was -17.0. running mean: -17.926727202434108, timestamp: 2022-08-20 08:48:01.641493\n",
      "resetting env. episode 3911, reward total was -15.0. running mean: -17.897459930409767, timestamp: 2022-08-20 08:48:04.267525\n",
      "resetting env. episode 3912, reward total was -17.0. running mean: -17.88848533110567, timestamp: 2022-08-20 08:48:06.273552\n",
      "resetting env. episode 3913, reward total was -17.0. running mean: -17.879600477794614, timestamp: 2022-08-20 08:48:09.379587\n",
      "resetting env. episode 3914, reward total was -20.0. running mean: -17.900804473016667, timestamp: 2022-08-20 08:48:11.540616\n",
      "resetting env. episode 3915, reward total was -18.0. running mean: -17.9017964282865, timestamp: 2022-08-20 08:48:14.603653\n",
      "resetting env. episode 3916, reward total was -17.0. running mean: -17.892778464003634, timestamp: 2022-08-20 08:48:16.898688\n",
      "resetting env. episode 3917, reward total was -18.0. running mean: -17.893850679363595, timestamp: 2022-08-20 08:48:19.799716\n",
      "resetting env. episode 3918, reward total was -21.0. running mean: -17.92491217256996, timestamp: 2022-08-20 08:48:22.097743\n",
      "resetting env. episode 3919, reward total was -19.0. running mean: -17.935663050844262, timestamp: 2022-08-20 08:48:23.950767\n",
      "resetting env. episode 3920, reward total was -19.0. running mean: -17.94630642033582, timestamp: 2022-08-20 08:48:26.132792\n",
      "resetting env. episode 3921, reward total was -21.0. running mean: -17.976843356132463, timestamp: 2022-08-20 08:48:28.189816\n",
      "resetting env. episode 3922, reward total was -17.0. running mean: -17.96707492257114, timestamp: 2022-08-20 08:48:30.538845\n",
      "resetting env. episode 3923, reward total was -18.0. running mean: -17.96740417334543, timestamp: 2022-08-20 08:48:32.948875\n",
      "resetting env. episode 3924, reward total was -17.0. running mean: -17.957730131611974, timestamp: 2022-08-20 08:48:35.259903\n",
      "resetting env. episode 3925, reward total was -19.0. running mean: -17.968152830295857, timestamp: 2022-08-20 08:48:38.119938\n",
      "resetting env. episode 3926, reward total was -20.0. running mean: -17.9884713019929, timestamp: 2022-08-20 08:48:40.535968\n",
      "resetting env. episode 3927, reward total was -21.0. running mean: -18.01858658897297, timestamp: 2022-08-20 08:48:43.153999\n",
      "resetting env. episode 3928, reward total was -20.0. running mean: -18.03840072308324, timestamp: 2022-08-20 08:48:45.120025\n",
      "resetting env. episode 3929, reward total was -16.0. running mean: -18.018016715852408, timestamp: 2022-08-20 08:48:47.812056\n",
      "resetting env. episode 3930, reward total was -15.0. running mean: -17.98783654869388, timestamp: 2022-08-20 08:48:50.920097\n",
      "resetting env. episode 3931, reward total was -14.0. running mean: -17.947958183206943, timestamp: 2022-08-20 08:48:54.080140\n",
      "resetting env. episode 3932, reward total was -17.0. running mean: -17.938478601374875, timestamp: 2022-08-20 08:48:57.214174\n",
      "resetting env. episode 3933, reward total was -16.0. running mean: -17.919093815361126, timestamp: 2022-08-20 08:48:59.490208\n",
      "resetting env. episode 3934, reward total was -19.0. running mean: -17.929902877207518, timestamp: 2022-08-20 08:49:01.952229\n",
      "resetting env. episode 3935, reward total was -16.0. running mean: -17.910603848435443, timestamp: 2022-08-20 08:49:04.579262\n",
      "resetting env. episode 3936, reward total was -19.0. running mean: -17.921497809951088, timestamp: 2022-08-20 08:49:07.117291\n",
      "resetting env. episode 3937, reward total was -19.0. running mean: -17.932282831851577, timestamp: 2022-08-20 08:49:09.549321\n",
      "resetting env. episode 3938, reward total was -17.0. running mean: -17.922960003533063, timestamp: 2022-08-20 08:49:11.804351\n",
      "resetting env. episode 3939, reward total was -19.0. running mean: -17.933730403497734, timestamp: 2022-08-20 08:49:13.777377\n",
      "resetting env. episode 3940, reward total was -16.0. running mean: -17.914393099462757, timestamp: 2022-08-20 08:49:16.839411\n",
      "resetting env. episode 3941, reward total was -18.0. running mean: -17.91524916846813, timestamp: 2022-08-20 08:49:19.836446\n",
      "resetting env. episode 3942, reward total was -17.0. running mean: -17.90609667678345, timestamp: 2022-08-20 08:49:22.552480\n",
      "resetting env. episode 3943, reward total was -17.0. running mean: -17.897035710015615, timestamp: 2022-08-20 08:49:25.465517\n",
      "resetting env. episode 3944, reward total was -20.0. running mean: -17.91806535291546, timestamp: 2022-08-20 08:49:28.618555\n",
      "resetting env. episode 3945, reward total was -17.0. running mean: -17.908884699386306, timestamp: 2022-08-20 08:49:30.842581\n",
      "resetting env. episode 3946, reward total was -20.0. running mean: -17.92979585239244, timestamp: 2022-08-20 08:49:33.582139\n",
      "resetting env. episode 3947, reward total was -19.0. running mean: -17.940497893868518, timestamp: 2022-08-20 08:49:35.721166\n",
      "resetting env. episode 3948, reward total was -16.0. running mean: -17.921092914929833, timestamp: 2022-08-20 08:49:37.726191\n",
      "resetting env. episode 3949, reward total was -18.0. running mean: -17.921881985780534, timestamp: 2022-08-20 08:49:40.019216\n",
      "resetting env. episode 3950, reward total was -16.0. running mean: -17.90266316592273, timestamp: 2022-08-20 08:49:41.878239\n",
      "resetting env. episode 3951, reward total was -17.0. running mean: -17.893636534263504, timestamp: 2022-08-20 08:49:44.608276\n",
      "resetting env. episode 3952, reward total was -16.0. running mean: -17.874700168920867, timestamp: 2022-08-20 08:49:47.641310\n",
      "resetting env. episode 3953, reward total was -17.0. running mean: -17.86595316723166, timestamp: 2022-08-20 08:49:51.005357\n",
      "resetting env. episode 3954, reward total was -21.0. running mean: -17.897293635559343, timestamp: 2022-08-20 08:49:52.715380\n",
      "resetting env. episode 3955, reward total was -18.0. running mean: -17.89832069920375, timestamp: 2022-08-20 08:49:55.069401\n",
      "resetting env. episode 3956, reward total was -20.0. running mean: -17.919337492211714, timestamp: 2022-08-20 08:49:57.514431\n",
      "resetting env. episode 3957, reward total was -15.0. running mean: -17.890144117289594, timestamp: 2022-08-20 08:49:59.983462\n",
      "resetting env. episode 3958, reward total was -18.0. running mean: -17.891242676116697, timestamp: 2022-08-20 08:50:02.737494\n",
      "resetting env. episode 3959, reward total was -16.0. running mean: -17.87233024935553, timestamp: 2022-08-20 08:50:06.232535\n",
      "resetting env. episode 3960, reward total was -18.0. running mean: -17.873606946861976, timestamp: 2022-08-20 08:50:08.544564\n",
      "resetting env. episode 3961, reward total was -20.0. running mean: -17.894870877393355, timestamp: 2022-08-20 08:50:10.489591\n",
      "resetting env. episode 3962, reward total was -19.0. running mean: -17.905922168619423, timestamp: 2022-08-20 08:50:12.886617\n",
      "resetting env. episode 3963, reward total was -15.0. running mean: -17.876862946933226, timestamp: 2022-08-20 08:50:15.371648\n",
      "resetting env. episode 3964, reward total was -18.0. running mean: -17.878094317463894, timestamp: 2022-08-20 08:50:17.928683\n",
      "resetting env. episode 3965, reward total was -20.0. running mean: -17.899313374289253, timestamp: 2022-08-20 08:50:20.172707\n",
      "resetting env. episode 3966, reward total was -20.0. running mean: -17.92032024054636, timestamp: 2022-08-20 08:50:22.787739\n",
      "resetting env. episode 3967, reward total was -21.0. running mean: -17.951117038140897, timestamp: 2022-08-20 08:50:26.103781\n",
      "resetting env. episode 3968, reward total was -17.0. running mean: -17.94160586775949, timestamp: 2022-08-20 08:50:28.775814\n",
      "resetting env. episode 3969, reward total was -16.0. running mean: -17.922189809081893, timestamp: 2022-08-20 08:50:31.976852\n",
      "resetting env. episode 3970, reward total was -19.0. running mean: -17.932967910991074, timestamp: 2022-08-20 08:50:34.537880\n",
      "resetting env. episode 3971, reward total was -19.0. running mean: -17.943638231881163, timestamp: 2022-08-20 08:50:36.582907\n",
      "resetting env. episode 3972, reward total was -17.0. running mean: -17.934201849562353, timestamp: 2022-08-20 08:50:39.243939\n",
      "resetting env. episode 3973, reward total was -16.0. running mean: -17.914859831066728, timestamp: 2022-08-20 08:50:42.269981\n",
      "resetting env. episode 3974, reward total was -19.0. running mean: -17.92571123275606, timestamp: 2022-08-20 08:50:44.435003\n",
      "resetting env. episode 3975, reward total was -15.0. running mean: -17.896454120428498, timestamp: 2022-08-20 08:50:46.857033\n",
      "resetting env. episode 3976, reward total was -18.0. running mean: -17.897489579224214, timestamp: 2022-08-20 08:50:49.334063\n",
      "resetting env. episode 3977, reward total was -20.0. running mean: -17.918514683431972, timestamp: 2022-08-20 08:50:52.150096\n",
      "resetting env. episode 3978, reward total was -17.0. running mean: -17.909329536597653, timestamp: 2022-08-20 08:50:55.283138\n",
      "resetting env. episode 3979, reward total was -19.0. running mean: -17.920236241231677, timestamp: 2022-08-20 08:50:57.026161\n",
      "resetting env. episode 3980, reward total was -19.0. running mean: -17.931033878819363, timestamp: 2022-08-20 08:51:00.174197\n",
      "resetting env. episode 3981, reward total was -17.0. running mean: -17.92172354003117, timestamp: 2022-08-20 08:51:03.140231\n",
      "resetting env. episode 3982, reward total was -19.0. running mean: -17.93250630463086, timestamp: 2022-08-20 08:51:04.792250\n",
      "resetting env. episode 3983, reward total was -17.0. running mean: -17.92318124158455, timestamp: 2022-08-20 08:51:07.265807\n",
      "resetting env. episode 3984, reward total was -15.0. running mean: -17.893949429168703, timestamp: 2022-08-20 08:51:09.815841\n",
      "resetting env. episode 3985, reward total was -20.0. running mean: -17.915009934877016, timestamp: 2022-08-20 08:51:12.220865\n",
      "resetting env. episode 3986, reward total was -14.0. running mean: -17.875859835528246, timestamp: 2022-08-20 08:51:15.064903\n",
      "resetting env. episode 3987, reward total was -18.0. running mean: -17.877101237172962, timestamp: 2022-08-20 08:51:17.562935\n",
      "resetting env. episode 3988, reward total was -16.0. running mean: -17.858330224801232, timestamp: 2022-08-20 08:51:20.984972\n",
      "resetting env. episode 3989, reward total was -18.0. running mean: -17.85974692255322, timestamp: 2022-08-20 08:51:23.716005\n",
      "resetting env. episode 3990, reward total was -20.0. running mean: -17.881149453327687, timestamp: 2022-08-20 08:51:25.902031\n",
      "resetting env. episode 3991, reward total was -18.0. running mean: -17.88233795879441, timestamp: 2022-08-20 08:51:28.686065\n",
      "resetting env. episode 3992, reward total was -18.0. running mean: -17.883514579206466, timestamp: 2022-08-20 08:51:30.939092\n",
      "resetting env. episode 3993, reward total was -19.0. running mean: -17.894679433414403, timestamp: 2022-08-20 08:51:34.061130\n",
      "resetting env. episode 3994, reward total was -14.0. running mean: -17.85573263908026, timestamp: 2022-08-20 08:51:37.261168\n",
      "resetting env. episode 3995, reward total was -9.0. running mean: -17.767175312689456, timestamp: 2022-08-20 08:51:41.801233\n",
      "resetting env. episode 3996, reward total was -19.0. running mean: -17.779503559562563, timestamp: 2022-08-20 08:51:44.454256\n",
      "resetting env. episode 3997, reward total was -19.0. running mean: -17.79170852396694, timestamp: 2022-08-20 08:51:47.167288\n",
      "resetting env. episode 3998, reward total was -16.0. running mean: -17.77379143872727, timestamp: 2022-08-20 08:51:49.704320\n",
      "resetting env. episode 3999, reward total was -16.0. running mean: -17.756053524339997, timestamp: 2022-08-20 08:51:52.494358\n",
      "resetting env. episode 4000, reward total was -16.0. running mean: -17.738492989096596, timestamp: 2022-08-20 08:51:56.419403\n",
      "resetting env. episode 4001, reward total was -19.0. running mean: -17.75110805920563, timestamp: 2022-08-20 08:51:58.046423\n",
      "resetting env. episode 4002, reward total was -20.0. running mean: -17.773596978613575, timestamp: 2022-08-20 08:52:00.172452\n",
      "resetting env. episode 4003, reward total was -19.0. running mean: -17.785861008827442, timestamp: 2022-08-20 08:52:02.827478\n",
      "resetting env. episode 4004, reward total was -18.0. running mean: -17.788002398739167, timestamp: 2022-08-20 08:52:05.346511\n",
      "resetting env. episode 4005, reward total was -16.0. running mean: -17.770122374751775, timestamp: 2022-08-20 08:52:08.229548\n",
      "resetting env. episode 4006, reward total was -19.0. running mean: -17.782421151004257, timestamp: 2022-08-20 08:52:10.865579\n",
      "resetting env. episode 4007, reward total was -17.0. running mean: -17.774596939494216, timestamp: 2022-08-20 08:52:14.102617\n",
      "resetting env. episode 4008, reward total was -21.0. running mean: -17.806850970099276, timestamp: 2022-08-20 08:52:16.316643\n",
      "resetting env. episode 4009, reward total was -19.0. running mean: -17.818782460398285, timestamp: 2022-08-20 08:52:19.043677\n",
      "resetting env. episode 4010, reward total was -17.0. running mean: -17.810594635794303, timestamp: 2022-08-20 08:52:22.088712\n",
      "resetting env. episode 4011, reward total was -18.0. running mean: -17.81248868943636, timestamp: 2022-08-20 08:52:25.042747\n",
      "resetting env. episode 4012, reward total was -19.0. running mean: -17.824363802542, timestamp: 2022-08-20 08:52:28.483788\n",
      "resetting env. episode 4013, reward total was -20.0. running mean: -17.846120164516577, timestamp: 2022-08-20 08:52:30.780817\n",
      "resetting env. episode 4014, reward total was -19.0. running mean: -17.85765896287141, timestamp: 2022-08-20 08:52:33.376850\n",
      "resetting env. episode 4015, reward total was -16.0. running mean: -17.839082373242697, timestamp: 2022-08-20 08:52:36.750888\n",
      "resetting env. episode 4016, reward total was -18.0. running mean: -17.840691549510268, timestamp: 2022-08-20 08:52:39.711926\n",
      "resetting env. episode 4017, reward total was -18.0. running mean: -17.842284634015165, timestamp: 2022-08-20 08:52:42.501963\n",
      "resetting env. episode 4018, reward total was -15.0. running mean: -17.813861787675012, timestamp: 2022-08-20 08:52:45.399994\n",
      "resetting env. episode 4019, reward total was -18.0. running mean: -17.81572316979826, timestamp: 2022-08-20 08:52:48.004549\n",
      "resetting env. episode 4020, reward total was -16.0. running mean: -17.797565938100277, timestamp: 2022-08-20 08:52:50.422579\n",
      "resetting env. episode 4021, reward total was -12.0. running mean: -17.739590278719277, timestamp: 2022-08-20 08:52:54.305630\n",
      "resetting env. episode 4022, reward total was -13.0. running mean: -17.692194375932083, timestamp: 2022-08-20 08:52:57.506664\n",
      "resetting env. episode 4023, reward total was -21.0. running mean: -17.725272432172762, timestamp: 2022-08-20 08:53:00.095701\n",
      "resetting env. episode 4024, reward total was -18.0. running mean: -17.728019707851033, timestamp: 2022-08-20 08:53:02.382723\n",
      "resetting env. episode 4025, reward total was -16.0. running mean: -17.710739510772523, timestamp: 2022-08-20 08:53:04.913755\n",
      "resetting env. episode 4026, reward total was -18.0. running mean: -17.713632115664797, timestamp: 2022-08-20 08:53:08.305797\n",
      "resetting env. episode 4027, reward total was -15.0. running mean: -17.686495794508147, timestamp: 2022-08-20 08:53:10.491821\n",
      "resetting env. episode 4028, reward total was -16.0. running mean: -17.669630836563066, timestamp: 2022-08-20 08:53:13.844864\n",
      "resetting env. episode 4029, reward total was -20.0. running mean: -17.692934528197434, timestamp: 2022-08-20 08:53:16.357896\n",
      "resetting env. episode 4030, reward total was -18.0. running mean: -17.69600518291546, timestamp: 2022-08-20 08:53:18.846922\n",
      "resetting env. episode 4031, reward total was -17.0. running mean: -17.689045131086306, timestamp: 2022-08-20 08:53:21.439953\n",
      "resetting env. episode 4032, reward total was -18.0. running mean: -17.69215467977544, timestamp: 2022-08-20 08:53:24.443991\n",
      "resetting env. episode 4033, reward total was -19.0. running mean: -17.70523313297769, timestamp: 2022-08-20 08:53:26.145010\n",
      "resetting env. episode 4034, reward total was -17.0. running mean: -17.698180801647915, timestamp: 2022-08-20 08:53:28.832046\n",
      "resetting env. episode 4035, reward total was -17.0. running mean: -17.69119899363144, timestamp: 2022-08-20 08:53:31.071070\n",
      "resetting env. episode 4036, reward total was -19.0. running mean: -17.704287003695125, timestamp: 2022-08-20 08:53:33.432102\n",
      "resetting env. episode 4037, reward total was -18.0. running mean: -17.707244133658172, timestamp: 2022-08-20 08:53:36.488138\n",
      "resetting env. episode 4038, reward total was -16.0. running mean: -17.69017169232159, timestamp: 2022-08-20 08:53:39.195168\n",
      "resetting env. episode 4039, reward total was -21.0. running mean: -17.723269975398377, timestamp: 2022-08-20 08:53:42.011205\n",
      "resetting env. episode 4040, reward total was -14.0. running mean: -17.686037275644395, timestamp: 2022-08-20 08:53:45.808248\n",
      "resetting env. episode 4041, reward total was -18.0. running mean: -17.68917690288795, timestamp: 2022-08-20 08:53:48.742285\n",
      "resetting env. episode 4042, reward total was -18.0. running mean: -17.69228513385907, timestamp: 2022-08-20 08:53:50.994311\n",
      "resetting env. episode 4043, reward total was -19.0. running mean: -17.70536228252048, timestamp: 2022-08-20 08:53:53.413340\n",
      "resetting env. episode 4044, reward total was -12.0. running mean: -17.648308659695275, timestamp: 2022-08-20 08:53:56.471381\n",
      "resetting env. episode 4045, reward total was -18.0. running mean: -17.65182557309832, timestamp: 2022-08-20 08:53:58.969408\n",
      "resetting env. episode 4046, reward total was -15.0. running mean: -17.625307317367337, timestamp: 2022-08-20 08:54:02.495453\n",
      "resetting env. episode 4047, reward total was -16.0. running mean: -17.609054244193665, timestamp: 2022-08-20 08:54:05.027482\n",
      "resetting env. episode 4048, reward total was -16.0. running mean: -17.592963701751728, timestamp: 2022-08-20 08:54:08.395520\n",
      "resetting env. episode 4049, reward total was -20.0. running mean: -17.61703406473421, timestamp: 2022-08-20 08:54:10.698553\n",
      "resetting env. episode 4050, reward total was -16.0. running mean: -17.600863724086867, timestamp: 2022-08-20 08:54:13.895588\n",
      "resetting env. episode 4051, reward total was -17.0. running mean: -17.594855086846, timestamp: 2022-08-20 08:54:17.027629\n",
      "resetting env. episode 4052, reward total was -20.0. running mean: -17.61890653597754, timestamp: 2022-08-20 08:54:18.970653\n",
      "resetting env. episode 4053, reward total was -19.0. running mean: -17.632717470617767, timestamp: 2022-08-20 08:54:20.895674\n",
      "resetting env. episode 4054, reward total was -17.0. running mean: -17.62639029591159, timestamp: 2022-08-20 08:54:23.617709\n",
      "resetting env. episode 4055, reward total was -21.0. running mean: -17.660126392952474, timestamp: 2022-08-20 08:54:25.587734\n",
      "resetting env. episode 4056, reward total was -18.0. running mean: -17.66352512902295, timestamp: 2022-08-20 08:54:28.178288\n",
      "resetting env. episode 4057, reward total was -19.0. running mean: -17.676889877732723, timestamp: 2022-08-20 08:54:30.090311\n",
      "resetting env. episode 4058, reward total was -14.0. running mean: -17.640120978955395, timestamp: 2022-08-20 08:54:32.896347\n",
      "resetting env. episode 4059, reward total was -18.0. running mean: -17.64371976916584, timestamp: 2022-08-20 08:54:35.528375\n",
      "resetting env. episode 4060, reward total was -19.0. running mean: -17.657282571474184, timestamp: 2022-08-20 08:54:38.058408\n",
      "resetting env. episode 4061, reward total was -17.0. running mean: -17.650709745759443, timestamp: 2022-08-20 08:54:40.481436\n",
      "resetting env. episode 4062, reward total was -21.0. running mean: -17.68420264830185, timestamp: 2022-08-20 08:54:42.746466\n",
      "resetting env. episode 4063, reward total was -19.0. running mean: -17.69736062181883, timestamp: 2022-08-20 08:54:45.960504\n",
      "resetting env. episode 4064, reward total was -16.0. running mean: -17.680387015600644, timestamp: 2022-08-20 08:54:49.399544\n",
      "resetting env. episode 4065, reward total was -17.0. running mean: -17.67358314544464, timestamp: 2022-08-20 08:54:51.834578\n",
      "resetting env. episode 4066, reward total was -17.0. running mean: -17.666847313990193, timestamp: 2022-08-20 08:54:55.050614\n",
      "resetting env. episode 4067, reward total was -18.0. running mean: -17.67017884085029, timestamp: 2022-08-20 08:54:57.749646\n",
      "resetting env. episode 4068, reward total was -18.0. running mean: -17.673477052441786, timestamp: 2022-08-20 08:55:01.068688\n",
      "resetting env. episode 4069, reward total was -19.0. running mean: -17.68674228191737, timestamp: 2022-08-20 08:55:03.887725\n",
      "resetting env. episode 4070, reward total was -17.0. running mean: -17.679874859098195, timestamp: 2022-08-20 08:55:06.109751\n",
      "resetting env. episode 4071, reward total was -19.0. running mean: -17.693076110507214, timestamp: 2022-08-20 08:55:08.436776\n",
      "resetting env. episode 4072, reward total was -15.0. running mean: -17.66614534940214, timestamp: 2022-08-20 08:55:11.300814\n",
      "resetting env. episode 4073, reward total was -19.0. running mean: -17.67948389590812, timestamp: 2022-08-20 08:55:13.779843\n",
      "resetting env. episode 4074, reward total was -19.0. running mean: -17.69268905694904, timestamp: 2022-08-20 08:55:15.969870\n",
      "resetting env. episode 4075, reward total was -18.0. running mean: -17.69576216637955, timestamp: 2022-08-20 08:55:18.592900\n",
      "resetting env. episode 4076, reward total was -17.0. running mean: -17.688804544715754, timestamp: 2022-08-20 08:55:21.816941\n",
      "resetting env. episode 4077, reward total was -20.0. running mean: -17.711916499268597, timestamp: 2022-08-20 08:55:24.884976\n",
      "resetting env. episode 4078, reward total was -19.0. running mean: -17.724797334275912, timestamp: 2022-08-20 08:55:27.088009\n",
      "resetting env. episode 4079, reward total was -17.0. running mean: -17.717549360933155, timestamp: 2022-08-20 08:55:29.799039\n",
      "resetting env. episode 4080, reward total was -13.0. running mean: -17.67037386732382, timestamp: 2022-08-20 08:55:32.601074\n",
      "resetting env. episode 4081, reward total was -13.0. running mean: -17.62367012865058, timestamp: 2022-08-20 08:55:36.176115\n",
      "resetting env. episode 4082, reward total was -18.0. running mean: -17.627433427364075, timestamp: 2022-08-20 08:55:38.794149\n",
      "resetting env. episode 4083, reward total was -16.0. running mean: -17.611159093090436, timestamp: 2022-08-20 08:55:42.331713\n",
      "resetting env. episode 4084, reward total was -18.0. running mean: -17.61504750215953, timestamp: 2022-08-20 08:55:44.499739\n",
      "resetting env. episode 4085, reward total was -14.0. running mean: -17.578897027137934, timestamp: 2022-08-20 08:55:47.716778\n",
      "resetting env. episode 4086, reward total was -15.0. running mean: -17.553108056866552, timestamp: 2022-08-20 08:55:50.552820\n",
      "resetting env. episode 4087, reward total was -20.0. running mean: -17.577576976297888, timestamp: 2022-08-20 08:55:52.756840\n",
      "resetting env. episode 4088, reward total was -19.0. running mean: -17.59180120653491, timestamp: 2022-08-20 08:55:55.832880\n",
      "resetting env. episode 4089, reward total was -17.0. running mean: -17.585883194469563, timestamp: 2022-08-20 08:55:59.909930\n",
      "resetting env. episode 4090, reward total was -16.0. running mean: -17.57002436252487, timestamp: 2022-08-20 08:56:02.627959\n",
      "resetting env. episode 4091, reward total was -18.0. running mean: -17.574324118899618, timestamp: 2022-08-20 08:56:06.306006\n",
      "resetting env. episode 4092, reward total was -18.0. running mean: -17.57858087771062, timestamp: 2022-08-20 08:56:08.694036\n",
      "resetting env. episode 4093, reward total was -12.0. running mean: -17.522795068933515, timestamp: 2022-08-20 08:56:13.075090\n",
      "resetting env. episode 4094, reward total was -19.0. running mean: -17.53756711824418, timestamp: 2022-08-20 08:56:15.434118\n",
      "resetting env. episode 4095, reward total was -20.0. running mean: -17.562191447061736, timestamp: 2022-08-20 08:56:18.232154\n",
      "resetting env. episode 4096, reward total was -14.0. running mean: -17.526569532591118, timestamp: 2022-08-20 08:56:21.032184\n",
      "resetting env. episode 4097, reward total was -18.0. running mean: -17.531303837265206, timestamp: 2022-08-20 08:56:23.851222\n",
      "resetting env. episode 4098, reward total was -18.0. running mean: -17.535990798892552, timestamp: 2022-08-20 08:56:26.699256\n",
      "resetting env. episode 4099, reward total was -18.0. running mean: -17.540630890903625, timestamp: 2022-08-20 08:56:29.704291\n",
      "resetting env. episode 4100, reward total was -17.0. running mean: -17.53522458199459, timestamp: 2022-08-20 08:56:32.020319\n",
      "resetting env. episode 4101, reward total was -20.0. running mean: -17.559872336174642, timestamp: 2022-08-20 08:56:34.488874\n",
      "resetting env. episode 4102, reward total was -18.0. running mean: -17.564273612812894, timestamp: 2022-08-20 08:56:36.953910\n",
      "resetting env. episode 4103, reward total was -19.0. running mean: -17.578630876684766, timestamp: 2022-08-20 08:56:39.524936\n",
      "resetting env. episode 4104, reward total was -19.0. running mean: -17.59284456791792, timestamp: 2022-08-20 08:56:41.818966\n",
      "resetting env. episode 4105, reward total was -19.0. running mean: -17.60691612223874, timestamp: 2022-08-20 08:56:44.272996\n",
      "resetting env. episode 4106, reward total was -16.0. running mean: -17.590846961016354, timestamp: 2022-08-20 08:56:46.468024\n",
      "resetting env. episode 4107, reward total was -15.0. running mean: -17.56493849140619, timestamp: 2022-08-20 08:56:48.948053\n",
      "resetting env. episode 4108, reward total was -19.0. running mean: -17.579289106492126, timestamp: 2022-08-20 08:56:51.094077\n",
      "resetting env. episode 4109, reward total was -19.0. running mean: -17.593496215427205, timestamp: 2022-08-20 08:56:53.663110\n",
      "resetting env. episode 4110, reward total was -19.0. running mean: -17.607561253272934, timestamp: 2022-08-20 08:56:55.847134\n",
      "resetting env. episode 4111, reward total was -18.0. running mean: -17.611485640740202, timestamp: 2022-08-20 08:56:58.439171\n",
      "resetting env. episode 4112, reward total was -21.0. running mean: -17.6453707843328, timestamp: 2022-08-20 08:57:01.054201\n",
      "resetting env. episode 4113, reward total was -20.0. running mean: -17.66891707648947, timestamp: 2022-08-20 08:57:03.331225\n",
      "resetting env. episode 4114, reward total was -19.0. running mean: -17.682227905724577, timestamp: 2022-08-20 08:57:04.800244\n",
      "resetting env. episode 4115, reward total was -19.0. running mean: -17.695405626667334, timestamp: 2022-08-20 08:57:07.470286\n",
      "resetting env. episode 4116, reward total was -16.0. running mean: -17.67845157040066, timestamp: 2022-08-20 08:57:10.278311\n",
      "resetting env. episode 4117, reward total was -13.0. running mean: -17.631667054696653, timestamp: 2022-08-20 08:57:13.440350\n",
      "resetting env. episode 4118, reward total was -19.0. running mean: -17.645350384149687, timestamp: 2022-08-20 08:57:15.401374\n",
      "resetting env. episode 4119, reward total was -20.0. running mean: -17.66889688030819, timestamp: 2022-08-20 08:57:17.244395\n",
      "resetting env. episode 4120, reward total was -17.0. running mean: -17.66220791150511, timestamp: 2022-08-20 08:57:20.247433\n",
      "resetting env. episode 4121, reward total was -19.0. running mean: -17.67558583239006, timestamp: 2022-08-20 08:57:22.894464\n",
      "resetting env. episode 4122, reward total was -20.0. running mean: -17.698829974066157, timestamp: 2022-08-20 08:57:24.654488\n",
      "resetting env. episode 4123, reward total was -18.0. running mean: -17.701841674325497, timestamp: 2022-08-20 08:57:27.057518\n",
      "resetting env. episode 4124, reward total was -20.0. running mean: -17.72482325758224, timestamp: 2022-08-20 08:57:29.071542\n",
      "resetting env. episode 4125, reward total was -19.0. running mean: -17.737575025006418, timestamp: 2022-08-20 08:57:31.972578\n",
      "resetting env. episode 4126, reward total was -14.0. running mean: -17.700199274756354, timestamp: 2022-08-20 08:57:34.922614\n",
      "resetting env. episode 4127, reward total was -14.0. running mean: -17.66319728200879, timestamp: 2022-08-20 08:57:38.339654\n",
      "resetting env. episode 4128, reward total was -15.0. running mean: -17.6365653091887, timestamp: 2022-08-20 08:57:40.760683\n",
      "resetting env. episode 4129, reward total was -11.0. running mean: -17.57019965609681, timestamp: 2022-08-20 08:57:44.155727\n",
      "resetting env. episode 4130, reward total was -16.0. running mean: -17.554497659535844, timestamp: 2022-08-20 08:57:47.520764\n",
      "resetting env. episode 4131, reward total was -17.0. running mean: -17.548952682940488, timestamp: 2022-08-20 08:57:50.284799\n",
      "resetting env. episode 4132, reward total was -19.0. running mean: -17.563463156111084, timestamp: 2022-08-20 08:57:52.975838\n",
      "resetting env. episode 4133, reward total was -20.0. running mean: -17.587828524549973, timestamp: 2022-08-20 08:57:55.527865\n",
      "resetting env. episode 4134, reward total was -20.0. running mean: -17.611950239304473, timestamp: 2022-08-20 08:57:57.538890\n",
      "resetting env. episode 4135, reward total was -18.0. running mean: -17.615830736911427, timestamp: 2022-08-20 08:58:00.476924\n",
      "resetting env. episode 4136, reward total was -19.0. running mean: -17.629672429542314, timestamp: 2022-08-20 08:58:02.965957\n",
      "resetting env. episode 4137, reward total was -18.0. running mean: -17.63337570524689, timestamp: 2022-08-20 08:58:04.766978\n",
      "resetting env. episode 4138, reward total was -18.0. running mean: -17.637041948194423, timestamp: 2022-08-20 08:58:06.999005\n",
      "resetting env. episode 4139, reward total was -15.0. running mean: -17.610671528712476, timestamp: 2022-08-20 08:58:11.166059\n",
      "resetting env. episode 4140, reward total was -19.0. running mean: -17.62456481342535, timestamp: 2022-08-20 08:58:13.176080\n",
      "resetting env. episode 4141, reward total was -19.0. running mean: -17.638319165291097, timestamp: 2022-08-20 08:58:15.167104\n",
      "resetting env. episode 4142, reward total was -15.0. running mean: -17.611935973638186, timestamp: 2022-08-20 08:58:18.318143\n",
      "resetting env. episode 4143, reward total was -19.0. running mean: -17.625816613901804, timestamp: 2022-08-20 08:58:20.739177\n",
      "resetting env. episode 4144, reward total was -17.0. running mean: -17.61955844776279, timestamp: 2022-08-20 08:58:24.242221\n",
      "resetting env. episode 4145, reward total was -19.0. running mean: -17.63336286328516, timestamp: 2022-08-20 08:58:27.191254\n",
      "resetting env. episode 4146, reward total was -16.0. running mean: -17.61702923465231, timestamp: 2022-08-20 08:58:29.086273\n",
      "resetting env. episode 4147, reward total was -17.0. running mean: -17.61085894230579, timestamp: 2022-08-20 08:58:31.526305\n",
      "resetting env. episode 4148, reward total was -20.0. running mean: -17.63475035288273, timestamp: 2022-08-20 08:58:34.018339\n",
      "resetting env. episode 4149, reward total was -17.0. running mean: -17.628402849353904, timestamp: 2022-08-20 08:58:36.165366\n",
      "resetting env. episode 4150, reward total was -17.0. running mean: -17.622118820860365, timestamp: 2022-08-20 08:58:38.629392\n",
      "resetting env. episode 4151, reward total was -18.0. running mean: -17.62589763265176, timestamp: 2022-08-20 08:58:41.495430\n",
      "resetting env. episode 4152, reward total was -15.0. running mean: -17.59963865632524, timestamp: 2022-08-20 08:58:45.124476\n",
      "resetting env. episode 4153, reward total was -18.0. running mean: -17.603642269761988, timestamp: 2022-08-20 08:58:48.846519\n",
      "resetting env. episode 4154, reward total was -17.0. running mean: -17.59760584706437, timestamp: 2022-08-20 08:58:51.811555\n",
      "resetting env. episode 4155, reward total was -17.0. running mean: -17.591629788593725, timestamp: 2022-08-20 08:58:54.501589\n",
      "resetting env. episode 4156, reward total was -17.0. running mean: -17.58571349070779, timestamp: 2022-08-20 08:58:56.657615\n",
      "resetting env. episode 4157, reward total was -20.0. running mean: -17.609856355800712, timestamp: 2022-08-20 08:58:58.648640\n",
      "resetting env. episode 4158, reward total was -17.0. running mean: -17.603757792242707, timestamp: 2022-08-20 08:59:01.286672\n",
      "resetting env. episode 4159, reward total was -18.0. running mean: -17.60772021432028, timestamp: 2022-08-20 08:59:03.819703\n",
      "resetting env. episode 4160, reward total was -19.0. running mean: -17.621643012177078, timestamp: 2022-08-20 08:59:07.524747\n",
      "resetting env. episode 4161, reward total was -14.0. running mean: -17.58542658205531, timestamp: 2022-08-20 08:59:10.773790\n",
      "resetting env. episode 4162, reward total was -19.0. running mean: -17.599572316234756, timestamp: 2022-08-20 08:59:13.024818\n",
      "resetting env. episode 4163, reward total was -20.0. running mean: -17.623576593072407, timestamp: 2022-08-20 08:59:15.201844\n",
      "resetting env. episode 4164, reward total was -19.0. running mean: -17.637340827141685, timestamp: 2022-08-20 08:59:17.524872\n",
      "resetting env. episode 4165, reward total was -16.0. running mean: -17.62096741887027, timestamp: 2022-08-20 08:59:19.844899\n",
      "resetting env. episode 4166, reward total was -20.0. running mean: -17.644757744681566, timestamp: 2022-08-20 08:59:21.321494\n",
      "resetting env. episode 4167, reward total was -17.0. running mean: -17.638310167234753, timestamp: 2022-08-20 08:59:23.965526\n",
      "resetting env. episode 4168, reward total was -21.0. running mean: -17.671927065562407, timestamp: 2022-08-20 08:59:25.465549\n",
      "resetting env. episode 4169, reward total was -20.0. running mean: -17.695207794906782, timestamp: 2022-08-20 08:59:27.230568\n",
      "resetting env. episode 4170, reward total was -21.0. running mean: -17.728255716957715, timestamp: 2022-08-20 08:59:29.463593\n",
      "resetting env. episode 4171, reward total was -20.0. running mean: -17.75097315978814, timestamp: 2022-08-20 08:59:31.626621\n",
      "resetting env. episode 4172, reward total was -18.0. running mean: -17.753463428190255, timestamp: 2022-08-20 08:59:33.707647\n",
      "resetting env. episode 4173, reward total was -20.0. running mean: -17.775928793908353, timestamp: 2022-08-20 08:59:36.682684\n",
      "resetting env. episode 4174, reward total was -21.0. running mean: -17.80816950596927, timestamp: 2022-08-20 08:59:37.968699\n",
      "resetting env. episode 4175, reward total was -18.0. running mean: -17.81008781090958, timestamp: 2022-08-20 08:59:40.115727\n",
      "resetting env. episode 4176, reward total was -16.0. running mean: -17.791986932800484, timestamp: 2022-08-20 08:59:43.246764\n",
      "resetting env. episode 4177, reward total was -19.0. running mean: -17.80406706347248, timestamp: 2022-08-20 08:59:45.009786\n",
      "resetting env. episode 4178, reward total was -15.0. running mean: -17.776026392837753, timestamp: 2022-08-20 08:59:47.490821\n",
      "resetting env. episode 4179, reward total was -19.0. running mean: -17.788266128909378, timestamp: 2022-08-20 08:59:49.154836\n",
      "resetting env. episode 4180, reward total was -21.0. running mean: -17.820383467620285, timestamp: 2022-08-20 08:59:52.259875\n",
      "resetting env. episode 4181, reward total was -16.0. running mean: -17.802179632944082, timestamp: 2022-08-20 08:59:54.983911\n",
      "resetting env. episode 4182, reward total was -20.0. running mean: -17.82415783661464, timestamp: 2022-08-20 08:59:56.695930\n",
      "resetting env. episode 4183, reward total was -18.0. running mean: -17.82591625824849, timestamp: 2022-08-20 08:59:59.822968\n",
      "resetting env. episode 4184, reward total was -20.0. running mean: -17.847657095666005, timestamp: 2022-08-20 09:00:01.706992\n",
      "resetting env. episode 4185, reward total was -21.0. running mean: -17.879180524709344, timestamp: 2022-08-20 09:00:02.919009\n",
      "resetting env. episode 4186, reward total was -16.0. running mean: -17.86038871946225, timestamp: 2022-08-20 09:00:05.727040\n",
      "resetting env. episode 4187, reward total was -21.0. running mean: -17.89178483226763, timestamp: 2022-08-20 09:00:07.475066\n",
      "resetting env. episode 4188, reward total was -18.0. running mean: -17.892866983944952, timestamp: 2022-08-20 09:00:09.911099\n",
      "resetting env. episode 4189, reward total was -15.0. running mean: -17.8639383141055, timestamp: 2022-08-20 09:00:13.174140\n",
      "resetting env. episode 4190, reward total was -18.0. running mean: -17.865298930964446, timestamp: 2022-08-20 09:00:15.483161\n",
      "resetting env. episode 4191, reward total was -18.0. running mean: -17.866645941654802, timestamp: 2022-08-20 09:00:17.665189\n",
      "resetting env. episode 4192, reward total was -19.0. running mean: -17.877979482238256, timestamp: 2022-08-20 09:00:19.872214\n",
      "resetting env. episode 4193, reward total was -20.0. running mean: -17.899199687415873, timestamp: 2022-08-20 09:00:22.172243\n",
      "resetting env. episode 4194, reward total was -19.0. running mean: -17.910207690541714, timestamp: 2022-08-20 09:00:23.901262\n",
      "resetting env. episode 4195, reward total was -11.0. running mean: -17.841105613636298, timestamp: 2022-08-20 09:00:27.627310\n",
      "resetting env. episode 4196, reward total was -18.0. running mean: -17.842694557499936, timestamp: 2022-08-20 09:00:30.316345\n",
      "resetting env. episode 4197, reward total was -20.0. running mean: -17.864267611924937, timestamp: 2022-08-20 09:00:32.946380\n",
      "resetting env. episode 4198, reward total was -20.0. running mean: -17.885624935805687, timestamp: 2022-08-20 09:00:34.849399\n",
      "resetting env. episode 4199, reward total was -18.0. running mean: -17.88676868644763, timestamp: 2022-08-20 09:00:37.612435\n",
      "resetting env. episode 4200, reward total was -20.0. running mean: -17.907900999583156, timestamp: 2022-08-20 09:00:40.094463\n",
      "resetting env. episode 4201, reward total was -16.0. running mean: -17.888821989587324, timestamp: 2022-08-20 09:00:43.270514\n",
      "resetting env. episode 4202, reward total was -19.0. running mean: -17.89993376969145, timestamp: 2022-08-20 09:00:46.500541\n",
      "resetting env. episode 4203, reward total was -20.0. running mean: -17.920934431994535, timestamp: 2022-08-20 09:00:49.478579\n",
      "resetting env. episode 4204, reward total was -19.0. running mean: -17.93172508767459, timestamp: 2022-08-20 09:00:51.854608\n",
      "resetting env. episode 4205, reward total was -15.0. running mean: -17.902407836797842, timestamp: 2022-08-20 09:00:54.846646\n",
      "resetting env. episode 4206, reward total was -17.0. running mean: -17.893383758429867, timestamp: 2022-08-20 09:00:57.455676\n",
      "resetting env. episode 4207, reward total was -17.0. running mean: -17.88444992084557, timestamp: 2022-08-20 09:01:00.782717\n",
      "resetting env. episode 4208, reward total was -18.0. running mean: -17.885605421637113, timestamp: 2022-08-20 09:01:03.130749\n",
      "resetting env. episode 4209, reward total was -18.0. running mean: -17.88674936742074, timestamp: 2022-08-20 09:01:05.736779\n",
      "resetting env. episode 4210, reward total was -13.0. running mean: -17.837881873746532, timestamp: 2022-08-20 09:01:08.824816\n",
      "resetting env. episode 4211, reward total was -20.0. running mean: -17.859503055009068, timestamp: 2022-08-20 09:01:11.030846\n",
      "resetting env. episode 4212, reward total was -16.0. running mean: -17.840908024458976, timestamp: 2022-08-20 09:01:13.449871\n",
      "resetting env. episode 4213, reward total was -19.0. running mean: -17.852498944214386, timestamp: 2022-08-20 09:01:16.158914\n",
      "resetting env. episode 4214, reward total was -12.0. running mean: -17.79397395477224, timestamp: 2022-08-20 09:01:19.199942\n",
      "resetting env. episode 4215, reward total was -17.0. running mean: -17.78603421522452, timestamp: 2022-08-20 09:01:21.616971\n",
      "resetting env. episode 4216, reward total was -21.0. running mean: -17.818173873072276, timestamp: 2022-08-20 09:01:24.150001\n",
      "resetting env. episode 4217, reward total was -16.0. running mean: -17.799992134341554, timestamp: 2022-08-20 09:01:26.394028\n",
      "resetting env. episode 4218, reward total was -14.0. running mean: -17.761992212998138, timestamp: 2022-08-20 09:01:29.670069\n",
      "resetting env. episode 4219, reward total was -18.0. running mean: -17.764372290868156, timestamp: 2022-08-20 09:01:31.667143\n",
      "resetting env. episode 4220, reward total was -18.0. running mean: -17.766728567959476, timestamp: 2022-08-20 09:01:33.440162\n",
      "resetting env. episode 4221, reward total was -19.0. running mean: -17.779061282279883, timestamp: 2022-08-20 09:01:35.023186\n",
      "resetting env. episode 4222, reward total was -20.0. running mean: -17.801270669457082, timestamp: 2022-08-20 09:01:36.617199\n",
      "resetting env. episode 4223, reward total was -14.0. running mean: -17.763257962762513, timestamp: 2022-08-20 09:01:39.506233\n",
      "resetting env. episode 4224, reward total was -17.0. running mean: -17.755625383134888, timestamp: 2022-08-20 09:01:42.893277\n",
      "resetting env. episode 4225, reward total was -18.0. running mean: -17.75806912930354, timestamp: 2022-08-20 09:01:44.770302\n",
      "resetting env. episode 4226, reward total was -15.0. running mean: -17.730488438010504, timestamp: 2022-08-20 09:01:48.104344\n",
      "resetting env. episode 4227, reward total was -17.0. running mean: -17.7231835536304, timestamp: 2022-08-20 09:01:49.900364\n",
      "resetting env. episode 4228, reward total was -19.0. running mean: -17.735951718094096, timestamp: 2022-08-20 09:01:52.006388\n",
      "resetting env. episode 4229, reward total was -18.0. running mean: -17.738592200913153, timestamp: 2022-08-20 09:01:55.459430\n",
      "resetting env. episode 4230, reward total was -20.0. running mean: -17.76120627890402, timestamp: 2022-08-20 09:01:58.008460\n",
      "resetting env. episode 4231, reward total was -15.0. running mean: -17.733594216114977, timestamp: 2022-08-20 09:02:00.844496\n",
      "resetting env. episode 4232, reward total was -19.0. running mean: -17.746258273953828, timestamp: 2022-08-20 09:02:02.710520\n",
      "resetting env. episode 4233, reward total was -20.0. running mean: -17.76879569121429, timestamp: 2022-08-20 09:02:04.246536\n",
      "resetting env. episode 4234, reward total was -17.0. running mean: -17.761107734302147, timestamp: 2022-08-20 09:02:06.321567\n",
      "resetting env. episode 4235, reward total was -18.0. running mean: -17.763496656959123, timestamp: 2022-08-20 09:02:08.958120\n",
      "resetting env. episode 4236, reward total was -20.0. running mean: -17.78586169038953, timestamp: 2022-08-20 09:02:11.262154\n",
      "resetting env. episode 4237, reward total was -17.0. running mean: -17.77800307348564, timestamp: 2022-08-20 09:02:13.566176\n",
      "resetting env. episode 4238, reward total was -19.0. running mean: -17.790223042750785, timestamp: 2022-08-20 09:02:15.780731\n",
      "resetting env. episode 4239, reward total was -19.0. running mean: -17.802320812323277, timestamp: 2022-08-20 09:02:17.678756\n",
      "resetting env. episode 4240, reward total was -20.0. running mean: -17.824297604200044, timestamp: 2022-08-20 09:02:21.000850\n",
      "resetting env. episode 4241, reward total was -17.0. running mean: -17.816054628158046, timestamp: 2022-08-20 09:02:23.377881\n",
      "resetting env. episode 4242, reward total was -20.0. running mean: -17.837894081876463, timestamp: 2022-08-20 09:02:25.959913\n",
      "resetting env. episode 4243, reward total was -15.0. running mean: -17.809515141057698, timestamp: 2022-08-20 09:02:29.634953\n",
      "resetting env. episode 4244, reward total was -18.0. running mean: -17.81141998964712, timestamp: 2022-08-20 09:02:32.905994\n",
      "resetting env. episode 4245, reward total was -19.0. running mean: -17.823305789750652, timestamp: 2022-08-20 09:02:35.099025\n",
      "resetting env. episode 4246, reward total was -21.0. running mean: -17.855072731853145, timestamp: 2022-08-20 09:02:36.987044\n",
      "resetting env. episode 4247, reward total was -20.0. running mean: -17.876522004534614, timestamp: 2022-08-20 09:02:39.149072\n",
      "resetting env. episode 4248, reward total was -18.0. running mean: -17.877756784489268, timestamp: 2022-08-20 09:02:41.251099\n",
      "resetting env. episode 4249, reward total was -19.0. running mean: -17.888979216644376, timestamp: 2022-08-20 09:02:43.657125\n",
      "resetting env. episode 4250, reward total was -15.0. running mean: -17.86008942447793, timestamp: 2022-08-20 09:02:47.488172\n",
      "resetting env. episode 4251, reward total was -19.0. running mean: -17.87148853023315, timestamp: 2022-08-20 09:02:50.399206\n",
      "resetting env. episode 4252, reward total was -16.0. running mean: -17.85277364493082, timestamp: 2022-08-20 09:02:53.731249\n",
      "resetting env. episode 4253, reward total was -17.0. running mean: -17.844245908481515, timestamp: 2022-08-20 09:02:56.090279\n",
      "resetting env. episode 4254, reward total was -18.0. running mean: -17.845803449396698, timestamp: 2022-08-20 09:02:58.119306\n",
      "resetting env. episode 4255, reward total was -15.0. running mean: -17.81734541490273, timestamp: 2022-08-20 09:03:01.361346\n",
      "resetting env. episode 4256, reward total was -18.0. running mean: -17.8191719607537, timestamp: 2022-08-20 09:03:03.468367\n",
      "resetting env. episode 4257, reward total was -18.0. running mean: -17.820980241146163, timestamp: 2022-08-20 09:03:05.343393\n",
      "resetting env. episode 4258, reward total was -17.0. running mean: -17.812770438734702, timestamp: 2022-08-20 09:03:07.792425\n",
      "resetting env. episode 4259, reward total was -15.0. running mean: -17.784642734347354, timestamp: 2022-08-20 09:03:11.969474\n",
      "resetting env. episode 4260, reward total was -21.0. running mean: -17.81679630700388, timestamp: 2022-08-20 09:03:13.745494\n",
      "resetting env. episode 4261, reward total was -18.0. running mean: -17.81862834393384, timestamp: 2022-08-20 09:03:15.855522\n",
      "resetting env. episode 4262, reward total was -19.0. running mean: -17.830442060494505, timestamp: 2022-08-20 09:03:19.132565\n",
      "resetting env. episode 4263, reward total was -17.0. running mean: -17.82213763988956, timestamp: 2022-08-20 09:03:21.759595\n",
      "resetting env. episode 4264, reward total was -17.0. running mean: -17.81391626349067, timestamp: 2022-08-20 09:03:24.146626\n",
      "resetting env. episode 4265, reward total was -18.0. running mean: -17.81577710085576, timestamp: 2022-08-20 09:03:27.216662\n",
      "resetting env. episode 4266, reward total was -17.0. running mean: -17.807619329847206, timestamp: 2022-08-20 09:03:30.450707\n",
      "resetting env. episode 4267, reward total was -19.0. running mean: -17.819543136548734, timestamp: 2022-08-20 09:03:32.038719\n",
      "resetting env. episode 4268, reward total was -19.0. running mean: -17.831347705183248, timestamp: 2022-08-20 09:03:34.408799\n",
      "resetting env. episode 4269, reward total was -19.0. running mean: -17.843034228131415, timestamp: 2022-08-20 09:03:37.262836\n",
      "resetting env. episode 4270, reward total was -16.0. running mean: -17.824603885850102, timestamp: 2022-08-20 09:03:40.450873\n",
      "resetting env. episode 4271, reward total was -20.0. running mean: -17.8463578469916, timestamp: 2022-08-20 09:03:42.525904\n",
      "resetting env. episode 4272, reward total was -21.0. running mean: -17.877894268521686, timestamp: 2022-08-20 09:03:45.200457\n",
      "resetting env. episode 4273, reward total was -18.0. running mean: -17.87911532583647, timestamp: 2022-08-20 09:03:47.536490\n",
      "resetting env. episode 4274, reward total was -19.0. running mean: -17.890324172578104, timestamp: 2022-08-20 09:03:50.011516\n",
      "resetting env. episode 4275, reward total was -21.0. running mean: -17.921420930852324, timestamp: 2022-08-20 09:03:51.738539\n",
      "resetting env. episode 4276, reward total was -20.0. running mean: -17.9422067215438, timestamp: 2022-08-20 09:03:53.611561\n",
      "resetting env. episode 4277, reward total was -19.0. running mean: -17.952784654328365, timestamp: 2022-08-20 09:03:56.118590\n",
      "resetting env. episode 4278, reward total was -17.0. running mean: -17.943256807785083, timestamp: 2022-08-20 09:03:58.270620\n",
      "resetting env. episode 4279, reward total was -15.0. running mean: -17.913824239707232, timestamp: 2022-08-20 09:04:01.861185\n",
      "resetting env. episode 4280, reward total was -18.0. running mean: -17.91468599731016, timestamp: 2022-08-20 09:04:04.837219\n",
      "resetting env. episode 4281, reward total was -20.0. running mean: -17.935539137337056, timestamp: 2022-08-20 09:04:06.353237\n",
      "resetting env. episode 4282, reward total was -19.0. running mean: -17.946183745963687, timestamp: 2022-08-20 09:04:08.467265\n",
      "resetting env. episode 4283, reward total was -19.0. running mean: -17.95672190850405, timestamp: 2022-08-20 09:04:10.629290\n",
      "resetting env. episode 4284, reward total was -21.0. running mean: -17.98715468941901, timestamp: 2022-08-20 09:04:14.376338\n",
      "resetting env. episode 4285, reward total was -19.0. running mean: -17.99728314252482, timestamp: 2022-08-20 09:04:16.977369\n",
      "resetting env. episode 4286, reward total was -20.0. running mean: -18.01731031109957, timestamp: 2022-08-20 09:04:18.736390\n",
      "resetting env. episode 4287, reward total was -18.0. running mean: -18.017137207988576, timestamp: 2022-08-20 09:04:21.530944\n",
      "resetting env. episode 4288, reward total was -19.0. running mean: -18.02696583590869, timestamp: 2022-08-20 09:04:23.356971\n",
      "resetting env. episode 4289, reward total was -18.0. running mean: -18.026696177549603, timestamp: 2022-08-20 09:04:25.668996\n",
      "resetting env. episode 4290, reward total was -13.0. running mean: -17.976429215774104, timestamp: 2022-08-20 09:04:29.387042\n",
      "resetting env. episode 4291, reward total was -14.0. running mean: -17.936664923616362, timestamp: 2022-08-20 09:04:32.904605\n",
      "resetting env. episode 4292, reward total was -19.0. running mean: -17.9472982743802, timestamp: 2022-08-20 09:04:35.623639\n",
      "resetting env. episode 4293, reward total was -17.0. running mean: -17.937825291636397, timestamp: 2022-08-20 09:04:37.951667\n",
      "resetting env. episode 4294, reward total was -12.0. running mean: -17.878447038720033, timestamp: 2022-08-20 09:04:41.400715\n",
      "resetting env. episode 4295, reward total was -19.0. running mean: -17.889662568332835, timestamp: 2022-08-20 09:04:43.453734\n",
      "resetting env. episode 4296, reward total was -21.0. running mean: -17.920765942649506, timestamp: 2022-08-20 09:04:46.058774\n",
      "resetting env. episode 4297, reward total was -20.0. running mean: -17.94155828322301, timestamp: 2022-08-20 09:04:49.168804\n",
      "resetting env. episode 4298, reward total was -17.0. running mean: -17.93214270039078, timestamp: 2022-08-20 09:04:51.767837\n",
      "resetting env. episode 4299, reward total was -17.0. running mean: -17.922821273386873, timestamp: 2022-08-20 09:04:53.743871\n",
      "resetting env. episode 4300, reward total was -21.0. running mean: -17.953593060653006, timestamp: 2022-08-20 09:04:55.432397\n",
      "resetting env. episode 4301, reward total was -21.0. running mean: -17.984057130046477, timestamp: 2022-08-20 09:04:57.186422\n",
      "resetting env. episode 4302, reward total was -19.0. running mean: -17.994216558746015, timestamp: 2022-08-20 09:04:58.947444\n",
      "resetting env. episode 4303, reward total was -14.0. running mean: -17.954274393158556, timestamp: 2022-08-20 09:05:02.646489\n",
      "resetting env. episode 4304, reward total was -15.0. running mean: -17.92473164922697, timestamp: 2022-08-20 09:05:05.543524\n",
      "resetting env. episode 4305, reward total was -17.0. running mean: -17.915484332734703, timestamp: 2022-08-20 09:05:09.368569\n",
      "resetting env. episode 4306, reward total was -21.0. running mean: -17.946329489407358, timestamp: 2022-08-20 09:05:11.496594\n",
      "resetting env. episode 4307, reward total was -16.0. running mean: -17.926866194513284, timestamp: 2022-08-20 09:05:14.196627\n",
      "resetting env. episode 4308, reward total was -21.0. running mean: -17.95759753256815, timestamp: 2022-08-20 09:05:15.688646\n",
      "resetting env. episode 4309, reward total was -19.0. running mean: -17.96802155724247, timestamp: 2022-08-20 09:05:18.139202\n",
      "resetting env. episode 4310, reward total was -20.0. running mean: -17.988341341670044, timestamp: 2022-08-20 09:05:19.808221\n",
      "resetting env. episode 4311, reward total was -18.0. running mean: -17.988457928253343, timestamp: 2022-08-20 09:05:22.137246\n",
      "resetting env. episode 4312, reward total was -21.0. running mean: -18.01857334897081, timestamp: 2022-08-20 09:05:24.381275\n",
      "resetting env. episode 4313, reward total was -18.0. running mean: -18.018387615481103, timestamp: 2022-08-20 09:05:26.566302\n",
      "resetting env. episode 4314, reward total was -21.0. running mean: -18.048203739326294, timestamp: 2022-08-20 09:05:28.730331\n",
      "resetting env. episode 4315, reward total was -16.0. running mean: -18.027721701933032, timestamp: 2022-08-20 09:05:31.288357\n",
      "resetting env. episode 4316, reward total was -21.0. running mean: -18.057444484913702, timestamp: 2022-08-20 09:05:33.091382\n",
      "resetting env. episode 4317, reward total was -21.0. running mean: -18.086870040064564, timestamp: 2022-08-20 09:05:34.352400\n",
      "resetting env. episode 4318, reward total was -18.0. running mean: -18.08600133966392, timestamp: 2022-08-20 09:05:36.976428\n",
      "resetting env. episode 4319, reward total was -20.0. running mean: -18.10514132626728, timestamp: 2022-08-20 09:05:39.508458\n",
      "resetting env. episode 4320, reward total was -21.0. running mean: -18.13408991300461, timestamp: 2022-08-20 09:05:41.181479\n",
      "resetting env. episode 4321, reward total was -19.0. running mean: -18.142749013874564, timestamp: 2022-08-20 09:05:44.209519\n",
      "resetting env. episode 4322, reward total was -19.0. running mean: -18.15132152373582, timestamp: 2022-08-20 09:05:45.760535\n",
      "resetting env. episode 4323, reward total was -21.0. running mean: -18.179808308498462, timestamp: 2022-08-20 09:05:47.147555\n",
      "resetting env. episode 4324, reward total was -21.0. running mean: -18.208010225413478, timestamp: 2022-08-20 09:05:50.120594\n",
      "resetting env. episode 4325, reward total was -19.0. running mean: -18.215930123159346, timestamp: 2022-08-20 09:05:52.015619\n",
      "resetting env. episode 4326, reward total was -16.0. running mean: -18.193770821927753, timestamp: 2022-08-20 09:05:54.737645\n",
      "resetting env. episode 4327, reward total was -18.0. running mean: -18.191833113708476, timestamp: 2022-08-20 09:05:57.696681\n",
      "resetting env. episode 4328, reward total was -19.0. running mean: -18.199914782571394, timestamp: 2022-08-20 09:06:00.111710\n",
      "resetting env. episode 4329, reward total was -20.0. running mean: -18.21791563474568, timestamp: 2022-08-20 09:06:02.747743\n",
      "resetting env. episode 4330, reward total was -15.0. running mean: -18.185736478398223, timestamp: 2022-08-20 09:06:06.515786\n",
      "resetting env. episode 4331, reward total was -14.0. running mean: -18.14387911361424, timestamp: 2022-08-20 09:06:10.891847\n",
      "resetting env. episode 4332, reward total was -12.0. running mean: -18.0824403224781, timestamp: 2022-08-20 09:06:14.488887\n",
      "resetting env. episode 4333, reward total was -19.0. running mean: -18.091615919253318, timestamp: 2022-08-20 09:06:16.399906\n",
      "resetting env. episode 4334, reward total was -19.0. running mean: -18.100699760060785, timestamp: 2022-08-20 09:06:19.879953\n",
      "resetting env. episode 4335, reward total was -15.0. running mean: -18.069692762460175, timestamp: 2022-08-20 09:06:22.576982\n",
      "resetting env. episode 4336, reward total was -20.0. running mean: -18.088995834835572, timestamp: 2022-08-20 09:06:24.780532\n",
      "resetting env. episode 4337, reward total was -17.0. running mean: -18.078105876487218, timestamp: 2022-08-20 09:06:27.338563\n",
      "resetting env. episode 4338, reward total was -20.0. running mean: -18.097324817722345, timestamp: 2022-08-20 09:06:30.024597\n",
      "resetting env. episode 4339, reward total was -18.0. running mean: -18.09635156954512, timestamp: 2022-08-20 09:06:32.594627\n",
      "resetting env. episode 4340, reward total was -17.0. running mean: -18.08538805384967, timestamp: 2022-08-20 09:06:35.292660\n",
      "resetting env. episode 4341, reward total was -19.0. running mean: -18.094534173311175, timestamp: 2022-08-20 09:06:37.178682\n",
      "resetting env. episode 4342, reward total was -19.0. running mean: -18.103588831578065, timestamp: 2022-08-20 09:06:38.976708\n",
      "resetting env. episode 4343, reward total was -14.0. running mean: -18.062552943262286, timestamp: 2022-08-20 09:06:42.738751\n",
      "resetting env. episode 4344, reward total was -18.0. running mean: -18.061927413829665, timestamp: 2022-08-20 09:06:45.766789\n",
      "resetting env. episode 4345, reward total was -20.0. running mean: -18.081308139691366, timestamp: 2022-08-20 09:06:47.904818\n",
      "resetting env. episode 4346, reward total was -19.0. running mean: -18.090495058294454, timestamp: 2022-08-20 09:06:49.402829\n",
      "resetting env. episode 4347, reward total was -15.0. running mean: -18.059590107711507, timestamp: 2022-08-20 09:06:52.508879\n",
      "resetting env. episode 4348, reward total was -20.0. running mean: -18.07899420663439, timestamp: 2022-08-20 09:06:54.376894\n",
      "resetting env. episode 4349, reward total was -16.0. running mean: -18.058204264568047, timestamp: 2022-08-20 09:06:56.244917\n",
      "resetting env. episode 4350, reward total was -21.0. running mean: -18.087622221922366, timestamp: 2022-08-20 09:06:58.076934\n",
      "resetting env. episode 4351, reward total was -19.0. running mean: -18.096745999703145, timestamp: 2022-08-20 09:06:59.803956\n",
      "resetting env. episode 4352, reward total was -14.0. running mean: -18.055778539706115, timestamp: 2022-08-20 09:07:02.701992\n",
      "resetting env. episode 4353, reward total was -17.0. running mean: -18.045220754309057, timestamp: 2022-08-20 09:07:04.972027\n",
      "resetting env. episode 4354, reward total was -14.0. running mean: -18.004768546765966, timestamp: 2022-08-20 09:07:08.084056\n",
      "resetting env. episode 4355, reward total was -19.0. running mean: -18.014720861298308, timestamp: 2022-08-20 09:07:10.566088\n",
      "resetting env. episode 4356, reward total was -18.0. running mean: -18.014573652685325, timestamp: 2022-08-20 09:07:12.851116\n",
      "resetting env. episode 4357, reward total was -19.0. running mean: -18.024427916158473, timestamp: 2022-08-20 09:07:15.530152\n",
      "resetting env. episode 4358, reward total was -17.0. running mean: -18.01418363699689, timestamp: 2022-08-20 09:07:17.493171\n",
      "resetting env. episode 4359, reward total was -17.0. running mean: -18.004041800626922, timestamp: 2022-08-20 09:07:19.841201\n",
      "resetting env. episode 4360, reward total was -18.0. running mean: -18.004001382620654, timestamp: 2022-08-20 09:07:22.277227\n",
      "resetting env. episode 4361, reward total was -17.0. running mean: -17.993961368794448, timestamp: 2022-08-20 09:07:25.536267\n",
      "resetting env. episode 4362, reward total was -17.0. running mean: -17.984021755106504, timestamp: 2022-08-20 09:07:29.972322\n",
      "resetting env. episode 4363, reward total was -17.0. running mean: -17.97418153755544, timestamp: 2022-08-20 09:07:33.383368\n",
      "resetting env. episode 4364, reward total was -13.0. running mean: -17.924439722179887, timestamp: 2022-08-20 09:07:36.289399\n",
      "resetting env. episode 4365, reward total was -16.0. running mean: -17.90519532495809, timestamp: 2022-08-20 09:07:39.600442\n",
      "resetting env. episode 4366, reward total was -19.0. running mean: -17.91614337170851, timestamp: 2022-08-20 09:07:41.401467\n",
      "resetting env. episode 4367, reward total was -18.0. running mean: -17.916981937991427, timestamp: 2022-08-20 09:07:43.918495\n",
      "resetting env. episode 4368, reward total was -17.0. running mean: -17.907812118611513, timestamp: 2022-08-20 09:07:48.004547\n",
      "resetting env. episode 4369, reward total was -14.0. running mean: -17.868733997425398, timestamp: 2022-08-20 09:07:51.150589\n",
      "resetting env. episode 4370, reward total was -12.0. running mean: -17.810046657451146, timestamp: 2022-08-20 09:07:54.503622\n",
      "resetting env. episode 4371, reward total was -18.0. running mean: -17.811946190876633, timestamp: 2022-08-20 09:07:57.141663\n",
      "resetting env. episode 4372, reward total was -19.0. running mean: -17.823826728967866, timestamp: 2022-08-20 09:07:59.943687\n",
      "resetting env. episode 4373, reward total was -13.0. running mean: -17.775588461678186, timestamp: 2022-08-20 09:08:03.023724\n",
      "resetting env. episode 4374, reward total was -18.0. running mean: -17.777832577061403, timestamp: 2022-08-20 09:08:05.606756\n",
      "resetting env. episode 4375, reward total was -19.0. running mean: -17.79005425129079, timestamp: 2022-08-20 09:08:08.155793\n",
      "resetting env. episode 4376, reward total was -16.0. running mean: -17.772153708777882, timestamp: 2022-08-20 09:08:11.004825\n",
      "resetting env. episode 4377, reward total was -18.0. running mean: -17.7744321716901, timestamp: 2022-08-20 09:08:13.588855\n",
      "resetting env. episode 4378, reward total was -13.0. running mean: -17.7266878499732, timestamp: 2022-08-20 09:08:16.849894\n",
      "resetting env. episode 4379, reward total was -19.0. running mean: -17.739420971473468, timestamp: 2022-08-20 09:08:18.828918\n",
      "resetting env. episode 4380, reward total was -18.0. running mean: -17.742026761758733, timestamp: 2022-08-20 09:08:22.365966\n",
      "resetting env. episode 4381, reward total was -15.0. running mean: -17.714606494141144, timestamp: 2022-08-20 09:08:26.019005\n",
      "resetting env. episode 4382, reward total was -20.0. running mean: -17.737460429199732, timestamp: 2022-08-20 09:08:28.499037\n",
      "resetting env. episode 4383, reward total was -18.0. running mean: -17.740085824907734, timestamp: 2022-08-20 09:08:30.764598\n",
      "resetting env. episode 4384, reward total was -20.0. running mean: -17.762684966658657, timestamp: 2022-08-20 09:08:32.730622\n",
      "resetting env. episode 4385, reward total was -19.0. running mean: -17.77505811699207, timestamp: 2022-08-20 09:08:35.843657\n",
      "resetting env. episode 4386, reward total was -18.0. running mean: -17.77730753582215, timestamp: 2022-08-20 09:08:39.010696\n",
      "resetting env. episode 4387, reward total was -14.0. running mean: -17.73953446046393, timestamp: 2022-08-20 09:08:42.423740\n",
      "resetting env. episode 4388, reward total was -18.0. running mean: -17.74213911585929, timestamp: 2022-08-20 09:08:44.643766\n",
      "resetting env. episode 4389, reward total was -14.0. running mean: -17.704717724700696, timestamp: 2022-08-20 09:08:47.750804\n",
      "resetting env. episode 4390, reward total was -15.0. running mean: -17.677670547453687, timestamp: 2022-08-20 09:08:51.447846\n",
      "resetting env. episode 4391, reward total was -14.0. running mean: -17.64089384197915, timestamp: 2022-08-20 09:08:54.164879\n",
      "resetting env. episode 4392, reward total was -16.0. running mean: -17.62448490355936, timestamp: 2022-08-20 09:08:57.131915\n",
      "resetting env. episode 4393, reward total was -15.0. running mean: -17.598240054523764, timestamp: 2022-08-20 09:08:59.977955\n",
      "resetting env. episode 4394, reward total was -17.0. running mean: -17.59225765397853, timestamp: 2022-08-20 09:09:04.067046\n",
      "resetting env. episode 4395, reward total was -19.0. running mean: -17.606335077438743, timestamp: 2022-08-20 09:09:06.011067\n",
      "resetting env. episode 4396, reward total was -17.0. running mean: -17.600271726664356, timestamp: 2022-08-20 09:09:09.058102\n",
      "resetting env. episode 4397, reward total was -20.0. running mean: -17.62426900939771, timestamp: 2022-08-20 09:09:11.381130\n",
      "resetting env. episode 4398, reward total was -19.0. running mean: -17.638026319303734, timestamp: 2022-08-20 09:09:13.857161\n",
      "resetting env. episode 4399, reward total was -13.0. running mean: -17.591646056110694, timestamp: 2022-08-20 09:09:17.499208\n",
      "resetting env. episode 4400, reward total was -15.0. running mean: -17.565729595549584, timestamp: 2022-08-20 09:09:20.778247\n",
      "resetting env. episode 4401, reward total was -17.0. running mean: -17.56007229959409, timestamp: 2022-08-20 09:09:24.754294\n",
      "resetting env. episode 4402, reward total was -11.0. running mean: -17.494471576598148, timestamp: 2022-08-20 09:09:29.564354\n",
      "resetting env. episode 4403, reward total was -16.0. running mean: -17.479526860832166, timestamp: 2022-08-20 09:09:33.220920\n",
      "resetting env. episode 4404, reward total was -20.0. running mean: -17.504731592223845, timestamp: 2022-08-20 09:09:35.093946\n",
      "resetting env. episode 4405, reward total was -17.0. running mean: -17.499684276301608, timestamp: 2022-08-20 09:09:38.189978\n",
      "resetting env. episode 4406, reward total was -19.0. running mean: -17.514687433538594, timestamp: 2022-08-20 09:09:40.737012\n",
      "resetting env. episode 4407, reward total was -15.0. running mean: -17.489540559203206, timestamp: 2022-08-20 09:09:44.203050\n",
      "resetting env. episode 4408, reward total was -17.0. running mean: -17.484645153611176, timestamp: 2022-08-20 09:09:45.847074\n",
      "resetting env. episode 4409, reward total was -20.0. running mean: -17.509798702075063, timestamp: 2022-08-20 09:09:47.932099\n",
      "resetting env. episode 4410, reward total was -18.0. running mean: -17.51470071505431, timestamp: 2022-08-20 09:09:50.345124\n",
      "resetting env. episode 4411, reward total was -18.0. running mean: -17.519553707903768, timestamp: 2022-08-20 09:09:54.159171\n",
      "resetting env. episode 4412, reward total was -21.0. running mean: -17.55435817082473, timestamp: 2022-08-20 09:09:55.769190\n",
      "resetting env. episode 4413, reward total was -18.0. running mean: -17.558814589116484, timestamp: 2022-08-20 09:09:58.246218\n",
      "resetting env. episode 4414, reward total was -13.0. running mean: -17.513226443225317, timestamp: 2022-08-20 09:10:02.684276\n",
      "resetting env. episode 4415, reward total was -19.0. running mean: -17.528094178793065, timestamp: 2022-08-20 09:10:05.469309\n",
      "resetting env. episode 4416, reward total was -21.0. running mean: -17.562813237005134, timestamp: 2022-08-20 09:10:07.921336\n",
      "resetting env. episode 4417, reward total was -16.0. running mean: -17.547185104635084, timestamp: 2022-08-20 09:10:11.043374\n",
      "resetting env. episode 4418, reward total was -19.0. running mean: -17.561713253588735, timestamp: 2022-08-20 09:10:14.016413\n",
      "resetting env. episode 4419, reward total was -19.0. running mean: -17.57609612105285, timestamp: 2022-08-20 09:10:16.149958\n",
      "resetting env. episode 4420, reward total was -16.0. running mean: -17.56033515984232, timestamp: 2022-08-20 09:10:19.373998\n",
      "resetting env. episode 4421, reward total was -16.0. running mean: -17.5447318082439, timestamp: 2022-08-20 09:10:22.883052\n",
      "resetting env. episode 4422, reward total was -16.0. running mean: -17.52928449016146, timestamp: 2022-08-20 09:10:25.701079\n",
      "resetting env. episode 4423, reward total was -15.0. running mean: -17.50399164525984, timestamp: 2022-08-20 09:10:29.885127\n",
      "resetting env. episode 4424, reward total was -18.0. running mean: -17.508951728807244, timestamp: 2022-08-20 09:10:32.127156\n",
      "resetting env. episode 4425, reward total was -12.0. running mean: -17.453862211519173, timestamp: 2022-08-20 09:10:35.377191\n",
      "resetting env. episode 4426, reward total was -19.0. running mean: -17.46932358940398, timestamp: 2022-08-20 09:10:38.110224\n",
      "resetting env. episode 4427, reward total was -17.0. running mean: -17.464630353509943, timestamp: 2022-08-20 09:10:40.768261\n",
      "resetting env. episode 4428, reward total was -16.0. running mean: -17.449984049974844, timestamp: 2022-08-20 09:10:43.778294\n",
      "resetting env. episode 4429, reward total was -19.0. running mean: -17.465484209475097, timestamp: 2022-08-20 09:10:46.122323\n",
      "resetting env. episode 4430, reward total was -19.0. running mean: -17.48082936738035, timestamp: 2022-08-20 09:10:48.595352\n",
      "resetting env. episode 4431, reward total was -15.0. running mean: -17.456021073706545, timestamp: 2022-08-20 09:10:51.285387\n",
      "resetting env. episode 4432, reward total was -21.0. running mean: -17.49146086296948, timestamp: 2022-08-20 09:10:53.990415\n",
      "resetting env. episode 4433, reward total was -15.0. running mean: -17.466546254339782, timestamp: 2022-08-20 09:10:57.108980\n",
      "resetting env. episode 4434, reward total was -17.0. running mean: -17.461880791796386, timestamp: 2022-08-20 09:11:00.308019\n",
      "resetting env. episode 4435, reward total was -17.0. running mean: -17.457261983878425, timestamp: 2022-08-20 09:11:02.859051\n",
      "resetting env. episode 4436, reward total was -14.0. running mean: -17.42268936403964, timestamp: 2022-08-20 09:11:06.014095\n",
      "resetting env. episode 4437, reward total was -18.0. running mean: -17.428462470399243, timestamp: 2022-08-20 09:11:08.701118\n",
      "resetting env. episode 4438, reward total was -15.0. running mean: -17.404177845695248, timestamp: 2022-08-20 09:11:12.098163\n",
      "resetting env. episode 4439, reward total was -16.0. running mean: -17.390136067238295, timestamp: 2022-08-20 09:11:16.234210\n",
      "resetting env. episode 4440, reward total was -15.0. running mean: -17.366234706565912, timestamp: 2022-08-20 09:11:19.374253\n",
      "resetting env. episode 4441, reward total was -18.0. running mean: -17.372572359500253, timestamp: 2022-08-20 09:11:22.048279\n",
      "resetting env. episode 4442, reward total was -19.0. running mean: -17.388846635905253, timestamp: 2022-08-20 09:11:24.828314\n",
      "resetting env. episode 4443, reward total was -17.0. running mean: -17.384958169546202, timestamp: 2022-08-20 09:11:27.376345\n",
      "resetting env. episode 4444, reward total was -17.0. running mean: -17.38110858785074, timestamp: 2022-08-20 09:11:29.696373\n",
      "resetting env. episode 4445, reward total was -20.0. running mean: -17.40729750197223, timestamp: 2022-08-20 09:11:31.807403\n",
      "resetting env. episode 4446, reward total was -16.0. running mean: -17.39322452695251, timestamp: 2022-08-20 09:11:35.168440\n",
      "resetting env. episode 4447, reward total was -20.0. running mean: -17.41929228168298, timestamp: 2022-08-20 09:11:37.742469\n",
      "resetting env. episode 4448, reward total was -17.0. running mean: -17.415099358866154, timestamp: 2022-08-20 09:11:40.356500\n",
      "resetting env. episode 4449, reward total was -10.0. running mean: -17.340948365277495, timestamp: 2022-08-20 09:11:44.263596\n",
      "resetting env. episode 4450, reward total was -17.0. running mean: -17.33753888162472, timestamp: 2022-08-20 09:11:47.357632\n",
      "resetting env. episode 4451, reward total was -19.0. running mean: -17.354163492808475, timestamp: 2022-08-20 09:11:49.807661\n",
      "resetting env. episode 4452, reward total was -15.0. running mean: -17.330621857880388, timestamp: 2022-08-20 09:11:53.005699\n",
      "resetting env. episode 4453, reward total was -21.0. running mean: -17.367315639301584, timestamp: 2022-08-20 09:11:55.915738\n",
      "resetting env. episode 4454, reward total was -19.0. running mean: -17.38364248290857, timestamp: 2022-08-20 09:11:58.535774\n",
      "resetting env. episode 4455, reward total was -16.0. running mean: -17.369806058079483, timestamp: 2022-08-20 09:12:02.530819\n",
      "resetting env. episode 4456, reward total was -18.0. running mean: -17.37610799749869, timestamp: 2022-08-20 09:12:04.873848\n",
      "resetting env. episode 4457, reward total was -19.0. running mean: -17.392346917523703, timestamp: 2022-08-20 09:12:07.302874\n",
      "resetting env. episode 4458, reward total was -20.0. running mean: -17.418423448348467, timestamp: 2022-08-20 09:12:10.034911\n",
      "resetting env. episode 4459, reward total was -13.0. running mean: -17.374239213864982, timestamp: 2022-08-20 09:12:13.220945\n",
      "resetting env. episode 4460, reward total was -16.0. running mean: -17.360496821726333, timestamp: 2022-08-20 09:12:16.032978\n",
      "resetting env. episode 4461, reward total was -17.0. running mean: -17.356891853509072, timestamp: 2022-08-20 09:12:18.889016\n",
      "resetting env. episode 4462, reward total was -18.0. running mean: -17.363322934973983, timestamp: 2022-08-20 09:12:22.185054\n",
      "resetting env. episode 4463, reward total was -16.0. running mean: -17.349689705624243, timestamp: 2022-08-20 09:12:25.181091\n",
      "resetting env. episode 4464, reward total was -13.0. running mean: -17.306192808568, timestamp: 2022-08-20 09:12:28.324128\n",
      "resetting env. episode 4465, reward total was -18.0. running mean: -17.31313088048232, timestamp: 2022-08-20 09:12:30.726156\n",
      "resetting env. episode 4466, reward total was -14.0. running mean: -17.279999571677497, timestamp: 2022-08-20 09:12:33.814198\n",
      "resetting env. episode 4467, reward total was -19.0. running mean: -17.29719957596072, timestamp: 2022-08-20 09:12:36.822234\n",
      "resetting env. episode 4468, reward total was -19.0. running mean: -17.314227580201116, timestamp: 2022-08-20 09:12:39.128260\n",
      "resetting env. episode 4469, reward total was -16.0. running mean: -17.301085304399106, timestamp: 2022-08-20 09:12:42.532300\n",
      "resetting env. episode 4470, reward total was -18.0. running mean: -17.308074451355115, timestamp: 2022-08-20 09:12:45.504339\n",
      "resetting env. episode 4471, reward total was -17.0. running mean: -17.304993706841564, timestamp: 2022-08-20 09:12:48.395373\n",
      "resetting env. episode 4472, reward total was -19.0. running mean: -17.32194376977315, timestamp: 2022-08-20 09:12:50.998408\n",
      "resetting env. episode 4473, reward total was -15.0. running mean: -17.298724332075416, timestamp: 2022-08-20 09:12:53.940439\n",
      "resetting env. episode 4474, reward total was -18.0. running mean: -17.30573708875466, timestamp: 2022-08-20 09:12:56.267468\n",
      "resetting env. episode 4475, reward total was -17.0. running mean: -17.302679717867115, timestamp: 2022-08-20 09:12:58.455496\n",
      "resetting env. episode 4476, reward total was -15.0. running mean: -17.27965292068844, timestamp: 2022-08-20 09:13:01.943539\n",
      "resetting env. episode 4477, reward total was -17.0. running mean: -17.27685639148156, timestamp: 2022-08-20 09:13:04.608571\n",
      "resetting env. episode 4478, reward total was -16.0. running mean: -17.264087827566744, timestamp: 2022-08-20 09:13:07.465649\n",
      "resetting env. episode 4479, reward total was -20.0. running mean: -17.291446949291075, timestamp: 2022-08-20 09:13:10.201685\n",
      "resetting env. episode 4480, reward total was -18.0. running mean: -17.298532479798162, timestamp: 2022-08-20 09:13:12.801762\n",
      "resetting env. episode 4481, reward total was -14.0. running mean: -17.26554715500018, timestamp: 2022-08-20 09:13:15.658798\n",
      "resetting env. episode 4482, reward total was -15.0. running mean: -17.24289168345018, timestamp: 2022-08-20 09:13:19.047838\n",
      "resetting env. episode 4483, reward total was -17.0. running mean: -17.24046276661568, timestamp: 2022-08-20 09:13:22.149879\n",
      "resetting env. episode 4484, reward total was -19.0. running mean: -17.258058138949522, timestamp: 2022-08-20 09:13:25.468916\n",
      "resetting env. episode 4485, reward total was -17.0. running mean: -17.255477557560027, timestamp: 2022-08-20 09:13:28.340956\n",
      "resetting env. episode 4486, reward total was -19.0. running mean: -17.272922781984427, timestamp: 2022-08-20 09:13:30.295978\n",
      "resetting env. episode 4487, reward total was -18.0. running mean: -17.280193554164583, timestamp: 2022-08-20 09:13:33.637015\n",
      "resetting env. episode 4488, reward total was -19.0. running mean: -17.29739161862294, timestamp: 2022-08-20 09:13:36.219049\n",
      "resetting env. episode 4489, reward total was -16.0. running mean: -17.28441770243671, timestamp: 2022-08-20 09:13:40.500118\n",
      "resetting env. episode 4490, reward total was -16.0. running mean: -17.271573525412343, timestamp: 2022-08-20 09:13:43.009133\n",
      "resetting env. episode 4491, reward total was -18.0. running mean: -17.27885779015822, timestamp: 2022-08-20 09:13:45.578686\n",
      "resetting env. episode 4492, reward total was -18.0. running mean: -17.28606921225664, timestamp: 2022-08-20 09:13:47.538711\n",
      "resetting env. episode 4493, reward total was -18.0. running mean: -17.293208520134073, timestamp: 2022-08-20 09:13:50.500751\n",
      "resetting env. episode 4494, reward total was -17.0. running mean: -17.290276434932732, timestamp: 2022-08-20 09:13:53.533786\n",
      "resetting env. episode 4495, reward total was -17.0. running mean: -17.287373670583406, timestamp: 2022-08-20 09:13:55.786815\n",
      "resetting env. episode 4496, reward total was -19.0. running mean: -17.304499933877572, timestamp: 2022-08-20 09:13:58.313846\n",
      "resetting env. episode 4497, reward total was -19.0. running mean: -17.3214549345388, timestamp: 2022-08-20 09:14:00.350870\n",
      "resetting env. episode 4498, reward total was -11.0. running mean: -17.25824038519341, timestamp: 2022-08-20 09:14:03.906909\n",
      "resetting env. episode 4499, reward total was -15.0. running mean: -17.235657981341475, timestamp: 2022-08-20 09:14:06.816950\n",
      "resetting env. episode 4500, reward total was -21.0. running mean: -17.273301401528062, timestamp: 2022-08-20 09:14:08.254963\n",
      "resetting env. episode 4501, reward total was -19.0. running mean: -17.29056838751278, timestamp: 2022-08-20 09:14:10.581991\n",
      "resetting env. episode 4502, reward total was -18.0. running mean: -17.297662703637652, timestamp: 2022-08-20 09:14:13.369027\n",
      "resetting env. episode 4503, reward total was -20.0. running mean: -17.324686076601274, timestamp: 2022-08-20 09:14:15.863063\n",
      "resetting env. episode 4504, reward total was -16.0. running mean: -17.31143921583526, timestamp: 2022-08-20 09:14:18.998096\n",
      "resetting env. episode 4505, reward total was -16.0. running mean: -17.298324823676907, timestamp: 2022-08-20 09:14:21.967133\n",
      "resetting env. episode 4506, reward total was -16.0. running mean: -17.28534157544014, timestamp: 2022-08-20 09:14:25.075168\n",
      "resetting env. episode 4507, reward total was -17.0. running mean: -17.282488159685737, timestamp: 2022-08-20 09:14:27.410717\n",
      "resetting env. episode 4508, reward total was -18.0. running mean: -17.28966327808888, timestamp: 2022-08-20 09:14:29.748748\n",
      "resetting env. episode 4509, reward total was -20.0. running mean: -17.31676664530799, timestamp: 2022-08-20 09:14:32.417778\n",
      "resetting env. episode 4510, reward total was -21.0. running mean: -17.35359897885491, timestamp: 2022-08-20 09:14:34.449805\n",
      "resetting env. episode 4511, reward total was -19.0. running mean: -17.370062989066362, timestamp: 2022-08-20 09:14:36.376831\n",
      "resetting env. episode 4512, reward total was -12.0. running mean: -17.3163623591757, timestamp: 2022-08-20 09:14:40.358875\n",
      "resetting env. episode 4513, reward total was -19.0. running mean: -17.33319873558394, timestamp: 2022-08-20 09:14:42.994909\n",
      "resetting env. episode 4514, reward total was -19.0. running mean: -17.349866748228102, timestamp: 2022-08-20 09:14:45.609941\n",
      "resetting env. episode 4515, reward total was -17.0. running mean: -17.346368080745822, timestamp: 2022-08-20 09:14:48.904981\n",
      "resetting env. episode 4516, reward total was -21.0. running mean: -17.382904399938365, timestamp: 2022-08-20 09:14:51.236010\n",
      "resetting env. episode 4517, reward total was -16.0. running mean: -17.369075355938982, timestamp: 2022-08-20 09:14:54.257567\n",
      "resetting env. episode 4518, reward total was -19.0. running mean: -17.38538460237959, timestamp: 2022-08-20 09:14:57.083603\n",
      "resetting env. episode 4519, reward total was -20.0. running mean: -17.411530756355795, timestamp: 2022-08-20 09:14:58.853628\n",
      "resetting env. episode 4520, reward total was -20.0. running mean: -17.437415448792237, timestamp: 2022-08-20 09:15:00.955646\n",
      "resetting env. episode 4521, reward total was -20.0. running mean: -17.463041294304315, timestamp: 2022-08-20 09:15:02.853675\n",
      "resetting env. episode 4522, reward total was -19.0. running mean: -17.478410881361274, timestamp: 2022-08-20 09:15:04.923696\n",
      "resetting env. episode 4523, reward total was -20.0. running mean: -17.503626772547662, timestamp: 2022-08-20 09:15:07.523727\n",
      "resetting env. episode 4524, reward total was -19.0. running mean: -17.518590504822185, timestamp: 2022-08-20 09:15:09.375752\n",
      "resetting env. episode 4525, reward total was -15.0. running mean: -17.493404599773964, timestamp: 2022-08-20 09:15:12.415787\n",
      "resetting env. episode 4526, reward total was -15.0. running mean: -17.46847055377622, timestamp: 2022-08-20 09:15:15.755829\n",
      "resetting env. episode 4527, reward total was -19.0. running mean: -17.483785848238462, timestamp: 2022-08-20 09:15:18.302858\n",
      "resetting env. episode 4528, reward total was -21.0. running mean: -17.51894798975608, timestamp: 2022-08-20 09:15:20.807416\n",
      "resetting env. episode 4529, reward total was -16.0. running mean: -17.503758509858518, timestamp: 2022-08-20 09:15:23.916453\n",
      "resetting env. episode 4530, reward total was -18.0. running mean: -17.50872092475993, timestamp: 2022-08-20 09:15:26.967488\n",
      "resetting env. episode 4531, reward total was -18.0. running mean: -17.51363371551233, timestamp: 2022-08-20 09:15:29.509514\n",
      "resetting env. episode 4532, reward total was -16.0. running mean: -17.498497378357207, timestamp: 2022-08-20 09:15:31.995547\n",
      "resetting env. episode 4533, reward total was -20.0. running mean: -17.523512404573633, timestamp: 2022-08-20 09:15:34.079570\n",
      "resetting env. episode 4534, reward total was -19.0. running mean: -17.538277280527897, timestamp: 2022-08-20 09:15:36.226597\n",
      "resetting env. episode 4535, reward total was -16.0. running mean: -17.52289450772262, timestamp: 2022-08-20 09:15:39.350634\n",
      "resetting env. episode 4536, reward total was -19.0. running mean: -17.537665562645394, timestamp: 2022-08-20 09:15:42.281675\n",
      "resetting env. episode 4537, reward total was -15.0. running mean: -17.512288907018938, timestamp: 2022-08-20 09:15:46.000718\n",
      "resetting env. episode 4538, reward total was -17.0. running mean: -17.50716601794875, timestamp: 2022-08-20 09:15:49.010758\n",
      "resetting env. episode 4539, reward total was -19.0. running mean: -17.522094357769266, timestamp: 2022-08-20 09:15:51.341793\n",
      "resetting env. episode 4540, reward total was -20.0. running mean: -17.546873414191573, timestamp: 2022-08-20 09:15:53.651815\n",
      "resetting env. episode 4541, reward total was -15.0. running mean: -17.521404680049656, timestamp: 2022-08-20 09:15:56.954849\n",
      "resetting env. episode 4542, reward total was -17.0. running mean: -17.51619063324916, timestamp: 2022-08-20 09:16:00.486893\n",
      "resetting env. episode 4543, reward total was -15.0. running mean: -17.491028726916667, timestamp: 2022-08-20 09:16:03.844934\n",
      "resetting env. episode 4544, reward total was -19.0. running mean: -17.5061184396475, timestamp: 2022-08-20 09:16:06.678967\n",
      "resetting env. episode 4545, reward total was -18.0. running mean: -17.511057255251025, timestamp: 2022-08-20 09:16:09.365009\n",
      "resetting env. episode 4546, reward total was -21.0. running mean: -17.545946682698514, timestamp: 2022-08-20 09:16:12.133038\n",
      "resetting env. episode 4547, reward total was -19.0. running mean: -17.56048721587153, timestamp: 2022-08-20 09:16:15.003070\n",
      "resetting env. episode 4548, reward total was -20.0. running mean: -17.584882343712813, timestamp: 2022-08-20 09:16:17.140096\n",
      "resetting env. episode 4549, reward total was -19.0. running mean: -17.599033520275686, timestamp: 2022-08-20 09:16:19.807128\n",
      "resetting env. episode 4550, reward total was -20.0. running mean: -17.623043185072927, timestamp: 2022-08-20 09:16:21.777156\n",
      "resetting env. episode 4551, reward total was -20.0. running mean: -17.646812753222196, timestamp: 2022-08-20 09:16:24.415185\n",
      "resetting env. episode 4552, reward total was -19.0. running mean: -17.660344625689977, timestamp: 2022-08-20 09:16:26.298216\n",
      "resetting env. episode 4553, reward total was -16.0. running mean: -17.64374117943308, timestamp: 2022-08-20 09:16:29.865252\n",
      "resetting env. episode 4554, reward total was -20.0. running mean: -17.667303767638746, timestamp: 2022-08-20 09:16:31.993279\n",
      "resetting env. episode 4555, reward total was -20.0. running mean: -17.690630729962358, timestamp: 2022-08-20 09:16:34.501307\n",
      "resetting env. episode 4556, reward total was -19.0. running mean: -17.703724422662734, timestamp: 2022-08-20 09:16:36.532333\n",
      "resetting env. episode 4557, reward total was -16.0. running mean: -17.686687178436106, timestamp: 2022-08-20 09:16:38.908364\n",
      "resetting env. episode 4558, reward total was -15.0. running mean: -17.659820306651742, timestamp: 2022-08-20 09:16:43.145414\n",
      "resetting env. episode 4559, reward total was -19.0. running mean: -17.673222103585225, timestamp: 2022-08-20 09:16:45.143443\n",
      "resetting env. episode 4560, reward total was -17.0. running mean: -17.666489882549374, timestamp: 2022-08-20 09:16:48.048472\n",
      "resetting env. episode 4561, reward total was -19.0. running mean: -17.679824983723883, timestamp: 2022-08-20 09:16:51.153512\n",
      "resetting env. episode 4562, reward total was -17.0. running mean: -17.673026733886644, timestamp: 2022-08-20 09:16:53.702543\n",
      "resetting env. episode 4563, reward total was -18.0. running mean: -17.67629646654778, timestamp: 2022-08-20 09:16:56.393575\n",
      "resetting env. episode 4564, reward total was -21.0. running mean: -17.7095335018823, timestamp: 2022-08-20 09:16:58.478603\n",
      "resetting env. episode 4565, reward total was -16.0. running mean: -17.69243816686348, timestamp: 2022-08-20 09:17:01.905646\n",
      "resetting env. episode 4566, reward total was -17.0. running mean: -17.685513785194846, timestamp: 2022-08-20 09:17:05.084208\n",
      "resetting env. episode 4567, reward total was -16.0. running mean: -17.668658647342898, timestamp: 2022-08-20 09:17:08.164251\n",
      "resetting env. episode 4568, reward total was -19.0. running mean: -17.68197206086947, timestamp: 2022-08-20 09:17:10.353274\n",
      "resetting env. episode 4569, reward total was -12.0. running mean: -17.625152340260776, timestamp: 2022-08-20 09:17:13.754315\n",
      "resetting env. episode 4570, reward total was -15.0. running mean: -17.598900816858166, timestamp: 2022-08-20 09:17:16.730354\n",
      "resetting env. episode 4571, reward total was -20.0. running mean: -17.622911808689583, timestamp: 2022-08-20 09:17:19.757388\n",
      "resetting env. episode 4572, reward total was -18.0. running mean: -17.62668269060269, timestamp: 2022-08-20 09:17:22.424424\n",
      "resetting env. episode 4573, reward total was -15.0. running mean: -17.60041586369666, timestamp: 2022-08-20 09:17:25.688988\n",
      "resetting env. episode 4574, reward total was -17.0. running mean: -17.594411705059695, timestamp: 2022-08-20 09:17:28.247024\n",
      "resetting env. episode 4575, reward total was -19.0. running mean: -17.6084675880091, timestamp: 2022-08-20 09:17:31.390057\n",
      "resetting env. episode 4576, reward total was -20.0. running mean: -17.632382912129007, timestamp: 2022-08-20 09:17:33.324080\n",
      "resetting env. episode 4577, reward total was -16.0. running mean: -17.616059083007716, timestamp: 2022-08-20 09:17:36.112121\n",
      "resetting env. episode 4578, reward total was -17.0. running mean: -17.609898492177642, timestamp: 2022-08-20 09:17:39.030150\n",
      "resetting env. episode 4579, reward total was -15.0. running mean: -17.583799507255865, timestamp: 2022-08-20 09:17:41.638183\n",
      "resetting env. episode 4580, reward total was -20.0. running mean: -17.607961512183305, timestamp: 2022-08-20 09:17:43.682210\n",
      "resetting env. episode 4581, reward total was -17.0. running mean: -17.601881897061475, timestamp: 2022-08-20 09:17:46.427241\n",
      "resetting env. episode 4582, reward total was -16.0. running mean: -17.58586307809086, timestamp: 2022-08-20 09:17:49.704282\n",
      "resetting env. episode 4583, reward total was -17.0. running mean: -17.580004447309953, timestamp: 2022-08-20 09:17:52.521317\n",
      "resetting env. episode 4584, reward total was -19.0. running mean: -17.594204402836855, timestamp: 2022-08-20 09:17:54.379342\n",
      "resetting env. episode 4585, reward total was -19.0. running mean: -17.60826235880849, timestamp: 2022-08-20 09:17:56.844418\n",
      "resetting env. episode 4586, reward total was -16.0. running mean: -17.592179735220405, timestamp: 2022-08-20 09:17:59.318452\n",
      "resetting env. episode 4587, reward total was -16.0. running mean: -17.576257937868203, timestamp: 2022-08-20 09:18:01.735478\n",
      "resetting env. episode 4588, reward total was -16.0. running mean: -17.560495358489522, timestamp: 2022-08-20 09:18:04.439510\n",
      "resetting env. episode 4589, reward total was -17.0. running mean: -17.55489040490463, timestamp: 2022-08-20 09:18:07.428552\n",
      "resetting env. episode 4590, reward total was -16.0. running mean: -17.53934150085558, timestamp: 2022-08-20 09:18:10.957592\n",
      "resetting env. episode 4591, reward total was -21.0. running mean: -17.573948085847025, timestamp: 2022-08-20 09:18:13.089616\n",
      "resetting env. episode 4592, reward total was -17.0. running mean: -17.568208604988556, timestamp: 2022-08-20 09:18:15.529649\n",
      "resetting env. episode 4593, reward total was -17.0. running mean: -17.56252651893867, timestamp: 2022-08-20 09:18:19.247693\n",
      "resetting env. episode 4594, reward total was -20.0. running mean: -17.586901253749286, timestamp: 2022-08-20 09:18:22.105731\n",
      "resetting env. episode 4595, reward total was -19.0. running mean: -17.601032241211794, timestamp: 2022-08-20 09:18:25.122763\n",
      "resetting env. episode 4596, reward total was -18.0. running mean: -17.605021918799675, timestamp: 2022-08-20 09:18:27.580794\n",
      "resetting env. episode 4597, reward total was -15.0. running mean: -17.578971699611678, timestamp: 2022-08-20 09:18:30.222827\n",
      "resetting env. episode 4598, reward total was -15.0. running mean: -17.55318198261556, timestamp: 2022-08-20 09:18:33.538868\n",
      "resetting env. episode 4599, reward total was -15.0. running mean: -17.527650162789403, timestamp: 2022-08-20 09:18:36.563906\n",
      "resetting env. episode 4600, reward total was -12.0. running mean: -17.47237366116151, timestamp: 2022-08-20 09:18:40.139946\n",
      "resetting env. episode 4601, reward total was -19.0. running mean: -17.487649924549896, timestamp: 2022-08-20 09:18:43.180984\n",
      "resetting env. episode 4602, reward total was -16.0. running mean: -17.472773425304396, timestamp: 2022-08-20 09:18:46.015017\n",
      "resetting env. episode 4603, reward total was -18.0. running mean: -17.478045691051353, timestamp: 2022-08-20 09:18:49.272062\n",
      "resetting env. episode 4604, reward total was -19.0. running mean: -17.49326523414084, timestamp: 2022-08-20 09:18:51.651090\n",
      "resetting env. episode 4605, reward total was -14.0. running mean: -17.458332581799432, timestamp: 2022-08-20 09:18:54.784125\n",
      "resetting env. episode 4606, reward total was -16.0. running mean: -17.443749255981437, timestamp: 2022-08-20 09:18:56.964153\n",
      "resetting env. episode 4607, reward total was -18.0. running mean: -17.449311763421623, timestamp: 2022-08-20 09:18:59.369183\n",
      "resetting env. episode 4608, reward total was -15.0. running mean: -17.424818645787404, timestamp: 2022-08-20 09:19:02.717228\n",
      "resetting env. episode 4609, reward total was -18.0. running mean: -17.43057045932953, timestamp: 2022-08-20 09:19:05.425262\n",
      "resetting env. episode 4610, reward total was -12.0. running mean: -17.376264754736237, timestamp: 2022-08-20 09:19:08.814298\n",
      "resetting env. episode 4611, reward total was -16.0. running mean: -17.362502107188874, timestamp: 2022-08-20 09:19:12.700344\n",
      "resetting env. episode 4612, reward total was -13.0. running mean: -17.318877086116984, timestamp: 2022-08-20 09:19:15.860383\n",
      "resetting env. episode 4613, reward total was -17.0. running mean: -17.315688315255816, timestamp: 2022-08-20 09:19:18.482414\n",
      "resetting env. episode 4614, reward total was -15.0. running mean: -17.292531432103257, timestamp: 2022-08-20 09:19:21.278451\n",
      "resetting env. episode 4615, reward total was -15.0. running mean: -17.26960611778222, timestamp: 2022-08-20 09:19:24.303486\n",
      "resetting env. episode 4616, reward total was -14.0. running mean: -17.236910056604398, timestamp: 2022-08-20 09:19:27.586529\n",
      "resetting env. episode 4617, reward total was -19.0. running mean: -17.254540956038355, timestamp: 2022-08-20 09:19:29.270555\n",
      "resetting env. episode 4618, reward total was -15.0. running mean: -17.231995546477968, timestamp: 2022-08-20 09:19:32.071580\n",
      "resetting env. episode 4619, reward total was -18.0. running mean: -17.23967559101319, timestamp: 2022-08-20 09:19:35.378142\n",
      "resetting env. episode 4620, reward total was -17.0. running mean: -17.23727883510306, timestamp: 2022-08-20 09:19:38.855185\n",
      "resetting env. episode 4621, reward total was -16.0. running mean: -17.22490604675203, timestamp: 2022-08-20 09:19:41.478739\n",
      "resetting env. episode 4622, reward total was -12.0. running mean: -17.172656986284508, timestamp: 2022-08-20 09:19:45.030783\n",
      "resetting env. episode 4623, reward total was -19.0. running mean: -17.190930416421665, timestamp: 2022-08-20 09:19:47.383810\n",
      "resetting env. episode 4624, reward total was -19.0. running mean: -17.20902111225745, timestamp: 2022-08-20 09:19:50.243845\n",
      "resetting env. episode 4625, reward total was -15.0. running mean: -17.186930901134872, timestamp: 2022-08-20 09:19:52.865879\n",
      "resetting env. episode 4626, reward total was -17.0. running mean: -17.185061592123525, timestamp: 2022-08-20 09:19:56.081919\n",
      "resetting env. episode 4627, reward total was -18.0. running mean: -17.193210976202288, timestamp: 2022-08-20 09:19:58.769954\n",
      "resetting env. episode 4628, reward total was -21.0. running mean: -17.231278866440267, timestamp: 2022-08-20 09:20:00.295968\n",
      "resetting env. episode 4629, reward total was -19.0. running mean: -17.248966077775865, timestamp: 2022-08-20 09:20:02.875000\n",
      "resetting env. episode 4630, reward total was -17.0. running mean: -17.246476416998107, timestamp: 2022-08-20 09:20:06.326569\n",
      "resetting env. episode 4631, reward total was -14.0. running mean: -17.214011652828127, timestamp: 2022-08-20 09:20:09.353604\n",
      "resetting env. episode 4632, reward total was -19.0. running mean: -17.231871536299845, timestamp: 2022-08-20 09:20:11.856635\n",
      "resetting env. episode 4633, reward total was -16.0. running mean: -17.219552820936848, timestamp: 2022-08-20 09:20:15.255680\n",
      "resetting env. episode 4634, reward total was -15.0. running mean: -17.197357292727478, timestamp: 2022-08-20 09:20:18.451716\n",
      "resetting env. episode 4635, reward total was -20.0. running mean: -17.225383719800202, timestamp: 2022-08-20 09:20:20.448743\n",
      "resetting env. episode 4636, reward total was -12.0. running mean: -17.1731298826022, timestamp: 2022-08-20 09:20:24.306792\n",
      "resetting env. episode 4637, reward total was -17.0. running mean: -17.17139858377618, timestamp: 2022-08-20 09:20:27.134827\n",
      "resetting env. episode 4638, reward total was -16.0. running mean: -17.15968459793842, timestamp: 2022-08-20 09:20:29.615853\n",
      "resetting env. episode 4639, reward total was -16.0. running mean: -17.148087751959036, timestamp: 2022-08-20 09:20:32.235890\n",
      "resetting env. episode 4640, reward total was -17.0. running mean: -17.146606874439446, timestamp: 2022-08-20 09:20:35.080919\n",
      "resetting env. episode 4641, reward total was -13.0. running mean: -17.10514080569505, timestamp: 2022-08-20 09:20:37.968955\n",
      "resetting env. episode 4642, reward total was -19.0. running mean: -17.1240893976381, timestamp: 2022-08-20 09:20:40.307984\n",
      "resetting env. episode 4643, reward total was -17.0. running mean: -17.12284850366172, timestamp: 2022-08-20 09:20:42.513011\n",
      "resetting env. episode 4644, reward total was -16.0. running mean: -17.111620018625104, timestamp: 2022-08-20 09:20:44.942038\n",
      "resetting env. episode 4645, reward total was -17.0. running mean: -17.110503818438854, timestamp: 2022-08-20 09:20:47.769077\n",
      "resetting env. episode 4646, reward total was -13.0. running mean: -17.069398780254463, timestamp: 2022-08-20 09:20:51.415117\n",
      "resetting env. episode 4647, reward total was -18.0. running mean: -17.07870479245192, timestamp: 2022-08-20 09:20:54.214152\n",
      "resetting env. episode 4648, reward total was -16.0. running mean: -17.0679177445274, timestamp: 2022-08-20 09:20:56.500182\n",
      "resetting env. episode 4649, reward total was -15.0. running mean: -17.047238567082125, timestamp: 2022-08-20 09:20:59.069216\n",
      "resetting env. episode 4650, reward total was -19.0. running mean: -17.066766181411307, timestamp: 2022-08-20 09:21:02.751254\n",
      "resetting env. episode 4651, reward total was -15.0. running mean: -17.04609851959719, timestamp: 2022-08-20 09:21:04.931283\n",
      "resetting env. episode 4652, reward total was -19.0. running mean: -17.06563753440122, timestamp: 2022-08-20 09:21:07.472316\n",
      "resetting env. episode 4653, reward total was -17.0. running mean: -17.064981159057208, timestamp: 2022-08-20 09:21:09.869343\n",
      "resetting env. episode 4654, reward total was -16.0. running mean: -17.054331347466636, timestamp: 2022-08-20 09:21:12.747378\n",
      "resetting env. episode 4655, reward total was -21.0. running mean: -17.09378803399197, timestamp: 2022-08-20 09:21:14.897404\n",
      "resetting env. episode 4656, reward total was -20.0. running mean: -17.12285015365205, timestamp: 2022-08-20 09:21:16.643425\n",
      "resetting env. episode 4657, reward total was -18.0. running mean: -17.131621652115527, timestamp: 2022-08-20 09:21:18.916456\n",
      "resetting env. episode 4658, reward total was -20.0. running mean: -17.16030543559437, timestamp: 2022-08-20 09:21:21.067478\n",
      "resetting env. episode 4659, reward total was -18.0. running mean: -17.168702381238425, timestamp: 2022-08-20 09:21:24.822525\n",
      "resetting env. episode 4660, reward total was -19.0. running mean: -17.18701535742604, timestamp: 2022-08-20 09:21:27.129555\n",
      "resetting env. episode 4661, reward total was -21.0. running mean: -17.22514520385178, timestamp: 2022-08-20 09:21:28.993579\n",
      "resetting env. episode 4662, reward total was -19.0. running mean: -17.242893751813263, timestamp: 2022-08-20 09:21:31.802611\n",
      "resetting env. episode 4663, reward total was -16.0. running mean: -17.23046481429513, timestamp: 2022-08-20 09:21:34.482641\n",
      "resetting env. episode 4664, reward total was -19.0. running mean: -17.24816016615218, timestamp: 2022-08-20 09:21:36.546667\n",
      "resetting env. episode 4665, reward total was -17.0. running mean: -17.245678564490657, timestamp: 2022-08-20 09:21:39.410705\n",
      "resetting env. episode 4666, reward total was -18.0. running mean: -17.25322177884575, timestamp: 2022-08-20 09:21:41.882732\n",
      "resetting env. episode 4667, reward total was -13.0. running mean: -17.21068956105729, timestamp: 2022-08-20 09:21:46.108306\n",
      "resetting env. episode 4668, reward total was -17.0. running mean: -17.20858266544672, timestamp: 2022-08-20 09:21:48.448335\n",
      "resetting env. episode 4669, reward total was -17.0. running mean: -17.206496838792255, timestamp: 2022-08-20 09:21:50.986370\n",
      "resetting env. episode 4670, reward total was -19.0. running mean: -17.224431870404334, timestamp: 2022-08-20 09:21:53.156393\n",
      "resetting env. episode 4671, reward total was -20.0. running mean: -17.252187551700292, timestamp: 2022-08-20 09:21:56.030428\n",
      "resetting env. episode 4672, reward total was -18.0. running mean: -17.25966567618329, timestamp: 2022-08-20 09:21:58.356459\n",
      "resetting env. episode 4673, reward total was -21.0. running mean: -17.297069019421457, timestamp: 2022-08-20 09:22:00.858486\n",
      "resetting env. episode 4674, reward total was -20.0. running mean: -17.32409832922724, timestamp: 2022-08-20 09:22:03.422515\n",
      "resetting env. episode 4675, reward total was -18.0. running mean: -17.330857345934966, timestamp: 2022-08-20 09:22:06.261550\n",
      "resetting env. episode 4676, reward total was -16.0. running mean: -17.317548772475615, timestamp: 2022-08-20 09:22:09.970121\n",
      "resetting env. episode 4677, reward total was -17.0. running mean: -17.31437328475086, timestamp: 2022-08-20 09:22:13.158161\n",
      "resetting env. episode 4678, reward total was -16.0. running mean: -17.30122955190335, timestamp: 2022-08-20 09:22:15.747191\n",
      "resetting env. episode 4679, reward total was -18.0. running mean: -17.308217256384317, timestamp: 2022-08-20 09:22:18.547227\n",
      "resetting env. episode 4680, reward total was -12.0. running mean: -17.255135083820473, timestamp: 2022-08-20 09:22:22.822286\n",
      "resetting env. episode 4681, reward total was -15.0. running mean: -17.232583732982267, timestamp: 2022-08-20 09:22:26.260318\n",
      "resetting env. episode 4682, reward total was -14.0. running mean: -17.200257895652445, timestamp: 2022-08-20 09:22:29.383355\n",
      "resetting env. episode 4683, reward total was -18.0. running mean: -17.20825531669592, timestamp: 2022-08-20 09:22:32.310391\n",
      "resetting env. episode 4684, reward total was -17.0. running mean: -17.20617276352896, timestamp: 2022-08-20 09:22:35.894437\n",
      "resetting env. episode 4685, reward total was -19.0. running mean: -17.224111035893674, timestamp: 2022-08-20 09:22:38.323466\n",
      "resetting env. episode 4686, reward total was -18.0. running mean: -17.23186992553474, timestamp: 2022-08-20 09:22:41.234499\n",
      "resetting env. episode 4687, reward total was -18.0. running mean: -17.239551226279392, timestamp: 2022-08-20 09:22:43.611529\n",
      "resetting env. episode 4688, reward total was -19.0. running mean: -17.257155714016598, timestamp: 2022-08-20 09:22:45.063551\n",
      "resetting env. episode 4689, reward total was -15.0. running mean: -17.23458415687643, timestamp: 2022-08-20 09:22:48.383109\n",
      "resetting env. episode 4690, reward total was -18.0. running mean: -17.242238315307667, timestamp: 2022-08-20 09:22:50.372128\n",
      "resetting env. episode 4691, reward total was -16.0. running mean: -17.22981593215459, timestamp: 2022-08-20 09:22:53.019170\n",
      "resetting env. episode 4692, reward total was -20.0. running mean: -17.257517772833044, timestamp: 2022-08-20 09:22:55.191199\n",
      "resetting env. episode 4693, reward total was -18.0. running mean: -17.264942595104714, timestamp: 2022-08-20 09:22:58.589231\n",
      "resetting env. episode 4694, reward total was -10.0. running mean: -17.19229316915367, timestamp: 2022-08-20 09:23:02.650802\n",
      "resetting env. episode 4695, reward total was -17.0. running mean: -17.190370237462133, timestamp: 2022-08-20 09:23:05.046831\n",
      "resetting env. episode 4696, reward total was -15.0. running mean: -17.16846653508751, timestamp: 2022-08-20 09:23:08.234876\n",
      "resetting env. episode 4697, reward total was -19.0. running mean: -17.186781869736638, timestamp: 2022-08-20 09:23:10.782431\n",
      "resetting env. episode 4698, reward total was -21.0. running mean: -17.224914051039274, timestamp: 2022-08-20 09:23:13.296463\n",
      "resetting env. episode 4699, reward total was -18.0. running mean: -17.232664910528882, timestamp: 2022-08-20 09:23:16.201499\n",
      "resetting env. episode 4700, reward total was -17.0. running mean: -17.230338261423594, timestamp: 2022-08-20 09:23:19.037531\n",
      "resetting env. episode 4701, reward total was -19.0. running mean: -17.24803487880936, timestamp: 2022-08-20 09:23:22.394576\n",
      "resetting env. episode 4702, reward total was -21.0. running mean: -17.285554530021265, timestamp: 2022-08-20 09:23:24.344595\n",
      "resetting env. episode 4703, reward total was -17.0. running mean: -17.282698984721055, timestamp: 2022-08-20 09:23:27.347635\n",
      "resetting env. episode 4704, reward total was -20.0. running mean: -17.309871994873845, timestamp: 2022-08-20 09:23:29.724666\n",
      "resetting env. episode 4705, reward total was -10.0. running mean: -17.236773274925106, timestamp: 2022-08-20 09:23:33.788711\n",
      "resetting env. episode 4706, reward total was -18.0. running mean: -17.244405542175855, timestamp: 2022-08-20 09:23:36.101739\n",
      "resetting env. episode 4707, reward total was -16.0. running mean: -17.231961486754095, timestamp: 2022-08-20 09:23:38.529770\n",
      "resetting env. episode 4708, reward total was -16.0. running mean: -17.219641871886555, timestamp: 2022-08-20 09:23:41.012797\n",
      "resetting env. episode 4709, reward total was -16.0. running mean: -17.20744545316769, timestamp: 2022-08-20 09:23:43.915832\n",
      "resetting env. episode 4710, reward total was -19.0. running mean: -17.225370998636013, timestamp: 2022-08-20 09:23:46.303863\n",
      "resetting env. episode 4711, reward total was -14.0. running mean: -17.193117288649653, timestamp: 2022-08-20 09:23:49.847907\n",
      "resetting env. episode 4712, reward total was -17.0. running mean: -17.19118611576316, timestamp: 2022-08-20 09:23:51.799935\n",
      "resetting env. episode 4713, reward total was -19.0. running mean: -17.20927425460553, timestamp: 2022-08-20 09:23:54.873969\n",
      "resetting env. episode 4714, reward total was -17.0. running mean: -17.207181512059474, timestamp: 2022-08-20 09:23:58.052010\n",
      "resetting env. episode 4715, reward total was -18.0. running mean: -17.215109696938878, timestamp: 2022-08-20 09:24:00.530036\n",
      "resetting env. episode 4716, reward total was -16.0. running mean: -17.202958599969488, timestamp: 2022-08-20 09:24:02.513062\n",
      "resetting env. episode 4717, reward total was -16.0. running mean: -17.190929013969793, timestamp: 2022-08-20 09:24:05.658106\n",
      "resetting env. episode 4718, reward total was -19.0. running mean: -17.209019723830096, timestamp: 2022-08-20 09:24:07.804127\n",
      "resetting env. episode 4719, reward total was -16.0. running mean: -17.196929526591795, timestamp: 2022-08-20 09:24:10.592158\n",
      "resetting env. episode 4720, reward total was -17.0. running mean: -17.19496023132588, timestamp: 2022-08-20 09:24:13.183234\n",
      "resetting env. episode 4721, reward total was -17.0. running mean: -17.193010629012623, timestamp: 2022-08-20 09:24:15.756268\n",
      "resetting env. episode 4722, reward total was -16.0. running mean: -17.181080522722496, timestamp: 2022-08-20 09:24:19.354307\n",
      "resetting env. episode 4723, reward total was -17.0. running mean: -17.179269717495274, timestamp: 2022-08-20 09:24:22.155342\n",
      "resetting env. episode 4724, reward total was -13.0. running mean: -17.13747702032032, timestamp: 2022-08-20 09:24:25.929397\n",
      "resetting env. episode 4725, reward total was -19.0. running mean: -17.156102250117115, timestamp: 2022-08-20 09:24:29.186430\n",
      "resetting env. episode 4726, reward total was -19.0. running mean: -17.174541227615943, timestamp: 2022-08-20 09:24:30.978450\n",
      "resetting env. episode 4727, reward total was -13.0. running mean: -17.132795815339783, timestamp: 2022-08-20 09:24:34.340494\n",
      "resetting env. episode 4728, reward total was -19.0. running mean: -17.151467857186386, timestamp: 2022-08-20 09:24:37.355530\n",
      "resetting env. episode 4729, reward total was -19.0. running mean: -17.169953178614524, timestamp: 2022-08-20 09:24:40.486566\n",
      "resetting env. episode 4730, reward total was -19.0. running mean: -17.18825364682838, timestamp: 2022-08-20 09:24:43.744602\n",
      "resetting env. episode 4731, reward total was -17.0. running mean: -17.186371110360096, timestamp: 2022-08-20 09:24:45.953153\n",
      "resetting env. episode 4732, reward total was -17.0. running mean: -17.184507399256496, timestamp: 2022-08-20 09:24:48.934188\n",
      "resetting env. episode 4733, reward total was -12.0. running mean: -17.132662325263933, timestamp: 2022-08-20 09:24:52.051750\n",
      "resetting env. episode 4734, reward total was -19.0. running mean: -17.151335702011295, timestamp: 2022-08-20 09:24:55.728792\n",
      "resetting env. episode 4735, reward total was -20.0. running mean: -17.17982234499118, timestamp: 2022-08-20 09:24:57.488344\n",
      "resetting env. episode 4736, reward total was -17.0. running mean: -17.17802412154127, timestamp: 2022-08-20 09:25:01.277915\n",
      "resetting env. episode 4737, reward total was -21.0. running mean: -17.21624388032586, timestamp: 2022-08-20 09:25:04.559953\n",
      "resetting env. episode 4738, reward total was -20.0. running mean: -17.2440814415226, timestamp: 2022-08-20 09:25:07.645990\n",
      "resetting env. episode 4739, reward total was -19.0. running mean: -17.261640627107376, timestamp: 2022-08-20 09:25:10.275022\n",
      "resetting env. episode 4740, reward total was -20.0. running mean: -17.2890242208363, timestamp: 2022-08-20 09:25:12.391046\n",
      "resetting env. episode 4741, reward total was -17.0. running mean: -17.286133978627937, timestamp: 2022-08-20 09:25:15.427082\n",
      "resetting env. episode 4742, reward total was -19.0. running mean: -17.30327263884166, timestamp: 2022-08-20 09:25:17.458106\n",
      "resetting env. episode 4743, reward total was -19.0. running mean: -17.320239912453243, timestamp: 2022-08-20 09:25:20.517143\n",
      "resetting env. episode 4744, reward total was -15.0. running mean: -17.297037513328707, timestamp: 2022-08-20 09:25:23.259177\n",
      "resetting env. episode 4745, reward total was -16.0. running mean: -17.28406713819542, timestamp: 2022-08-20 09:25:26.559218\n",
      "resetting env. episode 4746, reward total was -19.0. running mean: -17.301226466813468, timestamp: 2022-08-20 09:25:28.312243\n",
      "resetting env. episode 4747, reward total was -16.0. running mean: -17.288214202145333, timestamp: 2022-08-20 09:25:31.035274\n",
      "resetting env. episode 4748, reward total was -17.0. running mean: -17.28533206012388, timestamp: 2022-08-20 09:25:33.673306\n",
      "resetting env. episode 4749, reward total was -17.0. running mean: -17.282478739522645, timestamp: 2022-08-20 09:25:35.848329\n",
      "resetting env. episode 4750, reward total was -18.0. running mean: -17.28965395212742, timestamp: 2022-08-20 09:25:38.424410\n",
      "resetting env. episode 4751, reward total was -21.0. running mean: -17.326757412606145, timestamp: 2022-08-20 09:25:41.133444\n",
      "resetting env. episode 4752, reward total was -14.0. running mean: -17.293489838480085, timestamp: 2022-08-20 09:25:43.981481\n",
      "resetting env. episode 4753, reward total was -16.0. running mean: -17.280554940095282, timestamp: 2022-08-20 09:25:46.724511\n",
      "resetting env. episode 4754, reward total was -19.0. running mean: -17.29774939069433, timestamp: 2022-08-20 09:25:49.317544\n",
      "resetting env. episode 4755, reward total was -14.0. running mean: -17.264771896787387, timestamp: 2022-08-20 09:25:53.046586\n",
      "resetting env. episode 4756, reward total was -18.0. running mean: -17.272124177819514, timestamp: 2022-08-20 09:25:55.855625\n",
      "resetting env. episode 4757, reward total was -15.0. running mean: -17.249402936041317, timestamp: 2022-08-20 09:25:58.343655\n",
      "resetting env. episode 4758, reward total was -19.0. running mean: -17.266908906680904, timestamp: 2022-08-20 09:26:00.112674\n",
      "resetting env. episode 4759, reward total was -11.0. running mean: -17.204239817614095, timestamp: 2022-08-20 09:26:05.111733\n",
      "resetting env. episode 4760, reward total was -15.0. running mean: -17.18219741943795, timestamp: 2022-08-20 09:26:07.568764\n",
      "resetting env. episode 4761, reward total was -20.0. running mean: -17.21037544524357, timestamp: 2022-08-20 09:26:09.352784\n",
      "resetting env. episode 4762, reward total was -17.0. running mean: -17.208271690791136, timestamp: 2022-08-20 09:26:11.936821\n",
      "resetting env. episode 4763, reward total was -20.0. running mean: -17.236188973883223, timestamp: 2022-08-20 09:26:14.026840\n",
      "resetting env. episode 4764, reward total was -18.0. running mean: -17.24382708414439, timestamp: 2022-08-20 09:26:17.637886\n",
      "resetting env. episode 4765, reward total was -19.0. running mean: -17.261388813302947, timestamp: 2022-08-20 09:26:19.497907\n",
      "resetting env. episode 4766, reward total was -12.0. running mean: -17.20877492516992, timestamp: 2022-08-20 09:26:23.845961\n",
      "resetting env. episode 4767, reward total was -16.0. running mean: -17.19668717591822, timestamp: 2022-08-20 09:26:26.774997\n",
      "resetting env. episode 4768, reward total was -18.0. running mean: -17.20472030415904, timestamp: 2022-08-20 09:26:30.125038\n",
      "resetting env. episode 4769, reward total was -20.0. running mean: -17.23267310111745, timestamp: 2022-08-20 09:26:32.000059\n",
      "resetting env. episode 4770, reward total was -10.0. running mean: -17.160346370106275, timestamp: 2022-08-20 09:26:36.854115\n",
      "resetting env. episode 4771, reward total was -16.0. running mean: -17.14874290640521, timestamp: 2022-08-20 09:26:40.293160\n",
      "resetting env. episode 4772, reward total was -20.0. running mean: -17.17725547734116, timestamp: 2022-08-20 09:26:42.756189\n",
      "resetting env. episode 4773, reward total was -19.0. running mean: -17.19548292256775, timestamp: 2022-08-20 09:26:44.898213\n",
      "resetting env. episode 4774, reward total was -17.0. running mean: -17.193528093342074, timestamp: 2022-08-20 09:26:48.637258\n",
      "resetting env. episode 4775, reward total was -16.0. running mean: -17.181592812408653, timestamp: 2022-08-20 09:26:51.233287\n",
      "resetting env. episode 4776, reward total was -14.0. running mean: -17.149776884284567, timestamp: 2022-08-20 09:26:54.487331\n",
      "resetting env. episode 4777, reward total was -12.0. running mean: -17.098279115441724, timestamp: 2022-08-20 09:26:58.197371\n",
      "resetting env. episode 4778, reward total was -20.0. running mean: -17.127296324287304, timestamp: 2022-08-20 09:27:00.882403\n",
      "resetting env. episode 4779, reward total was -15.0. running mean: -17.10602336104443, timestamp: 2022-08-20 09:27:03.997445\n",
      "resetting env. episode 4780, reward total was -17.0. running mean: -17.104963127433987, timestamp: 2022-08-20 09:27:07.413484\n",
      "resetting env. episode 4781, reward total was -20.0. running mean: -17.133913496159646, timestamp: 2022-08-20 09:27:10.931055\n",
      "resetting env. episode 4782, reward total was -17.0. running mean: -17.132574361198053, timestamp: 2022-08-20 09:27:13.422084\n",
      "resetting env. episode 4783, reward total was -17.0. running mean: -17.131248617586074, timestamp: 2022-08-20 09:27:16.323116\n",
      "resetting env. episode 4784, reward total was -20.0. running mean: -17.159936131410213, timestamp: 2022-08-20 09:27:18.163138\n",
      "resetting env. episode 4785, reward total was -16.0. running mean: -17.148336770096112, timestamp: 2022-08-20 09:27:21.362179\n",
      "resetting env. episode 4786, reward total was -17.0. running mean: -17.146853402395152, timestamp: 2022-08-20 09:27:24.186215\n",
      "resetting env. episode 4787, reward total was -18.0. running mean: -17.1553848683712, timestamp: 2022-08-20 09:27:26.430239\n",
      "resetting env. episode 4788, reward total was -14.0. running mean: -17.12383101968749, timestamp: 2022-08-20 09:27:29.992286\n",
      "resetting env. episode 4789, reward total was -13.0. running mean: -17.082592709490616, timestamp: 2022-08-20 09:27:33.705325\n",
      "resetting env. episode 4790, reward total was -12.0. running mean: -17.03176678239571, timestamp: 2022-08-20 09:27:38.256427\n",
      "resetting env. episode 4791, reward total was -14.0. running mean: -17.001449114571752, timestamp: 2022-08-20 09:27:41.633467\n",
      "resetting env. episode 4792, reward total was -18.0. running mean: -17.011434623426034, timestamp: 2022-08-20 09:27:44.069494\n",
      "resetting env. episode 4793, reward total was -18.0. running mean: -17.021320277191773, timestamp: 2022-08-20 09:27:47.109531\n",
      "resetting env. episode 4794, reward total was -14.0. running mean: -16.991107074419855, timestamp: 2022-08-20 09:27:49.986573\n",
      "resetting env. episode 4795, reward total was -15.0. running mean: -16.971196003675654, timestamp: 2022-08-20 09:27:53.131135\n",
      "resetting env. episode 4796, reward total was -19.0. running mean: -16.9914840436389, timestamp: 2022-08-20 09:27:55.617165\n",
      "resetting env. episode 4797, reward total was -18.0. running mean: -17.00156920320251, timestamp: 2022-08-20 09:27:58.737203\n",
      "resetting env. episode 4798, reward total was -15.0. running mean: -16.981553511170485, timestamp: 2022-08-20 09:28:02.515251\n",
      "resetting env. episode 4799, reward total was -15.0. running mean: -16.961737976058778, timestamp: 2022-08-20 09:28:07.271308\n",
      "resetting env. episode 4800, reward total was -15.0. running mean: -16.94212059629819, timestamp: 2022-08-20 09:28:09.646333\n",
      "resetting env. episode 4801, reward total was -16.0. running mean: -16.932699390335205, timestamp: 2022-08-20 09:28:13.223380\n",
      "resetting env. episode 4802, reward total was -13.0. running mean: -16.893372396431854, timestamp: 2022-08-20 09:28:17.449430\n",
      "resetting env. episode 4803, reward total was -14.0. running mean: -16.864438672467536, timestamp: 2022-08-20 09:28:20.595466\n",
      "resetting env. episode 4804, reward total was -17.0. running mean: -16.86579428574286, timestamp: 2022-08-20 09:28:23.629503\n",
      "resetting env. episode 4805, reward total was -20.0. running mean: -16.89713634288543, timestamp: 2022-08-20 09:28:26.019536\n",
      "resetting env. episode 4806, reward total was -17.0. running mean: -16.898164979456578, timestamp: 2022-08-20 09:28:28.689565\n",
      "resetting env. episode 4807, reward total was -16.0. running mean: -16.88918332966201, timestamp: 2022-08-20 09:28:31.475598\n",
      "resetting env. episode 4808, reward total was -15.0. running mean: -16.87029149636539, timestamp: 2022-08-20 09:28:34.027628\n",
      "resetting env. episode 4809, reward total was -16.0. running mean: -16.861588581401737, timestamp: 2022-08-20 09:28:36.415657\n",
      "resetting env. episode 4810, reward total was -10.0. running mean: -16.79297269558772, timestamp: 2022-08-20 09:28:40.508230\n",
      "resetting env. episode 4811, reward total was -19.0. running mean: -16.815042968631847, timestamp: 2022-08-20 09:28:43.221272\n",
      "resetting env. episode 4812, reward total was -14.0. running mean: -16.78689253894553, timestamp: 2022-08-20 09:28:46.654304\n",
      "resetting env. episode 4813, reward total was -19.0. running mean: -16.809023613556075, timestamp: 2022-08-20 09:28:49.458337\n",
      "resetting env. episode 4814, reward total was -17.0. running mean: -16.810933377420515, timestamp: 2022-08-20 09:28:52.439375\n",
      "resetting env. episode 4815, reward total was -14.0. running mean: -16.78282404364631, timestamp: 2022-08-20 09:28:55.195409\n",
      "resetting env. episode 4816, reward total was -14.0. running mean: -16.754995803209848, timestamp: 2022-08-20 09:28:58.557447\n",
      "resetting env. episode 4817, reward total was -19.0. running mean: -16.777445845177752, timestamp: 2022-08-20 09:29:00.565476\n",
      "resetting env. episode 4818, reward total was -15.0. running mean: -16.759671386725973, timestamp: 2022-08-20 09:29:03.497510\n",
      "resetting env. episode 4819, reward total was -17.0. running mean: -16.762074672858716, timestamp: 2022-08-20 09:29:05.942539\n",
      "resetting env. episode 4820, reward total was -20.0. running mean: -16.794453926130128, timestamp: 2022-08-20 09:29:07.467557\n",
      "resetting env. episode 4821, reward total was -20.0. running mean: -16.826509386868825, timestamp: 2022-08-20 09:29:09.444585\n",
      "resetting env. episode 4822, reward total was -21.0. running mean: -16.86824429300014, timestamp: 2022-08-20 09:29:11.689607\n",
      "resetting env. episode 4823, reward total was -16.0. running mean: -16.859561850070136, timestamp: 2022-08-20 09:29:15.181650\n",
      "resetting env. episode 4824, reward total was -18.0. running mean: -16.870966231569433, timestamp: 2022-08-20 09:29:17.709205\n",
      "resetting env. episode 4825, reward total was -12.0. running mean: -16.82225656925374, timestamp: 2022-08-20 09:29:21.193251\n",
      "resetting env. episode 4826, reward total was -17.0. running mean: -16.824034003561202, timestamp: 2022-08-20 09:29:23.882281\n",
      "resetting env. episode 4827, reward total was -16.0. running mean: -16.81579366352559, timestamp: 2022-08-20 09:29:26.652315\n",
      "resetting env. episode 4828, reward total was -20.0. running mean: -16.84763572689033, timestamp: 2022-08-20 09:29:29.274352\n",
      "resetting env. episode 4829, reward total was -15.0. running mean: -16.829159369621426, timestamp: 2022-08-20 09:29:32.428388\n",
      "resetting env. episode 4830, reward total was -18.0. running mean: -16.84086777592521, timestamp: 2022-08-20 09:29:35.841426\n",
      "resetting env. episode 4831, reward total was -14.0. running mean: -16.81245909816596, timestamp: 2022-08-20 09:29:38.672466\n",
      "resetting env. episode 4832, reward total was -20.0. running mean: -16.8443345071843, timestamp: 2022-08-20 09:29:41.029488\n",
      "resetting env. episode 4833, reward total was -15.0. running mean: -16.825891162112455, timestamp: 2022-08-20 09:29:43.999526\n",
      "resetting env. episode 4834, reward total was -19.0. running mean: -16.847632250491333, timestamp: 2022-08-20 09:29:46.882566\n",
      "resetting env. episode 4835, reward total was -15.0. running mean: -16.82915592798642, timestamp: 2022-08-20 09:29:49.871123\n",
      "resetting env. episode 4836, reward total was -14.0. running mean: -16.800864368706556, timestamp: 2022-08-20 09:29:53.118160\n",
      "resetting env. episode 4837, reward total was -17.0. running mean: -16.80285572501949, timestamp: 2022-08-20 09:29:56.280197\n",
      "resetting env. episode 4838, reward total was -19.0. running mean: -16.824827167769296, timestamp: 2022-08-20 09:29:59.010753\n",
      "resetting env. episode 4839, reward total was -15.0. running mean: -16.8065788960916, timestamp: 2022-08-20 09:30:02.311800\n",
      "resetting env. episode 4840, reward total was -19.0. running mean: -16.828513107130686, timestamp: 2022-08-20 09:30:04.733346\n",
      "resetting env. episode 4841, reward total was -18.0. running mean: -16.840227976059378, timestamp: 2022-08-20 09:30:07.355379\n",
      "resetting env. episode 4842, reward total was -18.0. running mean: -16.851825696298782, timestamp: 2022-08-20 09:30:10.447418\n",
      "resetting env. episode 4843, reward total was -14.0. running mean: -16.823307439335796, timestamp: 2022-08-20 09:30:13.940460\n",
      "resetting env. episode 4844, reward total was -15.0. running mean: -16.805074364942435, timestamp: 2022-08-20 09:30:17.106500\n",
      "resetting env. episode 4845, reward total was -17.0. running mean: -16.807023621293013, timestamp: 2022-08-20 09:30:19.550527\n",
      "resetting env. episode 4846, reward total was -15.0. running mean: -16.78895338508008, timestamp: 2022-08-20 09:30:22.939569\n",
      "resetting env. episode 4847, reward total was -17.0. running mean: -16.791063851229282, timestamp: 2022-08-20 09:30:26.775619\n",
      "resetting env. episode 4848, reward total was -20.0. running mean: -16.82315321271699, timestamp: 2022-08-20 09:30:29.613651\n",
      "resetting env. episode 4849, reward total was -9.0. running mean: -16.74492168058982, timestamp: 2022-08-20 09:30:34.128709\n",
      "resetting env. episode 4850, reward total was -15.0. running mean: -16.72747246378392, timestamp: 2022-08-20 09:30:37.065740\n",
      "resetting env. episode 4851, reward total was -17.0. running mean: -16.73019773914608, timestamp: 2022-08-20 09:30:39.732775\n",
      "resetting env. episode 4852, reward total was -10.0. running mean: -16.662895761754623, timestamp: 2022-08-20 09:30:43.608822\n",
      "resetting env. episode 4853, reward total was -19.0. running mean: -16.686266804137077, timestamp: 2022-08-20 09:30:45.532848\n",
      "resetting env. episode 4854, reward total was -19.0. running mean: -16.709404136095706, timestamp: 2022-08-20 09:30:48.005876\n",
      "resetting env. episode 4855, reward total was -15.0. running mean: -16.692310094734747, timestamp: 2022-08-20 09:30:51.559918\n",
      "resetting env. episode 4856, reward total was -14.0. running mean: -16.6653869937874, timestamp: 2022-08-20 09:30:55.029963\n",
      "resetting env. episode 4857, reward total was -20.0. running mean: -16.698733123849525, timestamp: 2022-08-20 09:30:57.181991\n",
      "resetting env. episode 4858, reward total was -19.0. running mean: -16.72174579261103, timestamp: 2022-08-20 09:31:00.015022\n",
      "resetting env. episode 4859, reward total was -17.0. running mean: -16.724528334684923, timestamp: 2022-08-20 09:31:03.128064\n",
      "resetting env. episode 4860, reward total was -21.0. running mean: -16.767283051338076, timestamp: 2022-08-20 09:31:05.534092\n",
      "resetting env. episode 4861, reward total was -19.0. running mean: -16.789610220824695, timestamp: 2022-08-20 09:31:08.090126\n",
      "resetting env. episode 4862, reward total was -13.0. running mean: -16.751714118616448, timestamp: 2022-08-20 09:31:12.308177\n",
      "resetting env. episode 4863, reward total was -18.0. running mean: -16.764196977430284, timestamp: 2022-08-20 09:31:15.436209\n",
      "resetting env. episode 4864, reward total was -17.0. running mean: -16.766555007655985, timestamp: 2022-08-20 09:31:17.958244\n",
      "resetting env. episode 4865, reward total was -19.0. running mean: -16.788889457579426, timestamp: 2022-08-20 09:31:20.542274\n",
      "resetting env. episode 4866, reward total was -17.0. running mean: -16.79100056300363, timestamp: 2022-08-20 09:31:23.650312\n",
      "resetting env. episode 4867, reward total was -13.0. running mean: -16.753090557373593, timestamp: 2022-08-20 09:31:26.600352\n",
      "resetting env. episode 4868, reward total was -16.0. running mean: -16.74555965179986, timestamp: 2022-08-20 09:31:29.290381\n",
      "resetting env. episode 4869, reward total was -18.0. running mean: -16.75810405528186, timestamp: 2022-08-20 09:31:31.733409\n",
      "resetting env. episode 4870, reward total was -17.0. running mean: -16.760523014729042, timestamp: 2022-08-20 09:31:34.044439\n",
      "resetting env. episode 4871, reward total was -17.0. running mean: -16.762917784581752, timestamp: 2022-08-20 09:31:37.301480\n",
      "resetting env. episode 4872, reward total was -21.0. running mean: -16.805288606735935, timestamp: 2022-08-20 09:31:39.500506\n",
      "resetting env. episode 4873, reward total was -16.0. running mean: -16.797235720668574, timestamp: 2022-08-20 09:31:42.989546\n",
      "resetting env. episode 4874, reward total was -18.0. running mean: -16.809263363461888, timestamp: 2022-08-20 09:31:45.953585\n",
      "resetting env. episode 4875, reward total was -16.0. running mean: -16.80117072982727, timestamp: 2022-08-20 09:31:48.949623\n",
      "resetting env. episode 4876, reward total was -12.0. running mean: -16.753159022528997, timestamp: 2022-08-20 09:31:52.851667\n",
      "resetting env. episode 4877, reward total was -13.0. running mean: -16.715627432303705, timestamp: 2022-08-20 09:31:56.549710\n",
      "resetting env. episode 4878, reward total was -15.0. running mean: -16.698471157980666, timestamp: 2022-08-20 09:32:00.160759\n",
      "resetting env. episode 4879, reward total was -17.0. running mean: -16.70148644640086, timestamp: 2022-08-20 09:32:03.045313\n",
      "resetting env. episode 4880, reward total was -20.0. running mean: -16.73447158193685, timestamp: 2022-08-20 09:32:05.104343\n",
      "resetting env. episode 4881, reward total was -15.0. running mean: -16.717126866117482, timestamp: 2022-08-20 09:32:07.675372\n",
      "resetting env. episode 4882, reward total was -17.0. running mean: -16.71995559745631, timestamp: 2022-08-20 09:32:10.525405\n",
      "resetting env. episode 4883, reward total was -19.0. running mean: -16.742756041481748, timestamp: 2022-08-20 09:32:12.493430\n",
      "resetting env. episode 4884, reward total was -13.0. running mean: -16.70532848106693, timestamp: 2022-08-20 09:32:16.233482\n",
      "resetting env. episode 4885, reward total was -18.0. running mean: -16.718275196256258, timestamp: 2022-08-20 09:32:18.413503\n",
      "resetting env. episode 4886, reward total was -15.0. running mean: -16.701092444293693, timestamp: 2022-08-20 09:32:21.919543\n",
      "resetting env. episode 4887, reward total was -12.0. running mean: -16.654081519850756, timestamp: 2022-08-20 09:32:25.805592\n",
      "resetting env. episode 4888, reward total was -21.0. running mean: -16.697540704652248, timestamp: 2022-08-20 09:32:28.364623\n",
      "resetting env. episode 4889, reward total was -19.0. running mean: -16.720565297605727, timestamp: 2022-08-20 09:32:30.777652\n",
      "resetting env. episode 4890, reward total was -17.0. running mean: -16.72335964462967, timestamp: 2022-08-20 09:32:33.726690\n",
      "resetting env. episode 4891, reward total was -15.0. running mean: -16.70612604818337, timestamp: 2022-08-20 09:32:36.934728\n",
      "resetting env. episode 4892, reward total was -17.0. running mean: -16.70906478770154, timestamp: 2022-08-20 09:32:40.448772\n",
      "resetting env. episode 4893, reward total was -15.0. running mean: -16.691974139824524, timestamp: 2022-08-20 09:32:44.140820\n",
      "resetting env. episode 4894, reward total was -12.0. running mean: -16.64505439842628, timestamp: 2022-08-20 09:32:47.263856\n",
      "resetting env. episode 4895, reward total was -18.0. running mean: -16.658603854442017, timestamp: 2022-08-20 09:32:49.403402\n",
      "resetting env. episode 4896, reward total was -18.0. running mean: -16.672017815897597, timestamp: 2022-08-20 09:32:51.447952\n",
      "resetting env. episode 4897, reward total was -18.0. running mean: -16.68529763773862, timestamp: 2022-08-20 09:32:53.992981\n",
      "resetting env. episode 4898, reward total was -18.0. running mean: -16.698444661361236, timestamp: 2022-08-20 09:32:56.128010\n",
      "resetting env. episode 4899, reward total was -17.0. running mean: -16.701460214747627, timestamp: 2022-08-20 09:32:59.092571\n",
      "resetting env. episode 4900, reward total was -17.0. running mean: -16.704445612600153, timestamp: 2022-08-20 09:33:02.071604\n",
      "resetting env. episode 4901, reward total was -18.0. running mean: -16.71740115647415, timestamp: 2022-08-20 09:33:04.410632\n",
      "resetting env. episode 4902, reward total was -16.0. running mean: -16.710227144909407, timestamp: 2022-08-20 09:33:07.257194\n",
      "resetting env. episode 4903, reward total was -20.0. running mean: -16.74312487346031, timestamp: 2022-08-20 09:33:08.745211\n",
      "resetting env. episode 4904, reward total was -14.0. running mean: -16.715693624725706, timestamp: 2022-08-20 09:33:11.681245\n",
      "resetting env. episode 4905, reward total was -16.0. running mean: -16.70853668847845, timestamp: 2022-08-20 09:33:14.855284\n",
      "resetting env. episode 4906, reward total was -14.0. running mean: -16.681451321593666, timestamp: 2022-08-20 09:33:17.786325\n",
      "resetting env. episode 4907, reward total was -16.0. running mean: -16.67463680837773, timestamp: 2022-08-20 09:33:20.151348\n",
      "resetting env. episode 4908, reward total was -19.0. running mean: -16.697890440293953, timestamp: 2022-08-20 09:33:22.372376\n",
      "resetting env. episode 4909, reward total was -18.0. running mean: -16.710911535891015, timestamp: 2022-08-20 09:33:25.635417\n",
      "resetting env. episode 4910, reward total was -21.0. running mean: -16.753802420532104, timestamp: 2022-08-20 09:33:27.766443\n",
      "resetting env. episode 4911, reward total was -15.0. running mean: -16.73626439632678, timestamp: 2022-08-20 09:33:31.931496\n",
      "resetting env. episode 4912, reward total was -20.0. running mean: -16.76890175236351, timestamp: 2022-08-20 09:33:34.227523\n",
      "resetting env. episode 4913, reward total was -16.0. running mean: -16.761212734839877, timestamp: 2022-08-20 09:33:37.674565\n",
      "resetting env. episode 4914, reward total was -19.0. running mean: -16.78360060749148, timestamp: 2022-08-20 09:33:40.555599\n",
      "resetting env. episode 4915, reward total was -15.0. running mean: -16.765764601416564, timestamp: 2022-08-20 09:33:43.217636\n",
      "resetting env. episode 4916, reward total was -17.0. running mean: -16.7681069554024, timestamp: 2022-08-20 09:33:46.575675\n",
      "resetting env. episode 4917, reward total was -19.0. running mean: -16.790425885848375, timestamp: 2022-08-20 09:33:49.245708\n",
      "resetting env. episode 4918, reward total was -20.0. running mean: -16.82252162698989, timestamp: 2022-08-20 09:33:50.903733\n",
      "resetting env. episode 4919, reward total was -20.0. running mean: -16.85429641071999, timestamp: 2022-08-20 09:33:52.878757\n",
      "resetting env. episode 4920, reward total was -19.0. running mean: -16.87575344661279, timestamp: 2022-08-20 09:33:55.171780\n",
      "resetting env. episode 4921, reward total was -20.0. running mean: -16.906995912146662, timestamp: 2022-08-20 09:33:56.989803\n",
      "resetting env. episode 4922, reward total was -15.0. running mean: -16.887925953025196, timestamp: 2022-08-20 09:34:00.211843\n",
      "resetting env. episode 4923, reward total was -14.0. running mean: -16.859046693494943, timestamp: 2022-08-20 09:34:02.925924\n",
      "resetting env. episode 4924, reward total was -16.0. running mean: -16.85045622655999, timestamp: 2022-08-20 09:34:06.915975\n",
      "resetting env. episode 4925, reward total was -18.0. running mean: -16.86195166429439, timestamp: 2022-08-20 09:34:09.167533\n",
      "resetting env. episode 4926, reward total was -19.0. running mean: -16.883332147651448, timestamp: 2022-08-20 09:34:11.282555\n",
      "resetting env. episode 4927, reward total was -16.0. running mean: -16.874498826174932, timestamp: 2022-08-20 09:34:13.770586\n",
      "resetting env. episode 4928, reward total was -19.0. running mean: -16.895753837913183, timestamp: 2022-08-20 09:34:16.421625\n",
      "resetting env. episode 4929, reward total was -16.0. running mean: -16.88679629953405, timestamp: 2022-08-20 09:34:19.130657\n",
      "resetting env. episode 4930, reward total was -16.0. running mean: -16.877928336538712, timestamp: 2022-08-20 09:34:22.604694\n",
      "resetting env. episode 4931, reward total was -16.0. running mean: -16.869149053173324, timestamp: 2022-08-20 09:34:25.688734\n",
      "resetting env. episode 4932, reward total was -21.0. running mean: -16.91045756264159, timestamp: 2022-08-20 09:34:27.239753\n",
      "resetting env. episode 4933, reward total was -19.0. running mean: -16.931352987015174, timestamp: 2022-08-20 09:34:30.112786\n",
      "resetting env. episode 4934, reward total was -17.0. running mean: -16.932039457145024, timestamp: 2022-08-20 09:34:32.648819\n",
      "resetting env. episode 4935, reward total was -12.0. running mean: -16.882719062573575, timestamp: 2022-08-20 09:34:36.976873\n",
      "resetting env. episode 4936, reward total was -19.0. running mean: -16.90389187194784, timestamp: 2022-08-20 09:34:38.688892\n",
      "resetting env. episode 4937, reward total was -18.0. running mean: -16.914852953228362, timestamp: 2022-08-20 09:34:41.679929\n",
      "resetting env. episode 4938, reward total was -19.0. running mean: -16.93570442369608, timestamp: 2022-08-20 09:34:44.079965\n",
      "resetting env. episode 4939, reward total was -14.0. running mean: -16.90634737945912, timestamp: 2022-08-20 09:34:46.692992\n",
      "resetting env. episode 4940, reward total was -14.0. running mean: -16.87728390566453, timestamp: 2022-08-20 09:34:50.086033\n",
      "resetting env. episode 4941, reward total was -17.0. running mean: -16.878511066607885, timestamp: 2022-08-20 09:34:52.382063\n",
      "resetting env. episode 4942, reward total was -19.0. running mean: -16.899725955941808, timestamp: 2022-08-20 09:34:54.497086\n",
      "resetting env. episode 4943, reward total was -21.0. running mean: -16.94072869638239, timestamp: 2022-08-20 09:34:56.706113\n",
      "resetting env. episode 4944, reward total was -18.0. running mean: -16.951321409418565, timestamp: 2022-08-20 09:34:59.659150\n",
      "resetting env. episode 4945, reward total was -17.0. running mean: -16.951808195324382, timestamp: 2022-08-20 09:35:02.495188\n",
      "resetting env. episode 4946, reward total was -18.0. running mean: -16.96229011337114, timestamp: 2022-08-20 09:35:05.035217\n",
      "resetting env. episode 4947, reward total was -16.0. running mean: -16.95266721223743, timestamp: 2022-08-20 09:35:08.711261\n",
      "resetting env. episode 4948, reward total was -19.0. running mean: -16.973140540115057, timestamp: 2022-08-20 09:35:11.205293\n",
      "resetting env. episode 4949, reward total was -15.0. running mean: -16.953409134713905, timestamp: 2022-08-20 09:35:13.783325\n",
      "resetting env. episode 4950, reward total was -10.0. running mean: -16.883875043366768, timestamp: 2022-08-20 09:35:17.146367\n",
      "resetting env. episode 4951, reward total was -13.0. running mean: -16.8450362929331, timestamp: 2022-08-20 09:35:20.256405\n",
      "resetting env. episode 4952, reward total was -19.0. running mean: -16.86658593000377, timestamp: 2022-08-20 09:35:22.404435\n",
      "resetting env. episode 4953, reward total was -10.0. running mean: -16.797920070703732, timestamp: 2022-08-20 09:35:25.858475\n",
      "resetting env. episode 4954, reward total was -18.0. running mean: -16.809940869996694, timestamp: 2022-08-20 09:35:28.194503\n",
      "resetting env. episode 4955, reward total was -17.0. running mean: -16.81184146129673, timestamp: 2022-08-20 09:35:30.901542\n",
      "resetting env. episode 4956, reward total was -14.0. running mean: -16.783723046683765, timestamp: 2022-08-20 09:35:33.930571\n",
      "resetting env. episode 4957, reward total was -13.0. running mean: -16.745885816216926, timestamp: 2022-08-20 09:35:37.079612\n",
      "resetting env. episode 4958, reward total was -15.0. running mean: -16.728426958054754, timestamp: 2022-08-20 09:35:40.180649\n",
      "resetting env. episode 4959, reward total was -14.0. running mean: -16.701142688474206, timestamp: 2022-08-20 09:35:43.462692\n",
      "resetting env. episode 4960, reward total was -19.0. running mean: -16.724131261589466, timestamp: 2022-08-20 09:35:46.274724\n",
      "resetting env. episode 4961, reward total was -11.0. running mean: -16.66688994897357, timestamp: 2022-08-20 09:35:49.974782\n",
      "resetting env. episode 4962, reward total was -20.0. running mean: -16.700221049483833, timestamp: 2022-08-20 09:35:52.336806\n",
      "resetting env. episode 4963, reward total was -15.0. running mean: -16.683218838988992, timestamp: 2022-08-20 09:35:56.010847\n",
      "resetting env. episode 4964, reward total was -17.0. running mean: -16.686386650599104, timestamp: 2022-08-20 09:35:58.739877\n",
      "resetting env. episode 4965, reward total was -19.0. running mean: -16.709522784093114, timestamp: 2022-08-20 09:36:01.501913\n",
      "resetting env. episode 4966, reward total was -16.0. running mean: -16.702427556252182, timestamp: 2022-08-20 09:36:05.474959\n",
      "resetting env. episode 4967, reward total was -13.0. running mean: -16.66540328068966, timestamp: 2022-08-20 09:36:08.845000\n",
      "resetting env. episode 4968, reward total was -18.0. running mean: -16.678749247882763, timestamp: 2022-08-20 09:36:11.070032\n",
      "resetting env. episode 4969, reward total was -20.0. running mean: -16.711961755403934, timestamp: 2022-08-20 09:36:13.621060\n",
      "resetting env. episode 4970, reward total was -17.0. running mean: -16.714842137849896, timestamp: 2022-08-20 09:36:15.757084\n",
      "resetting env. episode 4971, reward total was -19.0. running mean: -16.737693716471398, timestamp: 2022-08-20 09:36:18.121636\n",
      "resetting env. episode 4972, reward total was -15.0. running mean: -16.720316779306682, timestamp: 2022-08-20 09:36:21.717681\n",
      "resetting env. episode 4973, reward total was -17.0. running mean: -16.723113611513618, timestamp: 2022-08-20 09:36:25.420726\n",
      "resetting env. episode 4974, reward total was -16.0. running mean: -16.71588247539848, timestamp: 2022-08-20 09:36:29.352812\n",
      "resetting env. episode 4975, reward total was -18.0. running mean: -16.728723650644493, timestamp: 2022-08-20 09:36:32.798856\n",
      "resetting env. episode 4976, reward total was -19.0. running mean: -16.75143641413805, timestamp: 2022-08-20 09:36:35.849895\n",
      "resetting env. episode 4977, reward total was -19.0. running mean: -16.77392204999667, timestamp: 2022-08-20 09:36:38.136923\n",
      "resetting env. episode 4978, reward total was -17.0. running mean: -16.776182829496705, timestamp: 2022-08-20 09:36:40.320948\n",
      "resetting env. episode 4979, reward total was -18.0. running mean: -16.788421001201737, timestamp: 2022-08-20 09:36:43.785991\n",
      "resetting env. episode 4980, reward total was -14.0. running mean: -16.76053679118972, timestamp: 2022-08-20 09:36:48.250045\n",
      "resetting env. episode 4981, reward total was -10.0. running mean: -16.692931423277823, timestamp: 2022-08-20 09:36:53.040103\n",
      "resetting env. episode 4982, reward total was -15.0. running mean: -16.676002109045044, timestamp: 2022-08-20 09:36:56.607146\n",
      "resetting env. episode 4983, reward total was -17.0. running mean: -16.679242087954595, timestamp: 2022-08-20 09:36:59.326178\n",
      "resetting env. episode 4984, reward total was -17.0. running mean: -16.68244966707505, timestamp: 2022-08-20 09:37:02.650222\n",
      "resetting env. episode 4985, reward total was -17.0. running mean: -16.685625170404304, timestamp: 2022-08-20 09:37:05.469257\n",
      "resetting env. episode 4986, reward total was -21.0. running mean: -16.72876891870026, timestamp: 2022-08-20 09:37:07.881284\n",
      "resetting env. episode 4987, reward total was -20.0. running mean: -16.761481229513258, timestamp: 2022-08-20 09:37:09.969309\n",
      "resetting env. episode 4988, reward total was -18.0. running mean: -16.773866417218127, timestamp: 2022-08-20 09:37:12.142335\n",
      "resetting env. episode 4989, reward total was -17.0. running mean: -16.776127753045948, timestamp: 2022-08-20 09:37:15.590386\n",
      "resetting env. episode 4990, reward total was -19.0. running mean: -16.79836647551549, timestamp: 2022-08-20 09:37:18.768415\n",
      "resetting env. episode 4991, reward total was -19.0. running mean: -16.820382810760336, timestamp: 2022-08-20 09:37:21.644453\n",
      "resetting env. episode 4992, reward total was -16.0. running mean: -16.812178982652732, timestamp: 2022-08-20 09:37:24.324485\n",
      "resetting env. episode 4993, reward total was -19.0. running mean: -16.834057192826204, timestamp: 2022-08-20 09:37:26.601512\n",
      "resetting env. episode 4994, reward total was -12.0. running mean: -16.785716620897944, timestamp: 2022-08-20 09:37:29.460550\n",
      "resetting env. episode 4995, reward total was -21.0. running mean: -16.827859454688966, timestamp: 2022-08-20 09:37:31.686574\n",
      "resetting env. episode 4996, reward total was -15.0. running mean: -16.809580860142074, timestamp: 2022-08-20 09:37:35.687155\n",
      "resetting env. episode 4997, reward total was -13.0. running mean: -16.77148505154065, timestamp: 2022-08-20 09:37:39.115194\n",
      "resetting env. episode 4998, reward total was -13.0. running mean: -16.733770201025244, timestamp: 2022-08-20 09:37:41.956755\n",
      "resetting env. episode 4999, reward total was -20.0. running mean: -16.76643249901499, timestamp: 2022-08-20 09:37:43.656774\n",
      "resetting env. episode 5000, reward total was -16.0. running mean: -16.75876817402484, timestamp: 2022-08-20 09:37:46.560808\n",
      "resetting env. episode 5001, reward total was -16.0. running mean: -16.751180492284593, timestamp: 2022-08-20 09:37:49.166839\n",
      "resetting env. episode 5002, reward total was -14.0. running mean: -16.723668687361748, timestamp: 2022-08-20 09:37:52.397877\n",
      "resetting env. episode 5003, reward total was -17.0. running mean: -16.72643200048813, timestamp: 2022-08-20 09:37:54.876911\n",
      "resetting env. episode 5004, reward total was -21.0. running mean: -16.76916768048325, timestamp: 2022-08-20 09:37:57.045935\n",
      "resetting env. episode 5005, reward total was -13.0. running mean: -16.731476003678416, timestamp: 2022-08-20 09:38:00.766982\n",
      "resetting env. episode 5006, reward total was -15.0. running mean: -16.71416124364163, timestamp: 2022-08-20 09:38:03.825021\n",
      "resetting env. episode 5007, reward total was -13.0. running mean: -16.677019631205212, timestamp: 2022-08-20 09:38:06.845059\n",
      "resetting env. episode 5008, reward total was -18.0. running mean: -16.69024943489316, timestamp: 2022-08-20 09:38:08.923083\n",
      "resetting env. episode 5009, reward total was -18.0. running mean: -16.70334694054423, timestamp: 2022-08-20 09:38:11.501110\n",
      "resetting env. episode 5010, reward total was -16.0. running mean: -16.696313471138787, timestamp: 2022-08-20 09:38:14.445146\n",
      "resetting env. episode 5011, reward total was -17.0. running mean: -16.6993503364274, timestamp: 2022-08-20 09:38:16.859182\n",
      "resetting env. episode 5012, reward total was -18.0. running mean: -16.712356833063126, timestamp: 2022-08-20 09:38:19.018204\n",
      "resetting env. episode 5013, reward total was -16.0. running mean: -16.705233264732495, timestamp: 2022-08-20 09:38:22.771251\n",
      "resetting env. episode 5014, reward total was -19.0. running mean: -16.72818093208517, timestamp: 2022-08-20 09:38:24.751316\n",
      "resetting env. episode 5015, reward total was -15.0. running mean: -16.710899122764317, timestamp: 2022-08-20 09:38:27.993361\n",
      "resetting env. episode 5016, reward total was -17.0. running mean: -16.713790131536676, timestamp: 2022-08-20 09:38:31.819402\n",
      "resetting env. episode 5017, reward total was -18.0. running mean: -16.72665223022131, timestamp: 2022-08-20 09:38:33.839430\n",
      "resetting env. episode 5018, reward total was -16.0. running mean: -16.719385707919095, timestamp: 2022-08-20 09:38:36.667464\n",
      "resetting env. episode 5019, reward total was -16.0. running mean: -16.712191850839904, timestamp: 2022-08-20 09:38:39.590498\n",
      "resetting env. episode 5020, reward total was -13.0. running mean: -16.675069932331503, timestamp: 2022-08-20 09:38:42.925541\n",
      "resetting env. episode 5021, reward total was -20.0. running mean: -16.708319233008186, timestamp: 2022-08-20 09:38:45.477573\n",
      "resetting env. episode 5022, reward total was -15.0. running mean: -16.691236040678103, timestamp: 2022-08-20 09:38:48.644613\n",
      "resetting env. episode 5023, reward total was -20.0. running mean: -16.724323680271322, timestamp: 2022-08-20 09:38:50.634636\n",
      "resetting env. episode 5024, reward total was -16.0. running mean: -16.71708044346861, timestamp: 2022-08-20 09:38:53.174671\n",
      "resetting env. episode 5025, reward total was -16.0. running mean: -16.709909639033924, timestamp: 2022-08-20 09:38:56.058703\n",
      "resetting env. episode 5026, reward total was -18.0. running mean: -16.722810542643586, timestamp: 2022-08-20 09:38:59.004737\n",
      "resetting env. episode 5027, reward total was -15.0. running mean: -16.70558243721715, timestamp: 2022-08-20 09:39:02.237778\n",
      "resetting env. episode 5028, reward total was -16.0. running mean: -16.69852661284498, timestamp: 2022-08-20 09:39:04.788809\n",
      "resetting env. episode 5029, reward total was -21.0. running mean: -16.74154134671653, timestamp: 2022-08-20 09:39:06.283832\n",
      "resetting env. episode 5030, reward total was -18.0. running mean: -16.754125933249366, timestamp: 2022-08-20 09:39:08.159851\n",
      "resetting env. episode 5031, reward total was -20.0. running mean: -16.78658467391687, timestamp: 2022-08-20 09:39:10.108879\n",
      "resetting env. episode 5032, reward total was -14.0. running mean: -16.758718827177702, timestamp: 2022-08-20 09:39:14.082928\n",
      "resetting env. episode 5033, reward total was -17.0. running mean: -16.761131638905926, timestamp: 2022-08-20 09:39:16.111948\n",
      "resetting env. episode 5034, reward total was -18.0. running mean: -16.773520322516866, timestamp: 2022-08-20 09:39:19.069990\n",
      "resetting env. episode 5035, reward total was -18.0. running mean: -16.785785119291695, timestamp: 2022-08-20 09:39:21.638018\n",
      "resetting env. episode 5036, reward total was -19.0. running mean: -16.80792726809878, timestamp: 2022-08-20 09:39:24.118046\n",
      "resetting env. episode 5037, reward total was -20.0. running mean: -16.83984799541779, timestamp: 2022-08-20 09:39:26.533076\n",
      "resetting env. episode 5038, reward total was -17.0. running mean: -16.841449515463616, timestamp: 2022-08-20 09:39:29.252109\n",
      "resetting env. episode 5039, reward total was -16.0. running mean: -16.83303502030898, timestamp: 2022-08-20 09:39:32.046143\n",
      "resetting env. episode 5040, reward total was -16.0. running mean: -16.82470467010589, timestamp: 2022-08-20 09:39:35.784188\n",
      "resetting env. episode 5041, reward total was -15.0. running mean: -16.80645762340483, timestamp: 2022-08-20 09:39:38.145223\n",
      "resetting env. episode 5042, reward total was -17.0. running mean: -16.808393047170785, timestamp: 2022-08-20 09:39:40.313775\n",
      "resetting env. episode 5043, reward total was -15.0. running mean: -16.790309116699074, timestamp: 2022-08-20 09:39:42.996803\n",
      "resetting env. episode 5044, reward total was -20.0. running mean: -16.822406025532082, timestamp: 2022-08-20 09:39:44.486826\n",
      "resetting env. episode 5045, reward total was -19.0. running mean: -16.844181965276764, timestamp: 2022-08-20 09:39:46.402373\n",
      "resetting env. episode 5046, reward total was -12.0. running mean: -16.795740145624, timestamp: 2022-08-20 09:39:49.946419\n",
      "resetting env. episode 5047, reward total was -16.0. running mean: -16.78778274416776, timestamp: 2022-08-20 09:39:52.722450\n",
      "resetting env. episode 5048, reward total was -17.0. running mean: -16.789904916726083, timestamp: 2022-08-20 09:39:55.274485\n",
      "resetting env. episode 5049, reward total was -20.0. running mean: -16.822005867558822, timestamp: 2022-08-20 09:39:57.107504\n",
      "resetting env. episode 5050, reward total was -18.0. running mean: -16.833785808883235, timestamp: 2022-08-20 09:40:00.050542\n",
      "resetting env. episode 5051, reward total was -12.0. running mean: -16.785447950794403, timestamp: 2022-08-20 09:40:03.762586\n",
      "resetting env. episode 5052, reward total was -13.0. running mean: -16.747593471286457, timestamp: 2022-08-20 09:40:06.564624\n",
      "resetting env. episode 5053, reward total was -19.0. running mean: -16.770117536573593, timestamp: 2022-08-20 09:40:08.804647\n",
      "resetting env. episode 5054, reward total was -20.0. running mean: -16.802416361207857, timestamp: 2022-08-20 09:40:10.438665\n",
      "resetting env. episode 5055, reward total was -14.0. running mean: -16.77439219759578, timestamp: 2022-08-20 09:40:14.274720\n",
      "resetting env. episode 5056, reward total was -17.0. running mean: -16.776648275619824, timestamp: 2022-08-20 09:40:17.190274\n",
      "resetting env. episode 5057, reward total was -17.0. running mean: -16.778881792863626, timestamp: 2022-08-20 09:40:20.109835\n",
      "resetting env. episode 5058, reward total was -19.0. running mean: -16.801092974934992, timestamp: 2022-08-20 09:40:22.922869\n",
      "resetting env. episode 5059, reward total was -15.0. running mean: -16.78308204518564, timestamp: 2022-08-20 09:40:25.853906\n",
      "resetting env. episode 5060, reward total was -19.0. running mean: -16.805251224733784, timestamp: 2022-08-20 09:40:28.127462\n",
      "resetting env. episode 5061, reward total was -20.0. running mean: -16.837198712486444, timestamp: 2022-08-20 09:40:31.547499\n",
      "resetting env. episode 5062, reward total was -21.0. running mean: -16.87882672536158, timestamp: 2022-08-20 09:40:33.218520\n",
      "resetting env. episode 5063, reward total was -17.0. running mean: -16.880038458107965, timestamp: 2022-08-20 09:40:35.946552\n",
      "resetting env. episode 5064, reward total was -16.0. running mean: -16.871238073526886, timestamp: 2022-08-20 09:40:39.064593\n",
      "resetting env. episode 5065, reward total was -16.0. running mean: -16.862525692791618, timestamp: 2022-08-20 09:40:41.583625\n",
      "resetting env. episode 5066, reward total was -13.0. running mean: -16.8239004358637, timestamp: 2022-08-20 09:40:45.033669\n",
      "resetting env. episode 5067, reward total was -17.0. running mean: -16.825661431505065, timestamp: 2022-08-20 09:40:48.429706\n",
      "resetting env. episode 5068, reward total was -17.0. running mean: -16.827404817190015, timestamp: 2022-08-20 09:40:51.023739\n",
      "resetting env. episode 5069, reward total was -17.0. running mean: -16.829130769018118, timestamp: 2022-08-20 09:40:53.601769\n",
      "resetting env. episode 5070, reward total was -16.0. running mean: -16.820839461327935, timestamp: 2022-08-20 09:40:56.184798\n",
      "resetting env. episode 5071, reward total was -16.0. running mean: -16.812631066714655, timestamp: 2022-08-20 09:40:59.529367\n",
      "resetting env. episode 5072, reward total was -12.0. running mean: -16.764504756047508, timestamp: 2022-08-20 09:41:02.757403\n",
      "resetting env. episode 5073, reward total was -20.0. running mean: -16.79685970848703, timestamp: 2022-08-20 09:41:05.176956\n",
      "resetting env. episode 5074, reward total was -14.0. running mean: -16.768891111402162, timestamp: 2022-08-20 09:41:08.153987\n",
      "resetting env. episode 5075, reward total was -15.0. running mean: -16.751202200288137, timestamp: 2022-08-20 09:41:11.300031\n",
      "resetting env. episode 5076, reward total was -17.0. running mean: -16.753690178285257, timestamp: 2022-08-20 09:41:14.111060\n",
      "resetting env. episode 5077, reward total was -16.0. running mean: -16.746153276502405, timestamp: 2022-08-20 09:41:17.764107\n",
      "resetting env. episode 5078, reward total was -17.0. running mean: -16.748691743737382, timestamp: 2022-08-20 09:41:21.191149\n",
      "resetting env. episode 5079, reward total was -21.0. running mean: -16.79120482630001, timestamp: 2022-08-20 09:41:23.254701\n",
      "resetting env. episode 5080, reward total was -17.0. running mean: -16.79329277803701, timestamp: 2022-08-20 09:41:26.107257\n",
      "resetting env. episode 5081, reward total was -17.0. running mean: -16.79535985025664, timestamp: 2022-08-20 09:41:28.276281\n",
      "resetting env. episode 5082, reward total was -15.0. running mean: -16.777406251754073, timestamp: 2022-08-20 09:41:30.832315\n",
      "resetting env. episode 5083, reward total was -20.0. running mean: -16.80963218923653, timestamp: 2022-08-20 09:41:33.107344\n",
      "resetting env. episode 5084, reward total was -16.0. running mean: -16.801535867344164, timestamp: 2022-08-20 09:41:35.774374\n",
      "resetting env. episode 5085, reward total was -18.0. running mean: -16.81352050867072, timestamp: 2022-08-20 09:41:38.168406\n",
      "resetting env. episode 5086, reward total was -20.0. running mean: -16.845385303584013, timestamp: 2022-08-20 09:41:39.361417\n",
      "resetting env. episode 5087, reward total was -20.0. running mean: -16.876931450548174, timestamp: 2022-08-20 09:41:42.281454\n",
      "resetting env. episode 5088, reward total was -12.0. running mean: -16.828162136042693, timestamp: 2022-08-20 09:41:46.221501\n",
      "resetting env. episode 5089, reward total was -17.0. running mean: -16.829880514682266, timestamp: 2022-08-20 09:41:49.291544\n",
      "resetting env. episode 5090, reward total was -18.0. running mean: -16.841581709535443, timestamp: 2022-08-20 09:41:51.324565\n",
      "resetting env. episode 5091, reward total was -19.0. running mean: -16.86316589244009, timestamp: 2022-08-20 09:41:53.997595\n",
      "resetting env. episode 5092, reward total was -16.0. running mean: -16.85453423351569, timestamp: 2022-08-20 09:41:56.604150\n",
      "resetting env. episode 5093, reward total was -16.0. running mean: -16.845988891180532, timestamp: 2022-08-20 09:41:59.283186\n",
      "resetting env. episode 5094, reward total was -18.0. running mean: -16.857529002268727, timestamp: 2022-08-20 09:42:01.486207\n",
      "resetting env. episode 5095, reward total was -18.0. running mean: -16.86895371224604, timestamp: 2022-08-20 09:42:04.349246\n",
      "resetting env. episode 5096, reward total was -18.0. running mean: -16.88026417512358, timestamp: 2022-08-20 09:42:07.359283\n",
      "resetting env. episode 5097, reward total was -20.0. running mean: -16.911461533372343, timestamp: 2022-08-20 09:42:09.293308\n",
      "resetting env. episode 5098, reward total was -20.0. running mean: -16.94234691803862, timestamp: 2022-08-20 09:42:11.933336\n",
      "resetting env. episode 5099, reward total was -20.0. running mean: -16.972923448858232, timestamp: 2022-08-20 09:42:14.192364\n",
      "resetting env. episode 5100, reward total was -20.0. running mean: -17.00319421436965, timestamp: 2022-08-20 09:42:17.105395\n",
      "resetting env. episode 5101, reward total was -16.0. running mean: -16.993162272225952, timestamp: 2022-08-20 09:42:19.691429\n",
      "resetting env. episode 5102, reward total was -17.0. running mean: -16.993230649503694, timestamp: 2022-08-20 09:42:22.612463\n",
      "resetting env. episode 5103, reward total was -18.0. running mean: -17.003298343008655, timestamp: 2022-08-20 09:42:24.668488\n",
      "resetting env. episode 5104, reward total was -16.0. running mean: -16.99326535957857, timestamp: 2022-08-20 09:42:27.459521\n",
      "resetting env. episode 5105, reward total was -14.0. running mean: -16.963332705982783, timestamp: 2022-08-20 09:42:30.423561\n",
      "resetting env. episode 5106, reward total was -17.0. running mean: -16.963699378922957, timestamp: 2022-08-20 09:42:33.244594\n",
      "resetting env. episode 5107, reward total was -14.0. running mean: -16.93406238513373, timestamp: 2022-08-20 09:42:36.735637\n",
      "resetting env. episode 5108, reward total was -19.0. running mean: -16.954721761282393, timestamp: 2022-08-20 09:42:39.156664\n",
      "resetting env. episode 5109, reward total was -19.0. running mean: -16.97517454366957, timestamp: 2022-08-20 09:42:41.551217\n",
      "resetting env. episode 5110, reward total was -19.0. running mean: -16.995422798232877, timestamp: 2022-08-20 09:42:43.058234\n",
      "resetting env. episode 5111, reward total was -19.0. running mean: -17.015468570250547, timestamp: 2022-08-20 09:42:45.707265\n",
      "resetting env. episode 5112, reward total was -15.0. running mean: -16.99531388454804, timestamp: 2022-08-20 09:42:48.667302\n",
      "resetting env. episode 5113, reward total was -15.0. running mean: -16.975360745702556, timestamp: 2022-08-20 09:42:52.210342\n",
      "resetting env. episode 5114, reward total was -19.0. running mean: -16.995607138245532, timestamp: 2022-08-20 09:42:54.482371\n",
      "resetting env. episode 5115, reward total was -16.0. running mean: -16.985651066863078, timestamp: 2022-08-20 09:42:57.136407\n",
      "resetting env. episode 5116, reward total was -19.0. running mean: -17.00579455619445, timestamp: 2022-08-20 09:42:59.977436\n",
      "resetting env. episode 5117, reward total was -15.0. running mean: -16.985736610632504, timestamp: 2022-08-20 09:43:02.548471\n",
      "resetting env. episode 5118, reward total was -13.0. running mean: -16.94587924452618, timestamp: 2022-08-20 09:43:06.276515\n",
      "resetting env. episode 5119, reward total was -20.0. running mean: -16.976420452080916, timestamp: 2022-08-20 09:43:08.123536\n",
      "resetting env. episode 5120, reward total was -18.0. running mean: -16.986656247560106, timestamp: 2022-08-20 09:43:11.052573\n",
      "resetting env. episode 5121, reward total was -18.0. running mean: -16.996789685084504, timestamp: 2022-08-20 09:43:13.404600\n",
      "resetting env. episode 5122, reward total was -17.0. running mean: -16.99682178823366, timestamp: 2022-08-20 09:43:16.156638\n",
      "resetting env. episode 5123, reward total was -19.0. running mean: -17.016853570351326, timestamp: 2022-08-20 09:43:18.329662\n",
      "resetting env. episode 5124, reward total was -21.0. running mean: -17.056685034647813, timestamp: 2022-08-20 09:43:20.156682\n",
      "resetting env. episode 5125, reward total was -18.0. running mean: -17.066118184301335, timestamp: 2022-08-20 09:43:22.751713\n",
      "resetting env. episode 5126, reward total was -18.0. running mean: -17.07545700245832, timestamp: 2022-08-20 09:43:25.833750\n",
      "resetting env. episode 5127, reward total was -18.0. running mean: -17.084702432433737, timestamp: 2022-08-20 09:43:28.583789\n",
      "resetting env. episode 5128, reward total was -16.0. running mean: -17.0738554081094, timestamp: 2022-08-20 09:43:31.853823\n",
      "resetting env. episode 5129, reward total was -18.0. running mean: -17.083116854028304, timestamp: 2022-08-20 09:43:34.850862\n",
      "resetting env. episode 5130, reward total was -12.0. running mean: -17.032285685488024, timestamp: 2022-08-20 09:43:39.539917\n",
      "resetting env. episode 5131, reward total was -17.0. running mean: -17.031962828633144, timestamp: 2022-08-20 09:43:43.598966\n",
      "resetting env. episode 5132, reward total was -15.0. running mean: -17.01164320034681, timestamp: 2022-08-20 09:43:47.241012\n",
      "resetting env. episode 5133, reward total was -17.0. running mean: -17.011526768343344, timestamp: 2022-08-20 09:43:50.222045\n",
      "resetting env. episode 5134, reward total was -16.0. running mean: -17.001411500659913, timestamp: 2022-08-20 09:43:53.260087\n",
      "resetting env. episode 5135, reward total was -17.0. running mean: -17.001397385653316, timestamp: 2022-08-20 09:43:57.426135\n",
      "resetting env. episode 5136, reward total was -17.0. running mean: -17.001383411796784, timestamp: 2022-08-20 09:44:01.445184\n",
      "resetting env. episode 5137, reward total was -19.0. running mean: -17.02136957767882, timestamp: 2022-08-20 09:44:04.371218\n",
      "resetting env. episode 5138, reward total was -19.0. running mean: -17.041155881902032, timestamp: 2022-08-20 09:44:06.210244\n",
      "resetting env. episode 5139, reward total was -15.0. running mean: -17.02074432308301, timestamp: 2022-08-20 09:44:09.291280\n",
      "resetting env. episode 5140, reward total was -18.0. running mean: -17.030536879852182, timestamp: 2022-08-20 09:44:11.888311\n",
      "resetting env. episode 5141, reward total was -18.0. running mean: -17.04023151105366, timestamp: 2022-08-20 09:44:14.751346\n",
      "resetting env. episode 5142, reward total was -16.0. running mean: -17.029829195943122, timestamp: 2022-08-20 09:44:17.465382\n",
      "resetting env. episode 5143, reward total was -14.0. running mean: -16.999530903983693, timestamp: 2022-08-20 09:44:20.147419\n",
      "resetting env. episode 5144, reward total was -12.0. running mean: -16.949535594943857, timestamp: 2022-08-20 09:44:23.633453\n",
      "resetting env. episode 5145, reward total was -14.0. running mean: -16.920040238994417, timestamp: 2022-08-20 09:44:26.944493\n",
      "resetting env. episode 5146, reward total was -12.0. running mean: -16.870839836604475, timestamp: 2022-08-20 09:44:30.459535\n",
      "resetting env. episode 5147, reward total was -17.0. running mean: -16.87213143823843, timestamp: 2022-08-20 09:44:33.843577\n",
      "resetting env. episode 5148, reward total was -20.0. running mean: -16.903410123856045, timestamp: 2022-08-20 09:44:36.839617\n",
      "resetting env. episode 5149, reward total was -19.0. running mean: -16.924376022617484, timestamp: 2022-08-20 09:44:39.164644\n",
      "resetting env. episode 5150, reward total was -20.0. running mean: -16.95513226239131, timestamp: 2022-08-20 09:44:41.892674\n",
      "resetting env. episode 5151, reward total was -16.0. running mean: -16.945580939767396, timestamp: 2022-08-20 09:44:44.946236\n",
      "resetting env. episode 5152, reward total was -18.0. running mean: -16.95612513036972, timestamp: 2022-08-20 09:44:47.667270\n",
      "resetting env. episode 5153, reward total was -19.0. running mean: -16.976563879066024, timestamp: 2022-08-20 09:44:50.368300\n",
      "resetting env. episode 5154, reward total was -18.0. running mean: -16.986798240275363, timestamp: 2022-08-20 09:44:53.450338\n",
      "resetting env. episode 5155, reward total was -14.0. running mean: -16.95693025787261, timestamp: 2022-08-20 09:44:56.320378\n",
      "resetting env. episode 5156, reward total was -14.0. running mean: -16.927360955293885, timestamp: 2022-08-20 09:44:59.300415\n",
      "resetting env. episode 5157, reward total was -18.0. running mean: -16.938087345740946, timestamp: 2022-08-20 09:45:01.676438\n",
      "resetting env. episode 5158, reward total was -19.0. running mean: -16.958706472283538, timestamp: 2022-08-20 09:45:04.591477\n",
      "resetting env. episode 5159, reward total was -17.0. running mean: -16.959119407560703, timestamp: 2022-08-20 09:45:07.030030\n",
      "resetting env. episode 5160, reward total was -14.0. running mean: -16.929528213485096, timestamp: 2022-08-20 09:45:10.783127\n",
      "resetting env. episode 5161, reward total was -18.0. running mean: -16.940232931350245, timestamp: 2022-08-20 09:45:12.884155\n",
      "resetting env. episode 5162, reward total was -15.0. running mean: -16.92083060203674, timestamp: 2022-08-20 09:45:15.931194\n",
      "resetting env. episode 5163, reward total was -20.0. running mean: -16.95162229601637, timestamp: 2022-08-20 09:45:18.627228\n",
      "resetting env. episode 5164, reward total was -19.0. running mean: -16.97210607305621, timestamp: 2022-08-20 09:45:20.904253\n",
      "resetting env. episode 5165, reward total was -11.0. running mean: -16.912385012325647, timestamp: 2022-08-20 09:45:24.697297\n",
      "resetting env. episode 5166, reward total was -18.0. running mean: -16.92326116220239, timestamp: 2022-08-20 09:45:27.074325\n",
      "resetting env. episode 5167, reward total was -19.0. running mean: -16.944028550580366, timestamp: 2022-08-20 09:45:28.830353\n",
      "resetting env. episode 5168, reward total was -16.0. running mean: -16.934588265074563, timestamp: 2022-08-20 09:45:31.730381\n",
      "resetting env. episode 5169, reward total was -16.0. running mean: -16.925242382423818, timestamp: 2022-08-20 09:45:34.612416\n",
      "resetting env. episode 5170, reward total was -13.0. running mean: -16.885989958599577, timestamp: 2022-08-20 09:45:38.394464\n",
      "resetting env. episode 5171, reward total was -11.0. running mean: -16.82713005901358, timestamp: 2022-08-20 09:45:42.716517\n",
      "resetting env. episode 5172, reward total was -16.0. running mean: -16.818858758423445, timestamp: 2022-08-20 09:45:45.587550\n",
      "resetting env. episode 5173, reward total was -16.0. running mean: -16.81067017083921, timestamp: 2022-08-20 09:45:48.756591\n",
      "resetting env. episode 5174, reward total was -18.0. running mean: -16.822563469130817, timestamp: 2022-08-20 09:45:51.800627\n",
      "resetting env. episode 5175, reward total was -16.0. running mean: -16.81433783443951, timestamp: 2022-08-20 09:45:55.326671\n",
      "resetting env. episode 5176, reward total was -16.0. running mean: -16.806194456095113, timestamp: 2022-08-20 09:45:58.347710\n",
      "resetting env. episode 5177, reward total was -21.0. running mean: -16.848132511534164, timestamp: 2022-08-20 09:46:00.662734\n",
      "resetting env. episode 5178, reward total was -11.0. running mean: -16.789651186418823, timestamp: 2022-08-20 09:46:04.784785\n",
      "resetting env. episode 5179, reward total was -12.0. running mean: -16.741754674554635, timestamp: 2022-08-20 09:46:07.831821\n",
      "resetting env. episode 5180, reward total was -14.0. running mean: -16.714337127809088, timestamp: 2022-08-20 09:46:11.573868\n",
      "resetting env. episode 5181, reward total was -15.0. running mean: -16.697193756530996, timestamp: 2022-08-20 09:46:14.523902\n",
      "resetting env. episode 5182, reward total was -18.0. running mean: -16.710221818965685, timestamp: 2022-08-20 09:46:16.993932\n",
      "resetting env. episode 5183, reward total was -20.0. running mean: -16.743119600776026, timestamp: 2022-08-20 09:46:19.333964\n",
      "resetting env. episode 5184, reward total was -18.0. running mean: -16.755688404768264, timestamp: 2022-08-20 09:46:21.635992\n",
      "resetting env. episode 5185, reward total was -21.0. running mean: -16.79813152072058, timestamp: 2022-08-20 09:46:23.951018\n",
      "resetting env. episode 5186, reward total was -13.0. running mean: -16.760150205513373, timestamp: 2022-08-20 09:46:27.293059\n",
      "resetting env. episode 5187, reward total was -21.0. running mean: -16.80254870345824, timestamp: 2022-08-20 09:46:30.111095\n",
      "resetting env. episode 5188, reward total was -19.0. running mean: -16.824523216423657, timestamp: 2022-08-20 09:46:32.528126\n",
      "resetting env. episode 5189, reward total was -16.0. running mean: -16.816277984259422, timestamp: 2022-08-20 09:46:35.990163\n",
      "resetting env. episode 5190, reward total was -19.0. running mean: -16.83811520441683, timestamp: 2022-08-20 09:46:38.234194\n",
      "resetting env. episode 5191, reward total was -19.0. running mean: -16.859734052372662, timestamp: 2022-08-20 09:46:40.510220\n",
      "resetting env. episode 5192, reward total was -18.0. running mean: -16.871136711848933, timestamp: 2022-08-20 09:46:44.154265\n",
      "resetting env. episode 5193, reward total was -18.0. running mean: -16.882425344730443, timestamp: 2022-08-20 09:46:46.722297\n",
      "resetting env. episode 5194, reward total was -19.0. running mean: -16.90360109128314, timestamp: 2022-08-20 09:46:49.490329\n",
      "resetting env. episode 5195, reward total was -14.0. running mean: -16.87456508037031, timestamp: 2022-08-20 09:46:53.092377\n",
      "resetting env. episode 5196, reward total was -20.0. running mean: -16.905819429566606, timestamp: 2022-08-20 09:46:56.218411\n",
      "resetting env. episode 5197, reward total was -15.0. running mean: -16.88676123527094, timestamp: 2022-08-20 09:46:59.650455\n",
      "resetting env. episode 5198, reward total was -18.0. running mean: -16.89789362291823, timestamp: 2022-08-20 09:47:02.529495\n",
      "resetting env. episode 5199, reward total was -20.0. running mean: -16.928914686689044, timestamp: 2022-08-20 09:47:05.085520\n",
      "resetting env. episode 5200, reward total was -20.0. running mean: -16.959625539822152, timestamp: 2022-08-20 09:47:07.328547\n",
      "resetting env. episode 5201, reward total was -16.0. running mean: -16.95002928442393, timestamp: 2022-08-20 09:47:10.653589\n",
      "resetting env. episode 5202, reward total was -16.0. running mean: -16.94052899157969, timestamp: 2022-08-20 09:47:13.792149\n",
      "resetting env. episode 5203, reward total was -20.0. running mean: -16.971123701663892, timestamp: 2022-08-20 09:47:16.382180\n",
      "resetting env. episode 5204, reward total was -14.0. running mean: -16.941412464647254, timestamp: 2022-08-20 09:47:20.417228\n",
      "resetting env. episode 5205, reward total was -14.0. running mean: -16.911998340000782, timestamp: 2022-08-20 09:47:23.744269\n",
      "resetting env. episode 5206, reward total was -16.0. running mean: -16.902878356600773, timestamp: 2022-08-20 09:47:26.483312\n",
      "resetting env. episode 5207, reward total was -17.0. running mean: -16.903849573034766, timestamp: 2022-08-20 09:47:29.043341\n",
      "resetting env. episode 5208, reward total was -18.0. running mean: -16.914811077304417, timestamp: 2022-08-20 09:47:32.362380\n",
      "resetting env. episode 5209, reward total was -15.0. running mean: -16.895662966531372, timestamp: 2022-08-20 09:47:35.866425\n",
      "resetting env. episode 5210, reward total was -19.0. running mean: -16.91670633686606, timestamp: 2022-08-20 09:47:38.065445\n",
      "resetting env. episode 5211, reward total was -15.0. running mean: -16.897539273497397, timestamp: 2022-08-20 09:47:41.918490\n",
      "resetting env. episode 5212, reward total was -18.0. running mean: -16.908563880762422, timestamp: 2022-08-20 09:47:45.509538\n",
      "resetting env. episode 5213, reward total was -7.0. running mean: -16.8094782419548, timestamp: 2022-08-20 09:47:49.760591\n",
      "resetting env. episode 5214, reward total was -18.0. running mean: -16.82138345953525, timestamp: 2022-08-20 09:47:53.028632\n",
      "resetting env. episode 5215, reward total was -19.0. running mean: -16.8431696249399, timestamp: 2022-08-20 09:47:55.624658\n",
      "resetting env. episode 5216, reward total was -16.0. running mean: -16.8347379286905, timestamp: 2022-08-20 09:47:58.743217\n",
      "resetting env. episode 5217, reward total was -15.0. running mean: -16.816390549403593, timestamp: 2022-08-20 09:48:02.134259\n",
      "resetting env. episode 5218, reward total was -17.0. running mean: -16.818226643909558, timestamp: 2022-08-20 09:48:05.156300\n",
      "resetting env. episode 5219, reward total was -17.0. running mean: -16.820044377470463, timestamp: 2022-08-20 09:48:08.425336\n",
      "resetting env. episode 5220, reward total was -17.0. running mean: -16.82184393369576, timestamp: 2022-08-20 09:48:11.714380\n",
      "resetting env. episode 5221, reward total was -15.0. running mean: -16.8036254943588, timestamp: 2022-08-20 09:48:14.749414\n",
      "resetting env. episode 5222, reward total was -18.0. running mean: -16.815589239415214, timestamp: 2022-08-20 09:48:18.245978\n",
      "resetting env. episode 5223, reward total was -17.0. running mean: -16.817433347021062, timestamp: 2022-08-20 09:48:20.585006\n",
      "resetting env. episode 5224, reward total was -15.0. running mean: -16.79925901355085, timestamp: 2022-08-20 09:48:23.631571\n",
      "resetting env. episode 5225, reward total was -9.0. running mean: -16.72126642341534, timestamp: 2022-08-20 09:48:27.454622\n",
      "resetting env. episode 5226, reward total was -16.0. running mean: -16.714053759181187, timestamp: 2022-08-20 09:48:30.421654\n",
      "resetting env. episode 5227, reward total was -14.0. running mean: -16.686913221589375, timestamp: 2022-08-20 09:48:34.087698\n",
      "resetting env. episode 5228, reward total was -9.0. running mean: -16.61004408937348, timestamp: 2022-08-20 09:48:38.853755\n",
      "resetting env. episode 5229, reward total was -17.0. running mean: -16.613943648479747, timestamp: 2022-08-20 09:48:42.303797\n",
      "resetting env. episode 5230, reward total was -19.0. running mean: -16.63780421199495, timestamp: 2022-08-20 09:48:45.007830\n",
      "resetting env. episode 5231, reward total was -17.0. running mean: -16.641426169875004, timestamp: 2022-08-20 09:48:47.884865\n",
      "resetting env. episode 5232, reward total was -15.0. running mean: -16.62501190817625, timestamp: 2022-08-20 09:48:50.272894\n",
      "resetting env. episode 5233, reward total was -13.0. running mean: -16.588761789094487, timestamp: 2022-08-20 09:48:54.407950\n",
      "resetting env. episode 5234, reward total was -14.0. running mean: -16.562874171203543, timestamp: 2022-08-20 09:48:57.145978\n",
      "resetting env. episode 5235, reward total was -20.0. running mean: -16.597245429491508, timestamp: 2022-08-20 09:48:58.913002\n",
      "resetting env. episode 5236, reward total was -16.0. running mean: -16.591272975196592, timestamp: 2022-08-20 09:49:01.715035\n",
      "resetting env. episode 5237, reward total was -17.0. running mean: -16.595360245444628, timestamp: 2022-08-20 09:49:05.557089\n",
      "resetting env. episode 5238, reward total was -19.0. running mean: -16.61940664299018, timestamp: 2022-08-20 09:49:08.455120\n",
      "resetting env. episode 5239, reward total was -19.0. running mean: -16.64321257656028, timestamp: 2022-08-20 09:49:11.872157\n",
      "resetting env. episode 5240, reward total was -14.0. running mean: -16.61678045079468, timestamp: 2022-08-20 09:49:15.191197\n",
      "resetting env. episode 5241, reward total was -17.0. running mean: -16.620612646286734, timestamp: 2022-08-20 09:49:17.766230\n",
      "resetting env. episode 5242, reward total was -11.0. running mean: -16.564406519823866, timestamp: 2022-08-20 09:49:22.502289\n",
      "resetting env. episode 5243, reward total was -9.0. running mean: -16.488762454625626, timestamp: 2022-08-20 09:49:27.544350\n",
      "resetting env. episode 5244, reward total was -18.0. running mean: -16.50387483007937, timestamp: 2022-08-20 09:49:29.718378\n",
      "resetting env. episode 5245, reward total was -16.0. running mean: -16.498836081778574, timestamp: 2022-08-20 09:49:32.569417\n",
      "resetting env. episode 5246, reward total was -19.0. running mean: -16.523847720960788, timestamp: 2022-08-20 09:49:35.100454\n",
      "resetting env. episode 5247, reward total was -17.0. running mean: -16.52860924375118, timestamp: 2022-08-20 09:49:38.476484\n",
      "resetting env. episode 5248, reward total was -18.0. running mean: -16.54332315131367, timestamp: 2022-08-20 09:49:40.507508\n",
      "resetting env. episode 5249, reward total was -15.0. running mean: -16.52788991980053, timestamp: 2022-08-20 09:49:43.964552\n",
      "resetting env. episode 5250, reward total was -13.0. running mean: -16.492611020602524, timestamp: 2022-08-20 09:49:47.912602\n",
      "resetting env. episode 5251, reward total was -16.0. running mean: -16.4876849103965, timestamp: 2022-08-20 09:49:50.825638\n",
      "resetting env. episode 5252, reward total was -18.0. running mean: -16.502808061292534, timestamp: 2022-08-20 09:49:53.246676\n",
      "resetting env. episode 5253, reward total was -14.0. running mean: -16.47777998067961, timestamp: 2022-08-20 09:49:57.585722\n",
      "resetting env. episode 5254, reward total was -19.0. running mean: -16.503002180872816, timestamp: 2022-08-20 09:50:00.667759\n",
      "resetting env. episode 5255, reward total was -16.0. running mean: -16.497972159064087, timestamp: 2022-08-20 09:50:03.278789\n",
      "resetting env. episode 5256, reward total was -12.0. running mean: -16.452992437473448, timestamp: 2022-08-20 09:50:06.757833\n",
      "resetting env. episode 5257, reward total was -12.0. running mean: -16.408462513098716, timestamp: 2022-08-20 09:50:11.743894\n",
      "resetting env. episode 5258, reward total was -13.0. running mean: -16.37437788796773, timestamp: 2022-08-20 09:50:14.679932\n",
      "resetting env. episode 5259, reward total was -16.0. running mean: -16.37063410908805, timestamp: 2022-08-20 09:50:17.362963\n",
      "resetting env. episode 5260, reward total was -17.0. running mean: -16.376927767997174, timestamp: 2022-08-20 09:50:20.692004\n",
      "resetting env. episode 5261, reward total was -12.0. running mean: -16.333158490317203, timestamp: 2022-08-20 09:50:23.999044\n",
      "resetting env. episode 5262, reward total was -15.0. running mean: -16.31982690541403, timestamp: 2022-08-20 09:50:28.165097\n",
      "resetting env. episode 5263, reward total was -17.0. running mean: -16.32662863635989, timestamp: 2022-08-20 09:50:31.376137\n",
      "resetting env. episode 5264, reward total was -15.0. running mean: -16.31336234999629, timestamp: 2022-08-20 09:50:34.977181\n",
      "resetting env. episode 5265, reward total was -18.0. running mean: -16.330228726496326, timestamp: 2022-08-20 09:50:38.867233\n",
      "resetting env. episode 5266, reward total was -12.0. running mean: -16.286926439231365, timestamp: 2022-08-20 09:50:41.656264\n",
      "resetting env. episode 5267, reward total was -17.0. running mean: -16.294057174839054, timestamp: 2022-08-20 09:50:44.352299\n",
      "resetting env. episode 5268, reward total was -13.0. running mean: -16.261116603090663, timestamp: 2022-08-20 09:50:47.590335\n",
      "resetting env. episode 5269, reward total was -15.0. running mean: -16.248505437059755, timestamp: 2022-08-20 09:50:51.849389\n",
      "resetting env. episode 5270, reward total was -19.0. running mean: -16.276020382689158, timestamp: 2022-08-20 09:50:54.979429\n",
      "resetting env. episode 5271, reward total was -17.0. running mean: -16.283260178862268, timestamp: 2022-08-20 09:50:58.035468\n",
      "resetting env. episode 5272, reward total was -17.0. running mean: -16.290427577073647, timestamp: 2022-08-20 09:51:01.115504\n",
      "resetting env. episode 5273, reward total was -17.0. running mean: -16.297523301302913, timestamp: 2022-08-20 09:51:04.454542\n",
      "resetting env. episode 5274, reward total was -17.0. running mean: -16.304548068289886, timestamp: 2022-08-20 09:51:07.792585\n",
      "resetting env. episode 5275, reward total was -20.0. running mean: -16.341502587606985, timestamp: 2022-08-20 09:51:09.592607\n",
      "resetting env. episode 5276, reward total was -15.0. running mean: -16.328087561730914, timestamp: 2022-08-20 09:51:13.152650\n",
      "resetting env. episode 5277, reward total was -19.0. running mean: -16.354806686113605, timestamp: 2022-08-20 09:51:15.495677\n",
      "resetting env. episode 5278, reward total was -15.0. running mean: -16.341258619252468, timestamp: 2022-08-20 09:51:19.328723\n",
      "resetting env. episode 5279, reward total was -17.0. running mean: -16.347846033059945, timestamp: 2022-08-20 09:51:22.380289\n",
      "resetting env. episode 5280, reward total was -20.0. running mean: -16.384367572729346, timestamp: 2022-08-20 09:51:25.248325\n",
      "resetting env. episode 5281, reward total was -20.0. running mean: -16.420523897002052, timestamp: 2022-08-20 09:51:28.159361\n",
      "resetting env. episode 5282, reward total was -14.0. running mean: -16.396318658032033, timestamp: 2022-08-20 09:51:32.053407\n",
      "resetting env. episode 5283, reward total was -18.0. running mean: -16.41235547145171, timestamp: 2022-08-20 09:51:35.296445\n",
      "resetting env. episode 5284, reward total was -16.0. running mean: -16.408231916737194, timestamp: 2022-08-20 09:51:37.798476\n",
      "resetting env. episode 5285, reward total was -17.0. running mean: -16.414149597569825, timestamp: 2022-08-20 09:51:40.564511\n",
      "resetting env. episode 5286, reward total was -12.0. running mean: -16.370008101594127, timestamp: 2022-08-20 09:51:44.452567\n",
      "resetting env. episode 5287, reward total was -17.0. running mean: -16.376308020578186, timestamp: 2022-08-20 09:51:47.962604\n",
      "resetting env. episode 5288, reward total was -17.0. running mean: -16.382544940372405, timestamp: 2022-08-20 09:51:51.268643\n",
      "resetting env. episode 5289, reward total was -19.0. running mean: -16.408719490968682, timestamp: 2022-08-20 09:51:53.871678\n",
      "resetting env. episode 5290, reward total was -17.0. running mean: -16.414632296058997, timestamp: 2022-08-20 09:51:56.919714\n",
      "resetting env. episode 5291, reward total was -14.0. running mean: -16.390485973098407, timestamp: 2022-08-20 09:52:00.685759\n",
      "resetting env. episode 5292, reward total was -19.0. running mean: -16.416581113367425, timestamp: 2022-08-20 09:52:03.221801\n",
      "resetting env. episode 5293, reward total was -21.0. running mean: -16.46241530223375, timestamp: 2022-08-20 09:52:05.653820\n",
      "resetting env. episode 5294, reward total was -15.0. running mean: -16.44779114921141, timestamp: 2022-08-20 09:52:08.669857\n",
      "resetting env. episode 5295, reward total was -19.0. running mean: -16.4733132377193, timestamp: 2022-08-20 09:52:11.478890\n",
      "resetting env. episode 5296, reward total was -18.0. running mean: -16.488580105342105, timestamp: 2022-08-20 09:52:14.101929\n",
      "resetting env. episode 5297, reward total was -17.0. running mean: -16.493694304288685, timestamp: 2022-08-20 09:52:17.675971\n",
      "resetting env. episode 5298, reward total was -18.0. running mean: -16.5087573612458, timestamp: 2022-08-20 09:52:20.270000\n",
      "resetting env. episode 5299, reward total was -15.0. running mean: -16.49366978763334, timestamp: 2022-08-20 09:52:24.720053\n",
      "resetting env. episode 5300, reward total was -15.0. running mean: -16.478733089757007, timestamp: 2022-08-20 09:52:28.291098\n",
      "resetting env. episode 5301, reward total was -12.0. running mean: -16.433945758859437, timestamp: 2022-08-20 09:52:32.261150\n",
      "resetting env. episode 5302, reward total was -13.0. running mean: -16.399606301270843, timestamp: 2022-08-20 09:52:35.792712\n",
      "resetting env. episode 5303, reward total was -15.0. running mean: -16.385610238258135, timestamp: 2022-08-20 09:52:39.232759\n",
      "resetting env. episode 5304, reward total was -12.0. running mean: -16.341754135875554, timestamp: 2022-08-20 09:52:43.127802\n",
      "resetting env. episode 5305, reward total was -14.0. running mean: -16.3183365945168, timestamp: 2022-08-20 09:52:46.073843\n",
      "resetting env. episode 5306, reward total was -21.0. running mean: -16.365153228571632, timestamp: 2022-08-20 09:52:48.631869\n",
      "resetting env. episode 5307, reward total was -13.0. running mean: -16.331501696285915, timestamp: 2022-08-20 09:52:52.894922\n",
      "resetting env. episode 5308, reward total was -13.0. running mean: -16.298186679323056, timestamp: 2022-08-20 09:52:56.262961\n",
      "resetting env. episode 5309, reward total was -18.0. running mean: -16.315204812529824, timestamp: 2022-08-20 09:52:59.852006\n",
      "resetting env. episode 5310, reward total was -19.0. running mean: -16.342052764404528, timestamp: 2022-08-20 09:53:02.892050\n",
      "resetting env. episode 5311, reward total was -10.0. running mean: -16.278632236760483, timestamp: 2022-08-20 09:53:07.771104\n",
      "resetting env. episode 5312, reward total was -18.0. running mean: -16.295845914392878, timestamp: 2022-08-20 09:53:10.751142\n",
      "resetting env. episode 5313, reward total was -13.0. running mean: -16.262887455248947, timestamp: 2022-08-20 09:53:14.322189\n",
      "resetting env. episode 5314, reward total was -15.0. running mean: -16.250258580696457, timestamp: 2022-08-20 09:53:17.385226\n",
      "resetting env. episode 5315, reward total was -16.0. running mean: -16.24775599488949, timestamp: 2022-08-20 09:53:21.564278\n",
      "resetting env. episode 5316, reward total was -16.0. running mean: -16.245278434940598, timestamp: 2022-08-20 09:53:24.418306\n",
      "resetting env. episode 5317, reward total was -18.0. running mean: -16.262825650591193, timestamp: 2022-08-20 09:53:27.638350\n",
      "resetting env. episode 5318, reward total was -16.0. running mean: -16.26019739408528, timestamp: 2022-08-20 09:53:32.317926\n",
      "resetting env. episode 5319, reward total was -15.0. running mean: -16.247595420144428, timestamp: 2022-08-20 09:53:36.321508\n",
      "resetting env. episode 5320, reward total was -18.0. running mean: -16.265119465942984, timestamp: 2022-08-20 09:53:38.443526\n",
      "resetting env. episode 5321, reward total was -19.0. running mean: -16.292468271283557, timestamp: 2022-08-20 09:53:40.915557\n",
      "resetting env. episode 5322, reward total was -14.0. running mean: -16.269543588570723, timestamp: 2022-08-20 09:53:44.301602\n",
      "resetting env. episode 5323, reward total was -13.0. running mean: -16.236848152685013, timestamp: 2022-08-20 09:53:48.138646\n",
      "resetting env. episode 5324, reward total was -13.0. running mean: -16.20447967115816, timestamp: 2022-08-20 09:53:52.014220\n",
      "resetting env. episode 5325, reward total was -21.0. running mean: -16.252434874446582, timestamp: 2022-08-20 09:53:53.509236\n",
      "resetting env. episode 5326, reward total was -17.0. running mean: -16.259910525702118, timestamp: 2022-08-20 09:53:56.340272\n",
      "resetting env. episode 5327, reward total was -10.0. running mean: -16.197311420445097, timestamp: 2022-08-20 09:54:00.747851\n",
      "resetting env. episode 5328, reward total was -19.0. running mean: -16.225338306240648, timestamp: 2022-08-20 09:54:03.345880\n",
      "resetting env. episode 5329, reward total was -16.0. running mean: -16.22308492317824, timestamp: 2022-08-20 09:54:07.439934\n",
      "resetting env. episode 5330, reward total was -20.0. running mean: -16.260854073946458, timestamp: 2022-08-20 09:54:10.093964\n",
      "resetting env. episode 5331, reward total was -13.0. running mean: -16.22824553320699, timestamp: 2022-08-20 09:54:13.950010\n",
      "resetting env. episode 5332, reward total was -16.0. running mean: -16.225963077874923, timestamp: 2022-08-20 09:54:16.505046\n",
      "resetting env. episode 5333, reward total was -18.0. running mean: -16.243703447096173, timestamp: 2022-08-20 09:54:18.905073\n",
      "resetting env. episode 5334, reward total was -15.0. running mean: -16.23126641262521, timestamp: 2022-08-20 09:54:21.702107\n",
      "resetting env. episode 5335, reward total was -14.0. running mean: -16.20895374849896, timestamp: 2022-08-20 09:54:25.414152\n",
      "resetting env. episode 5336, reward total was -20.0. running mean: -16.24686421101397, timestamp: 2022-08-20 09:54:27.692180\n",
      "resetting env. episode 5337, reward total was -12.0. running mean: -16.20439556890383, timestamp: 2022-08-20 09:54:31.408223\n",
      "resetting env. episode 5338, reward total was -11.0. running mean: -16.15235161321479, timestamp: 2022-08-20 09:54:36.120281\n",
      "resetting env. episode 5339, reward total was -12.0. running mean: -16.110828097082642, timestamp: 2022-08-20 09:54:38.848317\n",
      "resetting env. episode 5340, reward total was -16.0. running mean: -16.109719816111816, timestamp: 2022-08-20 09:54:42.415358\n",
      "resetting env. episode 5341, reward total was -14.0. running mean: -16.088622617950698, timestamp: 2022-08-20 09:54:46.716410\n",
      "resetting env. episode 5342, reward total was -18.0. running mean: -16.10773639177119, timestamp: 2022-08-20 09:54:50.064455\n",
      "resetting env. episode 5343, reward total was -19.0. running mean: -16.13665902785348, timestamp: 2022-08-20 09:54:53.691496\n",
      "resetting env. episode 5344, reward total was -17.0. running mean: -16.145292437574945, timestamp: 2022-08-20 09:54:56.531529\n",
      "resetting env. episode 5345, reward total was -15.0. running mean: -16.133839513199195, timestamp: 2022-08-20 09:54:59.443088\n",
      "resetting env. episode 5346, reward total was -18.0. running mean: -16.152501118067203, timestamp: 2022-08-20 09:55:02.677126\n",
      "resetting env. episode 5347, reward total was -16.0. running mean: -16.15097610688653, timestamp: 2022-08-20 09:55:06.565695\n",
      "resetting env. episode 5348, reward total was -17.0. running mean: -16.159466345817666, timestamp: 2022-08-20 09:55:09.995743\n",
      "resetting env. episode 5349, reward total was -20.0. running mean: -16.19787168235949, timestamp: 2022-08-20 09:55:13.151778\n",
      "resetting env. episode 5350, reward total was -14.0. running mean: -16.175892965535898, timestamp: 2022-08-20 09:55:15.909341\n",
      "resetting env. episode 5351, reward total was -17.0. running mean: -16.18413403588054, timestamp: 2022-08-20 09:55:19.520381\n",
      "resetting env. episode 5352, reward total was -15.0. running mean: -16.172292695521733, timestamp: 2022-08-20 09:55:22.785422\n",
      "resetting env. episode 5353, reward total was -21.0. running mean: -16.220569768566516, timestamp: 2022-08-20 09:55:25.333456\n",
      "resetting env. episode 5354, reward total was -21.0. running mean: -16.268364070880853, timestamp: 2022-08-20 09:55:28.216488\n",
      "resetting env. episode 5355, reward total was -18.0. running mean: -16.285680430172043, timestamp: 2022-08-20 09:55:31.342528\n",
      "resetting env. episode 5356, reward total was -18.0. running mean: -16.30282362587032, timestamp: 2022-08-20 09:55:34.584568\n",
      "resetting env. episode 5357, reward total was -19.0. running mean: -16.32979538961162, timestamp: 2022-08-20 09:55:37.713604\n",
      "resetting env. episode 5358, reward total was -19.0. running mean: -16.356497435715504, timestamp: 2022-08-20 09:55:39.831629\n",
      "resetting env. episode 5359, reward total was -20.0. running mean: -16.39293246135835, timestamp: 2022-08-20 09:55:43.028667\n",
      "resetting env. episode 5360, reward total was -17.0. running mean: -16.399003136744767, timestamp: 2022-08-20 09:55:46.075704\n",
      "resetting env. episode 5361, reward total was -17.0. running mean: -16.40501310537732, timestamp: 2022-08-20 09:55:49.136747\n",
      "resetting env. episode 5362, reward total was -15.0. running mean: -16.390962974323546, timestamp: 2022-08-20 09:55:53.471799\n",
      "resetting env. episode 5363, reward total was -18.0. running mean: -16.407053344580312, timestamp: 2022-08-20 09:55:56.447835\n",
      "resetting env. episode 5364, reward total was -19.0. running mean: -16.43298281113451, timestamp: 2022-08-20 09:55:58.688861\n",
      "resetting env. episode 5365, reward total was -11.0. running mean: -16.378652983023166, timestamp: 2022-08-20 09:56:03.309916\n",
      "resetting env. episode 5366, reward total was -11.0. running mean: -16.324866453192932, timestamp: 2022-08-20 09:56:06.608954\n",
      "resetting env. episode 5367, reward total was -13.0. running mean: -16.291617788661, timestamp: 2022-08-20 09:56:10.832007\n",
      "resetting env. episode 5368, reward total was -15.0. running mean: -16.278701610774387, timestamp: 2022-08-20 09:56:15.014582\n",
      "resetting env. episode 5369, reward total was -15.0. running mean: -16.265914594666643, timestamp: 2022-08-20 09:56:18.735625\n",
      "resetting env. episode 5370, reward total was -17.0. running mean: -16.27325544871998, timestamp: 2022-08-20 09:56:21.328180\n",
      "resetting env. episode 5371, reward total was -15.0. running mean: -16.26052289423278, timestamp: 2022-08-20 09:56:24.411220\n",
      "resetting env. episode 5372, reward total was -20.0. running mean: -16.29791766529045, timestamp: 2022-08-20 09:56:27.234257\n",
      "resetting env. episode 5373, reward total was -10.0. running mean: -16.234938488637546, timestamp: 2022-08-20 09:56:31.906312\n",
      "resetting env. episode 5374, reward total was -17.0. running mean: -16.242589103751172, timestamp: 2022-08-20 09:56:34.291338\n",
      "resetting env. episode 5375, reward total was -15.0. running mean: -16.23016321271366, timestamp: 2022-08-20 09:56:37.340373\n",
      "resetting env. episode 5376, reward total was -14.0. running mean: -16.207861580586524, timestamp: 2022-08-20 09:56:41.631427\n",
      "resetting env. episode 5377, reward total was -12.0. running mean: -16.16578296478066, timestamp: 2022-08-20 09:56:45.897478\n",
      "resetting env. episode 5378, reward total was -15.0. running mean: -16.15412513513285, timestamp: 2022-08-20 09:56:48.847519\n",
      "resetting env. episode 5379, reward total was -11.0. running mean: -16.102583883781524, timestamp: 2022-08-20 09:56:52.661560\n",
      "resetting env. episode 5380, reward total was -15.0. running mean: -16.091558044943707, timestamp: 2022-08-20 09:56:56.246607\n",
      "resetting env. episode 5381, reward total was -15.0. running mean: -16.080642464494268, timestamp: 2022-08-20 09:57:00.141650\n",
      "resetting env. episode 5382, reward total was -13.0. running mean: -16.049836039849325, timestamp: 2022-08-20 09:57:03.861705\n",
      "resetting env. episode 5383, reward total was -14.0. running mean: -16.02933767945083, timestamp: 2022-08-20 09:57:06.926736\n",
      "resetting env. episode 5384, reward total was -13.0. running mean: -15.999044302656323, timestamp: 2022-08-20 09:57:10.891780\n",
      "resetting env. episode 5385, reward total was -18.0. running mean: -16.01905385962976, timestamp: 2022-08-20 09:57:13.560816\n",
      "resetting env. episode 5386, reward total was -16.0. running mean: -16.01886332103346, timestamp: 2022-08-20 09:57:16.872856\n",
      "resetting env. episode 5387, reward total was -13.0. running mean: -15.988674687823126, timestamp: 2022-08-20 09:57:20.610899\n",
      "resetting env. episode 5388, reward total was -17.0. running mean: -15.998787940944895, timestamp: 2022-08-20 09:57:22.881928\n",
      "resetting env. episode 5389, reward total was -14.0. running mean: -15.978800061535447, timestamp: 2022-08-20 09:57:27.145984\n",
      "resetting env. episode 5390, reward total was -19.0. running mean: -16.009012060920092, timestamp: 2022-08-20 09:57:29.738011\n",
      "resetting env. episode 5391, reward total was -7.0. running mean: -15.918921940310891, timestamp: 2022-08-20 09:57:34.439069\n",
      "resetting env. episode 5392, reward total was -14.0. running mean: -15.899732720907783, timestamp: 2022-08-20 09:57:38.221110\n",
      "resetting env. episode 5393, reward total was -18.0. running mean: -15.920735393698704, timestamp: 2022-08-20 09:57:41.378150\n",
      "resetting env. episode 5394, reward total was -17.0. running mean: -15.931528039761718, timestamp: 2022-08-20 09:57:43.535175\n",
      "resetting env. episode 5395, reward total was -18.0. running mean: -15.9522127593641, timestamp: 2022-08-20 09:57:47.416225\n",
      "resetting env. episode 5396, reward total was -17.0. running mean: -15.962690631770458, timestamp: 2022-08-20 09:57:50.200782\n",
      "resetting env. episode 5397, reward total was -20.0. running mean: -16.003063725452755, timestamp: 2022-08-20 09:57:52.808813\n",
      "resetting env. episode 5398, reward total was -17.0. running mean: -16.013033088198227, timestamp: 2022-08-20 09:57:55.892847\n",
      "resetting env. episode 5399, reward total was -19.0. running mean: -16.042902757316245, timestamp: 2022-08-20 09:57:58.192874\n",
      "resetting env. episode 5400, reward total was -19.0. running mean: -16.072473729743084, timestamp: 2022-08-20 09:58:01.325913\n",
      "resetting env. episode 5401, reward total was -19.0. running mean: -16.101748992445653, timestamp: 2022-08-20 09:58:04.026950\n",
      "resetting env. episode 5402, reward total was -16.0. running mean: -16.100731502521196, timestamp: 2022-08-20 09:58:06.558978\n",
      "resetting env. episode 5403, reward total was -17.0. running mean: -16.109724187495985, timestamp: 2022-08-20 09:58:08.981004\n",
      "resetting env. episode 5404, reward total was -15.0. running mean: -16.098626945621024, timestamp: 2022-08-20 09:58:11.947042\n",
      "resetting env. episode 5405, reward total was -15.0. running mean: -16.087640676164813, timestamp: 2022-08-20 09:58:15.500088\n",
      "resetting env. episode 5406, reward total was -17.0. running mean: -16.096764269403167, timestamp: 2022-08-20 09:58:18.484120\n",
      "resetting env. episode 5407, reward total was -16.0. running mean: -16.095796626709134, timestamp: 2022-08-20 09:58:21.802160\n",
      "resetting env. episode 5408, reward total was -16.0. running mean: -16.094838660442043, timestamp: 2022-08-20 09:58:25.456208\n",
      "resetting env. episode 5409, reward total was -17.0. running mean: -16.103890273837624, timestamp: 2022-08-20 09:58:28.696244\n",
      "resetting env. episode 5410, reward total was -19.0. running mean: -16.13285137109925, timestamp: 2022-08-20 09:58:31.806803\n",
      "resetting env. episode 5411, reward total was -17.0. running mean: -16.141522857388257, timestamp: 2022-08-20 09:58:35.136366\n",
      "resetting env. episode 5412, reward total was -15.0. running mean: -16.130107628814372, timestamp: 2022-08-20 09:58:38.274409\n",
      "resetting env. episode 5413, reward total was -12.0. running mean: -16.08880655252623, timestamp: 2022-08-20 09:58:41.665444\n",
      "resetting env. episode 5414, reward total was -16.0. running mean: -16.087918487000966, timestamp: 2022-08-20 09:58:44.898485\n",
      "resetting env. episode 5415, reward total was -13.0. running mean: -16.057039302130956, timestamp: 2022-08-20 09:58:49.106535\n",
      "resetting env. episode 5416, reward total was -15.0. running mean: -16.046468909109645, timestamp: 2022-08-20 09:58:52.548575\n",
      "resetting env. episode 5417, reward total was -17.0. running mean: -16.05600422001855, timestamp: 2022-08-20 09:58:55.117608\n",
      "resetting env. episode 5418, reward total was -18.0. running mean: -16.075444177818365, timestamp: 2022-08-20 09:58:57.386631\n",
      "resetting env. episode 5419, reward total was -10.0. running mean: -16.014689736040182, timestamp: 2022-08-20 09:59:01.268679\n",
      "resetting env. episode 5420, reward total was -13.0. running mean: -15.984542838679781, timestamp: 2022-08-20 09:59:05.544731\n",
      "resetting env. episode 5421, reward total was -18.0. running mean: -16.004697410292984, timestamp: 2022-08-20 09:59:09.035771\n",
      "resetting env. episode 5422, reward total was -15.0. running mean: -15.994650436190055, timestamp: 2022-08-20 09:59:12.125814\n",
      "resetting env. episode 5423, reward total was -12.0. running mean: -15.954703931828153, timestamp: 2022-08-20 09:59:15.486850\n",
      "resetting env. episode 5424, reward total was -17.0. running mean: -15.96515689250987, timestamp: 2022-08-20 09:59:18.177881\n",
      "resetting env. episode 5425, reward total was -17.0. running mean: -15.975505323584771, timestamp: 2022-08-20 09:59:20.980914\n",
      "resetting env. episode 5426, reward total was -6.0. running mean: -15.875750270348924, timestamp: 2022-08-20 09:59:26.094498\n",
      "resetting env. episode 5427, reward total was -17.0. running mean: -15.886992767645435, timestamp: 2022-08-20 09:59:29.353538\n",
      "resetting env. episode 5428, reward total was -16.0. running mean: -15.88812283996898, timestamp: 2022-08-20 09:59:32.055572\n",
      "resetting env. episode 5429, reward total was -17.0. running mean: -15.899241611569291, timestamp: 2022-08-20 09:59:34.853602\n",
      "resetting env. episode 5430, reward total was -14.0. running mean: -15.8802491954536, timestamp: 2022-08-20 09:59:38.724171\n",
      "resetting env. episode 5431, reward total was -17.0. running mean: -15.891446703499064, timestamp: 2022-08-20 09:59:41.371207\n",
      "resetting env. episode 5432, reward total was -19.0. running mean: -15.922532236464072, timestamp: 2022-08-20 09:59:43.909232\n",
      "resetting env. episode 5433, reward total was -13.0. running mean: -15.893306914099432, timestamp: 2022-08-20 09:59:47.873283\n",
      "resetting env. episode 5434, reward total was -18.0. running mean: -15.914373844958437, timestamp: 2022-08-20 09:59:50.429317\n",
      "resetting env. episode 5435, reward total was -16.0. running mean: -15.915230106508853, timestamp: 2022-08-20 09:59:53.766353\n",
      "resetting env. episode 5436, reward total was -16.0. running mean: -15.916077805443765, timestamp: 2022-08-20 09:59:57.008394\n",
      "resetting env. episode 5437, reward total was -10.0. running mean: -15.856917027389326, timestamp: 2022-08-20 10:00:01.193447\n",
      "resetting env. episode 5438, reward total was -18.0. running mean: -15.878347857115433, timestamp: 2022-08-20 10:00:04.655482\n",
      "resetting env. episode 5439, reward total was -14.0. running mean: -15.85956437854428, timestamp: 2022-08-20 10:00:08.078525\n",
      "resetting env. episode 5440, reward total was -19.0. running mean: -15.890968734758836, timestamp: 2022-08-20 10:00:10.859559\n",
      "resetting env. episode 5441, reward total was -15.0. running mean: -15.882059047411248, timestamp: 2022-08-20 10:00:13.164584\n",
      "resetting env. episode 5442, reward total was -13.0. running mean: -15.853238456937136, timestamp: 2022-08-20 10:00:16.854628\n",
      "resetting env. episode 5443, reward total was -16.0. running mean: -15.854706072367765, timestamp: 2022-08-20 10:00:20.525199\n",
      "resetting env. episode 5444, reward total was -18.0. running mean: -15.876159011644088, timestamp: 2022-08-20 10:00:23.494761\n",
      "resetting env. episode 5445, reward total was -18.0. running mean: -15.897397421527646, timestamp: 2022-08-20 10:00:26.029790\n",
      "resetting env. episode 5446, reward total was -13.0. running mean: -15.86842344731237, timestamp: 2022-08-20 10:00:29.640835\n",
      "resetting env. episode 5447, reward total was -18.0. running mean: -15.889739212839245, timestamp: 2022-08-20 10:00:33.272877\n",
      "resetting env. episode 5448, reward total was -20.0. running mean: -15.930841820710851, timestamp: 2022-08-20 10:00:35.269906\n",
      "resetting env. episode 5449, reward total was -16.0. running mean: -15.931533402503742, timestamp: 2022-08-20 10:00:38.302943\n",
      "resetting env. episode 5450, reward total was -20.0. running mean: -15.972218068478703, timestamp: 2022-08-20 10:00:40.468967\n",
      "resetting env. episode 5451, reward total was -15.0. running mean: -15.962495887793917, timestamp: 2022-08-20 10:00:43.740004\n",
      "resetting env. episode 5452, reward total was -18.0. running mean: -15.982870928915977, timestamp: 2022-08-20 10:00:47.307048\n",
      "resetting env. episode 5453, reward total was -17.0. running mean: -15.993042219626817, timestamp: 2022-08-20 10:00:51.446096\n",
      "resetting env. episode 5454, reward total was -16.0. running mean: -15.993111797430549, timestamp: 2022-08-20 10:00:54.367130\n",
      "resetting env. episode 5455, reward total was -13.0. running mean: -15.963180679456244, timestamp: 2022-08-20 10:00:57.381166\n",
      "resetting env. episode 5456, reward total was -16.0. running mean: -15.963548872661681, timestamp: 2022-08-20 10:01:01.468744\n",
      "resetting env. episode 5457, reward total was -11.0. running mean: -15.913913383935064, timestamp: 2022-08-20 10:01:04.824784\n",
      "resetting env. episode 5458, reward total was -19.0. running mean: -15.944774250095714, timestamp: 2022-08-20 10:01:07.034808\n",
      "resetting env. episode 5459, reward total was -18.0. running mean: -15.965326507594757, timestamp: 2022-08-20 10:01:10.643853\n",
      "resetting env. episode 5460, reward total was -12.0. running mean: -15.925673242518808, timestamp: 2022-08-20 10:01:15.000905\n",
      "resetting env. episode 5461, reward total was -19.0. running mean: -15.95641651009362, timestamp: 2022-08-20 10:01:17.740936\n",
      "resetting env. episode 5462, reward total was -11.0. running mean: -15.906852344992682, timestamp: 2022-08-20 10:01:21.694985\n",
      "resetting env. episode 5463, reward total was -14.0. running mean: -15.887783821542756, timestamp: 2022-08-20 10:01:25.706030\n",
      "resetting env. episode 5464, reward total was -12.0. running mean: -15.848905983327327, timestamp: 2022-08-20 10:01:29.318072\n",
      "resetting env. episode 5465, reward total was -12.0. running mean: -15.810416923494053, timestamp: 2022-08-20 10:01:33.547126\n",
      "resetting env. episode 5466, reward total was -17.0. running mean: -15.822312754259112, timestamp: 2022-08-20 10:01:36.163163\n",
      "resetting env. episode 5467, reward total was -16.0. running mean: -15.824089626716521, timestamp: 2022-08-20 10:01:39.638194\n",
      "resetting env. episode 5468, reward total was -12.0. running mean: -15.785848730449356, timestamp: 2022-08-20 10:01:43.527242\n",
      "resetting env. episode 5469, reward total was -19.0. running mean: -15.817990243144862, timestamp: 2022-08-20 10:01:45.988276\n",
      "resetting env. episode 5470, reward total was -13.0. running mean: -15.789810340713414, timestamp: 2022-08-20 10:01:49.284312\n",
      "resetting env. episode 5471, reward total was -15.0. running mean: -15.78191223730628, timestamp: 2022-08-20 10:01:52.665357\n",
      "resetting env. episode 5472, reward total was -19.0. running mean: -15.814093114933216, timestamp: 2022-08-20 10:01:56.116394\n",
      "resetting env. episode 5473, reward total was -19.0. running mean: -15.845952183783883, timestamp: 2022-08-20 10:01:58.584422\n",
      "resetting env. episode 5474, reward total was -17.0. running mean: -15.857492661946043, timestamp: 2022-08-20 10:02:01.089451\n",
      "resetting env. episode 5475, reward total was -17.0. running mean: -15.868917735326583, timestamp: 2022-08-20 10:02:04.977502\n",
      "resetting env. episode 5476, reward total was -15.0. running mean: -15.860228557973318, timestamp: 2022-08-20 10:02:08.032537\n",
      "resetting env. episode 5477, reward total was -15.0. running mean: -15.851626272393586, timestamp: 2022-08-20 10:02:11.290572\n",
      "resetting env. episode 5478, reward total was -15.0. running mean: -15.843110009669651, timestamp: 2022-08-20 10:02:15.137623\n",
      "resetting env. episode 5479, reward total was -17.0. running mean: -15.854678909572954, timestamp: 2022-08-20 10:02:18.150659\n",
      "resetting env. episode 5480, reward total was -15.0. running mean: -15.846132120477224, timestamp: 2022-08-20 10:02:21.473694\n",
      "resetting env. episode 5481, reward total was -12.0. running mean: -15.80767079927245, timestamp: 2022-08-20 10:02:24.937264\n",
      "resetting env. episode 5482, reward total was -15.0. running mean: -15.799594091279726, timestamp: 2022-08-20 10:02:27.553296\n",
      "resetting env. episode 5483, reward total was -13.0. running mean: -15.771598150366929, timestamp: 2022-08-20 10:02:31.160914\n",
      "resetting env. episode 5484, reward total was -15.0. running mean: -15.76388216886326, timestamp: 2022-08-20 10:02:35.463962\n",
      "resetting env. episode 5485, reward total was -15.0. running mean: -15.756243347174628, timestamp: 2022-08-20 10:02:39.371063\n",
      "resetting env. episode 5486, reward total was -15.0. running mean: -15.748680913702882, timestamp: 2022-08-20 10:02:43.074109\n",
      "resetting env. episode 5487, reward total was -17.0. running mean: -15.761194104565853, timestamp: 2022-08-20 10:02:46.141140\n",
      "resetting env. episode 5488, reward total was -14.0. running mean: -15.743582163520195, timestamp: 2022-08-20 10:02:49.097180\n",
      "resetting env. episode 5489, reward total was -13.0. running mean: -15.716146341884993, timestamp: 2022-08-20 10:02:52.157214\n",
      "resetting env. episode 5490, reward total was -15.0. running mean: -15.708984878466143, timestamp: 2022-08-20 10:02:55.335254\n",
      "resetting env. episode 5491, reward total was -8.0. running mean: -15.631895029681482, timestamp: 2022-08-20 10:03:00.566318\n",
      "resetting env. episode 5492, reward total was -18.0. running mean: -15.655576079384668, timestamp: 2022-08-20 10:03:03.447354\n",
      "resetting env. episode 5493, reward total was -18.0. running mean: -15.67902031859082, timestamp: 2022-08-20 10:03:05.950377\n",
      "resetting env. episode 5494, reward total was -12.0. running mean: -15.642230115404912, timestamp: 2022-08-20 10:03:09.670425\n",
      "resetting env. episode 5495, reward total was -15.0. running mean: -15.635807814250864, timestamp: 2022-08-20 10:03:13.234467\n",
      "resetting env. episode 5496, reward total was -18.0. running mean: -15.659449736108355, timestamp: 2022-08-20 10:03:16.363503\n",
      "resetting env. episode 5497, reward total was -16.0. running mean: -15.662855238747271, timestamp: 2022-08-20 10:03:19.660544\n",
      "resetting env. episode 5498, reward total was -16.0. running mean: -15.6662266863598, timestamp: 2022-08-20 10:03:23.371588\n",
      "resetting env. episode 5499, reward total was -14.0. running mean: -15.649564419496201, timestamp: 2022-08-20 10:03:26.748630\n",
      "resetting env. episode 5500, reward total was -15.0. running mean: -15.64306877530124, timestamp: 2022-08-20 10:03:31.041678\n",
      "resetting env. episode 5501, reward total was -16.0. running mean: -15.646638087548228, timestamp: 2022-08-20 10:03:33.755713\n",
      "resetting env. episode 5502, reward total was -16.0. running mean: -15.650171706672745, timestamp: 2022-08-20 10:03:36.656748\n",
      "resetting env. episode 5503, reward total was -16.0. running mean: -15.653669989606017, timestamp: 2022-08-20 10:03:39.940791\n",
      "resetting env. episode 5504, reward total was -16.0. running mean: -15.657133289709957, timestamp: 2022-08-20 10:03:43.224349\n",
      "resetting env. episode 5505, reward total was -14.0. running mean: -15.640561956812858, timestamp: 2022-08-20 10:03:47.082392\n",
      "resetting env. episode 5506, reward total was -9.0. running mean: -15.574156337244728, timestamp: 2022-08-20 10:03:51.316446\n",
      "resetting env. episode 5507, reward total was -14.0. running mean: -15.558414773872281, timestamp: 2022-08-20 10:03:55.408496\n",
      "resetting env. episode 5508, reward total was -9.0. running mean: -15.492830626133557, timestamp: 2022-08-20 10:04:00.364550\n",
      "resetting env. episode 5509, reward total was -17.0. running mean: -15.50790231987222, timestamp: 2022-08-20 10:04:03.516597\n",
      "resetting env. episode 5510, reward total was -18.0. running mean: -15.532823296673499, timestamp: 2022-08-20 10:04:06.338622\n",
      "resetting env. episode 5511, reward total was -12.0. running mean: -15.497495063706763, timestamp: 2022-08-20 10:04:09.869665\n",
      "resetting env. episode 5512, reward total was -17.0. running mean: -15.512520113069696, timestamp: 2022-08-20 10:04:13.455710\n",
      "resetting env. episode 5513, reward total was -18.0. running mean: -15.537394911938998, timestamp: 2022-08-20 10:04:16.243741\n",
      "resetting env. episode 5514, reward total was -13.0. running mean: -15.512020962819609, timestamp: 2022-08-20 10:04:19.558789\n",
      "resetting env. episode 5515, reward total was -17.0. running mean: -15.526900753191413, timestamp: 2022-08-20 10:04:22.418815\n",
      "resetting env. episode 5516, reward total was -18.0. running mean: -15.551631745659499, timestamp: 2022-08-20 10:04:25.334851\n",
      "resetting env. episode 5517, reward total was -18.0. running mean: -15.576115428202904, timestamp: 2022-08-20 10:04:27.706881\n",
      "resetting env. episode 5518, reward total was -17.0. running mean: -15.590354273920875, timestamp: 2022-08-20 10:04:31.463444\n",
      "resetting env. episode 5519, reward total was -17.0. running mean: -15.604450731181666, timestamp: 2022-08-20 10:04:34.893010\n",
      "resetting env. episode 5520, reward total was -18.0. running mean: -15.628406223869849, timestamp: 2022-08-20 10:04:38.228047\n",
      "resetting env. episode 5521, reward total was -17.0. running mean: -15.64212216163115, timestamp: 2022-08-20 10:04:41.548093\n",
      "resetting env. episode 5522, reward total was -13.0. running mean: -15.61570094001484, timestamp: 2022-08-20 10:04:45.292135\n",
      "resetting env. episode 5523, reward total was -19.0. running mean: -15.64954393061469, timestamp: 2022-08-20 10:04:47.510160\n",
      "resetting env. episode 5524, reward total was -17.0. running mean: -15.663048491308544, timestamp: 2022-08-20 10:04:52.422221\n",
      "resetting env. episode 5525, reward total was -18.0. running mean: -15.686418006395458, timestamp: 2022-08-20 10:04:55.493260\n",
      "resetting env. episode 5526, reward total was -19.0. running mean: -15.719553826331502, timestamp: 2022-08-20 10:04:57.773285\n",
      "resetting env. episode 5527, reward total was -15.0. running mean: -15.712358288068188, timestamp: 2022-08-20 10:05:01.456858\n",
      "resetting env. episode 5528, reward total was -16.0. running mean: -15.715234705187505, timestamp: 2022-08-20 10:05:05.160900\n",
      "resetting env. episode 5529, reward total was -14.0. running mean: -15.69808235813563, timestamp: 2022-08-20 10:05:08.760465\n",
      "resetting env. episode 5530, reward total was -17.0. running mean: -15.711101534554274, timestamp: 2022-08-20 10:05:12.131508\n",
      "resetting env. episode 5531, reward total was -13.0. running mean: -15.683990519208733, timestamp: 2022-08-20 10:05:16.507557\n",
      "resetting env. episode 5532, reward total was -18.0. running mean: -15.707150614016644, timestamp: 2022-08-20 10:05:19.533597\n",
      "resetting env. episode 5533, reward total was -13.0. running mean: -15.680079107876479, timestamp: 2022-08-20 10:05:24.835659\n",
      "resetting env. episode 5534, reward total was -19.0. running mean: -15.713278316797712, timestamp: 2022-08-20 10:05:27.289208\n",
      "resetting env. episode 5535, reward total was -14.0. running mean: -15.696145533629736, timestamp: 2022-08-20 10:05:31.726264\n",
      "resetting env. episode 5536, reward total was -12.0. running mean: -15.659184078293437, timestamp: 2022-08-20 10:05:35.938361\n",
      "resetting env. episode 5537, reward total was -12.0. running mean: -15.622592237510503, timestamp: 2022-08-20 10:05:40.194408\n",
      "resetting env. episode 5538, reward total was -11.0. running mean: -15.576366315135397, timestamp: 2022-08-20 10:05:44.268460\n",
      "resetting env. episode 5539, reward total was -15.0. running mean: -15.570602651984043, timestamp: 2022-08-20 10:05:47.270498\n",
      "resetting env. episode 5540, reward total was -13.0. running mean: -15.544896625464203, timestamp: 2022-08-20 10:05:53.086098\n",
      "resetting env. episode 5541, reward total was -17.0. running mean: -15.55944765920956, timestamp: 2022-08-20 10:05:57.171145\n",
      "resetting env. episode 5542, reward total was -18.0. running mean: -15.583853182617464, timestamp: 2022-08-20 10:06:00.121180\n",
      "resetting env. episode 5543, reward total was -14.0. running mean: -15.568014650791289, timestamp: 2022-08-20 10:06:02.971214\n",
      "resetting env. episode 5544, reward total was -10.0. running mean: -15.512334504283375, timestamp: 2022-08-20 10:06:06.710261\n",
      "resetting env. episode 5545, reward total was -14.0. running mean: -15.497211159240543, timestamp: 2022-08-20 10:06:10.970312\n",
      "resetting env. episode 5546, reward total was -15.0. running mean: -15.492239047648138, timestamp: 2022-08-20 10:06:15.140362\n",
      "resetting env. episode 5547, reward total was -10.0. running mean: -15.437316657171655, timestamp: 2022-08-20 10:06:19.734943\n",
      "resetting env. episode 5548, reward total was -15.0. running mean: -15.43294349059994, timestamp: 2022-08-20 10:06:22.631979\n",
      "resetting env. episode 5549, reward total was -17.0. running mean: -15.44861405569394, timestamp: 2022-08-20 10:06:26.835029\n",
      "resetting env. episode 5550, reward total was -19.0. running mean: -15.484127915137, timestamp: 2022-08-20 10:06:29.722064\n",
      "resetting env. episode 5551, reward total was -13.0. running mean: -15.459286635985631, timestamp: 2022-08-20 10:06:33.017108\n",
      "resetting env. episode 5552, reward total was -21.0. running mean: -15.514693769625776, timestamp: 2022-08-20 10:06:35.893141\n",
      "resetting env. episode 5553, reward total was -11.0. running mean: -15.469546831929517, timestamp: 2022-08-20 10:06:40.319193\n",
      "resetting env. episode 5554, reward total was -12.0. running mean: -15.434851363610221, timestamp: 2022-08-20 10:06:43.969238\n",
      "resetting env. episode 5555, reward total was -19.0. running mean: -15.470502849974118, timestamp: 2022-08-20 10:06:46.576267\n",
      "resetting env. episode 5556, reward total was -12.0. running mean: -15.435797821474376, timestamp: 2022-08-20 10:06:51.552333\n",
      "resetting env. episode 5557, reward total was -16.0. running mean: -15.441439843259632, timestamp: 2022-08-20 10:06:54.897367\n",
      "resetting env. episode 5558, reward total was -8.0. running mean: -15.367025444827036, timestamp: 2022-08-20 10:06:59.694426\n",
      "resetting env. episode 5559, reward total was -17.0. running mean: -15.383355190378765, timestamp: 2022-08-20 10:07:02.831465\n",
      "resetting env. episode 5560, reward total was -11.0. running mean: -15.339521638474977, timestamp: 2022-08-20 10:07:07.978527\n",
      "resetting env. episode 5561, reward total was -10.0. running mean: -15.286126422090227, timestamp: 2022-08-20 10:07:11.886573\n",
      "resetting env. episode 5562, reward total was -13.0. running mean: -15.263265157869325, timestamp: 2022-08-20 10:07:15.789621\n",
      "resetting env. episode 5563, reward total was -18.0. running mean: -15.290632506290631, timestamp: 2022-08-20 10:07:19.470670\n",
      "resetting env. episode 5564, reward total was -14.0. running mean: -15.277726181227726, timestamp: 2022-08-20 10:07:24.196725\n",
      "resetting env. episode 5565, reward total was -16.0. running mean: -15.284948919415449, timestamp: 2022-08-20 10:07:27.279760\n",
      "resetting env. episode 5566, reward total was -10.0. running mean: -15.232099430221293, timestamp: 2022-08-20 10:07:31.333808\n",
      "resetting env. episode 5567, reward total was -16.0. running mean: -15.23977843591908, timestamp: 2022-08-20 10:07:34.817851\n",
      "resetting env. episode 5568, reward total was -14.0. running mean: -15.227380651559889, timestamp: 2022-08-20 10:07:40.575920\n",
      "resetting env. episode 5569, reward total was -15.0. running mean: -15.22510684504429, timestamp: 2022-08-20 10:07:44.478969\n",
      "resetting env. episode 5570, reward total was -15.0. running mean: -15.222855776593848, timestamp: 2022-08-20 10:07:47.821010\n",
      "resetting env. episode 5571, reward total was -18.0. running mean: -15.250627218827908, timestamp: 2022-08-20 10:07:51.199048\n",
      "resetting env. episode 5572, reward total was -15.0. running mean: -15.248120946639629, timestamp: 2022-08-20 10:07:54.421091\n",
      "resetting env. episode 5573, reward total was -14.0. running mean: -15.235639737173233, timestamp: 2022-08-20 10:07:58.149652\n",
      "resetting env. episode 5574, reward total was -12.0. running mean: -15.2032833398015, timestamp: 2022-08-20 10:08:02.702708\n",
      "resetting env. episode 5575, reward total was -20.0. running mean: -15.251250506403483, timestamp: 2022-08-20 10:08:04.680733\n",
      "resetting env. episode 5576, reward total was -18.0. running mean: -15.278738001339448, timestamp: 2022-08-20 10:08:08.124772\n",
      "resetting env. episode 5577, reward total was -19.0. running mean: -15.315950621326053, timestamp: 2022-08-20 10:08:10.769808\n",
      "resetting env. episode 5578, reward total was -13.0. running mean: -15.292791115112793, timestamp: 2022-08-20 10:08:15.402861\n",
      "resetting env. episode 5579, reward total was -14.0. running mean: -15.279863203961666, timestamp: 2022-08-20 10:08:19.331911\n",
      "resetting env. episode 5580, reward total was -15.0. running mean: -15.27706457192205, timestamp: 2022-08-20 10:08:23.151954\n",
      "resetting env. episode 5581, reward total was -16.0. running mean: -15.28429392620283, timestamp: 2022-08-20 10:08:26.818000\n",
      "resetting env. episode 5582, reward total was -13.0. running mean: -15.261450986940803, timestamp: 2022-08-20 10:08:31.269055\n",
      "resetting env. episode 5583, reward total was -19.0. running mean: -15.298836477071394, timestamp: 2022-08-20 10:08:35.914114\n",
      "resetting env. episode 5584, reward total was -19.0. running mean: -15.33584811230068, timestamp: 2022-08-20 10:08:39.510152\n",
      "resetting env. episode 5585, reward total was -19.0. running mean: -15.372489631177672, timestamp: 2022-08-20 10:08:43.201209\n",
      "resetting env. episode 5586, reward total was -15.0. running mean: -15.368764734865895, timestamp: 2022-08-20 10:08:47.289249\n",
      "resetting env. episode 5587, reward total was -14.0. running mean: -15.355077087517236, timestamp: 2022-08-20 10:08:52.791318\n",
      "resetting env. episode 5588, reward total was -19.0. running mean: -15.391526316642063, timestamp: 2022-08-20 10:08:56.146354\n",
      "resetting env. episode 5589, reward total was -19.0. running mean: -15.42761105347564, timestamp: 2022-08-20 10:08:58.754914\n",
      "resetting env. episode 5590, reward total was -14.0. running mean: -15.413334942940885, timestamp: 2022-08-20 10:09:01.716475\n",
      "resetting env. episode 5591, reward total was -19.0. running mean: -15.449201593511475, timestamp: 2022-08-20 10:09:04.680509\n",
      "resetting env. episode 5592, reward total was -19.0. running mean: -15.484709577576359, timestamp: 2022-08-20 10:09:07.518546\n",
      "resetting env. episode 5593, reward total was -17.0. running mean: -15.499862481800594, timestamp: 2022-08-20 10:09:10.114574\n",
      "resetting env. episode 5594, reward total was -11.0. running mean: -15.454863856982588, timestamp: 2022-08-20 10:09:13.723139\n",
      "resetting env. episode 5595, reward total was -14.0. running mean: -15.440315218412762, timestamp: 2022-08-20 10:09:18.092190\n",
      "resetting env. episode 5596, reward total was -16.0. running mean: -15.445912066228635, timestamp: 2022-08-20 10:09:22.043238\n",
      "resetting env. episode 5597, reward total was -19.0. running mean: -15.481452945566348, timestamp: 2022-08-20 10:09:24.324266\n",
      "resetting env. episode 5598, reward total was -18.0. running mean: -15.506638416110684, timestamp: 2022-08-20 10:09:26.719293\n",
      "resetting env. episode 5599, reward total was -15.0. running mean: -15.501572031949578, timestamp: 2022-08-20 10:09:30.642343\n",
      "resetting env. episode 5600, reward total was -12.0. running mean: -15.466556311630082, timestamp: 2022-08-20 10:09:34.737389\n",
      "resetting env. episode 5601, reward total was -17.0. running mean: -15.48189074851378, timestamp: 2022-08-20 10:09:37.968429\n",
      "resetting env. episode 5602, reward total was -18.0. running mean: -15.507071841028642, timestamp: 2022-08-20 10:09:40.978466\n",
      "resetting env. episode 5603, reward total was -9.0. running mean: -15.442001122618356, timestamp: 2022-08-20 10:09:46.232533\n",
      "resetting env. episode 5604, reward total was -16.0. running mean: -15.447581111392171, timestamp: 2022-08-20 10:09:49.747571\n",
      "resetting env. episode 5605, reward total was -13.0. running mean: -15.42310530027825, timestamp: 2022-08-20 10:09:53.723621\n",
      "resetting env. episode 5606, reward total was -13.0. running mean: -15.398874247275469, timestamp: 2022-08-20 10:09:57.981669\n",
      "resetting env. episode 5607, reward total was -14.0. running mean: -15.384885504802714, timestamp: 2022-08-20 10:10:02.501245\n",
      "resetting env. episode 5608, reward total was -16.0. running mean: -15.391036649754687, timestamp: 2022-08-20 10:10:06.735297\n",
      "resetting env. episode 5609, reward total was -21.0. running mean: -15.447126283257141, timestamp: 2022-08-20 10:10:10.924347\n",
      "resetting env. episode 5610, reward total was -11.0. running mean: -15.40265502042457, timestamp: 2022-08-20 10:10:15.852451\n",
      "resetting env. episode 5611, reward total was -17.0. running mean: -15.418628470220323, timestamp: 2022-08-20 10:10:18.475482\n",
      "resetting env. episode 5612, reward total was -17.0. running mean: -15.434442185518119, timestamp: 2022-08-20 10:10:21.187516\n",
      "resetting env. episode 5613, reward total was -21.0. running mean: -15.490097763662938, timestamp: 2022-08-20 10:10:24.018549\n",
      "resetting env. episode 5614, reward total was -16.0. running mean: -15.495196786026309, timestamp: 2022-08-20 10:10:27.028585\n",
      "resetting env. episode 5615, reward total was -5.0. running mean: -15.390244818166046, timestamp: 2022-08-20 10:10:31.495643\n",
      "resetting env. episode 5616, reward total was -12.0. running mean: -15.356342369984384, timestamp: 2022-08-20 10:10:35.180683\n",
      "resetting env. episode 5617, reward total was -18.0. running mean: -15.38277894628454, timestamp: 2022-08-20 10:10:38.453727\n",
      "resetting env. episode 5618, reward total was -18.0. running mean: -15.408951156821695, timestamp: 2022-08-20 10:10:41.145756\n",
      "resetting env. episode 5619, reward total was -11.0. running mean: -15.364861645253477, timestamp: 2022-08-20 10:10:44.778800\n",
      "resetting env. episode 5620, reward total was -16.0. running mean: -15.371213028800941, timestamp: 2022-08-20 10:10:47.580361\n",
      "resetting env. episode 5621, reward total was -17.0. running mean: -15.387500898512931, timestamp: 2022-08-20 10:10:50.215392\n",
      "resetting env. episode 5622, reward total was -16.0. running mean: -15.3936258895278, timestamp: 2022-08-20 10:10:53.052426\n",
      "resetting env. episode 5623, reward total was -15.0. running mean: -15.389689630632523, timestamp: 2022-08-20 10:10:56.396467\n",
      "resetting env. episode 5624, reward total was -16.0. running mean: -15.395792734326198, timestamp: 2022-08-20 10:10:59.881511\n",
      "resetting env. episode 5625, reward total was -8.0. running mean: -15.321834806982936, timestamp: 2022-08-20 10:11:03.698556\n",
      "resetting env. episode 5626, reward total was -17.0. running mean: -15.338616458913107, timestamp: 2022-08-20 10:11:06.281589\n",
      "resetting env. episode 5627, reward total was -12.0. running mean: -15.305230294323975, timestamp: 2022-08-20 10:11:08.888637\n",
      "resetting env. episode 5628, reward total was -15.0. running mean: -15.302177991380736, timestamp: 2022-08-20 10:11:11.562653\n",
      "resetting env. episode 5629, reward total was -21.0. running mean: -15.35915621146693, timestamp: 2022-08-20 10:11:13.183672\n",
      "resetting env. episode 5630, reward total was -15.0. running mean: -15.35556464935226, timestamp: 2022-08-20 10:11:17.089718\n",
      "resetting env. episode 5631, reward total was -17.0. running mean: -15.372009002858738, timestamp: 2022-08-20 10:11:20.577760\n",
      "resetting env. episode 5632, reward total was -16.0. running mean: -15.37828891283015, timestamp: 2022-08-20 10:11:23.997798\n",
      "resetting env. episode 5633, reward total was -13.0. running mean: -15.35450602370185, timestamp: 2022-08-20 10:11:27.693844\n",
      "resetting env. episode 5634, reward total was -16.0. running mean: -15.360960963464832, timestamp: 2022-08-20 10:11:30.698879\n",
      "resetting env. episode 5635, reward total was -13.0. running mean: -15.337351353830185, timestamp: 2022-08-20 10:11:34.429924\n",
      "resetting env. episode 5636, reward total was -12.0. running mean: -15.303977840291882, timestamp: 2022-08-20 10:11:38.456971\n",
      "resetting env. episode 5637, reward total was -13.0. running mean: -15.280938061888964, timestamp: 2022-08-20 10:11:42.029017\n",
      "resetting env. episode 5638, reward total was -18.0. running mean: -15.308128681270073, timestamp: 2022-08-20 10:11:44.673048\n",
      "resetting env. episode 5639, reward total was -20.0. running mean: -15.355047394457372, timestamp: 2022-08-20 10:11:47.102126\n",
      "resetting env. episode 5640, reward total was -15.0. running mean: -15.3514969205128, timestamp: 2022-08-20 10:11:50.515167\n",
      "resetting env. episode 5641, reward total was -21.0. running mean: -15.407981951307672, timestamp: 2022-08-20 10:11:52.103181\n",
      "resetting env. episode 5642, reward total was -14.0. running mean: -15.393902131794595, timestamp: 2022-08-20 10:11:55.467227\n",
      "resetting env. episode 5643, reward total was -16.0. running mean: -15.39996311047665, timestamp: 2022-08-20 10:11:58.179256\n",
      "resetting env. episode 5644, reward total was -21.0. running mean: -15.455963479371883, timestamp: 2022-08-20 10:11:59.474272\n",
      "resetting env. episode 5645, reward total was -13.0. running mean: -15.431403844578165, timestamp: 2022-08-20 10:12:02.943317\n",
      "resetting env. episode 5646, reward total was -16.0. running mean: -15.437089806132384, timestamp: 2022-08-20 10:12:05.829351\n",
      "resetting env. episode 5647, reward total was -18.0. running mean: -15.46271890807106, timestamp: 2022-08-20 10:12:08.076374\n",
      "resetting env. episode 5648, reward total was -18.0. running mean: -15.488091718990349, timestamp: 2022-08-20 10:12:11.354416\n",
      "resetting env. episode 5649, reward total was -12.0. running mean: -15.453210801800445, timestamp: 2022-08-20 10:12:14.496450\n",
      "resetting env. episode 5650, reward total was -14.0. running mean: -15.43867869378244, timestamp: 2022-08-20 10:12:18.012495\n",
      "resetting env. episode 5651, reward total was -17.0. running mean: -15.454291906844617, timestamp: 2022-08-20 10:12:20.667526\n",
      "resetting env. episode 5652, reward total was -18.0. running mean: -15.479748987776171, timestamp: 2022-08-20 10:12:23.717564\n",
      "resetting env. episode 5653, reward total was -15.0. running mean: -15.47495149789841, timestamp: 2022-08-20 10:12:26.863600\n",
      "resetting env. episode 5654, reward total was -13.0. running mean: -15.450201982919426, timestamp: 2022-08-20 10:12:30.944650\n",
      "resetting env. episode 5655, reward total was -15.0. running mean: -15.445699963090231, timestamp: 2022-08-20 10:12:34.526692\n",
      "resetting env. episode 5656, reward total was -14.0. running mean: -15.43124296345933, timestamp: 2022-08-20 10:12:37.929734\n",
      "resetting env. episode 5657, reward total was -9.0. running mean: -15.366930533824736, timestamp: 2022-08-20 10:12:41.917828\n",
      "resetting env. episode 5658, reward total was -16.0. running mean: -15.373261228486488, timestamp: 2022-08-20 10:12:45.101871\n",
      "resetting env. episode 5659, reward total was -15.0. running mean: -15.369528616201624, timestamp: 2022-08-20 10:12:49.257922\n",
      "resetting env. episode 5660, reward total was -18.0. running mean: -15.395833330039608, timestamp: 2022-08-20 10:12:52.074951\n",
      "resetting env. episode 5661, reward total was -12.0. running mean: -15.36187499673921, timestamp: 2022-08-20 10:12:56.798007\n",
      "resetting env. episode 5662, reward total was -13.0. running mean: -15.338256246771818, timestamp: 2022-08-20 10:13:00.422574\n",
      "resetting env. episode 5663, reward total was -17.0. running mean: -15.3548736843041, timestamp: 2022-08-20 10:13:04.510623\n",
      "resetting env. episode 5664, reward total was -18.0. running mean: -15.381324947461058, timestamp: 2022-08-20 10:13:07.860664\n",
      "resetting env. episode 5665, reward total was -20.0. running mean: -15.427511697986446, timestamp: 2022-08-20 10:13:10.260695\n",
      "resetting env. episode 5666, reward total was -14.0. running mean: -15.413236581006583, timestamp: 2022-08-20 10:13:13.907737\n",
      "resetting env. episode 5667, reward total was -14.0. running mean: -15.399104215196518, timestamp: 2022-08-20 10:13:17.466781\n",
      "resetting env. episode 5668, reward total was -19.0. running mean: -15.435113173044552, timestamp: 2022-08-20 10:13:19.563804\n",
      "resetting env. episode 5669, reward total was -16.0. running mean: -15.440762041314107, timestamp: 2022-08-20 10:13:23.665852\n",
      "resetting env. episode 5670, reward total was -17.0. running mean: -15.456354420900967, timestamp: 2022-08-20 10:13:25.754875\n",
      "resetting env. episode 5671, reward total was -6.0. running mean: -15.361790876691957, timestamp: 2022-08-20 10:13:30.907937\n",
      "resetting env. episode 5672, reward total was -11.0. running mean: -15.318172967925037, timestamp: 2022-08-20 10:13:36.491003\n",
      "resetting env. episode 5673, reward total was -14.0. running mean: -15.304991238245787, timestamp: 2022-08-20 10:13:40.203575\n",
      "resetting env. episode 5674, reward total was -14.0. running mean: -15.291941325863329, timestamp: 2022-08-20 10:13:43.668616\n",
      "resetting env. episode 5675, reward total was -18.0. running mean: -15.319021912604695, timestamp: 2022-08-20 10:13:47.028653\n",
      "resetting env. episode 5676, reward total was -16.0. running mean: -15.325831693478648, timestamp: 2022-08-20 10:13:50.465217\n",
      "resetting env. episode 5677, reward total was -12.0. running mean: -15.29257337654386, timestamp: 2022-08-20 10:13:54.592268\n",
      "resetting env. episode 5678, reward total was -15.0. running mean: -15.289647642778421, timestamp: 2022-08-20 10:13:58.277835\n",
      "resetting env. episode 5679, reward total was -19.0. running mean: -15.326751166350636, timestamp: 2022-08-20 10:14:00.987869\n",
      "resetting env. episode 5680, reward total was -18.0. running mean: -15.35348365468713, timestamp: 2022-08-20 10:14:02.964890\n",
      "resetting env. episode 5681, reward total was -20.0. running mean: -15.399948818140258, timestamp: 2022-08-20 10:14:06.285933\n",
      "resetting env. episode 5682, reward total was -14.0. running mean: -15.385949329958855, timestamp: 2022-08-20 10:14:09.813974\n",
      "resetting env. episode 5683, reward total was -16.0. running mean: -15.392089836659267, timestamp: 2022-08-20 10:14:12.018001\n",
      "resetting env. episode 5684, reward total was -13.0. running mean: -15.368168938292674, timestamp: 2022-08-20 10:14:15.688042\n",
      "resetting env. episode 5685, reward total was -15.0. running mean: -15.364487248909748, timestamp: 2022-08-20 10:14:20.172100\n",
      "resetting env. episode 5686, reward total was -18.0. running mean: -15.39084237642065, timestamp: 2022-08-20 10:14:23.695139\n",
      "resetting env. episode 5687, reward total was -16.0. running mean: -15.396933952656443, timestamp: 2022-08-20 10:14:26.202168\n",
      "resetting env. episode 5688, reward total was -15.0. running mean: -15.392964613129879, timestamp: 2022-08-20 10:14:29.182206\n",
      "resetting env. episode 5689, reward total was -17.0. running mean: -15.409034966998579, timestamp: 2022-08-20 10:14:32.264241\n",
      "resetting env. episode 5690, reward total was -14.0. running mean: -15.394944617328594, timestamp: 2022-08-20 10:14:36.221289\n",
      "resetting env. episode 5691, reward total was -16.0. running mean: -15.400995171155309, timestamp: 2022-08-20 10:14:40.663342\n",
      "resetting env. episode 5692, reward total was -6.0. running mean: -15.306985219443757, timestamp: 2022-08-20 10:14:45.963405\n",
      "resetting env. episode 5693, reward total was -16.0. running mean: -15.313915367249319, timestamp: 2022-08-20 10:14:49.060444\n",
      "resetting env. episode 5694, reward total was -14.0. running mean: -15.300776213576826, timestamp: 2022-08-20 10:14:53.021486\n",
      "resetting env. episode 5695, reward total was -19.0. running mean: -15.337768451441057, timestamp: 2022-08-20 10:14:56.531529\n",
      "resetting env. episode 5696, reward total was -17.0. running mean: -15.354390766926647, timestamp: 2022-08-20 10:14:59.235563\n",
      "resetting env. episode 5697, reward total was -13.0. running mean: -15.330846859257381, timestamp: 2022-08-20 10:15:03.190606\n",
      "resetting env. episode 5698, reward total was -14.0. running mean: -15.317538390664808, timestamp: 2022-08-20 10:15:07.921667\n",
      "resetting env. episode 5699, reward total was -13.0. running mean: -15.29436300675816, timestamp: 2022-08-20 10:15:11.888712\n",
      "resetting env. episode 5700, reward total was -18.0. running mean: -15.321419376690578, timestamp: 2022-08-20 10:15:14.099738\n",
      "resetting env. episode 5701, reward total was -19.0. running mean: -15.35820518292367, timestamp: 2022-08-20 10:15:16.385769\n",
      "resetting env. episode 5702, reward total was -20.0. running mean: -15.404623131094434, timestamp: 2022-08-20 10:15:18.945797\n",
      "resetting env. episode 5703, reward total was -12.0. running mean: -15.370576899783488, timestamp: 2022-08-20 10:15:23.529854\n",
      "resetting env. episode 5704, reward total was -17.0. running mean: -15.386871130785654, timestamp: 2022-08-20 10:15:26.543885\n",
      "resetting env. episode 5705, reward total was -20.0. running mean: -15.433002419477797, timestamp: 2022-08-20 10:15:29.437921\n",
      "resetting env. episode 5706, reward total was -17.0. running mean: -15.448672395283019, timestamp: 2022-08-20 10:15:32.239956\n",
      "resetting env. episode 5707, reward total was -13.0. running mean: -15.42418567133019, timestamp: 2022-08-20 10:15:35.649994\n",
      "resetting env. episode 5708, reward total was -8.0. running mean: -15.349943814616887, timestamp: 2022-08-20 10:15:40.462051\n",
      "resetting env. episode 5709, reward total was -19.0. running mean: -15.386444376470719, timestamp: 2022-08-20 10:15:42.533078\n",
      "resetting env. episode 5710, reward total was -18.0. running mean: -15.412579932706011, timestamp: 2022-08-20 10:15:45.388111\n",
      "resetting env. episode 5711, reward total was -16.0. running mean: -15.418454133378951, timestamp: 2022-08-20 10:15:48.248673\n",
      "resetting env. episode 5712, reward total was -16.0. running mean: -15.424269592045162, timestamp: 2022-08-20 10:15:51.505708\n",
      "resetting env. episode 5713, reward total was -12.0. running mean: -15.39002689612471, timestamp: 2022-08-20 10:15:56.084760\n",
      "resetting env. episode 5714, reward total was -15.0. running mean: -15.386126627163462, timestamp: 2022-08-20 10:15:59.450804\n",
      "resetting env. episode 5715, reward total was -17.0. running mean: -15.402265360891827, timestamp: 2022-08-20 10:16:02.995371\n",
      "resetting env. episode 5716, reward total was -13.0. running mean: -15.37824270728291, timestamp: 2022-08-20 10:16:06.696414\n",
      "resetting env. episode 5717, reward total was -11.0. running mean: -15.33446028021008, timestamp: 2022-08-20 10:16:11.545469\n",
      "resetting env. episode 5718, reward total was -15.0. running mean: -15.331115677407979, timestamp: 2022-08-20 10:16:16.571533\n",
      "resetting env. episode 5719, reward total was -16.0. running mean: -15.337804520633899, timestamp: 2022-08-20 10:16:19.489566\n",
      "resetting env. episode 5720, reward total was -12.0. running mean: -15.30442647542756, timestamp: 2022-08-20 10:16:23.726614\n",
      "resetting env. episode 5721, reward total was -19.0. running mean: -15.341382210673284, timestamp: 2022-08-20 10:16:26.126643\n",
      "resetting env. episode 5722, reward total was -13.0. running mean: -15.317968388566552, timestamp: 2022-08-20 10:16:29.755685\n",
      "resetting env. episode 5723, reward total was -20.0. running mean: -15.364788704680885, timestamp: 2022-08-20 10:16:33.293728\n",
      "resetting env. episode 5724, reward total was -17.0. running mean: -15.381140817634076, timestamp: 2022-08-20 10:16:37.439776\n",
      "resetting env. episode 5725, reward total was -17.0. running mean: -15.397329409457734, timestamp: 2022-08-20 10:16:40.508814\n",
      "resetting env. episode 5726, reward total was -13.0. running mean: -15.373356115363158, timestamp: 2022-08-20 10:16:44.874864\n",
      "resetting env. episode 5727, reward total was -12.0. running mean: -15.339622554209527, timestamp: 2022-08-20 10:16:48.802912\n",
      "resetting env. episode 5728, reward total was -15.0. running mean: -15.336226328667431, timestamp: 2022-08-20 10:16:52.011469\n",
      "resetting env. episode 5729, reward total was -19.0. running mean: -15.372864065380757, timestamp: 2022-08-20 10:16:56.441521\n",
      "resetting env. episode 5730, reward total was -13.0. running mean: -15.34913542472695, timestamp: 2022-08-20 10:16:59.960565\n",
      "resetting env. episode 5731, reward total was -17.0. running mean: -15.365644070479679, timestamp: 2022-08-20 10:17:02.336593\n",
      "resetting env. episode 5732, reward total was -17.0. running mean: -15.381987629774882, timestamp: 2022-08-20 10:17:05.203625\n",
      "resetting env. episode 5733, reward total was -17.0. running mean: -15.398167753477132, timestamp: 2022-08-20 10:17:07.783656\n",
      "resetting env. episode 5734, reward total was -17.0. running mean: -15.41418607594236, timestamp: 2022-08-20 10:17:10.745692\n",
      "resetting env. episode 5735, reward total was -17.0. running mean: -15.430044215182937, timestamp: 2022-08-20 10:17:13.239720\n",
      "resetting env. episode 5736, reward total was -17.0. running mean: -15.445743773031108, timestamp: 2022-08-20 10:17:16.928764\n",
      "resetting env. episode 5737, reward total was -16.0. running mean: -15.451286335300797, timestamp: 2022-08-20 10:17:19.962799\n",
      "resetting env. episode 5738, reward total was -12.0. running mean: -15.416773471947788, timestamp: 2022-08-20 10:17:24.213851\n",
      "resetting env. episode 5739, reward total was -16.0. running mean: -15.422605737228311, timestamp: 2022-08-20 10:17:28.239901\n",
      "resetting env. episode 5740, reward total was -15.0. running mean: -15.418379679856029, timestamp: 2022-08-20 10:17:31.276931\n",
      "resetting env. episode 5741, reward total was -16.0. running mean: -15.424195883057468, timestamp: 2022-08-20 10:17:34.571505\n",
      "resetting env. episode 5742, reward total was -10.0. running mean: -15.369953924226893, timestamp: 2022-08-20 10:17:38.661552\n",
      "resetting env. episode 5743, reward total was -14.0. running mean: -15.356254384984625, timestamp: 2022-08-20 10:17:42.177594\n",
      "resetting env. episode 5744, reward total was -16.0. running mean: -15.36269184113478, timestamp: 2022-08-20 10:17:45.027626\n",
      "resetting env. episode 5745, reward total was -14.0. running mean: -15.349064922723432, timestamp: 2022-08-20 10:17:48.641669\n",
      "resetting env. episode 5746, reward total was -13.0. running mean: -15.325574273496198, timestamp: 2022-08-20 10:17:51.876754\n",
      "resetting env. episode 5747, reward total was -17.0. running mean: -15.342318530761236, timestamp: 2022-08-20 10:17:55.559793\n",
      "resetting env. episode 5748, reward total was -15.0. running mean: -15.338895345453624, timestamp: 2022-08-20 10:17:58.529877\n",
      "resetting env. episode 5749, reward total was -12.0. running mean: -15.305506391999087, timestamp: 2022-08-20 10:18:02.394922\n",
      "resetting env. episode 5750, reward total was -18.0. running mean: -15.332451328079095, timestamp: 2022-08-20 10:18:04.676954\n",
      "resetting env. episode 5751, reward total was -16.0. running mean: -15.339126814798304, timestamp: 2022-08-20 10:18:07.440982\n",
      "resetting env. episode 5752, reward total was -13.0. running mean: -15.315735546650322, timestamp: 2022-08-20 10:18:10.492018\n",
      "resetting env. episode 5753, reward total was -16.0. running mean: -15.322578191183819, timestamp: 2022-08-20 10:18:14.676068\n",
      "resetting env. episode 5754, reward total was -19.0. running mean: -15.359352409271981, timestamp: 2022-08-20 10:18:17.776105\n",
      "resetting env. episode 5755, reward total was -20.0. running mean: -15.40575888517926, timestamp: 2022-08-20 10:18:20.461135\n",
      "resetting env. episode 5756, reward total was -12.0. running mean: -15.371701296327467, timestamp: 2022-08-20 10:18:24.572185\n",
      "resetting env. episode 5757, reward total was -17.0. running mean: -15.387984283364192, timestamp: 2022-08-20 10:18:27.779746\n",
      "resetting env. episode 5758, reward total was -17.0. running mean: -15.40410444053055, timestamp: 2022-08-20 10:18:31.613790\n",
      "resetting env. episode 5759, reward total was -16.0. running mean: -15.410063396125244, timestamp: 2022-08-20 10:18:34.817829\n",
      "resetting env. episode 5760, reward total was -16.0. running mean: -15.415962762163991, timestamp: 2022-08-20 10:18:38.032867\n",
      "resetting env. episode 5761, reward total was -15.0. running mean: -15.411803134542351, timestamp: 2022-08-20 10:18:41.088902\n",
      "resetting env. episode 5762, reward total was -9.0. running mean: -15.347685103196927, timestamp: 2022-08-20 10:18:45.369952\n",
      "resetting env. episode 5763, reward total was -15.0. running mean: -15.344208252164957, timestamp: 2022-08-20 10:18:48.529990\n",
      "resetting env. episode 5764, reward total was -20.0. running mean: -15.390766169643307, timestamp: 2022-08-20 10:18:52.107034\n",
      "resetting env. episode 5765, reward total was -17.0. running mean: -15.406858507946874, timestamp: 2022-08-20 10:18:55.745126\n",
      "resetting env. episode 5766, reward total was -15.0. running mean: -15.402789922867406, timestamp: 2022-08-20 10:18:58.432161\n",
      "resetting env. episode 5767, reward total was -15.0. running mean: -15.398762023638731, timestamp: 2022-08-20 10:19:01.490206\n",
      "resetting env. episode 5768, reward total was -21.0. running mean: -15.454774403402345, timestamp: 2022-08-20 10:19:03.758218\n",
      "resetting env. episode 5769, reward total was -20.0. running mean: -15.500226659368321, timestamp: 2022-08-20 10:19:06.136769\n",
      "resetting env. episode 5770, reward total was -16.0. running mean: -15.505224392774638, timestamp: 2022-08-20 10:19:09.354808\n",
      "resetting env. episode 5771, reward total was -19.0. running mean: -15.54017214884689, timestamp: 2022-08-20 10:19:11.178826\n",
      "resetting env. episode 5772, reward total was -16.0. running mean: -15.544770427358422, timestamp: 2022-08-20 10:19:14.878872\n",
      "resetting env. episode 5773, reward total was -15.0. running mean: -15.539322723084839, timestamp: 2022-08-20 10:19:18.911924\n",
      "resetting env. episode 5774, reward total was -19.0. running mean: -15.573929495853989, timestamp: 2022-08-20 10:19:20.954943\n",
      "resetting env. episode 5775, reward total was -8.0. running mean: -15.498190200895449, timestamp: 2022-08-20 10:19:25.635000\n",
      "resetting env. episode 5776, reward total was -16.0. running mean: -15.503208298886495, timestamp: 2022-08-20 10:19:29.133039\n",
      "resetting env. episode 5777, reward total was -19.0. running mean: -15.538176215897629, timestamp: 2022-08-20 10:19:31.611067\n",
      "resetting env. episode 5778, reward total was -13.0. running mean: -15.512794453738653, timestamp: 2022-08-20 10:19:35.051633\n",
      "resetting env. episode 5779, reward total was -16.0. running mean: -15.517666509201266, timestamp: 2022-08-20 10:19:37.916667\n",
      "resetting env. episode 5780, reward total was -13.0. running mean: -15.492489844109254, timestamp: 2022-08-20 10:19:41.932239\n",
      "resetting env. episode 5781, reward total was -19.0. running mean: -15.52756494566816, timestamp: 2022-08-20 10:19:44.127266\n",
      "resetting env. episode 5782, reward total was -16.0. running mean: -15.532289296211479, timestamp: 2022-08-20 10:19:47.092298\n",
      "resetting env. episode 5783, reward total was -17.0. running mean: -15.546966403249364, timestamp: 2022-08-20 10:19:49.465326\n",
      "resetting env. episode 5784, reward total was -11.0. running mean: -15.50149673921687, timestamp: 2022-08-20 10:19:55.048394\n",
      "resetting env. episode 5785, reward total was -16.0. running mean: -15.506481771824701, timestamp: 2022-08-20 10:19:58.850436\n",
      "resetting env. episode 5786, reward total was -10.0. running mean: -15.451416954106454, timestamp: 2022-08-20 10:20:03.000486\n",
      "resetting env. episode 5787, reward total was -21.0. running mean: -15.50690278456539, timestamp: 2022-08-20 10:20:06.066528\n",
      "resetting env. episode 5788, reward total was -17.0. running mean: -15.521833756719737, timestamp: 2022-08-20 10:20:09.502611\n",
      "resetting env. episode 5789, reward total was -15.0. running mean: -15.51661541915254, timestamp: 2022-08-20 10:20:12.774652\n",
      "resetting env. episode 5790, reward total was -8.0. running mean: -15.441449264961015, timestamp: 2022-08-20 10:20:17.622708\n",
      "resetting env. episode 5791, reward total was -15.0. running mean: -15.437034772311405, timestamp: 2022-08-20 10:20:21.778759\n",
      "resetting env. episode 5792, reward total was -18.0. running mean: -15.46266442458829, timestamp: 2022-08-20 10:20:24.232788\n",
      "resetting env. episode 5793, reward total was -12.0. running mean: -15.428037780342406, timestamp: 2022-08-20 10:20:28.658847\n",
      "resetting env. episode 5794, reward total was -12.0. running mean: -15.39375740253898, timestamp: 2022-08-20 10:20:32.614886\n",
      "resetting env. episode 5795, reward total was -15.0. running mean: -15.389819828513591, timestamp: 2022-08-20 10:20:36.573935\n",
      "resetting env. episode 5796, reward total was -18.0. running mean: -15.415921630228455, timestamp: 2022-08-20 10:20:39.910972\n",
      "resetting env. episode 5797, reward total was -16.0. running mean: -15.42176241392617, timestamp: 2022-08-20 10:20:43.103008\n",
      "resetting env. episode 5798, reward total was -17.0. running mean: -15.437544789786909, timestamp: 2022-08-20 10:20:46.863053\n",
      "resetting env. episode 5799, reward total was -15.0. running mean: -15.43316934188904, timestamp: 2022-08-20 10:20:49.726614\n",
      "resetting env. episode 5800, reward total was -17.0. running mean: -15.448837648470148, timestamp: 2022-08-20 10:20:53.178180\n",
      "resetting env. episode 5801, reward total was -18.0. running mean: -15.474349271985446, timestamp: 2022-08-20 10:20:55.867216\n",
      "resetting env. episode 5802, reward total was -14.0. running mean: -15.459605779265592, timestamp: 2022-08-20 10:20:58.791246\n",
      "resetting env. episode 5803, reward total was -18.0. running mean: -15.485009721472936, timestamp: 2022-08-20 10:21:01.532279\n",
      "resetting env. episode 5804, reward total was -19.0. running mean: -15.520159624258206, timestamp: 2022-08-20 10:21:04.307314\n",
      "resetting env. episode 5805, reward total was -20.0. running mean: -15.564958028015623, timestamp: 2022-08-20 10:21:06.998344\n",
      "resetting env. episode 5806, reward total was -15.0. running mean: -15.559308447735466, timestamp: 2022-08-20 10:21:09.821377\n",
      "resetting env. episode 5807, reward total was -20.0. running mean: -15.603715363258111, timestamp: 2022-08-20 10:21:11.509398\n",
      "resetting env. episode 5808, reward total was -20.0. running mean: -15.647678209625528, timestamp: 2022-08-20 10:21:13.821424\n",
      "resetting env. episode 5809, reward total was -15.0. running mean: -15.641201427529273, timestamp: 2022-08-20 10:21:17.711995\n",
      "resetting env. episode 5810, reward total was -14.0. running mean: -15.62478941325398, timestamp: 2022-08-20 10:21:21.022560\n",
      "resetting env. episode 5811, reward total was -15.0. running mean: -15.618541519121441, timestamp: 2022-08-20 10:21:24.337595\n",
      "resetting env. episode 5812, reward total was -15.0. running mean: -15.612356103930226, timestamp: 2022-08-20 10:21:27.882642\n",
      "resetting env. episode 5813, reward total was -18.0. running mean: -15.636232542890923, timestamp: 2022-08-20 10:21:30.971683\n",
      "resetting env. episode 5814, reward total was -18.0. running mean: -15.659870217462013, timestamp: 2022-08-20 10:21:33.800708\n",
      "resetting env. episode 5815, reward total was -20.0. running mean: -15.703271515287392, timestamp: 2022-08-20 10:21:35.950734\n",
      "resetting env. episode 5816, reward total was -18.0. running mean: -15.726238800134517, timestamp: 2022-08-20 10:21:38.590777\n",
      "resetting env. episode 5817, reward total was -19.0. running mean: -15.75897641213317, timestamp: 2022-08-20 10:21:41.503804\n",
      "resetting env. episode 5818, reward total was -16.0. running mean: -15.76138664801184, timestamp: 2022-08-20 10:21:44.934843\n",
      "resetting env. episode 5819, reward total was -16.0. running mean: -15.76377278153172, timestamp: 2022-08-20 10:21:47.456871\n",
      "resetting env. episode 5820, reward total was -11.0. running mean: -15.716135053716403, timestamp: 2022-08-20 10:21:51.499921\n",
      "resetting env. episode 5821, reward total was -18.0. running mean: -15.738973703179239, timestamp: 2022-08-20 10:21:55.066963\n",
      "resetting env. episode 5822, reward total was -17.0. running mean: -15.751583966147447, timestamp: 2022-08-20 10:21:58.249005\n",
      "resetting env. episode 5823, reward total was -14.0. running mean: -15.734068126485973, timestamp: 2022-08-20 10:22:01.401036\n",
      "resetting env. episode 5824, reward total was -18.0. running mean: -15.756727445221113, timestamp: 2022-08-20 10:22:04.430076\n",
      "resetting env. episode 5825, reward total was -16.0. running mean: -15.759160170768903, timestamp: 2022-08-20 10:22:08.491645\n",
      "resetting env. episode 5826, reward total was -16.0. running mean: -15.761568569061213, timestamp: 2022-08-20 10:22:11.403727\n",
      "resetting env. episode 5827, reward total was -19.0. running mean: -15.7939528833706, timestamp: 2022-08-20 10:22:14.620769\n",
      "resetting env. episode 5828, reward total was -13.0. running mean: -15.766013354536895, timestamp: 2022-08-20 10:22:18.170340\n",
      "resetting env. episode 5829, reward total was -21.0. running mean: -15.818353220991527, timestamp: 2022-08-20 10:22:19.717351\n",
      "resetting env. episode 5830, reward total was -19.0. running mean: -15.850169688781612, timestamp: 2022-08-20 10:22:22.502383\n",
      "resetting env. episode 5831, reward total was -18.0. running mean: -15.871667991893796, timestamp: 2022-08-20 10:22:25.596424\n",
      "resetting env. episode 5832, reward total was -16.0. running mean: -15.872951311974859, timestamp: 2022-08-20 10:22:29.251467\n",
      "resetting env. episode 5833, reward total was -17.0. running mean: -15.88422179885511, timestamp: 2022-08-20 10:22:32.300505\n",
      "resetting env. episode 5834, reward total was -15.0. running mean: -15.875379580866559, timestamp: 2022-08-20 10:22:35.694542\n",
      "resetting env. episode 5835, reward total was -19.0. running mean: -15.906625785057892, timestamp: 2022-08-20 10:22:38.540581\n",
      "resetting env. episode 5836, reward total was -18.0. running mean: -15.927559527207313, timestamp: 2022-08-20 10:22:41.364610\n",
      "resetting env. episode 5837, reward total was -19.0. running mean: -15.95828393193524, timestamp: 2022-08-20 10:22:44.368649\n",
      "resetting env. episode 5838, reward total was -12.0. running mean: -15.918701092615887, timestamp: 2022-08-20 10:22:48.692697\n",
      "resetting env. episode 5839, reward total was -14.0. running mean: -15.899514081689729, timestamp: 2022-08-20 10:22:51.925735\n",
      "resetting env. episode 5840, reward total was -14.0. running mean: -15.880518940872832, timestamp: 2022-08-20 10:22:55.560778\n",
      "resetting env. episode 5841, reward total was -13.0. running mean: -15.851713751464105, timestamp: 2022-08-20 10:22:59.010349\n",
      "resetting env. episode 5842, reward total was -12.0. running mean: -15.813196613949463, timestamp: 2022-08-20 10:23:02.757439\n",
      "resetting env. episode 5843, reward total was -14.0. running mean: -15.79506464780997, timestamp: 2022-08-20 10:23:06.608484\n",
      "resetting env. episode 5844, reward total was -19.0. running mean: -15.82711400133187, timestamp: 2022-08-20 10:23:08.591040\n",
      "resetting env. episode 5845, reward total was -12.0. running mean: -15.78884286131855, timestamp: 2022-08-20 10:23:12.930086\n",
      "resetting env. episode 5846, reward total was -12.0. running mean: -15.750954432705363, timestamp: 2022-08-20 10:23:16.947138\n",
      "resetting env. episode 5847, reward total was -20.0. running mean: -15.793444888378309, timestamp: 2022-08-20 10:23:20.032697\n",
      "resetting env. episode 5848, reward total was -18.0. running mean: -15.815510439494526, timestamp: 2022-08-20 10:23:23.130736\n",
      "resetting env. episode 5849, reward total was -16.0. running mean: -15.817355335099581, timestamp: 2022-08-20 10:23:26.507773\n",
      "resetting env. episode 5850, reward total was -13.0. running mean: -15.789181781748585, timestamp: 2022-08-20 10:23:29.344808\n",
      "resetting env. episode 5851, reward total was -14.0. running mean: -15.7712899639311, timestamp: 2022-08-20 10:23:32.735380\n",
      "resetting env. episode 5852, reward total was -18.0. running mean: -15.793577064291789, timestamp: 2022-08-20 10:23:35.768934\n",
      "resetting env. episode 5853, reward total was -16.0. running mean: -15.79564129364887, timestamp: 2022-08-20 10:23:38.656968\n",
      "resetting env. episode 5854, reward total was -18.0. running mean: -15.817684880712381, timestamp: 2022-08-20 10:23:40.954999\n",
      "resetting env. episode 5855, reward total was -5.0. running mean: -15.709508031905258, timestamp: 2022-08-20 10:23:46.326060\n",
      "resetting env. episode 5856, reward total was -16.0. running mean: -15.712412951586206, timestamp: 2022-08-20 10:23:49.304096\n",
      "resetting env. episode 5857, reward total was -13.0. running mean: -15.685288822070344, timestamp: 2022-08-20 10:23:52.428129\n",
      "resetting env. episode 5858, reward total was -15.0. running mean: -15.678435933849642, timestamp: 2022-08-20 10:23:56.297177\n",
      "resetting env. episode 5859, reward total was -17.0. running mean: -15.691651574511145, timestamp: 2022-08-20 10:23:59.131216\n",
      "resetting env. episode 5860, reward total was -19.0. running mean: -15.724735058766033, timestamp: 2022-08-20 10:24:01.875244\n",
      "resetting env. episode 5861, reward total was -18.0. running mean: -15.747487708178372, timestamp: 2022-08-20 10:24:04.336273\n",
      "resetting env. episode 5862, reward total was -19.0. running mean: -15.780012831096588, timestamp: 2022-08-20 10:24:06.746302\n",
      "resetting env. episode 5863, reward total was -18.0. running mean: -15.802212702785623, timestamp: 2022-08-20 10:24:09.327337\n",
      "resetting env. episode 5864, reward total was -19.0. running mean: -15.834190575757766, timestamp: 2022-08-20 10:24:12.606370\n",
      "resetting env. episode 5865, reward total was -14.0. running mean: -15.81584867000019, timestamp: 2022-08-20 10:24:15.599408\n",
      "resetting env. episode 5866, reward total was -17.0. running mean: -15.827690183300188, timestamp: 2022-08-20 10:24:18.142442\n",
      "resetting env. episode 5867, reward total was -17.0. running mean: -15.839413281467186, timestamp: 2022-08-20 10:24:21.134478\n",
      "resetting env. episode 5868, reward total was -13.0. running mean: -15.811019148652514, timestamp: 2022-08-20 10:24:24.673038\n",
      "resetting env. episode 5869, reward total was -21.0. running mean: -15.86290895716599, timestamp: 2022-08-20 10:24:27.079609\n",
      "resetting env. episode 5870, reward total was -17.0. running mean: -15.87427986759433, timestamp: 2022-08-20 10:24:30.540653\n",
      "resetting env. episode 5871, reward total was -10.0. running mean: -15.815537068918387, timestamp: 2022-08-20 10:24:35.440232\n",
      "resetting env. episode 5872, reward total was -14.0. running mean: -15.797381698229204, timestamp: 2022-08-20 10:24:38.821275\n",
      "resetting env. episode 5873, reward total was -12.0. running mean: -15.759407881246911, timestamp: 2022-08-20 10:24:42.774322\n",
      "resetting env. episode 5874, reward total was -16.0. running mean: -15.761813802434443, timestamp: 2022-08-20 10:24:47.123374\n",
      "resetting env. episode 5875, reward total was -18.0. running mean: -15.784195664410097, timestamp: 2022-08-20 10:24:50.509414\n",
      "resetting env. episode 5876, reward total was -15.0. running mean: -15.776353707765997, timestamp: 2022-08-20 10:24:53.738452\n",
      "resetting env. episode 5877, reward total was -18.0. running mean: -15.798590170688337, timestamp: 2022-08-20 10:24:56.717489\n",
      "resetting env. episode 5878, reward total was -14.0. running mean: -15.780604268981454, timestamp: 2022-08-20 10:24:59.569524\n",
      "resetting env. episode 5879, reward total was -16.0. running mean: -15.78279822629164, timestamp: 2022-08-20 10:25:03.271087\n",
      "resetting env. episode 5880, reward total was -6.0. running mean: -15.684970244028722, timestamp: 2022-08-20 10:25:08.293146\n",
      "resetting env. episode 5881, reward total was -18.0. running mean: -15.708120541588436, timestamp: 2022-08-20 10:25:11.635187\n",
      "resetting env. episode 5882, reward total was -16.0. running mean: -15.71103933617255, timestamp: 2022-08-20 10:25:15.080758\n",
      "resetting env. episode 5883, reward total was -16.0. running mean: -15.713928942810826, timestamp: 2022-08-20 10:25:19.136799\n",
      "resetting env. episode 5884, reward total was -13.0. running mean: -15.686789653382718, timestamp: 2022-08-20 10:25:22.951845\n",
      "resetting env. episode 5885, reward total was -17.0. running mean: -15.699921756848891, timestamp: 2022-08-20 10:25:25.422876\n",
      "resetting env. episode 5886, reward total was -12.0. running mean: -15.662922539280402, timestamp: 2022-08-20 10:25:30.253931\n",
      "resetting env. episode 5887, reward total was -12.0. running mean: -15.626293313887597, timestamp: 2022-08-20 10:25:34.809986\n",
      "resetting env. episode 5888, reward total was -18.0. running mean: -15.65003038074872, timestamp: 2022-08-20 10:25:37.848546\n",
      "resetting env. episode 5889, reward total was -19.0. running mean: -15.683530076941233, timestamp: 2022-08-20 10:25:40.274578\n",
      "resetting env. episode 5890, reward total was -15.0. running mean: -15.676694776171821, timestamp: 2022-08-20 10:25:44.489624\n",
      "resetting env. episode 5891, reward total was -17.0. running mean: -15.689927828410102, timestamp: 2022-08-20 10:25:48.351672\n",
      "resetting env. episode 5892, reward total was -13.0. running mean: -15.663028550126002, timestamp: 2022-08-20 10:25:52.355717\n",
      "resetting env. episode 5893, reward total was -15.0. running mean: -15.656398264624743, timestamp: 2022-08-20 10:25:57.472778\n",
      "resetting env. episode 5894, reward total was -16.0. running mean: -15.659834281978496, timestamp: 2022-08-20 10:26:00.167810\n",
      "resetting env. episode 5895, reward total was -18.0. running mean: -15.68323593915871, timestamp: 2022-08-20 10:26:02.512838\n",
      "resetting env. episode 5896, reward total was -9.0. running mean: -15.616403579767123, timestamp: 2022-08-20 10:26:06.776893\n",
      "resetting env. episode 5897, reward total was -16.0. running mean: -15.620239543969452, timestamp: 2022-08-20 10:26:10.449941\n",
      "resetting env. episode 5898, reward total was -17.0. running mean: -15.634037148529758, timestamp: 2022-08-20 10:26:13.276971\n",
      "resetting env. episode 5899, reward total was -15.0. running mean: -15.627696777044461, timestamp: 2022-08-20 10:26:17.055014\n",
      "resetting env. episode 5900, reward total was -17.0. running mean: -15.641419809274016, timestamp: 2022-08-20 10:26:20.732054\n",
      "resetting env. episode 5901, reward total was -18.0. running mean: -15.665005611181275, timestamp: 2022-08-20 10:26:24.347097\n",
      "resetting env. episode 5902, reward total was -10.0. running mean: -15.608355555069462, timestamp: 2022-08-20 10:26:29.026153\n",
      "resetting env. episode 5903, reward total was -16.0. running mean: -15.612271999518768, timestamp: 2022-08-20 10:26:32.080192\n",
      "resetting env. episode 5904, reward total was -17.0. running mean: -15.62614927952358, timestamp: 2022-08-20 10:26:36.619773\n",
      "resetting env. episode 5905, reward total was -19.0. running mean: -15.659887786728342, timestamp: 2022-08-20 10:26:39.949814\n",
      "resetting env. episode 5906, reward total was -18.0. running mean: -15.683288908861059, timestamp: 2022-08-20 10:26:42.360851\n",
      "resetting env. episode 5907, reward total was -16.0. running mean: -15.686456019772448, timestamp: 2022-08-20 10:26:45.470881\n",
      "resetting env. episode 5908, reward total was -17.0. running mean: -15.699591459574723, timestamp: 2022-08-20 10:26:48.491917\n",
      "resetting env. episode 5909, reward total was -15.0. running mean: -15.692595544978976, timestamp: 2022-08-20 10:26:52.664968\n",
      "resetting env. episode 5910, reward total was -15.0. running mean: -15.685669589529187, timestamp: 2022-08-20 10:26:56.861017\n",
      "resetting env. episode 5911, reward total was -9.0. running mean: -15.618812893633894, timestamp: 2022-08-20 10:27:01.910077\n",
      "resetting env. episode 5912, reward total was -13.0. running mean: -15.592624764697556, timestamp: 2022-08-20 10:27:05.360119\n",
      "resetting env. episode 5913, reward total was -18.0. running mean: -15.61669851705058, timestamp: 2022-08-20 10:27:08.364153\n",
      "resetting env. episode 5914, reward total was -12.0. running mean: -15.580531531880073, timestamp: 2022-08-20 10:27:12.344204\n",
      "resetting env. episode 5915, reward total was -18.0. running mean: -15.604726216561271, timestamp: 2022-08-20 10:27:15.263235\n",
      "resetting env. episode 5916, reward total was -18.0. running mean: -15.628678954395658, timestamp: 2022-08-20 10:27:17.665265\n",
      "resetting env. episode 5917, reward total was -17.0. running mean: -15.642392164851701, timestamp: 2022-08-20 10:27:20.266295\n",
      "resetting env. episode 5918, reward total was -15.0. running mean: -15.635968243203184, timestamp: 2022-08-20 10:27:23.790336\n",
      "resetting env. episode 5919, reward total was -19.0. running mean: -15.66960856077115, timestamp: 2022-08-20 10:27:26.755372\n",
      "resetting env. episode 5920, reward total was -17.0. running mean: -15.68291247516344, timestamp: 2022-08-20 10:27:31.234428\n",
      "resetting env. episode 5921, reward total was -13.0. running mean: -15.656083350411805, timestamp: 2022-08-20 10:27:35.194475\n",
      "resetting env. episode 5922, reward total was -19.0. running mean: -15.689522516907687, timestamp: 2022-08-20 10:27:39.991529\n",
      "resetting env. episode 5923, reward total was -15.0. running mean: -15.68262729173861, timestamp: 2022-08-20 10:27:43.782575\n",
      "resetting env. episode 5924, reward total was -15.0. running mean: -15.675801018821224, timestamp: 2022-08-20 10:27:46.664611\n",
      "resetting env. episode 5925, reward total was -18.0. running mean: -15.69904300863301, timestamp: 2022-08-20 10:27:50.064651\n",
      "resetting env. episode 5926, reward total was -14.0. running mean: -15.682052578546681, timestamp: 2022-08-20 10:27:53.440689\n",
      "resetting env. episode 5927, reward total was -15.0. running mean: -15.675232052761215, timestamp: 2022-08-20 10:27:56.686728\n",
      "resetting env. episode 5928, reward total was -15.0. running mean: -15.668479732233603, timestamp: 2022-08-20 10:28:00.232777\n",
      "resetting env. episode 5929, reward total was -12.0. running mean: -15.631794934911266, timestamp: 2022-08-20 10:28:04.385818\n",
      "resetting env. episode 5930, reward total was -20.0. running mean: -15.675476985562153, timestamp: 2022-08-20 10:28:07.273854\n",
      "resetting env. episode 5931, reward total was -15.0. running mean: -15.66872221570653, timestamp: 2022-08-20 10:28:10.851899\n",
      "resetting env. episode 5932, reward total was -13.0. running mean: -15.642034993549466, timestamp: 2022-08-20 10:28:14.362938\n",
      "resetting env. episode 5933, reward total was -13.0. running mean: -15.615614643613972, timestamp: 2022-08-20 10:28:17.972981\n",
      "resetting env. episode 5934, reward total was -17.0. running mean: -15.629458497177831, timestamp: 2022-08-20 10:28:21.130019\n",
      "resetting env. episode 5935, reward total was -17.0. running mean: -15.643163912206052, timestamp: 2022-08-20 10:28:23.648049\n",
      "resetting env. episode 5936, reward total was -18.0. running mean: -15.66673227308399, timestamp: 2022-08-20 10:28:26.926089\n",
      "resetting env. episode 5937, reward total was -15.0. running mean: -15.660064950353151, timestamp: 2022-08-20 10:28:30.566133\n",
      "resetting env. episode 5938, reward total was -19.0. running mean: -15.69346430084962, timestamp: 2022-08-20 10:28:33.067159\n",
      "resetting env. episode 5939, reward total was -15.0. running mean: -15.686529657841124, timestamp: 2022-08-20 10:28:37.159209\n",
      "resetting env. episode 5940, reward total was -13.0. running mean: -15.659664361262713, timestamp: 2022-08-20 10:28:42.407274\n",
      "resetting env. episode 5941, reward total was -14.0. running mean: -15.643067717650087, timestamp: 2022-08-20 10:28:45.905310\n",
      "resetting env. episode 5942, reward total was -16.0. running mean: -15.646637040473586, timestamp: 2022-08-20 10:28:50.303362\n",
      "resetting env. episode 5943, reward total was -18.0. running mean: -15.670170670068849, timestamp: 2022-08-20 10:28:55.030422\n",
      "resetting env. episode 5944, reward total was -14.0. running mean: -15.65346896336816, timestamp: 2022-08-20 10:28:58.644461\n",
      "resetting env. episode 5945, reward total was -15.0. running mean: -15.646934273734479, timestamp: 2022-08-20 10:29:03.491519\n",
      "resetting env. episode 5946, reward total was -19.0. running mean: -15.680464930997132, timestamp: 2022-08-20 10:29:06.149555\n",
      "resetting env. episode 5947, reward total was -17.0. running mean: -15.69366028168716, timestamp: 2022-08-20 10:29:09.276586\n",
      "resetting env. episode 5948, reward total was -14.0. running mean: -15.676723678870289, timestamp: 2022-08-20 10:29:13.122635\n",
      "resetting env. episode 5949, reward total was -17.0. running mean: -15.689956442081586, timestamp: 2022-08-20 10:29:16.488671\n",
      "resetting env. episode 5950, reward total was -12.0. running mean: -15.653056877660768, timestamp: 2022-08-20 10:29:20.049716\n",
      "resetting env. episode 5951, reward total was -14.0. running mean: -15.63652630888416, timestamp: 2022-08-20 10:29:23.814759\n",
      "resetting env. episode 5952, reward total was -16.0. running mean: -15.640161045795319, timestamp: 2022-08-20 10:29:28.020863\n",
      "resetting env. episode 5953, reward total was -19.0. running mean: -15.673759435337365, timestamp: 2022-08-20 10:29:30.749893\n",
      "resetting env. episode 5954, reward total was -18.0. running mean: -15.697021840983991, timestamp: 2022-08-20 10:29:35.534954\n",
      "resetting env. episode 5955, reward total was -19.0. running mean: -15.73005162257415, timestamp: 2022-08-20 10:29:37.978978\n",
      "resetting env. episode 5956, reward total was -16.0. running mean: -15.732751106348408, timestamp: 2022-08-20 10:29:41.915029\n",
      "resetting env. episode 5957, reward total was -17.0. running mean: -15.745423595284924, timestamp: 2022-08-20 10:29:45.369070\n",
      "resetting env. episode 5958, reward total was -16.0. running mean: -15.747969359332075, timestamp: 2022-08-20 10:29:49.209111\n",
      "resetting env. episode 5959, reward total was -18.0. running mean: -15.770489665738754, timestamp: 2022-08-20 10:29:52.253146\n",
      "resetting env. episode 5960, reward total was -19.0. running mean: -15.802784769081367, timestamp: 2022-08-20 10:29:54.691174\n",
      "resetting env. episode 5961, reward total was -10.0. running mean: -15.744756921390552, timestamp: 2022-08-20 10:29:58.996226\n",
      "resetting env. episode 5962, reward total was -14.0. running mean: -15.727309352176647, timestamp: 2022-08-20 10:30:02.361266\n",
      "resetting env. episode 5963, reward total was -17.0. running mean: -15.74003625865488, timestamp: 2022-08-20 10:30:05.694305\n",
      "resetting env. episode 5964, reward total was -18.0. running mean: -15.762635896068332, timestamp: 2022-08-20 10:30:08.965345\n",
      "resetting env. episode 5965, reward total was -13.0. running mean: -15.735009537107649, timestamp: 2022-08-20 10:30:13.978404\n",
      "resetting env. episode 5966, reward total was -19.0. running mean: -15.767659441736571, timestamp: 2022-08-20 10:30:17.139441\n",
      "resetting env. episode 5967, reward total was -17.0. running mean: -15.779982847319205, timestamp: 2022-08-20 10:30:19.852477\n",
      "resetting env. episode 5968, reward total was -18.0. running mean: -15.802183018846012, timestamp: 2022-08-20 10:30:22.743506\n",
      "resetting env. episode 5969, reward total was -19.0. running mean: -15.834161188657552, timestamp: 2022-08-20 10:30:25.040536\n",
      "resetting env. episode 5970, reward total was -14.0. running mean: -15.815819576770977, timestamp: 2022-08-20 10:30:29.054580\n",
      "resetting env. episode 5971, reward total was -9.0. running mean: -15.747661381003267, timestamp: 2022-08-20 10:30:33.182631\n",
      "resetting env. episode 5972, reward total was -14.0. running mean: -15.730184767193235, timestamp: 2022-08-20 10:30:36.597674\n",
      "resetting env. episode 5973, reward total was -16.0. running mean: -15.732882919521302, timestamp: 2022-08-20 10:30:40.501719\n",
      "resetting env. episode 5974, reward total was -17.0. running mean: -15.745554090326088, timestamp: 2022-08-20 10:30:43.760756\n",
      "resetting env. episode 5975, reward total was -17.0. running mean: -15.758098549422828, timestamp: 2022-08-20 10:30:46.352787\n",
      "resetting env. episode 5976, reward total was -19.0. running mean: -15.7905175639286, timestamp: 2022-08-20 10:30:49.097817\n",
      "resetting env. episode 5977, reward total was -18.0. running mean: -15.812612388289313, timestamp: 2022-08-20 10:30:52.281859\n",
      "resetting env. episode 5978, reward total was -9.0. running mean: -15.74448626440642, timestamp: 2022-08-20 10:30:56.729908\n",
      "resetting env. episode 5979, reward total was -20.0. running mean: -15.787041401762355, timestamp: 2022-08-20 10:30:58.779463\n",
      "resetting env. episode 5980, reward total was -14.0. running mean: -15.769170987744733, timestamp: 2022-08-20 10:31:03.512514\n",
      "resetting env. episode 5981, reward total was -19.0. running mean: -15.801479277867285, timestamp: 2022-08-20 10:31:05.262539\n",
      "resetting env. episode 5982, reward total was -16.0. running mean: -15.803464485088613, timestamp: 2022-08-20 10:31:07.951091\n",
      "resetting env. episode 5983, reward total was -16.0. running mean: -15.805429840237727, timestamp: 2022-08-20 10:31:11.115127\n",
      "resetting env. episode 5984, reward total was -19.0. running mean: -15.837375541835348, timestamp: 2022-08-20 10:31:13.392150\n",
      "resetting env. episode 5985, reward total was -16.0. running mean: -15.839001786416995, timestamp: 2022-08-20 10:31:16.962192\n",
      "resetting env. episode 5986, reward total was -16.0. running mean: -15.840611768552826, timestamp: 2022-08-20 10:31:20.527235\n",
      "resetting env. episode 5987, reward total was -17.0. running mean: -15.852205650867297, timestamp: 2022-08-20 10:31:24.222277\n",
      "resetting env. episode 5988, reward total was -16.0. running mean: -15.853683594358625, timestamp: 2022-08-20 10:31:27.257315\n",
      "resetting env. episode 5989, reward total was -15.0. running mean: -15.845146758415039, timestamp: 2022-08-20 10:31:29.698343\n",
      "resetting env. episode 5990, reward total was -17.0. running mean: -15.856695290830888, timestamp: 2022-08-20 10:31:33.773439\n",
      "resetting env. episode 5991, reward total was -11.0. running mean: -15.808128337922579, timestamp: 2022-08-20 10:31:38.851497\n",
      "resetting env. episode 5992, reward total was -19.0. running mean: -15.840047054543353, timestamp: 2022-08-20 10:31:41.917535\n",
      "resetting env. episode 5993, reward total was -13.0. running mean: -15.81164658399792, timestamp: 2022-08-20 10:31:46.083583\n",
      "resetting env. episode 5994, reward total was -18.0. running mean: -15.83353011815794, timestamp: 2022-08-20 10:31:48.691614\n",
      "resetting env. episode 5995, reward total was -21.0. running mean: -15.88519481697636, timestamp: 2022-08-20 10:31:51.567647\n",
      "resetting env. episode 5996, reward total was -17.0. running mean: -15.896342868806597, timestamp: 2022-08-20 10:31:54.780684\n",
      "resetting env. episode 5997, reward total was -18.0. running mean: -15.91737944011853, timestamp: 2022-08-20 10:31:58.116726\n",
      "resetting env. episode 5998, reward total was -17.0. running mean: -15.928205645717345, timestamp: 2022-08-20 10:32:00.682754\n",
      "resetting env. episode 5999, reward total was -20.0. running mean: -15.96892358926017, timestamp: 2022-08-20 10:32:03.445785\n",
      "resetting env. episode 6000, reward total was -17.0. running mean: -15.979234353367568, timestamp: 2022-08-20 10:32:07.621837\n",
      "resetting env. episode 6001, reward total was -18.0. running mean: -15.999442009833892, timestamp: 2022-08-20 10:32:10.282869\n",
      "resetting env. episode 6002, reward total was -17.0. running mean: -16.009447589735554, timestamp: 2022-08-20 10:32:13.620908\n",
      "resetting env. episode 6003, reward total was -19.0. running mean: -16.0393531138382, timestamp: 2022-08-20 10:32:17.314947\n",
      "resetting env. episode 6004, reward total was -18.0. running mean: -16.058959582699817, timestamp: 2022-08-20 10:32:20.351987\n",
      "resetting env. episode 6005, reward total was -17.0. running mean: -16.06836998687282, timestamp: 2022-08-20 10:32:23.220017\n",
      "resetting env. episode 6006, reward total was -15.0. running mean: -16.057686287004092, timestamp: 2022-08-20 10:32:27.171063\n",
      "resetting env. episode 6007, reward total was -16.0. running mean: -16.05710942413405, timestamp: 2022-08-20 10:32:30.946119\n",
      "resetting env. episode 6008, reward total was -17.0. running mean: -16.066538329892712, timestamp: 2022-08-20 10:32:34.890155\n",
      "resetting env. episode 6009, reward total was -17.0. running mean: -16.075872946593787, timestamp: 2022-08-20 10:32:38.460196\n",
      "resetting env. episode 6010, reward total was -19.0. running mean: -16.10511421712785, timestamp: 2022-08-20 10:32:41.238227\n",
      "resetting env. episode 6011, reward total was -15.0. running mean: -16.09406307495657, timestamp: 2022-08-20 10:32:44.576266\n",
      "resetting env. episode 6012, reward total was -18.0. running mean: -16.113122444207004, timestamp: 2022-08-20 10:32:48.039828\n",
      "resetting env. episode 6013, reward total was -12.0. running mean: -16.071991219764936, timestamp: 2022-08-20 10:32:52.576879\n",
      "resetting env. episode 6014, reward total was -15.0. running mean: -16.061271307567285, timestamp: 2022-08-20 10:32:55.452912\n",
      "resetting env. episode 6015, reward total was -19.0. running mean: -16.09065859449161, timestamp: 2022-08-20 10:32:58.929958\n",
      "resetting env. episode 6016, reward total was -14.0. running mean: -16.069752008546693, timestamp: 2022-08-20 10:33:02.465997\n",
      "resetting env. episode 6017, reward total was -16.0. running mean: -16.069054488461227, timestamp: 2022-08-20 10:33:06.066040\n",
      "resetting env. episode 6018, reward total was -8.0. running mean: -15.988363943576614, timestamp: 2022-08-20 10:33:11.635102\n",
      "resetting env. episode 6019, reward total was -16.0. running mean: -15.988480304140849, timestamp: 2022-08-20 10:33:14.598139\n",
      "resetting env. episode 6020, reward total was -17.0. running mean: -15.99859550109944, timestamp: 2022-08-20 10:33:18.004175\n",
      "resetting env. episode 6021, reward total was -18.0. running mean: -16.018609546088445, timestamp: 2022-08-20 10:33:21.391738\n",
      "resetting env. episode 6022, reward total was -18.0. running mean: -16.038423450627562, timestamp: 2022-08-20 10:33:25.750787\n",
      "resetting env. episode 6023, reward total was -19.0. running mean: -16.068039216121285, timestamp: 2022-08-20 10:33:28.211826\n",
      "resetting env. episode 6024, reward total was -17.0. running mean: -16.077358823960072, timestamp: 2022-08-20 10:33:32.384869\n",
      "resetting env. episode 6025, reward total was -18.0. running mean: -16.09658523572047, timestamp: 2022-08-20 10:33:35.417905\n",
      "resetting env. episode 6026, reward total was -18.0. running mean: -16.115619383363267, timestamp: 2022-08-20 10:33:39.033941\n",
      "resetting env. episode 6027, reward total was -18.0. running mean: -16.134463189529633, timestamp: 2022-08-20 10:33:42.691987\n",
      "resetting env. episode 6028, reward total was -15.0. running mean: -16.123118557634335, timestamp: 2022-08-20 10:33:45.806022\n",
      "resetting env. episode 6029, reward total was -18.0. running mean: -16.141887372057994, timestamp: 2022-08-20 10:33:50.430075\n",
      "resetting env. episode 6030, reward total was -17.0. running mean: -16.150468498337414, timestamp: 2022-08-20 10:33:53.595112\n",
      "resetting env. episode 6031, reward total was -10.0. running mean: -16.08896381335404, timestamp: 2022-08-20 10:33:57.876163\n",
      "resetting env. episode 6032, reward total was -19.0. running mean: -16.118074175220503, timestamp: 2022-08-20 10:34:01.367203\n",
      "resetting env. episode 6033, reward total was -18.0. running mean: -16.1368934334683, timestamp: 2022-08-20 10:34:04.595244\n",
      "resetting env. episode 6034, reward total was -20.0. running mean: -16.175524499133616, timestamp: 2022-08-20 10:34:07.983283\n",
      "resetting env. episode 6035, reward total was -11.0. running mean: -16.123769254142278, timestamp: 2022-08-20 10:34:11.534321\n",
      "resetting env. episode 6036, reward total was -17.0. running mean: -16.132531561600857, timestamp: 2022-08-20 10:34:15.484372\n",
      "resetting env. episode 6037, reward total was -16.0. running mean: -16.131206245984846, timestamp: 2022-08-20 10:34:18.125401\n",
      "resetting env. episode 6038, reward total was -11.0. running mean: -16.079894183524996, timestamp: 2022-08-20 10:34:22.504454\n",
      "resetting env. episode 6039, reward total was -15.0. running mean: -16.069095241689745, timestamp: 2022-08-20 10:34:26.813022\n",
      "resetting env. episode 6040, reward total was -15.0. running mean: -16.058404289272847, timestamp: 2022-08-20 10:34:30.749067\n",
      "resetting env. episode 6041, reward total was -11.0. running mean: -16.007820246380117, timestamp: 2022-08-20 10:34:34.802116\n",
      "resetting env. episode 6042, reward total was -10.0. running mean: -15.947742043916316, timestamp: 2022-08-20 10:34:38.973164\n",
      "resetting env. episode 6043, reward total was -15.0. running mean: -15.938264623477153, timestamp: 2022-08-20 10:34:43.094258\n",
      "resetting env. episode 6044, reward total was -16.0. running mean: -15.938881977242382, timestamp: 2022-08-20 10:34:46.404298\n",
      "resetting env. episode 6045, reward total was -20.0. running mean: -15.979493157469957, timestamp: 2022-08-20 10:34:48.979329\n",
      "resetting env. episode 6046, reward total was -13.0. running mean: -15.949698225895258, timestamp: 2022-08-20 10:34:52.405366\n",
      "resetting env. episode 6047, reward total was -10.0. running mean: -15.890201243636305, timestamp: 2022-08-20 10:34:56.730418\n",
      "resetting env. episode 6048, reward total was -14.0. running mean: -15.871299231199943, timestamp: 2022-08-20 10:35:01.195470\n",
      "resetting env. episode 6049, reward total was -15.0. running mean: -15.862586238887944, timestamp: 2022-08-20 10:35:05.012516\n",
      "resetting env. episode 6050, reward total was -15.0. running mean: -15.853960376499066, timestamp: 2022-08-20 10:35:08.475552\n",
      "resetting env. episode 6051, reward total was -19.0. running mean: -15.885420772734074, timestamp: 2022-08-20 10:35:11.611591\n",
      "resetting env. episode 6052, reward total was -19.0. running mean: -15.916566565006733, timestamp: 2022-08-20 10:35:13.983617\n",
      "resetting env. episode 6053, reward total was -18.0. running mean: -15.937400899356664, timestamp: 2022-08-20 10:35:17.528657\n",
      "resetting env. episode 6054, reward total was -16.0. running mean: -15.938026890363098, timestamp: 2022-08-20 10:35:21.268701\n",
      "resetting env. episode 6055, reward total was -14.0. running mean: -15.918646621459468, timestamp: 2022-08-20 10:35:26.224284\n",
      "resetting env. episode 6056, reward total was -15.0. running mean: -15.909460155244874, timestamp: 2022-08-20 10:35:30.256326\n",
      "resetting env. episode 6057, reward total was -20.0. running mean: -15.950365553692425, timestamp: 2022-08-20 10:35:32.718356\n",
      "resetting env. episode 6058, reward total was -17.0. running mean: -15.9608618981555, timestamp: 2022-08-20 10:35:36.837402\n",
      "resetting env. episode 6059, reward total was -13.0. running mean: -15.931253279173946, timestamp: 2022-08-20 10:35:41.109452\n",
      "resetting env. episode 6060, reward total was -19.0. running mean: -15.961940746382206, timestamp: 2022-08-20 10:35:44.671015\n",
      "resetting env. episode 6061, reward total was -16.0. running mean: -15.962321338918384, timestamp: 2022-08-20 10:35:49.175070\n",
      "resetting env. episode 6062, reward total was -15.0. running mean: -15.952698125529201, timestamp: 2022-08-20 10:35:53.248115\n",
      "resetting env. episode 6063, reward total was -10.0. running mean: -15.893171144273909, timestamp: 2022-08-20 10:35:58.645177\n",
      "resetting env. episode 6064, reward total was -13.0. running mean: -15.864239432831171, timestamp: 2022-08-20 10:36:01.885217\n",
      "resetting env. episode 6065, reward total was -16.0. running mean: -15.865597038502859, timestamp: 2022-08-20 10:36:04.859249\n",
      "resetting env. episode 6066, reward total was -19.0. running mean: -15.89694106811783, timestamp: 2022-08-20 10:36:07.388277\n",
      "resetting env. episode 6067, reward total was -17.0. running mean: -15.90797165743665, timestamp: 2022-08-20 10:36:10.734319\n",
      "resetting env. episode 6068, reward total was -18.0. running mean: -15.928891940862284, timestamp: 2022-08-20 10:36:14.041879\n",
      "resetting env. episode 6069, reward total was -18.0. running mean: -15.949603021453662, timestamp: 2022-08-20 10:36:16.243906\n",
      "resetting env. episode 6070, reward total was -16.0. running mean: -15.950106991239124, timestamp: 2022-08-20 10:36:20.374951\n",
      "resetting env. episode 6071, reward total was -15.0. running mean: -15.940605921326734, timestamp: 2022-08-20 10:36:24.423999\n",
      "resetting env. episode 6072, reward total was -18.0. running mean: -15.961199862113466, timestamp: 2022-08-20 10:36:27.487040\n",
      "resetting env. episode 6073, reward total was -20.0. running mean: -16.001587863492333, timestamp: 2022-08-20 10:36:29.728062\n",
      "resetting env. episode 6074, reward total was -10.0. running mean: -15.94157198485741, timestamp: 2022-08-20 10:36:33.948109\n",
      "resetting env. episode 6075, reward total was -17.0. running mean: -15.952156265008835, timestamp: 2022-08-20 10:36:38.725167\n",
      "resetting env. episode 6076, reward total was -16.0. running mean: -15.952634702358747, timestamp: 2022-08-20 10:36:42.688211\n",
      "resetting env. episode 6077, reward total was -15.0. running mean: -15.94310835533516, timestamp: 2022-08-20 10:36:45.877247\n",
      "resetting env. episode 6078, reward total was -18.0. running mean: -15.963677271781807, timestamp: 2022-08-20 10:36:50.321298\n",
      "resetting env. episode 6079, reward total was -18.0. running mean: -15.984040499063989, timestamp: 2022-08-20 10:36:54.026867\n",
      "resetting env. episode 6080, reward total was -18.0. running mean: -16.00420009407335, timestamp: 2022-08-20 10:36:57.751910\n",
      "resetting env. episode 6081, reward total was -15.0. running mean: -15.994158093132617, timestamp: 2022-08-20 10:37:00.397946\n",
      "resetting env. episode 6082, reward total was -13.0. running mean: -15.964216512201292, timestamp: 2022-08-20 10:37:04.706997\n",
      "resetting env. episode 6083, reward total was -13.0. running mean: -15.934574347079279, timestamp: 2022-08-20 10:37:09.378047\n",
      "resetting env. episode 6084, reward total was -9.0. running mean: -15.865228603608486, timestamp: 2022-08-20 10:37:15.605642\n",
      "resetting env. episode 6085, reward total was -18.0. running mean: -15.8865763175724, timestamp: 2022-08-20 10:37:18.780680\n",
      "resetting env. episode 6086, reward total was -13.0. running mean: -15.857710554396677, timestamp: 2022-08-20 10:37:22.432724\n",
      "resetting env. episode 6087, reward total was -15.0. running mean: -15.84913344885271, timestamp: 2022-08-20 10:37:26.800296\n",
      "resetting env. episode 6088, reward total was -14.0. running mean: -15.830642114364183, timestamp: 2022-08-20 10:37:30.604339\n",
      "resetting env. episode 6089, reward total was -17.0. running mean: -15.84233569322054, timestamp: 2022-08-20 10:37:33.715376\n",
      "resetting env. episode 6090, reward total was -14.0. running mean: -15.823912336288336, timestamp: 2022-08-20 10:37:38.595434\n",
      "resetting env. episode 6091, reward total was -19.0. running mean: -15.855673212925451, timestamp: 2022-08-20 10:37:41.009986\n",
      "resetting env. episode 6092, reward total was -9.0. running mean: -15.787116480796197, timestamp: 2022-08-20 10:37:46.104052\n",
      "resetting env. episode 6093, reward total was -18.0. running mean: -15.809245315988234, timestamp: 2022-08-20 10:37:48.670076\n",
      "resetting env. episode 6094, reward total was -16.0. running mean: -15.81115286282835, timestamp: 2022-08-20 10:37:52.228118\n",
      "resetting env. episode 6095, reward total was -19.0. running mean: -15.843041334200066, timestamp: 2022-08-20 10:37:54.463142\n",
      "resetting env. episode 6096, reward total was -10.0. running mean: -15.784610920858064, timestamp: 2022-08-20 10:37:58.453192\n",
      "resetting env. episode 6097, reward total was -16.0. running mean: -15.786764811649483, timestamp: 2022-08-20 10:38:01.571225\n",
      "resetting env. episode 6098, reward total was -8.0. running mean: -15.708897163532988, timestamp: 2022-08-20 10:38:06.660286\n",
      "resetting env. episode 6099, reward total was -15.0. running mean: -15.701808191897658, timestamp: 2022-08-20 10:38:10.408331\n",
      "resetting env. episode 6100, reward total was -16.0. running mean: -15.704790109978681, timestamp: 2022-08-20 10:38:13.549366\n",
      "resetting env. episode 6101, reward total was -13.0. running mean: -15.677742208878895, timestamp: 2022-08-20 10:38:18.257421\n",
      "resetting env. episode 6102, reward total was -16.0. running mean: -15.680964786790106, timestamp: 2022-08-20 10:38:21.776462\n",
      "resetting env. episode 6103, reward total was -18.0. running mean: -15.704155138922205, timestamp: 2022-08-20 10:38:24.795501\n",
      "resetting env. episode 6104, reward total was -7.0. running mean: -15.617113587532984, timestamp: 2022-08-20 10:38:29.746555\n",
      "resetting env. episode 6105, reward total was -17.0. running mean: -15.630942451657655, timestamp: 2022-08-20 10:38:32.834114\n",
      "resetting env. episode 6106, reward total was -6.0. running mean: -15.534633027141078, timestamp: 2022-08-20 10:38:37.548179\n",
      "resetting env. episode 6107, reward total was -19.0. running mean: -15.569286696869666, timestamp: 2022-08-20 10:38:39.948196\n",
      "resetting env. episode 6108, reward total was -17.0. running mean: -15.58359382990097, timestamp: 2022-08-20 10:38:44.240249\n",
      "resetting env. episode 6109, reward total was -14.0. running mean: -15.56775789160196, timestamp: 2022-08-20 10:38:47.380287\n",
      "resetting env. episode 6110, reward total was -15.0. running mean: -15.562080312685941, timestamp: 2022-08-20 10:38:51.108326\n",
      "resetting env. episode 6111, reward total was -18.0. running mean: -15.58645950955908, timestamp: 2022-08-20 10:38:53.720358\n",
      "resetting env. episode 6112, reward total was -16.0. running mean: -15.59059491446349, timestamp: 2022-08-20 10:38:56.851398\n",
      "resetting env. episode 6113, reward total was -19.0. running mean: -15.624688965318853, timestamp: 2022-08-20 10:38:58.785422\n",
      "resetting env. episode 6114, reward total was -18.0. running mean: -15.648442075665665, timestamp: 2022-08-20 10:39:02.443464\n",
      "resetting env. episode 6115, reward total was -19.0. running mean: -15.681957654909008, timestamp: 2022-08-20 10:39:05.954504\n",
      "resetting env. episode 6116, reward total was -12.0. running mean: -15.645138078359917, timestamp: 2022-08-20 10:39:09.325074\n",
      "resetting env. episode 6117, reward total was -18.0. running mean: -15.668686697576318, timestamp: 2022-08-20 10:39:14.225132\n",
      "resetting env. episode 6118, reward total was -15.0. running mean: -15.661999830600555, timestamp: 2022-08-20 10:39:17.100167\n",
      "resetting env. episode 6119, reward total was -9.0. running mean: -15.59537983229455, timestamp: 2022-08-20 10:39:21.801223\n",
      "resetting env. episode 6120, reward total was -19.0. running mean: -15.629426033971603, timestamp: 2022-08-20 10:39:24.319251\n",
      "resetting env. episode 6121, reward total was -14.0. running mean: -15.613131773631887, timestamp: 2022-08-20 10:39:28.479305\n",
      "resetting env. episode 6122, reward total was -18.0. running mean: -15.637000455895567, timestamp: 2022-08-20 10:39:31.846341\n",
      "resetting env. episode 6123, reward total was -6.0. running mean: -15.540630451336611, timestamp: 2022-08-20 10:39:38.425421\n",
      "resetting env. episode 6124, reward total was -17.0. running mean: -15.555224146823244, timestamp: 2022-08-20 10:39:41.383502\n",
      "resetting env. episode 6125, reward total was -12.0. running mean: -15.519671905355011, timestamp: 2022-08-20 10:39:45.978076\n",
      "resetting env. episode 6126, reward total was -19.0. running mean: -15.55447518630146, timestamp: 2022-08-20 10:39:49.081114\n",
      "resetting env. episode 6127, reward total was -20.0. running mean: -15.598930434438444, timestamp: 2022-08-20 10:39:51.786149\n",
      "resetting env. episode 6128, reward total was -14.0. running mean: -15.58294113009406, timestamp: 2022-08-20 10:39:56.476199\n",
      "resetting env. episode 6129, reward total was -17.0. running mean: -15.59711171879312, timestamp: 2022-08-20 10:40:00.264245\n",
      "resetting env. episode 6130, reward total was -17.0. running mean: -15.611140601605188, timestamp: 2022-08-20 10:40:02.943275\n",
      "resetting env. episode 6131, reward total was -15.0. running mean: -15.605029195589136, timestamp: 2022-08-20 10:40:07.416896\n",
      "resetting env. episode 6132, reward total was -15.0. running mean: -15.598978903633245, timestamp: 2022-08-20 10:40:11.389938\n",
      "resetting env. episode 6133, reward total was -19.0. running mean: -15.632989114596912, timestamp: 2022-08-20 10:40:13.986967\n",
      "resetting env. episode 6134, reward total was -15.0. running mean: -15.626659223450943, timestamp: 2022-08-20 10:40:17.738014\n",
      "resetting env. episode 6135, reward total was -17.0. running mean: -15.640392631216434, timestamp: 2022-08-20 10:40:20.751049\n",
      "resetting env. episode 6136, reward total was -17.0. running mean: -15.65398870490427, timestamp: 2022-08-20 10:40:24.507094\n",
      "resetting env. episode 6137, reward total was -17.0. running mean: -15.667448817855227, timestamp: 2022-08-20 10:40:26.955124\n",
      "resetting env. episode 6138, reward total was -13.0. running mean: -15.640774329676676, timestamp: 2022-08-20 10:40:31.229171\n",
      "resetting env. episode 6139, reward total was -16.0. running mean: -15.64436658637991, timestamp: 2022-08-20 10:40:35.890753\n",
      "resetting env. episode 6140, reward total was -17.0. running mean: -15.65792292051611, timestamp: 2022-08-20 10:40:39.355791\n",
      "resetting env. episode 6141, reward total was -20.0. running mean: -15.70134369131095, timestamp: 2022-08-20 10:40:42.301830\n",
      "resetting env. episode 6142, reward total was -12.0. running mean: -15.66433025439784, timestamp: 2022-08-20 10:40:45.988871\n",
      "resetting env. episode 6143, reward total was -18.0. running mean: -15.68768695185386, timestamp: 2022-08-20 10:40:48.488900\n",
      "resetting env. episode 6144, reward total was -13.0. running mean: -15.660810082335322, timestamp: 2022-08-20 10:40:52.056945\n",
      "resetting env. episode 6145, reward total was -17.0. running mean: -15.674201981511969, timestamp: 2022-08-20 10:40:56.237994\n",
      "resetting env. episode 6146, reward total was -18.0. running mean: -15.697459961696849, timestamp: 2022-08-20 10:40:58.487020\n",
      "resetting env. episode 6147, reward total was -17.0. running mean: -15.71048536207988, timestamp: 2022-08-20 10:41:01.579061\n",
      "resetting env. episode 6148, reward total was -16.0. running mean: -15.71338050845908, timestamp: 2022-08-20 10:41:04.671091\n",
      "resetting env. episode 6149, reward total was -18.0. running mean: -15.736246703374489, timestamp: 2022-08-20 10:41:08.478139\n",
      "resetting env. episode 6150, reward total was -13.0. running mean: -15.708884236340744, timestamp: 2022-08-20 10:41:12.326182\n",
      "resetting env. episode 6151, reward total was -12.0. running mean: -15.671795393977336, timestamp: 2022-08-20 10:41:16.045227\n",
      "resetting env. episode 6152, reward total was -10.0. running mean: -15.615077440037561, timestamp: 2022-08-20 10:41:20.885285\n",
      "resetting env. episode 6153, reward total was -20.0. running mean: -15.658926665637185, timestamp: 2022-08-20 10:41:23.643315\n",
      "resetting env. episode 6154, reward total was -10.0. running mean: -15.602337398980813, timestamp: 2022-08-20 10:41:27.799366\n",
      "resetting env. episode 6155, reward total was -16.0. running mean: -15.606314024991004, timestamp: 2022-08-20 10:41:31.621410\n",
      "resetting env. episode 6156, reward total was -19.0. running mean: -15.640250884741093, timestamp: 2022-08-20 10:41:33.856437\n",
      "resetting env. episode 6157, reward total was -18.0. running mean: -15.663848375893682, timestamp: 2022-08-20 10:41:36.805470\n",
      "resetting env. episode 6158, reward total was -18.0. running mean: -15.687209892134746, timestamp: 2022-08-20 10:41:39.844506\n",
      "resetting env. episode 6159, reward total was -19.0. running mean: -15.720337793213398, timestamp: 2022-08-20 10:41:44.384564\n",
      "resetting env. episode 6160, reward total was -16.0. running mean: -15.723134415281264, timestamp: 2022-08-20 10:41:47.525597\n",
      "resetting env. episode 6161, reward total was -15.0. running mean: -15.715903071128452, timestamp: 2022-08-20 10:41:50.418632\n",
      "resetting env. episode 6162, reward total was -10.0. running mean: -15.658744040417167, timestamp: 2022-08-20 10:41:54.615203\n",
      "resetting env. episode 6163, reward total was -17.0. running mean: -15.672156600012995, timestamp: 2022-08-20 10:41:57.516238\n",
      "resetting env. episode 6164, reward total was -19.0. running mean: -15.705435034012865, timestamp: 2022-08-20 10:41:59.702266\n",
      "resetting env. episode 6165, reward total was -15.0. running mean: -15.698380683672736, timestamp: 2022-08-20 10:42:03.229310\n",
      "resetting env. episode 6166, reward total was -18.0. running mean: -15.721396876836009, timestamp: 2022-08-20 10:42:06.687348\n",
      "resetting env. episode 6167, reward total was -15.0. running mean: -15.714182908067649, timestamp: 2022-08-20 10:42:09.015379\n",
      "resetting env. episode 6168, reward total was -19.0. running mean: -15.747041078986971, timestamp: 2022-08-20 10:42:11.566402\n",
      "resetting env. episode 6169, reward total was -18.0. running mean: -15.769570668197101, timestamp: 2022-08-20 10:42:14.014952\n",
      "resetting env. episode 6170, reward total was -15.0. running mean: -15.76187496151513, timestamp: 2022-08-20 10:42:16.663982\n",
      "resetting env. episode 6171, reward total was -16.0. running mean: -15.764256211899978, timestamp: 2022-08-20 10:42:19.067010\n",
      "resetting env. episode 6172, reward total was -19.0. running mean: -15.796613649780978, timestamp: 2022-08-20 10:42:23.413066\n",
      "resetting env. episode 6173, reward total was -19.0. running mean: -15.828647513283167, timestamp: 2022-08-20 10:42:27.786117\n",
      "resetting env. episode 6174, reward total was -19.0. running mean: -15.860361038150335, timestamp: 2022-08-20 10:42:29.390135\n",
      "resetting env. episode 6175, reward total was -19.0. running mean: -15.891757427768832, timestamp: 2022-08-20 10:42:32.286167\n",
      "resetting env. episode 6176, reward total was -10.0. running mean: -15.832839853491143, timestamp: 2022-08-20 10:42:38.322239\n",
      "resetting env. episode 6177, reward total was -17.0. running mean: -15.844511454956232, timestamp: 2022-08-20 10:42:42.023282\n",
      "resetting env. episode 6178, reward total was -15.0. running mean: -15.836066340406669, timestamp: 2022-08-20 10:42:45.765327\n",
      "resetting env. episode 6179, reward total was -12.0. running mean: -15.797705677002602, timestamp: 2022-08-20 10:42:49.499370\n",
      "resetting env. episode 6180, reward total was -14.0. running mean: -15.779728620232577, timestamp: 2022-08-20 10:42:53.983424\n",
      "resetting env. episode 6181, reward total was -16.0. running mean: -15.78193133403025, timestamp: 2022-08-20 10:42:57.575470\n",
      "resetting env. episode 6182, reward total was -13.0. running mean: -15.754112020689949, timestamp: 2022-08-20 10:43:02.393524\n",
      "resetting env. episode 6183, reward total was -17.0. running mean: -15.76657090048305, timestamp: 2022-08-20 10:43:05.144554\n",
      "resetting env. episode 6184, reward total was -13.0. running mean: -15.738905191478219, timestamp: 2022-08-20 10:43:08.810599\n",
      "resetting env. episode 6185, reward total was -17.0. running mean: -15.751516139563437, timestamp: 2022-08-20 10:43:12.826648\n",
      "resetting env. episode 6186, reward total was -17.0. running mean: -15.764000978167802, timestamp: 2022-08-20 10:43:16.763693\n",
      "resetting env. episode 6187, reward total was -16.0. running mean: -15.766360968386124, timestamp: 2022-08-20 10:43:20.691739\n",
      "resetting env. episode 6188, reward total was -12.0. running mean: -15.728697358702261, timestamp: 2022-08-20 10:43:25.094793\n",
      "resetting env. episode 6189, reward total was -16.0. running mean: -15.731410385115238, timestamp: 2022-08-20 10:43:29.498845\n",
      "resetting env. episode 6190, reward total was -15.0. running mean: -15.724096281264085, timestamp: 2022-08-20 10:43:33.277413\n",
      "resetting env. episode 6191, reward total was -13.0. running mean: -15.696855318451446, timestamp: 2022-08-20 10:43:37.513462\n",
      "resetting env. episode 6192, reward total was -19.0. running mean: -15.729886765266931, timestamp: 2022-08-20 10:43:40.257496\n",
      "resetting env. episode 6193, reward total was -16.0. running mean: -15.732587897614263, timestamp: 2022-08-20 10:43:43.460579\n",
      "resetting env. episode 6194, reward total was -11.0. running mean: -15.685262018638118, timestamp: 2022-08-20 10:43:48.351641\n",
      "resetting env. episode 6195, reward total was -18.0. running mean: -15.708409398451737, timestamp: 2022-08-20 10:43:52.923216\n",
      "resetting env. episode 6196, reward total was -11.0. running mean: -15.66132530446722, timestamp: 2022-08-20 10:43:59.329289\n",
      "resetting env. episode 6197, reward total was -9.0. running mean: -15.594712051422547, timestamp: 2022-08-20 10:44:03.991343\n",
      "resetting env. episode 6198, reward total was -21.0. running mean: -15.648764930908323, timestamp: 2022-08-20 10:44:06.521901\n",
      "resetting env. episode 6199, reward total was -17.0. running mean: -15.66227728159924, timestamp: 2022-08-20 10:44:09.716938\n",
      "resetting env. episode 6200, reward total was -16.0. running mean: -15.665654508783247, timestamp: 2022-08-20 10:44:14.660995\n",
      "resetting env. episode 6201, reward total was -16.0. running mean: -15.668997963695414, timestamp: 2022-08-20 10:44:19.324053\n",
      "resetting env. episode 6202, reward total was -15.0. running mean: -15.66230798405846, timestamp: 2022-08-20 10:44:22.743097\n",
      "resetting env. episode 6203, reward total was -18.0. running mean: -15.685684904217874, timestamp: 2022-08-20 10:44:26.222131\n",
      "resetting env. episode 6204, reward total was -16.0. running mean: -15.688828055175696, timestamp: 2022-08-20 10:44:29.343165\n",
      "resetting env. episode 6205, reward total was -14.0. running mean: -15.67193977462394, timestamp: 2022-08-20 10:44:32.891734\n",
      "resetting env. episode 6206, reward total was -14.0. running mean: -15.6552203768777, timestamp: 2022-08-20 10:44:36.755777\n",
      "resetting env. episode 6207, reward total was -19.0. running mean: -15.688668173108923, timestamp: 2022-08-20 10:44:39.563332\n",
      "resetting env. episode 6208, reward total was -14.0. running mean: -15.671781491377834, timestamp: 2022-08-20 10:44:43.938384\n",
      "resetting env. episode 6209, reward total was -14.0. running mean: -15.655063676464056, timestamp: 2022-08-20 10:44:47.603427\n",
      "resetting env. episode 6210, reward total was -17.0. running mean: -15.668513039699416, timestamp: 2022-08-20 10:44:51.493469\n",
      "resetting env. episode 6211, reward total was -13.0. running mean: -15.641827909302423, timestamp: 2022-08-20 10:44:55.223514\n",
      "resetting env. episode 6212, reward total was -10.0. running mean: -15.585409630209398, timestamp: 2022-08-20 10:45:00.407579\n",
      "resetting env. episode 6213, reward total was -16.0. running mean: -15.589555533907303, timestamp: 2022-08-20 10:45:03.986667\n",
      "resetting env. episode 6214, reward total was -13.0. running mean: -15.56365997856823, timestamp: 2022-08-20 10:45:08.082713\n",
      "resetting env. episode 6215, reward total was -16.0. running mean: -15.568023378782549, timestamp: 2022-08-20 10:45:12.110763\n",
      "resetting env. episode 6216, reward total was -15.0. running mean: -15.562343144994724, timestamp: 2022-08-20 10:45:15.199798\n",
      "resetting env. episode 6217, reward total was -15.0. running mean: -15.556719713544776, timestamp: 2022-08-20 10:45:18.485840\n",
      "resetting env. episode 6218, reward total was -16.0. running mean: -15.56115251640933, timestamp: 2022-08-20 10:45:21.120864\n",
      "resetting env. episode 6219, reward total was -14.0. running mean: -15.545540991245236, timestamp: 2022-08-20 10:45:25.050916\n",
      "resetting env. episode 6220, reward total was -8.0. running mean: -15.470085581332784, timestamp: 2022-08-20 10:45:29.177963\n",
      "resetting env. episode 6221, reward total was -13.0. running mean: -15.445384725519457, timestamp: 2022-08-20 10:45:32.530998\n",
      "resetting env. episode 6222, reward total was -18.0. running mean: -15.470930878264262, timestamp: 2022-08-20 10:45:35.708036\n",
      "resetting env. episode 6223, reward total was -15.0. running mean: -15.46622156948162, timestamp: 2022-08-20 10:45:40.151088\n",
      "resetting env. episode 6224, reward total was -16.0. running mean: -15.471559353786803, timestamp: 2022-08-20 10:45:43.981134\n",
      "resetting env. episode 6225, reward total was -15.0. running mean: -15.466843760248935, timestamp: 2022-08-20 10:45:49.224193\n",
      "resetting env. episode 6226, reward total was -16.0. running mean: -15.472175322646445, timestamp: 2022-08-20 10:45:52.632237\n",
      "resetting env. episode 6227, reward total was -15.0. running mean: -15.46745356941998, timestamp: 2022-08-20 10:45:55.490787\n",
      "resetting env. episode 6228, reward total was -14.0. running mean: -15.45277903372578, timestamp: 2022-08-20 10:45:59.879840\n",
      "resetting env. episode 6229, reward total was -18.0. running mean: -15.478251243388522, timestamp: 2022-08-20 10:46:03.395880\n",
      "resetting env. episode 6230, reward total was -17.0. running mean: -15.493468730954637, timestamp: 2022-08-20 10:46:07.535932\n",
      "resetting env. episode 6231, reward total was -19.0. running mean: -15.52853404364509, timestamp: 2022-08-20 10:46:10.940973\n",
      "resetting env. episode 6232, reward total was -14.0. running mean: -15.513248703208639, timestamp: 2022-08-20 10:46:14.446014\n",
      "resetting env. episode 6233, reward total was -9.0. running mean: -15.448116216176553, timestamp: 2022-08-20 10:46:19.513068\n",
      "resetting env. episode 6234, reward total was -20.0. running mean: -15.493635054014787, timestamp: 2022-08-20 10:46:21.583093\n",
      "resetting env. episode 6235, reward total was -15.0. running mean: -15.48869870347464, timestamp: 2022-08-20 10:46:25.915144\n",
      "resetting env. episode 6236, reward total was -12.0. running mean: -15.453811716439892, timestamp: 2022-08-20 10:46:30.132193\n",
      "resetting env. episode 6237, reward total was -20.0. running mean: -15.499273599275492, timestamp: 2022-08-20 10:46:32.970228\n",
      "resetting env. episode 6238, reward total was -20.0. running mean: -15.544280863282737, timestamp: 2022-08-20 10:46:35.109254\n",
      "resetting env. episode 6239, reward total was -12.0. running mean: -15.508838054649908, timestamp: 2022-08-20 10:46:39.480302\n",
      "resetting env. episode 6240, reward total was -17.0. running mean: -15.52374967410341, timestamp: 2022-08-20 10:46:42.289337\n",
      "resetting env. episode 6241, reward total was -11.0. running mean: -15.478512177362376, timestamp: 2022-08-20 10:46:46.866390\n",
      "resetting env. episode 6242, reward total was -8.0. running mean: -15.403727055588751, timestamp: 2022-08-20 10:46:51.606444\n",
      "resetting env. episode 6243, reward total was -18.0. running mean: -15.429689785032863, timestamp: 2022-08-20 10:46:53.737472\n",
      "resetting env. episode 6244, reward total was -11.0. running mean: -15.385392887182533, timestamp: 2022-08-20 10:46:57.845043\n",
      "resetting env. episode 6245, reward total was -19.0. running mean: -15.421538958310707, timestamp: 2022-08-20 10:47:00.699125\n",
      "resetting env. episode 6246, reward total was -18.0. running mean: -15.4473235687276, timestamp: 2022-08-20 10:47:02.993151\n",
      "resetting env. episode 6247, reward total was -15.0. running mean: -15.442850333040324, timestamp: 2022-08-20 10:47:06.885197\n",
      "resetting env. episode 6248, reward total was -15.0. running mean: -15.43842182970992, timestamp: 2022-08-20 10:47:11.004248\n",
      "resetting env. episode 6249, reward total was -19.0. running mean: -15.47403761141282, timestamp: 2022-08-20 10:47:14.595811\n",
      "resetting env. episode 6250, reward total was -18.0. running mean: -15.499297235298691, timestamp: 2022-08-20 10:47:17.135842\n",
      "resetting env. episode 6251, reward total was -15.0. running mean: -15.494304262945704, timestamp: 2022-08-20 10:47:20.655894\n",
      "resetting env. episode 6252, reward total was -5.0. running mean: -15.389361220316248, timestamp: 2022-08-20 10:47:27.206960\n",
      "resetting env. episode 6253, reward total was -21.0. running mean: -15.445467608113086, timestamp: 2022-08-20 10:47:29.281989\n",
      "resetting env. episode 6254, reward total was -15.0. running mean: -15.441012932031954, timestamp: 2022-08-20 10:47:33.020027\n",
      "resetting env. episode 6255, reward total was -18.0. running mean: -15.466602802711634, timestamp: 2022-08-20 10:47:35.621063\n",
      "resetting env. episode 6256, reward total was -13.0. running mean: -15.441936774684518, timestamp: 2022-08-20 10:47:39.324109\n",
      "resetting env. episode 6257, reward total was -8.0. running mean: -15.367517406937672, timestamp: 2022-08-20 10:47:43.781155\n",
      "resetting env. episode 6258, reward total was -16.0. running mean: -15.373842232868295, timestamp: 2022-08-20 10:47:46.677186\n",
      "resetting env. episode 6259, reward total was -15.0. running mean: -15.370103810539613, timestamp: 2022-08-20 10:47:50.396234\n",
      "resetting env. episode 6260, reward total was -17.0. running mean: -15.386402772434217, timestamp: 2022-08-20 10:47:53.602267\n",
      "resetting env. episode 6261, reward total was -18.0. running mean: -15.412538744709874, timestamp: 2022-08-20 10:47:56.697306\n",
      "resetting env. episode 6262, reward total was -16.0. running mean: -15.418413357262775, timestamp: 2022-08-20 10:48:00.463400\n",
      "resetting env. episode 6263, reward total was -19.0. running mean: -15.454229223690147, timestamp: 2022-08-20 10:48:03.889441\n",
      "resetting env. episode 6264, reward total was -17.0. running mean: -15.469686931453245, timestamp: 2022-08-20 10:48:08.064488\n",
      "resetting env. episode 6265, reward total was -17.0. running mean: -15.484990062138712, timestamp: 2022-08-20 10:48:11.090524\n",
      "resetting env. episode 6266, reward total was -15.0. running mean: -15.480140161517324, timestamp: 2022-08-20 10:48:14.864566\n",
      "resetting env. episode 6267, reward total was -17.0. running mean: -15.49533875990215, timestamp: 2022-08-20 10:48:18.123611\n",
      "resetting env. episode 6268, reward total was -19.0. running mean: -15.530385372303128, timestamp: 2022-08-20 10:48:22.150652\n",
      "resetting env. episode 6269, reward total was -13.0. running mean: -15.505081518580097, timestamp: 2022-08-20 10:48:26.105696\n",
      "resetting env. episode 6270, reward total was -19.0. running mean: -15.540030703394295, timestamp: 2022-08-20 10:48:30.278746\n",
      "resetting env. episode 6271, reward total was -15.0. running mean: -15.534630396360352, timestamp: 2022-08-20 10:48:33.930790\n",
      "resetting env. episode 6272, reward total was -15.0. running mean: -15.529284092396749, timestamp: 2022-08-20 10:48:37.700354\n",
      "resetting env. episode 6273, reward total was -8.0. running mean: -15.45399125147278, timestamp: 2022-08-20 10:48:43.070419\n",
      "resetting env. episode 6274, reward total was -15.0. running mean: -15.449451338958053, timestamp: 2022-08-20 10:48:47.558001\n",
      "resetting env. episode 6275, reward total was -13.0. running mean: -15.424956825568472, timestamp: 2022-08-20 10:48:50.861553\n",
      "resetting env. episode 6276, reward total was -15.0. running mean: -15.420707257312788, timestamp: 2022-08-20 10:48:53.830590\n",
      "resetting env. episode 6277, reward total was -15.0. running mean: -15.416500184739661, timestamp: 2022-08-20 10:48:57.382631\n",
      "resetting env. episode 6278, reward total was -12.0. running mean: -15.382335182892264, timestamp: 2022-08-20 10:49:01.952685\n",
      "resetting env. episode 6279, reward total was -11.0. running mean: -15.338511831063341, timestamp: 2022-08-20 10:49:05.700724\n",
      "resetting env. episode 6280, reward total was -15.0. running mean: -15.335126712752707, timestamp: 2022-08-20 10:49:09.736774\n",
      "resetting env. episode 6281, reward total was -12.0. running mean: -15.301775445625179, timestamp: 2022-08-20 10:49:13.760819\n",
      "resetting env. episode 6282, reward total was -16.0. running mean: -15.308757691168926, timestamp: 2022-08-20 10:49:17.683865\n",
      "resetting env. episode 6283, reward total was -18.0. running mean: -15.335670114257237, timestamp: 2022-08-20 10:49:21.281908\n",
      "resetting env. episode 6284, reward total was -16.0. running mean: -15.342313413114665, timestamp: 2022-08-20 10:49:24.977947\n",
      "resetting env. episode 6285, reward total was -9.0. running mean: -15.278890278983518, timestamp: 2022-08-20 10:49:29.840005\n",
      "resetting env. episode 6286, reward total was -16.0. running mean: -15.286101376193683, timestamp: 2022-08-20 10:49:32.727042\n",
      "resetting env. episode 6287, reward total was -13.0. running mean: -15.263240362431747, timestamp: 2022-08-20 10:49:36.974090\n",
      "resetting env. episode 6288, reward total was -14.0. running mean: -15.25060795880743, timestamp: 2022-08-20 10:49:40.380130\n",
      "resetting env. episode 6289, reward total was -12.0. running mean: -15.218101879219356, timestamp: 2022-08-20 10:49:44.516178\n",
      "resetting env. episode 6290, reward total was -7.0. running mean: -15.135920860427163, timestamp: 2022-08-20 10:49:49.830235\n",
      "resetting env. episode 6291, reward total was -12.0. running mean: -15.104561651822891, timestamp: 2022-08-20 10:49:54.729294\n",
      "resetting env. episode 6292, reward total was -18.0. running mean: -15.133516035304662, timestamp: 2022-08-20 10:49:57.662328\n",
      "resetting env. episode 6293, reward total was -17.0. running mean: -15.152180874951616, timestamp: 2022-08-20 10:50:01.659373\n",
      "resetting env. episode 6294, reward total was -17.0. running mean: -15.1706590662021, timestamp: 2022-08-20 10:50:05.210416\n",
      "resetting env. episode 6295, reward total was -19.0. running mean: -15.208952475540078, timestamp: 2022-08-20 10:50:07.380447\n",
      "resetting env. episode 6296, reward total was -17.0. running mean: -15.226862950784678, timestamp: 2022-08-20 10:50:10.514482\n",
      "resetting env. episode 6297, reward total was -14.0. running mean: -15.214594321276833, timestamp: 2022-08-20 10:50:14.424523\n",
      "resetting env. episode 6298, reward total was -10.0. running mean: -15.162448378064063, timestamp: 2022-08-20 10:50:19.303580\n",
      "resetting env. episode 6299, reward total was -17.0. running mean: -15.180823894283423, timestamp: 2022-08-20 10:50:23.657631\n",
      "resetting env. episode 6300, reward total was -18.0. running mean: -15.209015655340588, timestamp: 2022-08-20 10:50:26.385659\n",
      "resetting env. episode 6301, reward total was -18.0. running mean: -15.236925498787182, timestamp: 2022-08-20 10:50:29.364698\n",
      "resetting env. episode 6302, reward total was -15.0. running mean: -15.23455624379931, timestamp: 2022-08-20 10:50:33.409741\n",
      "resetting env. episode 6303, reward total was -18.0. running mean: -15.262210681361315, timestamp: 2022-08-20 10:50:37.077783\n",
      "resetting env. episode 6304, reward total was -17.0. running mean: -15.279588574547702, timestamp: 2022-08-20 10:50:40.051346\n",
      "resetting env. episode 6305, reward total was -19.0. running mean: -15.316792688802225, timestamp: 2022-08-20 10:50:42.501373\n",
      "resetting env. episode 6306, reward total was -12.0. running mean: -15.283624761914202, timestamp: 2022-08-20 10:50:47.146430\n",
      "resetting env. episode 6307, reward total was -17.0. running mean: -15.30078851429506, timestamp: 2022-08-20 10:50:49.718455\n",
      "resetting env. episode 6308, reward total was -13.0. running mean: -15.27778062915211, timestamp: 2022-08-20 10:50:54.633517\n",
      "resetting env. episode 6309, reward total was -20.0. running mean: -15.325002822860588, timestamp: 2022-08-20 10:50:57.545069\n",
      "resetting env. episode 6310, reward total was -14.0. running mean: -15.311752794631982, timestamp: 2022-08-20 10:51:00.286104\n",
      "resetting env. episode 6311, reward total was -9.0. running mean: -15.248635266685662, timestamp: 2022-08-20 10:51:04.972154\n",
      "resetting env. episode 6312, reward total was -17.0. running mean: -15.266148914018805, timestamp: 2022-08-20 10:51:08.741208\n",
      "resetting env. episode 6313, reward total was -16.0. running mean: -15.273487424878617, timestamp: 2022-08-20 10:51:12.372244\n",
      "resetting env. episode 6314, reward total was -14.0. running mean: -15.260752550629832, timestamp: 2022-08-20 10:51:15.997809\n",
      "resetting env. episode 6315, reward total was -16.0. running mean: -15.268145025123534, timestamp: 2022-08-20 10:51:19.384847\n",
      "resetting env. episode 6316, reward total was -7.0. running mean: -15.1854635748723, timestamp: 2022-08-20 10:51:24.025903\n",
      "resetting env. episode 6317, reward total was -16.0. running mean: -15.193608939123576, timestamp: 2022-08-20 10:51:27.134937\n",
      "resetting env. episode 6318, reward total was -16.0. running mean: -15.20167284973234, timestamp: 2022-08-20 10:51:31.110988\n",
      "resetting env. episode 6319, reward total was -17.0. running mean: -15.219656121235015, timestamp: 2022-08-20 10:51:34.823025\n",
      "resetting env. episode 6320, reward total was -10.0. running mean: -15.167459560022666, timestamp: 2022-08-20 10:51:39.017599\n",
      "resetting env. episode 6321, reward total was -13.0. running mean: -15.14578496442244, timestamp: 2022-08-20 10:51:42.559641\n",
      "resetting env. episode 6322, reward total was -10.0. running mean: -15.094327114778215, timestamp: 2022-08-20 10:51:47.343694\n",
      "resetting env. episode 6323, reward total was -13.0. running mean: -15.073383843630433, timestamp: 2022-08-20 10:51:51.395740\n",
      "resetting env. episode 6324, reward total was -19.0. running mean: -15.112650005194128, timestamp: 2022-08-20 10:51:54.900785\n",
      "resetting env. episode 6325, reward total was -17.0. running mean: -15.131523505142187, timestamp: 2022-08-20 10:51:58.841350\n",
      "resetting env. episode 6326, reward total was -17.0. running mean: -15.150208270090765, timestamp: 2022-08-20 10:52:02.730392\n",
      "resetting env. episode 6327, reward total was -16.0. running mean: -15.158706187389857, timestamp: 2022-08-20 10:52:07.100447\n",
      "resetting env. episode 6328, reward total was -17.0. running mean: -15.177119125515958, timestamp: 2022-08-20 10:52:10.206480\n",
      "resetting env. episode 6329, reward total was -11.0. running mean: -15.135347934260798, timestamp: 2022-08-20 10:52:14.941537\n",
      "resetting env. episode 6330, reward total was -13.0. running mean: -15.11399445491819, timestamp: 2022-08-20 10:52:18.587578\n",
      "resetting env. episode 6331, reward total was -15.0. running mean: -15.112854510369008, timestamp: 2022-08-20 10:52:21.675612\n",
      "resetting env. episode 6332, reward total was -15.0. running mean: -15.111725965265318, timestamp: 2022-08-20 10:52:25.227655\n",
      "resetting env. episode 6333, reward total was -15.0. running mean: -15.110608705612666, timestamp: 2022-08-20 10:52:29.027700\n",
      "resetting env. episode 6334, reward total was -14.0. running mean: -15.09950261855654, timestamp: 2022-08-20 10:52:32.579738\n",
      "resetting env. episode 6335, reward total was -18.0. running mean: -15.128507592370974, timestamp: 2022-08-20 10:52:35.799777\n",
      "resetting env. episode 6336, reward total was -17.0. running mean: -15.147222516447265, timestamp: 2022-08-20 10:52:39.599821\n",
      "resetting env. episode 6337, reward total was -13.0. running mean: -15.125750291282793, timestamp: 2022-08-20 10:52:43.686869\n",
      "resetting env. episode 6338, reward total was -13.0. running mean: -15.104492788369965, timestamp: 2022-08-20 10:52:47.020903\n",
      "resetting env. episode 6339, reward total was -15.0. running mean: -15.103447860486266, timestamp: 2022-08-20 10:52:51.561965\n",
      "resetting env. episode 6340, reward total was -12.0. running mean: -15.072413381881402, timestamp: 2022-08-20 10:52:55.389998\n",
      "resetting env. episode 6341, reward total was -17.0. running mean: -15.091689248062588, timestamp: 2022-08-20 10:53:00.587059\n",
      "resetting env. episode 6342, reward total was -19.0. running mean: -15.13077235558196, timestamp: 2022-08-20 10:53:03.518092\n",
      "resetting env. episode 6343, reward total was -20.0. running mean: -15.179464632026141, timestamp: 2022-08-20 10:53:05.666117\n",
      "resetting env. episode 6344, reward total was -16.0. running mean: -15.18766998570588, timestamp: 2022-08-20 10:53:09.453159\n",
      "resetting env. episode 6345, reward total was -16.0. running mean: -15.19579328584882, timestamp: 2022-08-20 10:53:13.494208\n",
      "resetting env. episode 6346, reward total was -11.0. running mean: -15.153835352990331, timestamp: 2022-08-20 10:53:18.071264\n",
      "resetting env. episode 6347, reward total was -18.0. running mean: -15.182296999460428, timestamp: 2022-08-20 10:53:21.019300\n",
      "resetting env. episode 6348, reward total was -13.0. running mean: -15.160474029465824, timestamp: 2022-08-20 10:53:24.972344\n",
      "resetting env. episode 6349, reward total was -6.0. running mean: -15.068869289171166, timestamp: 2022-08-20 10:53:31.371412\n",
      "resetting env. episode 6350, reward total was -12.0. running mean: -15.038180596279453, timestamp: 2022-08-20 10:53:35.982466\n",
      "resetting env. episode 6351, reward total was -18.0. running mean: -15.067798790316658, timestamp: 2022-08-20 10:53:39.760510\n",
      "resetting env. episode 6352, reward total was -17.0. running mean: -15.08712080241349, timestamp: 2022-08-20 10:53:42.773544\n",
      "resetting env. episode 6353, reward total was -19.0. running mean: -15.126249594389355, timestamp: 2022-08-20 10:53:46.494588\n",
      "resetting env. episode 6354, reward total was -14.0. running mean: -15.114987098445463, timestamp: 2022-08-20 10:53:51.378646\n",
      "resetting env. episode 6355, reward total was -17.0. running mean: -15.133837227461008, timestamp: 2022-08-20 10:53:54.978218\n",
      "resetting env. episode 6356, reward total was -19.0. running mean: -15.172498855186397, timestamp: 2022-08-20 10:53:57.973251\n",
      "resetting env. episode 6357, reward total was -19.0. running mean: -15.210773866634533, timestamp: 2022-08-20 10:54:01.174287\n",
      "resetting env. episode 6358, reward total was -13.0. running mean: -15.188666127968188, timestamp: 2022-08-20 10:54:05.029331\n",
      "resetting env. episode 6359, reward total was -9.0. running mean: -15.126779466688506, timestamp: 2022-08-20 10:54:10.197390\n",
      "resetting env. episode 6360, reward total was -17.0. running mean: -15.14551167202162, timestamp: 2022-08-20 10:54:14.231435\n",
      "resetting env. episode 6361, reward total was -5.0. running mean: -15.044056555301404, timestamp: 2022-08-20 10:54:19.109490\n",
      "resetting env. episode 6362, reward total was -15.0. running mean: -15.04361598974839, timestamp: 2022-08-20 10:54:22.363530\n",
      "resetting env. episode 6363, reward total was -19.0. running mean: -15.083179829850906, timestamp: 2022-08-20 10:54:25.363564\n",
      "resetting env. episode 6364, reward total was -13.0. running mean: -15.062348031552398, timestamp: 2022-08-20 10:54:29.120607\n",
      "resetting env. episode 6365, reward total was -17.0. running mean: -15.081724551236874, timestamp: 2022-08-20 10:54:32.322644\n",
      "resetting env. episode 6366, reward total was -17.0. running mean: -15.100907305724505, timestamp: 2022-08-20 10:54:35.935210\n",
      "resetting env. episode 6367, reward total was -11.0. running mean: -15.059898232667258, timestamp: 2022-08-20 10:54:40.437259\n",
      "resetting env. episode 6368, reward total was -19.0. running mean: -15.099299250340586, timestamp: 2022-08-20 10:54:44.191304\n",
      "resetting env. episode 6369, reward total was -20.0. running mean: -15.148306257837179, timestamp: 2022-08-20 10:54:47.834348\n",
      "resetting env. episode 6370, reward total was -15.0. running mean: -15.146823195258808, timestamp: 2022-08-20 10:54:52.021921\n",
      "resetting env. episode 6371, reward total was -17.0. running mean: -15.16535496330622, timestamp: 2022-08-20 10:54:55.803966\n",
      "resetting env. episode 6372, reward total was -19.0. running mean: -15.203701413673157, timestamp: 2022-08-20 10:54:59.797013\n",
      "resetting env. episode 6373, reward total was -17.0. running mean: -15.221664399536426, timestamp: 2022-08-20 10:55:03.517054\n",
      "resetting env. episode 6374, reward total was -19.0. running mean: -15.25944775554106, timestamp: 2022-08-20 10:55:07.163098\n",
      "resetting env. episode 6375, reward total was -18.0. running mean: -15.28685327798565, timestamp: 2022-08-20 10:55:10.610137\n",
      "resetting env. episode 6376, reward total was -19.0. running mean: -15.323984745205792, timestamp: 2022-08-20 10:55:14.250180\n",
      "resetting env. episode 6377, reward total was -18.0. running mean: -15.350744897753733, timestamp: 2022-08-20 10:55:18.056222\n",
      "resetting env. episode 6378, reward total was -19.0. running mean: -15.387237448776196, timestamp: 2022-08-20 10:55:21.951273\n",
      "resetting env. episode 6379, reward total was -18.0. running mean: -15.413365074288434, timestamp: 2022-08-20 10:55:25.360308\n",
      "resetting env. episode 6380, reward total was -13.0. running mean: -15.38923142354555, timestamp: 2022-08-20 10:55:29.690357\n",
      "resetting env. episode 6381, reward total was -14.0. running mean: -15.375339109310094, timestamp: 2022-08-20 10:55:34.643425\n",
      "resetting env. episode 6382, reward total was -15.0. running mean: -15.371585718216993, timestamp: 2022-08-20 10:55:38.551463\n",
      "resetting env. episode 6383, reward total was -18.0. running mean: -15.397869861034822, timestamp: 2022-08-20 10:55:41.777498\n",
      "resetting env. episode 6384, reward total was -16.0. running mean: -15.403891162424474, timestamp: 2022-08-20 10:55:45.675545\n",
      "resetting env. episode 6385, reward total was -16.0. running mean: -15.40985225080023, timestamp: 2022-08-20 10:55:49.621592\n",
      "resetting env. episode 6386, reward total was -18.0. running mean: -15.435753728292227, timestamp: 2022-08-20 10:55:53.485153\n",
      "resetting env. episode 6387, reward total was -19.0. running mean: -15.471396191009303, timestamp: 2022-08-20 10:55:57.043194\n",
      "resetting env. episode 6388, reward total was -16.0. running mean: -15.47668222909921, timestamp: 2022-08-20 10:56:00.281233\n",
      "resetting env. episode 6389, reward total was -15.0. running mean: -15.471915406808217, timestamp: 2022-08-20 10:56:03.949279\n",
      "resetting env. episode 6390, reward total was -16.0. running mean: -15.477196252740134, timestamp: 2022-08-20 10:56:07.294314\n",
      "resetting env. episode 6391, reward total was -16.0. running mean: -15.482424290212732, timestamp: 2022-08-20 10:56:10.162352\n",
      "resetting env. episode 6392, reward total was -13.0. running mean: -15.457600047310605, timestamp: 2022-08-20 10:56:14.878404\n",
      "resetting env. episode 6393, reward total was -14.0. running mean: -15.443024046837499, timestamp: 2022-08-20 10:56:18.675451\n",
      "resetting env. episode 6394, reward total was -13.0. running mean: -15.418593806369124, timestamp: 2022-08-20 10:56:23.361034\n",
      "resetting env. episode 6395, reward total was -16.0. running mean: -15.424407868305433, timestamp: 2022-08-20 10:56:27.914081\n",
      "resetting env. episode 6396, reward total was -10.0. running mean: -15.370163789622378, timestamp: 2022-08-20 10:56:32.974140\n",
      "resetting env. episode 6397, reward total was -12.0. running mean: -15.336462151726153, timestamp: 2022-08-20 10:56:38.096201\n",
      "resetting env. episode 6398, reward total was -16.0. running mean: -15.34309753020889, timestamp: 2022-08-20 10:56:41.507239\n",
      "resetting env. episode 6399, reward total was -19.0. running mean: -15.379666554906802, timestamp: 2022-08-20 10:56:44.603281\n",
      "resetting env. episode 6400, reward total was -19.0. running mean: -15.415869889357733, timestamp: 2022-08-20 10:56:48.283321\n",
      "resetting env. episode 6401, reward total was -15.0. running mean: -15.411711190464157, timestamp: 2022-08-20 10:56:52.368369\n",
      "resetting env. episode 6402, reward total was -11.0. running mean: -15.367594078559515, timestamp: 2022-08-20 10:56:57.106422\n",
      "resetting env. episode 6403, reward total was -12.0. running mean: -15.333918137773919, timestamp: 2022-08-20 10:57:01.627479\n",
      "resetting env. episode 6404, reward total was -11.0. running mean: -15.29057895639618, timestamp: 2022-08-20 10:57:05.443045\n",
      "resetting env. episode 6405, reward total was -15.0. running mean: -15.287673166832219, timestamp: 2022-08-20 10:57:09.655093\n",
      "resetting env. episode 6406, reward total was -14.0. running mean: -15.274796435163898, timestamp: 2022-08-20 10:57:13.976145\n",
      "resetting env. episode 6407, reward total was -14.0. running mean: -15.26204847081226, timestamp: 2022-08-20 10:57:17.470187\n",
      "resetting env. episode 6408, reward total was -17.0. running mean: -15.279427986104137, timestamp: 2022-08-20 10:57:21.149225\n",
      "resetting env. episode 6409, reward total was -9.0. running mean: -15.216633706243096, timestamp: 2022-08-20 10:57:25.699279\n",
      "resetting env. episode 6410, reward total was -18.0. running mean: -15.244467369180665, timestamp: 2022-08-20 10:57:29.270323\n",
      "resetting env. episode 6411, reward total was -19.0. running mean: -15.282022695488857, timestamp: 2022-08-20 10:57:32.845364\n",
      "resetting env. episode 6412, reward total was -19.0. running mean: -15.319202468533968, timestamp: 2022-08-20 10:57:35.811398\n",
      "resetting env. episode 6413, reward total was -17.0. running mean: -15.336010443848627, timestamp: 2022-08-20 10:57:38.557433\n",
      "resetting env. episode 6414, reward total was -18.0. running mean: -15.362650339410141, timestamp: 2022-08-20 10:57:41.292462\n",
      "resetting env. episode 6415, reward total was -14.0. running mean: -15.349023836016041, timestamp: 2022-08-20 10:57:45.150027\n",
      "resetting env. episode 6416, reward total was -15.0. running mean: -15.345533597655882, timestamp: 2022-08-20 10:57:49.154072\n",
      "resetting env. episode 6417, reward total was -13.0. running mean: -15.322078261679323, timestamp: 2022-08-20 10:57:54.108129\n",
      "resetting env. episode 6418, reward total was -19.0. running mean: -15.358857479062529, timestamp: 2022-08-20 10:57:57.736175\n",
      "resetting env. episode 6419, reward total was -12.0. running mean: -15.325268904271903, timestamp: 2022-08-20 10:58:01.709220\n",
      "resetting env. episode 6420, reward total was -20.0. running mean: -15.372016215229182, timestamp: 2022-08-20 10:58:05.242262\n",
      "resetting env. episode 6421, reward total was -17.0. running mean: -15.38829605307689, timestamp: 2022-08-20 10:58:08.430298\n",
      "resetting env. episode 6422, reward total was -19.0. running mean: -15.424413092546121, timestamp: 2022-08-20 10:58:11.415334\n",
      "resetting env. episode 6423, reward total was -15.0. running mean: -15.42016896162066, timestamp: 2022-08-20 10:58:15.278378\n",
      "resetting env. episode 6424, reward total was -16.0. running mean: -15.425967272004455, timestamp: 2022-08-20 10:58:18.402416\n",
      "resetting env. episode 6425, reward total was -19.0. running mean: -15.46170759928441, timestamp: 2022-08-20 10:58:22.002456\n",
      "resetting env. episode 6426, reward total was -14.0. running mean: -15.447090523291566, timestamp: 2022-08-20 10:58:25.570542\n",
      "resetting env. episode 6427, reward total was -20.0. running mean: -15.492619618058649, timestamp: 2022-08-20 10:58:28.596580\n",
      "resetting env. episode 6428, reward total was -15.0. running mean: -15.487693421878063, timestamp: 2022-08-20 10:58:32.415623\n",
      "resetting env. episode 6429, reward total was -15.0. running mean: -15.482816487659283, timestamp: 2022-08-20 10:58:35.933673\n",
      "resetting env. episode 6430, reward total was -15.0. running mean: -15.477988322782691, timestamp: 2022-08-20 10:58:40.077233\n",
      "resetting env. episode 6431, reward total was -20.0. running mean: -15.523208439554864, timestamp: 2022-08-20 10:58:42.670263\n",
      "resetting env. episode 6432, reward total was -13.0. running mean: -15.497976355159317, timestamp: 2022-08-20 10:58:46.924314\n",
      "resetting env. episode 6433, reward total was -15.0. running mean: -15.492996591607724, timestamp: 2022-08-20 10:58:50.805357\n",
      "resetting env. episode 6434, reward total was -19.0. running mean: -15.528066625691647, timestamp: 2022-08-20 10:58:53.729392\n",
      "resetting env. episode 6435, reward total was -16.0. running mean: -15.532785959434731, timestamp: 2022-08-20 10:58:57.176518\n",
      "resetting env. episode 6436, reward total was -12.0. running mean: -15.497458099840383, timestamp: 2022-08-20 10:59:01.328569\n",
      "resetting env. episode 6437, reward total was -18.0. running mean: -15.522483518841979, timestamp: 2022-08-20 10:59:04.604605\n",
      "resetting env. episode 6438, reward total was -17.0. running mean: -15.537258683653558, timestamp: 2022-08-20 10:59:07.633642\n",
      "resetting env. episode 6439, reward total was -12.0. running mean: -15.501886096817021, timestamp: 2022-08-20 10:59:12.466698\n",
      "resetting env. episode 6440, reward total was -13.0. running mean: -15.476867235848852, timestamp: 2022-08-20 10:59:16.997752\n",
      "resetting env. episode 6441, reward total was -21.0. running mean: -15.532098563490365, timestamp: 2022-08-20 10:59:19.803785\n",
      "resetting env. episode 6442, reward total was -13.0. running mean: -15.506777577855463, timestamp: 2022-08-20 10:59:23.783832\n",
      "resetting env. episode 6443, reward total was -13.0. running mean: -15.481709802076908, timestamp: 2022-08-20 10:59:27.554875\n",
      "resetting env. episode 6444, reward total was -17.0. running mean: -15.496892704056139, timestamp: 2022-08-20 10:59:31.265920\n",
      "resetting env. episode 6445, reward total was -14.0. running mean: -15.481923777015577, timestamp: 2022-08-20 10:59:34.941959\n",
      "resetting env. episode 6446, reward total was -9.0. running mean: -15.417104539245422, timestamp: 2022-08-20 10:59:39.481013\n",
      "resetting env. episode 6447, reward total was -17.0. running mean: -15.432933493852968, timestamp: 2022-08-20 10:59:43.295058\n",
      "resetting env. episode 6448, reward total was -12.0. running mean: -15.398604158914438, timestamp: 2022-08-20 10:59:48.392165\n",
      "resetting env. episode 6449, reward total was -14.0. running mean: -15.384618117325294, timestamp: 2022-08-20 10:59:53.275749\n",
      "resetting env. episode 6450, reward total was -17.0. running mean: -15.40077193615204, timestamp: 2022-08-20 10:59:56.314303\n",
      "resetting env. episode 6451, reward total was -6.0. running mean: -15.306764216790521, timestamp: 2022-08-20 11:00:01.341364\n",
      "resetting env. episode 6452, reward total was -12.0. running mean: -15.273696574622615, timestamp: 2022-08-20 11:00:06.223421\n",
      "resetting env. episode 6453, reward total was -13.0. running mean: -15.25095960887639, timestamp: 2022-08-20 11:00:10.213469\n",
      "resetting env. episode 6454, reward total was -15.0. running mean: -15.248450012787625, timestamp: 2022-08-20 11:00:14.143515\n",
      "resetting env. episode 6455, reward total was -12.0. running mean: -15.215965512659748, timestamp: 2022-08-20 11:00:19.152570\n",
      "resetting env. episode 6456, reward total was -6.0. running mean: -15.123805857533151, timestamp: 2022-08-20 11:00:25.326179\n",
      "resetting env. episode 6457, reward total was -13.0. running mean: -15.10256779895782, timestamp: 2022-08-20 11:00:29.239215\n",
      "resetting env. episode 6458, reward total was -16.0. running mean: -15.111542120968242, timestamp: 2022-08-20 11:00:32.468253\n",
      "resetting env. episode 6459, reward total was -14.0. running mean: -15.10042669975856, timestamp: 2022-08-20 11:00:36.724303\n",
      "resetting env. episode 6460, reward total was -16.0. running mean: -15.109422432760974, timestamp: 2022-08-20 11:00:40.613351\n",
      "resetting env. episode 6461, reward total was -18.0. running mean: -15.138328208433364, timestamp: 2022-08-20 11:00:43.993390\n",
      "resetting env. episode 6462, reward total was -20.0. running mean: -15.18694492634903, timestamp: 2022-08-20 11:00:47.719432\n",
      "resetting env. episode 6463, reward total was -17.0. running mean: -15.20507547708554, timestamp: 2022-08-20 11:00:51.591999\n",
      "resetting env. episode 6464, reward total was -13.0. running mean: -15.183024722314686, timestamp: 2022-08-20 11:00:56.161049\n",
      "resetting env. episode 6465, reward total was -17.0. running mean: -15.201194475091539, timestamp: 2022-08-20 11:00:58.856089\n",
      "resetting env. episode 6466, reward total was -15.0. running mean: -15.199182530340623, timestamp: 2022-08-20 11:01:03.541145\n",
      "resetting env. episode 6467, reward total was -12.0. running mean: -15.167190705037216, timestamp: 2022-08-20 11:01:06.817174\n",
      "resetting env. episode 6468, reward total was -14.0. running mean: -15.155518797986844, timestamp: 2022-08-20 11:01:10.494221\n",
      "resetting env. episode 6469, reward total was -16.0. running mean: -15.163963610006975, timestamp: 2022-08-20 11:01:13.537253\n",
      "resetting env. episode 6470, reward total was -12.0. running mean: -15.132323973906905, timestamp: 2022-08-20 11:01:18.713312\n",
      "resetting env. episode 6471, reward total was -11.0. running mean: -15.091000734167835, timestamp: 2022-08-20 11:01:23.643898\n",
      "resetting env. episode 6472, reward total was -10.0. running mean: -15.040090726826156, timestamp: 2022-08-20 11:01:28.403958\n",
      "resetting env. episode 6473, reward total was -17.0. running mean: -15.059689819557894, timestamp: 2022-08-20 11:01:31.789995\n",
      "resetting env. episode 6474, reward total was -17.0. running mean: -15.079092921362315, timestamp: 2022-08-20 11:01:36.579052\n",
      "resetting env. episode 6475, reward total was -14.0. running mean: -15.068301992148692, timestamp: 2022-08-20 11:01:40.995103\n",
      "resetting env. episode 6476, reward total was -15.0. running mean: -15.067618972227205, timestamp: 2022-08-20 11:01:43.874661\n",
      "resetting env. episode 6477, reward total was -15.0. running mean: -15.066942782504933, timestamp: 2022-08-20 11:01:47.344698\n",
      "resetting env. episode 6478, reward total was -16.0. running mean: -15.076273354679884, timestamp: 2022-08-20 11:01:52.023751\n",
      "resetting env. episode 6479, reward total was -18.0. running mean: -15.105510621133085, timestamp: 2022-08-20 11:01:55.802798\n",
      "resetting env. episode 6480, reward total was -16.0. running mean: -15.114455514921755, timestamp: 2022-08-20 11:02:00.125372\n",
      "resetting env. episode 6481, reward total was -10.0. running mean: -15.063310959772537, timestamp: 2022-08-20 11:02:04.417423\n",
      "resetting env. episode 6482, reward total was -18.0. running mean: -15.09267785017481, timestamp: 2022-08-20 11:02:07.647468\n",
      "resetting env. episode 6483, reward total was -15.0. running mean: -15.091751071673063, timestamp: 2022-08-20 11:02:12.362516\n",
      "resetting env. episode 6484, reward total was -14.0. running mean: -15.080833560956332, timestamp: 2022-08-20 11:02:16.836098\n",
      "resetting env. episode 6485, reward total was -16.0. running mean: -15.09002522534677, timestamp: 2022-08-20 11:02:21.388153\n",
      "resetting env. episode 6486, reward total was -16.0. running mean: -15.099124973093302, timestamp: 2022-08-20 11:02:25.806251\n",
      "resetting env. episode 6487, reward total was -19.0. running mean: -15.138133723362367, timestamp: 2022-08-20 11:02:30.099303\n",
      "resetting env. episode 6488, reward total was -16.0. running mean: -15.146752386128744, timestamp: 2022-08-20 11:02:34.253350\n",
      "resetting env. episode 6489, reward total was -18.0. running mean: -15.175284862267457, timestamp: 2022-08-20 11:02:36.819380\n",
      "resetting env. episode 6490, reward total was -20.0. running mean: -15.223532013644782, timestamp: 2022-08-20 11:02:39.199930\n",
      "resetting env. episode 6491, reward total was -13.0. running mean: -15.201296693508334, timestamp: 2022-08-20 11:02:44.210987\n",
      "resetting env. episode 6492, reward total was -18.0. running mean: -15.22928372657325, timestamp: 2022-08-20 11:02:46.681019\n",
      "resetting env. episode 6493, reward total was -12.0. running mean: -15.196990889307516, timestamp: 2022-08-20 11:02:51.336069\n",
      "resetting env. episode 6494, reward total was -11.0. running mean: -15.15502098041444, timestamp: 2022-08-20 11:02:55.863172\n",
      "resetting env. episode 6495, reward total was -15.0. running mean: -15.153470770610296, timestamp: 2022-08-20 11:02:59.690223\n",
      "resetting env. episode 6496, reward total was -15.0. running mean: -15.151936062904193, timestamp: 2022-08-20 11:03:03.863266\n",
      "resetting env. episode 6497, reward total was -13.0. running mean: -15.130416702275152, timestamp: 2022-08-20 11:03:07.375307\n",
      "resetting env. episode 6498, reward total was -15.0. running mean: -15.129112535252402, timestamp: 2022-08-20 11:03:12.108359\n",
      "resetting env. episode 6499, reward total was -13.0. running mean: -15.107821409899879, timestamp: 2022-08-20 11:03:16.359409\n",
      "resetting env. episode 6500, reward total was -20.0. running mean: -15.15674319580088, timestamp: 2022-08-20 11:03:19.812448\n",
      "resetting env. episode 6501, reward total was -17.0. running mean: -15.175175763842871, timestamp: 2022-08-20 11:03:23.778017\n",
      "resetting env. episode 6502, reward total was -12.0. running mean: -15.143424006204441, timestamp: 2022-08-20 11:03:28.907076\n",
      "resetting env. episode 6503, reward total was -14.0. running mean: -15.131989766142397, timestamp: 2022-08-20 11:03:31.669108\n",
      "resetting env. episode 6504, reward total was -17.0. running mean: -15.150669868480973, timestamp: 2022-08-20 11:03:34.574666\n",
      "resetting env. episode 6505, reward total was -9.0. running mean: -15.089163169796164, timestamp: 2022-08-20 11:03:38.987719\n",
      "resetting env. episode 6506, reward total was -16.0. running mean: -15.098271538098203, timestamp: 2022-08-20 11:03:42.549757\n",
      "resetting env. episode 6507, reward total was -13.0. running mean: -15.077288822717222, timestamp: 2022-08-20 11:03:47.622816\n",
      "resetting env. episode 6508, reward total was -19.0. running mean: -15.11651593449005, timestamp: 2022-08-20 11:03:52.016866\n",
      "resetting env. episode 6509, reward total was -14.0. running mean: -15.10535077514515, timestamp: 2022-08-20 11:03:55.652908\n",
      "resetting env. episode 6510, reward total was -15.0. running mean: -15.104297267393699, timestamp: 2022-08-20 11:03:58.777947\n",
      "resetting env. episode 6511, reward total was -12.0. running mean: -15.073254294719762, timestamp: 2022-08-20 11:04:03.733005\n",
      "resetting env. episode 6512, reward total was -10.0. running mean: -15.022521751772564, timestamp: 2022-08-20 11:04:08.580059\n",
      "resetting env. episode 6513, reward total was -13.0. running mean: -15.002296534254839, timestamp: 2022-08-20 11:04:12.267108\n",
      "resetting env. episode 6514, reward total was -11.0. running mean: -14.96227356891229, timestamp: 2022-08-20 11:04:17.480694\n",
      "resetting env. episode 6515, reward total was -7.0. running mean: -14.882650833223167, timestamp: 2022-08-20 11:04:23.055763\n",
      "resetting env. episode 6516, reward total was -17.0. running mean: -14.903824324890936, timestamp: 2022-08-20 11:04:27.028328\n",
      "resetting env. episode 6517, reward total was -15.0. running mean: -14.904786081642026, timestamp: 2022-08-20 11:04:30.682370\n",
      "resetting env. episode 6518, reward total was -14.0. running mean: -14.895738220825606, timestamp: 2022-08-20 11:04:34.999421\n",
      "resetting env. episode 6519, reward total was -18.0. running mean: -14.92678083861735, timestamp: 2022-08-20 11:04:38.651466\n",
      "resetting env. episode 6520, reward total was -12.0. running mean: -14.897513030231176, timestamp: 2022-08-20 11:04:43.513517\n",
      "resetting env. episode 6521, reward total was -17.0. running mean: -14.918537899928864, timestamp: 2022-08-20 11:04:45.808547\n",
      "resetting env. episode 6522, reward total was -15.0. running mean: -14.919352520929577, timestamp: 2022-08-20 11:04:49.333585\n",
      "resetting env. episode 6523, reward total was -15.0. running mean: -14.920158995720282, timestamp: 2022-08-20 11:04:52.753627\n",
      "resetting env. episode 6524, reward total was -15.0. running mean: -14.92095740576308, timestamp: 2022-08-20 11:04:56.971680\n",
      "resetting env. episode 6525, reward total was -17.0. running mean: -14.941747831705449, timestamp: 2022-08-20 11:05:01.067725\n",
      "resetting env. episode 6526, reward total was -12.0. running mean: -14.912330353388393, timestamp: 2022-08-20 11:05:05.420771\n",
      "resetting env. episode 6527, reward total was -14.0. running mean: -14.90320704985451, timestamp: 2022-08-20 11:05:09.836824\n",
      "resetting env. episode 6528, reward total was -15.0. running mean: -14.904174979355965, timestamp: 2022-08-20 11:05:14.757881\n",
      "resetting env. episode 6529, reward total was -14.0. running mean: -14.895133229562406, timestamp: 2022-08-20 11:05:20.053943\n",
      "resetting env. episode 6530, reward total was -15.0. running mean: -14.896181897266782, timestamp: 2022-08-20 11:05:24.332994\n",
      "resetting env. episode 6531, reward total was -17.0. running mean: -14.917220078294115, timestamp: 2022-08-20 11:05:27.008023\n",
      "resetting env. episode 6532, reward total was -14.0. running mean: -14.908047877511175, timestamp: 2022-08-20 11:05:31.981082\n",
      "resetting env. episode 6533, reward total was -16.0. running mean: -14.918967398736063, timestamp: 2022-08-20 11:05:35.795126\n",
      "resetting env. episode 6534, reward total was -16.0. running mean: -14.929777724748703, timestamp: 2022-08-20 11:05:39.212164\n",
      "resetting env. episode 6535, reward total was -14.0. running mean: -14.920479947501217, timestamp: 2022-08-20 11:05:43.568214\n",
      "resetting env. episode 6536, reward total was -16.0. running mean: -14.931275148026206, timestamp: 2022-08-20 11:05:46.790252\n",
      "resetting env. episode 6537, reward total was -18.0. running mean: -14.961962396545943, timestamp: 2022-08-20 11:05:49.662288\n",
      "resetting env. episode 6538, reward total was -18.0. running mean: -14.992342772580482, timestamp: 2022-08-20 11:05:53.258325\n",
      "resetting env. episode 6539, reward total was -19.0. running mean: -15.032419344854677, timestamp: 2022-08-20 11:05:56.509365\n",
      "resetting env. episode 6540, reward total was -13.0. running mean: -15.01209515140613, timestamp: 2022-08-20 11:06:00.659413\n",
      "resetting env. episode 6541, reward total was -16.0. running mean: -15.02197419989207, timestamp: 2022-08-20 11:06:03.290445\n",
      "resetting env. episode 6542, reward total was -12.0. running mean: -14.991754457893148, timestamp: 2022-08-20 11:06:07.622494\n",
      "resetting env. episode 6543, reward total was -14.0. running mean: -14.981836913314217, timestamp: 2022-08-20 11:06:12.108545\n",
      "resetting env. episode 6544, reward total was -17.0. running mean: -15.002018544181075, timestamp: 2022-08-20 11:06:16.180594\n",
      "resetting env. episode 6545, reward total was -14.0. running mean: -14.991998358739265, timestamp: 2022-08-20 11:06:19.111630\n",
      "resetting env. episode 6546, reward total was -19.0. running mean: -15.03207837515187, timestamp: 2022-08-20 11:06:21.515657\n",
      "resetting env. episode 6547, reward total was -14.0. running mean: -15.021757591400352, timestamp: 2022-08-20 11:06:25.713704\n",
      "resetting env. episode 6548, reward total was -19.0. running mean: -15.061540015486347, timestamp: 2022-08-20 11:06:29.211747\n",
      "resetting env. episode 6549, reward total was -14.0. running mean: -15.050924615331484, timestamp: 2022-08-20 11:06:32.727308\n",
      "resetting env. episode 6550, reward total was -17.0. running mean: -15.07041536917817, timestamp: 2022-08-20 11:06:37.180361\n",
      "resetting env. episode 6551, reward total was -13.0. running mean: -15.049711215486388, timestamp: 2022-08-20 11:06:41.864416\n",
      "resetting env. episode 6552, reward total was -14.0. running mean: -15.039214103331524, timestamp: 2022-08-20 11:06:45.019496\n",
      "resetting env. episode 6553, reward total was -14.0. running mean: -15.02882196229821, timestamp: 2022-08-20 11:06:48.908540\n",
      "resetting env. episode 6554, reward total was -14.0. running mean: -15.018533742675228, timestamp: 2022-08-20 11:06:53.849121\n",
      "resetting env. episode 6555, reward total was -11.0. running mean: -14.978348405248475, timestamp: 2022-08-20 11:06:58.938181\n",
      "resetting env. episode 6556, reward total was -15.0. running mean: -14.978564921195991, timestamp: 2022-08-20 11:07:03.009752\n",
      "resetting env. episode 6557, reward total was -13.0. running mean: -14.958779271984032, timestamp: 2022-08-20 11:07:07.768807\n",
      "resetting env. episode 6558, reward total was -12.0. running mean: -14.92919147926419, timestamp: 2022-08-20 11:07:13.596875\n",
      "resetting env. episode 6559, reward total was -17.0. running mean: -14.949899564471549, timestamp: 2022-08-20 11:07:18.216927\n",
      "resetting env. episode 6560, reward total was -17.0. running mean: -14.970400568826832, timestamp: 2022-08-20 11:07:22.235973\n",
      "resetting env. episode 6561, reward total was -10.0. running mean: -14.920696563138563, timestamp: 2022-08-20 11:07:26.012015\n",
      "resetting env. episode 6562, reward total was -18.0. running mean: -14.951489597507177, timestamp: 2022-08-20 11:07:29.088054\n",
      "resetting env. episode 6563, reward total was -18.0. running mean: -14.981974701532105, timestamp: 2022-08-20 11:07:33.341101\n",
      "resetting env. episode 6564, reward total was -10.0. running mean: -14.932154954516783, timestamp: 2022-08-20 11:07:37.323146\n",
      "resetting env. episode 6565, reward total was -15.0. running mean: -14.932833404971616, timestamp: 2022-08-20 11:07:41.718198\n",
      "resetting env. episode 6566, reward total was -19.0. running mean: -14.973505070921899, timestamp: 2022-08-20 11:07:44.412226\n",
      "resetting env. episode 6567, reward total was -15.0. running mean: -14.97377002021268, timestamp: 2022-08-20 11:07:48.414277\n",
      "resetting env. episode 6568, reward total was -15.0. running mean: -14.974032320010553, timestamp: 2022-08-20 11:07:52.566324\n",
      "resetting env. episode 6569, reward total was -17.0. running mean: -14.994291996810446, timestamp: 2022-08-20 11:07:55.661358\n",
      "resetting env. episode 6570, reward total was -16.0. running mean: -15.004349076842342, timestamp: 2022-08-20 11:07:59.498402\n",
      "resetting env. episode 6571, reward total was -15.0. running mean: -15.004305586073919, timestamp: 2022-08-20 11:08:04.054457\n",
      "resetting env. episode 6572, reward total was -14.0. running mean: -14.99426253021318, timestamp: 2022-08-20 11:08:08.754508\n",
      "resetting env. episode 6573, reward total was -12.0. running mean: -14.964319904911047, timestamp: 2022-08-20 11:08:13.431563\n",
      "resetting env. episode 6574, reward total was -7.0. running mean: -14.884676705861937, timestamp: 2022-08-20 11:08:18.870625\n",
      "resetting env. episode 6575, reward total was -15.0. running mean: -14.885829938803317, timestamp: 2022-08-20 11:08:21.308654\n",
      "resetting env. episode 6576, reward total was -17.0. running mean: -14.906971639415284, timestamp: 2022-08-20 11:08:25.411704\n",
      "resetting env. episode 6577, reward total was -10.0. running mean: -14.85790192302113, timestamp: 2022-08-20 11:08:29.364744\n",
      "resetting env. episode 6578, reward total was -18.0. running mean: -14.889322903790918, timestamp: 2022-08-20 11:08:32.597830\n",
      "resetting env. episode 6579, reward total was -15.0. running mean: -14.890429674753008, timestamp: 2022-08-20 11:08:35.762867\n",
      "resetting env. episode 6580, reward total was -16.0. running mean: -14.901525378005479, timestamp: 2022-08-20 11:08:38.906905\n",
      "resetting env. episode 6581, reward total was -15.0. running mean: -14.902510124225424, timestamp: 2022-08-20 11:08:42.152948\n",
      "resetting env. episode 6582, reward total was -14.0. running mean: -14.893485022983171, timestamp: 2022-08-20 11:08:46.234509\n",
      "resetting env. episode 6583, reward total was -16.0. running mean: -14.90455017275334, timestamp: 2022-08-20 11:08:50.595559\n",
      "resetting env. episode 6584, reward total was -15.0. running mean: -14.905504671025806, timestamp: 2022-08-20 11:08:56.257621\n",
      "resetting env. episode 6585, reward total was -12.0. running mean: -14.876449624315548, timestamp: 2022-08-20 11:09:00.158669\n",
      "resetting env. episode 6586, reward total was -12.0. running mean: -14.847685128072392, timestamp: 2022-08-20 11:09:04.767720\n",
      "resetting env. episode 6587, reward total was -21.0. running mean: -14.909208276791668, timestamp: 2022-08-20 11:09:07.867278\n",
      "resetting env. episode 6588, reward total was -13.0. running mean: -14.890116194023753, timestamp: 2022-08-20 11:09:12.961338\n",
      "resetting env. episode 6589, reward total was -14.0. running mean: -14.881215032083515, timestamp: 2022-08-20 11:09:17.477909\n",
      "resetting env. episode 6590, reward total was -17.0. running mean: -14.90240288176268, timestamp: 2022-08-20 11:09:21.135956\n",
      "resetting env. episode 6591, reward total was -13.0. running mean: -14.883378852945054, timestamp: 2022-08-20 11:09:25.366003\n",
      "resetting env. episode 6592, reward total was -12.0. running mean: -14.854545064415602, timestamp: 2022-08-20 11:09:29.361046\n",
      "resetting env. episode 6593, reward total was -17.0. running mean: -14.875999613771445, timestamp: 2022-08-20 11:09:32.768087\n",
      "resetting env. episode 6594, reward total was -14.0. running mean: -14.86723961763373, timestamp: 2022-08-20 11:09:37.524141\n",
      "resetting env. episode 6595, reward total was -15.0. running mean: -14.868567221457393, timestamp: 2022-08-20 11:09:41.361189\n",
      "resetting env. episode 6596, reward total was -16.0. running mean: -14.87988154924282, timestamp: 2022-08-20 11:09:44.315222\n",
      "resetting env. episode 6597, reward total was -19.0. running mean: -14.92108273375039, timestamp: 2022-08-20 11:09:48.561268\n",
      "resetting env. episode 6598, reward total was -16.0. running mean: -14.931871906412887, timestamp: 2022-08-20 11:09:52.193308\n",
      "resetting env. episode 6599, reward total was -11.0. running mean: -14.892553187348758, timestamp: 2022-08-20 11:09:57.272894\n",
      "resetting env. episode 6600, reward total was -17.0. running mean: -14.91362765547527, timestamp: 2022-08-20 11:10:00.508926\n",
      "resetting env. episode 6601, reward total was -18.0. running mean: -14.944491378920517, timestamp: 2022-08-20 11:10:02.941955\n",
      "resetting env. episode 6602, reward total was -12.0. running mean: -14.915046465131311, timestamp: 2022-08-20 11:10:07.319009\n",
      "resetting env. episode 6603, reward total was -20.0. running mean: -14.965896000479997, timestamp: 2022-08-20 11:10:09.104024\n",
      "resetting env. episode 6604, reward total was -15.0. running mean: -14.966237040475198, timestamp: 2022-08-20 11:10:13.695078\n",
      "resetting env. episode 6605, reward total was -15.0. running mean: -14.966574670070447, timestamp: 2022-08-20 11:10:17.606126\n",
      "resetting env. episode 6606, reward total was -17.0. running mean: -14.986908923369741, timestamp: 2022-08-20 11:10:21.037160\n",
      "resetting env. episode 6607, reward total was -17.0. running mean: -15.007039834136044, timestamp: 2022-08-20 11:10:25.382213\n",
      "resetting env. episode 6608, reward total was -16.0. running mean: -15.016969435794683, timestamp: 2022-08-20 11:10:28.994252\n",
      "resetting env. episode 6609, reward total was -17.0. running mean: -15.036799741436736, timestamp: 2022-08-20 11:10:32.055286\n",
      "resetting env. episode 6610, reward total was -13.0. running mean: -15.01643174402237, timestamp: 2022-08-20 11:10:35.696327\n",
      "resetting env. episode 6611, reward total was -19.0. running mean: -15.056267426582146, timestamp: 2022-08-20 11:10:37.683354\n",
      "resetting env. episode 6612, reward total was -16.0. running mean: -15.065704752316325, timestamp: 2022-08-20 11:10:41.527397\n",
      "resetting env. episode 6613, reward total was -15.0. running mean: -15.065047704793162, timestamp: 2022-08-20 11:10:45.978451\n",
      "resetting env. episode 6614, reward total was -15.0. running mean: -15.06439722774523, timestamp: 2022-08-20 11:10:49.971497\n",
      "resetting env. episode 6615, reward total was -20.0. running mean: -15.113753255467778, timestamp: 2022-08-20 11:10:52.069517\n",
      "resetting env. episode 6616, reward total was -18.0. running mean: -15.1426157229131, timestamp: 2022-08-20 11:10:55.977565\n",
      "resetting env. episode 6617, reward total was -14.0. running mean: -15.131189565683968, timestamp: 2022-08-20 11:11:00.365612\n",
      "resetting env. episode 6618, reward total was -19.0. running mean: -15.169877670027129, timestamp: 2022-08-20 11:11:02.562157\n",
      "resetting env. episode 6619, reward total was -10.0. running mean: -15.118178893326856, timestamp: 2022-08-20 11:11:07.915219\n",
      "resetting env. episode 6620, reward total was -20.0. running mean: -15.166997104393587, timestamp: 2022-08-20 11:11:11.116256\n",
      "resetting env. episode 6621, reward total was -14.0. running mean: -15.155327133349651, timestamp: 2022-08-20 11:11:14.688297\n",
      "resetting env. episode 6622, reward total was -13.0. running mean: -15.133773862016156, timestamp: 2022-08-20 11:11:20.226361\n",
      "resetting env. episode 6623, reward total was -15.0. running mean: -15.132436123395994, timestamp: 2022-08-20 11:11:23.917403\n",
      "resetting env. episode 6624, reward total was -20.0. running mean: -15.181111762162033, timestamp: 2022-08-20 11:11:25.811428\n",
      "resetting env. episode 6625, reward total was -10.0. running mean: -15.129300644540411, timestamp: 2022-08-20 11:11:31.502493\n",
      "resetting env. episode 6626, reward total was -14.0. running mean: -15.118007638095007, timestamp: 2022-08-20 11:11:35.119531\n",
      "resetting env. episode 6627, reward total was -11.0. running mean: -15.076827561714056, timestamp: 2022-08-20 11:11:40.163592\n",
      "resetting env. episode 6628, reward total was -17.0. running mean: -15.096059286096915, timestamp: 2022-08-20 11:11:43.604632\n",
      "resetting env. episode 6629, reward total was -9.0. running mean: -15.035098693235946, timestamp: 2022-08-20 11:11:49.477698\n",
      "resetting env. episode 6630, reward total was -15.0. running mean: -15.034747706303587, timestamp: 2022-08-20 11:11:53.416743\n",
      "resetting env. episode 6631, reward total was -8.0. running mean: -14.964400229240551, timestamp: 2022-08-20 11:11:58.811804\n",
      "resetting env. episode 6632, reward total was -15.0. running mean: -14.964756226948147, timestamp: 2022-08-20 11:12:02.262844\n",
      "resetting env. episode 6633, reward total was -14.0. running mean: -14.955108664678665, timestamp: 2022-08-20 11:12:05.408883\n",
      "resetting env. episode 6634, reward total was -17.0. running mean: -14.975557578031879, timestamp: 2022-08-20 11:12:08.565442\n",
      "resetting env. episode 6635, reward total was -19.0. running mean: -15.01580200225156, timestamp: 2022-08-20 11:12:11.025472\n",
      "resetting env. episode 6636, reward total was -11.0. running mean: -14.975643982229043, timestamp: 2022-08-20 11:12:15.334525\n",
      "resetting env. episode 6637, reward total was -16.0. running mean: -14.985887542406752, timestamp: 2022-08-20 11:12:18.934562\n",
      "resetting env. episode 6638, reward total was -14.0. running mean: -14.976028666982685, timestamp: 2022-08-20 11:12:23.399616\n",
      "resetting env. episode 6639, reward total was -13.0. running mean: -14.95626838031286, timestamp: 2022-08-20 11:12:27.090178\n",
      "resetting env. episode 6640, reward total was -19.0. running mean: -14.99670569650973, timestamp: 2022-08-20 11:12:31.273227\n",
      "resetting env. episode 6641, reward total was -14.0. running mean: -14.986738639544633, timestamp: 2022-08-20 11:12:36.161283\n",
      "resetting env. episode 6642, reward total was -15.0. running mean: -14.986871253149188, timestamp: 2022-08-20 11:12:39.849327\n",
      "resetting env. episode 6643, reward total was -15.0. running mean: -14.987002540617697, timestamp: 2022-08-20 11:12:44.616382\n",
      "resetting env. episode 6644, reward total was -11.0. running mean: -14.94713251521152, timestamp: 2022-08-20 11:12:49.714444\n",
      "resetting env. episode 6645, reward total was -13.0. running mean: -14.927661190059405, timestamp: 2022-08-20 11:12:55.051501\n",
      "resetting env. episode 6646, reward total was -20.0. running mean: -14.97838457815881, timestamp: 2022-08-20 11:12:57.941536\n",
      "resetting env. episode 6647, reward total was -9.0. running mean: -14.918600732377222, timestamp: 2022-08-20 11:13:03.289601\n",
      "resetting env. episode 6648, reward total was -9.0. running mean: -14.85941472505345, timestamp: 2022-08-20 11:13:08.082657\n",
      "resetting env. episode 6649, reward total was -12.0. running mean: -14.830820577802914, timestamp: 2022-08-20 11:13:12.694708\n",
      "resetting env. episode 6650, reward total was -19.0. running mean: -14.872512372024884, timestamp: 2022-08-20 11:13:15.277738\n",
      "resetting env. episode 6651, reward total was -15.0. running mean: -14.873787248304636, timestamp: 2022-08-20 11:13:19.018784\n",
      "resetting env. episode 6652, reward total was -11.0. running mean: -14.835049375821589, timestamp: 2022-08-20 11:13:24.009904\n",
      "resetting env. episode 6653, reward total was -14.0. running mean: -14.826698882063374, timestamp: 2022-08-20 11:13:29.659493\n",
      "resetting env. episode 6654, reward total was -15.0. running mean: -14.82843189324274, timestamp: 2022-08-20 11:13:33.556537\n",
      "resetting env. episode 6655, reward total was -15.0. running mean: -14.830147574310313, timestamp: 2022-08-20 11:13:38.237592\n",
      "resetting env. episode 6656, reward total was -14.0. running mean: -14.82184609856721, timestamp: 2022-08-20 11:13:42.163638\n",
      "resetting env. episode 6657, reward total was -10.0. running mean: -14.773627637581537, timestamp: 2022-08-20 11:13:47.792704\n",
      "resetting env. episode 6658, reward total was -16.0. running mean: -14.785891361205723, timestamp: 2022-08-20 11:13:51.354746\n",
      "resetting env. episode 6659, reward total was -17.0. running mean: -14.808032447593666, timestamp: 2022-08-20 11:13:55.847841\n",
      "resetting env. episode 6660, reward total was -13.0. running mean: -14.78995212311773, timestamp: 2022-08-20 11:14:00.009892\n",
      "resetting env. episode 6661, reward total was -17.0. running mean: -14.812052601886553, timestamp: 2022-08-20 11:14:03.392933\n",
      "resetting env. episode 6662, reward total was -9.0. running mean: -14.753932075867686, timestamp: 2022-08-20 11:14:08.819992\n",
      "resetting env. episode 6663, reward total was -19.0. running mean: -14.796392755109009, timestamp: 2022-08-20 11:14:12.196033\n",
      "resetting env. episode 6664, reward total was -13.0. running mean: -14.778428827557919, timestamp: 2022-08-20 11:14:17.285089\n",
      "resetting env. episode 6665, reward total was -15.0. running mean: -14.78064453928234, timestamp: 2022-08-20 11:14:22.038144\n",
      "resetting env. episode 6666, reward total was -14.0. running mean: -14.772838093889517, timestamp: 2022-08-20 11:14:26.926201\n",
      "resetting env. episode 6667, reward total was -16.0. running mean: -14.785109712950621, timestamp: 2022-08-20 11:14:31.160251\n",
      "resetting env. episode 6668, reward total was -8.0. running mean: -14.717258615821116, timestamp: 2022-08-20 11:14:36.800316\n",
      "resetting env. episode 6669, reward total was -11.0. running mean: -14.680086029662904, timestamp: 2022-08-20 11:14:42.319910\n",
      "resetting env. episode 6670, reward total was -12.0. running mean: -14.653285169366274, timestamp: 2022-08-20 11:14:47.037959\n",
      "resetting env. episode 6671, reward total was -15.0. running mean: -14.65675231767261, timestamp: 2022-08-20 11:14:51.047008\n",
      "resetting env. episode 6672, reward total was -20.0. running mean: -14.710184794495884, timestamp: 2022-08-20 11:14:54.946576\n",
      "resetting env. episode 6673, reward total was -17.0. running mean: -14.733082946550924, timestamp: 2022-08-20 11:14:58.718621\n",
      "resetting env. episode 6674, reward total was -15.0. running mean: -14.735752117085415, timestamp: 2022-08-20 11:15:03.005669\n",
      "resetting env. episode 6675, reward total was -17.0. running mean: -14.758394595914561, timestamp: 2022-08-20 11:15:08.008732\n",
      "resetting env. episode 6676, reward total was -13.0. running mean: -14.740810649955415, timestamp: 2022-08-20 11:15:13.431793\n",
      "resetting env. episode 6677, reward total was -9.0. running mean: -14.68340254345586, timestamp: 2022-08-20 11:15:19.044856\n",
      "resetting env. episode 6678, reward total was -13.0. running mean: -14.666568518021302, timestamp: 2022-08-20 11:15:23.035903\n",
      "resetting env. episode 6679, reward total was -10.0. running mean: -14.619902832841088, timestamp: 2022-08-20 11:15:28.502964\n",
      "resetting env. episode 6680, reward total was -15.0. running mean: -14.623703804512678, timestamp: 2022-08-20 11:15:33.747025\n",
      "resetting env. episode 6681, reward total was -10.0. running mean: -14.57746676646755, timestamp: 2022-08-20 11:15:39.084097\n",
      "resetting env. episode 6682, reward total was -14.0. running mean: -14.571692098802876, timestamp: 2022-08-20 11:15:43.528139\n",
      "resetting env. episode 6683, reward total was -16.0. running mean: -14.585975177814847, timestamp: 2022-08-20 11:15:47.512190\n",
      "resetting env. episode 6684, reward total was -10.0. running mean: -14.540115426036698, timestamp: 2022-08-20 11:15:52.699246\n",
      "resetting env. episode 6685, reward total was -13.0. running mean: -14.52471427177633, timestamp: 2022-08-20 11:15:56.370291\n",
      "resetting env. episode 6686, reward total was -15.0. running mean: -14.529467129058567, timestamp: 2022-08-20 11:16:00.244332\n",
      "resetting env. episode 6687, reward total was -16.0. running mean: -14.544172457767981, timestamp: 2022-08-20 11:16:04.444902\n",
      "resetting env. episode 6688, reward total was -12.0. running mean: -14.518730733190301, timestamp: 2022-08-20 11:16:08.440949\n",
      "resetting env. episode 6689, reward total was -15.0. running mean: -14.523543425858398, timestamp: 2022-08-20 11:16:12.092992\n",
      "resetting env. episode 6690, reward total was -11.0. running mean: -14.488307991599813, timestamp: 2022-08-20 11:16:16.809045\n",
      "resetting env. episode 6691, reward total was -16.0. running mean: -14.503424911683815, timestamp: 2022-08-20 11:16:20.581091\n",
      "resetting env. episode 6692, reward total was -17.0. running mean: -14.528390662566977, timestamp: 2022-08-20 11:16:23.979130\n",
      "resetting env. episode 6693, reward total was -5.0. running mean: -14.433106755941308, timestamp: 2022-08-20 11:16:30.293205\n",
      "resetting env. episode 6694, reward total was -18.0. running mean: -14.468775688381895, timestamp: 2022-08-20 11:16:34.851254\n",
      "resetting env. episode 6695, reward total was 2.0. running mean: -14.304087931498076, timestamp: 2022-08-20 11:16:41.472859\n",
      "resetting env. episode 6696, reward total was -16.0. running mean: -14.321047052183095, timestamp: 2022-08-20 11:16:45.342901\n",
      "resetting env. episode 6697, reward total was -11.0. running mean: -14.287836581661264, timestamp: 2022-08-20 11:16:51.534974\n",
      "resetting env. episode 6698, reward total was -13.0. running mean: -14.274958215844652, timestamp: 2022-08-20 11:16:55.418019\n",
      "resetting env. episode 6699, reward total was -7.0. running mean: -14.202208633686206, timestamp: 2022-08-20 11:17:01.360085\n",
      "resetting env. episode 6700, reward total was -17.0. running mean: -14.230186547349344, timestamp: 2022-08-20 11:17:05.394136\n",
      "resetting env. episode 6701, reward total was -17.0. running mean: -14.25788468187585, timestamp: 2022-08-20 11:17:09.577183\n",
      "resetting env. episode 6702, reward total was -16.0. running mean: -14.275305835057091, timestamp: 2022-08-20 11:17:14.531242\n",
      "resetting env. episode 6703, reward total was -17.0. running mean: -14.30255277670652, timestamp: 2022-08-20 11:17:19.014292\n",
      "resetting env. episode 6704, reward total was -9.0. running mean: -14.249527248939454, timestamp: 2022-08-20 11:17:25.014360\n",
      "resetting env. episode 6705, reward total was -14.0. running mean: -14.24703197645006, timestamp: 2022-08-20 11:17:28.621405\n",
      "resetting env. episode 6706, reward total was -7.0. running mean: -14.17456165668556, timestamp: 2022-08-20 11:17:34.986476\n",
      "resetting env. episode 6707, reward total was -14.0. running mean: -14.172816040118704, timestamp: 2022-08-20 11:17:39.200523\n",
      "resetting env. episode 6708, reward total was -14.0. running mean: -14.171087879717517, timestamp: 2022-08-20 11:17:45.170594\n",
      "resetting env. episode 6709, reward total was -9.0. running mean: -14.119377000920341, timestamp: 2022-08-20 11:17:51.091662\n",
      "resetting env. episode 6710, reward total was -8.0. running mean: -14.058183230911137, timestamp: 2022-08-20 11:17:56.623725\n",
      "resetting env. episode 6711, reward total was -7.0. running mean: -13.987601398602026, timestamp: 2022-08-20 11:18:01.944788\n",
      "resetting env. episode 6712, reward total was -11.0. running mean: -13.957725384616005, timestamp: 2022-08-20 11:18:07.041847\n",
      "resetting env. episode 6713, reward total was -7.0. running mean: -13.888148130769844, timestamp: 2022-08-20 11:18:13.530922\n",
      "resetting env. episode 6714, reward total was -11.0. running mean: -13.859266649462144, timestamp: 2022-08-20 11:18:19.153994\n",
      "resetting env. episode 6715, reward total was -19.0. running mean: -13.910673982967522, timestamp: 2022-08-20 11:18:21.965020\n",
      "resetting env. episode 6716, reward total was -14.0. running mean: -13.911567243137847, timestamp: 2022-08-20 11:18:26.588073\n",
      "resetting env. episode 6717, reward total was -13.0. running mean: -13.90245157070647, timestamp: 2022-08-20 11:18:31.255132\n",
      "resetting env. episode 6718, reward total was -20.0. running mean: -13.963427054999404, timestamp: 2022-08-20 11:18:34.381165\n",
      "resetting env. episode 6719, reward total was -15.0. running mean: -13.97379278444941, timestamp: 2022-08-20 11:18:37.910207\n",
      "resetting env. episode 6720, reward total was -21.0. running mean: -14.044054856604916, timestamp: 2022-08-20 11:18:40.890241\n",
      "resetting env. episode 6721, reward total was -9.0. running mean: -13.993614308038866, timestamp: 2022-08-20 11:18:44.963288\n",
      "resetting env. episode 6722, reward total was -13.0. running mean: -13.983678164958478, timestamp: 2022-08-20 11:18:49.686342\n",
      "resetting env. episode 6723, reward total was -20.0. running mean: -14.043841383308893, timestamp: 2022-08-20 11:18:52.367897\n",
      "resetting env. episode 6724, reward total was -17.0. running mean: -14.073402969475804, timestamp: 2022-08-20 11:18:56.479944\n",
      "resetting env. episode 6725, reward total was -9.0. running mean: -14.022668939781045, timestamp: 2022-08-20 11:19:01.878026\n",
      "resetting env. episode 6726, reward total was -12.0. running mean: -14.002442250383234, timestamp: 2022-08-20 11:19:07.095090\n",
      "resetting env. episode 6727, reward total was -14.0. running mean: -14.002417827879402, timestamp: 2022-08-20 11:19:11.533136\n",
      "resetting env. episode 6728, reward total was -12.0. running mean: -13.982393649600606, timestamp: 2022-08-20 11:19:15.302706\n",
      "resetting env. episode 6729, reward total was -12.0. running mean: -13.9625697131046, timestamp: 2022-08-20 11:19:19.902757\n",
      "resetting env. episode 6730, reward total was -18.0. running mean: -14.002944015973553, timestamp: 2022-08-20 11:19:24.095807\n",
      "resetting env. episode 6731, reward total was -17.0. running mean: -14.032914575813816, timestamp: 2022-08-20 11:19:26.936837\n",
      "resetting env. episode 6732, reward total was -9.0. running mean: -13.982585430055678, timestamp: 2022-08-20 11:19:32.836907\n",
      "resetting env. episode 6733, reward total was -15.0. running mean: -13.992759575755121, timestamp: 2022-08-20 11:19:37.326958\n",
      "resetting env. episode 6734, reward total was -13.0. running mean: -13.98283197999757, timestamp: 2022-08-20 11:19:41.872061\n",
      "resetting env. episode 6735, reward total was -16.0. running mean: -14.003003660197594, timestamp: 2022-08-20 11:19:45.818105\n",
      "resetting env. episode 6736, reward total was -14.0. running mean: -14.002973623595619, timestamp: 2022-08-20 11:19:49.971154\n",
      "resetting env. episode 6737, reward total was -14.0. running mean: -14.002943887359663, timestamp: 2022-08-20 11:19:54.479207\n",
      "resetting env. episode 6738, reward total was -15.0. running mean: -14.012914448486066, timestamp: 2022-08-20 11:19:57.717242\n",
      "resetting env. episode 6739, reward total was -11.0. running mean: -13.982785304001204, timestamp: 2022-08-20 11:20:02.197294\n",
      "resetting env. episode 6740, reward total was -14.0. running mean: -13.982957450961193, timestamp: 2022-08-20 11:20:06.187339\n",
      "resetting env. episode 6741, reward total was -17.0. running mean: -14.01312787645158, timestamp: 2022-08-20 11:20:09.604381\n",
      "resetting env. episode 6742, reward total was -12.0. running mean: -13.992996597687064, timestamp: 2022-08-20 11:20:15.408449\n",
      "resetting env. episode 6743, reward total was -13.0. running mean: -13.983066631710194, timestamp: 2022-08-20 11:20:20.170504\n",
      "resetting env. episode 6744, reward total was -17.0. running mean: -14.013235965393092, timestamp: 2022-08-20 11:20:23.693544\n",
      "resetting env. episode 6745, reward total was -15.0. running mean: -14.023103605739161, timestamp: 2022-08-20 11:20:27.456586\n",
      "resetting env. episode 6746, reward total was -13.0. running mean: -14.01287256968177, timestamp: 2022-08-20 11:20:31.937163\n",
      "resetting env. episode 6747, reward total was -6.0. running mean: -13.932743843984953, timestamp: 2022-08-20 11:20:37.399231\n",
      "resetting env. episode 6748, reward total was -15.0. running mean: -13.943416405545104, timestamp: 2022-08-20 11:20:40.983270\n",
      "resetting env. episode 6749, reward total was -13.0. running mean: -13.933982241489653, timestamp: 2022-08-20 11:20:44.923316\n",
      "resetting env. episode 6750, reward total was -18.0. running mean: -13.974642419074756, timestamp: 2022-08-20 11:20:48.282353\n",
      "resetting env. episode 6751, reward total was -14.0. running mean: -13.97489599488401, timestamp: 2022-08-20 11:20:52.364400\n",
      "resetting env. episode 6752, reward total was -15.0. running mean: -13.98514703493517, timestamp: 2022-08-20 11:20:56.511450\n",
      "resetting env. episode 6753, reward total was -18.0. running mean: -14.025295564585818, timestamp: 2022-08-20 11:21:00.572496\n",
      "resetting env. episode 6754, reward total was -10.0. running mean: -13.98504260893996, timestamp: 2022-08-20 11:21:06.519567\n",
      "resetting env. episode 6755, reward total was -13.0. running mean: -13.975192182850561, timestamp: 2022-08-20 11:21:11.139616\n",
      "resetting env. episode 6756, reward total was -12.0. running mean: -13.955440261022055, timestamp: 2022-08-20 11:21:14.899658\n",
      "resetting env. episode 6757, reward total was -13.0. running mean: -13.945885858411835, timestamp: 2022-08-20 11:21:19.730714\n",
      "resetting env. episode 6758, reward total was -17.0. running mean: -13.976426999827716, timestamp: 2022-08-20 11:21:24.063765\n",
      "resetting env. episode 6759, reward total was -15.0. running mean: -13.986662729829439, timestamp: 2022-08-20 11:21:28.769819\n",
      "resetting env. episode 6760, reward total was -9.0. running mean: -13.936796102531144, timestamp: 2022-08-20 11:21:34.288883\n",
      "resetting env. episode 6761, reward total was -19.0. running mean: -13.987428141505832, timestamp: 2022-08-20 11:21:37.994923\n",
      "resetting env. episode 6762, reward total was -19.0. running mean: -14.037553860090773, timestamp: 2022-08-20 11:21:42.213974\n",
      "resetting env. episode 6763, reward total was -17.0. running mean: -14.067178321489864, timestamp: 2022-08-20 11:21:45.425009\n",
      "resetting env. episode 6764, reward total was -12.0. running mean: -14.046506538274965, timestamp: 2022-08-20 11:21:51.848085\n",
      "resetting env. episode 6765, reward total was -11.0. running mean: -14.016041472892214, timestamp: 2022-08-20 11:21:57.503203\n",
      "resetting env. episode 6766, reward total was -17.0. running mean: -14.04588105816329, timestamp: 2022-08-20 11:22:02.675259\n",
      "resetting env. episode 6767, reward total was -9.0. running mean: -13.995422247581658, timestamp: 2022-08-20 11:22:06.814304\n",
      "resetting env. episode 6768, reward total was -18.0. running mean: -14.03546802510584, timestamp: 2022-08-20 11:22:10.537346\n",
      "resetting env. episode 6769, reward total was -11.0. running mean: -14.00511334485478, timestamp: 2022-08-20 11:22:15.604405\n",
      "resetting env. episode 6770, reward total was -14.0. running mean: -14.005062211406234, timestamp: 2022-08-20 11:22:19.447977\n",
      "resetting env. episode 6771, reward total was -12.0. running mean: -13.98501158929217, timestamp: 2022-08-20 11:22:24.419031\n",
      "resetting env. episode 6772, reward total was -15.0. running mean: -13.99516147339925, timestamp: 2022-08-20 11:22:28.620080\n",
      "resetting env. episode 6773, reward total was -13.0. running mean: -13.985209858665257, timestamp: 2022-08-20 11:22:32.922131\n",
      "resetting env. episode 6774, reward total was -11.0. running mean: -13.955357760078604, timestamp: 2022-08-20 11:22:37.014181\n",
      "resetting env. episode 6775, reward total was -15.0. running mean: -13.965804182477818, timestamp: 2022-08-20 11:22:42.045764\n",
      "resetting env. episode 6776, reward total was 2.0. running mean: -13.80614614065304, timestamp: 2022-08-20 11:22:48.637833\n",
      "resetting env. episode 6777, reward total was -15.0. running mean: -13.818084679246509, timestamp: 2022-08-20 11:22:52.641403\n",
      "resetting env. episode 6778, reward total was -15.0. running mean: -13.829903832454043, timestamp: 2022-08-20 11:22:56.630449\n",
      "resetting env. episode 6779, reward total was -17.0. running mean: -13.861604794129503, timestamp: 2022-08-20 11:22:59.328482\n",
      "resetting env. episode 6780, reward total was -11.0. running mean: -13.832988746188208, timestamp: 2022-08-20 11:23:04.859544\n",
      "resetting env. episode 6781, reward total was -20.0. running mean: -13.894658858726325, timestamp: 2022-08-20 11:23:09.132645\n",
      "resetting env. episode 6782, reward total was -21.0. running mean: -13.965712270139063, timestamp: 2022-08-20 11:23:12.201680\n",
      "resetting env. episode 6783, reward total was -16.0. running mean: -13.986055147437673, timestamp: 2022-08-20 11:23:16.501730\n",
      "resetting env. episode 6784, reward total was -18.0. running mean: -14.026194595963297, timestamp: 2022-08-20 11:23:20.327780\n",
      "resetting env. episode 6785, reward total was -14.0. running mean: -14.025932650003664, timestamp: 2022-08-20 11:23:23.969820\n",
      "resetting env. episode 6786, reward total was -17.0. running mean: -14.055673323503628, timestamp: 2022-08-20 11:23:27.870861\n",
      "resetting env. episode 6787, reward total was -16.0. running mean: -14.07511659026859, timestamp: 2022-08-20 11:23:31.969909\n",
      "resetting env. episode 6788, reward total was -17.0. running mean: -14.104365424365906, timestamp: 2022-08-20 11:23:35.846954\n",
      "resetting env. episode 6789, reward total was -16.0. running mean: -14.123321770122246, timestamp: 2022-08-20 11:23:39.318994\n",
      "resetting env. episode 6790, reward total was -15.0. running mean: -14.132088552421024, timestamp: 2022-08-20 11:23:43.047035\n",
      "resetting env. episode 6791, reward total was -10.0. running mean: -14.090767666896813, timestamp: 2022-08-20 11:23:48.641623\n",
      "resetting env. episode 6792, reward total was -14.0. running mean: -14.089859990227845, timestamp: 2022-08-20 11:23:53.734683\n",
      "resetting env. episode 6793, reward total was -8.0. running mean: -14.028961390325566, timestamp: 2022-08-20 11:23:59.906755\n",
      "resetting env. episode 6794, reward total was -11.0. running mean: -13.99867177642231, timestamp: 2022-08-20 11:24:05.074856\n",
      "resetting env. episode 6795, reward total was -14.0. running mean: -13.998685058658086, timestamp: 2022-08-20 11:24:09.612913\n",
      "resetting env. episode 6796, reward total was -16.0. running mean: -14.018698208071505, timestamp: 2022-08-20 11:24:13.406951\n",
      "resetting env. episode 6797, reward total was -10.0. running mean: -13.97851122599079, timestamp: 2022-08-20 11:24:18.506014\n",
      "resetting env. episode 6798, reward total was -18.0. running mean: -14.018726113730882, timestamp: 2022-08-20 11:24:22.526065\n",
      "resetting env. episode 6799, reward total was -17.0. running mean: -14.048538852593573, timestamp: 2022-08-20 11:24:25.682097\n",
      "resetting env. episode 6800, reward total was -13.0. running mean: -14.038053464067637, timestamp: 2022-08-20 11:24:31.070156\n",
      "resetting env. episode 6801, reward total was -16.0. running mean: -14.05767292942696, timestamp: 2022-08-20 11:24:35.068207\n",
      "resetting env. episode 6802, reward total was -11.0. running mean: -14.02709620013269, timestamp: 2022-08-20 11:24:39.933787\n",
      "resetting env. episode 6803, reward total was -14.0. running mean: -14.026825238131362, timestamp: 2022-08-20 11:24:44.402839\n",
      "resetting env. episode 6804, reward total was -15.0. running mean: -14.03655698575005, timestamp: 2022-08-20 11:24:49.061886\n",
      "resetting env. episode 6805, reward total was -20.0. running mean: -14.096191415892548, timestamp: 2022-08-20 11:24:52.158922\n",
      "resetting env. episode 6806, reward total was -13.0. running mean: -14.085229501733624, timestamp: 2022-08-20 11:24:56.263970\n",
      "resetting env. episode 6807, reward total was -7.0. running mean: -14.014377206716288, timestamp: 2022-08-20 11:25:01.441032\n",
      "resetting env. episode 6808, reward total was -17.0. running mean: -14.044233434649126, timestamp: 2022-08-20 11:25:04.803067\n",
      "resetting env. episode 6809, reward total was -13.0. running mean: -14.033791100302635, timestamp: 2022-08-20 11:25:09.645126\n",
      "resetting env. episode 6810, reward total was -11.0. running mean: -14.003453189299607, timestamp: 2022-08-20 11:25:13.904171\n",
      "resetting env. episode 6811, reward total was -15.0. running mean: -14.013418657406612, timestamp: 2022-08-20 11:25:20.092241\n",
      "resetting env. episode 6812, reward total was -14.0. running mean: -14.013284470832547, timestamp: 2022-08-20 11:25:24.448293\n",
      "resetting env. episode 6813, reward total was -15.0. running mean: -14.023151626124221, timestamp: 2022-08-20 11:25:28.241339\n",
      "resetting env. episode 6814, reward total was -13.0. running mean: -14.01292010986298, timestamp: 2022-08-20 11:25:33.189392\n",
      "resetting env. episode 6815, reward total was -16.0. running mean: -14.032790908764351, timestamp: 2022-08-20 11:25:37.590441\n",
      "resetting env. episode 6816, reward total was -14.0. running mean: -14.032462999676708, timestamp: 2022-08-20 11:25:41.940491\n",
      "resetting env. episode 6817, reward total was -13.0. running mean: -14.022138369679942, timestamp: 2022-08-20 11:25:46.262540\n",
      "resetting env. episode 6818, reward total was -10.0. running mean: -13.981916985983142, timestamp: 2022-08-20 11:25:51.028593\n",
      "resetting env. episode 6819, reward total was -4.0. running mean: -13.88209781612331, timestamp: 2022-08-20 11:25:57.479668\n",
      "resetting env. episode 6820, reward total was -14.0. running mean: -13.883276837962077, timestamp: 2022-08-20 11:26:01.928720\n",
      "resetting env. episode 6821, reward total was -11.0. running mean: -13.854444069582456, timestamp: 2022-08-20 11:26:07.016777\n",
      "resetting env. episode 6822, reward total was -8.0. running mean: -13.795899628886632, timestamp: 2022-08-20 11:26:12.615843\n",
      "resetting env. episode 6823, reward total was -18.0. running mean: -13.837940632597766, timestamp: 2022-08-20 11:26:16.194885\n",
      "resetting env. episode 6824, reward total was -17.0. running mean: -13.869561226271788, timestamp: 2022-08-20 11:26:20.699932\n",
      "resetting env. episode 6825, reward total was -17.0. running mean: -13.90086561400907, timestamp: 2022-08-20 11:26:24.246500\n",
      "resetting env. episode 6826, reward total was -17.0. running mean: -13.93185695786898, timestamp: 2022-08-20 11:26:29.338555\n",
      "resetting env. episode 6827, reward total was -11.0. running mean: -13.90253838829029, timestamp: 2022-08-20 11:26:32.971596\n",
      "resetting env. episode 6828, reward total was -20.0. running mean: -13.963513004407387, timestamp: 2022-08-20 11:26:36.198635\n",
      "resetting env. episode 6829, reward total was -18.0. running mean: -14.003877874363313, timestamp: 2022-08-20 11:26:39.206668\n",
      "resetting env. episode 6830, reward total was -7.0. running mean: -13.93383909561968, timestamp: 2022-08-20 11:26:44.346727\n",
      "resetting env. episode 6831, reward total was -11.0. running mean: -13.904500704663482, timestamp: 2022-08-20 11:26:50.314321\n",
      "resetting env. episode 6832, reward total was -11.0. running mean: -13.875455697616847, timestamp: 2022-08-20 11:26:55.082374\n",
      "resetting env. episode 6833, reward total was -11.0. running mean: -13.846701140640677, timestamp: 2022-08-20 11:26:59.552430\n",
      "resetting env. episode 6834, reward total was -17.0. running mean: -13.87823412923427, timestamp: 2022-08-20 11:27:04.138480\n",
      "resetting env. episode 6835, reward total was -18.0. running mean: -13.919451787941927, timestamp: 2022-08-20 11:27:07.864521\n",
      "resetting env. episode 6836, reward total was -16.0. running mean: -13.940257270062508, timestamp: 2022-08-20 11:27:10.844555\n",
      "resetting env. episode 6837, reward total was -19.0. running mean: -13.990854697361883, timestamp: 2022-08-20 11:27:15.019602\n",
      "resetting env. episode 6838, reward total was -17.0. running mean: -14.020946150388264, timestamp: 2022-08-20 11:27:19.071648\n",
      "resetting env. episode 6839, reward total was -13.0. running mean: -14.010736688884382, timestamp: 2022-08-20 11:27:24.141705\n",
      "resetting env. episode 6840, reward total was -13.0. running mean: -14.00062932199554, timestamp: 2022-08-20 11:27:30.237824\n",
      "resetting env. episode 6841, reward total was -18.0. running mean: -14.040623028775583, timestamp: 2022-08-20 11:27:35.314881\n",
      "resetting env. episode 6842, reward total was -10.0. running mean: -14.000216798487827, timestamp: 2022-08-20 11:27:41.199950\n",
      "resetting env. episode 6843, reward total was -17.0. running mean: -14.030214630502948, timestamp: 2022-08-20 11:27:46.486061\n",
      "resetting env. episode 6844, reward total was -14.0. running mean: -14.029912484197919, timestamp: 2022-08-20 11:27:51.527119\n",
      "resetting env. episode 6845, reward total was -11.0. running mean: -13.999613359355939, timestamp: 2022-08-20 11:27:55.677165\n",
      "resetting env. episode 6846, reward total was -14.0. running mean: -13.99961722576238, timestamp: 2022-08-20 11:27:59.721210\n",
      "resetting env. episode 6847, reward total was -5.0. running mean: -13.909621053504758, timestamp: 2022-08-20 11:28:06.555818\n",
      "resetting env. episode 6848, reward total was -13.0. running mean: -13.90052484296971, timestamp: 2022-08-20 11:28:10.697867\n",
      "resetting env. episode 6849, reward total was -18.0. running mean: -13.941519594540013, timestamp: 2022-08-20 11:28:14.168903\n",
      "resetting env. episode 6850, reward total was -14.0. running mean: -13.942104398594614, timestamp: 2022-08-20 11:28:18.628956\n",
      "resetting env. episode 6851, reward total was -11.0. running mean: -13.912683354608667, timestamp: 2022-08-20 11:28:24.292547\n",
      "resetting env. episode 6852, reward total was -17.0. running mean: -13.94355652106258, timestamp: 2022-08-20 11:28:28.657595\n",
      "resetting env. episode 6853, reward total was -11.0. running mean: -13.914120955851955, timestamp: 2022-08-20 11:28:33.911651\n",
      "resetting env. episode 6854, reward total was -10.0. running mean: -13.874979746293434, timestamp: 2022-08-20 11:28:39.236237\n",
      "resetting env. episode 6855, reward total was -11.0. running mean: -13.8462299488305, timestamp: 2022-08-20 11:28:43.542810\n",
      "resetting env. episode 6856, reward total was -4.0. running mean: -13.747767649342194, timestamp: 2022-08-20 11:28:50.197883\n",
      "resetting env. episode 6857, reward total was -14.0. running mean: -13.750289972848773, timestamp: 2022-08-20 11:28:54.776937\n",
      "resetting env. episode 6858, reward total was -15.0. running mean: -13.762787073120284, timestamp: 2022-08-20 11:28:58.466983\n",
      "resetting env. episode 6859, reward total was -11.0. running mean: -13.735159202389081, timestamp: 2022-08-20 11:29:04.451050\n",
      "resetting env. episode 6860, reward total was -9.0. running mean: -13.68780761036519, timestamp: 2022-08-20 11:29:09.209102\n",
      "resetting env. episode 6861, reward total was -8.0. running mean: -13.630929534261538, timestamp: 2022-08-20 11:29:16.971193\n",
      "resetting env. episode 6862, reward total was -21.0. running mean: -13.704620238918924, timestamp: 2022-08-20 11:29:21.002244\n",
      "resetting env. episode 6863, reward total was -16.0. running mean: -13.727574036529735, timestamp: 2022-08-20 11:29:24.584282\n",
      "resetting env. episode 6864, reward total was -13.0. running mean: -13.720298296164438, timestamp: 2022-08-20 11:29:28.830331\n",
      "resetting env. episode 6865, reward total was -17.0. running mean: -13.753095313202794, timestamp: 2022-08-20 11:29:33.565388\n",
      "resetting env. episode 6866, reward total was -17.0. running mean: -13.785564360070765, timestamp: 2022-08-20 11:29:37.834433\n",
      "resetting env. episode 6867, reward total was -16.0. running mean: -13.807708716470058, timestamp: 2022-08-20 11:29:41.948482\n",
      "resetting env. episode 6868, reward total was -17.0. running mean: -13.839631629305357, timestamp: 2022-08-20 11:29:45.374518\n",
      "resetting env. episode 6869, reward total was -19.0. running mean: -13.891235313012302, timestamp: 2022-08-20 11:29:50.673107\n",
      "resetting env. episode 6870, reward total was -16.0. running mean: -13.912322959882179, timestamp: 2022-08-20 11:29:54.341151\n",
      "resetting env. episode 6871, reward total was -11.0. running mean: -13.883199730283357, timestamp: 2022-08-20 11:29:58.525196\n",
      "resetting env. episode 6872, reward total was -14.0. running mean: -13.884367732980524, timestamp: 2022-08-20 11:30:02.270244\n",
      "resetting env. episode 6873, reward total was -17.0. running mean: -13.915524055650717, timestamp: 2022-08-20 11:30:06.376289\n",
      "resetting env. episode 6874, reward total was -10.0. running mean: -13.87636881509421, timestamp: 2022-08-20 11:30:11.287344\n",
      "resetting env. episode 6875, reward total was -12.0. running mean: -13.857605126943268, timestamp: 2022-08-20 11:30:16.271406\n",
      "resetting env. episode 6876, reward total was -18.0. running mean: -13.899029075673834, timestamp: 2022-08-20 11:30:18.448953\n",
      "resetting env. episode 6877, reward total was -15.0. running mean: -13.910038784917095, timestamp: 2022-08-20 11:30:22.850005\n",
      "resetting env. episode 6878, reward total was -20.0. running mean: -13.970938397067924, timestamp: 2022-08-20 11:30:25.047030\n",
      "resetting env. episode 6879, reward total was -15.0. running mean: -13.981229013097245, timestamp: 2022-08-20 11:30:27.634057\n",
      "resetting env. episode 6880, reward total was -18.0. running mean: -14.021416722966272, timestamp: 2022-08-20 11:30:32.068107\n",
      "resetting env. episode 6881, reward total was -15.0. running mean: -14.03120255573661, timestamp: 2022-08-20 11:30:36.013156\n",
      "resetting env. episode 6882, reward total was -17.0. running mean: -14.060890530179243, timestamp: 2022-08-20 11:30:40.566206\n",
      "resetting env. episode 6883, reward total was -14.0. running mean: -14.060281624877451, timestamp: 2022-08-20 11:30:44.360256\n",
      "resetting env. episode 6884, reward total was -17.0. running mean: -14.089678808628676, timestamp: 2022-08-20 11:30:48.994308\n",
      "resetting env. episode 6885, reward total was -15.0. running mean: -14.098782020542389, timestamp: 2022-08-20 11:30:52.377344\n",
      "resetting env. episode 6886, reward total was -16.0. running mean: -14.117794200336965, timestamp: 2022-08-20 11:30:57.541401\n",
      "resetting env. episode 6887, reward total was -16.0. running mean: -14.136616258333595, timestamp: 2022-08-20 11:31:02.495463\n",
      "resetting env. episode 6888, reward total was -17.0. running mean: -14.165250095750258, timestamp: 2022-08-20 11:31:06.699508\n",
      "resetting env. episode 6889, reward total was -19.0. running mean: -14.213597594792754, timestamp: 2022-08-20 11:31:10.564553\n",
      "resetting env. episode 6890, reward total was -17.0. running mean: -14.241461618844825, timestamp: 2022-08-20 11:31:14.275596\n",
      "resetting env. episode 6891, reward total was -10.0. running mean: -14.199047002656377, timestamp: 2022-08-20 11:31:19.375654\n",
      "resetting env. episode 6892, reward total was -12.0. running mean: -14.177056532629813, timestamp: 2022-08-20 11:31:23.540704\n",
      "resetting env. episode 6893, reward total was -17.0. running mean: -14.205285967303514, timestamp: 2022-08-20 11:31:26.522255\n",
      "resetting env. episode 6894, reward total was -6.0. running mean: -14.12323310763048, timestamp: 2022-08-20 11:31:32.388324\n",
      "resetting env. episode 6895, reward total was -14.0. running mean: -14.122000776554176, timestamp: 2022-08-20 11:31:36.250367\n",
      "resetting env. episode 6896, reward total was -16.0. running mean: -14.140780768788634, timestamp: 2022-08-20 11:31:39.489407\n",
      "resetting env. episode 6897, reward total was -15.0. running mean: -14.149372961100747, timestamp: 2022-08-20 11:31:43.033450\n",
      "resetting env. episode 6898, reward total was -16.0. running mean: -14.16787923148974, timestamp: 2022-08-20 11:31:47.668024\n",
      "resetting env. episode 6899, reward total was -17.0. running mean: -14.196200439174843, timestamp: 2022-08-20 11:31:51.985074\n",
      "resetting env. episode 6900, reward total was -15.0. running mean: -14.204238434783095, timestamp: 2022-08-20 11:31:55.992120\n",
      "resetting env. episode 6901, reward total was -5.0. running mean: -14.112196050435264, timestamp: 2022-08-20 11:32:01.731186\n",
      "resetting env. episode 6902, reward total was -15.0. running mean: -14.12107408993091, timestamp: 2022-08-20 11:32:05.829232\n",
      "resetting env. episode 6903, reward total was -9.0. running mean: -14.069863349031602, timestamp: 2022-08-20 11:32:11.853302\n",
      "resetting env. episode 6904, reward total was -12.0. running mean: -14.049164715541284, timestamp: 2022-08-20 11:32:16.430354\n",
      "resetting env. episode 6905, reward total was -11.0. running mean: -14.018673068385871, timestamp: 2022-08-20 11:32:22.218421\n",
      "resetting env. episode 6906, reward total was -15.0. running mean: -14.028486337702013, timestamp: 2022-08-20 11:32:26.977477\n",
      "resetting env. episode 6907, reward total was -14.0. running mean: -14.028201474324993, timestamp: 2022-08-20 11:32:32.508541\n",
      "resetting env. episode 6908, reward total was -15.0. running mean: -14.037919459581744, timestamp: 2022-08-20 11:32:38.000603\n",
      "resetting env. episode 6909, reward total was -17.0. running mean: -14.067540264985926, timestamp: 2022-08-20 11:32:42.209650\n",
      "resetting env. episode 6910, reward total was -11.0. running mean: -14.036864862336065, timestamp: 2022-08-20 11:32:46.801702\n",
      "resetting env. episode 6911, reward total was -8.0. running mean: -13.976496213712705, timestamp: 2022-08-20 11:32:52.790772\n",
      "resetting env. episode 6912, reward total was -15.0. running mean: -13.986731251575579, timestamp: 2022-08-20 11:32:57.143827\n",
      "resetting env. episode 6913, reward total was -19.0. running mean: -14.036863939059822, timestamp: 2022-08-20 11:33:00.849865\n",
      "resetting env. episode 6914, reward total was -17.0. running mean: -14.066495299669224, timestamp: 2022-08-20 11:33:04.651429\n",
      "resetting env. episode 6915, reward total was -13.0. running mean: -14.055830346672533, timestamp: 2022-08-20 11:33:10.178492\n",
      "resetting env. episode 6916, reward total was -16.0. running mean: -14.075272043205807, timestamp: 2022-08-20 11:33:13.722535\n",
      "resetting env. episode 6917, reward total was -16.0. running mean: -14.094519322773749, timestamp: 2022-08-20 11:33:17.566582\n",
      "resetting env. episode 6918, reward total was -18.0. running mean: -14.13357412954601, timestamp: 2022-08-20 11:33:22.264633\n",
      "resetting env. episode 6919, reward total was -17.0. running mean: -14.16223838825055, timestamp: 2022-08-20 11:33:26.740686\n",
      "resetting env. episode 6920, reward total was -14.0. running mean: -14.160616004368045, timestamp: 2022-08-20 11:33:31.607742\n",
      "resetting env. episode 6921, reward total was -18.0. running mean: -14.199009844324364, timestamp: 2022-08-20 11:33:34.118773\n",
      "resetting env. episode 6922, reward total was -21.0. running mean: -14.26701974588112, timestamp: 2022-08-20 11:33:38.554823\n",
      "resetting env. episode 6923, reward total was -15.0. running mean: -14.27434954842231, timestamp: 2022-08-20 11:33:42.976398\n",
      "resetting env. episode 6924, reward total was -8.0. running mean: -14.211606052938086, timestamp: 2022-08-20 11:33:49.621477\n",
      "resetting env. episode 6925, reward total was -13.0. running mean: -14.199489992408706, timestamp: 2022-08-20 11:33:53.931521\n",
      "resetting env. episode 6926, reward total was -13.0. running mean: -14.18749509248462, timestamp: 2022-08-20 11:33:58.833625\n",
      "resetting env. episode 6927, reward total was -14.0. running mean: -14.185620141559774, timestamp: 2022-08-20 11:34:04.679692\n",
      "resetting env. episode 6928, reward total was -15.0. running mean: -14.193763940144176, timestamp: 2022-08-20 11:34:09.476747\n",
      "resetting env. episode 6929, reward total was -15.0. running mean: -14.201826300742734, timestamp: 2022-08-20 11:34:13.916800\n",
      "resetting env. episode 6930, reward total was -15.0. running mean: -14.209808037735307, timestamp: 2022-08-20 11:34:18.692376\n",
      "resetting env. episode 6931, reward total was -19.0. running mean: -14.257709957357953, timestamp: 2022-08-20 11:34:22.318416\n",
      "resetting env. episode 6932, reward total was -15.0. running mean: -14.265132857784375, timestamp: 2022-08-20 11:34:27.254472\n",
      "resetting env. episode 6933, reward total was -11.0. running mean: -14.232481529206531, timestamp: 2022-08-20 11:34:32.813539\n",
      "resetting env. episode 6934, reward total was -17.0. running mean: -14.260156713914466, timestamp: 2022-08-20 11:34:35.623573\n",
      "resetting env. episode 6935, reward total was -13.0. running mean: -14.247555146775321, timestamp: 2022-08-20 11:34:40.440628\n",
      "resetting env. episode 6936, reward total was -15.0. running mean: -14.255079595307569, timestamp: 2022-08-20 11:34:45.010678\n",
      "resetting env. episode 6937, reward total was -17.0. running mean: -14.282528799354493, timestamp: 2022-08-20 11:34:48.832724\n",
      "resetting env. episode 6938, reward total was -16.0. running mean: -14.299703511360947, timestamp: 2022-08-20 11:34:53.714779\n",
      "resetting env. episode 6939, reward total was -10.0. running mean: -14.256706476247338, timestamp: 2022-08-20 11:34:59.627375\n",
      "resetting env. episode 6940, reward total was -15.0. running mean: -14.264139411484864, timestamp: 2022-08-20 11:35:04.038425\n",
      "resetting env. episode 6941, reward total was -16.0. running mean: -14.281498017370016, timestamp: 2022-08-20 11:35:07.898469\n",
      "resetting env. episode 6942, reward total was -18.0. running mean: -14.318683037196315, timestamp: 2022-08-20 11:35:11.521509\n",
      "resetting env. episode 6943, reward total was -15.0. running mean: -14.325496206824353, timestamp: 2022-08-20 11:35:16.111560\n",
      "resetting env. episode 6944, reward total was -18.0. running mean: -14.362241244756108, timestamp: 2022-08-20 11:35:20.923619\n",
      "resetting env. episode 6945, reward total was -14.0. running mean: -14.358618832308547, timestamp: 2022-08-20 11:35:25.807674\n",
      "resetting env. episode 6946, reward total was -7.0. running mean: -14.285032643985462, timestamp: 2022-08-20 11:35:31.862745\n",
      "resetting env. episode 6947, reward total was -16.0. running mean: -14.302182317545608, timestamp: 2022-08-20 11:35:37.207804\n",
      "resetting env. episode 6948, reward total was -18.0. running mean: -14.339160494370152, timestamp: 2022-08-20 11:35:40.581848\n",
      "resetting env. episode 6949, reward total was -13.0. running mean: -14.32576888942645, timestamp: 2022-08-20 11:35:44.825891\n",
      "resetting env. episode 6950, reward total was -14.0. running mean: -14.322511200532187, timestamp: 2022-08-20 11:35:50.011950\n",
      "resetting env. episode 6951, reward total was -17.0. running mean: -14.349286088526865, timestamp: 2022-08-20 11:35:52.992031\n",
      "resetting env. episode 6952, reward total was -15.0. running mean: -14.355793227641596, timestamp: 2022-08-20 11:35:58.779621\n",
      "resetting env. episode 6953, reward total was -14.0. running mean: -14.352235295365181, timestamp: 2022-08-20 11:36:02.578670\n",
      "resetting env. episode 6954, reward total was -18.0. running mean: -14.38871294241153, timestamp: 2022-08-20 11:36:06.391711\n",
      "resetting env. episode 6955, reward total was -13.0. running mean: -14.374825812987416, timestamp: 2022-08-20 11:36:11.371771\n",
      "resetting env. episode 6956, reward total was -12.0. running mean: -14.351077554857541, timestamp: 2022-08-20 11:36:15.747816\n",
      "resetting env. episode 6957, reward total was -17.0. running mean: -14.377566779308966, timestamp: 2022-08-20 11:36:19.090854\n",
      "resetting env. episode 6958, reward total was -19.0. running mean: -14.423791111515875, timestamp: 2022-08-20 11:36:23.973910\n",
      "resetting env. episode 6959, reward total was -14.0. running mean: -14.419553200400717, timestamp: 2022-08-20 11:36:29.522975\n",
      "resetting env. episode 6960, reward total was -17.0. running mean: -14.44535766839671, timestamp: 2022-08-20 11:36:33.981025\n",
      "resetting env. episode 6961, reward total was -13.0. running mean: -14.430904091712744, timestamp: 2022-08-20 11:36:37.952072\n",
      "resetting env. episode 6962, reward total was -15.0. running mean: -14.436595050795617, timestamp: 2022-08-20 11:36:43.905139\n",
      "resetting env. episode 6963, reward total was -19.0. running mean: -14.482229100287661, timestamp: 2022-08-20 11:36:48.413195\n",
      "resetting env. episode 6964, reward total was -19.0. running mean: -14.527406809284784, timestamp: 2022-08-20 11:36:51.725229\n",
      "resetting env. episode 6965, reward total was -15.0. running mean: -14.532132741191937, timestamp: 2022-08-20 11:36:55.431276\n",
      "resetting env. episode 6966, reward total was -17.0. running mean: -14.556811413780018, timestamp: 2022-08-20 11:36:59.567323\n",
      "resetting env. episode 6967, reward total was -13.0. running mean: -14.541243299642218, timestamp: 2022-08-20 11:37:05.056382\n",
      "resetting env. episode 6968, reward total was -19.0. running mean: -14.585830866645795, timestamp: 2022-08-20 11:37:07.707414\n",
      "resetting env. episode 6969, reward total was -16.0. running mean: -14.599972557979337, timestamp: 2022-08-20 11:37:11.340455\n",
      "resetting env. episode 6970, reward total was -8.0. running mean: -14.533972832399543, timestamp: 2022-08-20 11:37:17.048522\n",
      "resetting env. episode 6971, reward total was -11.0. running mean: -14.498633104075548, timestamp: 2022-08-20 11:37:22.320585\n",
      "resetting env. episode 6972, reward total was -14.0. running mean: -14.493646773034794, timestamp: 2022-08-20 11:37:27.826646\n",
      "resetting env. episode 6973, reward total was -13.0. running mean: -14.478710305304446, timestamp: 2022-08-20 11:37:32.871703\n",
      "resetting env. episode 6974, reward total was -11.0. running mean: -14.443923202251401, timestamp: 2022-08-20 11:37:38.205763\n",
      "resetting env. episode 6975, reward total was -14.0. running mean: -14.439483970228888, timestamp: 2022-08-20 11:37:42.082810\n",
      "resetting env. episode 6976, reward total was -8.0. running mean: -14.3750891305266, timestamp: 2022-08-20 11:37:49.035894\n",
      "resetting env. episode 6977, reward total was -20.0. running mean: -14.431338239221333, timestamp: 2022-08-20 11:37:53.128941\n",
      "resetting env. episode 6978, reward total was -14.0. running mean: -14.427024856829119, timestamp: 2022-08-20 11:37:58.198995\n",
      "resetting env. episode 6979, reward total was -17.0. running mean: -14.452754608260827, timestamp: 2022-08-20 11:38:02.125040\n",
      "resetting env. episode 6980, reward total was -14.0. running mean: -14.44822706217822, timestamp: 2022-08-20 11:38:06.543612\n",
      "resetting env. episode 6981, reward total was -7.0. running mean: -14.373744791556437, timestamp: 2022-08-20 11:38:12.703681\n",
      "resetting env. episode 6982, reward total was -15.0. running mean: -14.380007343640873, timestamp: 2022-08-20 11:38:16.976731\n",
      "resetting env. episode 6983, reward total was -4.0. running mean: -14.276207270204463, timestamp: 2022-08-20 11:38:24.780820\n",
      "resetting env. episode 6984, reward total was -20.0. running mean: -14.333445197502417, timestamp: 2022-08-20 11:38:28.416862\n",
      "resetting env. episode 6985, reward total was -14.0. running mean: -14.330110745527394, timestamp: 2022-08-20 11:38:32.866915\n",
      "resetting env. episode 6986, reward total was -17.0. running mean: -14.35680963807212, timestamp: 2022-08-20 11:38:36.925960\n",
      "resetting env. episode 6987, reward total was -11.0. running mean: -14.323241541691397, timestamp: 2022-08-20 11:38:42.302022\n",
      "resetting env. episode 6988, reward total was -15.0. running mean: -14.330009126274483, timestamp: 2022-08-20 11:38:45.957065\n",
      "resetting env. episode 6989, reward total was -9.0. running mean: -14.276709035011738, timestamp: 2022-08-20 11:38:50.940122\n",
      "resetting env. episode 6990, reward total was -15.0. running mean: -14.28394194466162, timestamp: 2022-08-20 11:38:55.462170\n",
      "resetting env. episode 6991, reward total was -13.0. running mean: -14.271102525215005, timestamp: 2022-08-20 11:39:00.692231\n",
      "resetting env. episode 6992, reward total was -10.0. running mean: -14.228391499962854, timestamp: 2022-08-20 11:39:06.254297\n",
      "resetting env. episode 6993, reward total was -15.0. running mean: -14.236107584963225, timestamp: 2022-08-20 11:39:11.094355\n",
      "resetting env. episode 6994, reward total was -13.0. running mean: -14.223746509113594, timestamp: 2022-08-20 11:39:16.674420\n",
      "resetting env. episode 6995, reward total was -17.0. running mean: -14.251509044022457, timestamp: 2022-08-20 11:39:20.221455\n",
      "resetting env. episode 6996, reward total was -21.0. running mean: -14.318993953582233, timestamp: 2022-08-20 11:39:23.493497\n",
      "resetting env. episode 6997, reward total was -13.0. running mean: -14.30580401404641, timestamp: 2022-08-20 11:39:27.709540\n",
      "resetting env. episode 6998, reward total was -16.0. running mean: -14.322745973905946, timestamp: 2022-08-20 11:39:32.865596\n",
      "resetting env. episode 6999, reward total was -15.0. running mean: -14.329518514166887, timestamp: 2022-08-20 11:39:36.875649\n",
      "resetting env. episode 7000, reward total was -10.0. running mean: -14.286223329025217, timestamp: 2022-08-20 11:39:42.918713\n",
      "resetting env. episode 7001, reward total was -13.0. running mean: -14.273361095734966, timestamp: 2022-08-20 11:39:47.701768\n",
      "resetting env. episode 7002, reward total was -13.0. running mean: -14.260627484777617, timestamp: 2022-08-20 11:39:51.577812\n",
      "resetting env. episode 7003, reward total was -14.0. running mean: -14.258021209929842, timestamp: 2022-08-20 11:39:56.593869\n",
      "resetting env. episode 7004, reward total was -13.0. running mean: -14.245440997830544, timestamp: 2022-08-20 11:40:01.039919\n",
      "resetting env. episode 7005, reward total was -5.0. running mean: -14.152986587852238, timestamp: 2022-08-20 11:40:07.381041\n",
      "resetting env. episode 7006, reward total was -8.0. running mean: -14.091456721973715, timestamp: 2022-08-20 11:40:12.313621\n",
      "resetting env. episode 7007, reward total was -2.0. running mean: -13.970542154753979, timestamp: 2022-08-20 11:40:18.926694\n",
      "resetting env. episode 7008, reward total was -18.0. running mean: -14.010836733206439, timestamp: 2022-08-20 11:40:22.955741\n",
      "resetting env. episode 7009, reward total was -19.0. running mean: -14.060728365874374, timestamp: 2022-08-20 11:40:26.949785\n",
      "resetting env. episode 7010, reward total was -16.0. running mean: -14.08012108221563, timestamp: 2022-08-20 11:40:30.766348\n",
      "resetting env. episode 7011, reward total was -15.0. running mean: -14.089319871393474, timestamp: 2022-08-20 11:40:34.387393\n",
      "resetting env. episode 7012, reward total was -18.0. running mean: -14.12842667267954, timestamp: 2022-08-20 11:40:38.009430\n",
      "resetting env. episode 7013, reward total was -19.0. running mean: -14.177142405952743, timestamp: 2022-08-20 11:40:40.791463\n",
      "resetting env. episode 7014, reward total was -7.0. running mean: -14.105370981893216, timestamp: 2022-08-20 11:40:46.402529\n",
      "resetting env. episode 7015, reward total was -17.0. running mean: -14.134317272074284, timestamp: 2022-08-20 11:40:49.837089\n",
      "resetting env. episode 7016, reward total was -12.0. running mean: -14.11297409935354, timestamp: 2022-08-20 11:40:55.026152\n",
      "resetting env. episode 7017, reward total was -14.0. running mean: -14.111844358360004, timestamp: 2022-08-20 11:41:00.036206\n",
      "resetting env. episode 7018, reward total was -15.0. running mean: -14.120725914776404, timestamp: 2022-08-20 11:41:04.608255\n",
      "resetting env. episode 7019, reward total was -14.0. running mean: -14.11951865562864, timestamp: 2022-08-20 11:41:07.860294\n",
      "resetting env. episode 7020, reward total was -7.0. running mean: -14.048323469072354, timestamp: 2022-08-20 11:41:16.294392\n",
      "resetting env. episode 7021, reward total was -11.0. running mean: -14.01784023438163, timestamp: 2022-08-20 11:41:21.877453\n",
      "resetting env. episode 7022, reward total was -19.0. running mean: -14.067661832037814, timestamp: 2022-08-20 11:41:26.053501\n",
      "resetting env. episode 7023, reward total was -17.0. running mean: -14.096985213717435, timestamp: 2022-08-20 11:41:29.999072\n",
      "resetting env. episode 7024, reward total was -16.0. running mean: -14.11601536158026, timestamp: 2022-08-20 11:41:33.883114\n",
      "resetting env. episode 7025, reward total was -12.0. running mean: -14.094855207964457, timestamp: 2022-08-20 11:41:38.204164\n",
      "resetting env. episode 7026, reward total was -19.0. running mean: -14.143906655884813, timestamp: 2022-08-20 11:41:41.426732\n",
      "resetting env. episode 7027, reward total was -16.0. running mean: -14.162467589325965, timestamp: 2022-08-20 11:41:46.183779\n",
      "resetting env. episode 7028, reward total was -12.0. running mean: -14.140842913432705, timestamp: 2022-08-20 11:41:51.362367\n",
      "resetting env. episode 7029, reward total was -17.0. running mean: -14.169434484298378, timestamp: 2022-08-20 11:41:55.657416\n",
      "resetting env. episode 7030, reward total was -20.0. running mean: -14.227740139455394, timestamp: 2022-08-20 11:41:58.902452\n",
      "resetting env. episode 7031, reward total was -17.0. running mean: -14.255462738060839, timestamp: 2022-08-20 11:42:02.985500\n",
      "resetting env. episode 7032, reward total was -8.0. running mean: -14.19290811068023, timestamp: 2022-08-20 11:42:09.211569\n",
      "resetting env. episode 7033, reward total was -17.0. running mean: -14.220979029573428, timestamp: 2022-08-20 11:42:12.803614\n",
      "resetting env. episode 7034, reward total was -14.0. running mean: -14.218769239277695, timestamp: 2022-08-20 11:42:17.417668\n",
      "resetting env. episode 7035, reward total was -12.0. running mean: -14.196581546884916, timestamp: 2022-08-20 11:42:22.021719\n",
      "resetting env. episode 7036, reward total was -10.0. running mean: -14.154615731416067, timestamp: 2022-08-20 11:42:26.876775\n",
      "resetting env. episode 7037, reward total was -13.0. running mean: -14.143069574101906, timestamp: 2022-08-20 11:42:31.760829\n",
      "resetting env. episode 7038, reward total was -9.0. running mean: -14.091638878360886, timestamp: 2022-08-20 11:42:36.736886\n",
      "resetting env. episode 7039, reward total was -7.0. running mean: -14.020722489577278, timestamp: 2022-08-20 11:42:41.903475\n",
      "resetting env. episode 7040, reward total was -12.0. running mean: -14.000515264681503, timestamp: 2022-08-20 11:42:46.501527\n",
      "resetting env. episode 7041, reward total was -16.0. running mean: -14.020510112034689, timestamp: 2022-08-20 11:42:50.476095\n",
      "resetting env. episode 7042, reward total was -19.0. running mean: -14.07030501091434, timestamp: 2022-08-20 11:42:53.368124\n",
      "resetting env. episode 7043, reward total was -17.0. running mean: -14.099601960805197, timestamp: 2022-08-20 11:42:57.734175\n",
      "resetting env. episode 7044, reward total was -18.0. running mean: -14.138605941197145, timestamp: 2022-08-20 11:43:01.000211\n",
      "resetting env. episode 7045, reward total was -15.0. running mean: -14.147219881785174, timestamp: 2022-08-20 11:43:04.436255\n",
      "resetting env. episode 7046, reward total was -13.0. running mean: -14.135747682967324, timestamp: 2022-08-20 11:43:08.619297\n",
      "resetting env. episode 7047, reward total was -20.0. running mean: -14.19439020613765, timestamp: 2022-08-20 11:43:11.059328\n",
      "resetting env. episode 7048, reward total was -18.0. running mean: -14.232446304076273, timestamp: 2022-08-20 11:43:14.416367\n",
      "resetting env. episode 7049, reward total was -18.0. running mean: -14.27012184103551, timestamp: 2022-08-20 11:43:17.696402\n",
      "resetting env. episode 7050, reward total was -12.0. running mean: -14.247420622625153, timestamp: 2022-08-20 11:43:21.913448\n",
      "resetting env. episode 7051, reward total was -17.0. running mean: -14.274946416398901, timestamp: 2022-08-20 11:43:25.639493\n",
      "resetting env. episode 7052, reward total was -14.0. running mean: -14.272196952234912, timestamp: 2022-08-20 11:43:29.001526\n",
      "resetting env. episode 7053, reward total was -19.0. running mean: -14.319474982712563, timestamp: 2022-08-20 11:43:32.005561\n",
      "resetting env. episode 7054, reward total was -17.0. running mean: -14.346280232885437, timestamp: 2022-08-20 11:43:36.005611\n",
      "resetting env. episode 7055, reward total was -18.0. running mean: -14.382817430556582, timestamp: 2022-08-20 11:43:39.660646\n",
      "resetting env. episode 7056, reward total was -13.0. running mean: -14.368989256251016, timestamp: 2022-08-20 11:43:44.287706\n",
      "resetting env. episode 7057, reward total was -18.0. running mean: -14.405299363688506, timestamp: 2022-08-20 11:43:48.218744\n",
      "resetting env. episode 7058, reward total was -12.0. running mean: -14.38124637005162, timestamp: 2022-08-20 11:43:52.280791\n",
      "resetting env. episode 7059, reward total was -15.0. running mean: -14.387433906351104, timestamp: 2022-08-20 11:43:56.934842\n",
      "resetting env. episode 7060, reward total was -17.0. running mean: -14.413559567287592, timestamp: 2022-08-20 11:44:01.357892\n",
      "resetting env. episode 7061, reward total was -12.0. running mean: -14.389423971614715, timestamp: 2022-08-20 11:44:05.361941\n",
      "resetting env. episode 7062, reward total was -13.0. running mean: -14.375529731898569, timestamp: 2022-08-20 11:44:09.663988\n",
      "resetting env. episode 7063, reward total was -15.0. running mean: -14.381774434579583, timestamp: 2022-08-20 11:44:15.235055\n",
      "resetting env. episode 7064, reward total was -15.0. running mean: -14.387956690233787, timestamp: 2022-08-20 11:44:20.438109\n",
      "resetting env. episode 7065, reward total was -18.0. running mean: -14.424077123331449, timestamp: 2022-08-20 11:44:24.017149\n",
      "resetting env. episode 7066, reward total was -5.0. running mean: -14.329836352098134, timestamp: 2022-08-20 11:44:29.216210\n",
      "resetting env. episode 7067, reward total was -15.0. running mean: -14.336537988577152, timestamp: 2022-08-20 11:44:32.368247\n",
      "resetting env. episode 7068, reward total was -16.0. running mean: -14.35317260869138, timestamp: 2022-08-20 11:44:36.594290\n",
      "resetting env. episode 7069, reward total was -19.0. running mean: -14.399640882604466, timestamp: 2022-08-20 11:44:40.365334\n",
      "resetting env. episode 7070, reward total was -11.0. running mean: -14.36564447377842, timestamp: 2022-08-20 11:44:44.991389\n",
      "resetting env. episode 7071, reward total was -20.0. running mean: -14.421988029040635, timestamp: 2022-08-20 11:44:48.292430\n",
      "resetting env. episode 7072, reward total was -13.0. running mean: -14.407768148750229, timestamp: 2022-08-20 11:44:53.072476\n",
      "resetting env. episode 7073, reward total was -15.0. running mean: -14.413690467262727, timestamp: 2022-08-20 11:44:56.985521\n",
      "resetting env. episode 7074, reward total was -16.0. running mean: -14.4295535625901, timestamp: 2022-08-20 11:45:00.833563\n",
      "resetting env. episode 7075, reward total was -14.0. running mean: -14.4252580269642, timestamp: 2022-08-20 11:45:04.648608\n",
      "resetting env. episode 7076, reward total was -15.0. running mean: -14.431005446694558, timestamp: 2022-08-20 11:45:08.929659\n",
      "resetting env. episode 7077, reward total was -19.0. running mean: -14.476695392227612, timestamp: 2022-08-20 11:45:12.516703\n",
      "resetting env. episode 7078, reward total was -17.0. running mean: -14.501928438305335, timestamp: 2022-08-20 11:45:16.581746\n",
      "resetting env. episode 7079, reward total was -16.0. running mean: -14.516909153922281, timestamp: 2022-08-20 11:45:20.354787\n",
      "resetting env. episode 7080, reward total was -12.0. running mean: -14.491740062383057, timestamp: 2022-08-20 11:45:25.089840\n",
      "resetting env. episode 7081, reward total was -17.0. running mean: -14.516822661759226, timestamp: 2022-08-20 11:45:28.735887\n",
      "resetting env. episode 7082, reward total was -18.0. running mean: -14.551654435141634, timestamp: 2022-08-20 11:45:31.878920\n",
      "resetting env. episode 7083, reward total was -18.0. running mean: -14.586137890790217, timestamp: 2022-08-20 11:45:35.474962\n",
      "resetting env. episode 7084, reward total was -16.0. running mean: -14.600276511882315, timestamp: 2022-08-20 11:45:39.636007\n",
      "resetting env. episode 7085, reward total was -17.0. running mean: -14.624273746763492, timestamp: 2022-08-20 11:45:43.602052\n",
      "resetting env. episode 7086, reward total was -9.0. running mean: -14.568031009295858, timestamp: 2022-08-20 11:45:48.202104\n",
      "resetting env. episode 7087, reward total was -17.0. running mean: -14.5923506992029, timestamp: 2022-08-20 11:45:51.906148\n",
      "resetting env. episode 7088, reward total was -21.0. running mean: -14.656427192210872, timestamp: 2022-08-20 11:45:54.915181\n",
      "resetting env. episode 7089, reward total was -20.0. running mean: -14.709862920288762, timestamp: 2022-08-20 11:45:58.084217\n",
      "resetting env. episode 7090, reward total was -15.0. running mean: -14.712764291085874, timestamp: 2022-08-20 11:46:02.641270\n",
      "resetting env. episode 7091, reward total was -18.0. running mean: -14.745636648175015, timestamp: 2022-08-20 11:46:06.203309\n",
      "resetting env. episode 7092, reward total was -17.0. running mean: -14.768180281693265, timestamp: 2022-08-20 11:46:09.701350\n",
      "resetting env. episode 7093, reward total was -19.0. running mean: -14.810498478876331, timestamp: 2022-08-20 11:46:13.298912\n",
      "resetting env. episode 7094, reward total was -14.0. running mean: -14.802393494087568, timestamp: 2022-08-20 11:46:17.595967\n",
      "resetting env. episode 7095, reward total was -13.0. running mean: -14.784369559146693, timestamp: 2022-08-20 11:46:22.736023\n",
      "resetting env. episode 7096, reward total was -12.0. running mean: -14.756525863555225, timestamp: 2022-08-20 11:46:26.958071\n",
      "resetting env. episode 7097, reward total was -16.0. running mean: -14.768960604919673, timestamp: 2022-08-20 11:46:31.203121\n",
      "resetting env. episode 7098, reward total was -17.0. running mean: -14.791270998870477, timestamp: 2022-08-20 11:46:34.349152\n",
      "resetting env. episode 7099, reward total was -17.0. running mean: -14.813358288881773, timestamp: 2022-08-20 11:46:37.878195\n",
      "resetting env. episode 7100, reward total was -17.0. running mean: -14.835224705992955, timestamp: 2022-08-20 11:46:42.704247\n",
      "resetting env. episode 7101, reward total was -15.0. running mean: -14.836872458933026, timestamp: 2022-08-20 11:46:46.948300\n",
      "resetting env. episode 7102, reward total was -15.0. running mean: -14.838503734343696, timestamp: 2022-08-20 11:46:52.008358\n",
      "resetting env. episode 7103, reward total was -11.0. running mean: -14.800118697000258, timestamp: 2022-08-20 11:46:57.933425\n",
      "resetting env. episode 7104, reward total was -16.0. running mean: -14.812117510030255, timestamp: 2022-08-20 11:47:03.138483\n",
      "resetting env. episode 7105, reward total was -11.0. running mean: -14.773996334929953, timestamp: 2022-08-20 11:47:09.533558\n",
      "resetting env. episode 7106, reward total was -15.0. running mean: -14.776256371580653, timestamp: 2022-08-20 11:47:13.746607\n",
      "resetting env. episode 7107, reward total was -13.0. running mean: -14.758493807864847, timestamp: 2022-08-20 11:47:18.730664\n",
      "resetting env. episode 7108, reward total was -13.0. running mean: -14.7409088697862, timestamp: 2022-08-20 11:47:24.296727\n",
      "resetting env. episode 7109, reward total was -11.0. running mean: -14.703499781088336, timestamp: 2022-08-20 11:47:28.011772\n",
      "resetting env. episode 7110, reward total was -18.0. running mean: -14.736464783277452, timestamp: 2022-08-20 11:47:33.292831\n",
      "resetting env. episode 7111, reward total was -6.0. running mean: -14.649100135444677, timestamp: 2022-08-20 11:47:38.835895\n",
      "resetting env. episode 7112, reward total was -17.0. running mean: -14.67260913409023, timestamp: 2022-08-20 11:47:42.481934\n",
      "resetting env. episode 7113, reward total was -14.0. running mean: -14.665883042749329, timestamp: 2022-08-20 11:47:46.363983\n",
      "resetting env. episode 7114, reward total was -20.0. running mean: -14.719224212321834, timestamp: 2022-08-20 11:47:49.986022\n",
      "resetting env. episode 7115, reward total was -14.0. running mean: -14.712031970198616, timestamp: 2022-08-20 11:47:54.767078\n",
      "resetting env. episode 7116, reward total was -19.0. running mean: -14.754911650496629, timestamp: 2022-08-20 11:47:58.394122\n",
      "resetting env. episode 7117, reward total was -17.0. running mean: -14.777362533991662, timestamp: 2022-08-20 11:48:03.309176\n",
      "resetting env. episode 7118, reward total was -12.0. running mean: -14.749588908651743, timestamp: 2022-08-20 11:48:07.678225\n",
      "resetting env. episode 7119, reward total was -15.0. running mean: -14.752093019565226, timestamp: 2022-08-20 11:48:11.383274\n",
      "resetting env. episode 7120, reward total was -10.0. running mean: -14.704572089369574, timestamp: 2022-08-20 11:48:16.510327\n",
      "resetting env. episode 7121, reward total was -13.0. running mean: -14.68752636847588, timestamp: 2022-08-20 11:48:20.823379\n",
      "resetting env. episode 7122, reward total was -14.0. running mean: -14.68065110479112, timestamp: 2022-08-20 11:48:24.982426\n",
      "resetting env. episode 7123, reward total was -15.0. running mean: -14.68384459374321, timestamp: 2022-08-20 11:48:29.440480\n",
      "resetting env. episode 7124, reward total was -8.0. running mean: -14.617006147805778, timestamp: 2022-08-20 11:48:34.851539\n",
      "resetting env. episode 7125, reward total was -15.0. running mean: -14.62083608632772, timestamp: 2022-08-20 11:48:39.009586\n",
      "resetting env. episode 7126, reward total was -9.0. running mean: -14.564627725464444, timestamp: 2022-08-20 11:48:43.659639\n",
      "resetting env. episode 7127, reward total was -19.0. running mean: -14.608981448209798, timestamp: 2022-08-20 11:48:46.861676\n",
      "resetting env. episode 7128, reward total was -18.0. running mean: -14.6428916337277, timestamp: 2022-08-20 11:48:50.148717\n",
      "resetting env. episode 7129, reward total was -16.0. running mean: -14.656462717390424, timestamp: 2022-08-20 11:48:54.583767\n",
      "resetting env. episode 7130, reward total was -20.0. running mean: -14.70989809021652, timestamp: 2022-08-20 11:48:57.426798\n",
      "resetting env. episode 7131, reward total was -20.0. running mean: -14.762799109314354, timestamp: 2022-08-20 11:49:00.204834\n",
      "resetting env. episode 7132, reward total was -19.0. running mean: -14.80517111822121, timestamp: 2022-08-20 11:49:03.387869\n",
      "resetting env. episode 7133, reward total was -16.0. running mean: -14.817119407038998, timestamp: 2022-08-20 11:49:06.667908\n",
      "resetting env. episode 7134, reward total was -17.0. running mean: -14.838948212968608, timestamp: 2022-08-20 11:49:09.919943\n",
      "resetting env. episode 7135, reward total was -20.0. running mean: -14.890558730838922, timestamp: 2022-08-20 11:49:12.646978\n",
      "resetting env. episode 7136, reward total was -19.0. running mean: -14.931653143530532, timestamp: 2022-08-20 11:49:15.988012\n",
      "resetting env. episode 7137, reward total was -18.0. running mean: -14.962336612095227, timestamp: 2022-08-20 11:49:20.215058\n",
      "resetting env. episode 7138, reward total was -17.0. running mean: -14.982713245974274, timestamp: 2022-08-20 11:49:23.174093\n",
      "resetting env. episode 7139, reward total was -21.0. running mean: -15.042886113514532, timestamp: 2022-08-20 11:49:26.597137\n",
      "resetting env. episode 7140, reward total was -15.0. running mean: -15.042457252379387, timestamp: 2022-08-20 11:49:30.290174\n",
      "resetting env. episode 7141, reward total was -16.0. running mean: -15.052032679855593, timestamp: 2022-08-20 11:49:34.459225\n",
      "resetting env. episode 7142, reward total was -15.0. running mean: -15.051512353057037, timestamp: 2022-08-20 11:49:38.092267\n",
      "resetting env. episode 7143, reward total was -12.0. running mean: -15.020997229526465, timestamp: 2022-08-20 11:49:42.571316\n",
      "resetting env. episode 7144, reward total was -15.0. running mean: -15.0207872572312, timestamp: 2022-08-20 11:49:47.190369\n",
      "resetting env. episode 7145, reward total was -11.0. running mean: -14.980579384658888, timestamp: 2022-08-20 11:49:52.669433\n",
      "resetting env. episode 7146, reward total was -15.0. running mean: -14.9807735908123, timestamp: 2022-08-20 11:49:57.304486\n",
      "resetting env. episode 7147, reward total was -15.0. running mean: -14.980965854904177, timestamp: 2022-08-20 11:50:01.167531\n",
      "resetting env. episode 7148, reward total was -12.0. running mean: -14.951156196355134, timestamp: 2022-08-20 11:50:06.154587\n",
      "resetting env. episode 7149, reward total was -19.0. running mean: -14.991644634391582, timestamp: 2022-08-20 11:50:09.745633\n",
      "resetting env. episode 7150, reward total was -15.0. running mean: -14.991728188047666, timestamp: 2022-08-20 11:50:13.358669\n",
      "resetting env. episode 7151, reward total was -13.0. running mean: -14.97181090616719, timestamp: 2022-08-20 11:50:17.438717\n",
      "resetting env. episode 7152, reward total was -14.0. running mean: -14.96209279710552, timestamp: 2022-08-20 11:50:21.850771\n",
      "resetting env. episode 7153, reward total was -17.0. running mean: -14.982471869134464, timestamp: 2022-08-20 11:50:25.246807\n",
      "resetting env. episode 7154, reward total was -17.0. running mean: -15.002647150443119, timestamp: 2022-08-20 11:50:28.614848\n",
      "resetting env. episode 7155, reward total was -13.0. running mean: -14.982620678938689, timestamp: 2022-08-20 11:50:33.296901\n",
      "resetting env. episode 7156, reward total was -11.0. running mean: -14.942794472149302, timestamp: 2022-08-20 11:50:37.463949\n",
      "resetting env. episode 7157, reward total was -15.0. running mean: -14.94336652742781, timestamp: 2022-08-20 11:50:41.179993\n",
      "resetting env. episode 7158, reward total was -16.0. running mean: -14.95393286215353, timestamp: 2022-08-20 11:50:45.133036\n",
      "resetting env. episode 7159, reward total was -14.0. running mean: -14.944393533531995, timestamp: 2022-08-20 11:50:48.802078\n",
      "resetting env. episode 7160, reward total was -15.0. running mean: -14.944949598196676, timestamp: 2022-08-20 11:50:52.468121\n",
      "resetting env. episode 7161, reward total was -20.0. running mean: -14.995500102214708, timestamp: 2022-08-20 11:50:55.579157\n",
      "resetting env. episode 7162, reward total was -16.0. running mean: -15.00554510119256, timestamp: 2022-08-20 11:50:59.054199\n",
      "resetting env. episode 7163, reward total was -17.0. running mean: -15.025489650180633, timestamp: 2022-08-20 11:51:02.604239\n",
      "resetting env. episode 7164, reward total was -11.0. running mean: -14.985234753678826, timestamp: 2022-08-20 11:51:06.594286\n",
      "resetting env. episode 7165, reward total was -15.0. running mean: -14.985382406142039, timestamp: 2022-08-20 11:51:10.664329\n",
      "resetting env. episode 7166, reward total was -8.0. running mean: -14.915528582080618, timestamp: 2022-08-20 11:51:16.110393\n",
      "resetting env. episode 7167, reward total was -13.0. running mean: -14.896373296259814, timestamp: 2022-08-20 11:51:20.405447\n",
      "resetting env. episode 7168, reward total was -15.0. running mean: -14.897409563297217, timestamp: 2022-08-20 11:51:23.776481\n",
      "resetting env. episode 7169, reward total was -20.0. running mean: -14.948435467664243, timestamp: 2022-08-20 11:51:26.872518\n",
      "resetting env. episode 7170, reward total was -19.0. running mean: -14.9889511129876, timestamp: 2022-08-20 11:51:30.059555\n",
      "resetting env. episode 7171, reward total was -15.0. running mean: -14.989061601857724, timestamp: 2022-08-20 11:51:33.957602\n",
      "resetting env. episode 7172, reward total was -11.0. running mean: -14.949170985839146, timestamp: 2022-08-20 11:51:38.519653\n",
      "resetting env. episode 7173, reward total was -15.0. running mean: -14.949679275980754, timestamp: 2022-08-20 11:51:43.441711\n",
      "resetting env. episode 7174, reward total was -16.0. running mean: -14.960182483220947, timestamp: 2022-08-20 11:51:47.112750\n",
      "resetting env. episode 7175, reward total was -15.0. running mean: -14.960580658388738, timestamp: 2022-08-20 11:51:52.207808\n",
      "resetting env. episode 7176, reward total was -16.0. running mean: -14.97097485180485, timestamp: 2022-08-20 11:51:55.934853\n",
      "resetting env. episode 7177, reward total was -16.0. running mean: -14.981265103286802, timestamp: 2022-08-20 11:51:59.905896\n",
      "resetting env. episode 7178, reward total was -13.0. running mean: -14.961452452253935, timestamp: 2022-08-20 11:52:04.486952\n",
      "resetting env. episode 7179, reward total was -14.0. running mean: -14.951837927731397, timestamp: 2022-08-20 11:52:08.090989\n",
      "resetting env. episode 7180, reward total was -5.0. running mean: -14.852319548454084, timestamp: 2022-08-20 11:52:13.902058\n",
      "resetting env. episode 7181, reward total was -12.0. running mean: -14.823796352969541, timestamp: 2022-08-20 11:52:19.108116\n",
      "resetting env. episode 7182, reward total was -15.0. running mean: -14.825558389439847, timestamp: 2022-08-20 11:52:23.218166\n",
      "resetting env. episode 7183, reward total was -10.0. running mean: -14.777302805545448, timestamp: 2022-08-20 11:52:27.880219\n",
      "resetting env. episode 7184, reward total was -15.0. running mean: -14.779529777489994, timestamp: 2022-08-20 11:52:32.197269\n",
      "resetting env. episode 7185, reward total was -15.0. running mean: -14.781734479715094, timestamp: 2022-08-20 11:52:36.738321\n",
      "resetting env. episode 7186, reward total was -12.0. running mean: -14.753917134917943, timestamp: 2022-08-20 11:52:41.937380\n",
      "resetting env. episode 7187, reward total was -17.0. running mean: -14.776377963568763, timestamp: 2022-08-20 11:52:45.209417\n",
      "resetting env. episode 7188, reward total was -10.0. running mean: -14.728614183933075, timestamp: 2022-08-20 11:52:51.278489\n",
      "resetting env. episode 7189, reward total was -15.0. running mean: -14.731328042093745, timestamp: 2022-08-20 11:52:55.578537\n",
      "resetting env. episode 7190, reward total was -19.0. running mean: -14.774014761672808, timestamp: 2022-08-20 11:52:59.414582\n",
      "resetting env. episode 7191, reward total was -15.0. running mean: -14.77627461405608, timestamp: 2022-08-20 11:53:04.427639\n",
      "resetting env. episode 7192, reward total was -15.0. running mean: -14.778511867915519, timestamp: 2022-08-20 11:53:09.693699\n",
      "resetting env. episode 7193, reward total was -18.0. running mean: -14.810726749236363, timestamp: 2022-08-20 11:53:12.897734\n",
      "resetting env. episode 7194, reward total was -13.0. running mean: -14.792619481744, timestamp: 2022-08-20 11:53:17.432787\n",
      "resetting env. episode 7195, reward total was -10.0. running mean: -14.744693286926559, timestamp: 2022-08-20 11:53:22.524848\n",
      "resetting env. episode 7196, reward total was -12.0. running mean: -14.717246354057293, timestamp: 2022-08-20 11:53:26.839902\n",
      "resetting env. episode 7197, reward total was -12.0. running mean: -14.69007389051672, timestamp: 2022-08-20 11:53:32.068955\n",
      "resetting env. episode 7198, reward total was -12.0. running mean: -14.663173151611552, timestamp: 2022-08-20 11:53:38.200027\n",
      "resetting env. episode 7199, reward total was -14.0. running mean: -14.656541420095436, timestamp: 2022-08-20 11:53:43.924094\n",
      "resetting env. episode 7200, reward total was -19.0. running mean: -14.69997600589448, timestamp: 2022-08-20 11:53:48.665149\n",
      "resetting env. episode 7201, reward total was -5.0. running mean: -14.602976245835537, timestamp: 2022-08-20 11:53:54.332211\n",
      "resetting env. episode 7202, reward total was -5.0. running mean: -14.506946483377183, timestamp: 2022-08-20 11:54:00.739288\n",
      "resetting env. episode 7203, reward total was -11.0. running mean: -14.47187701854341, timestamp: 2022-08-20 11:54:05.909345\n",
      "resetting env. episode 7204, reward total was -15.0. running mean: -14.477158248357975, timestamp: 2022-08-20 11:54:10.972406\n",
      "resetting env. episode 7205, reward total was -14.0. running mean: -14.472386665874396, timestamp: 2022-08-20 11:54:16.010460\n",
      "resetting env. episode 7206, reward total was -17.0. running mean: -14.497662799215652, timestamp: 2022-08-20 11:54:20.115509\n",
      "resetting env. episode 7207, reward total was -15.0. running mean: -14.502686171223496, timestamp: 2022-08-20 11:54:24.575564\n",
      "resetting env. episode 7208, reward total was -18.0. running mean: -14.53765930951126, timestamp: 2022-08-20 11:54:27.785597\n",
      "resetting env. episode 7209, reward total was -15.0. running mean: -14.542282716416148, timestamp: 2022-08-20 11:54:32.052646\n",
      "resetting env. episode 7210, reward total was -12.0. running mean: -14.516859889251986, timestamp: 2022-08-20 11:54:36.217694\n",
      "resetting env. episode 7211, reward total was -18.0. running mean: -14.551691290359466, timestamp: 2022-08-20 11:54:39.854736\n",
      "resetting env. episode 7212, reward total was -13.0. running mean: -14.536174377455872, timestamp: 2022-08-20 11:54:45.735805\n",
      "resetting env. episode 7213, reward total was -17.0. running mean: -14.560812633681312, timestamp: 2022-08-20 11:54:49.532847\n",
      "resetting env. episode 7214, reward total was -16.0. running mean: -14.575204507344498, timestamp: 2022-08-20 11:54:52.951889\n",
      "resetting env. episode 7215, reward total was -5.0. running mean: -14.479452462271054, timestamp: 2022-08-20 11:54:59.490967\n",
      "resetting env. episode 7216, reward total was -18.0. running mean: -14.514657937648343, timestamp: 2022-08-20 11:55:03.741011\n",
      "resetting env. episode 7217, reward total was -16.0. running mean: -14.52951135827186, timestamp: 2022-08-20 11:55:07.437052\n",
      "resetting env. episode 7218, reward total was -19.0. running mean: -14.57421624468914, timestamp: 2022-08-20 11:55:11.624100\n",
      "resetting env. episode 7219, reward total was -15.0. running mean: -14.578474082242248, timestamp: 2022-08-20 11:55:15.109144\n",
      "resetting env. episode 7220, reward total was -11.0. running mean: -14.542689341419825, timestamp: 2022-08-20 11:55:20.213200\n",
      "resetting env. episode 7221, reward total was -15.0. running mean: -14.547262448005627, timestamp: 2022-08-20 11:55:24.399248\n",
      "resetting env. episode 7222, reward total was -9.0. running mean: -14.49178982352557, timestamp: 2022-08-20 11:55:29.895312\n",
      "resetting env. episode 7223, reward total was -15.0. running mean: -14.496871925290314, timestamp: 2022-08-20 11:55:33.964359\n",
      "resetting env. episode 7224, reward total was -12.0. running mean: -14.47190320603741, timestamp: 2022-08-20 11:55:37.770413\n",
      "resetting env. episode 7225, reward total was -14.0. running mean: -14.467184173977037, timestamp: 2022-08-20 11:55:42.053457\n",
      "resetting env. episode 7226, reward total was -19.0. running mean: -14.512512332237266, timestamp: 2022-08-20 11:55:45.588490\n",
      "resetting env. episode 7227, reward total was -17.0. running mean: -14.537387208914893, timestamp: 2022-08-20 11:55:50.296546\n",
      "resetting env. episode 7228, reward total was -16.0. running mean: -14.552013336825745, timestamp: 2022-08-20 11:55:54.204596\n",
      "resetting env. episode 7229, reward total was -17.0. running mean: -14.576493203457487, timestamp: 2022-08-20 11:55:57.594635\n",
      "resetting env. episode 7230, reward total was -12.0. running mean: -14.55072827142291, timestamp: 2022-08-20 11:56:02.068679\n",
      "resetting env. episode 7231, reward total was -19.0. running mean: -14.59522098870868, timestamp: 2022-08-20 11:56:05.994729\n",
      "resetting env. episode 7232, reward total was -9.0. running mean: -14.539268778821594, timestamp: 2022-08-20 11:56:11.194787\n",
      "resetting env. episode 7233, reward total was -17.0. running mean: -14.563876091033377, timestamp: 2022-08-20 11:56:15.395830\n",
      "resetting env. episode 7234, reward total was -16.0. running mean: -14.578237330123043, timestamp: 2022-08-20 11:56:19.775882\n",
      "resetting env. episode 7235, reward total was -20.0. running mean: -14.632454956821812, timestamp: 2022-08-20 11:56:22.813916\n",
      "resetting env. episode 7236, reward total was -11.0. running mean: -14.596130407253593, timestamp: 2022-08-20 11:56:27.922974\n",
      "resetting env. episode 7237, reward total was -11.0. running mean: -14.560169103181057, timestamp: 2022-08-20 11:56:33.414037\n",
      "resetting env. episode 7238, reward total was -9.0. running mean: -14.504567412149246, timestamp: 2022-08-20 11:56:37.973090\n",
      "resetting env. episode 7239, reward total was -11.0. running mean: -14.469521738027753, timestamp: 2022-08-20 11:56:42.815145\n",
      "resetting env. episode 7240, reward total was -17.0. running mean: -14.494826520647475, timestamp: 2022-08-20 11:56:47.072191\n",
      "resetting env. episode 7241, reward total was -11.0. running mean: -14.459878255441, timestamp: 2022-08-20 11:56:51.618245\n",
      "resetting env. episode 7242, reward total was -17.0. running mean: -14.485279472886589, timestamp: 2022-08-20 11:56:55.495288\n",
      "resetting env. episode 7243, reward total was -20.0. running mean: -14.540426678157722, timestamp: 2022-08-20 11:56:58.658327\n",
      "resetting env. episode 7244, reward total was -15.0. running mean: -14.545022411376145, timestamp: 2022-08-20 11:57:03.055378\n",
      "resetting env. episode 7245, reward total was -17.0. running mean: -14.569572187262384, timestamp: 2022-08-20 11:57:07.852431\n",
      "resetting env. episode 7246, reward total was -15.0. running mean: -14.57387646538976, timestamp: 2022-08-20 11:57:11.132469\n",
      "resetting env. episode 7247, reward total was -14.0. running mean: -14.568137700735864, timestamp: 2022-08-20 11:57:15.928523\n",
      "resetting env. episode 7248, reward total was -18.0. running mean: -14.602456323728505, timestamp: 2022-08-20 11:57:19.000558\n",
      "resetting env. episode 7249, reward total was -12.0. running mean: -14.57643176049122, timestamp: 2022-08-20 11:57:23.741618\n",
      "resetting env. episode 7250, reward total was -13.0. running mean: -14.560667442886308, timestamp: 2022-08-20 11:57:28.590666\n",
      "resetting env. episode 7251, reward total was -13.0. running mean: -14.545060768457445, timestamp: 2022-08-20 11:57:33.480723\n",
      "resetting env. episode 7252, reward total was -16.0. running mean: -14.55961016077287, timestamp: 2022-08-20 11:57:39.007786\n",
      "resetting env. episode 7253, reward total was -21.0. running mean: -14.624014059165141, timestamp: 2022-08-20 11:57:42.867829\n",
      "resetting env. episode 7254, reward total was -19.0. running mean: -14.66777391857349, timestamp: 2022-08-20 11:57:46.144865\n",
      "resetting env. episode 7255, reward total was -18.0. running mean: -14.701096179387754, timestamp: 2022-08-20 11:57:50.350913\n",
      "resetting env. episode 7256, reward total was -16.0. running mean: -14.714085217593876, timestamp: 2022-08-20 11:57:53.802954\n",
      "resetting env. episode 7257, reward total was -14.0. running mean: -14.706944365417938, timestamp: 2022-08-20 11:57:58.012003\n",
      "resetting env. episode 7258, reward total was -16.0. running mean: -14.719874921763758, timestamp: 2022-08-20 11:58:02.662052\n",
      "resetting env. episode 7259, reward total was -16.0. running mean: -14.73267617254612, timestamp: 2022-08-20 11:58:06.446100\n",
      "resetting env. episode 7260, reward total was -17.0. running mean: -14.755349410820658, timestamp: 2022-08-20 11:58:11.050151\n",
      "resetting env. episode 7261, reward total was -19.0. running mean: -14.79779591671245, timestamp: 2022-08-20 11:58:15.587200\n",
      "resetting env. episode 7262, reward total was -15.0. running mean: -14.799817957545326, timestamp: 2022-08-20 11:58:20.218257\n",
      "resetting env. episode 7263, reward total was -16.0. running mean: -14.811819777969873, timestamp: 2022-08-20 11:58:24.054297\n",
      "resetting env. episode 7264, reward total was -16.0. running mean: -14.823701580190175, timestamp: 2022-08-20 11:58:27.841341\n",
      "resetting env. episode 7265, reward total was -15.0. running mean: -14.825464564388273, timestamp: 2022-08-20 11:58:31.288385\n",
      "resetting env. episode 7266, reward total was -15.0. running mean: -14.82720991874439, timestamp: 2022-08-20 11:58:35.611428\n",
      "resetting env. episode 7267, reward total was -17.0. running mean: -14.848937819556946, timestamp: 2022-08-20 11:58:39.000470\n",
      "resetting env. episode 7268, reward total was -18.0. running mean: -14.880448441361377, timestamp: 2022-08-20 11:58:42.760513\n",
      "resetting env. episode 7269, reward total was -16.0. running mean: -14.891643956947764, timestamp: 2022-08-20 11:58:47.344566\n",
      "resetting env. episode 7270, reward total was -19.0. running mean: -14.932727517378286, timestamp: 2022-08-20 11:58:50.554598\n",
      "resetting env. episode 7271, reward total was -18.0. running mean: -14.963400242204502, timestamp: 2022-08-20 11:58:53.815641\n",
      "resetting env. episode 7272, reward total was -9.0. running mean: -14.903766239782456, timestamp: 2022-08-20 11:58:58.704693\n",
      "resetting env. episode 7273, reward total was -14.0. running mean: -14.894728577384631, timestamp: 2022-08-20 11:59:02.627737\n",
      "resetting env. episode 7274, reward total was -15.0. running mean: -14.895781291610785, timestamp: 2022-08-20 11:59:06.207780\n",
      "resetting env. episode 7275, reward total was -14.0. running mean: -14.886823478694678, timestamp: 2022-08-20 11:59:11.999845\n",
      "resetting env. episode 7276, reward total was -14.0. running mean: -14.877955243907731, timestamp: 2022-08-20 11:59:16.245895\n",
      "resetting env. episode 7277, reward total was -11.0. running mean: -14.839175691468654, timestamp: 2022-08-20 11:59:20.598947\n",
      "resetting env. episode 7278, reward total was -17.0. running mean: -14.860783934553966, timestamp: 2022-08-20 11:59:25.202998\n",
      "resetting env. episode 7279, reward total was -12.0. running mean: -14.832176095208427, timestamp: 2022-08-20 11:59:29.782049\n",
      "resetting env. episode 7280, reward total was -15.0. running mean: -14.833854334256342, timestamp: 2022-08-20 11:59:33.389088\n",
      "resetting env. episode 7281, reward total was -19.0. running mean: -14.875515790913779, timestamp: 2022-08-20 11:59:36.579123\n",
      "resetting env. episode 7282, reward total was -18.0. running mean: -14.906760633004641, timestamp: 2022-08-20 11:59:41.024174\n",
      "resetting env. episode 7283, reward total was -16.0. running mean: -14.917693026674595, timestamp: 2022-08-20 11:59:44.872223\n",
      "resetting env. episode 7284, reward total was -17.0. running mean: -14.938516096407849, timestamp: 2022-08-20 11:59:48.349263\n",
      "resetting env. episode 7285, reward total was -11.0. running mean: -14.89913093544377, timestamp: 2022-08-20 11:59:53.300317\n",
      "resetting env. episode 7286, reward total was -3.0. running mean: -14.780139626089332, timestamp: 2022-08-20 12:00:00.878400\n",
      "resetting env. episode 7287, reward total was -16.0. running mean: -14.792338229828438, timestamp: 2022-08-20 12:00:04.663443\n",
      "resetting env. episode 7288, reward total was -17.0. running mean: -14.814414847530154, timestamp: 2022-08-20 12:00:09.249492\n",
      "resetting env. episode 7289, reward total was -15.0. running mean: -14.816270699054852, timestamp: 2022-08-20 12:00:12.569535\n",
      "resetting env. episode 7290, reward total was -12.0. running mean: -14.788107992064303, timestamp: 2022-08-20 12:00:16.910583\n",
      "resetting env. episode 7291, reward total was -18.0. running mean: -14.82022691214366, timestamp: 2022-08-20 12:00:20.747626\n",
      "resetting env. episode 7292, reward total was -18.0. running mean: -14.852024643022222, timestamp: 2022-08-20 12:00:25.476680\n",
      "resetting env. episode 7293, reward total was -17.0. running mean: -14.873504396592, timestamp: 2022-08-20 12:00:29.426723\n",
      "resetting env. episode 7294, reward total was -17.0. running mean: -14.89476935262608, timestamp: 2022-08-20 12:00:33.501770\n",
      "resetting env. episode 7295, reward total was -17.0. running mean: -14.91582165909982, timestamp: 2022-08-20 12:00:38.155822\n",
      "resetting env. episode 7296, reward total was -15.0. running mean: -14.916663442508822, timestamp: 2022-08-20 12:00:41.871862\n",
      "resetting env. episode 7297, reward total was -11.0. running mean: -14.877496808083734, timestamp: 2022-08-20 12:00:46.198917\n",
      "resetting env. episode 7298, reward total was -5.0. running mean: -14.778721840002897, timestamp: 2022-08-20 12:00:51.807979\n",
      "resetting env. episode 7299, reward total was -14.0. running mean: -14.770934621602867, timestamp: 2022-08-20 12:00:56.104027\n",
      "resetting env. episode 7300, reward total was -16.0. running mean: -14.783225275386839, timestamp: 2022-08-20 12:00:59.811065\n",
      "resetting env. episode 7301, reward total was -13.0. running mean: -14.76539302263297, timestamp: 2022-08-20 12:01:04.615119\n",
      "resetting env. episode 7302, reward total was -8.0. running mean: -14.697739092406641, timestamp: 2022-08-20 12:01:10.657191\n",
      "resetting env. episode 7303, reward total was -19.0. running mean: -14.740761701482574, timestamp: 2022-08-20 12:01:15.032239\n",
      "resetting env. episode 7304, reward total was -21.0. running mean: -14.803354084467749, timestamp: 2022-08-20 12:01:18.711280\n",
      "resetting env. episode 7305, reward total was -15.0. running mean: -14.805320543623072, timestamp: 2022-08-20 12:01:24.615348\n",
      "resetting env. episode 7306, reward total was -14.0. running mean: -14.797267338186842, timestamp: 2022-08-20 12:01:29.277403\n",
      "resetting env. episode 7307, reward total was -17.0. running mean: -14.819294664804973, timestamp: 2022-08-20 12:01:34.171454\n",
      "resetting env. episode 7308, reward total was -10.0. running mean: -14.771101718156922, timestamp: 2022-08-20 12:01:38.904508\n",
      "resetting env. episode 7309, reward total was -16.0. running mean: -14.783390700975353, timestamp: 2022-08-20 12:01:43.458561\n",
      "resetting env. episode 7310, reward total was -14.0. running mean: -14.7755567939656, timestamp: 2022-08-20 12:01:49.107623\n",
      "resetting env. episode 7311, reward total was -10.0. running mean: -14.727801226025944, timestamp: 2022-08-20 12:01:54.287682\n",
      "resetting env. episode 7312, reward total was -18.0. running mean: -14.760523213765683, timestamp: 2022-08-20 12:01:58.156727\n",
      "resetting env. episode 7313, reward total was -16.0. running mean: -14.772917981628026, timestamp: 2022-08-20 12:02:02.328775\n",
      "resetting env. episode 7314, reward total was -15.0. running mean: -14.775188801811746, timestamp: 2022-08-20 12:02:06.536823\n",
      "resetting env. episode 7315, reward total was -16.0. running mean: -14.787436913793629, timestamp: 2022-08-20 12:02:11.042872\n",
      "resetting env. episode 7316, reward total was -14.0. running mean: -14.779562544655693, timestamp: 2022-08-20 12:02:16.152932\n",
      "resetting env. episode 7317, reward total was -15.0. running mean: -14.781766919209137, timestamp: 2022-08-20 12:02:20.351976\n",
      "resetting env. episode 7318, reward total was -21.0. running mean: -14.843949250017046, timestamp: 2022-08-20 12:02:23.736016\n",
      "resetting env. episode 7319, reward total was -16.0. running mean: -14.855509757516876, timestamp: 2022-08-20 12:02:28.190070\n",
      "resetting env. episode 7320, reward total was -13.0. running mean: -14.836954659941707, timestamp: 2022-08-20 12:02:33.941133\n",
      "resetting env. episode 7321, reward total was -15.0. running mean: -14.83858511334229, timestamp: 2022-08-20 12:02:37.998183\n",
      "resetting env. episode 7322, reward total was -18.0. running mean: -14.870199262208867, timestamp: 2022-08-20 12:02:40.717211\n",
      "resetting env. episode 7323, reward total was -21.0. running mean: -14.93149726958678, timestamp: 2022-08-20 12:02:44.170248\n",
      "resetting env. episode 7324, reward total was -12.0. running mean: -14.902182296890912, timestamp: 2022-08-20 12:02:48.997316\n",
      "resetting env. episode 7325, reward total was -18.0. running mean: -14.933160473922003, timestamp: 2022-08-20 12:02:52.688346\n",
      "resetting env. episode 7326, reward total was -14.0. running mean: -14.923828869182783, timestamp: 2022-08-20 12:02:57.959406\n",
      "resetting env. episode 7327, reward total was -21.0. running mean: -14.984590580490956, timestamp: 2022-08-20 12:03:01.008441\n",
      "resetting env. episode 7328, reward total was -10.0. running mean: -14.934744674686046, timestamp: 2022-08-20 12:03:06.433503\n",
      "resetting env. episode 7329, reward total was -17.0. running mean: -14.955397227939185, timestamp: 2022-08-20 12:03:11.526065\n",
      "resetting env. episode 7330, reward total was -11.0. running mean: -14.915843255659793, timestamp: 2022-08-20 12:03:17.004122\n",
      "resetting env. episode 7331, reward total was -18.0. running mean: -14.946684823103194, timestamp: 2022-08-20 12:03:20.418160\n",
      "resetting env. episode 7332, reward total was -10.0. running mean: -14.897217974872161, timestamp: 2022-08-20 12:03:25.560222\n",
      "resetting env. episode 7333, reward total was -12.0. running mean: -14.868245795123439, timestamp: 2022-08-20 12:03:30.589276\n",
      "resetting env. episode 7334, reward total was -13.0. running mean: -14.849563337172205, timestamp: 2022-08-20 12:03:35.268337\n",
      "resetting env. episode 7335, reward total was -13.0. running mean: -14.831067703800484, timestamp: 2022-08-20 12:03:40.237396\n",
      "resetting env. episode 7336, reward total was -16.0. running mean: -14.842757026762479, timestamp: 2022-08-20 12:03:44.154445\n",
      "resetting env. episode 7337, reward total was -13.0. running mean: -14.824329456494855, timestamp: 2022-08-20 12:03:49.640506\n",
      "resetting env. episode 7338, reward total was -14.0. running mean: -14.816086161929906, timestamp: 2022-08-20 12:03:54.426559\n",
      "resetting env. episode 7339, reward total was -12.0. running mean: -14.787925300310606, timestamp: 2022-08-20 12:03:59.538619\n",
      "resetting env. episode 7340, reward total was -17.0. running mean: -14.8100460473075, timestamp: 2022-08-20 12:04:02.837653\n",
      "resetting env. episode 7341, reward total was -19.0. running mean: -14.851945586834423, timestamp: 2022-08-20 12:04:07.076706\n",
      "resetting env. episode 7342, reward total was -11.0. running mean: -14.813426130966079, timestamp: 2022-08-20 12:04:11.473755\n",
      "resetting env. episode 7343, reward total was -15.0. running mean: -14.815291869656418, timestamp: 2022-08-20 12:04:15.499798\n",
      "resetting env. episode 7344, reward total was -15.0. running mean: -14.817138950959855, timestamp: 2022-08-20 12:04:19.379842\n",
      "resetting env. episode 7345, reward total was -15.0. running mean: -14.818967561450256, timestamp: 2022-08-20 12:04:23.409895\n",
      "resetting env. episode 7346, reward total was -12.0. running mean: -14.790777885835752, timestamp: 2022-08-20 12:04:28.594948\n",
      "resetting env. episode 7347, reward total was -16.0. running mean: -14.802870106977394, timestamp: 2022-08-20 12:04:32.834998\n",
      "resetting env. episode 7348, reward total was -3.0. running mean: -14.684841405907619, timestamp: 2022-08-20 12:04:38.442066\n",
      "resetting env. episode 7349, reward total was -19.0. running mean: -14.727992991848541, timestamp: 2022-08-20 12:04:41.771100\n",
      "resetting env. episode 7350, reward total was -13.0. running mean: -14.710713061930056, timestamp: 2022-08-20 12:04:46.165150\n",
      "resetting env. episode 7351, reward total was -15.0. running mean: -14.713605931310756, timestamp: 2022-08-20 12:04:49.608189\n",
      "resetting env. episode 7352, reward total was -15.0. running mean: -14.71646987199765, timestamp: 2022-08-20 12:04:53.122234\n",
      "resetting env. episode 7353, reward total was -17.0. running mean: -14.739305173277673, timestamp: 2022-08-20 12:04:57.523287\n",
      "resetting env. episode 7354, reward total was -17.0. running mean: -14.761912121544896, timestamp: 2022-08-20 12:05:01.802333\n",
      "resetting env. episode 7355, reward total was -21.0. running mean: -14.824293000329448, timestamp: 2022-08-20 12:05:05.154369\n",
      "resetting env. episode 7356, reward total was -17.0. running mean: -14.846050070326152, timestamp: 2022-08-20 12:05:09.509420\n",
      "resetting env. episode 7357, reward total was -15.0. running mean: -14.84758956962289, timestamp: 2022-08-20 12:05:13.445468\n",
      "resetting env. episode 7358, reward total was -10.0. running mean: -14.79911367392666, timestamp: 2022-08-20 12:05:18.470525\n",
      "resetting env. episode 7359, reward total was -16.0. running mean: -14.811122537187394, timestamp: 2022-08-20 12:05:21.915564\n",
      "resetting env. episode 7360, reward total was -16.0. running mean: -14.82301131181552, timestamp: 2022-08-20 12:05:25.970611\n",
      "resetting env. episode 7361, reward total was -18.0. running mean: -14.854781198697365, timestamp: 2022-08-20 12:05:29.871654\n",
      "resetting env. episode 7362, reward total was -19.0. running mean: -14.89623338671039, timestamp: 2022-08-20 12:05:34.010704\n",
      "resetting env. episode 7363, reward total was -15.0. running mean: -14.897271052843287, timestamp: 2022-08-20 12:05:39.109760\n",
      "resetting env. episode 7364, reward total was -15.0. running mean: -14.898298342314854, timestamp: 2022-08-20 12:05:42.469799\n",
      "resetting env. episode 7365, reward total was -15.0. running mean: -14.899315358891705, timestamp: 2022-08-20 12:05:46.481847\n",
      "resetting env. episode 7366, reward total was -15.0. running mean: -14.900322205302789, timestamp: 2022-08-20 12:05:51.405905\n",
      "resetting env. episode 7367, reward total was -13.0. running mean: -14.881318983249761, timestamp: 2022-08-20 12:05:55.797951\n",
      "resetting env. episode 7368, reward total was -8.0. running mean: -14.812505793417264, timestamp: 2022-08-20 12:06:01.748021\n",
      "resetting env. episode 7369, reward total was -18.0. running mean: -14.84438073548309, timestamp: 2022-08-20 12:06:05.988073\n",
      "resetting env. episode 7370, reward total was -11.0. running mean: -14.80593692812826, timestamp: 2022-08-20 12:06:11.819136\n",
      "resetting env. episode 7371, reward total was -17.0. running mean: -14.827877558846977, timestamp: 2022-08-20 12:06:15.853184\n",
      "resetting env. episode 7372, reward total was -7.0. running mean: -14.749598783258508, timestamp: 2022-08-20 12:06:21.574254\n",
      "resetting env. episode 7373, reward total was -17.0. running mean: -14.772102795425923, timestamp: 2022-08-20 12:06:25.408292\n",
      "resetting env. episode 7374, reward total was -17.0. running mean: -14.794381767471663, timestamp: 2022-08-20 12:06:29.345336\n",
      "resetting env. episode 7375, reward total was -12.0. running mean: -14.766437949796945, timestamp: 2022-08-20 12:06:34.144393\n",
      "resetting env. episode 7376, reward total was -21.0. running mean: -14.828773570298976, timestamp: 2022-08-20 12:06:37.692436\n",
      "resetting env. episode 7377, reward total was -14.0. running mean: -14.820485834595987, timestamp: 2022-08-20 12:06:41.350478\n",
      "resetting env. episode 7378, reward total was -17.0. running mean: -14.842280976250027, timestamp: 2022-08-20 12:06:45.495525\n",
      "resetting env. episode 7379, reward total was -11.0. running mean: -14.803858166487526, timestamp: 2022-08-20 12:06:50.752586\n",
      "resetting env. episode 7380, reward total was -14.0. running mean: -14.79581958482265, timestamp: 2022-08-20 12:06:54.344623\n",
      "resetting env. episode 7381, reward total was -17.0. running mean: -14.817861388974423, timestamp: 2022-08-20 12:06:58.691674\n",
      "resetting env. episode 7382, reward total was -11.0. running mean: -14.779682775084678, timestamp: 2022-08-20 12:07:03.884735\n",
      "resetting env. episode 7383, reward total was -17.0. running mean: -14.801885947333831, timestamp: 2022-08-20 12:07:07.279776\n",
      "resetting env. episode 7384, reward total was -12.0. running mean: -14.773867087860491, timestamp: 2022-08-20 12:07:13.138844\n",
      "resetting env. episode 7385, reward total was -17.0. running mean: -14.796128416981887, timestamp: 2022-08-20 12:07:15.364868\n",
      "resetting env. episode 7386, reward total was -17.0. running mean: -14.818167132812068, timestamp: 2022-08-20 12:07:19.412916\n",
      "resetting env. episode 7387, reward total was -15.0. running mean: -14.819985461483947, timestamp: 2022-08-20 12:07:24.642975\n",
      "resetting env. episode 7388, reward total was -16.0. running mean: -14.831785606869108, timestamp: 2022-08-20 12:07:28.793022\n",
      "resetting env. episode 7389, reward total was -15.0. running mean: -14.833467750800416, timestamp: 2022-08-20 12:07:32.493068\n",
      "resetting env. episode 7390, reward total was -13.0. running mean: -14.815133073292413, timestamp: 2022-08-20 12:07:37.134119\n",
      "resetting env. episode 7391, reward total was -19.0. running mean: -14.856981742559489, timestamp: 2022-08-20 12:07:41.389167\n",
      "resetting env. episode 7392, reward total was -11.0. running mean: -14.818411925133892, timestamp: 2022-08-20 12:07:46.564226\n",
      "resetting env. episode 7393, reward total was -11.0. running mean: -14.780227805882554, timestamp: 2022-08-20 12:07:51.953289\n",
      "resetting env. episode 7394, reward total was -16.0. running mean: -14.792425527823728, timestamp: 2022-08-20 12:07:56.959345\n",
      "resetting env. episode 7395, reward total was -14.0. running mean: -14.78450127254549, timestamp: 2022-08-20 12:08:01.597398\n",
      "resetting env. episode 7396, reward total was -16.0. running mean: -14.796656259820036, timestamp: 2022-08-20 12:08:05.914450\n",
      "resetting env. episode 7397, reward total was -10.0. running mean: -14.748689697221835, timestamp: 2022-08-20 12:08:11.982518\n",
      "resetting env. episode 7398, reward total was -11.0. running mean: -14.711202800249616, timestamp: 2022-08-20 12:08:16.981576\n",
      "resetting env. episode 7399, reward total was -9.0. running mean: -14.65409077224712, timestamp: 2022-08-20 12:08:22.345636\n",
      "resetting env. episode 7400, reward total was -15.0. running mean: -14.657549864524649, timestamp: 2022-08-20 12:08:26.706687\n",
      "resetting env. episode 7401, reward total was -17.0. running mean: -14.680974365879402, timestamp: 2022-08-20 12:08:30.533732\n",
      "resetting env. episode 7402, reward total was -18.0. running mean: -14.714164622220608, timestamp: 2022-08-20 12:08:35.320792\n",
      "resetting env. episode 7403, reward total was -19.0. running mean: -14.757022975998401, timestamp: 2022-08-20 12:08:39.151833\n",
      "resetting env. episode 7404, reward total was -11.0. running mean: -14.719452746238417, timestamp: 2022-08-20 12:08:43.882885\n",
      "resetting env. episode 7405, reward total was -13.0. running mean: -14.702258218776034, timestamp: 2022-08-20 12:08:48.399939\n",
      "resetting env. episode 7406, reward total was -11.0. running mean: -14.665235636588273, timestamp: 2022-08-20 12:08:54.622012\n",
      "resetting env. episode 7407, reward total was -11.0. running mean: -14.62858328022239, timestamp: 2022-08-20 12:08:58.959060\n",
      "resetting env. episode 7408, reward total was -17.0. running mean: -14.652297447420166, timestamp: 2022-08-20 12:09:03.548115\n",
      "resetting env. episode 7409, reward total was -17.0. running mean: -14.675774472945964, timestamp: 2022-08-20 12:09:07.988163\n",
      "resetting env. episode 7410, reward total was -15.0. running mean: -14.679016728216505, timestamp: 2022-08-20 12:09:12.254214\n",
      "resetting env. episode 7411, reward total was -17.0. running mean: -14.70222656093434, timestamp: 2022-08-20 12:09:16.788264\n",
      "resetting env. episode 7412, reward total was -13.0. running mean: -14.685204295324997, timestamp: 2022-08-20 12:09:21.762320\n",
      "resetting env. episode 7413, reward total was -16.0. running mean: -14.698352252371746, timestamp: 2022-08-20 12:09:26.269374\n",
      "resetting env. episode 7414, reward total was -17.0. running mean: -14.72136872984803, timestamp: 2022-08-20 12:09:29.863414\n",
      "resetting env. episode 7415, reward total was -6.0. running mean: -14.63415504254955, timestamp: 2022-08-20 12:09:35.453481\n",
      "resetting env. episode 7416, reward total was -11.0. running mean: -14.597813492124054, timestamp: 2022-08-20 12:09:40.582540\n",
      "resetting env. episode 7417, reward total was -15.0. running mean: -14.601835357202814, timestamp: 2022-08-20 12:09:44.688584\n",
      "resetting env. episode 7418, reward total was -16.0. running mean: -14.615817003630786, timestamp: 2022-08-20 12:09:49.017636\n",
      "resetting env. episode 7419, reward total was -14.0. running mean: -14.609658833594478, timestamp: 2022-08-20 12:09:54.460700\n",
      "resetting env. episode 7420, reward total was -15.0. running mean: -14.613562245258533, timestamp: 2022-08-20 12:09:59.661758\n",
      "resetting env. episode 7421, reward total was -17.0. running mean: -14.637426622805949, timestamp: 2022-08-20 12:10:04.267813\n",
      "resetting env. episode 7422, reward total was -14.0. running mean: -14.63105235657789, timestamp: 2022-08-20 12:10:07.424849\n",
      "resetting env. episode 7423, reward total was -17.0. running mean: -14.65474183301211, timestamp: 2022-08-20 12:10:10.708884\n",
      "resetting env. episode 7424, reward total was -15.0. running mean: -14.65819441468199, timestamp: 2022-08-20 12:10:15.471938\n",
      "resetting env. episode 7425, reward total was -10.0. running mean: -14.611612470535169, timestamp: 2022-08-20 12:10:20.110992\n",
      "resetting env. episode 7426, reward total was -7.0. running mean: -14.535496345829818, timestamp: 2022-08-20 12:10:26.036062\n",
      "resetting env. episode 7427, reward total was -12.0. running mean: -14.510141382371518, timestamp: 2022-08-20 12:10:32.730136\n",
      "resetting env. episode 7428, reward total was -16.0. running mean: -14.525039968547803, timestamp: 2022-08-20 12:10:36.701184\n",
      "resetting env. episode 7429, reward total was -16.0. running mean: -14.539789568862325, timestamp: 2022-08-20 12:10:41.143237\n",
      "resetting env. episode 7430, reward total was -17.0. running mean: -14.564391673173702, timestamp: 2022-08-20 12:10:44.824274\n",
      "resetting env. episode 7431, reward total was -17.0. running mean: -14.588747756441965, timestamp: 2022-08-20 12:10:49.693332\n",
      "resetting env. episode 7432, reward total was -18.0. running mean: -14.622860278877544, timestamp: 2022-08-20 12:10:53.897381\n",
      "resetting env. episode 7433, reward total was -13.0. running mean: -14.606631676088769, timestamp: 2022-08-20 12:10:57.871425\n",
      "resetting env. episode 7434, reward total was -11.0. running mean: -14.570565359327881, timestamp: 2022-08-20 12:11:02.638479\n",
      "resetting env. episode 7435, reward total was -13.0. running mean: -14.554859705734604, timestamp: 2022-08-20 12:11:06.789527\n",
      "resetting env. episode 7436, reward total was -13.0. running mean: -14.539311108677259, timestamp: 2022-08-20 12:11:11.059575\n",
      "resetting env. episode 7437, reward total was -19.0. running mean: -14.583917997590486, timestamp: 2022-08-20 12:11:14.672620\n",
      "resetting env. episode 7438, reward total was -14.0. running mean: -14.578078817614582, timestamp: 2022-08-20 12:11:18.522660\n",
      "resetting env. episode 7439, reward total was -17.0. running mean: -14.602298029438435, timestamp: 2022-08-20 12:11:22.729710\n",
      "resetting env. episode 7440, reward total was -15.0. running mean: -14.60627504914405, timestamp: 2022-08-20 12:11:28.153769\n",
      "resetting env. episode 7441, reward total was -11.0. running mean: -14.57021229865261, timestamp: 2022-08-20 12:11:32.143818\n",
      "resetting env. episode 7442, reward total was -14.0. running mean: -14.564510175666085, timestamp: 2022-08-20 12:11:36.556874\n",
      "resetting env. episode 7443, reward total was -19.0. running mean: -14.608865073909422, timestamp: 2022-08-20 12:11:40.531912\n",
      "resetting env. episode 7444, reward total was -16.0. running mean: -14.622776423170329, timestamp: 2022-08-20 12:11:44.127954\n",
      "resetting env. episode 7445, reward total was -14.0. running mean: -14.616548658938626, timestamp: 2022-08-20 12:11:49.318011\n",
      "resetting env. episode 7446, reward total was -15.0. running mean: -14.620383172349241, timestamp: 2022-08-20 12:11:53.429065\n",
      "resetting env. episode 7447, reward total was -18.0. running mean: -14.654179340625749, timestamp: 2022-08-20 12:11:56.438103\n",
      "resetting env. episode 7448, reward total was -18.0. running mean: -14.687637547219492, timestamp: 2022-08-20 12:12:00.741143\n",
      "resetting env. episode 7449, reward total was -17.0. running mean: -14.710761171747297, timestamp: 2022-08-20 12:12:04.979192\n",
      "resetting env. episode 7450, reward total was -9.0. running mean: -14.653653560029824, timestamp: 2022-08-20 12:12:10.586252\n",
      "resetting env. episode 7451, reward total was -18.0. running mean: -14.687117024429526, timestamp: 2022-08-20 12:12:14.354297\n",
      "resetting env. episode 7452, reward total was -11.0. running mean: -14.65024585418523, timestamp: 2022-08-20 12:12:19.232353\n",
      "resetting env. episode 7453, reward total was -17.0. running mean: -14.673743395643376, timestamp: 2022-08-20 12:12:23.717404\n",
      "resetting env. episode 7454, reward total was -10.0. running mean: -14.627005961686942, timestamp: 2022-08-20 12:12:28.836463\n",
      "resetting env. episode 7455, reward total was -14.0. running mean: -14.620735902070074, timestamp: 2022-08-20 12:12:33.693518\n",
      "resetting env. episode 7456, reward total was -16.0. running mean: -14.634528543049372, timestamp: 2022-08-20 12:12:37.469562\n",
      "resetting env. episode 7457, reward total was -17.0. running mean: -14.658183257618878, timestamp: 2022-08-20 12:12:40.567598\n",
      "resetting env. episode 7458, reward total was -11.0. running mean: -14.62160142504269, timestamp: 2022-08-20 12:12:45.568652\n",
      "resetting env. episode 7459, reward total was -18.0. running mean: -14.655385410792261, timestamp: 2022-08-20 12:12:48.457684\n",
      "resetting env. episode 7460, reward total was -8.0. running mean: -14.588831556684339, timestamp: 2022-08-20 12:12:54.216751\n",
      "resetting env. episode 7461, reward total was -15.0. running mean: -14.592943241117496, timestamp: 2022-08-20 12:12:58.934807\n",
      "resetting env. episode 7462, reward total was -13.0. running mean: -14.57701380870632, timestamp: 2022-08-20 12:13:03.229856\n",
      "resetting env. episode 7463, reward total was -11.0. running mean: -14.541243670619256, timestamp: 2022-08-20 12:13:08.009912\n",
      "resetting env. episode 7464, reward total was -11.0. running mean: -14.505831233913062, timestamp: 2022-08-20 12:13:12.604962\n",
      "resetting env. episode 7465, reward total was -12.0. running mean: -14.48077292157393, timestamp: 2022-08-20 12:13:18.138026\n",
      "resetting env. episode 7466, reward total was -18.0. running mean: -14.515965192358191, timestamp: 2022-08-20 12:13:21.412061\n",
      "resetting env. episode 7467, reward total was -17.0. running mean: -14.54080554043461, timestamp: 2022-08-20 12:13:24.941104\n",
      "resetting env. episode 7468, reward total was -11.0. running mean: -14.505397485030263, timestamp: 2022-08-20 12:13:29.877160\n",
      "resetting env. episode 7469, reward total was -17.0. running mean: -14.53034351017996, timestamp: 2022-08-20 12:13:34.173212\n",
      "resetting env. episode 7470, reward total was -16.0. running mean: -14.54504007507816, timestamp: 2022-08-20 12:13:38.160257\n",
      "resetting env. episode 7471, reward total was -15.0. running mean: -14.549589674327379, timestamp: 2022-08-20 12:13:43.826317\n",
      "resetting env. episode 7472, reward total was -11.0. running mean: -14.514093777584105, timestamp: 2022-08-20 12:13:50.095389\n",
      "resetting env. episode 7473, reward total was -16.0. running mean: -14.528952839808264, timestamp: 2022-08-20 12:13:54.187435\n",
      "resetting env. episode 7474, reward total was -14.0. running mean: -14.523663311410182, timestamp: 2022-08-20 12:13:59.319493\n",
      "resetting env. episode 7475, reward total was -13.0. running mean: -14.50842667829608, timestamp: 2022-08-20 12:14:03.806547\n",
      "resetting env. episode 7476, reward total was -16.0. running mean: -14.52334241151312, timestamp: 2022-08-20 12:14:08.499599\n",
      "resetting env. episode 7477, reward total was -13.0. running mean: -14.50810898739799, timestamp: 2022-08-20 12:14:14.049667\n",
      "resetting env. episode 7478, reward total was -12.0. running mean: -14.483027897524009, timestamp: 2022-08-20 12:14:17.816705\n",
      "resetting env. episode 7479, reward total was -12.0. running mean: -14.458197618548768, timestamp: 2022-08-20 12:14:22.226755\n",
      "resetting env. episode 7480, reward total was -14.0. running mean: -14.45361564236328, timestamp: 2022-08-20 12:14:26.918807\n",
      "resetting env. episode 7481, reward total was -15.0. running mean: -14.459079485939647, timestamp: 2022-08-20 12:14:31.765865\n",
      "resetting env. episode 7482, reward total was -15.0. running mean: -14.46448869108025, timestamp: 2022-08-20 12:14:36.454923\n",
      "resetting env. episode 7483, reward total was -14.0. running mean: -14.459843804169449, timestamp: 2022-08-20 12:14:41.413978\n",
      "resetting env. episode 7484, reward total was -11.0. running mean: -14.425245366127754, timestamp: 2022-08-20 12:14:45.681025\n",
      "resetting env. episode 7485, reward total was -16.0. running mean: -14.440992912466477, timestamp: 2022-08-20 12:14:50.462079\n",
      "resetting env. episode 7486, reward total was -19.0. running mean: -14.486582983341812, timestamp: 2022-08-20 12:14:54.528121\n",
      "resetting env. episode 7487, reward total was -14.0. running mean: -14.481717153508393, timestamp: 2022-08-20 12:14:59.772184\n",
      "resetting env. episode 7488, reward total was -17.0. running mean: -14.506899981973309, timestamp: 2022-08-20 12:15:04.289234\n",
      "resetting env. episode 7489, reward total was -13.0. running mean: -14.491830982153576, timestamp: 2022-08-20 12:15:08.212279\n",
      "resetting env. episode 7490, reward total was -16.0. running mean: -14.50691267233204, timestamp: 2022-08-20 12:15:12.003321\n",
      "resetting env. episode 7491, reward total was -15.0. running mean: -14.51184354560872, timestamp: 2022-08-20 12:15:16.619374\n",
      "resetting env. episode 7492, reward total was -15.0. running mean: -14.516725110152633, timestamp: 2022-08-20 12:15:20.665431\n",
      "resetting env. episode 7493, reward total was -11.0. running mean: -14.481557859051106, timestamp: 2022-08-20 12:15:25.624478\n",
      "resetting env. episode 7494, reward total was -7.0. running mean: -14.406742280460595, timestamp: 2022-08-20 12:15:31.380546\n",
      "resetting env. episode 7495, reward total was -16.0. running mean: -14.42267485765599, timestamp: 2022-08-20 12:15:35.731590\n",
      "resetting env. episode 7496, reward total was -11.0. running mean: -14.388448109079429, timestamp: 2022-08-20 12:15:40.779648\n",
      "resetting env. episode 7497, reward total was -14.0. running mean: -14.384563627988635, timestamp: 2022-08-20 12:15:45.223703\n",
      "resetting env. episode 7498, reward total was -13.0. running mean: -14.37071799170875, timestamp: 2022-08-20 12:15:50.155755\n",
      "resetting env. episode 7499, reward total was -12.0. running mean: -14.34701081179166, timestamp: 2022-08-20 12:15:55.771818\n",
      "resetting env. episode 7500, reward total was -16.0. running mean: -14.363540703673744, timestamp: 2022-08-20 12:16:00.226866\n",
      "resetting env. episode 7501, reward total was -19.0. running mean: -14.409905296637005, timestamp: 2022-08-20 12:16:03.721908\n",
      "resetting env. episode 7502, reward total was -17.0. running mean: -14.435806243670635, timestamp: 2022-08-20 12:16:06.994943\n",
      "resetting env. episode 7503, reward total was -12.0. running mean: -14.411448181233927, timestamp: 2022-08-20 12:16:11.847999\n",
      "resetting env. episode 7504, reward total was -12.0. running mean: -14.387333699421587, timestamp: 2022-08-20 12:16:16.639055\n",
      "resetting env. episode 7505, reward total was -19.0. running mean: -14.43346036242737, timestamp: 2022-08-20 12:16:19.721089\n",
      "resetting env. episode 7506, reward total was -12.0. running mean: -14.409125758803096, timestamp: 2022-08-20 12:16:24.039143\n",
      "resetting env. episode 7507, reward total was -19.0. running mean: -14.455034501215065, timestamp: 2022-08-20 12:16:27.786178\n",
      "resetting env. episode 7508, reward total was -12.0. running mean: -14.430484156202914, timestamp: 2022-08-20 12:16:32.693233\n",
      "resetting env. episode 7509, reward total was -15.0. running mean: -14.436179314640885, timestamp: 2022-08-20 12:16:36.972283\n",
      "resetting env. episode 7510, reward total was -15.0. running mean: -14.441817521494476, timestamp: 2022-08-20 12:16:41.566338\n",
      "resetting env. episode 7511, reward total was -15.0. running mean: -14.447399346279532, timestamp: 2022-08-20 12:16:46.465391\n",
      "resetting env. episode 7512, reward total was -9.0. running mean: -14.392925352816736, timestamp: 2022-08-20 12:16:52.238458\n",
      "resetting env. episode 7513, reward total was -15.0. running mean: -14.398996099288569, timestamp: 2022-08-20 12:16:55.896497\n",
      "resetting env. episode 7514, reward total was -17.0. running mean: -14.425006138295682, timestamp: 2022-08-20 12:17:00.472547\n",
      "resetting env. episode 7515, reward total was -13.0. running mean: -14.410756076912726, timestamp: 2022-08-20 12:17:05.364602\n",
      "resetting env. episode 7516, reward total was -9.0. running mean: -14.356648516143599, timestamp: 2022-08-20 12:17:11.462674\n",
      "resetting env. episode 7517, reward total was -15.0. running mean: -14.363082030982163, timestamp: 2022-08-20 12:17:16.112725\n",
      "resetting env. episode 7518, reward total was -15.0. running mean: -14.369451210672342, timestamp: 2022-08-20 12:17:20.621776\n",
      "resetting env. episode 7519, reward total was -12.0. running mean: -14.345756698565618, timestamp: 2022-08-20 12:17:25.811844\n",
      "resetting env. episode 7520, reward total was -13.0. running mean: -14.332299131579962, timestamp: 2022-08-20 12:17:30.619888\n",
      "resetting env. episode 7521, reward total was -10.0. running mean: -14.288976140264161, timestamp: 2022-08-20 12:17:35.343942\n",
      "resetting env. episode 7522, reward total was -17.0. running mean: -14.316086378861518, timestamp: 2022-08-20 12:17:39.171990\n",
      "resetting env. episode 7523, reward total was -19.0. running mean: -14.362925515072902, timestamp: 2022-08-20 12:17:43.571039\n",
      "resetting env. episode 7524, reward total was -11.0. running mean: -14.329296259922172, timestamp: 2022-08-20 12:17:48.190104\n",
      "resetting env. episode 7525, reward total was -16.0. running mean: -14.34600329732295, timestamp: 2022-08-20 12:17:52.692141\n",
      "resetting env. episode 7526, reward total was -17.0. running mean: -14.37254326434972, timestamp: 2022-08-20 12:17:56.594182\n",
      "resetting env. episode 7527, reward total was -15.0. running mean: -14.378817831706222, timestamp: 2022-08-20 12:18:01.522238\n",
      "resetting env. episode 7528, reward total was -14.0. running mean: -14.37502965338916, timestamp: 2022-08-20 12:18:05.953289\n",
      "resetting env. episode 7529, reward total was -16.0. running mean: -14.391279356855268, timestamp: 2022-08-20 12:18:10.019336\n",
      "resetting env. episode 7530, reward total was -15.0. running mean: -14.397366563286715, timestamp: 2022-08-20 12:18:14.297383\n",
      "resetting env. episode 7531, reward total was -16.0. running mean: -14.413392897653848, timestamp: 2022-08-20 12:18:17.526420\n",
      "resetting env. episode 7532, reward total was -19.0. running mean: -14.45925896867731, timestamp: 2022-08-20 12:18:21.524466\n",
      "resetting env. episode 7533, reward total was -16.0. running mean: -14.474666378990536, timestamp: 2022-08-20 12:18:25.643514\n",
      "resetting env. episode 7534, reward total was -15.0. running mean: -14.47991971520063, timestamp: 2022-08-20 12:18:29.420553\n",
      "resetting env. episode 7535, reward total was -10.0. running mean: -14.435120518048624, timestamp: 2022-08-20 12:18:35.634625\n",
      "resetting env. episode 7536, reward total was -13.0. running mean: -14.420769312868138, timestamp: 2022-08-20 12:18:39.017663\n",
      "resetting env. episode 7537, reward total was -16.0. running mean: -14.436561619739457, timestamp: 2022-08-20 12:18:43.091715\n",
      "resetting env. episode 7538, reward total was -13.0. running mean: -14.422196003542064, timestamp: 2022-08-20 12:18:47.350757\n",
      "resetting env. episode 7539, reward total was -15.0. running mean: -14.427974043506644, timestamp: 2022-08-20 12:18:51.872807\n",
      "resetting env. episode 7540, reward total was -12.0. running mean: -14.403694303071576, timestamp: 2022-08-20 12:18:56.732861\n",
      "resetting env. episode 7541, reward total was -14.0. running mean: -14.39965736004086, timestamp: 2022-08-20 12:19:01.316913\n",
      "resetting env. episode 7542, reward total was -13.0. running mean: -14.385660786440452, timestamp: 2022-08-20 12:19:07.053976\n",
      "resetting env. episode 7543, reward total was -7.0. running mean: -14.311804178576047, timestamp: 2022-08-20 12:19:12.121035\n",
      "resetting env. episode 7544, reward total was -9.0. running mean: -14.258686136790287, timestamp: 2022-08-20 12:19:16.818089\n",
      "resetting env. episode 7545, reward total was -16.0. running mean: -14.276099275422384, timestamp: 2022-08-20 12:19:21.003135\n",
      "resetting env. episode 7546, reward total was -12.0. running mean: -14.253338282668158, timestamp: 2022-08-20 12:19:25.099182\n",
      "resetting env. episode 7547, reward total was -12.0. running mean: -14.230804899841475, timestamp: 2022-08-20 12:19:29.634239\n",
      "resetting env. episode 7548, reward total was -12.0. running mean: -14.20849685084306, timestamp: 2022-08-20 12:19:34.261286\n",
      "resetting env. episode 7549, reward total was -18.0. running mean: -14.246411882334629, timestamp: 2022-08-20 12:19:39.151342\n",
      "resetting env. episode 7550, reward total was -9.0. running mean: -14.193947763511282, timestamp: 2022-08-20 12:19:44.597401\n",
      "resetting env. episode 7551, reward total was -11.0. running mean: -14.162008285876169, timestamp: 2022-08-20 12:19:50.768476\n",
      "resetting env. episode 7552, reward total was -14.0. running mean: -14.160388203017408, timestamp: 2022-08-20 12:19:56.030536\n",
      "resetting env. episode 7553, reward total was -10.0. running mean: -14.118784320987233, timestamp: 2022-08-20 12:20:02.001602\n",
      "resetting env. episode 7554, reward total was -13.0. running mean: -14.107596477777362, timestamp: 2022-08-20 12:20:06.022648\n",
      "resetting env. episode 7555, reward total was -13.0. running mean: -14.09652051299959, timestamp: 2022-08-20 12:20:11.224709\n",
      "resetting env. episode 7556, reward total was -15.0. running mean: -14.105555307869594, timestamp: 2022-08-20 12:20:15.807761\n",
      "resetting env. episode 7557, reward total was -15.0. running mean: -14.114499754790899, timestamp: 2022-08-20 12:20:20.205808\n",
      "resetting env. episode 7558, reward total was -16.0. running mean: -14.133354757242989, timestamp: 2022-08-20 12:20:23.945850\n",
      "resetting env. episode 7559, reward total was -12.0. running mean: -14.112021209670559, timestamp: 2022-08-20 12:20:28.767906\n",
      "resetting env. episode 7560, reward total was -11.0. running mean: -14.080900997573853, timestamp: 2022-08-20 12:20:34.094966\n",
      "resetting env. episode 7561, reward total was -12.0. running mean: -14.060091987598113, timestamp: 2022-08-20 12:20:38.697022\n",
      "resetting env. episode 7562, reward total was -8.0. running mean: -13.999491067722133, timestamp: 2022-08-20 12:20:44.521086\n",
      "resetting env. episode 7563, reward total was -15.0. running mean: -14.00949615704491, timestamp: 2022-08-20 12:20:49.638147\n",
      "resetting env. episode 7564, reward total was -15.0. running mean: -14.019401195474462, timestamp: 2022-08-20 12:20:53.119183\n",
      "resetting env. episode 7565, reward total was -13.0. running mean: -14.009207183519718, timestamp: 2022-08-20 12:20:57.556233\n",
      "resetting env. episode 7566, reward total was -17.0. running mean: -14.039115111684522, timestamp: 2022-08-20 12:21:02.200286\n",
      "resetting env. episode 7567, reward total was -16.0. running mean: -14.058723960567677, timestamp: 2022-08-20 12:21:06.552338\n",
      "resetting env. episode 7568, reward total was -15.0. running mean: -14.068136720962, timestamp: 2022-08-20 12:21:10.938388\n",
      "resetting env. episode 7569, reward total was -15.0. running mean: -14.07745535375238, timestamp: 2022-08-20 12:21:15.114437\n",
      "resetting env. episode 7570, reward total was -16.0. running mean: -14.096680800214857, timestamp: 2022-08-20 12:21:19.764486\n",
      "resetting env. episode 7571, reward total was -12.0. running mean: -14.075713992212707, timestamp: 2022-08-20 12:21:24.139540\n",
      "resetting env. episode 7572, reward total was -12.0. running mean: -14.054956852290578, timestamp: 2022-08-20 12:21:28.961595\n",
      "resetting env. episode 7573, reward total was -15.0. running mean: -14.064407283767673, timestamp: 2022-08-20 12:21:33.544647\n",
      "resetting env. episode 7574, reward total was -17.0. running mean: -14.093763210929996, timestamp: 2022-08-20 12:21:37.457692\n",
      "resetting env. episode 7575, reward total was -17.0. running mean: -14.122825578820697, timestamp: 2022-08-20 12:21:41.551738\n",
      "resetting env. episode 7576, reward total was -15.0. running mean: -14.13159732303249, timestamp: 2022-08-20 12:21:45.433780\n",
      "resetting env. episode 7577, reward total was -13.0. running mean: -14.120281349802166, timestamp: 2022-08-20 12:21:50.802842\n",
      "resetting env. episode 7578, reward total was -10.0. running mean: -14.079078536304143, timestamp: 2022-08-20 12:21:55.549900\n",
      "resetting env. episode 7579, reward total was -10.0. running mean: -14.038287750941102, timestamp: 2022-08-20 12:22:00.101952\n",
      "resetting env. episode 7580, reward total was -17.0. running mean: -14.06790487343169, timestamp: 2022-08-20 12:22:04.576999\n",
      "resetting env. episode 7581, reward total was -16.0. running mean: -14.087225824697374, timestamp: 2022-08-20 12:22:08.720046\n",
      "resetting env. episode 7582, reward total was -9.0. running mean: -14.0363535664504, timestamp: 2022-08-20 12:22:14.395113\n",
      "resetting env. episode 7583, reward total was -17.0. running mean: -14.065990030785896, timestamp: 2022-08-20 12:22:18.695165\n",
      "resetting env. episode 7584, reward total was -14.0. running mean: -14.065330130478037, timestamp: 2022-08-20 12:22:22.654216\n",
      "resetting env. episode 7585, reward total was -17.0. running mean: -14.094676829173256, timestamp: 2022-08-20 12:22:26.508252\n",
      "resetting env. episode 7586, reward total was -12.0. running mean: -14.073730060881523, timestamp: 2022-08-20 12:22:32.174318\n",
      "resetting env. episode 7587, reward total was -13.0. running mean: -14.062992760272708, timestamp: 2022-08-20 12:22:36.218368\n",
      "resetting env. episode 7588, reward total was -21.0. running mean: -14.132362832669982, timestamp: 2022-08-20 12:22:39.936405\n",
      "resetting env. episode 7589, reward total was -18.0. running mean: -14.17103920434328, timestamp: 2022-08-20 12:22:43.652447\n",
      "resetting env. episode 7590, reward total was -17.0. running mean: -14.199328812299848, timestamp: 2022-08-20 12:22:47.509493\n",
      "resetting env. episode 7591, reward total was -13.0. running mean: -14.18733552417685, timestamp: 2022-08-20 12:22:51.643539\n",
      "resetting env. episode 7592, reward total was -15.0. running mean: -14.195462168935082, timestamp: 2022-08-20 12:22:56.301591\n",
      "resetting env. episode 7593, reward total was -16.0. running mean: -14.213507547245731, timestamp: 2022-08-20 12:23:00.073370\n",
      "resetting env. episode 7594, reward total was -10.0. running mean: -14.171372471773273, timestamp: 2022-08-20 12:23:04.966426\n",
      "resetting env. episode 7595, reward total was -12.0. running mean: -14.14965874705554, timestamp: 2022-08-20 12:23:10.494493\n",
      "resetting env. episode 7596, reward total was -12.0. running mean: -14.128162159584983, timestamp: 2022-08-20 12:23:15.506549\n",
      "resetting env. episode 7597, reward total was -17.0. running mean: -14.156880537989133, timestamp: 2022-08-20 12:23:18.860587\n",
      "resetting env. episode 7598, reward total was -10.0. running mean: -14.115311732609241, timestamp: 2022-08-20 12:23:24.510648\n",
      "resetting env. episode 7599, reward total was -14.0. running mean: -14.114158615283149, timestamp: 2022-08-20 12:23:29.829712\n",
      "resetting env. episode 7600, reward total was -13.0. running mean: -14.103017029130317, timestamp: 2022-08-20 12:23:34.015759\n",
      "resetting env. episode 7601, reward total was -18.0. running mean: -14.141986858839013, timestamp: 2022-08-20 12:23:39.333821\n",
      "resetting env. episode 7602, reward total was -16.0. running mean: -14.160566990250624, timestamp: 2022-08-20 12:23:44.096877\n",
      "resetting env. episode 7603, reward total was -18.0. running mean: -14.198961320348117, timestamp: 2022-08-20 12:23:48.657928\n",
      "resetting env. episode 7604, reward total was -10.0. running mean: -14.156971707144635, timestamp: 2022-08-20 12:23:53.844989\n",
      "resetting env. episode 7605, reward total was -17.0. running mean: -14.185401990073188, timestamp: 2022-08-20 12:23:58.150040\n",
      "resetting env. episode 7606, reward total was -16.0. running mean: -14.203547970172457, timestamp: 2022-08-20 12:24:02.330090\n",
      "resetting env. episode 7607, reward total was -18.0. running mean: -14.24151249047073, timestamp: 2022-08-20 12:24:06.013131\n",
      "resetting env. episode 7608, reward total was -16.0. running mean: -14.259097365566024, timestamp: 2022-08-20 12:24:10.320179\n",
      "resetting env. episode 7609, reward total was -13.0. running mean: -14.246506391910364, timestamp: 2022-08-20 12:24:14.881230\n",
      "resetting env. episode 7610, reward total was -13.0. running mean: -14.23404132799126, timestamp: 2022-08-20 12:24:20.875298\n",
      "resetting env. episode 7611, reward total was -14.0. running mean: -14.231700914711348, timestamp: 2022-08-20 12:24:26.502364\n",
      "resetting env. episode 7612, reward total was -7.0. running mean: -14.159383905564235, timestamp: 2022-08-20 12:24:32.686432\n",
      "resetting env. episode 7613, reward total was -10.0. running mean: -14.117790066508592, timestamp: 2022-08-20 12:24:37.989496\n",
      "resetting env. episode 7614, reward total was -13.0. running mean: -14.106612165843506, timestamp: 2022-08-20 12:24:42.864551\n",
      "resetting env. episode 7615, reward total was -7.0. running mean: -14.035546044185072, timestamp: 2022-08-20 12:24:48.482616\n",
      "resetting env. episode 7616, reward total was -15.0. running mean: -14.04519058374322, timestamp: 2022-08-20 12:24:53.863678\n",
      "resetting env. episode 7617, reward total was -13.0. running mean: -14.03473867790579, timestamp: 2022-08-20 12:24:58.318728\n",
      "resetting env. episode 7618, reward total was -16.0. running mean: -14.05439129112673, timestamp: 2022-08-20 12:25:02.790782\n",
      "resetting env. episode 7619, reward total was -9.0. running mean: -14.003847378215463, timestamp: 2022-08-20 12:25:08.190847\n",
      "resetting env. episode 7620, reward total was -13.0. running mean: -13.993808904433308, timestamp: 2022-08-20 12:25:13.265900\n",
      "resetting env. episode 7621, reward total was -13.0. running mean: -13.983870815388975, timestamp: 2022-08-20 12:25:17.928955\n",
      "resetting env. episode 7622, reward total was -11.0. running mean: -13.954032107235085, timestamp: 2022-08-20 12:25:23.352017\n",
      "resetting env. episode 7623, reward total was -8.0. running mean: -13.894491786162734, timestamp: 2022-08-20 12:25:28.637078\n",
      "resetting env. episode 7624, reward total was -15.0. running mean: -13.905546868301107, timestamp: 2022-08-20 12:25:34.306143\n",
      "resetting env. episode 7625, reward total was -12.0. running mean: -13.886491399618095, timestamp: 2022-08-20 12:25:40.141210\n",
      "resetting env. episode 7626, reward total was -11.0. running mean: -13.857626485621912, timestamp: 2022-08-20 12:25:44.766263\n",
      "resetting env. episode 7627, reward total was -19.0. running mean: -13.909050220765693, timestamp: 2022-08-20 12:25:48.535307\n",
      "resetting env. episode 7628, reward total was -15.0. running mean: -13.919959718558037, timestamp: 2022-08-20 12:25:53.120364\n",
      "resetting env. episode 7629, reward total was -9.0. running mean: -13.870760121372456, timestamp: 2022-08-20 12:25:58.856426\n",
      "resetting env. episode 7630, reward total was -17.0. running mean: -13.902052520158731, timestamp: 2022-08-20 12:26:03.147473\n",
      "resetting env. episode 7631, reward total was -17.0. running mean: -13.933031994957144, timestamp: 2022-08-20 12:26:07.546529\n",
      "resetting env. episode 7632, reward total was -16.0. running mean: -13.953701675007572, timestamp: 2022-08-20 12:26:12.383581\n",
      "resetting env. episode 7633, reward total was -8.0. running mean: -13.894164658257496, timestamp: 2022-08-20 12:26:17.438642\n",
      "resetting env. episode 7634, reward total was -14.0. running mean: -13.895223011674922, timestamp: 2022-08-20 12:26:22.146696\n",
      "resetting env. episode 7635, reward total was -17.0. running mean: -13.926270781558173, timestamp: 2022-08-20 12:26:24.770724\n",
      "resetting env. episode 7636, reward total was -8.0. running mean: -13.867008073742591, timestamp: 2022-08-20 12:26:30.534789\n",
      "resetting env. episode 7637, reward total was -9.0. running mean: -13.818337993005164, timestamp: 2022-08-20 12:26:38.169877\n",
      "resetting env. episode 7638, reward total was -17.0. running mean: -13.850154613075112, timestamp: 2022-08-20 12:26:42.560930\n",
      "resetting env. episode 7639, reward total was -15.0. running mean: -13.861653066944362, timestamp: 2022-08-20 12:26:46.663975\n",
      "resetting env. episode 7640, reward total was -20.0. running mean: -13.923036536274918, timestamp: 2022-08-20 12:26:50.374016\n",
      "resetting env. episode 7641, reward total was -12.0. running mean: -13.903806170912167, timestamp: 2022-08-20 12:26:55.701082\n",
      "resetting env. episode 7642, reward total was -8.0. running mean: -13.844768109203045, timestamp: 2022-08-20 12:27:00.859141\n",
      "resetting env. episode 7643, reward total was -11.0. running mean: -13.816320428111014, timestamp: 2022-08-20 12:27:06.846206\n",
      "resetting env. episode 7644, reward total was -8.0. running mean: -13.758157223829905, timestamp: 2022-08-20 12:27:13.158279\n",
      "resetting env. episode 7645, reward total was -7.0. running mean: -13.690575651591606, timestamp: 2022-08-20 12:27:19.748354\n",
      "resetting env. episode 7646, reward total was -16.0. running mean: -13.713669895075691, timestamp: 2022-08-20 12:27:24.869415\n",
      "resetting env. episode 7647, reward total was -17.0. running mean: -13.746533196124934, timestamp: 2022-08-20 12:27:28.977457\n",
      "resetting env. episode 7648, reward total was -15.0. running mean: -13.759067864163685, timestamp: 2022-08-20 12:27:32.626502\n",
      "resetting env. episode 7649, reward total was -12.0. running mean: -13.741477185522047, timestamp: 2022-08-20 12:27:37.645563\n",
      "resetting env. episode 7650, reward total was -16.0. running mean: -13.764062413666826, timestamp: 2022-08-20 12:27:42.302608\n",
      "resetting env. episode 7651, reward total was -9.0. running mean: -13.716421789530157, timestamp: 2022-08-20 12:27:47.677671\n",
      "resetting env. episode 7652, reward total was -11.0. running mean: -13.689257571634855, timestamp: 2022-08-20 12:27:53.830712\n",
      "resetting env. episode 7653, reward total was -18.0. running mean: -13.732364995918505, timestamp: 2022-08-20 12:27:57.776755\n",
      "resetting env. episode 7654, reward total was -14.0. running mean: -13.73504134595932, timestamp: 2022-08-20 12:28:02.754812\n",
      "resetting env. episode 7655, reward total was -12.0. running mean: -13.717690932499726, timestamp: 2022-08-20 12:28:06.971858\n",
      "resetting env. episode 7656, reward total was -15.0. running mean: -13.73051402317473, timestamp: 2022-08-20 12:28:10.590904\n",
      "resetting env. episode 7657, reward total was -19.0. running mean: -13.783208882942981, timestamp: 2022-08-20 12:28:13.916939\n",
      "resetting env. episode 7658, reward total was -14.0. running mean: -13.785376794113551, timestamp: 2022-08-20 12:28:17.322980\n",
      "resetting env. episode 7659, reward total was -17.0. running mean: -13.817523026172415, timestamp: 2022-08-20 12:28:21.106022\n",
      "resetting env. episode 7660, reward total was -18.0. running mean: -13.85934779591069, timestamp: 2022-08-20 12:28:24.673064\n",
      "resetting env. episode 7661, reward total was -19.0. running mean: -13.910754317951582, timestamp: 2022-08-20 12:28:29.017110\n",
      "resetting env. episode 7662, reward total was -14.0. running mean: -13.911646774772066, timestamp: 2022-08-20 12:28:34.014169\n",
      "resetting env. episode 7663, reward total was -15.0. running mean: -13.922530307024346, timestamp: 2022-08-20 12:28:38.566221\n",
      "resetting env. episode 7664, reward total was -14.0. running mean: -13.923305003954102, timestamp: 2022-08-20 12:28:43.445278\n",
      "resetting env. episode 7665, reward total was -9.0. running mean: -13.87407195391456, timestamp: 2022-08-20 12:28:49.979350\n",
      "resetting env. episode 7666, reward total was -8.0. running mean: -13.815331234375416, timestamp: 2022-08-20 12:28:54.723403\n",
      "resetting env. episode 7667, reward total was -10.0. running mean: -13.777177922031662, timestamp: 2022-08-20 12:28:59.750463\n",
      "resetting env. episode 7668, reward total was -15.0. running mean: -13.789406142811345, timestamp: 2022-08-20 12:29:03.658505\n",
      "resetting env. episode 7669, reward total was -11.0. running mean: -13.76151208138323, timestamp: 2022-08-20 12:29:09.126569\n",
      "resetting env. episode 7670, reward total was -10.0. running mean: -13.723896960569398, timestamp: 2022-08-20 12:29:13.586619\n",
      "resetting env. episode 7671, reward total was -5.0. running mean: -13.636657990963705, timestamp: 2022-08-20 12:29:19.375684\n",
      "resetting env. episode 7672, reward total was -13.0. running mean: -13.630291411054069, timestamp: 2022-08-20 12:29:22.799723\n",
      "resetting env. episode 7673, reward total was -17.0. running mean: -13.663988496943528, timestamp: 2022-08-20 12:29:27.077773\n",
      "resetting env. episode 7674, reward total was -15.0. running mean: -13.677348611974093, timestamp: 2022-08-20 12:29:32.603839\n",
      "resetting env. episode 7675, reward total was -17.0. running mean: -13.710575125854351, timestamp: 2022-08-20 12:29:36.435881\n",
      "resetting env. episode 7676, reward total was -8.0. running mean: -13.653469374595808, timestamp: 2022-08-20 12:29:42.758952\n",
      "resetting env. episode 7677, reward total was -13.0. running mean: -13.646934680849851, timestamp: 2022-08-20 12:29:46.538996\n",
      "resetting env. episode 7678, reward total was -15.0. running mean: -13.660465334041353, timestamp: 2022-08-20 12:29:51.308049\n",
      "resetting env. episode 7679, reward total was -15.0. running mean: -13.67386068070094, timestamp: 2022-08-20 12:29:55.448097\n",
      "resetting env. episode 7680, reward total was -15.0. running mean: -13.687122073893931, timestamp: 2022-08-20 12:30:00.608152\n",
      "resetting env. episode 7681, reward total was -15.0. running mean: -13.700250853154992, timestamp: 2022-08-20 12:30:04.683203\n",
      "resetting env. episode 7682, reward total was -11.0. running mean: -13.673248344623442, timestamp: 2022-08-20 12:30:09.678266\n",
      "resetting env. episode 7683, reward total was -8.0. running mean: -13.616515861177207, timestamp: 2022-08-20 12:30:14.407316\n",
      "resetting env. episode 7684, reward total was -13.0. running mean: -13.610350702565436, timestamp: 2022-08-20 12:30:18.755366\n",
      "resetting env. episode 7685, reward total was -13.0. running mean: -13.604247195539783, timestamp: 2022-08-20 12:30:23.178412\n",
      "resetting env. episode 7686, reward total was -15.0. running mean: -13.618204723584386, timestamp: 2022-08-20 12:30:27.044459\n",
      "resetting env. episode 7687, reward total was -6.0. running mean: -13.542022676348543, timestamp: 2022-08-20 12:30:33.123523\n",
      "resetting env. episode 7688, reward total was -11.0. running mean: -13.516602449585056, timestamp: 2022-08-20 12:30:39.010595\n",
      "resetting env. episode 7689, reward total was -18.0. running mean: -13.561436425089205, timestamp: 2022-08-20 12:30:43.547644\n",
      "resetting env. episode 7690, reward total was -17.0. running mean: -13.595822060838312, timestamp: 2022-08-20 12:30:46.809680\n",
      "resetting env. episode 7691, reward total was -5.0. running mean: -13.50986384022993, timestamp: 2022-08-20 12:30:53.532759\n",
      "resetting env. episode 7692, reward total was -7.0. running mean: -13.44476520182763, timestamp: 2022-08-20 12:31:00.472837\n",
      "resetting env. episode 7693, reward total was -9.0. running mean: -13.400317549809355, timestamp: 2022-08-20 12:31:06.816909\n",
      "resetting env. episode 7694, reward total was -15.0. running mean: -13.416314374311261, timestamp: 2022-08-20 12:31:10.537953\n",
      "resetting env. episode 7695, reward total was -17.0. running mean: -13.452151230568148, timestamp: 2022-08-20 12:31:14.514995\n",
      "resetting env. episode 7696, reward total was -12.0. running mean: -13.437629718262466, timestamp: 2022-08-20 12:31:18.992048\n",
      "resetting env. episode 7697, reward total was -10.0. running mean: -13.40325342107984, timestamp: 2022-08-20 12:31:24.524110\n",
      "resetting env. episode 7698, reward total was -12.0. running mean: -13.389220886869042, timestamp: 2022-08-20 12:31:29.217164\n",
      "resetting env. episode 7699, reward total was -15.0. running mean: -13.405328678000352, timestamp: 2022-08-20 12:31:34.759228\n",
      "resetting env. episode 7700, reward total was -12.0. running mean: -13.391275391220347, timestamp: 2022-08-20 12:31:39.212281\n",
      "resetting env. episode 7701, reward total was -16.0. running mean: -13.417362637308143, timestamp: 2022-08-20 12:31:43.169325\n",
      "resetting env. episode 7702, reward total was -8.0. running mean: -13.363189010935061, timestamp: 2022-08-20 12:31:48.966390\n",
      "resetting env. episode 7703, reward total was -12.0. running mean: -13.34955712082571, timestamp: 2022-08-20 12:31:54.130447\n",
      "resetting env. episode 7704, reward total was -9.0. running mean: -13.306061549617452, timestamp: 2022-08-20 12:31:59.218506\n",
      "resetting env. episode 7705, reward total was -16.0. running mean: -13.333000934121277, timestamp: 2022-08-20 12:32:03.521555\n",
      "resetting env. episode 7706, reward total was -7.0. running mean: -13.269670924780064, timestamp: 2022-08-20 12:32:10.004628\n",
      "resetting env. episode 7707, reward total was -14.0. running mean: -13.276974215532263, timestamp: 2022-08-20 12:32:15.254691\n",
      "resetting env. episode 7708, reward total was -9.0. running mean: -13.23420447337694, timestamp: 2022-08-20 12:32:20.633758\n",
      "resetting env. episode 7709, reward total was -13.0. running mean: -13.23186242864317, timestamp: 2022-08-20 12:32:25.511806\n",
      "resetting env. episode 7710, reward total was -13.0. running mean: -13.229543804356739, timestamp: 2022-08-20 12:32:30.322859\n",
      "resetting env. episode 7711, reward total was -19.0. running mean: -13.287248366313172, timestamp: 2022-08-20 12:32:35.094915\n",
      "resetting env. episode 7712, reward total was -19.0. running mean: -13.34437588265004, timestamp: 2022-08-20 12:32:38.782955\n",
      "resetting env. episode 7713, reward total was -13.0. running mean: -13.34093212382354, timestamp: 2022-08-20 12:32:42.762999\n",
      "resetting env. episode 7714, reward total was -12.0. running mean: -13.327522802585303, timestamp: 2022-08-20 12:32:48.222060\n",
      "resetting env. episode 7715, reward total was -3.0. running mean: -13.224247574559449, timestamp: 2022-08-20 12:32:54.050126\n",
      "resetting env. episode 7716, reward total was -11.0. running mean: -13.202005098813855, timestamp: 2022-08-20 12:33:00.939203\n",
      "resetting env. episode 7717, reward total was -17.0. running mean: -13.239985047825716, timestamp: 2022-08-20 12:33:05.851259\n",
      "resetting env. episode 7718, reward total was -11.0. running mean: -13.217585197347457, timestamp: 2022-08-20 12:33:10.523312\n",
      "resetting env. episode 7719, reward total was -15.0. running mean: -13.235409345373983, timestamp: 2022-08-20 12:33:15.100364\n",
      "resetting env. episode 7720, reward total was -11.0. running mean: -13.213055251920242, timestamp: 2022-08-20 12:33:21.624436\n",
      "resetting env. episode 7721, reward total was -14.0. running mean: -13.22092469940104, timestamp: 2022-08-20 12:33:26.434493\n",
      "resetting env. episode 7722, reward total was -21.0. running mean: -13.29871545240703, timestamp: 2022-08-20 12:33:29.663529\n",
      "resetting env. episode 7723, reward total was -12.0. running mean: -13.28572829788296, timestamp: 2022-08-20 12:33:34.510582\n",
      "resetting env. episode 7724, reward total was -18.0. running mean: -13.33287101490413, timestamp: 2022-08-20 12:33:38.729631\n",
      "resetting env. episode 7725, reward total was -14.0. running mean: -13.33954230475509, timestamp: 2022-08-20 12:33:44.255693\n",
      "resetting env. episode 7726, reward total was -16.0. running mean: -13.36614688170754, timestamp: 2022-08-20 12:33:50.249762\n",
      "resetting env. episode 7727, reward total was -14.0. running mean: -13.372485412890464, timestamp: 2022-08-20 12:33:55.618822\n",
      "resetting env. episode 7728, reward total was -15.0. running mean: -13.38876055876156, timestamp: 2022-08-20 12:34:00.863885\n",
      "resetting env. episode 7729, reward total was -16.0. running mean: -13.414872953173944, timestamp: 2022-08-20 12:34:05.525934\n",
      "resetting env. episode 7730, reward total was -9.0. running mean: -13.370724223642204, timestamp: 2022-08-20 12:34:11.501000\n",
      "resetting env. episode 7731, reward total was -9.0. running mean: -13.327016981405782, timestamp: 2022-08-20 12:34:17.005065\n",
      "resetting env. episode 7732, reward total was -10.0. running mean: -13.293746811591724, timestamp: 2022-08-20 12:34:22.158120\n",
      "resetting env. episode 7733, reward total was -18.0. running mean: -13.340809343475806, timestamp: 2022-08-20 12:34:26.077168\n",
      "resetting env. episode 7734, reward total was -13.0. running mean: -13.337401250041049, timestamp: 2022-08-20 12:34:32.125233\n",
      "resetting env. episode 7735, reward total was -3.0. running mean: -13.234027237540637, timestamp: 2022-08-20 12:34:38.502305\n",
      "resetting env. episode 7736, reward total was -20.0. running mean: -13.30168696516523, timestamp: 2022-08-20 12:34:42.993358\n",
      "resetting env. episode 7737, reward total was -14.0. running mean: -13.308670095513579, timestamp: 2022-08-20 12:34:48.619420\n",
      "resetting env. episode 7738, reward total was -15.0. running mean: -13.325583394558443, timestamp: 2022-08-20 12:34:53.467477\n",
      "resetting env. episode 7739, reward total was -18.0. running mean: -13.372327560612858, timestamp: 2022-08-20 12:34:58.004527\n",
      "resetting env. episode 7740, reward total was -17.0. running mean: -13.40860428500673, timestamp: 2022-08-20 12:35:02.511579\n",
      "resetting env. episode 7741, reward total was -21.0. running mean: -13.484518242156664, timestamp: 2022-08-20 12:35:06.095620\n",
      "resetting env. episode 7742, reward total was -18.0. running mean: -13.529673059735098, timestamp: 2022-08-20 12:35:11.634685\n",
      "resetting env. episode 7743, reward total was -19.0. running mean: -13.584376329137745, timestamp: 2022-08-20 12:35:15.819729\n",
      "resetting env. episode 7744, reward total was -16.0. running mean: -13.608532565846367, timestamp: 2022-08-20 12:35:19.439768\n",
      "resetting env. episode 7745, reward total was -12.0. running mean: -13.592447240187903, timestamp: 2022-08-20 12:35:25.171834\n",
      "resetting env. episode 7746, reward total was -12.0. running mean: -13.576522767786024, timestamp: 2022-08-20 12:35:31.207903\n",
      "resetting env. episode 7747, reward total was -12.0. running mean: -13.560757540108163, timestamp: 2022-08-20 12:35:35.650953\n",
      "resetting env. episode 7748, reward total was -15.0. running mean: -13.575149964707082, timestamp: 2022-08-20 12:35:40.774011\n",
      "resetting env. episode 7749, reward total was -18.0. running mean: -13.61939846506001, timestamp: 2022-08-20 12:35:45.606067\n",
      "resetting env. episode 7750, reward total was -21.0. running mean: -13.693204480409412, timestamp: 2022-08-20 12:35:49.013103\n",
      "resetting env. episode 7751, reward total was -7.0. running mean: -13.626272435605317, timestamp: 2022-08-20 12:35:55.042172\n",
      "resetting env. episode 7752, reward total was -11.0. running mean: -13.600009711249264, timestamp: 2022-08-20 12:36:00.763237\n",
      "resetting env. episode 7753, reward total was -7.0. running mean: -13.534009614136771, timestamp: 2022-08-20 12:36:06.036295\n",
      "resetting env. episode 7754, reward total was -13.0. running mean: -13.528669517995404, timestamp: 2022-08-20 12:36:09.890340\n",
      "resetting env. episode 7755, reward total was -15.0. running mean: -13.54338282281545, timestamp: 2022-08-20 12:36:14.286389\n",
      "resetting env. episode 7756, reward total was -13.0. running mean: -13.537948994587296, timestamp: 2022-08-20 12:36:19.518448\n",
      "resetting env. episode 7757, reward total was -14.0. running mean: -13.542569504641424, timestamp: 2022-08-20 12:36:23.675498\n",
      "resetting env. episode 7758, reward total was -14.0. running mean: -13.54714380959501, timestamp: 2022-08-20 12:36:28.776555\n",
      "resetting env. episode 7759, reward total was -15.0. running mean: -13.56167237149906, timestamp: 2022-08-20 12:36:35.284626\n",
      "resetting env. episode 7760, reward total was -17.0. running mean: -13.59605564778407, timestamp: 2022-08-20 12:36:39.001668\n",
      "resetting env. episode 7761, reward total was -13.0. running mean: -13.59009509130623, timestamp: 2022-08-20 12:36:44.071725\n",
      "resetting env. episode 7762, reward total was -19.0. running mean: -13.644194140393168, timestamp: 2022-08-20 12:36:47.262761\n",
      "resetting env. episode 7763, reward total was -8.0. running mean: -13.587752198989236, timestamp: 2022-08-20 12:36:52.829825\n",
      "resetting env. episode 7764, reward total was -12.0. running mean: -13.571874676999343, timestamp: 2022-08-20 12:36:59.351904\n",
      "resetting env. episode 7765, reward total was -18.0. running mean: -13.616155930229349, timestamp: 2022-08-20 12:37:03.129940\n",
      "resetting env. episode 7766, reward total was -17.0. running mean: -13.649994370927056, timestamp: 2022-08-20 12:37:07.427992\n",
      "resetting env. episode 7767, reward total was -17.0. running mean: -13.683494427217784, timestamp: 2022-08-20 12:37:10.993031\n",
      "resetting env. episode 7768, reward total was -12.0. running mean: -13.666659482945606, timestamp: 2022-08-20 12:37:16.756098\n",
      "resetting env. episode 7769, reward total was -13.0. running mean: -13.65999288811615, timestamp: 2022-08-20 12:37:21.260150\n",
      "resetting env. episode 7770, reward total was -11.0. running mean: -13.633392959234989, timestamp: 2022-08-20 12:37:26.476210\n",
      "resetting env. episode 7771, reward total was -19.0. running mean: -13.687059029642638, timestamp: 2022-08-20 12:37:29.975252\n",
      "resetting env. episode 7772, reward total was -5.0. running mean: -13.600188439346212, timestamp: 2022-08-20 12:37:37.276331\n",
      "resetting env. episode 7773, reward total was -9.0. running mean: -13.55418655495275, timestamp: 2022-08-20 12:37:43.343403\n",
      "resetting env. episode 7774, reward total was -14.0. running mean: -13.558644689403224, timestamp: 2022-08-20 12:37:48.883465\n",
      "resetting env. episode 7775, reward total was -7.0. running mean: -13.493058242509191, timestamp: 2022-08-20 12:37:55.035535\n",
      "resetting env. episode 7776, reward total was -13.0. running mean: -13.4881276600841, timestamp: 2022-08-20 12:38:00.262598\n",
      "resetting env. episode 7777, reward total was -15.0. running mean: -13.503246383483258, timestamp: 2022-08-20 12:38:06.132664\n",
      "resetting env. episode 7778, reward total was -13.0. running mean: -13.498213919648427, timestamp: 2022-08-20 12:38:11.289718\n",
      "resetting env. episode 7779, reward total was -5.0. running mean: -13.413231780451943, timestamp: 2022-08-20 12:38:17.240787\n",
      "resetting env. episode 7780, reward total was -15.0. running mean: -13.429099462647423, timestamp: 2022-08-20 12:38:22.566847\n",
      "resetting env. episode 7781, reward total was -14.0. running mean: -13.43480846802095, timestamp: 2022-08-20 12:38:27.885909\n",
      "resetting env. episode 7782, reward total was -11.0. running mean: -13.410460383340741, timestamp: 2022-08-20 12:38:33.874977\n",
      "resetting env. episode 7783, reward total was -11.0. running mean: -13.386355779507333, timestamp: 2022-08-20 12:38:39.314042\n",
      "resetting env. episode 7784, reward total was -14.0. running mean: -13.39249222171226, timestamp: 2022-08-20 12:38:43.556092\n",
      "resetting env. episode 7785, reward total was -12.0. running mean: -13.378567299495137, timestamp: 2022-08-20 12:38:49.663162\n",
      "resetting env. episode 7786, reward total was -10.0. running mean: -13.344781626500184, timestamp: 2022-08-20 12:38:55.295224\n",
      "resetting env. episode 7787, reward total was -10.0. running mean: -13.311333810235181, timestamp: 2022-08-20 12:39:00.361283\n",
      "resetting env. episode 7788, reward total was -17.0. running mean: -13.34822047213283, timestamp: 2022-08-20 12:39:05.442340\n",
      "resetting env. episode 7789, reward total was -21.0. running mean: -13.424738267411502, timestamp: 2022-08-20 12:39:09.912393\n",
      "resetting env. episode 7790, reward total was -15.0. running mean: -13.440490884737388, timestamp: 2022-08-20 12:39:15.010451\n",
      "resetting env. episode 7791, reward total was -20.0. running mean: -13.506085975890013, timestamp: 2022-08-20 12:39:18.747497\n",
      "resetting env. episode 7792, reward total was -13.0. running mean: -13.501025116131114, timestamp: 2022-08-20 12:39:23.354547\n",
      "resetting env. episode 7793, reward total was -13.0. running mean: -13.496014864969803, timestamp: 2022-08-20 12:39:28.374609\n",
      "resetting env. episode 7794, reward total was -9.0. running mean: -13.451054716320105, timestamp: 2022-08-20 12:39:33.947669\n",
      "resetting env. episode 7795, reward total was -12.0. running mean: -13.436544169156903, timestamp: 2022-08-20 12:39:39.695739\n",
      "resetting env. episode 7796, reward total was -20.0. running mean: -13.502178727465333, timestamp: 2022-08-20 12:39:43.051777\n",
      "resetting env. episode 7797, reward total was -15.0. running mean: -13.51715694019068, timestamp: 2022-08-20 12:39:47.136825\n",
      "resetting env. episode 7798, reward total was -13.0. running mean: -13.511985370788775, timestamp: 2022-08-20 12:39:53.077894\n",
      "resetting env. episode 7799, reward total was -9.0. running mean: -13.466865517080887, timestamp: 2022-08-20 12:39:59.619962\n",
      "resetting env. episode 7800, reward total was -15.0. running mean: -13.482196861910078, timestamp: 2022-08-20 12:40:05.029025\n",
      "resetting env. episode 7801, reward total was -17.0. running mean: -13.517374893290977, timestamp: 2022-08-20 12:40:08.912071\n",
      "resetting env. episode 7802, reward total was -12.0. running mean: -13.502201144358066, timestamp: 2022-08-20 12:40:13.515124\n",
      "resetting env. episode 7803, reward total was -19.0. running mean: -13.557179132914484, timestamp: 2022-08-20 12:40:16.896164\n",
      "resetting env. episode 7804, reward total was -12.0. running mean: -13.541607341585339, timestamp: 2022-08-20 12:40:23.181239\n",
      "resetting env. episode 7805, reward total was -14.0. running mean: -13.546191268169485, timestamp: 2022-08-20 12:40:28.013294\n",
      "resetting env. episode 7806, reward total was -14.0. running mean: -13.55072935548779, timestamp: 2022-08-20 12:40:32.480344\n",
      "resetting env. episode 7807, reward total was -17.0. running mean: -13.585222061932912, timestamp: 2022-08-20 12:40:37.461400\n",
      "resetting env. episode 7808, reward total was -18.0. running mean: -13.629369841313583, timestamp: 2022-08-20 12:40:42.149454\n",
      "resetting env. episode 7809, reward total was -12.0. running mean: -13.613076142900447, timestamp: 2022-08-20 12:40:47.399514\n",
      "resetting env. episode 7810, reward total was -13.0. running mean: -13.606945381471443, timestamp: 2022-08-20 12:40:53.370581\n",
      "resetting env. episode 7811, reward total was -11.0. running mean: -13.580875927656727, timestamp: 2022-08-20 12:40:58.842645\n",
      "resetting env. episode 7812, reward total was -13.0. running mean: -13.57506716838016, timestamp: 2022-08-20 12:41:03.367697\n",
      "resetting env. episode 7813, reward total was -6.0. running mean: -13.499316496696359, timestamp: 2022-08-20 12:41:10.855783\n",
      "resetting env. episode 7814, reward total was -9.0. running mean: -13.454323331729395, timestamp: 2022-08-20 12:41:17.465861\n",
      "resetting env. episode 7815, reward total was -8.0. running mean: -13.399780098412101, timestamp: 2022-08-20 12:41:24.039945\n",
      "resetting env. episode 7816, reward total was -17.0. running mean: -13.43578229742798, timestamp: 2022-08-20 12:41:28.953992\n",
      "resetting env. episode 7817, reward total was -18.0. running mean: -13.4814244744537, timestamp: 2022-08-20 12:41:33.753047\n",
      "resetting env. episode 7818, reward total was -15.0. running mean: -13.496610229709162, timestamp: 2022-08-20 12:41:37.671092\n",
      "resetting env. episode 7819, reward total was -15.0. running mean: -13.51164412741207, timestamp: 2022-08-20 12:41:44.162168\n",
      "resetting env. episode 7820, reward total was -14.0. running mean: -13.51652768613795, timestamp: 2022-08-20 12:41:49.439227\n",
      "resetting env. episode 7821, reward total was -14.0. running mean: -13.521362409276572, timestamp: 2022-08-20 12:41:54.944292\n",
      "resetting env. episode 7822, reward total was -11.0. running mean: -13.496148785183806, timestamp: 2022-08-20 12:42:00.107351\n",
      "resetting env. episode 7823, reward total was -12.0. running mean: -13.481187297331967, timestamp: 2022-08-20 12:42:06.483422\n",
      "resetting env. episode 7824, reward total was -11.0. running mean: -13.456375424358647, timestamp: 2022-08-20 12:42:13.000498\n",
      "resetting env. episode 7825, reward total was -20.0. running mean: -13.52181167011506, timestamp: 2022-08-20 12:42:17.091547\n",
      "resetting env. episode 7826, reward total was -19.0. running mean: -13.57659355341391, timestamp: 2022-08-20 12:42:21.329597\n",
      "resetting env. episode 7827, reward total was -13.0. running mean: -13.57082761787977, timestamp: 2022-08-20 12:42:27.209662\n",
      "resetting env. episode 7828, reward total was -12.0. running mean: -13.555119341700971, timestamp: 2022-08-20 12:42:32.693724\n",
      "resetting env. episode 7829, reward total was -12.0. running mean: -13.53956814828396, timestamp: 2022-08-20 12:42:38.302788\n",
      "resetting env. episode 7830, reward total was -16.0. running mean: -13.564172466801121, timestamp: 2022-08-20 12:42:42.111835\n",
      "resetting env. episode 7831, reward total was -12.0. running mean: -13.54853074213311, timestamp: 2022-08-20 12:42:48.465904\n",
      "resetting env. episode 7832, reward total was -13.0. running mean: -13.543045434711779, timestamp: 2022-08-20 12:42:54.037971\n",
      "resetting env. episode 7833, reward total was -17.0. running mean: -13.577614980364661, timestamp: 2022-08-20 12:42:59.520037\n",
      "resetting env. episode 7834, reward total was -14.0. running mean: -13.581838830561015, timestamp: 2022-08-20 12:43:05.558101\n",
      "resetting env. episode 7835, reward total was -12.0. running mean: -13.566020442255404, timestamp: 2022-08-20 12:43:10.571158\n",
      "resetting env. episode 7836, reward total was -12.0. running mean: -13.550360237832848, timestamp: 2022-08-20 12:43:16.175223\n",
      "resetting env. episode 7837, reward total was -16.0. running mean: -13.57485663545452, timestamp: 2022-08-20 12:43:20.819278\n",
      "resetting env. episode 7838, reward total was -17.0. running mean: -13.609108069099975, timestamp: 2022-08-20 12:43:24.835325\n",
      "resetting env. episode 7839, reward total was -10.0. running mean: -13.573016988408975, timestamp: 2022-08-20 12:43:31.446399\n",
      "resetting env. episode 7840, reward total was -14.0. running mean: -13.577286818524886, timestamp: 2022-08-20 12:43:37.681473\n",
      "resetting env. episode 7841, reward total was -14.0. running mean: -13.581513950339637, timestamp: 2022-08-20 12:43:44.304547\n",
      "resetting env. episode 7842, reward total was -12.0. running mean: -13.56569881083624, timestamp: 2022-08-20 12:43:48.818599\n",
      "resetting env. episode 7843, reward total was -15.0. running mean: -13.580041822727878, timestamp: 2022-08-20 12:43:52.972649\n",
      "resetting env. episode 7844, reward total was -13.0. running mean: -13.5742414045006, timestamp: 2022-08-20 12:43:58.324711\n",
      "resetting env. episode 7845, reward total was -11.0. running mean: -13.548498990455593, timestamp: 2022-08-20 12:44:04.415781\n",
      "resetting env. episode 7846, reward total was -18.0. running mean: -13.593014000551037, timestamp: 2022-08-20 12:44:08.522827\n",
      "resetting env. episode 7847, reward total was -11.0. running mean: -13.567083860545525, timestamp: 2022-08-20 12:44:14.463896\n",
      "resetting env. episode 7848, reward total was -6.0. running mean: -13.49141302194007, timestamp: 2022-08-20 12:44:20.862970\n",
      "resetting env. episode 7849, reward total was -15.0. running mean: -13.50649889172067, timestamp: 2022-08-20 12:44:27.339045\n",
      "resetting env. episode 7850, reward total was -17.0. running mean: -13.541433902803462, timestamp: 2022-08-20 12:44:32.594106\n",
      "resetting env. episode 7851, reward total was -11.0. running mean: -13.516019563775426, timestamp: 2022-08-20 12:44:38.525173\n",
      "resetting env. episode 7852, reward total was -15.0. running mean: -13.530859368137673, timestamp: 2022-08-20 12:44:43.402230\n",
      "resetting env. episode 7853, reward total was -15.0. running mean: -13.545550774456297, timestamp: 2022-08-20 12:44:48.214282\n",
      "resetting env. episode 7854, reward total was -15.0. running mean: -13.560095266711734, timestamp: 2022-08-20 12:44:52.695334\n",
      "resetting env. episode 7855, reward total was -11.0. running mean: -13.534494314044617, timestamp: 2022-08-20 12:44:59.351413\n",
      "resetting env. episode 7856, reward total was -17.0. running mean: -13.56914937090417, timestamp: 2022-08-20 12:45:03.380460\n",
      "resetting env. episode 7857, reward total was -13.0. running mean: -13.56345787719513, timestamp: 2022-08-20 12:45:09.505527\n",
      "resetting env. episode 7858, reward total was -7.0. running mean: -13.49782329842318, timestamp: 2022-08-20 12:45:15.051597\n",
      "resetting env. episode 7859, reward total was -15.0. running mean: -13.512845065438949, timestamp: 2022-08-20 12:45:19.532642\n",
      "resetting env. episode 7860, reward total was -11.0. running mean: -13.487716614784558, timestamp: 2022-08-20 12:45:25.607711\n",
      "resetting env. episode 7861, reward total was -17.0. running mean: -13.522839448636713, timestamp: 2022-08-20 12:45:30.566772\n",
      "resetting env. episode 7862, reward total was -14.0. running mean: -13.527611054150347, timestamp: 2022-08-20 12:45:36.492841\n",
      "resetting env. episode 7863, reward total was -17.0. running mean: -13.562334943608843, timestamp: 2022-08-20 12:45:40.220880\n",
      "resetting env. episode 7864, reward total was -13.0. running mean: -13.556711594172755, timestamp: 2022-08-20 12:45:45.901948\n",
      "resetting env. episode 7865, reward total was -15.0. running mean: -13.571144478231028, timestamp: 2022-08-20 12:45:50.657000\n",
      "resetting env. episode 7866, reward total was -13.0. running mean: -13.565433033448718, timestamp: 2022-08-20 12:45:55.587061\n",
      "resetting env. episode 7867, reward total was -9.0. running mean: -13.51977870311423, timestamp: 2022-08-20 12:46:02.270137\n",
      "resetting env. episode 7868, reward total was -16.0. running mean: -13.544580916083088, timestamp: 2022-08-20 12:46:06.775187\n",
      "resetting env. episode 7869, reward total was -15.0. running mean: -13.559135106922257, timestamp: 2022-08-20 12:46:11.405239\n",
      "resetting env. episode 7870, reward total was -15.0. running mean: -13.573543755853034, timestamp: 2022-08-20 12:46:15.874291\n",
      "resetting env. episode 7871, reward total was -12.0. running mean: -13.557808318294503, timestamp: 2022-08-20 12:46:20.454343\n",
      "resetting env. episode 7872, reward total was -18.0. running mean: -13.602230235111557, timestamp: 2022-08-20 12:46:25.020400\n",
      "resetting env. episode 7873, reward total was -13.0. running mean: -13.596207932760443, timestamp: 2022-08-20 12:46:30.045456\n",
      "resetting env. episode 7874, reward total was -17.0. running mean: -13.630245853432838, timestamp: 2022-08-20 12:46:33.433493\n",
      "resetting env. episode 7875, reward total was -15.0. running mean: -13.643943394898509, timestamp: 2022-08-20 12:46:38.570553\n",
      "resetting env. episode 7876, reward total was -15.0. running mean: -13.657503960949525, timestamp: 2022-08-20 12:46:43.186604\n",
      "resetting env. episode 7877, reward total was -16.0. running mean: -13.68092892134003, timestamp: 2022-08-20 12:46:47.227650\n",
      "resetting env. episode 7878, reward total was -20.0. running mean: -13.744119632126628, timestamp: 2022-08-20 12:46:51.229696\n",
      "resetting env. episode 7879, reward total was -14.0. running mean: -13.746678435805363, timestamp: 2022-08-20 12:46:56.879759\n",
      "resetting env. episode 7880, reward total was -16.0. running mean: -13.769211651447309, timestamp: 2022-08-20 12:47:02.382822\n",
      "resetting env. episode 7881, reward total was -16.0. running mean: -13.791519534932835, timestamp: 2022-08-20 12:47:06.685872\n",
      "resetting env. episode 7882, reward total was -19.0. running mean: -13.843604339583505, timestamp: 2022-08-20 12:47:11.394927\n",
      "resetting env. episode 7883, reward total was -7.0. running mean: -13.77516829618767, timestamp: 2022-08-20 12:47:17.589996\n",
      "resetting env. episode 7884, reward total was -15.0. running mean: -13.787416613225794, timestamp: 2022-08-20 12:47:23.394064\n",
      "resetting env. episode 7885, reward total was -16.0. running mean: -13.809542447093536, timestamp: 2022-08-20 12:47:28.656123\n",
      "resetting env. episode 7886, reward total was -12.0. running mean: -13.7914470226226, timestamp: 2022-08-20 12:47:34.985196\n",
      "resetting env. episode 7887, reward total was -14.0. running mean: -13.793532552396375, timestamp: 2022-08-20 12:47:39.516246\n",
      "resetting env. episode 7888, reward total was -19.0. running mean: -13.84559722687241, timestamp: 2022-08-20 12:47:43.881300\n",
      "resetting env. episode 7889, reward total was -19.0. running mean: -13.897141254603685, timestamp: 2022-08-20 12:47:47.709339\n",
      "resetting env. episode 7890, reward total was -15.0. running mean: -13.90816984205765, timestamp: 2022-08-20 12:47:51.931389\n",
      "resetting env. episode 7891, reward total was -9.0. running mean: -13.859088143637072, timestamp: 2022-08-20 12:47:57.368449\n",
      "resetting env. episode 7892, reward total was -6.0. running mean: -13.7804972622007, timestamp: 2022-08-20 12:48:03.257517\n",
      "resetting env. episode 7893, reward total was -18.0. running mean: -13.822692289578693, timestamp: 2022-08-20 12:48:07.948570\n",
      "resetting env. episode 7894, reward total was -17.0. running mean: -13.854465366682906, timestamp: 2022-08-20 12:48:12.945628\n",
      "resetting env. episode 7895, reward total was -10.0. running mean: -13.815920713016077, timestamp: 2022-08-20 12:48:17.980686\n",
      "resetting env. episode 7896, reward total was -12.0. running mean: -13.797761505885916, timestamp: 2022-08-20 12:48:23.948757\n",
      "resetting env. episode 7897, reward total was -16.0. running mean: -13.819783890827056, timestamp: 2022-08-20 12:48:29.733821\n",
      "resetting env. episode 7898, reward total was -15.0. running mean: -13.831586051918785, timestamp: 2022-08-20 12:48:35.110882\n",
      "resetting env. episode 7899, reward total was -16.0. running mean: -13.853270191399597, timestamp: 2022-08-20 12:48:39.455930\n",
      "resetting env. episode 7900, reward total was -13.0. running mean: -13.8447374894856, timestamp: 2022-08-20 12:48:44.524986\n",
      "resetting env. episode 7901, reward total was -13.0. running mean: -13.836290114590746, timestamp: 2022-08-20 12:48:50.133055\n",
      "resetting env. episode 7902, reward total was -13.0. running mean: -13.82792721344484, timestamp: 2022-08-20 12:48:55.863118\n",
      "resetting env. episode 7903, reward total was -19.0. running mean: -13.87964794131039, timestamp: 2022-08-20 12:49:00.197166\n",
      "resetting env. episode 7904, reward total was -17.0. running mean: -13.910851461897286, timestamp: 2022-08-20 12:49:05.699229\n",
      "resetting env. episode 7905, reward total was -10.0. running mean: -13.871742947278312, timestamp: 2022-08-20 12:49:11.896301\n",
      "resetting env. episode 7906, reward total was -12.0. running mean: -13.853025517805529, timestamp: 2022-08-20 12:49:18.015372\n",
      "resetting env. episode 7907, reward total was -17.0. running mean: -13.884495262627473, timestamp: 2022-08-20 12:49:23.150430\n",
      "resetting env. episode 7908, reward total was -19.0. running mean: -13.935650310001197, timestamp: 2022-08-20 12:49:27.766480\n",
      "resetting env. episode 7909, reward total was -15.0. running mean: -13.946293806901185, timestamp: 2022-08-20 12:49:32.956541\n",
      "resetting env. episode 7910, reward total was -6.0. running mean: -13.866830868832173, timestamp: 2022-08-20 12:49:39.086611\n",
      "resetting env. episode 7911, reward total was -14.0. running mean: -13.868162560143851, timestamp: 2022-08-20 12:49:44.630676\n",
      "resetting env. episode 7912, reward total was -20.0. running mean: -13.929480934542411, timestamp: 2022-08-20 12:49:48.155714\n",
      "resetting env. episode 7913, reward total was -15.0. running mean: -13.940186125196988, timestamp: 2022-08-20 12:49:53.000770\n",
      "resetting env. episode 7914, reward total was -15.0. running mean: -13.950784263945017, timestamp: 2022-08-20 12:49:57.693824\n",
      "resetting env. episode 7915, reward total was -9.0. running mean: -13.901276421305568, timestamp: 2022-08-20 12:50:03.116883\n",
      "resetting env. episode 7916, reward total was -20.0. running mean: -13.96226365709251, timestamp: 2022-08-20 12:50:07.044927\n",
      "resetting env. episode 7917, reward total was -11.0. running mean: -13.932641020521585, timestamp: 2022-08-20 12:50:12.426992\n",
      "resetting env. episode 7918, reward total was -15.0. running mean: -13.943314610316369, timestamp: 2022-08-20 12:50:17.504051\n",
      "resetting env. episode 7919, reward total was -14.0. running mean: -13.943881464213206, timestamp: 2022-08-20 12:50:22.839109\n",
      "resetting env. episode 7920, reward total was -15.0. running mean: -13.954442649571074, timestamp: 2022-08-20 12:50:27.575164\n",
      "resetting env. episode 7921, reward total was -13.0. running mean: -13.944898223075365, timestamp: 2022-08-20 12:50:32.228215\n",
      "resetting env. episode 7922, reward total was -17.0. running mean: -13.975449240844611, timestamp: 2022-08-20 12:50:38.113283\n",
      "resetting env. episode 7923, reward total was -10.0. running mean: -13.935694748436164, timestamp: 2022-08-20 12:50:46.176378\n",
      "resetting env. episode 7924, reward total was -11.0. running mean: -13.906337800951801, timestamp: 2022-08-20 12:50:51.991442\n",
      "resetting env. episode 7925, reward total was -14.0. running mean: -13.907274422942283, timestamp: 2022-08-20 12:50:58.440520\n",
      "resetting env. episode 7926, reward total was -11.0. running mean: -13.878201678712859, timestamp: 2022-08-20 12:51:03.739575\n",
      "resetting env. episode 7927, reward total was -14.0. running mean: -13.87941966192573, timestamp: 2022-08-20 12:51:07.936623\n",
      "resetting env. episode 7928, reward total was -18.0. running mean: -13.920625465306474, timestamp: 2022-08-20 12:51:12.816680\n",
      "resetting env. episode 7929, reward total was -14.0. running mean: -13.92141921065341, timestamp: 2022-08-20 12:51:17.990736\n",
      "resetting env. episode 7930, reward total was -14.0. running mean: -13.922205018546876, timestamp: 2022-08-20 12:51:22.737789\n",
      "resetting env. episode 7931, reward total was -13.0. running mean: -13.912982968361408, timestamp: 2022-08-20 12:51:27.598844\n",
      "resetting env. episode 7932, reward total was -7.0. running mean: -13.843853138677794, timestamp: 2022-08-20 12:51:34.355923\n",
      "resetting env. episode 7933, reward total was -13.0. running mean: -13.835414607291016, timestamp: 2022-08-20 12:51:40.080985\n",
      "resetting env. episode 7934, reward total was -13.0. running mean: -13.827060461218107, timestamp: 2022-08-20 12:51:45.484048\n",
      "resetting env. episode 7935, reward total was -17.0. running mean: -13.858789856605926, timestamp: 2022-08-20 12:51:50.725107\n",
      "resetting env. episode 7936, reward total was -15.0. running mean: -13.870201958039866, timestamp: 2022-08-20 12:51:55.788164\n",
      "resetting env. episode 7937, reward total was -13.0. running mean: -13.861499938459469, timestamp: 2022-08-20 12:52:01.962233\n",
      "resetting env. episode 7938, reward total was -11.0. running mean: -13.832884939074873, timestamp: 2022-08-20 12:52:07.910302\n",
      "resetting env. episode 7939, reward total was -16.0. running mean: -13.854556089684124, timestamp: 2022-08-20 12:52:12.899356\n",
      "resetting env. episode 7940, reward total was -9.0. running mean: -13.806010528787283, timestamp: 2022-08-20 12:52:19.776434\n",
      "resetting env. episode 7941, reward total was 9.0. running mean: -13.57795042349941, timestamp: 2022-08-20 12:52:24.515487\n",
      "resetting env. episode 7942, reward total was -7.0. running mean: -13.512170919264415, timestamp: 2022-08-20 12:52:32.271574\n",
      "resetting env. episode 7943, reward total was -17.0. running mean: -13.547049210071771, timestamp: 2022-08-20 12:52:35.558615\n",
      "resetting env. episode 7944, reward total was -13.0. running mean: -13.541578717971055, timestamp: 2022-08-20 12:52:42.457689\n",
      "resetting env. episode 7945, reward total was -18.0. running mean: -13.586162930791344, timestamp: 2022-08-20 12:52:47.158743\n",
      "resetting env. episode 7946, reward total was -20.0. running mean: -13.650301301483431, timestamp: 2022-08-20 12:52:51.268788\n",
      "resetting env. episode 7947, reward total was -15.0. running mean: -13.663798288468596, timestamp: 2022-08-20 12:52:56.391852\n",
      "resetting env. episode 7948, reward total was -4.0. running mean: -13.56716030558391, timestamp: 2022-08-20 12:53:03.546927\n",
      "resetting env. episode 7949, reward total was -16.0. running mean: -13.591488702528071, timestamp: 2022-08-20 12:53:09.499996\n",
      "resetting env. episode 7950, reward total was -16.0. running mean: -13.61557381550279, timestamp: 2022-08-20 12:53:15.144060\n",
      "resetting env. episode 7951, reward total was -11.0. running mean: -13.589418077347762, timestamp: 2022-08-20 12:53:20.159118\n",
      "resetting env. episode 7952, reward total was -13.0. running mean: -13.583523896574285, timestamp: 2022-08-20 12:53:26.931193\n",
      "resetting env. episode 7953, reward total was -6.0. running mean: -13.507688657608542, timestamp: 2022-08-20 12:53:32.894261\n",
      "resetting env. episode 7954, reward total was -14.0. running mean: -13.512611771032457, timestamp: 2022-08-20 12:53:37.130311\n",
      "resetting env. episode 7955, reward total was -13.0. running mean: -13.507485653322133, timestamp: 2022-08-20 12:53:43.100380\n",
      "resetting env. episode 7956, reward total was -9.0. running mean: -13.462410796788912, timestamp: 2022-08-20 12:53:49.393451\n",
      "resetting env. episode 7957, reward total was -14.0. running mean: -13.467786688821024, timestamp: 2022-08-20 12:53:55.960524\n",
      "resetting env. episode 7958, reward total was -13.0. running mean: -13.463108821932813, timestamp: 2022-08-20 12:54:03.158606\n",
      "resetting env. episode 7959, reward total was -17.0. running mean: -13.498477733713486, timestamp: 2022-08-20 12:54:08.060662\n",
      "resetting env. episode 7960, reward total was -17.0. running mean: -13.533492956376351, timestamp: 2022-08-20 12:54:12.877716\n",
      "resetting env. episode 7961, reward total was -12.0. running mean: -13.518158026812587, timestamp: 2022-08-20 12:54:18.643782\n",
      "resetting env. episode 7962, reward total was -15.0. running mean: -13.532976446544462, timestamp: 2022-08-20 12:54:23.834842\n",
      "resetting env. episode 7963, reward total was -15.0. running mean: -13.547646682079018, timestamp: 2022-08-20 12:54:28.081891\n",
      "resetting env. episode 7964, reward total was -7.0. running mean: -13.482170215258227, timestamp: 2022-08-20 12:54:34.164959\n",
      "resetting env. episode 7965, reward total was -17.0. running mean: -13.517348513105645, timestamp: 2022-08-20 12:54:39.456018\n",
      "resetting env. episode 7966, reward total was -15.0. running mean: -13.532175027974588, timestamp: 2022-08-20 12:54:44.519082\n",
      "resetting env. episode 7967, reward total was -8.0. running mean: -13.476853277694843, timestamp: 2022-08-20 12:54:51.676160\n",
      "resetting env. episode 7968, reward total was -14.0. running mean: -13.482084744917895, timestamp: 2022-08-20 12:54:57.536232\n",
      "resetting env. episode 7969, reward total was -7.0. running mean: -13.417263897468716, timestamp: 2022-08-20 12:55:04.280306\n",
      "resetting env. episode 7970, reward total was -8.0. running mean: -13.363091258494029, timestamp: 2022-08-20 12:55:10.148374\n",
      "resetting env. episode 7971, reward total was -12.0. running mean: -13.349460345909087, timestamp: 2022-08-20 12:55:15.273431\n",
      "resetting env. episode 7972, reward total was -11.0. running mean: -13.325965742449995, timestamp: 2022-08-20 12:55:20.861498\n",
      "resetting env. episode 7973, reward total was -9.0. running mean: -13.282706085025495, timestamp: 2022-08-20 12:55:27.170567\n",
      "resetting env. episode 7974, reward total was -9.0. running mean: -13.23987902417524, timestamp: 2022-08-20 12:55:33.172639\n",
      "resetting env. episode 7975, reward total was -9.0. running mean: -13.197480233933486, timestamp: 2022-08-20 12:55:39.093705\n",
      "resetting env. episode 7976, reward total was -12.0. running mean: -13.185505431594152, timestamp: 2022-08-20 12:55:46.282789\n",
      "resetting env. episode 7977, reward total was -11.0. running mean: -13.16365037727821, timestamp: 2022-08-20 12:55:51.513848\n",
      "resetting env. episode 7978, reward total was -14.0. running mean: -13.172013873505428, timestamp: 2022-08-20 12:55:56.180902\n",
      "resetting env. episode 7979, reward total was -11.0. running mean: -13.150293734770372, timestamp: 2022-08-20 12:56:00.475953\n",
      "resetting env. episode 7980, reward total was -6.0. running mean: -13.078790797422668, timestamp: 2022-08-20 12:56:07.454032\n",
      "resetting env. episode 7981, reward total was -12.0. running mean: -13.06800288944844, timestamp: 2022-08-20 12:56:12.175086\n",
      "resetting env. episode 7982, reward total was -17.0. running mean: -13.107322860553955, timestamp: 2022-08-20 12:56:16.384136\n",
      "resetting env. episode 7983, reward total was -16.0. running mean: -13.136249631948415, timestamp: 2022-08-20 12:56:20.311179\n",
      "resetting env. episode 7984, reward total was -7.0. running mean: -13.07488713562893, timestamp: 2022-08-20 12:56:26.653258\n",
      "resetting env. episode 7985, reward total was -15.0. running mean: -13.094138264272642, timestamp: 2022-08-20 12:56:31.917312\n",
      "resetting env. episode 7986, reward total was -18.0. running mean: -13.143196881629915, timestamp: 2022-08-20 12:56:35.912360\n",
      "resetting env. episode 7987, reward total was -9.0. running mean: -13.101764912813616, timestamp: 2022-08-20 12:56:42.434434\n",
      "resetting env. episode 7988, reward total was -10.0. running mean: -13.07074726368548, timestamp: 2022-08-20 12:56:47.802496\n",
      "resetting env. episode 7989, reward total was -9.0. running mean: -13.030039791048624, timestamp: 2022-08-20 12:56:54.386573\n",
      "resetting env. episode 7990, reward total was -12.0. running mean: -13.019739393138137, timestamp: 2022-08-20 12:57:00.662643\n",
      "resetting env. episode 7991, reward total was -11.0. running mean: -12.999541999206755, timestamp: 2022-08-20 12:57:07.499724\n",
      "resetting env. episode 7992, reward total was -8.0. running mean: -12.949546579214688, timestamp: 2022-08-20 12:57:14.146800\n",
      "resetting env. episode 7993, reward total was -14.0. running mean: -12.960051113422542, timestamp: 2022-08-20 12:57:19.407862\n",
      "resetting env. episode 7994, reward total was -13.0. running mean: -12.960450602288319, timestamp: 2022-08-20 12:57:25.158927\n",
      "resetting env. episode 7995, reward total was -14.0. running mean: -12.970846096265436, timestamp: 2022-08-20 12:57:31.494001\n",
      "resetting env. episode 7996, reward total was -14.0. running mean: -12.981137635302783, timestamp: 2022-08-20 12:57:36.907060\n",
      "resetting env. episode 7997, reward total was -12.0. running mean: -12.971326258949755, timestamp: 2022-08-20 12:57:43.424136\n",
      "resetting env. episode 7998, reward total was -15.0. running mean: -12.991612996360258, timestamp: 2022-08-20 12:57:48.333191\n",
      "resetting env. episode 7999, reward total was -19.0. running mean: -13.051696866396655, timestamp: 2022-08-20 12:57:52.666241\n",
      "resetting env. episode 8000, reward total was -6.0. running mean: -12.981179897732689, timestamp: 2022-08-20 12:57:59.887327\n",
      "resetting env. episode 8001, reward total was -15.0. running mean: -13.001368098755362, timestamp: 2022-08-20 12:58:06.169397\n",
      "resetting env. episode 8002, reward total was -13.0. running mean: -13.001354417767809, timestamp: 2022-08-20 12:58:11.343461\n",
      "resetting env. episode 8003, reward total was -10.0. running mean: -12.97134087359013, timestamp: 2022-08-20 12:58:16.465516\n",
      "resetting env. episode 8004, reward total was -19.0. running mean: -13.031627464854228, timestamp: 2022-08-20 12:58:20.047558\n",
      "resetting env. episode 8005, reward total was -14.0. running mean: -13.041311190205686, timestamp: 2022-08-20 12:58:26.460630\n",
      "resetting env. episode 8006, reward total was -17.0. running mean: -13.08089807830363, timestamp: 2022-08-20 12:58:32.464699\n",
      "resetting env. episode 8007, reward total was -8.0. running mean: -13.030089097520593, timestamp: 2022-08-20 12:58:39.836785\n",
      "resetting env. episode 8008, reward total was -15.0. running mean: -13.049788206545387, timestamp: 2022-08-20 12:58:45.310846\n",
      "resetting env. episode 8009, reward total was -18.0. running mean: -13.099290324479933, timestamp: 2022-08-20 12:58:49.729902\n",
      "resetting env. episode 8010, reward total was -13.0. running mean: -13.098297421235134, timestamp: 2022-08-20 12:58:56.608979\n",
      "resetting env. episode 8011, reward total was -11.0. running mean: -13.077314447022783, timestamp: 2022-08-20 12:59:04.375070\n",
      "resetting env. episode 8012, reward total was -5.0. running mean: -12.996541302552556, timestamp: 2022-08-20 12:59:11.859153\n",
      "resetting env. episode 8013, reward total was -11.0. running mean: -12.97657588952703, timestamp: 2022-08-20 12:59:17.896222\n",
      "resetting env. episode 8014, reward total was -12.0. running mean: -12.966810130631758, timestamp: 2022-08-20 12:59:23.324289\n",
      "resetting env. episode 8015, reward total was -16.0. running mean: -12.99714202932544, timestamp: 2022-08-20 12:59:28.375340\n",
      "resetting env. episode 8016, reward total was -18.0. running mean: -13.047170609032186, timestamp: 2022-08-20 12:59:31.898383\n",
      "resetting env. episode 8017, reward total was -8.0. running mean: -12.996698902941864, timestamp: 2022-08-20 12:59:38.205454\n",
      "resetting env. episode 8018, reward total was -21.0. running mean: -13.076731913912447, timestamp: 2022-08-20 12:59:42.975511\n",
      "resetting env. episode 8019, reward total was -15.0. running mean: -13.095964594773323, timestamp: 2022-08-20 12:59:48.122573\n",
      "resetting env. episode 8020, reward total was -7.0. running mean: -13.03500494882559, timestamp: 2022-08-20 12:59:55.665657\n",
      "resetting env. episode 8021, reward total was -11.0. running mean: -13.014654899337334, timestamp: 2022-08-20 13:00:01.476726\n",
      "resetting env. episode 8022, reward total was -15.0. running mean: -13.03450835034396, timestamp: 2022-08-20 13:00:06.265780\n",
      "resetting env. episode 8023, reward total was -19.0. running mean: -13.094163266840521, timestamp: 2022-08-20 13:00:11.380839\n",
      "resetting env. episode 8024, reward total was -9.0. running mean: -13.053221634172116, timestamp: 2022-08-20 13:00:18.392926\n",
      "resetting env. episode 8025, reward total was -18.0. running mean: -13.102689417830394, timestamp: 2022-08-20 13:00:23.186979\n",
      "resetting env. episode 8026, reward total was -14.0. running mean: -13.111662523652091, timestamp: 2022-08-20 13:00:28.869040\n",
      "resetting env. episode 8027, reward total was -14.0. running mean: -13.120545898415571, timestamp: 2022-08-20 13:00:34.047099\n",
      "resetting env. episode 8028, reward total was -15.0. running mean: -13.139340439431416, timestamp: 2022-08-20 13:00:39.027156\n",
      "resetting env. episode 8029, reward total was -8.0. running mean: -13.087947035037102, timestamp: 2022-08-20 13:00:45.470229\n",
      "resetting env. episode 8030, reward total was -13.0. running mean: -13.087067564686732, timestamp: 2022-08-20 13:00:51.047293\n",
      "resetting env. episode 8031, reward total was -13.0. running mean: -13.086196889039865, timestamp: 2022-08-20 13:00:56.380353\n",
      "resetting env. episode 8032, reward total was -7.0. running mean: -13.025334920149467, timestamp: 2022-08-20 13:01:03.483435\n",
      "resetting env. episode 8033, reward total was -14.0. running mean: -13.035081570947973, timestamp: 2022-08-20 13:01:08.861499\n",
      "resetting env. episode 8034, reward total was -9.0. running mean: -12.994730755238493, timestamp: 2022-08-20 13:01:15.099571\n",
      "resetting env. episode 8035, reward total was -13.0. running mean: -12.994783447686109, timestamp: 2022-08-20 13:01:20.696634\n",
      "resetting env. episode 8036, reward total was -15.0. running mean: -13.014835613209248, timestamp: 2022-08-20 13:01:26.079695\n",
      "resetting env. episode 8037, reward total was -15.0. running mean: -13.034687257077156, timestamp: 2022-08-20 13:01:31.915764\n",
      "resetting env. episode 8038, reward total was -14.0. running mean: -13.044340384506384, timestamp: 2022-08-20 13:01:37.092823\n",
      "resetting env. episode 8039, reward total was -9.0. running mean: -13.00389698066132, timestamp: 2022-08-20 13:01:43.073896\n",
      "resetting env. episode 8040, reward total was -5.0. running mean: -12.923858010854708, timestamp: 2022-08-20 13:01:51.270987\n",
      "resetting env. episode 8041, reward total was -15.0. running mean: -12.944619430746162, timestamp: 2022-08-20 13:01:56.478044\n",
      "resetting env. episode 8042, reward total was -12.0. running mean: -12.935173236438699, timestamp: 2022-08-20 13:02:02.659116\n",
      "resetting env. episode 8043, reward total was -15.0. running mean: -12.955821504074311, timestamp: 2022-08-20 13:02:07.477170\n",
      "resetting env. episode 8044, reward total was -17.0. running mean: -12.996263289033568, timestamp: 2022-08-20 13:02:11.009219\n",
      "resetting env. episode 8045, reward total was -17.0. running mean: -13.036300656143231, timestamp: 2022-08-20 13:02:16.050270\n",
      "resetting env. episode 8046, reward total was -8.0. running mean: -12.985937649581798, timestamp: 2022-08-20 13:02:21.367332\n",
      "resetting env. episode 8047, reward total was -14.0. running mean: -12.996078273085981, timestamp: 2022-08-20 13:02:26.184389\n",
      "resetting env. episode 8048, reward total was -12.0. running mean: -12.98611749035512, timestamp: 2022-08-20 13:02:32.050459\n",
      "resetting env. episode 8049, reward total was -11.0. running mean: -12.966256315451568, timestamp: 2022-08-20 13:02:37.216516\n",
      "resetting env. episode 8050, reward total was -17.0. running mean: -13.006593752297052, timestamp: 2022-08-20 13:02:42.337573\n",
      "resetting env. episode 8051, reward total was -12.0. running mean: -12.99652781477408, timestamp: 2022-08-20 13:02:48.489645\n",
      "resetting env. episode 8052, reward total was -12.0. running mean: -12.986562536626337, timestamp: 2022-08-20 13:02:55.292732\n",
      "resetting env. episode 8053, reward total was -19.0. running mean: -13.046696911260073, timestamp: 2022-08-20 13:03:00.114783\n",
      "resetting env. episode 8054, reward total was -16.0. running mean: -13.076229942147473, timestamp: 2022-08-20 13:03:04.606162\n",
      "resetting env. episode 8055, reward total was -3.0. running mean: -12.975467642725997, timestamp: 2022-08-20 13:03:12.562923\n",
      "resetting env. episode 8056, reward total was -20.0. running mean: -13.045712966298737, timestamp: 2022-08-20 13:03:16.103960\n",
      "resetting env. episode 8057, reward total was -13.0. running mean: -13.04525583663575, timestamp: 2022-08-20 13:03:20.938015\n",
      "resetting env. episode 8058, reward total was -11.0. running mean: -13.024803278269392, timestamp: 2022-08-20 13:03:26.524086\n",
      "resetting env. episode 8059, reward total was -17.0. running mean: -13.064555245486698, timestamp: 2022-08-20 13:03:31.949143\n",
      "resetting env. episode 8060, reward total was -9.0. running mean: -13.02390969303183, timestamp: 2022-08-20 13:03:38.340218\n",
      "resetting env. episode 8061, reward total was -15.0. running mean: -13.043670596101514, timestamp: 2022-08-20 13:03:42.406265\n",
      "resetting env. episode 8062, reward total was -11.0. running mean: -13.023233890140498, timestamp: 2022-08-20 13:03:48.237333\n",
      "resetting env. episode 8063, reward total was -19.0. running mean: -13.083001551239091, timestamp: 2022-08-20 13:03:52.322378\n",
      "resetting env. episode 8064, reward total was -14.0. running mean: -13.0921715357267, timestamp: 2022-08-20 13:03:57.495436\n",
      "resetting env. episode 8065, reward total was -11.0. running mean: -13.071249820369433, timestamp: 2022-08-20 13:04:02.161491\n",
      "resetting env. episode 8066, reward total was 1.0. running mean: -12.930537322165739, timestamp: 2022-08-20 13:04:09.776580\n",
      "resetting env. episode 8067, reward total was -14.0. running mean: -12.941231948944083, timestamp: 2022-08-20 13:04:14.792637\n",
      "resetting env. episode 8068, reward total was -18.0. running mean: -12.99181962945464, timestamp: 2022-08-20 13:04:20.328698\n",
      "resetting env. episode 8069, reward total was -15.0. running mean: -13.011901433160094, timestamp: 2022-08-20 13:04:25.487759\n",
      "resetting env. episode 8070, reward total was -16.0. running mean: -13.041782418828493, timestamp: 2022-08-20 13:04:29.162801\n",
      "resetting env. episode 8071, reward total was -14.0. running mean: -13.051364594640209, timestamp: 2022-08-20 13:04:33.966858\n",
      "resetting env. episode 8072, reward total was -15.0. running mean: -13.070850948693806, timestamp: 2022-08-20 13:04:39.496919\n",
      "resetting env. episode 8073, reward total was -18.0. running mean: -13.120142439206868, timestamp: 2022-08-20 13:04:44.101974\n",
      "resetting env. episode 8074, reward total was -17.0. running mean: -13.158941014814799, timestamp: 2022-08-20 13:04:48.731028\n",
      "resetting env. episode 8075, reward total was -15.0. running mean: -13.17735160466665, timestamp: 2022-08-20 13:04:53.702086\n",
      "resetting env. episode 8076, reward total was -13.0. running mean: -13.175578088619986, timestamp: 2022-08-20 13:04:59.677149\n",
      "resetting env. episode 8077, reward total was -13.0. running mean: -13.173822307733786, timestamp: 2022-08-20 13:05:04.061202\n",
      "resetting env. episode 8078, reward total was -11.0. running mean: -13.152084084656448, timestamp: 2022-08-20 13:05:10.264273\n",
      "resetting env. episode 8079, reward total was -16.0. running mean: -13.180563243809884, timestamp: 2022-08-20 13:05:14.174316\n",
      "resetting env. episode 8080, reward total was -11.0. running mean: -13.158757611371785, timestamp: 2022-08-20 13:05:21.009395\n",
      "resetting env. episode 8081, reward total was -7.0. running mean: -13.097170035258067, timestamp: 2022-08-20 13:05:28.254479\n",
      "resetting env. episode 8082, reward total was -10.0. running mean: -13.066198334905486, timestamp: 2022-08-20 13:05:34.101548\n",
      "resetting env. episode 8083, reward total was -7.0. running mean: -13.005536351556431, timestamp: 2022-08-20 13:05:40.033613\n",
      "resetting env. episode 8084, reward total was -21.0. running mean: -13.085480988040867, timestamp: 2022-08-20 13:05:43.477650\n",
      "resetting env. episode 8085, reward total was -17.0. running mean: -13.124626178160458, timestamp: 2022-08-20 13:05:48.750711\n",
      "resetting env. episode 8086, reward total was -19.0. running mean: -13.183379916378852, timestamp: 2022-08-20 13:05:52.778757\n",
      "resetting env. episode 8087, reward total was -11.0. running mean: -13.161546117215064, timestamp: 2022-08-20 13:05:59.557838\n",
      "resetting env. episode 8088, reward total was -17.0. running mean: -13.199930656042913, timestamp: 2022-08-20 13:06:03.725881\n",
      "resetting env. episode 8089, reward total was -10.0. running mean: -13.167931349482483, timestamp: 2022-08-20 13:06:09.245946\n",
      "resetting env. episode 8090, reward total was -18.0. running mean: -13.216252035987658, timestamp: 2022-08-20 13:06:14.389004\n",
      "resetting env. episode 8091, reward total was -9.0. running mean: -13.17408951562778, timestamp: 2022-08-20 13:06:21.539086\n",
      "resetting env. episode 8092, reward total was -5.0. running mean: -13.092348620471503, timestamp: 2022-08-20 13:06:26.967145\n",
      "resetting env. episode 8093, reward total was -17.0. running mean: -13.131425134266788, timestamp: 2022-08-20 13:06:31.586202\n",
      "resetting env. episode 8094, reward total was -17.0. running mean: -13.17011088292412, timestamp: 2022-08-20 13:06:36.721257\n",
      "resetting env. episode 8095, reward total was -15.0. running mean: -13.188409774094879, timestamp: 2022-08-20 13:06:41.400313\n",
      "resetting env. episode 8096, reward total was -13.0. running mean: -13.18652567635393, timestamp: 2022-08-20 13:06:47.063376\n",
      "resetting env. episode 8097, reward total was -17.0. running mean: -13.224660419590391, timestamp: 2022-08-20 13:06:52.766441\n",
      "resetting env. episode 8098, reward total was -11.0. running mean: -13.202413815394486, timestamp: 2022-08-20 13:06:58.978512\n",
      "resetting env. episode 8099, reward total was -17.0. running mean: -13.240389677240541, timestamp: 2022-08-20 13:07:03.090560\n",
      "resetting env. episode 8100, reward total was -9.0. running mean: -13.197985780468136, timestamp: 2022-08-20 13:07:08.771622\n",
      "resetting env. episode 8101, reward total was -7.0. running mean: -13.136005922663454, timestamp: 2022-08-20 13:07:14.930695\n",
      "resetting env. episode 8102, reward total was -15.0. running mean: -13.15464586343682, timestamp: 2022-08-20 13:07:19.440746\n",
      "resetting env. episode 8103, reward total was -14.0. running mean: -13.163099404802452, timestamp: 2022-08-20 13:07:24.713809\n",
      "resetting env. episode 8104, reward total was -15.0. running mean: -13.181468410754428, timestamp: 2022-08-20 13:07:29.334856\n",
      "resetting env. episode 8105, reward total was -10.0. running mean: -13.149653726646884, timestamp: 2022-08-20 13:07:36.119937\n",
      "resetting env. episode 8106, reward total was -16.0. running mean: -13.178157189380414, timestamp: 2022-08-20 13:07:41.758998\n",
      "resetting env. episode 8107, reward total was -9.0. running mean: -13.13637561748661, timestamp: 2022-08-20 13:07:48.416075\n",
      "resetting env. episode 8108, reward total was -13.0. running mean: -13.135011861311744, timestamp: 2022-08-20 13:07:54.600148\n",
      "resetting env. episode 8109, reward total was -11.0. running mean: -13.113661742698627, timestamp: 2022-08-20 13:07:59.593202\n",
      "resetting env. episode 8110, reward total was -12.0. running mean: -13.10252512527164, timestamp: 2022-08-20 13:08:04.768262\n",
      "resetting env. episode 8111, reward total was -11.0. running mean: -13.081499874018924, timestamp: 2022-08-20 13:08:10.677328\n",
      "resetting env. episode 8112, reward total was -12.0. running mean: -13.070684875278733, timestamp: 2022-08-20 13:08:17.255402\n",
      "resetting env. episode 8113, reward total was -11.0. running mean: -13.049978026525945, timestamp: 2022-08-20 13:08:24.398485\n",
      "resetting env. episode 8114, reward total was -16.0. running mean: -13.079478246260686, timestamp: 2022-08-20 13:08:28.955538\n",
      "resetting env. episode 8115, reward total was -11.0. running mean: -13.05868346379808, timestamp: 2022-08-20 13:08:34.640602\n",
      "resetting env. episode 8116, reward total was -17.0. running mean: -13.098096629160098, timestamp: 2022-08-20 13:08:39.799664\n",
      "resetting env. episode 8117, reward total was -9.0. running mean: -13.057115662868497, timestamp: 2022-08-20 13:08:44.983722\n",
      "resetting env. episode 8118, reward total was -13.0. running mean: -13.056544506239813, timestamp: 2022-08-20 13:08:50.119777\n",
      "resetting env. episode 8119, reward total was -15.0. running mean: -13.075979061177415, timestamp: 2022-08-20 13:08:54.950833\n",
      "resetting env. episode 8120, reward total was -9.0. running mean: -13.03521927056564, timestamp: 2022-08-20 13:09:02.497917\n",
      "resetting env. episode 8121, reward total was -10.0. running mean: -13.004867077859984, timestamp: 2022-08-20 13:09:09.656003\n",
      "resetting env. episode 8122, reward total was -13.0. running mean: -13.004818407081386, timestamp: 2022-08-20 13:09:15.494067\n",
      "resetting env. episode 8123, reward total was -15.0. running mean: -13.024770223010572, timestamp: 2022-08-20 13:09:20.387122\n",
      "resetting env. episode 8124, reward total was -13.0. running mean: -13.024522520780467, timestamp: 2022-08-20 13:09:25.034174\n",
      "resetting env. episode 8125, reward total was -16.0. running mean: -13.054277295572662, timestamp: 2022-08-20 13:09:28.477211\n",
      "resetting env. episode 8126, reward total was -14.0. running mean: -13.063734522616937, timestamp: 2022-08-20 13:09:32.785260\n",
      "resetting env. episode 8127, reward total was -18.0. running mean: -13.113097177390767, timestamp: 2022-08-20 13:09:37.202311\n",
      "resetting env. episode 8128, reward total was -13.0. running mean: -13.11196620561686, timestamp: 2022-08-20 13:09:42.107102\n",
      "resetting env. episode 8129, reward total was -7.0. running mean: -13.050846543560692, timestamp: 2022-08-20 13:09:47.746165\n",
      "resetting env. episode 8130, reward total was -13.0. running mean: -13.050338078125085, timestamp: 2022-08-20 13:09:53.514228\n",
      "resetting env. episode 8131, reward total was -16.0. running mean: -13.079834697343834, timestamp: 2022-08-20 13:09:58.367282\n",
      "resetting env. episode 8132, reward total was -15.0. running mean: -13.099036350370396, timestamp: 2022-08-20 13:10:05.238364\n",
      "resetting env. episode 8133, reward total was -14.0. running mean: -13.108045986866692, timestamp: 2022-08-20 13:10:11.115434\n",
      "resetting env. episode 8134, reward total was -19.0. running mean: -13.166965526998025, timestamp: 2022-08-20 13:10:15.247482\n",
      "resetting env. episode 8135, reward total was -17.0. running mean: -13.205295871728044, timestamp: 2022-08-20 13:10:19.938530\n",
      "resetting env. episode 8136, reward total was -15.0. running mean: -13.223242913010763, timestamp: 2022-08-20 13:10:25.135589\n",
      "resetting env. episode 8137, reward total was -11.0. running mean: -13.201010483880655, timestamp: 2022-08-20 13:10:30.753655\n",
      "resetting env. episode 8138, reward total was -14.0. running mean: -13.209000379041848, timestamp: 2022-08-20 13:10:35.650721\n",
      "resetting env. episode 8139, reward total was -13.0. running mean: -13.20691037525143, timestamp: 2022-08-20 13:10:41.901782\n",
      "resetting env. episode 8140, reward total was -19.0. running mean: -13.264841271498916, timestamp: 2022-08-20 13:10:47.587846\n",
      "resetting env. episode 8141, reward total was -10.0. running mean: -13.232192858783927, timestamp: 2022-08-20 13:10:52.965906\n",
      "resetting env. episode 8142, reward total was -15.0. running mean: -13.249870930196089, timestamp: 2022-08-20 13:10:57.873963\n",
      "resetting env. episode 8143, reward total was -15.0. running mean: -13.267372220894128, timestamp: 2022-08-20 13:11:02.142014\n",
      "resetting env. episode 8144, reward total was -8.0. running mean: -13.214698498685186, timestamp: 2022-08-20 13:11:07.953079\n",
      "resetting env. episode 8145, reward total was -11.0. running mean: -13.192551513698334, timestamp: 2022-08-20 13:11:14.025152\n",
      "resetting env. episode 8146, reward total was -16.0. running mean: -13.220625998561351, timestamp: 2022-08-20 13:11:18.346202\n",
      "resetting env. episode 8147, reward total was -7.0. running mean: -13.158419738575738, timestamp: 2022-08-20 13:11:24.946276\n",
      "resetting env. episode 8148, reward total was -13.0. running mean: -13.15683554118998, timestamp: 2022-08-20 13:11:29.505328\n",
      "resetting env. episode 8149, reward total was -14.0. running mean: -13.165267185778081, timestamp: 2022-08-20 13:11:34.437384\n",
      "resetting env. episode 8150, reward total was -6.0. running mean: -13.0936145139203, timestamp: 2022-08-20 13:11:41.767467\n",
      "resetting env. episode 8151, reward total was -17.0. running mean: -13.132678368781097, timestamp: 2022-08-20 13:11:46.032521\n",
      "resetting env. episode 8152, reward total was -13.0. running mean: -13.131351585093286, timestamp: 2022-08-20 13:11:51.330578\n",
      "resetting env. episode 8153, reward total was -11.0. running mean: -13.110038069242353, timestamp: 2022-08-20 13:11:55.575630\n",
      "resetting env. episode 8154, reward total was -5.0. running mean: -13.02893768854993, timestamp: 2022-08-20 13:12:02.039701\n",
      "resetting env. episode 8155, reward total was -14.0. running mean: -13.038648311664431, timestamp: 2022-08-20 13:12:08.454775\n",
      "resetting env. episode 8156, reward total was -13.0. running mean: -13.038261828547787, timestamp: 2022-08-20 13:12:14.219841\n",
      "resetting env. episode 8157, reward total was -14.0. running mean: -13.047879210262309, timestamp: 2022-08-20 13:12:19.017894\n",
      "resetting env. episode 8158, reward total was -10.0. running mean: -13.017400418159685, timestamp: 2022-08-20 13:12:24.130961\n",
      "resetting env. episode 8159, reward total was -14.0. running mean: -13.027226413978088, timestamp: 2022-08-20 13:12:28.754007\n",
      "resetting env. episode 8160, reward total was -15.0. running mean: -13.046954149838307, timestamp: 2022-08-20 13:12:33.939071\n",
      "resetting env. episode 8161, reward total was -14.0. running mean: -13.056484608339924, timestamp: 2022-08-20 13:12:38.956126\n",
      "resetting env. episode 8162, reward total was -21.0. running mean: -13.135919762256526, timestamp: 2022-08-20 13:12:42.285166\n",
      "resetting env. episode 8163, reward total was -12.0. running mean: -13.12456056463396, timestamp: 2022-08-20 13:12:48.231234\n",
      "resetting env. episode 8164, reward total was -12.0. running mean: -13.113314958987619, timestamp: 2022-08-20 13:12:54.161302\n",
      "resetting env. episode 8165, reward total was -16.0. running mean: -13.142181809397742, timestamp: 2022-08-20 13:12:59.406365\n",
      "resetting env. episode 8166, reward total was -13.0. running mean: -13.140759991303765, timestamp: 2022-08-20 13:13:05.318432\n",
      "resetting env. episode 8167, reward total was -10.0. running mean: -13.109352391390727, timestamp: 2022-08-20 13:13:11.381503\n",
      "resetting env. episode 8168, reward total was -11.0. running mean: -13.088258867476819, timestamp: 2022-08-20 13:13:17.784577\n",
      "resetting env. episode 8169, reward total was -13.0. running mean: -13.08737627880205, timestamp: 2022-08-20 13:13:23.758648\n",
      "resetting env. episode 8170, reward total was -16.0. running mean: -13.11650251601403, timestamp: 2022-08-20 13:13:27.425686\n",
      "resetting env. episode 8171, reward total was -16.0. running mean: -13.14533749085389, timestamp: 2022-08-20 13:13:32.544751\n",
      "resetting env. episode 8172, reward total was -8.0. running mean: -13.093884115945352, timestamp: 2022-08-20 13:13:37.419806\n",
      "resetting env. episode 8173, reward total was -8.0. running mean: -13.042945274785898, timestamp: 2022-08-20 13:13:45.102894\n",
      "resetting env. episode 8174, reward total was -13.0. running mean: -13.042515822038041, timestamp: 2022-08-20 13:13:49.564952\n",
      "resetting env. episode 8175, reward total was -3.0. running mean: -12.94209066381766, timestamp: 2022-08-20 13:13:55.738021\n",
      "resetting env. episode 8176, reward total was -12.0. running mean: -12.932669757179482, timestamp: 2022-08-20 13:14:02.877099\n",
      "resetting env. episode 8177, reward total was -7.0. running mean: -12.873343059607688, timestamp: 2022-08-20 13:14:09.361173\n",
      "resetting env. episode 8178, reward total was -17.0. running mean: -12.914609629011611, timestamp: 2022-08-20 13:14:13.913228\n",
      "resetting env. episode 8179, reward total was 6.0. running mean: -12.725463532721495, timestamp: 2022-08-20 13:14:20.265301\n",
      "resetting env. episode 8180, reward total was -15.0. running mean: -12.74820889739428, timestamp: 2022-08-20 13:14:26.165369\n",
      "resetting env. episode 8181, reward total was -17.0. running mean: -12.790726808420336, timestamp: 2022-08-20 13:14:28.999408\n",
      "resetting env. episode 8182, reward total was 6.0. running mean: -12.602819540336132, timestamp: 2022-08-20 13:14:35.466476\n",
      "resetting env. episode 8183, reward total was -15.0. running mean: -12.626791344932771, timestamp: 2022-08-20 13:14:40.536536\n",
      "resetting env. episode 8184, reward total was -13.0. running mean: -12.630523431483445, timestamp: 2022-08-20 13:14:45.295593\n",
      "resetting env. episode 8185, reward total was -17.0. running mean: -12.67421819716861, timestamp: 2022-08-20 13:14:49.507643\n",
      "resetting env. episode 8186, reward total was -10.0. running mean: -12.647476015196924, timestamp: 2022-08-20 13:14:55.559711\n",
      "resetting env. episode 8187, reward total was -10.0. running mean: -12.621001255044954, timestamp: 2022-08-20 13:15:02.872795\n",
      "resetting env. episode 8188, reward total was -13.0. running mean: -12.624791242494505, timestamp: 2022-08-20 13:15:07.709855\n",
      "resetting env. episode 8189, reward total was -15.0. running mean: -12.64854333006956, timestamp: 2022-08-20 13:15:12.335909\n",
      "resetting env. episode 8190, reward total was -9.0. running mean: -12.612057896768864, timestamp: 2022-08-20 13:15:17.917973\n",
      "resetting env. episode 8191, reward total was -11.0. running mean: -12.595937317801175, timestamp: 2022-08-20 13:15:23.694038\n",
      "resetting env. episode 8192, reward total was -11.0. running mean: -12.579977944623163, timestamp: 2022-08-20 13:15:29.983111\n",
      "resetting env. episode 8193, reward total was -15.0. running mean: -12.604178165176933, timestamp: 2022-08-20 13:15:35.039168\n",
      "resetting env. episode 8194, reward total was -8.0. running mean: -12.558136383525163, timestamp: 2022-08-20 13:15:40.979240\n",
      "resetting env. episode 8195, reward total was -19.0. running mean: -12.62255501968991, timestamp: 2022-08-20 13:15:46.184300\n",
      "resetting env. episode 8196, reward total was -13.0. running mean: -12.626329469493012, timestamp: 2022-08-20 13:15:50.885353\n",
      "resetting env. episode 8197, reward total was -14.0. running mean: -12.640066174798083, timestamp: 2022-08-20 13:15:55.619411\n",
      "resetting env. episode 8198, reward total was -14.0. running mean: -12.653665513050102, timestamp: 2022-08-20 13:16:01.082470\n",
      "resetting env. episode 8199, reward total was -6.0. running mean: -12.587128857919602, timestamp: 2022-08-20 13:16:08.086552\n",
      "resetting env. episode 8200, reward total was -19.0. running mean: -12.651257569340405, timestamp: 2022-08-20 13:16:12.092596\n",
      "resetting env. episode 8201, reward total was -17.0. running mean: -12.694744993647001, timestamp: 2022-08-20 13:16:17.545660\n",
      "resetting env. episode 8202, reward total was -13.0. running mean: -12.697797543710532, timestamp: 2022-08-20 13:16:23.469735\n",
      "resetting env. episode 8203, reward total was -7.0. running mean: -12.640819568273427, timestamp: 2022-08-20 13:16:30.272813\n",
      "resetting env. episode 8204, reward total was -15.0. running mean: -12.664411372590694, timestamp: 2022-08-20 13:16:34.916863\n",
      "resetting env. episode 8205, reward total was -17.0. running mean: -12.707767258864786, timestamp: 2022-08-20 13:16:40.322925\n",
      "resetting env. episode 8206, reward total was -14.0. running mean: -12.720689586276139, timestamp: 2022-08-20 13:16:44.820978\n",
      "resetting env. episode 8207, reward total was -10.0. running mean: -12.693482690413378, timestamp: 2022-08-20 13:16:49.142031\n",
      "resetting env. episode 8208, reward total was -15.0. running mean: -12.716547863509245, timestamp: 2022-08-20 13:16:53.618079\n",
      "resetting env. episode 8209, reward total was -12.0. running mean: -12.709382384874152, timestamp: 2022-08-20 13:17:00.265156\n",
      "resetting env. episode 8210, reward total was -17.0. running mean: -12.75228856102541, timestamp: 2022-08-20 13:17:05.317223\n",
      "resetting env. episode 8211, reward total was -16.0. running mean: -12.784765675415155, timestamp: 2022-08-20 13:17:11.316285\n",
      "resetting env. episode 8212, reward total was -11.0. running mean: -12.766918018661002, timestamp: 2022-08-20 13:17:17.564359\n",
      "resetting env. episode 8213, reward total was -17.0. running mean: -12.809248838474392, timestamp: 2022-08-20 13:17:22.052458\n",
      "resetting env. episode 8214, reward total was -15.0. running mean: -12.831156350089648, timestamp: 2022-08-20 13:17:26.684508\n",
      "resetting env. episode 8215, reward total was -10.0. running mean: -12.802844786588752, timestamp: 2022-08-20 13:17:32.080572\n",
      "resetting env. episode 8216, reward total was -13.0. running mean: -12.804816338722866, timestamp: 2022-08-20 13:17:37.022627\n",
      "resetting env. episode 8217, reward total was -16.0. running mean: -12.836768175335637, timestamp: 2022-08-20 13:17:41.552681\n",
      "resetting env. episode 8218, reward total was -8.0. running mean: -12.78840049358228, timestamp: 2022-08-20 13:17:48.444767\n",
      "resetting env. episode 8219, reward total was -12.0. running mean: -12.780516488646457, timestamp: 2022-08-20 13:17:53.818824\n",
      "resetting env. episode 8220, reward total was -15.0. running mean: -12.802711323759993, timestamp: 2022-08-20 13:17:58.688879\n",
      "resetting env. episode 8221, reward total was -9.0. running mean: -12.764684210522393, timestamp: 2022-08-20 13:18:05.019955\n",
      "resetting env. episode 8222, reward total was -14.0. running mean: -12.77703736841717, timestamp: 2022-08-20 13:18:11.265027\n",
      "resetting env. episode 8223, reward total was -15.0. running mean: -12.799266994733, timestamp: 2022-08-20 13:18:15.445078\n",
      "resetting env. episode 8224, reward total was -9.0. running mean: -12.761274324785669, timestamp: 2022-08-20 13:18:21.423145\n",
      "resetting env. episode 8225, reward total was -17.0. running mean: -12.803661581537812, timestamp: 2022-08-20 13:18:25.914198\n",
      "resetting env. episode 8226, reward total was -15.0. running mean: -12.825624965722433, timestamp: 2022-08-20 13:18:31.173261\n",
      "resetting env. episode 8227, reward total was -11.0. running mean: -12.807368716065207, timestamp: 2022-08-20 13:18:35.525310\n",
      "resetting env. episode 8228, reward total was -13.0. running mean: -12.809295028904556, timestamp: 2022-08-20 13:18:40.552368\n",
      "resetting env. episode 8229, reward total was -14.0. running mean: -12.82120207861551, timestamp: 2022-08-20 13:18:45.643427\n",
      "resetting env. episode 8230, reward total was -13.0. running mean: -12.822990057829356, timestamp: 2022-08-20 13:18:51.827496\n",
      "resetting env. episode 8231, reward total was -15.0. running mean: -12.844760157251063, timestamp: 2022-08-20 13:18:58.438573\n",
      "resetting env. episode 8232, reward total was -18.0. running mean: -12.896312555678552, timestamp: 2022-08-20 13:19:02.971626\n",
      "resetting env. episode 8233, reward total was -17.0. running mean: -12.937349430121767, timestamp: 2022-08-20 13:19:07.652684\n",
      "resetting env. episode 8234, reward total was -14.0. running mean: -12.94797593582055, timestamp: 2022-08-20 13:19:13.825754\n",
      "resetting env. episode 8235, reward total was -6.0. running mean: -12.878496176462344, timestamp: 2022-08-20 13:19:20.683833\n",
      "resetting env. episode 8236, reward total was -7.0. running mean: -12.81971121469772, timestamp: 2022-08-20 13:19:27.864916\n",
      "resetting env. episode 8237, reward total was -12.0. running mean: -12.811514102550742, timestamp: 2022-08-20 13:19:34.372995\n",
      "resetting env. episode 8238, reward total was -17.0. running mean: -12.853398961525235, timestamp: 2022-08-20 13:19:38.699043\n",
      "resetting env. episode 8239, reward total was -13.0. running mean: -12.854864971909983, timestamp: 2022-08-20 13:19:43.192093\n",
      "resetting env. episode 8240, reward total was -8.0. running mean: -12.806316322190883, timestamp: 2022-08-20 13:19:49.900173\n",
      "resetting env. episode 8241, reward total was -13.0. running mean: -12.808253158968974, timestamp: 2022-08-20 13:19:54.654226\n",
      "resetting env. episode 8242, reward total was -17.0. running mean: -12.850170627379283, timestamp: 2022-08-20 13:19:59.671288\n",
      "resetting env. episode 8243, reward total was -12.0. running mean: -12.841668921105489, timestamp: 2022-08-20 13:20:04.117337\n",
      "resetting env. episode 8244, reward total was -10.0. running mean: -12.813252231894433, timestamp: 2022-08-20 13:20:09.313395\n",
      "resetting env. episode 8245, reward total was -19.0. running mean: -12.875119709575488, timestamp: 2022-08-20 13:20:12.435433\n",
      "resetting env. episode 8246, reward total was -11.0. running mean: -12.856368512479733, timestamp: 2022-08-20 13:20:18.305499\n",
      "resetting env. episode 8247, reward total was -19.0. running mean: -12.917804827354935, timestamp: 2022-08-20 13:20:22.351553\n",
      "resetting env. episode 8248, reward total was -11.0. running mean: -12.898626779081384, timestamp: 2022-08-20 13:20:27.305603\n",
      "resetting env. episode 8249, reward total was -13.0. running mean: -12.89964051129057, timestamp: 2022-08-20 13:20:32.390664\n",
      "resetting env. episode 8250, reward total was -12.0. running mean: -12.890644106177664, timestamp: 2022-08-20 13:20:37.143721\n",
      "resetting env. episode 8251, reward total was -11.0. running mean: -12.871737665115887, timestamp: 2022-08-20 13:20:42.603782\n",
      "resetting env. episode 8252, reward total was -17.0. running mean: -12.913020288464729, timestamp: 2022-08-20 13:20:45.884821\n",
      "resetting env. episode 8253, reward total was -13.0. running mean: -12.913890085580082, timestamp: 2022-08-20 13:20:51.038881\n",
      "resetting env. episode 8254, reward total was -17.0. running mean: -12.95475118472428, timestamp: 2022-08-20 13:20:55.285929\n",
      "resetting env. episode 8255, reward total was -18.0. running mean: -13.005203672877037, timestamp: 2022-08-20 13:20:59.901984\n",
      "resetting env. episode 8256, reward total was -17.0. running mean: -13.045151636148267, timestamp: 2022-08-20 13:21:03.839029\n",
      "resetting env. episode 8257, reward total was -7.0. running mean: -12.984700119786785, timestamp: 2022-08-20 13:21:10.738112\n",
      "resetting env. episode 8258, reward total was -12.0. running mean: -12.974853118588916, timestamp: 2022-08-20 13:21:16.383175\n",
      "resetting env. episode 8259, reward total was -17.0. running mean: -13.015104587403027, timestamp: 2022-08-20 13:21:20.573224\n",
      "resetting env. episode 8260, reward total was -13.0. running mean: -13.014953541528998, timestamp: 2022-08-20 13:21:25.287276\n",
      "resetting env. episode 8261, reward total was -18.0. running mean: -13.064804006113707, timestamp: 2022-08-20 13:21:30.090335\n",
      "resetting env. episode 8262, reward total was -20.0. running mean: -13.13415596605257, timestamp: 2022-08-20 13:21:33.786376\n",
      "resetting env. episode 8263, reward total was -11.0. running mean: -13.112814406392044, timestamp: 2022-08-20 13:21:39.335441\n",
      "resetting env. episode 8264, reward total was -13.0. running mean: -13.111686262328124, timestamp: 2022-08-20 13:21:43.363486\n",
      "resetting env. episode 8265, reward total was -15.0. running mean: -13.130569399704843, timestamp: 2022-08-20 13:21:48.666550\n",
      "resetting env. episode 8266, reward total was -18.0. running mean: -13.179263705707793, timestamp: 2022-08-20 13:21:52.696594\n",
      "resetting env. episode 8267, reward total was -19.0. running mean: -13.237471068650715, timestamp: 2022-08-20 13:21:55.771633\n",
      "resetting env. episode 8268, reward total was -15.0. running mean: -13.255096357964208, timestamp: 2022-08-20 13:22:00.396685\n",
      "resetting env. episode 8269, reward total was -10.0. running mean: -13.222545394384564, timestamp: 2022-08-20 13:22:06.046750\n",
      "resetting env. episode 8270, reward total was -13.0. running mean: -13.220319940440719, timestamp: 2022-08-20 13:22:11.988818\n",
      "resetting env. episode 8271, reward total was -6.0. running mean: -13.148116741036311, timestamp: 2022-08-20 13:22:17.844886\n",
      "resetting env. episode 8272, reward total was -19.0. running mean: -13.206635573625947, timestamp: 2022-08-20 13:22:21.853933\n",
      "resetting env. episode 8273, reward total was -6.0. running mean: -13.134569217889688, timestamp: 2022-08-20 13:22:28.503007\n",
      "resetting env. episode 8274, reward total was -16.0. running mean: -13.16322352571079, timestamp: 2022-08-20 13:22:33.041059\n",
      "resetting env. episode 8275, reward total was -13.0. running mean: -13.161591290453684, timestamp: 2022-08-20 13:22:37.361111\n",
      "resetting env. episode 8276, reward total was -11.0. running mean: -13.139975377549145, timestamp: 2022-08-20 13:22:41.617161\n",
      "resetting env. episode 8277, reward total was -13.0. running mean: -13.138575623773654, timestamp: 2022-08-20 13:22:45.318204\n",
      "resetting env. episode 8278, reward total was -15.0. running mean: -13.157189867535918, timestamp: 2022-08-20 13:22:50.313262\n",
      "resetting env. episode 8279, reward total was -18.0. running mean: -13.205617968860558, timestamp: 2022-08-20 13:22:53.986302\n",
      "resetting env. episode 8280, reward total was -15.0. running mean: -13.223561789171953, timestamp: 2022-08-20 13:22:58.375355\n",
      "resetting env. episode 8281, reward total was -15.0. running mean: -13.241326171280233, timestamp: 2022-08-20 13:23:03.422412\n",
      "resetting env. episode 8282, reward total was -13.0. running mean: -13.238912909567432, timestamp: 2022-08-20 13:23:08.047464\n",
      "resetting env. episode 8283, reward total was -12.0. running mean: -13.226523780471757, timestamp: 2022-08-20 13:23:13.732531\n",
      "resetting env. episode 8284, reward total was -14.0. running mean: -13.234258542667039, timestamp: 2022-08-20 13:23:17.771574\n",
      "resetting env. episode 8285, reward total was -11.0. running mean: -13.211915957240368, timestamp: 2022-08-20 13:23:23.711648\n",
      "resetting env. episode 8286, reward total was -13.0. running mean: -13.209796797667964, timestamp: 2022-08-20 13:23:28.038698\n",
      "resetting env. episode 8287, reward total was -14.0. running mean: -13.217698829691285, timestamp: 2022-08-20 13:23:34.003763\n",
      "resetting env. episode 8288, reward total was -15.0. running mean: -13.235521841394373, timestamp: 2022-08-20 13:23:38.391817\n",
      "resetting env. episode 8289, reward total was -11.0. running mean: -13.21316662298043, timestamp: 2022-08-20 13:23:44.466889\n",
      "resetting env. episode 8290, reward total was -14.0. running mean: -13.221034956750625, timestamp: 2022-08-20 13:23:49.542942\n",
      "resetting env. episode 8291, reward total was -15.0. running mean: -13.238824607183119, timestamp: 2022-08-20 13:23:55.130005\n",
      "resetting env. episode 8292, reward total was -14.0. running mean: -13.246436361111288, timestamp: 2022-08-20 13:23:59.035051\n",
      "resetting env. episode 8293, reward total was -11.0. running mean: -13.223971997500174, timestamp: 2022-08-20 13:24:05.178121\n",
      "resetting env. episode 8294, reward total was -11.0. running mean: -13.20173227752517, timestamp: 2022-08-20 13:24:10.709184\n",
      "resetting env. episode 8295, reward total was -11.0. running mean: -13.179714954749919, timestamp: 2022-08-20 13:24:16.766256\n",
      "resetting env. episode 8296, reward total was -12.0. running mean: -13.16791780520242, timestamp: 2022-08-20 13:24:21.139304\n",
      "resetting env. episode 8297, reward total was -7.0. running mean: -13.106238627150395, timestamp: 2022-08-20 13:24:26.930373\n",
      "resetting env. episode 8298, reward total was -9.0. running mean: -13.065176240878891, timestamp: 2022-08-20 13:24:34.030451\n",
      "resetting env. episode 8299, reward total was -17.0. running mean: -13.104524478470102, timestamp: 2022-08-20 13:24:38.217501\n",
      "resetting env. episode 8300, reward total was -19.0. running mean: -13.1634792336854, timestamp: 2022-08-20 13:24:42.512548\n",
      "resetting env. episode 8301, reward total was -10.0. running mean: -13.131844441348546, timestamp: 2022-08-20 13:24:48.741629\n",
      "resetting env. episode 8302, reward total was -13.0. running mean: -13.130525996935061, timestamp: 2022-08-20 13:24:54.585687\n",
      "resetting env. episode 8303, reward total was -16.0. running mean: -13.159220736965711, timestamp: 2022-08-20 13:24:59.771748\n",
      "resetting env. episode 8304, reward total was -6.0. running mean: -13.087628529596055, timestamp: 2022-08-20 13:25:07.890840\n",
      "resetting env. episode 8305, reward total was -6.0. running mean: -13.016752244300095, timestamp: 2022-08-20 13:25:14.803919\n",
      "resetting env. episode 8306, reward total was -17.0. running mean: -13.056584721857094, timestamp: 2022-08-20 13:25:19.402975\n",
      "resetting env. episode 8307, reward total was -12.0. running mean: -13.046018874638522, timestamp: 2022-08-20 13:25:24.549035\n",
      "resetting env. episode 8308, reward total was -15.0. running mean: -13.065558685892137, timestamp: 2022-08-20 13:25:30.131096\n",
      "resetting env. episode 8309, reward total was -18.0. running mean: -13.114903099033215, timestamp: 2022-08-20 13:25:33.607138\n",
      "resetting env. episode 8310, reward total was -9.0. running mean: -13.073754068042883, timestamp: 2022-08-20 13:25:40.065211\n",
      "resetting env. episode 8311, reward total was -13.0. running mean: -13.073016527362455, timestamp: 2022-08-20 13:25:45.552277\n",
      "resetting env. episode 8312, reward total was -8.0. running mean: -13.022286362088831, timestamp: 2022-08-20 13:25:53.230361\n",
      "resetting env. episode 8313, reward total was -10.0. running mean: -12.992063498467942, timestamp: 2022-08-20 13:25:58.680425\n",
      "resetting env. episode 8314, reward total was -8.0. running mean: -12.942142863483262, timestamp: 2022-08-20 13:26:05.978510\n",
      "resetting env. episode 8315, reward total was -9.0. running mean: -12.902721434848429, timestamp: 2022-08-20 13:26:10.653561\n",
      "resetting env. episode 8316, reward total was -16.0. running mean: -12.933694220499945, timestamp: 2022-08-20 13:26:15.753621\n",
      "resetting env. episode 8317, reward total was -15.0. running mean: -12.954357278294946, timestamp: 2022-08-20 13:26:20.828679\n",
      "resetting env. episode 8318, reward total was -7.0. running mean: -12.894813705511996, timestamp: 2022-08-20 13:26:27.096753\n",
      "resetting env. episode 8319, reward total was -15.0. running mean: -12.915865568456876, timestamp: 2022-08-20 13:26:32.189815\n",
      "resetting env. episode 8320, reward total was -17.0. running mean: -12.956706912772308, timestamp: 2022-08-20 13:26:38.526879\n",
      "resetting env. episode 8321, reward total was -18.0. running mean: -13.007139843644584, timestamp: 2022-08-20 13:26:42.459923\n",
      "resetting env. episode 8322, reward total was -8.0. running mean: -12.957068445208138, timestamp: 2022-08-20 13:26:50.036014\n",
      "resetting env. episode 8323, reward total was -11.0. running mean: -12.937497760756056, timestamp: 2022-08-20 13:26:55.141070\n",
      "resetting env. episode 8324, reward total was -15.0. running mean: -12.958122783148495, timestamp: 2022-08-20 13:27:01.228144\n",
      "resetting env. episode 8325, reward total was -9.0. running mean: -12.91854155531701, timestamp: 2022-08-20 13:27:07.283214\n",
      "resetting env. episode 8326, reward total was -14.0. running mean: -12.92935613976384, timestamp: 2022-08-20 13:27:12.868273\n",
      "resetting env. episode 8327, reward total was -2.0. running mean: -12.820062578366201, timestamp: 2022-08-20 13:27:19.393352\n",
      "resetting env. episode 8328, reward total was -15.0. running mean: -12.841861952582539, timestamp: 2022-08-20 13:27:24.433406\n",
      "resetting env. episode 8329, reward total was -15.0. running mean: -12.863443333056713, timestamp: 2022-08-20 13:27:28.744456\n",
      "resetting env. episode 8330, reward total was -12.0. running mean: -12.854808899726144, timestamp: 2022-08-20 13:27:33.187509\n",
      "resetting env. episode 8331, reward total was -12.0. running mean: -12.846260810728882, timestamp: 2022-08-20 13:27:38.633568\n",
      "resetting env. episode 8332, reward total was -17.0. running mean: -12.887798202621592, timestamp: 2022-08-20 13:27:44.674639\n",
      "resetting env. episode 8333, reward total was -13.0. running mean: -12.888920220595377, timestamp: 2022-08-20 13:27:50.515709\n",
      "resetting env. episode 8334, reward total was -12.0. running mean: -12.880031018389422, timestamp: 2022-08-20 13:27:56.272772\n",
      "resetting env. episode 8335, reward total was -15.0. running mean: -12.901230708205528, timestamp: 2022-08-20 13:28:02.081839\n",
      "resetting env. episode 8336, reward total was -6.0. running mean: -12.832218401123473, timestamp: 2022-08-20 13:28:07.196898\n",
      "resetting env. episode 8337, reward total was -21.0. running mean: -12.913896217112239, timestamp: 2022-08-20 13:28:11.063944\n",
      "resetting env. episode 8338, reward total was -17.0. running mean: -12.954757254941116, timestamp: 2022-08-20 13:28:16.592005\n",
      "resetting env. episode 8339, reward total was -9.0. running mean: -12.915209682391705, timestamp: 2022-08-20 13:28:23.125079\n",
      "resetting env. episode 8340, reward total was -17.0. running mean: -12.956057585567788, timestamp: 2022-08-20 13:28:28.112139\n",
      "resetting env. episode 8341, reward total was -3.0. running mean: -12.85649700971211, timestamp: 2022-08-20 13:28:35.516228\n",
      "resetting env. episode 8342, reward total was -11.0. running mean: -12.837932039614987, timestamp: 2022-08-20 13:28:40.428283\n",
      "resetting env. episode 8343, reward total was -11.0. running mean: -12.819552719218837, timestamp: 2022-08-20 13:28:45.410341\n",
      "resetting env. episode 8344, reward total was -16.0. running mean: -12.851357192026649, timestamp: 2022-08-20 13:28:50.122391\n",
      "resetting env. episode 8345, reward total was -19.0. running mean: -12.912843620106381, timestamp: 2022-08-20 13:28:53.198428\n",
      "resetting env. episode 8346, reward total was -12.0. running mean: -12.903715183905316, timestamp: 2022-08-20 13:28:57.692482\n",
      "resetting env. episode 8347, reward total was -11.0. running mean: -12.884678032066262, timestamp: 2022-08-20 13:29:04.456558\n",
      "resetting env. episode 8348, reward total was -3.0. running mean: -12.785831251745599, timestamp: 2022-08-20 13:29:11.101636\n",
      "resetting env. episode 8349, reward total was -14.0. running mean: -12.797972939228144, timestamp: 2022-08-20 13:29:15.510685\n",
      "resetting env. episode 8350, reward total was -15.0. running mean: -12.819993209835863, timestamp: 2022-08-20 13:29:20.067737\n",
      "resetting env. episode 8351, reward total was -14.0. running mean: -12.831793277737505, timestamp: 2022-08-20 13:29:24.301792\n",
      "resetting env. episode 8352, reward total was -12.0. running mean: -12.82347534496013, timestamp: 2022-08-20 13:29:28.223832\n",
      "resetting env. episode 8353, reward total was -16.0. running mean: -12.855240591510528, timestamp: 2022-08-20 13:29:32.270880\n",
      "resetting env. episode 8354, reward total was -15.0. running mean: -12.876688185595423, timestamp: 2022-08-20 13:29:36.696935\n",
      "resetting env. episode 8355, reward total was -14.0. running mean: -12.88792130373947, timestamp: 2022-08-20 13:29:40.837979\n",
      "resetting env. episode 8356, reward total was -14.0. running mean: -12.899042090702075, timestamp: 2022-08-20 13:29:45.417032\n",
      "resetting env. episode 8357, reward total was -19.0. running mean: -12.960051669795053, timestamp: 2022-08-20 13:29:48.855073\n",
      "resetting env. episode 8358, reward total was -11.0. running mean: -12.940451153097102, timestamp: 2022-08-20 13:29:54.953145\n",
      "resetting env. episode 8359, reward total was -15.0. running mean: -12.961046641566131, timestamp: 2022-08-20 13:29:59.113197\n",
      "resetting env. episode 8360, reward total was -17.0. running mean: -13.00143617515047, timestamp: 2022-08-20 13:30:04.047251\n",
      "resetting env. episode 8361, reward total was -17.0. running mean: -13.041421813398966, timestamp: 2022-08-20 13:30:08.364299\n",
      "resetting env. episode 8362, reward total was -13.0. running mean: -13.041007595264977, timestamp: 2022-08-20 13:30:14.560373\n",
      "resetting env. episode 8363, reward total was -9.0. running mean: -13.000597519312327, timestamp: 2022-08-20 13:30:21.218449\n",
      "resetting env. episode 8364, reward total was -7.0. running mean: -12.940591544119204, timestamp: 2022-08-20 13:30:27.803525\n",
      "resetting env. episode 8365, reward total was -13.0. running mean: -12.941185628678014, timestamp: 2022-08-20 13:30:32.450578\n",
      "resetting env. episode 8366, reward total was -18.0. running mean: -12.991773772391234, timestamp: 2022-08-20 13:30:36.171621\n",
      "resetting env. episode 8367, reward total was -16.0. running mean: -13.021856034667321, timestamp: 2022-08-20 13:30:41.252678\n",
      "resetting env. episode 8368, reward total was -19.0. running mean: -13.081637474320647, timestamp: 2022-08-20 13:30:45.065723\n",
      "resetting env. episode 8369, reward total was -6.0. running mean: -13.010821099577441, timestamp: 2022-08-20 13:30:51.443801\n",
      "resetting env. episode 8370, reward total was -18.0. running mean: -13.060712888581666, timestamp: 2022-08-20 13:30:55.113841\n",
      "resetting env. episode 8371, reward total was -12.0. running mean: -13.050105759695848, timestamp: 2022-08-20 13:30:59.787896\n",
      "resetting env. episode 8372, reward total was -12.0. running mean: -13.039604702098888, timestamp: 2022-08-20 13:31:04.735953\n",
      "resetting env. episode 8373, reward total was -15.0. running mean: -13.0592086550779, timestamp: 2022-08-20 13:31:09.663011\n",
      "resetting env. episode 8374, reward total was -11.0. running mean: -13.03861656852712, timestamp: 2022-08-20 13:31:14.479066\n",
      "resetting env. episode 8375, reward total was -7.0. running mean: -12.978230402841849, timestamp: 2022-08-20 13:31:21.346148\n",
      "resetting env. episode 8376, reward total was -15.0. running mean: -12.99844809881343, timestamp: 2022-08-20 13:31:25.729195\n",
      "resetting env. episode 8377, reward total was -11.0. running mean: -12.978463617825295, timestamp: 2022-08-20 13:31:30.755254\n",
      "resetting env. episode 8378, reward total was -17.0. running mean: -13.018678981647042, timestamp: 2022-08-20 13:31:35.524310\n",
      "resetting env. episode 8379, reward total was -13.0. running mean: -13.018492191830573, timestamp: 2022-08-20 13:31:40.690371\n",
      "resetting env. episode 8380, reward total was -12.0. running mean: -13.008307269912267, timestamp: 2022-08-20 13:31:45.420428\n",
      "resetting env. episode 8381, reward total was -7.0. running mean: -12.948224197213145, timestamp: 2022-08-20 13:31:52.448507\n",
      "resetting env. episode 8382, reward total was 5.0. running mean: -12.768741955241012, timestamp: 2022-08-20 13:31:58.691578\n",
      "resetting env. episode 8383, reward total was -13.0. running mean: -12.771054535688602, timestamp: 2022-08-20 13:32:03.928639\n",
      "resetting env. episode 8384, reward total was -9.0. running mean: -12.733343990331717, timestamp: 2022-08-20 13:32:10.819718\n",
      "resetting env. episode 8385, reward total was -16.0. running mean: -12.7660105504284, timestamp: 2022-08-20 13:32:15.731775\n",
      "resetting env. episode 8386, reward total was -7.0. running mean: -12.708350444924115, timestamp: 2022-08-20 13:32:23.251866\n",
      "resetting env. episode 8387, reward total was -13.0. running mean: -12.711266940474875, timestamp: 2022-08-20 13:32:28.116922\n",
      "resetting env. episode 8388, reward total was -5.0. running mean: -12.634154271070127, timestamp: 2022-08-20 13:32:33.763988\n",
      "resetting env. episode 8389, reward total was -17.0. running mean: -12.677812728359426, timestamp: 2022-08-20 13:32:38.569043\n",
      "resetting env. episode 8390, reward total was -13.0. running mean: -12.681034601075831, timestamp: 2022-08-20 13:32:43.210095\n",
      "resetting env. episode 8391, reward total was -15.0. running mean: -12.704224255065073, timestamp: 2022-08-20 13:32:48.174154\n",
      "resetting env. episode 8392, reward total was -17.0. running mean: -12.747182012514422, timestamp: 2022-08-20 13:32:52.526213\n",
      "resetting env. episode 8393, reward total was -17.0. running mean: -12.789710192389277, timestamp: 2022-08-20 13:32:57.907266\n",
      "resetting env. episode 8394, reward total was -15.0. running mean: -12.811813090465385, timestamp: 2022-08-20 13:33:03.686331\n",
      "resetting env. episode 8395, reward total was -16.0. running mean: -12.84369495956073, timestamp: 2022-08-20 13:33:08.286389\n",
      "resetting env. episode 8396, reward total was -15.0. running mean: -12.865258009965123, timestamp: 2022-08-20 13:33:12.286431\n",
      "resetting env. episode 8397, reward total was -15.0. running mean: -12.886605429865472, timestamp: 2022-08-20 13:33:17.208491\n",
      "resetting env. episode 8398, reward total was -15.0. running mean: -12.907739375566818, timestamp: 2022-08-20 13:33:22.119546\n",
      "resetting env. episode 8399, reward total was -15.0. running mean: -12.92866198181115, timestamp: 2022-08-20 13:33:29.078628\n",
      "resetting env. episode 8400, reward total was -17.0. running mean: -12.969375361993038, timestamp: 2022-08-20 13:33:33.945682\n",
      "resetting env. episode 8401, reward total was -15.0. running mean: -12.989681608373107, timestamp: 2022-08-20 13:33:38.068732\n",
      "resetting env. episode 8402, reward total was -10.0. running mean: -12.959784792289376, timestamp: 2022-08-20 13:33:43.967801\n",
      "resetting env. episode 8403, reward total was -15.0. running mean: -12.980186944366483, timestamp: 2022-08-20 13:33:48.811857\n",
      "resetting env. episode 8404, reward total was -12.0. running mean: -12.970385074922818, timestamp: 2022-08-20 13:33:55.216928\n",
      "resetting env. episode 8405, reward total was -7.0. running mean: -12.91068122417359, timestamp: 2022-08-20 13:34:03.339026\n",
      "resetting env. episode 8406, reward total was -17.0. running mean: -12.951574411931855, timestamp: 2022-08-20 13:34:07.386073\n",
      "resetting env. episode 8407, reward total was -12.0. running mean: -12.942058667812535, timestamp: 2022-08-20 13:34:13.970148\n",
      "resetting env. episode 8408, reward total was -13.0. running mean: -12.94263808113441, timestamp: 2022-08-20 13:34:20.311224\n",
      "resetting env. episode 8409, reward total was -10.0. running mean: -12.913211700323066, timestamp: 2022-08-20 13:34:27.086299\n",
      "resetting env. episode 8410, reward total was -13.0. running mean: -12.914079583319836, timestamp: 2022-08-20 13:34:32.068359\n",
      "resetting env. episode 8411, reward total was -15.0. running mean: -12.934938787486638, timestamp: 2022-08-20 13:34:36.526410\n",
      "resetting env. episode 8412, reward total was -14.0. running mean: -12.945589399611773, timestamp: 2022-08-20 13:34:41.300464\n",
      "resetting env. episode 8413, reward total was -14.0. running mean: -12.956133505615655, timestamp: 2022-08-20 13:34:47.596537\n",
      "resetting env. episode 8414, reward total was -10.0. running mean: -12.9265721705595, timestamp: 2022-08-20 13:34:53.396609\n",
      "resetting env. episode 8415, reward total was -6.0. running mean: -12.857306448853905, timestamp: 2022-08-20 13:35:00.050683\n",
      "resetting env. episode 8416, reward total was -11.0. running mean: -12.838733384365366, timestamp: 2022-08-20 13:35:06.050752\n",
      "resetting env. episode 8417, reward total was -17.0. running mean: -12.880346050521712, timestamp: 2022-08-20 13:35:10.823807\n",
      "resetting env. episode 8418, reward total was -15.0. running mean: -12.901542590016495, timestamp: 2022-08-20 13:35:15.110863\n",
      "resetting env. episode 8419, reward total was -13.0. running mean: -12.90252716411633, timestamp: 2022-08-20 13:35:20.953926\n",
      "resetting env. episode 8420, reward total was -17.0. running mean: -12.943501892475167, timestamp: 2022-08-20 13:35:25.593980\n",
      "resetting env. episode 8421, reward total was -13.0. running mean: -12.944066873550415, timestamp: 2022-08-20 13:35:30.276035\n",
      "resetting env. episode 8422, reward total was -13.0. running mean: -12.944626204814911, timestamp: 2022-08-20 13:35:36.456116\n",
      "resetting env. episode 8423, reward total was -20.0. running mean: -13.01517994276676, timestamp: 2022-08-20 13:35:40.368153\n",
      "resetting env. episode 8424, reward total was -16.0. running mean: -13.045028143339094, timestamp: 2022-08-20 13:35:44.996207\n",
      "resetting env. episode 8425, reward total was -17.0. running mean: -13.084577861905702, timestamp: 2022-08-20 13:35:50.976274\n",
      "resetting env. episode 8426, reward total was -13.0. running mean: -13.083732083286645, timestamp: 2022-08-20 13:35:55.793328\n",
      "resetting env. episode 8427, reward total was -14.0. running mean: -13.09289476245378, timestamp: 2022-08-20 13:36:01.258390\n",
      "resetting env. episode 8428, reward total was -15.0. running mean: -13.111965814829242, timestamp: 2022-08-20 13:36:05.545444\n",
      "resetting env. episode 8429, reward total was -13.0. running mean: -13.11084615668095, timestamp: 2022-08-20 13:36:09.960494\n",
      "resetting env. episode 8430, reward total was -12.0. running mean: -13.09973769511414, timestamp: 2022-08-20 13:36:15.963565\n",
      "resetting env. episode 8431, reward total was -14.0. running mean: -13.108740318163, timestamp: 2022-08-20 13:36:21.806633\n",
      "resetting env. episode 8432, reward total was -14.0. running mean: -13.11765291498137, timestamp: 2022-08-20 13:36:27.917703\n",
      "resetting env. episode 8433, reward total was -12.0. running mean: -13.106476385831556, timestamp: 2022-08-20 13:36:32.694759\n",
      "resetting env. episode 8434, reward total was -12.0. running mean: -13.09541162197324, timestamp: 2022-08-20 13:36:38.806828\n",
      "resetting env. episode 8435, reward total was -16.0. running mean: -13.124457505753508, timestamp: 2022-08-20 13:36:42.503870\n",
      "resetting env. episode 8436, reward total was -9.0. running mean: -13.083212930695973, timestamp: 2022-08-20 13:36:49.314956\n",
      "resetting env. episode 8437, reward total was -8.0. running mean: -13.032380801389014, timestamp: 2022-08-20 13:36:55.692025\n",
      "resetting env. episode 8438, reward total was -9.0. running mean: -12.992056993375122, timestamp: 2022-08-20 13:37:02.040097\n",
      "resetting env. episode 8439, reward total was -5.0. running mean: -12.912136423441371, timestamp: 2022-08-20 13:37:08.636175\n",
      "resetting env. episode 8440, reward total was -6.0. running mean: -12.843015059206957, timestamp: 2022-08-20 13:37:16.086261\n",
      "resetting env. episode 8441, reward total was -5.0. running mean: -12.764584908614887, timestamp: 2022-08-20 13:37:22.823338\n",
      "resetting env. episode 8442, reward total was -8.0. running mean: -12.71693905952874, timestamp: 2022-08-20 13:37:30.250423\n",
      "resetting env. episode 8443, reward total was -21.0. running mean: -12.799769668933452, timestamp: 2022-08-20 13:37:34.026467\n",
      "resetting env. episode 8444, reward total was -18.0. running mean: -12.851771972244117, timestamp: 2022-08-20 13:37:37.818513\n",
      "resetting env. episode 8445, reward total was -15.0. running mean: -12.873254252521676, timestamp: 2022-08-20 13:37:42.344561\n",
      "resetting env. episode 8446, reward total was -10.0. running mean: -12.844521709996458, timestamp: 2022-08-20 13:37:49.389646\n",
      "resetting env. episode 8447, reward total was -10.0. running mean: -12.816076492896494, timestamp: 2022-08-20 13:37:54.966709\n",
      "resetting env. episode 8448, reward total was -14.0. running mean: -12.827915727967529, timestamp: 2022-08-20 13:38:00.231772\n",
      "resetting env. episode 8449, reward total was -17.0. running mean: -12.869636570687854, timestamp: 2022-08-20 13:38:05.129826\n",
      "resetting env. episode 8450, reward total was -6.0. running mean: -12.800940204980977, timestamp: 2022-08-20 13:38:11.681901\n",
      "resetting env. episode 8451, reward total was -9.0. running mean: -12.762930802931168, timestamp: 2022-08-20 13:38:16.937960\n",
      "resetting env. episode 8452, reward total was -13.0. running mean: -12.765301494901857, timestamp: 2022-08-20 13:38:23.443041\n",
      "resetting env. episode 8453, reward total was -18.0. running mean: -12.817648479952839, timestamp: 2022-08-20 13:38:27.166077\n",
      "resetting env. episode 8454, reward total was -13.0. running mean: -12.819471995153311, timestamp: 2022-08-20 13:38:32.747144\n",
      "resetting env. episode 8455, reward total was -7.0. running mean: -12.761277275201778, timestamp: 2022-08-20 13:38:38.844215\n",
      "resetting env. episode 8456, reward total was -12.0. running mean: -12.753664502449759, timestamp: 2022-08-20 13:38:43.837270\n",
      "resetting env. episode 8457, reward total was -7.0. running mean: -12.696127857425262, timestamp: 2022-08-20 13:38:51.125353\n",
      "resetting env. episode 8458, reward total was -17.0. running mean: -12.739166578851009, timestamp: 2022-08-20 13:38:55.402402\n",
      "resetting env. episode 8459, reward total was -10.0. running mean: -12.711774913062499, timestamp: 2022-08-20 13:39:01.512475\n",
      "resetting env. episode 8460, reward total was -21.0. running mean: -12.794657163931875, timestamp: 2022-08-20 13:39:06.580529\n",
      "resetting env. episode 8461, reward total was -16.0. running mean: -12.826710592292557, timestamp: 2022-08-20 13:39:11.626593\n",
      "resetting env. episode 8462, reward total was -13.0. running mean: -12.82844348636963, timestamp: 2022-08-20 13:39:16.996652\n",
      "resetting env. episode 8463, reward total was -7.0. running mean: -12.770159051505935, timestamp: 2022-08-20 13:39:23.412727\n",
      "resetting env. episode 8464, reward total was -11.0. running mean: -12.752457460990875, timestamp: 2022-08-20 13:39:31.052819\n",
      "resetting env. episode 8465, reward total was -15.0. running mean: -12.774932886380967, timestamp: 2022-08-20 13:39:37.219884\n",
      "resetting env. episode 8466, reward total was -11.0. running mean: -12.757183557517155, timestamp: 2022-08-20 13:39:42.394942\n",
      "resetting env. episode 8467, reward total was -15.0. running mean: -12.779611721941984, timestamp: 2022-08-20 13:39:47.073997\n",
      "resetting env. episode 8468, reward total was -19.0. running mean: -12.841815604722564, timestamp: 2022-08-20 13:39:51.302045\n",
      "resetting env. episode 8469, reward total was -19.0. running mean: -12.903397448675337, timestamp: 2022-08-20 13:39:55.241091\n",
      "resetting env. episode 8470, reward total was -15.0. running mean: -12.924363474188583, timestamp: 2022-08-20 13:39:59.523138\n",
      "resetting env. episode 8471, reward total was -15.0. running mean: -12.945119839446697, timestamp: 2022-08-20 13:40:05.446213\n",
      "resetting env. episode 8472, reward total was -15.0. running mean: -12.96566864105223, timestamp: 2022-08-20 13:40:10.069262\n",
      "resetting env. episode 8473, reward total was -5.0. running mean: -12.88601195464171, timestamp: 2022-08-20 13:40:14.925319\n",
      "resetting env. episode 8474, reward total was -17.0. running mean: -12.927151835095293, timestamp: 2022-08-20 13:40:18.706365\n",
      "resetting env. episode 8475, reward total was -17.0. running mean: -12.96788031674434, timestamp: 2022-08-20 13:40:23.203414\n",
      "resetting env. episode 8476, reward total was -20.0. running mean: -13.038201513576896, timestamp: 2022-08-20 13:40:28.142471\n",
      "resetting env. episode 8477, reward total was -19.0. running mean: -13.097819498441126, timestamp: 2022-08-20 13:40:32.389517\n",
      "resetting env. episode 8478, reward total was -11.0. running mean: -13.076841303456714, timestamp: 2022-08-20 13:40:38.530595\n",
      "resetting env. episode 8479, reward total was -1.0. running mean: -12.956072890422146, timestamp: 2022-08-20 13:40:46.982687\n",
      "resetting env. episode 8480, reward total was -15.0. running mean: -12.976512161517924, timestamp: 2022-08-20 13:40:52.501752\n",
      "resetting env. episode 8481, reward total was -11.0. running mean: -12.956747039902744, timestamp: 2022-08-20 13:40:59.327826\n",
      "resetting env. episode 8482, reward total was -14.0. running mean: -12.967179569503717, timestamp: 2022-08-20 13:41:04.579898\n",
      "resetting env. episode 8483, reward total was -13.0. running mean: -12.96750777380868, timestamp: 2022-08-20 13:41:10.534957\n",
      "resetting env. episode 8484, reward total was -10.0. running mean: -12.937832696070593, timestamp: 2022-08-20 13:41:16.175023\n",
      "resetting env. episode 8485, reward total was -17.0. running mean: -12.978454369109887, timestamp: 2022-08-20 13:41:20.756079\n",
      "resetting env. episode 8486, reward total was -4.0. running mean: -12.888669825418788, timestamp: 2022-08-20 13:41:29.469176\n",
      "resetting env. episode 8487, reward total was -16.0. running mean: -12.9197831271646, timestamp: 2022-08-20 13:41:34.694761\n",
      "resetting env. episode 8488, reward total was -13.0. running mean: -12.920585295892954, timestamp: 2022-08-20 13:41:40.003822\n",
      "resetting env. episode 8489, reward total was -6.0. running mean: -12.851379442934025, timestamp: 2022-08-20 13:41:45.801411\n",
      "resetting env. episode 8490, reward total was -15.0. running mean: -12.872865648504686, timestamp: 2022-08-20 13:41:50.917990\n",
      "resetting env. episode 8491, reward total was -7.0. running mean: -12.81413699201964, timestamp: 2022-08-20 13:41:58.089075\n",
      "resetting env. episode 8492, reward total was -5.0. running mean: -12.735995622099443, timestamp: 2022-08-20 13:42:05.584679\n",
      "resetting env. episode 8493, reward total was -17.0. running mean: -12.778635665878449, timestamp: 2022-08-20 13:42:09.325728\n",
      "resetting env. episode 8494, reward total was -16.0. running mean: -12.810849309219664, timestamp: 2022-08-20 13:42:13.694773\n",
      "resetting env. episode 8495, reward total was -9.0. running mean: -12.772740816127467, timestamp: 2022-08-20 13:42:20.254848\n",
      "resetting env. episode 8496, reward total was -13.0. running mean: -12.775013407966192, timestamp: 2022-08-20 13:42:26.457921\n",
      "resetting env. episode 8497, reward total was -13.0. running mean: -12.77726327388653, timestamp: 2022-08-20 13:42:32.501516\n",
      "resetting env. episode 8498, reward total was -16.0. running mean: -12.809490641147665, timestamp: 2022-08-20 13:42:36.820559\n",
      "resetting env. episode 8499, reward total was -8.0. running mean: -12.761395734736189, timestamp: 2022-08-20 13:42:43.069631\n",
      "resetting env. episode 8500, reward total was -15.0. running mean: -12.783781777388826, timestamp: 2022-08-20 13:42:49.106699\n",
      "resetting env. episode 8501, reward total was -13.0. running mean: -12.785943959614938, timestamp: 2022-08-20 13:42:54.984766\n",
      "resetting env. episode 8502, reward total was -16.0. running mean: -12.81808452001879, timestamp: 2022-08-20 13:43:00.893837\n",
      "resetting env. episode 8503, reward total was -21.0. running mean: -12.899903674818603, timestamp: 2022-08-20 13:43:04.065873\n",
      "resetting env. episode 8504, reward total was -11.0. running mean: -12.880904638070415, timestamp: 2022-08-20 13:43:10.262939\n",
      "resetting env. episode 8505, reward total was -12.0. running mean: -12.87209559168971, timestamp: 2022-08-20 13:43:15.323003\n",
      "resetting env. episode 8506, reward total was -10.0. running mean: -12.843374635772813, timestamp: 2022-08-20 13:43:21.508071\n",
      "resetting env. episode 8507, reward total was -12.0. running mean: -12.834940889415083, timestamp: 2022-08-20 13:43:26.791651\n",
      "resetting env. episode 8508, reward total was -13.0. running mean: -12.836591480520934, timestamp: 2022-08-20 13:43:32.249716\n",
      "resetting env. episode 8509, reward total was -13.0. running mean: -12.838225565715724, timestamp: 2022-08-20 13:43:36.158761\n",
      "resetting env. episode 8510, reward total was -9.0. running mean: -12.799843310058566, timestamp: 2022-08-20 13:43:42.762833\n",
      "resetting env. episode 8511, reward total was -11.0. running mean: -12.78184487695798, timestamp: 2022-08-20 13:43:49.200909\n",
      "resetting env. episode 8512, reward total was -12.0. running mean: -12.7740264281884, timestamp: 2022-08-20 13:43:54.287970\n",
      "resetting env. episode 8513, reward total was -14.0. running mean: -12.786286163906516, timestamp: 2022-08-20 13:43:58.607013\n",
      "resetting env. episode 8514, reward total was -11.0. running mean: -12.76842330226745, timestamp: 2022-08-20 13:44:04.325605\n",
      "resetting env. episode 8515, reward total was -13.0. running mean: -12.770739069244776, timestamp: 2022-08-20 13:44:09.551665\n",
      "resetting env. episode 8516, reward total was -19.0. running mean: -12.833031678552327, timestamp: 2022-08-20 13:44:13.737712\n",
      "resetting env. episode 8517, reward total was 7.0. running mean: -12.634701361766803, timestamp: 2022-08-20 13:44:20.639790\n",
      "resetting env. episode 8518, reward total was -14.0. running mean: -12.648354348149136, timestamp: 2022-08-20 13:44:26.893863\n",
      "resetting env. episode 8519, reward total was -16.0. running mean: -12.681870804667644, timestamp: 2022-08-20 13:44:32.174922\n",
      "resetting env. episode 8520, reward total was -16.0. running mean: -12.715052096620967, timestamp: 2022-08-20 13:44:38.414994\n",
      "resetting env. episode 8521, reward total was -9.0. running mean: -12.677901575654758, timestamp: 2022-08-20 13:44:47.018094\n",
      "resetting env. episode 8522, reward total was -11.0. running mean: -12.66112255989821, timestamp: 2022-08-20 13:44:53.176175\n",
      "resetting env. episode 8523, reward total was -2.0. running mean: -12.554511334299228, timestamp: 2022-08-20 13:44:59.379235\n",
      "resetting env. episode 8524, reward total was -13.0. running mean: -12.558966220956236, timestamp: 2022-08-20 13:45:04.856823\n",
      "resetting env. episode 8525, reward total was -20.0. running mean: -12.633376558746672, timestamp: 2022-08-20 13:45:09.366878\n",
      "resetting env. episode 8526, reward total was -5.0. running mean: -12.557042793159207, timestamp: 2022-08-20 13:45:15.839950\n",
      "resetting env. episode 8527, reward total was -11.0. running mean: -12.541472365227614, timestamp: 2022-08-20 13:45:20.163536\n",
      "resetting env. episode 8528, reward total was -14.0. running mean: -12.556057641575338, timestamp: 2022-08-20 13:45:25.966601\n",
      "resetting env. episode 8529, reward total was -19.0. running mean: -12.620497065159583, timestamp: 2022-08-20 13:45:29.679165\n",
      "resetting env. episode 8530, reward total was -13.0. running mean: -12.624292094507988, timestamp: 2022-08-20 13:45:34.971227\n",
      "resetting env. episode 8531, reward total was -19.0. running mean: -12.688049173562908, timestamp: 2022-08-20 13:45:38.597270\n",
      "resetting env. episode 8532, reward total was -6.0. running mean: -12.621168681827278, timestamp: 2022-08-20 13:45:45.252350\n",
      "resetting env. episode 8533, reward total was -17.0. running mean: -12.664956995009005, timestamp: 2022-08-20 13:45:51.069412\n",
      "resetting env. episode 8534, reward total was -8.0. running mean: -12.618307425058916, timestamp: 2022-08-20 13:45:57.891491\n",
      "resetting env. episode 8535, reward total was -14.0. running mean: -12.632124350808327, timestamp: 2022-08-20 13:46:02.550073\n",
      "resetting env. episode 8536, reward total was -6.0. running mean: -12.565803107300244, timestamp: 2022-08-20 13:46:09.094665\n",
      "resetting env. episode 8537, reward total was -19.0. running mean: -12.63014507622724, timestamp: 2022-08-20 13:46:13.006712\n",
      "resetting env. episode 8538, reward total was -13.0. running mean: -12.63384362546497, timestamp: 2022-08-20 13:46:18.445301\n",
      "resetting env. episode 8539, reward total was -14.0. running mean: -12.64750518921032, timestamp: 2022-08-20 13:46:24.204370\n",
      "resetting env. episode 8540, reward total was -11.0. running mean: -12.631030137318215, timestamp: 2022-08-20 13:46:30.179964\n",
      "resetting env. episode 8541, reward total was -17.0. running mean: -12.674719835945032, timestamp: 2022-08-20 13:46:34.542014\n",
      "resetting env. episode 8542, reward total was -11.0. running mean: -12.657972637585582, timestamp: 2022-08-20 13:46:39.423596\n",
      "resetting env. episode 8543, reward total was -17.0. running mean: -12.701392911209725, timestamp: 2022-08-20 13:46:44.177656\n",
      "resetting env. episode 8544, reward total was -7.0. running mean: -12.644378982097628, timestamp: 2022-08-20 13:46:49.835245\n",
      "resetting env. episode 8545, reward total was -7.0. running mean: -12.587935192276651, timestamp: 2022-08-20 13:46:56.186320\n",
      "resetting env. episode 8546, reward total was -5.0. running mean: -12.512055840353886, timestamp: 2022-08-20 13:47:02.791392\n",
      "resetting env. episode 8547, reward total was -6.0. running mean: -12.446935281950347, timestamp: 2022-08-20 13:47:09.692996\n",
      "resetting env. episode 8548, reward total was -13.0. running mean: -12.452465929130845, timestamp: 2022-08-20 13:47:14.841054\n",
      "resetting env. episode 8549, reward total was -13.0. running mean: -12.457941269839537, timestamp: 2022-08-20 13:47:21.171131\n",
      "resetting env. episode 8550, reward total was -6.0. running mean: -12.393361857141143, timestamp: 2022-08-20 13:47:28.700216\n",
      "resetting env. episode 8551, reward total was -13.0. running mean: -12.399428238569731, timestamp: 2022-08-20 13:47:35.409292\n",
      "resetting env. episode 8552, reward total was -7.0. running mean: -12.345433956184035, timestamp: 2022-08-20 13:47:43.351387\n",
      "resetting env. episode 8553, reward total was -12.0. running mean: -12.341979616622194, timestamp: 2022-08-20 13:47:49.399454\n",
      "resetting env. episode 8554, reward total was -10.0. running mean: -12.31855982045597, timestamp: 2022-08-20 13:47:55.354524\n",
      "resetting env. episode 8555, reward total was -17.0. running mean: -12.365374222251411, timestamp: 2022-08-20 13:47:59.275566\n",
      "resetting env. episode 8556, reward total was -11.0. running mean: -12.351720480028897, timestamp: 2022-08-20 13:48:05.744645\n",
      "resetting env. episode 8557, reward total was -5.0. running mean: -12.27820327522861, timestamp: 2022-08-20 13:48:11.256707\n",
      "resetting env. episode 8558, reward total was -17.0. running mean: -12.325421242476322, timestamp: 2022-08-20 13:48:14.897749\n",
      "resetting env. episode 8559, reward total was -19.0. running mean: -12.392167030051558, timestamp: 2022-08-20 13:48:18.405316\n",
      "resetting env. episode 8560, reward total was -14.0. running mean: -12.408245359751044, timestamp: 2022-08-20 13:48:23.511377\n",
      "resetting env. episode 8561, reward total was -12.0. running mean: -12.404162906153532, timestamp: 2022-08-20 13:48:28.446431\n",
      "resetting env. episode 8562, reward total was -5.0. running mean: -12.330121277091997, timestamp: 2022-08-20 13:48:35.359037\n",
      "resetting env. episode 8563, reward total was -11.0. running mean: -12.316820064321076, timestamp: 2022-08-20 13:48:39.459089\n",
      "resetting env. episode 8564, reward total was -11.0. running mean: -12.303651863677866, timestamp: 2022-08-20 13:48:44.850147\n",
      "resetting env. episode 8565, reward total was -15.0. running mean: -12.330615345041087, timestamp: 2022-08-20 13:48:50.423209\n",
      "resetting env. episode 8566, reward total was -12.0. running mean: -12.327309191590675, timestamp: 2022-08-20 13:48:54.967265\n",
      "resetting env. episode 8567, reward total was -13.0. running mean: -12.334036099674769, timestamp: 2022-08-20 13:48:59.082316\n",
      "resetting env. episode 8568, reward total was -8.0. running mean: -12.290695738678021, timestamp: 2022-08-20 13:49:05.275428\n",
      "resetting env. episode 8569, reward total was -14.0. running mean: -12.307788781291242, timestamp: 2022-08-20 13:49:10.398007\n",
      "resetting env. episode 8570, reward total was -19.0. running mean: -12.374710893478328, timestamp: 2022-08-20 13:49:15.136583\n",
      "resetting env. episode 8571, reward total was -9.0. running mean: -12.340963784543545, timestamp: 2022-08-20 13:49:22.162191\n",
      "resetting env. episode 8572, reward total was -15.0. running mean: -12.36755414669811, timestamp: 2022-08-20 13:49:28.133255\n",
      "resetting env. episode 8573, reward total was -17.0. running mean: -12.413878605231128, timestamp: 2022-08-20 13:49:32.325827\n",
      "resetting env. episode 8574, reward total was -11.0. running mean: -12.399739819178816, timestamp: 2022-08-20 13:49:36.661401\n",
      "resetting env. episode 8575, reward total was -12.0. running mean: -12.395742420987027, timestamp: 2022-08-20 13:49:41.426456\n",
      "resetting env. episode 8576, reward total was -12.0. running mean: -12.391784996777156, timestamp: 2022-08-20 13:49:47.264523\n",
      "resetting env. episode 8577, reward total was -6.0. running mean: -12.327867146809385, timestamp: 2022-08-20 13:49:52.991589\n",
      "resetting env. episode 8578, reward total was -12.0. running mean: -12.32458847534129, timestamp: 2022-08-20 13:49:58.303650\n",
      "resetting env. episode 8579, reward total was -6.0. running mean: -12.261342590587878, timestamp: 2022-08-20 13:50:06.176791\n",
      "resetting env. episode 8580, reward total was -17.0. running mean: -12.308729164682, timestamp: 2022-08-20 13:50:11.362850\n",
      "resetting env. episode 8581, reward total was -4.0. running mean: -12.225641873035178, timestamp: 2022-08-20 13:50:18.649940\n",
      "resetting env. episode 8582, reward total was -12.0. running mean: -12.223385454304825, timestamp: 2022-08-20 13:50:24.018998\n",
      "resetting env. episode 8583, reward total was -19.0. running mean: -12.291151599761776, timestamp: 2022-08-20 13:50:28.671052\n",
      "resetting env. episode 8584, reward total was -16.0. running mean: -12.328240083764157, timestamp: 2022-08-20 13:50:33.755629\n",
      "resetting env. episode 8585, reward total was -16.0. running mean: -12.364957682926516, timestamp: 2022-08-20 13:50:38.211685\n",
      "resetting env. episode 8586, reward total was -13.0. running mean: -12.371308106097251, timestamp: 2022-08-20 13:50:43.111739\n",
      "resetting env. episode 8587, reward total was -18.0. running mean: -12.427595025036277, timestamp: 2022-08-20 13:50:48.270804\n",
      "resetting env. episode 8588, reward total was -15.0. running mean: -12.453319074785915, timestamp: 2022-08-20 13:50:52.938855\n",
      "resetting env. episode 8589, reward total was -12.0. running mean: -12.448785884038054, timestamp: 2022-08-20 13:50:57.509906\n",
      "resetting env. episode 8590, reward total was -2.0. running mean: -12.344298025197673, timestamp: 2022-08-20 13:51:05.303996\n",
      "resetting env. episode 8591, reward total was -19.0. running mean: -12.410855044945697, timestamp: 2022-08-20 13:51:09.524045\n",
      "resetting env. episode 8592, reward total was -13.0. running mean: -12.416746494496241, timestamp: 2022-08-20 13:51:14.381104\n",
      "resetting env. episode 8593, reward total was -7.0. running mean: -12.362579029551279, timestamp: 2022-08-20 13:51:20.119177\n",
      "resetting env. episode 8594, reward total was -14.0. running mean: -12.378953239255766, timestamp: 2022-08-20 13:51:24.194217\n",
      "resetting env. episode 8595, reward total was -11.0. running mean: -12.365163706863209, timestamp: 2022-08-20 13:51:30.483288\n",
      "resetting env. episode 8596, reward total was -5.0. running mean: -12.291512069794578, timestamp: 2022-08-20 13:51:37.310372\n",
      "resetting env. episode 8597, reward total was -12.0. running mean: -12.28859694909663, timestamp: 2022-08-20 13:51:42.210424\n",
      "resetting env. episode 8598, reward total was -13.0. running mean: -12.295710979605666, timestamp: 2022-08-20 13:51:46.411995\n",
      "resetting env. episode 8599, reward total was -11.0. running mean: -12.282753869809609, timestamp: 2022-08-20 13:51:51.872059\n",
      "resetting env. episode 8600, reward total was -11.0. running mean: -12.269926331111511, timestamp: 2022-08-20 13:51:57.289642\n",
      "resetting env. episode 8601, reward total was -15.0. running mean: -12.297227067800396, timestamp: 2022-08-20 13:52:01.029683\n",
      "resetting env. episode 8602, reward total was -17.0. running mean: -12.344254797122392, timestamp: 2022-08-20 13:52:04.819247\n",
      "resetting env. episode 8603, reward total was -10.0. running mean: -12.320812249151167, timestamp: 2022-08-20 13:52:11.010319\n",
      "resetting env. episode 8604, reward total was -12.0. running mean: -12.317604126659655, timestamp: 2022-08-20 13:52:16.947388\n",
      "resetting env. episode 8605, reward total was -14.0. running mean: -12.334428085393059, timestamp: 2022-08-20 13:52:22.098449\n",
      "resetting env. episode 8606, reward total was -13.0. running mean: -12.341083804539128, timestamp: 2022-08-20 13:52:26.966504\n",
      "resetting env. episode 8607, reward total was -9.0. running mean: -12.307672966493737, timestamp: 2022-08-20 13:52:32.737569\n",
      "resetting env. episode 8608, reward total was -8.0. running mean: -12.2645962368288, timestamp: 2022-08-20 13:52:38.739646\n",
      "resetting env. episode 8609, reward total was -15.0. running mean: -12.291950274460511, timestamp: 2022-08-20 13:52:43.243696\n",
      "resetting env. episode 8610, reward total was -5.0. running mean: -12.219030771715907, timestamp: 2022-08-20 13:52:49.869769\n",
      "resetting env. episode 8611, reward total was -6.0. running mean: -12.156840463998748, timestamp: 2022-08-20 13:52:56.855374\n",
      "resetting env. episode 8612, reward total was -12.0. running mean: -12.15527205935876, timestamp: 2022-08-20 13:53:02.952443\n",
      "resetting env. episode 8613, reward total was -15.0. running mean: -12.183719338765172, timestamp: 2022-08-20 13:53:07.669506\n",
      "resetting env. episode 8614, reward total was -18.0. running mean: -12.24188214537752, timestamp: 2022-08-20 13:53:11.504549\n",
      "resetting env. episode 8615, reward total was -6.0. running mean: -12.179463323923745, timestamp: 2022-08-20 13:53:18.302622\n",
      "resetting env. episode 8616, reward total was -17.0. running mean: -12.227668690684506, timestamp: 2022-08-20 13:53:23.339682\n",
      "resetting env. episode 8617, reward total was -17.0. running mean: -12.275392003777661, timestamp: 2022-08-20 13:53:27.986736\n",
      "resetting env. episode 8618, reward total was -14.0. running mean: -12.292638083739885, timestamp: 2022-08-20 13:53:31.646782\n",
      "resetting env. episode 8619, reward total was -13.0. running mean: -12.299711702902487, timestamp: 2022-08-20 13:53:38.187901\n",
      "resetting env. episode 8620, reward total was -17.0. running mean: -12.346714585873462, timestamp: 2022-08-20 13:53:42.405952\n",
      "resetting env. episode 8621, reward total was -9.0. running mean: -12.313247440014727, timestamp: 2022-08-20 13:53:47.137007\n",
      "resetting env. episode 8622, reward total was -2.0. running mean: -12.21011496561458, timestamp: 2022-08-20 13:53:53.948085\n",
      "resetting env. episode 8623, reward total was -2.0. running mean: -12.108013815958433, timestamp: 2022-08-20 13:54:01.112691\n",
      "resetting env. episode 8624, reward total was -3.0. running mean: -12.016933677798848, timestamp: 2022-08-20 13:54:07.422762\n",
      "resetting env. episode 8625, reward total was -6.0. running mean: -11.95676434102086, timestamp: 2022-08-20 13:54:14.765854\n",
      "resetting env. episode 8626, reward total was -15.0. running mean: -11.987196697610651, timestamp: 2022-08-20 13:54:19.464901\n",
      "resetting env. episode 8627, reward total was -17.0. running mean: -12.037324730634545, timestamp: 2022-08-20 13:54:25.090971\n",
      "resetting env. episode 8628, reward total was -3.0. running mean: -11.9469514833282, timestamp: 2022-08-20 13:54:32.258050\n",
      "resetting env. episode 8629, reward total was -12.0. running mean: -11.947481968494916, timestamp: 2022-08-20 13:54:38.043649\n",
      "resetting env. episode 8630, reward total was -15.0. running mean: -11.978007148809967, timestamp: 2022-08-20 13:54:42.798704\n",
      "resetting env. episode 8631, reward total was -2.0. running mean: -11.878227077321867, timestamp: 2022-08-20 13:54:49.726781\n",
      "resetting env. episode 8632, reward total was -17.0. running mean: -11.929444806548648, timestamp: 2022-08-20 13:54:53.719831\n",
      "resetting env. episode 8633, reward total was -7.0. running mean: -11.880150358483162, timestamp: 2022-08-20 13:54:59.889435\n",
      "resetting env. episode 8634, reward total was -9.0. running mean: -11.85134885489833, timestamp: 2022-08-20 13:55:05.604499\n",
      "resetting env. episode 8635, reward total was -21.0. running mean: -11.942835366349348, timestamp: 2022-08-20 13:55:09.999551\n",
      "resetting env. episode 8636, reward total was -21.0. running mean: -12.033407012685855, timestamp: 2022-08-20 13:55:13.480592\n",
      "resetting env. episode 8637, reward total was -10.0. running mean: -12.013072942558995, timestamp: 2022-08-20 13:55:19.446659\n",
      "resetting env. episode 8638, reward total was 2.0. running mean: -11.872942213133406, timestamp: 2022-08-20 13:55:26.648788\n",
      "resetting env. episode 8639, reward total was -14.0. running mean: -11.894212791002072, timestamp: 2022-08-20 13:55:31.465848\n",
      "resetting env. episode 8640, reward total was -11.0. running mean: -11.88527066309205, timestamp: 2022-08-20 13:55:36.455900\n",
      "resetting env. episode 8641, reward total was -7.0. running mean: -11.83641795646113, timestamp: 2022-08-20 13:55:43.245505\n",
      "resetting env. episode 8642, reward total was -13.0. running mean: -11.848053776896519, timestamp: 2022-08-20 13:55:48.556573\n",
      "resetting env. episode 8643, reward total was -18.0. running mean: -11.909573239127553, timestamp: 2022-08-20 13:55:52.913615\n",
      "resetting env. episode 8644, reward total was -5.0. running mean: -11.840477506736278, timestamp: 2022-08-20 13:55:59.929695\n",
      "resetting env. episode 8645, reward total was -16.0. running mean: -11.882072731668915, timestamp: 2022-08-20 13:56:03.738263\n",
      "resetting env. episode 8646, reward total was -8.0. running mean: -11.843252004352225, timestamp: 2022-08-20 13:56:10.153336\n",
      "resetting env. episode 8647, reward total was -14.0. running mean: -11.864819484308702, timestamp: 2022-08-20 13:56:14.359382\n",
      "resetting env. episode 8648, reward total was -14.0. running mean: -11.886171289465615, timestamp: 2022-08-20 13:56:19.612442\n",
      "resetting env. episode 8649, reward total was -18.0. running mean: -11.947309576570959, timestamp: 2022-08-20 13:56:23.936493\n",
      "resetting env. episode 8650, reward total was -15.0. running mean: -11.97783648080525, timestamp: 2022-08-20 13:56:29.141551\n",
      "resetting env. episode 8651, reward total was -12.0. running mean: -11.978058115997197, timestamp: 2022-08-20 13:56:34.832620\n",
      "resetting env. episode 8652, reward total was -15.0. running mean: -12.008277534837225, timestamp: 2022-08-20 13:56:40.106682\n",
      "resetting env. episode 8653, reward total was -13.0. running mean: -12.018194759488853, timestamp: 2022-08-20 13:56:45.166739\n",
      "resetting env. episode 8654, reward total was -17.0. running mean: -12.068012811893965, timestamp: 2022-08-20 13:56:49.982792\n",
      "resetting env. episode 8655, reward total was -3.0. running mean: -11.977332683775025, timestamp: 2022-08-20 13:56:56.344869\n",
      "resetting env. episode 8656, reward total was -10.0. running mean: -11.957559356937274, timestamp: 2022-08-20 13:57:00.893918\n",
      "resetting env. episode 8657, reward total was -15.0. running mean: -11.987983763367902, timestamp: 2022-08-20 13:57:05.715972\n",
      "resetting env. episode 8658, reward total was -15.0. running mean: -12.018103925734223, timestamp: 2022-08-20 13:57:11.243039\n",
      "resetting env. episode 8659, reward total was -16.0. running mean: -12.05792288647688, timestamp: 2022-08-20 13:57:15.630089\n",
      "resetting env. episode 8660, reward total was -12.0. running mean: -12.057343657612112, timestamp: 2022-08-20 13:57:20.674146\n",
      "resetting env. episode 8661, reward total was -5.0. running mean: -11.986770221035991, timestamp: 2022-08-20 13:57:28.338232\n",
      "resetting env. episode 8662, reward total was -17.0. running mean: -12.036902518825631, timestamp: 2022-08-20 13:57:32.998287\n",
      "resetting env. episode 8663, reward total was -7.0. running mean: -11.986533493637374, timestamp: 2022-08-20 13:57:38.863888\n",
      "resetting env. episode 8664, reward total was -13.0. running mean: -11.996668158701, timestamp: 2022-08-20 13:57:45.193008\n",
      "resetting env. episode 8665, reward total was -14.0. running mean: -12.01670147711399, timestamp: 2022-08-20 13:57:50.167065\n",
      "resetting env. episode 8666, reward total was -18.0. running mean: -12.07653446234285, timestamp: 2022-08-20 13:57:54.282117\n",
      "resetting env. episode 8667, reward total was -10.0. running mean: -12.055769117719422, timestamp: 2022-08-20 13:57:59.793178\n",
      "resetting env. episode 8668, reward total was -13.0. running mean: -12.065211426542229, timestamp: 2022-08-20 13:58:04.534234\n",
      "resetting env. episode 8669, reward total was -13.0. running mean: -12.074559312276808, timestamp: 2022-08-20 13:58:10.306296\n",
      "resetting env. episode 8670, reward total was -11.0. running mean: -12.063813719154039, timestamp: 2022-08-20 13:58:16.136885\n",
      "resetting env. episode 8671, reward total was -10.0. running mean: -12.043175581962497, timestamp: 2022-08-20 13:58:22.876965\n",
      "resetting env. episode 8672, reward total was -10.0. running mean: -12.022743826142872, timestamp: 2022-08-20 13:58:28.739036\n",
      "resetting env. episode 8673, reward total was -6.0. running mean: -11.962516387881443, timestamp: 2022-08-20 13:58:34.875150\n",
      "resetting env. episode 8674, reward total was -11.0. running mean: -11.952891224002629, timestamp: 2022-08-20 13:58:39.994209\n",
      "resetting env. episode 8675, reward total was -7.0. running mean: -11.903362311762603, timestamp: 2022-08-20 13:58:46.509281\n",
      "resetting env. episode 8676, reward total was -17.0. running mean: -11.954328688644976, timestamp: 2022-08-20 13:58:50.063323\n",
      "resetting env. episode 8677, reward total was -16.0. running mean: -11.994785401758527, timestamp: 2022-08-20 13:58:53.954369\n",
      "resetting env. episode 8678, reward total was -3.0. running mean: -11.904837547740941, timestamp: 2022-08-20 13:58:59.659436\n",
      "resetting env. episode 8679, reward total was -11.0. running mean: -11.89578917226353, timestamp: 2022-08-20 13:59:04.580010\n",
      "resetting env. episode 8680, reward total was -8.0. running mean: -11.856831280540895, timestamp: 2022-08-20 13:59:11.250087\n",
      "resetting env. episode 8681, reward total was -11.0. running mean: -11.848262967735485, timestamp: 2022-08-20 13:59:15.749142\n",
      "resetting env. episode 8682, reward total was -16.0. running mean: -11.889780338058129, timestamp: 2022-08-20 13:59:19.915186\n",
      "resetting env. episode 8683, reward total was -17.0. running mean: -11.940882534677547, timestamp: 2022-08-20 13:59:24.203234\n",
      "resetting env. episode 8684, reward total was -13.0. running mean: -11.951473709330772, timestamp: 2022-08-20 13:59:28.985292\n",
      "resetting env. episode 8685, reward total was -15.0. running mean: -11.981958972237464, timestamp: 2022-08-20 13:59:34.634356\n",
      "resetting env. episode 8686, reward total was -11.0. running mean: -11.972139382515088, timestamp: 2022-08-20 13:59:40.282419\n",
      "resetting env. episode 8687, reward total was -14.0. running mean: -11.992417988689938, timestamp: 2022-08-20 13:59:45.421478\n",
      "resetting env. episode 8688, reward total was -9.0. running mean: -11.962493808803039, timestamp: 2022-08-20 13:59:50.831542\n",
      "resetting env. episode 8689, reward total was -16.0. running mean: -12.002868870715009, timestamp: 2022-08-20 13:59:54.794584\n",
      "resetting env. episode 8690, reward total was -9.0. running mean: -11.97284018200786, timestamp: 2022-08-20 14:00:00.235648\n",
      "resetting env. episode 8691, reward total was -11.0. running mean: -11.96311178018778, timestamp: 2022-08-20 14:00:05.933711\n",
      "resetting env. episode 8692, reward total was -17.0. running mean: -12.013480662385902, timestamp: 2022-08-20 14:00:10.078758\n",
      "resetting env. episode 8693, reward total was -6.0. running mean: -11.953345855762043, timestamp: 2022-08-20 14:00:16.315829\n",
      "resetting env. episode 8694, reward total was -8.0. running mean: -11.913812397204422, timestamp: 2022-08-20 14:00:22.568900\n",
      "resetting env. episode 8695, reward total was -10.0. running mean: -11.894674273232377, timestamp: 2022-08-20 14:00:29.344978\n",
      "resetting env. episode 8696, reward total was -16.0. running mean: -11.935727530500053, timestamp: 2022-08-20 14:00:34.151032\n",
      "resetting env. episode 8697, reward total was -17.0. running mean: -11.986370255195052, timestamp: 2022-08-20 14:00:38.510083\n",
      "resetting env. episode 8698, reward total was -13.0. running mean: -11.996506552643101, timestamp: 2022-08-20 14:00:43.373664\n",
      "resetting env. episode 8699, reward total was -3.0. running mean: -11.90654148711667, timestamp: 2022-08-20 14:00:50.735751\n",
      "resetting env. episode 8700, reward total was -17.0. running mean: -11.957476072245502, timestamp: 2022-08-20 14:00:55.931809\n",
      "resetting env. episode 8701, reward total was -12.0. running mean: -11.957901311523045, timestamp: 2022-08-20 14:01:02.488883\n",
      "resetting env. episode 8702, reward total was -16.0. running mean: -11.998322298407816, timestamp: 2022-08-20 14:01:07.637939\n",
      "resetting env. episode 8703, reward total was -10.0. running mean: -11.978339075423737, timestamp: 2022-08-20 14:01:13.201004\n",
      "resetting env. episode 8704, reward total was -10.0. running mean: -11.958555684669498, timestamp: 2022-08-20 14:01:18.453071\n",
      "resetting env. episode 8705, reward total was -14.0. running mean: -11.978970127822803, timestamp: 2022-08-20 14:01:23.877127\n",
      "resetting env. episode 8706, reward total was -6.0. running mean: -11.919180426544576, timestamp: 2022-08-20 14:01:30.764204\n",
      "resetting env. episode 8707, reward total was -14.0. running mean: -11.939988622279131, timestamp: 2022-08-20 14:01:35.698794\n",
      "resetting env. episode 8708, reward total was -9.0. running mean: -11.91058873605634, timestamp: 2022-08-20 14:01:41.638858\n",
      "resetting env. episode 8709, reward total was -13.0. running mean: -11.921482848695778, timestamp: 2022-08-20 14:01:46.501912\n",
      "resetting env. episode 8710, reward total was -12.0. running mean: -11.922268020208818, timestamp: 2022-08-20 14:01:51.335966\n",
      "resetting env. episode 8711, reward total was -13.0. running mean: -11.93304534000673, timestamp: 2022-08-20 14:01:55.906021\n",
      "resetting env. episode 8712, reward total was -1.0. running mean: -11.823714886606663, timestamp: 2022-08-20 14:02:03.817111\n",
      "resetting env. episode 8713, reward total was -14.0. running mean: -11.845477737740596, timestamp: 2022-08-20 14:02:07.971160\n",
      "resetting env. episode 8714, reward total was -2.0. running mean: -11.74702296036319, timestamp: 2022-08-20 14:02:15.019241\n",
      "resetting env. episode 8715, reward total was -15.0. running mean: -11.779552730759558, timestamp: 2022-08-20 14:02:20.946311\n",
      "resetting env. episode 8716, reward total was -16.0. running mean: -11.821757203451963, timestamp: 2022-08-20 14:02:25.126882\n",
      "resetting env. episode 8717, reward total was -15.0. running mean: -11.853539631417444, timestamp: 2022-08-20 14:02:30.582946\n",
      "resetting env. episode 8718, reward total was -19.0. running mean: -11.92500423510327, timestamp: 2022-08-20 14:02:34.920990\n",
      "resetting env. episode 8719, reward total was -7.0. running mean: -11.875754192752238, timestamp: 2022-08-20 14:02:41.823596\n",
      "resetting env. episode 8720, reward total was -14.0. running mean: -11.896996650824716, timestamp: 2022-08-20 14:02:45.659637\n",
      "resetting env. episode 8721, reward total was -3.0. running mean: -11.808026684316468, timestamp: 2022-08-20 14:02:52.653721\n",
      "resetting env. episode 8722, reward total was -17.0. running mean: -11.859946417473303, timestamp: 2022-08-20 14:02:57.279772\n",
      "resetting env. episode 8723, reward total was -12.0. running mean: -11.861346953298568, timestamp: 2022-08-20 14:03:02.950837\n",
      "resetting env. episode 8724, reward total was -15.0. running mean: -11.892733483765582, timestamp: 2022-08-20 14:03:08.468899\n",
      "resetting env. episode 8725, reward total was -14.0. running mean: -11.913806148927927, timestamp: 2022-08-20 14:03:12.871951\n",
      "resetting env. episode 8726, reward total was -12.0. running mean: -11.914668087438647, timestamp: 2022-08-20 14:03:17.260004\n",
      "resetting env. episode 8727, reward total was -10.0. running mean: -11.89552140656426, timestamp: 2022-08-20 14:03:23.265071\n",
      "resetting env. episode 8728, reward total was -5.0. running mean: -11.826566192498618, timestamp: 2022-08-20 14:03:29.359140\n",
      "resetting env. episode 8729, reward total was -16.0. running mean: -11.86830053057363, timestamp: 2022-08-20 14:03:33.714190\n",
      "resetting env. episode 8730, reward total was -7.0. running mean: -11.819617525267894, timestamp: 2022-08-20 14:03:41.372280\n",
      "resetting env. episode 8731, reward total was -12.0. running mean: -11.821421350015214, timestamp: 2022-08-20 14:03:46.699341\n",
      "resetting env. episode 8732, reward total was -7.0. running mean: -11.773207136515062, timestamp: 2022-08-20 14:03:53.746422\n",
      "resetting env. episode 8733, reward total was -11.0. running mean: -11.76547506514991, timestamp: 2022-08-20 14:03:59.084483\n",
      "resetting env. episode 8734, reward total was -11.0. running mean: -11.75782031449841, timestamp: 2022-08-20 14:04:03.468533\n",
      "resetting env. episode 8735, reward total was -13.0. running mean: -11.770242111353427, timestamp: 2022-08-20 14:04:08.258590\n",
      "resetting env. episode 8736, reward total was -14.0. running mean: -11.792539690239893, timestamp: 2022-08-20 14:04:13.038694\n",
      "resetting env. episode 8737, reward total was -6.0. running mean: -11.734614293337495, timestamp: 2022-08-20 14:04:20.003775\n",
      "resetting env. episode 8738, reward total was -17.0. running mean: -11.78726815040412, timestamp: 2022-08-20 14:04:24.179824\n",
      "resetting env. episode 8739, reward total was -7.0. running mean: -11.73939546890008, timestamp: 2022-08-20 14:04:30.505893\n",
      "resetting env. episode 8740, reward total was -11.0. running mean: -11.732001514211078, timestamp: 2022-08-20 14:04:35.653954\n",
      "resetting env. episode 8741, reward total was -9.0. running mean: -11.704681499068966, timestamp: 2022-08-20 14:04:42.391033\n",
      "resetting env. episode 8742, reward total was -19.0. running mean: -11.777634684078276, timestamp: 2022-08-20 14:04:46.249078\n",
      "resetting env. episode 8743, reward total was -14.0. running mean: -11.799858337237493, timestamp: 2022-08-20 14:04:50.900133\n",
      "resetting env. episode 8744, reward total was -14.0. running mean: -11.82185975386512, timestamp: 2022-08-20 14:04:55.481184\n",
      "resetting env. episode 8745, reward total was -18.0. running mean: -11.883641156326467, timestamp: 2022-08-20 14:04:59.657236\n",
      "resetting env. episode 8746, reward total was -12.0. running mean: -11.884804744763201, timestamp: 2022-08-20 14:05:05.180297\n",
      "resetting env. episode 8747, reward total was -14.0. running mean: -11.90595669731557, timestamp: 2022-08-20 14:05:10.145355\n",
      "resetting env. episode 8748, reward total was -13.0. running mean: -11.916897130342415, timestamp: 2022-08-20 14:05:15.649419\n",
      "resetting env. episode 8749, reward total was -15.0. running mean: -11.947728159038991, timestamp: 2022-08-20 14:05:20.995484\n",
      "resetting env. episode 8750, reward total was -18.0. running mean: -12.008250877448601, timestamp: 2022-08-20 14:05:26.157540\n",
      "resetting env. episode 8751, reward total was -13.0. running mean: -12.018168368674116, timestamp: 2022-08-20 14:05:33.026624\n",
      "resetting env. episode 8752, reward total was -12.0. running mean: -12.017986684987374, timestamp: 2022-08-20 14:05:38.940690\n",
      "resetting env. episode 8753, reward total was -15.0. running mean: -12.0478068181375, timestamp: 2022-08-20 14:05:44.615757\n",
      "resetting env. episode 8754, reward total was -11.0. running mean: -12.037328749956124, timestamp: 2022-08-20 14:05:49.340338\n",
      "resetting env. episode 8755, reward total was -13.0. running mean: -12.046955462456564, timestamp: 2022-08-20 14:05:54.558394\n",
      "resetting env. episode 8756, reward total was -13.0. running mean: -12.056485907832, timestamp: 2022-08-20 14:06:00.225460\n",
      "resetting env. episode 8757, reward total was -6.0. running mean: -11.995921048753681, timestamp: 2022-08-20 14:06:07.351545\n",
      "resetting env. episode 8758, reward total was -18.0. running mean: -12.055961838266144, timestamp: 2022-08-20 14:06:10.512588\n",
      "resetting env. episode 8759, reward total was -12.0. running mean: -12.055402219883483, timestamp: 2022-08-20 14:06:16.180170\n",
      "resetting env. episode 8760, reward total was -17.0. running mean: -12.104848197684648, timestamp: 2022-08-20 14:06:20.661221\n",
      "resetting env. episode 8761, reward total was -7.0. running mean: -12.053799715707802, timestamp: 2022-08-20 14:06:27.151295\n",
      "resetting env. episode 8762, reward total was -7.0. running mean: -12.003261718550725, timestamp: 2022-08-20 14:06:33.585373\n",
      "resetting env. episode 8763, reward total was -6.0. running mean: -11.943229101365217, timestamp: 2022-08-20 14:06:40.692974\n",
      "resetting env. episode 8764, reward total was 2.0. running mean: -11.803796810351566, timestamp: 2022-08-20 14:06:48.528068\n",
      "resetting env. episode 8765, reward total was -13.0. running mean: -11.81575884224805, timestamp: 2022-08-20 14:06:53.821910\n",
      "resetting env. episode 8766, reward total was -11.0. running mean: -11.807601253825569, timestamp: 2022-08-20 14:06:59.146974\n",
      "resetting env. episode 8767, reward total was -17.0. running mean: -11.859525241287313, timestamp: 2022-08-20 14:07:04.077031\n",
      "resetting env. episode 8768, reward total was -10.0. running mean: -11.84092998887444, timestamp: 2022-08-20 14:07:09.067088\n",
      "resetting env. episode 8769, reward total was 4.0. running mean: -11.682520688985695, timestamp: 2022-08-20 14:07:16.780176\n",
      "resetting env. episode 8770, reward total was -16.0. running mean: -11.725695482095839, timestamp: 2022-08-20 14:07:22.320242\n",
      "resetting env. episode 8771, reward total was -15.0. running mean: -11.758438527274881, timestamp: 2022-08-20 14:07:25.901286\n",
      "resetting env. episode 8772, reward total was -10.0. running mean: -11.740854142002132, timestamp: 2022-08-20 14:07:30.407334\n",
      "resetting env. episode 8773, reward total was -2.0. running mean: -11.64344560058211, timestamp: 2022-08-20 14:07:37.753421\n",
      "resetting env. episode 8774, reward total was -16.0. running mean: -11.687011144576289, timestamp: 2022-08-20 14:07:42.406999\n",
      "resetting env. episode 8775, reward total was -3.0. running mean: -11.600141033130525, timestamp: 2022-08-20 14:07:49.356613\n",
      "resetting env. episode 8776, reward total was -9.0. running mean: -11.574139622799219, timestamp: 2022-08-20 14:07:55.556673\n",
      "resetting env. episode 8777, reward total was -7.0. running mean: -11.528398226571227, timestamp: 2022-08-20 14:08:00.741261\n",
      "resetting env. episode 8778, reward total was -9.0. running mean: -11.503114244305515, timestamp: 2022-08-20 14:08:06.281326\n",
      "resetting env. episode 8779, reward total was -13.0. running mean: -11.51808310186246, timestamp: 2022-08-20 14:08:11.586388\n",
      "resetting env. episode 8780, reward total was -12.0. running mean: -11.522902270843835, timestamp: 2022-08-20 14:08:17.861457\n",
      "resetting env. episode 8781, reward total was -11.0. running mean: -11.517673248135395, timestamp: 2022-08-20 14:08:24.381537\n",
      "resetting env. episode 8782, reward total was -11.0. running mean: -11.51249651565404, timestamp: 2022-08-20 14:08:29.547118\n",
      "resetting env. episode 8783, reward total was 3.0. running mean: -11.3673715504975, timestamp: 2022-08-20 14:08:37.457203\n",
      "resetting env. episode 8784, reward total was -11.0. running mean: -11.363697834992525, timestamp: 2022-08-20 14:08:43.813279\n",
      "resetting env. episode 8785, reward total was -14.0. running mean: -11.3900608566426, timestamp: 2022-08-20 14:08:48.778336\n",
      "resetting env. episode 8786, reward total was -8.0. running mean: -11.356160248076174, timestamp: 2022-08-20 14:08:56.254424\n",
      "resetting env. episode 8787, reward total was -7.0. running mean: -11.312598645595413, timestamp: 2022-08-20 14:09:03.400508\n",
      "resetting env. episode 8788, reward total was -19.0. running mean: -11.389472659139459, timestamp: 2022-08-20 14:09:07.641553\n",
      "resetting env. episode 8789, reward total was -12.0. running mean: -11.395577932548063, timestamp: 2022-08-20 14:09:14.066632\n",
      "resetting env. episode 8790, reward total was -10.0. running mean: -11.381622153222581, timestamp: 2022-08-20 14:09:20.241231\n",
      "resetting env. episode 8791, reward total was -7.0. running mean: -11.337805931690356, timestamp: 2022-08-20 14:09:26.669302\n",
      "resetting env. episode 8792, reward total was -9.0. running mean: -11.314427872373452, timestamp: 2022-08-20 14:09:32.865375\n",
      "resetting env. episode 8793, reward total was -13.0. running mean: -11.331283593649719, timestamp: 2022-08-20 14:09:38.394437\n",
      "resetting env. episode 8794, reward total was -9.0. running mean: -11.307970757713221, timestamp: 2022-08-20 14:09:44.301036\n",
      "resetting env. episode 8795, reward total was -10.0. running mean: -11.294891050136089, timestamp: 2022-08-20 14:09:50.156102\n",
      "resetting env. episode 8796, reward total was -9.0. running mean: -11.271942139634728, timestamp: 2022-08-20 14:09:56.244172\n",
      "resetting env. episode 8797, reward total was -13.0. running mean: -11.289222718238381, timestamp: 2022-08-20 14:10:02.185766\n",
      "resetting env. episode 8798, reward total was -12.0. running mean: -11.296330491055997, timestamp: 2022-08-20 14:10:08.325841\n",
      "resetting env. episode 8799, reward total was -12.0. running mean: -11.303367186145437, timestamp: 2022-08-20 14:10:12.879890\n",
      "resetting env. episode 8800, reward total was -13.0. running mean: -11.320333514283982, timestamp: 2022-08-20 14:10:18.210950\n",
      "resetting env. episode 8801, reward total was -5.0. running mean: -11.257130179141143, timestamp: 2022-08-20 14:10:25.210033\n",
      "resetting env. episode 8802, reward total was -11.0. running mean: -11.25455887734973, timestamp: 2022-08-20 14:10:29.820083\n",
      "resetting env. episode 8803, reward total was -10.0. running mean: -11.242013288576233, timestamp: 2022-08-20 14:10:36.140155\n",
      "resetting env. episode 8804, reward total was -9.0. running mean: -11.21959315569047, timestamp: 2022-08-20 14:10:42.217225\n",
      "resetting env. episode 8805, reward total was -8.0. running mean: -11.187397224133566, timestamp: 2022-08-20 14:10:49.499310\n",
      "resetting env. episode 8806, reward total was -10.0. running mean: -11.17552325189223, timestamp: 2022-08-20 14:10:55.184378\n",
      "resetting env. episode 8807, reward total was -14.0. running mean: -11.203768019373308, timestamp: 2022-08-20 14:11:00.850440\n",
      "resetting env. episode 8808, reward total was -6.0. running mean: -11.151730339179576, timestamp: 2022-08-20 14:11:07.934523\n",
      "resetting env. episode 8809, reward total was -12.0. running mean: -11.160213035787779, timestamp: 2022-08-20 14:11:13.310113\n",
      "resetting env. episode 8810, reward total was -9.0. running mean: -11.1386109054299, timestamp: 2022-08-20 14:11:21.560726\n",
      "resetting env. episode 8811, reward total was -16.0. running mean: -11.1872247963756, timestamp: 2022-08-20 14:11:25.901774\n",
      "resetting env. episode 8812, reward total was -16.0. running mean: -11.235352548411845, timestamp: 2022-08-20 14:11:31.277836\n",
      "resetting env. episode 8813, reward total was -13.0. running mean: -11.252999022927726, timestamp: 2022-08-20 14:11:37.004901\n",
      "resetting env. episode 8814, reward total was -13.0. running mean: -11.27046903269845, timestamp: 2022-08-20 14:11:42.501014\n",
      "resetting env. episode 8815, reward total was -9.0. running mean: -11.247764342371466, timestamp: 2022-08-20 14:11:47.337071\n",
      "resetting env. episode 8816, reward total was -15.0. running mean: -11.285286698947752, timestamp: 2022-08-20 14:11:53.190135\n",
      "resetting env. episode 8817, reward total was 2.0. running mean: -11.152433831958275, timestamp: 2022-08-20 14:11:59.959217\n",
      "resetting env. episode 8818, reward total was -8.0. running mean: -11.120909493638692, timestamp: 2022-08-20 14:12:05.703284\n",
      "resetting env. episode 8819, reward total was -10.0. running mean: -11.109700398702305, timestamp: 2022-08-20 14:12:11.917354\n",
      "resetting env. episode 8820, reward total was -7.0. running mean: -11.068603394715282, timestamp: 2022-08-20 14:12:18.648432\n",
      "resetting env. episode 8821, reward total was -14.0. running mean: -11.09791736076813, timestamp: 2022-08-20 14:12:23.692490\n",
      "resetting env. episode 8822, reward total was -12.0. running mean: -11.106938187160448, timestamp: 2022-08-20 14:12:29.249551\n",
      "resetting env. episode 8823, reward total was -8.0. running mean: -11.075868805288843, timestamp: 2022-08-20 14:12:36.133633\n",
      "resetting env. episode 8824, reward total was -18.0. running mean: -11.145110117235955, timestamp: 2022-08-20 14:12:40.495680\n",
      "resetting env. episode 8825, reward total was -5.0. running mean: -11.083659016063596, timestamp: 2022-08-20 14:12:47.665768\n",
      "resetting env. episode 8826, reward total was -7.0. running mean: -11.04282242590296, timestamp: 2022-08-20 14:12:54.552842\n",
      "resetting env. episode 8827, reward total was -13.0. running mean: -11.062394201643931, timestamp: 2022-08-20 14:13:00.655914\n",
      "resetting env. episode 8828, reward total was -12.0. running mean: -11.071770259627492, timestamp: 2022-08-20 14:13:05.544969\n",
      "resetting env. episode 8829, reward total was -12.0. running mean: -11.081052557031215, timestamp: 2022-08-20 14:13:10.911031\n",
      "resetting env. episode 8830, reward total was -4.0. running mean: -11.010242031460903, timestamp: 2022-08-20 14:13:16.721097\n",
      "resetting env. episode 8831, reward total was -8.0. running mean: -10.980139611146294, timestamp: 2022-08-20 14:13:21.293149\n",
      "resetting env. episode 8832, reward total was -15.0. running mean: -11.020338215034831, timestamp: 2022-08-20 14:13:26.359210\n",
      "resetting env. episode 8833, reward total was -10.0. running mean: -11.010134832884482, timestamp: 2022-08-20 14:13:32.257320\n",
      "resetting env. episode 8834, reward total was -11.0. running mean: -11.010033484555636, timestamp: 2022-08-20 14:13:37.825912\n",
      "resetting env. episode 8835, reward total was -13.0. running mean: -11.02993314971008, timestamp: 2022-08-20 14:13:43.026970\n",
      "resetting env. episode 8836, reward total was -5.0. running mean: -10.96963381821298, timestamp: 2022-08-20 14:13:49.500044\n",
      "resetting env. episode 8837, reward total was -7.0. running mean: -10.92993748003085, timestamp: 2022-08-20 14:13:55.137110\n",
      "resetting env. episode 8838, reward total was -5.0. running mean: -10.870638105230542, timestamp: 2022-08-20 14:14:01.003698\n",
      "resetting env. episode 8839, reward total was -17.0. running mean: -10.931931724178236, timestamp: 2022-08-20 14:14:04.994745\n",
      "resetting env. episode 8840, reward total was -8.0. running mean: -10.902612406936454, timestamp: 2022-08-20 14:14:10.694810\n",
      "resetting env. episode 8841, reward total was -19.0. running mean: -10.983586282867089, timestamp: 2022-08-20 14:14:14.835859\n",
      "resetting env. episode 8842, reward total was -19.0. running mean: -11.063750420038417, timestamp: 2022-08-20 14:14:19.182912\n",
      "resetting env. episode 8843, reward total was -10.0. running mean: -11.053112915838032, timestamp: 2022-08-20 14:14:25.656992\n",
      "resetting env. episode 8844, reward total was -11.0. running mean: -11.052581786679651, timestamp: 2022-08-20 14:14:29.414024\n",
      "resetting env. episode 8845, reward total was -12.0. running mean: -11.062055968812853, timestamp: 2022-08-20 14:14:35.475095\n",
      "resetting env. episode 8846, reward total was -9.0. running mean: -11.041435409124725, timestamp: 2022-08-20 14:14:41.593691\n",
      "resetting env. episode 8847, reward total was -11.0. running mean: -11.041021055033477, timestamp: 2022-08-20 14:14:45.523739\n",
      "resetting env. episode 8848, reward total was -15.0. running mean: -11.080610844483143, timestamp: 2022-08-20 14:14:50.540320\n",
      "resetting env. episode 8849, reward total was 1.0. running mean: -10.959804736038311, timestamp: 2022-08-20 14:14:58.758411\n",
      "resetting env. episode 8850, reward total was -13.0. running mean: -10.98020668867793, timestamp: 2022-08-20 14:15:03.326469\n",
      "resetting env. episode 8851, reward total was -10.0. running mean: -10.97040462179115, timestamp: 2022-08-20 14:15:08.314522\n",
      "resetting env. episode 8852, reward total was -7.0. running mean: -10.930700575573239, timestamp: 2022-08-20 14:15:14.743596\n",
      "resetting env. episode 8853, reward total was -12.0. running mean: -10.941393569817505, timestamp: 2022-08-20 14:15:19.535175\n",
      "resetting env. episode 8854, reward total was -13.0. running mean: -10.96197963411933, timestamp: 2022-08-20 14:15:24.383753\n",
      "resetting env. episode 8855, reward total was -8.0. running mean: -10.932359837778137, timestamp: 2022-08-20 14:15:28.445849\n",
      "resetting env. episode 8856, reward total was -14.0. running mean: -10.963036239400356, timestamp: 2022-08-20 14:15:33.292906\n",
      "resetting env. episode 8857, reward total was -10.0. running mean: -10.953405877006352, timestamp: 2022-08-20 14:15:38.991969\n",
      "resetting env. episode 8858, reward total was -12.0. running mean: -10.963871818236287, timestamp: 2022-08-20 14:15:44.402036\n",
      "resetting env. episode 8859, reward total was -12.0. running mean: -10.974233100053922, timestamp: 2022-08-20 14:15:48.841604\n",
      "resetting env. episode 8860, reward total was -9.0. running mean: -10.954490769053383, timestamp: 2022-08-20 14:15:53.588657\n",
      "resetting env. episode 8861, reward total was -18.0. running mean: -11.024945861362848, timestamp: 2022-08-20 14:15:57.458226\n",
      "resetting env. episode 8862, reward total was -11.0. running mean: -11.02469640274922, timestamp: 2022-08-20 14:16:03.359293\n",
      "resetting env. episode 8863, reward total was -14.0. running mean: -11.054449438721727, timestamp: 2022-08-20 14:16:08.477350\n",
      "resetting env. episode 8864, reward total was -14.0. running mean: -11.08390494433451, timestamp: 2022-08-20 14:16:14.599422\n",
      "resetting env. episode 8865, reward total was -10.0. running mean: -11.073065894891164, timestamp: 2022-08-20 14:16:19.350533\n",
      "resetting env. episode 8866, reward total was -9.0. running mean: -11.052335235942252, timestamp: 2022-08-20 14:16:25.153650\n",
      "resetting env. episode 8867, reward total was -13.0. running mean: -11.07181188358283, timestamp: 2022-08-20 14:16:29.658701\n",
      "resetting env. episode 8868, reward total was -8.0. running mean: -11.041093764747002, timestamp: 2022-08-20 14:16:35.193766\n",
      "resetting env. episode 8869, reward total was -3.0. running mean: -10.96068282709953, timestamp: 2022-08-20 14:16:42.719854\n",
      "resetting env. episode 8870, reward total was -15.0. running mean: -11.001075998828535, timestamp: 2022-08-20 14:16:47.527905\n",
      "resetting env. episode 8871, reward total was -3.0. running mean: -10.92106523884025, timestamp: 2022-08-20 14:16:54.313985\n",
      "resetting env. episode 8872, reward total was -12.0. running mean: -10.931854586451847, timestamp: 2022-08-20 14:17:00.269054\n",
      "resetting env. episode 8873, reward total was -14.0. running mean: -10.962536040587329, timestamp: 2022-08-20 14:17:05.767113\n",
      "resetting env. episode 8874, reward total was -12.0. running mean: -10.972910680181455, timestamp: 2022-08-20 14:17:11.715187\n",
      "resetting env. episode 8875, reward total was -10.0. running mean: -10.96318157337964, timestamp: 2022-08-20 14:17:16.558760\n",
      "resetting env. episode 8876, reward total was -9.0. running mean: -10.943549757645842, timestamp: 2022-08-20 14:17:22.430353\n",
      "resetting env. episode 8877, reward total was -13.0. running mean: -10.964114260069385, timestamp: 2022-08-20 14:17:28.376419\n",
      "resetting env. episode 8878, reward total was -8.0. running mean: -10.934473117468691, timestamp: 2022-08-20 14:17:34.415488\n",
      "resetting env. episode 8879, reward total was -11.0. running mean: -10.935128386294004, timestamp: 2022-08-20 14:17:39.948553\n",
      "resetting env. episode 8880, reward total was -16.0. running mean: -10.985777102431063, timestamp: 2022-08-20 14:17:44.562600\n",
      "resetting env. episode 8881, reward total was -12.0. running mean: -10.995919331406752, timestamp: 2022-08-20 14:17:48.802652\n",
      "resetting env. episode 8882, reward total was -14.0. running mean: -11.025960138092685, timestamp: 2022-08-20 14:17:53.589234\n",
      "resetting env. episode 8883, reward total was -6.0. running mean: -10.97570053671176, timestamp: 2022-08-20 14:17:59.200303\n",
      "resetting env. episode 8884, reward total was -10.0. running mean: -10.96594353134464, timestamp: 2022-08-20 14:18:04.342361\n",
      "resetting env. episode 8885, reward total was -10.0. running mean: -10.956284096031194, timestamp: 2022-08-20 14:18:09.497415\n",
      "resetting env. episode 8886, reward total was -13.0. running mean: -10.976721255070883, timestamp: 2022-08-20 14:18:14.359999\n",
      "resetting env. episode 8887, reward total was -12.0. running mean: -10.986954042520173, timestamp: 2022-08-20 14:18:19.109053\n",
      "resetting env. episode 8888, reward total was -8.0. running mean: -10.957084502094972, timestamp: 2022-08-20 14:18:23.788108\n",
      "resetting env. episode 8889, reward total was -9.0. running mean: -10.937513657074023, timestamp: 2022-08-20 14:18:30.345184\n",
      "resetting env. episode 8890, reward total was -11.0. running mean: -10.938138520503282, timestamp: 2022-08-20 14:18:35.351235\n",
      "resetting env. episode 8891, reward total was -16.0. running mean: -10.988757135298249, timestamp: 2022-08-20 14:18:39.148283\n",
      "resetting env. episode 8892, reward total was -9.0. running mean: -10.968869563945265, timestamp: 2022-08-20 14:18:44.714345\n",
      "resetting env. episode 8893, reward total was -5.0. running mean: -10.909180868305814, timestamp: 2022-08-20 14:18:51.912426\n",
      "resetting env. episode 8894, reward total was -14.0. running mean: -10.940089059622757, timestamp: 2022-08-20 14:18:57.292488\n",
      "resetting env. episode 8895, reward total was -10.0. running mean: -10.93068816902653, timestamp: 2022-08-20 14:19:02.930552\n",
      "resetting env. episode 8896, reward total was -17.0. running mean: -10.991381287336264, timestamp: 2022-08-20 14:19:07.221132\n",
      "resetting env. episode 8897, reward total was -7.0. running mean: -10.951467474462902, timestamp: 2022-08-20 14:19:14.959736\n",
      "resetting env. episode 8898, reward total was -16.0. running mean: -11.001952799718273, timestamp: 2022-08-20 14:19:20.215852\n",
      "resetting env. episode 8899, reward total was -16.0. running mean: -11.05193327172109, timestamp: 2022-08-20 14:19:24.671903\n",
      "resetting env. episode 8900, reward total was -13.0. running mean: -11.07141393900388, timestamp: 2022-08-20 14:19:29.674961\n",
      "resetting env. episode 8901, reward total was -11.0. running mean: -11.070699799613841, timestamp: 2022-08-20 14:19:35.838559\n",
      "resetting env. episode 8902, reward total was -16.0. running mean: -11.119992801617704, timestamp: 2022-08-20 14:19:39.657601\n",
      "resetting env. episode 8903, reward total was -10.0. running mean: -11.108792873601526, timestamp: 2022-08-20 14:19:45.274196\n",
      "resetting env. episode 8904, reward total was -11.0. running mean: -11.10770494486551, timestamp: 2022-08-20 14:19:50.843306\n",
      "resetting env. episode 8905, reward total was -17.0. running mean: -11.166627895416855, timestamp: 2022-08-20 14:19:55.345359\n",
      "resetting env. episode 8906, reward total was -13.0. running mean: -11.184961616462688, timestamp: 2022-08-20 14:20:00.559414\n",
      "resetting env. episode 8907, reward total was -13.0. running mean: -11.203112000298063, timestamp: 2022-08-20 14:20:05.118470\n",
      "resetting env. episode 8908, reward total was -9.0. running mean: -11.181080880295083, timestamp: 2022-08-20 14:20:10.950536\n",
      "resetting env. episode 8909, reward total was -10.0. running mean: -11.169270071492132, timestamp: 2022-08-20 14:20:16.149600\n",
      "resetting env. episode 8910, reward total was -2.0. running mean: -11.07757737077721, timestamp: 2022-08-20 14:20:22.951672\n",
      "resetting env. episode 8911, reward total was -12.0. running mean: -11.086801597069437, timestamp: 2022-08-20 14:20:27.852730\n",
      "resetting env. episode 8912, reward total was -6.0. running mean: -11.035933581098742, timestamp: 2022-08-20 14:20:34.102801\n",
      "resetting env. episode 8913, reward total was -9.0. running mean: -11.015574245287755, timestamp: 2022-08-20 14:20:39.489862\n",
      "resetting env. episode 8914, reward total was -12.0. running mean: -11.025418502834876, timestamp: 2022-08-20 14:20:44.939925\n",
      "resetting env. episode 8915, reward total was 1.0. running mean: -10.905164317806527, timestamp: 2022-08-20 14:20:51.955528\n",
      "resetting env. episode 8916, reward total was -8.0. running mean: -10.876112674628462, timestamp: 2022-08-20 14:20:57.662595\n",
      "resetting env. episode 8917, reward total was -4.0. running mean: -10.807351547882178, timestamp: 2022-08-20 14:21:03.452661\n",
      "resetting env. episode 8918, reward total was -9.0. running mean: -10.789278032403356, timestamp: 2022-08-20 14:21:09.283727\n",
      "resetting env. episode 8919, reward total was -9.0. running mean: -10.771385252079321, timestamp: 2022-08-20 14:21:14.465832\n",
      "resetting env. episode 8920, reward total was -10.0. running mean: -10.763671399558527, timestamp: 2022-08-20 14:21:19.730891\n",
      "resetting env. episode 8921, reward total was -12.0. running mean: -10.77603468556294, timestamp: 2022-08-20 14:21:25.318958\n",
      "resetting env. episode 8922, reward total was -3.0. running mean: -10.69827433870731, timestamp: 2022-08-20 14:21:31.541551\n",
      "resetting env. episode 8923, reward total was -15.0. running mean: -10.741291595320238, timestamp: 2022-08-20 14:21:36.626609\n",
      "resetting env. episode 8924, reward total was -7.0. running mean: -10.703878679367035, timestamp: 2022-08-20 14:21:43.491689\n",
      "resetting env. episode 8925, reward total was -13.0. running mean: -10.726839892573365, timestamp: 2022-08-20 14:21:49.318752\n",
      "resetting env. episode 8926, reward total was -7.0. running mean: -10.68957149364763, timestamp: 2022-08-20 14:21:55.230818\n",
      "resetting env. episode 8927, reward total was -8.0. running mean: -10.662675778711154, timestamp: 2022-08-20 14:22:01.198887\n",
      "resetting env. episode 8928, reward total was -17.0. running mean: -10.726049020924043, timestamp: 2022-08-20 14:22:05.065937\n",
      "resetting env. episode 8929, reward total was -8.0. running mean: -10.698788530714802, timestamp: 2022-08-20 14:22:10.862524\n",
      "resetting env. episode 8930, reward total was -14.0. running mean: -10.731800645407654, timestamp: 2022-08-20 14:22:15.839583\n",
      "resetting env. episode 8931, reward total was -9.0. running mean: -10.714482638953577, timestamp: 2022-08-20 14:22:20.648635\n",
      "resetting env. episode 8932, reward total was -11.0. running mean: -10.71733781256404, timestamp: 2022-08-20 14:22:26.612708\n",
      "resetting env. episode 8933, reward total was -15.0. running mean: -10.7601644344384, timestamp: 2022-08-20 14:22:31.686768\n",
      "resetting env. episode 8934, reward total was -7.0. running mean: -10.722562790094015, timestamp: 2022-08-20 14:22:39.236852\n",
      "resetting env. episode 8935, reward total was -11.0. running mean: -10.725337162193075, timestamp: 2022-08-20 14:22:43.643902\n",
      "resetting env. episode 8936, reward total was -6.0. running mean: -10.678083790571144, timestamp: 2022-08-20 14:22:50.481507\n",
      "resetting env. episode 8937, reward total was -11.0. running mean: -10.681302952665432, timestamp: 2022-08-20 14:22:56.661580\n",
      "resetting env. episode 8938, reward total was -14.0. running mean: -10.714489923138778, timestamp: 2022-08-20 14:23:01.865640\n",
      "resetting env. episode 8939, reward total was -6.0. running mean: -10.66734502390739, timestamp: 2022-08-20 14:23:08.288713\n",
      "resetting env. episode 8940, reward total was -15.0. running mean: -10.710671573668318, timestamp: 2022-08-20 14:23:13.024293\n",
      "resetting env. episode 8941, reward total was -7.0. running mean: -10.673564857931634, timestamp: 2022-08-20 14:23:19.728371\n",
      "resetting env. episode 8942, reward total was -7.0. running mean: -10.636829209352317, timestamp: 2022-08-20 14:23:26.258445\n",
      "resetting env. episode 8943, reward total was -17.0. running mean: -10.700460917258795, timestamp: 2022-08-20 14:23:31.672507\n",
      "resetting env. episode 8944, reward total was -17.0. running mean: -10.763456308086207, timestamp: 2022-08-20 14:23:36.238560\n",
      "resetting env. episode 8945, reward total was -20.0. running mean: -10.855821745005343, timestamp: 2022-08-20 14:23:40.080606\n",
      "resetting env. episode 8946, reward total was -13.0. running mean: -10.877263527555291, timestamp: 2022-08-20 14:23:44.152655\n",
      "resetting env. episode 8947, reward total was -14.0. running mean: -10.908490892279739, timestamp: 2022-08-20 14:23:48.721704\n",
      "resetting env. episode 8948, reward total was -15.0. running mean: -10.949405983356941, timestamp: 2022-08-20 14:23:53.116759\n",
      "resetting env. episode 8949, reward total was -7.0. running mean: -10.909911923523373, timestamp: 2022-08-20 14:23:58.846829\n",
      "resetting env. episode 8950, reward total was -11.0. running mean: -10.910812804288138, timestamp: 2022-08-20 14:24:03.463877\n",
      "resetting env. episode 8951, reward total was -9.0. running mean: -10.891704676245256, timestamp: 2022-08-20 14:24:08.983939\n",
      "resetting env. episode 8952, reward total was -19.0. running mean: -10.972787629482802, timestamp: 2022-08-20 14:24:12.789987\n",
      "resetting env. episode 8953, reward total was -5.0. running mean: -10.913059753187975, timestamp: 2022-08-20 14:24:20.113071\n",
      "resetting env. episode 8954, reward total was -12.0. running mean: -10.923929155656094, timestamp: 2022-08-20 14:24:25.454136\n",
      "resetting env. episode 8955, reward total was -16.0. running mean: -10.974689864099533, timestamp: 2022-08-20 14:24:29.941183\n",
      "resetting env. episode 8956, reward total was -17.0. running mean: -11.034942965458537, timestamp: 2022-08-20 14:24:34.136233\n",
      "resetting env. episode 8957, reward total was 7.0. running mean: -10.854593535803952, timestamp: 2022-08-20 14:24:39.637341\n",
      "resetting env. episode 8958, reward total was -5.0. running mean: -10.796047600445913, timestamp: 2022-08-20 14:24:45.285929\n",
      "resetting env. episode 8959, reward total was -17.0. running mean: -10.858087124441454, timestamp: 2022-08-20 14:24:49.439981\n",
      "resetting env. episode 8960, reward total was -15.0. running mean: -10.899506253197039, timestamp: 2022-08-20 14:24:54.194030\n",
      "resetting env. episode 8961, reward total was -5.0. running mean: -10.840511190665069, timestamp: 2022-08-20 14:25:00.533104\n",
      "resetting env. episode 8962, reward total was -12.0. running mean: -10.852106078758418, timestamp: 2022-08-20 14:25:05.758165\n",
      "resetting env. episode 8963, reward total was -13.0. running mean: -10.873585017970834, timestamp: 2022-08-20 14:25:09.928213\n",
      "resetting env. episode 8964, reward total was -9.0. running mean: -10.854849167791125, timestamp: 2022-08-20 14:25:15.340275\n",
      "resetting env. episode 8965, reward total was -15.0. running mean: -10.896300676113214, timestamp: 2022-08-20 14:25:20.531335\n",
      "resetting env. episode 8966, reward total was -7.0. running mean: -10.857337669352082, timestamp: 2022-08-20 14:25:26.530408\n",
      "resetting env. episode 8967, reward total was -15.0. running mean: -10.898764292658562, timestamp: 2022-08-20 14:25:30.901455\n",
      "resetting env. episode 8968, reward total was -9.0. running mean: -10.879776649731976, timestamp: 2022-08-20 14:25:37.034528\n",
      "resetting env. episode 8969, reward total was -11.0. running mean: -10.880978883234656, timestamp: 2022-08-20 14:25:42.985600\n",
      "resetting env. episode 8970, reward total was -9.0. running mean: -10.86216909440231, timestamp: 2022-08-20 14:25:48.081657\n",
      "resetting env. episode 8971, reward total was -13.0. running mean: -10.883547403458287, timestamp: 2022-08-20 14:25:52.375228\n",
      "resetting env. episode 8972, reward total was -10.0. running mean: -10.874711929423704, timestamp: 2022-08-20 14:25:58.058297\n",
      "resetting env. episode 8973, reward total was -5.0. running mean: -10.815964810129467, timestamp: 2022-08-20 14:26:04.317367\n",
      "resetting env. episode 8974, reward total was -19.0. running mean: -10.897805162028172, timestamp: 2022-08-20 14:26:07.637409\n",
      "resetting env. episode 8975, reward total was -10.0. running mean: -10.88882711040789, timestamp: 2022-08-20 14:26:14.279481\n",
      "resetting env. episode 8976, reward total was -14.0. running mean: -10.919938839303812, timestamp: 2022-08-20 14:26:19.137537\n",
      "resetting env. episode 8977, reward total was -5.0. running mean: -10.860739450910774, timestamp: 2022-08-20 14:26:24.740603\n",
      "resetting env. episode 8978, reward total was 4.0. running mean: -10.712132056401668, timestamp: 2022-08-20 14:26:30.901673\n",
      "resetting env. episode 8979, reward total was -13.0. running mean: -10.735010735837651, timestamp: 2022-08-20 14:26:36.865741\n",
      "resetting env. episode 8980, reward total was -10.0. running mean: -10.727660628479274, timestamp: 2022-08-20 14:26:41.588796\n",
      "resetting env. episode 8981, reward total was -13.0. running mean: -10.750384022194481, timestamp: 2022-08-20 14:26:46.956857\n",
      "resetting env. episode 8982, reward total was -11.0. running mean: -10.752880181972536, timestamp: 2022-08-20 14:26:52.761927\n",
      "resetting env. episode 8983, reward total was -13.0. running mean: -10.775351380152811, timestamp: 2022-08-20 14:26:58.386560\n",
      "resetting env. episode 8984, reward total was -16.0. running mean: -10.827597866351283, timestamp: 2022-08-20 14:27:02.955615\n",
      "resetting env. episode 8985, reward total was -5.0. running mean: -10.76932188768777, timestamp: 2022-08-20 14:27:10.005695\n",
      "resetting env. episode 8986, reward total was -5.0. running mean: -10.711628668810892, timestamp: 2022-08-20 14:27:16.797300\n",
      "resetting env. episode 8987, reward total was -8.0. running mean: -10.684512382122783, timestamp: 2022-08-20 14:27:22.585888\n",
      "resetting env. episode 8988, reward total was -12.0. running mean: -10.697667258301554, timestamp: 2022-08-20 14:27:27.938949\n",
      "resetting env. episode 8989, reward total was -10.0. running mean: -10.690690585718537, timestamp: 2022-08-20 14:27:32.201998\n",
      "resetting env. episode 8990, reward total was -8.0. running mean: -10.663783679861352, timestamp: 2022-08-20 14:27:38.536069\n",
      "resetting env. episode 8991, reward total was -17.0. running mean: -10.727145843062738, timestamp: 2022-08-20 14:27:42.264114\n",
      "resetting env. episode 8992, reward total was -16.0. running mean: -10.77987438463211, timestamp: 2022-08-20 14:27:46.242158\n",
      "resetting env. episode 8993, reward total was -9.0. running mean: -10.76207564078579, timestamp: 2022-08-20 14:27:51.859224\n",
      "resetting env. episode 8994, reward total was -15.0. running mean: -10.804454884377932, timestamp: 2022-08-20 14:27:56.845282\n",
      "resetting env. episode 8995, reward total was -12.0. running mean: -10.816410335534153, timestamp: 2022-08-20 14:28:01.906341\n",
      "resetting env. episode 8996, reward total was -13.0. running mean: -10.838246232178811, timestamp: 2022-08-20 14:28:06.783395\n",
      "resetting env. episode 8997, reward total was -10.0. running mean: -10.829863769857022, timestamp: 2022-08-20 14:28:11.063444\n",
      "resetting env. episode 8998, reward total was -16.0. running mean: -10.881565132158451, timestamp: 2022-08-20 14:28:15.660023\n",
      "resetting env. episode 8999, reward total was -15.0. running mean: -10.922749480836867, timestamp: 2022-08-20 14:28:19.798592\n",
      "resetting env. episode 9000, reward total was -15.0. running mean: -10.963521986028498, timestamp: 2022-08-20 14:28:24.273642\n",
      "resetting env. episode 9001, reward total was -11.0. running mean: -10.963886766168212, timestamp: 2022-08-20 14:28:29.402702\n",
      "resetting env. episode 9002, reward total was -11.0. running mean: -10.96424789850653, timestamp: 2022-08-20 14:28:34.501760\n",
      "resetting env. episode 9003, reward total was -4.0. running mean: -10.894605419521463, timestamp: 2022-08-20 14:28:41.024837\n",
      "resetting env. episode 9004, reward total was -9.0. running mean: -10.875659365326248, timestamp: 2022-08-20 14:28:47.186908\n",
      "resetting env. episode 9005, reward total was -2.0. running mean: -10.786902771672985, timestamp: 2022-08-20 14:28:53.995987\n",
      "resetting env. episode 9006, reward total was -17.0. running mean: -10.849033743956255, timestamp: 2022-08-20 14:28:58.973043\n",
      "resetting env. episode 9007, reward total was -14.0. running mean: -10.880543406516693, timestamp: 2022-08-20 14:29:05.027113\n",
      "resetting env. episode 9008, reward total was -17.0. running mean: -10.941737972451527, timestamp: 2022-08-20 14:29:09.470163\n",
      "resetting env. episode 9009, reward total was -7.0. running mean: -10.902320592727012, timestamp: 2022-08-20 14:29:14.977226\n",
      "resetting env. episode 9010, reward total was -12.0. running mean: -10.91329738679974, timestamp: 2022-08-20 14:29:20.424813\n",
      "resetting env. episode 9011, reward total was -13.0. running mean: -10.934164412931745, timestamp: 2022-08-20 14:29:26.322888\n",
      "resetting env. episode 9012, reward total was -16.0. running mean: -10.984822768802427, timestamp: 2022-08-20 14:29:31.780464\n",
      "resetting env. episode 9013, reward total was -10.0. running mean: -10.974974541114403, timestamp: 2022-08-20 14:29:36.662045\n",
      "resetting env. episode 9014, reward total was -8.0. running mean: -10.94522479570326, timestamp: 2022-08-20 14:29:43.438124\n",
      "resetting env. episode 9015, reward total was -11.0. running mean: -10.945772547746227, timestamp: 2022-08-20 14:29:48.729185\n",
      "resetting env. episode 9016, reward total was -14.0. running mean: -10.976314822268765, timestamp: 2022-08-20 14:29:54.115246\n",
      "resetting env. episode 9017, reward total was -12.0. running mean: -10.986551674046076, timestamp: 2022-08-20 14:29:59.725311\n",
      "resetting env. episode 9018, reward total was -3.0. running mean: -10.906686157305614, timestamp: 2022-08-20 14:30:06.681391\n",
      "resetting env. episode 9019, reward total was -5.0. running mean: -10.847619295732558, timestamp: 2022-08-20 14:30:13.600997\n",
      "resetting env. episode 9020, reward total was -14.0. running mean: -10.879143102775233, timestamp: 2022-08-20 14:30:18.630579\n",
      "resetting env. episode 9021, reward total was -16.0. running mean: -10.93035167174748, timestamp: 2022-08-20 14:30:23.406684\n",
      "resetting env. episode 9022, reward total was -7.0. running mean: -10.891048155030006, timestamp: 2022-08-20 14:30:29.020748\n",
      "resetting env. episode 9023, reward total was -7.0. running mean: -10.852137673479707, timestamp: 2022-08-20 14:30:35.056342\n",
      "resetting env. episode 9024, reward total was -10.0. running mean: -10.843616296744909, timestamp: 2022-08-20 14:30:40.253402\n",
      "resetting env. episode 9025, reward total was -5.0. running mean: -10.78518013377746, timestamp: 2022-08-20 14:30:46.897003\n",
      "resetting env. episode 9026, reward total was -9.0. running mean: -10.767328332439686, timestamp: 2022-08-20 14:30:53.290075\n",
      "resetting env. episode 9027, reward total was -16.0. running mean: -10.819655049115289, timestamp: 2022-08-20 14:30:57.194646\n",
      "resetting env. episode 9028, reward total was -19.0. running mean: -10.901458498624136, timestamp: 2022-08-20 14:31:00.512677\n",
      "resetting env. episode 9029, reward total was -19.0. running mean: -10.982443913637894, timestamp: 2022-08-20 14:31:04.218724\n",
      "resetting env. episode 9030, reward total was -7.0. running mean: -10.942619474501516, timestamp: 2022-08-20 14:31:10.572796\n",
      "resetting env. episode 9031, reward total was -18.0. running mean: -11.0131932797565, timestamp: 2022-08-20 14:31:14.915844\n",
      "resetting env. episode 9032, reward total was -12.0. running mean: -11.023061346958935, timestamp: 2022-08-20 14:31:19.531898\n",
      "resetting env. episode 9033, reward total was -14.0. running mean: -11.052830733489346, timestamp: 2022-08-20 14:31:24.918959\n",
      "resetting env. episode 9034, reward total was -11.0. running mean: -11.052302426154451, timestamp: 2022-08-20 14:31:29.993017\n",
      "resetting env. episode 9035, reward total was -7.0. running mean: -11.011779401892907, timestamp: 2022-08-20 14:31:35.365077\n",
      "resetting env. episode 9036, reward total was -9.0. running mean: -10.991661607873978, timestamp: 2022-08-20 14:31:41.515148\n",
      "resetting env. episode 9037, reward total was -10.0. running mean: -10.981744991795237, timestamp: 2022-08-20 14:31:47.678218\n",
      "resetting env. episode 9038, reward total was -15.0. running mean: -11.021927541877284, timestamp: 2022-08-20 14:31:52.593276\n",
      "resetting env. episode 9039, reward total was -15.0. running mean: -11.061708266458512, timestamp: 2022-08-20 14:31:58.210385\n",
      "resetting env. episode 9040, reward total was -10.0. running mean: -11.051091183793925, timestamp: 2022-08-20 14:32:04.664987\n",
      "resetting env. episode 9041, reward total was -10.0. running mean: -11.040580271955985, timestamp: 2022-08-20 14:32:10.864056\n",
      "resetting env. episode 9042, reward total was -10.0. running mean: -11.030174469236425, timestamp: 2022-08-20 14:32:16.382122\n",
      "resetting env. episode 9043, reward total was -15.0. running mean: -11.06987272454406, timestamp: 2022-08-20 14:32:20.207162\n",
      "resetting env. episode 9044, reward total was -9.0. running mean: -11.04917399729862, timestamp: 2022-08-20 14:32:25.519225\n",
      "resetting env. episode 9045, reward total was -10.0. running mean: -11.038682257325634, timestamp: 2022-08-20 14:32:31.885295\n",
      "resetting env. episode 9046, reward total was -4.0. running mean: -10.968295434752378, timestamp: 2022-08-20 14:32:38.586892\n",
      "resetting env. episode 9047, reward total was -3.0. running mean: -10.888612480404854, timestamp: 2022-08-20 14:32:45.322970\n",
      "resetting env. episode 9048, reward total was -16.0. running mean: -10.939726355600806, timestamp: 2022-08-20 14:32:51.033033\n",
      "resetting env. episode 9049, reward total was -18.0. running mean: -11.010329092044797, timestamp: 2022-08-20 14:32:54.986600\n",
      "resetting env. episode 9050, reward total was -1.0. running mean: -10.91022580112435, timestamp: 2022-08-20 14:33:02.976689\n",
      "resetting env. episode 9051, reward total was -5.0. running mean: -10.851123543113106, timestamp: 2022-08-20 14:33:09.768767\n",
      "resetting env. episode 9052, reward total was -9.0. running mean: -10.832612307681975, timestamp: 2022-08-20 14:33:15.274831\n",
      "resetting env. episode 9053, reward total was -11.0. running mean: -10.834286184605155, timestamp: 2022-08-20 14:33:20.381889\n",
      "resetting env. episode 9054, reward total was -9.0. running mean: -10.815943322759104, timestamp: 2022-08-20 14:33:26.204954\n",
      "resetting env. episode 9055, reward total was -15.0. running mean: -10.857783889531513, timestamp: 2022-08-20 14:33:31.084533\n",
      "resetting env. episode 9056, reward total was 4.0. running mean: -10.7092060506362, timestamp: 2022-08-20 14:33:37.367606\n",
      "resetting env. episode 9057, reward total was -8.0. running mean: -10.682113990129837, timestamp: 2022-08-20 14:33:43.652675\n",
      "resetting env. episode 9058, reward total was -17.0. running mean: -10.74529285022854, timestamp: 2022-08-20 14:33:48.288730\n",
      "resetting env. episode 9059, reward total was -13.0. running mean: -10.767839921726255, timestamp: 2022-08-20 14:33:53.068303\n",
      "resetting env. episode 9060, reward total was -12.0. running mean: -10.780161522508992, timestamp: 2022-08-20 14:33:58.389363\n",
      "resetting env. episode 9061, reward total was -11.0. running mean: -10.782359907283901, timestamp: 2022-08-20 14:34:03.175419\n",
      "resetting env. episode 9062, reward total was -7.0. running mean: -10.744536308211062, timestamp: 2022-08-20 14:34:08.516479\n",
      "resetting env. episode 9063, reward total was -7.0. running mean: -10.707090945128952, timestamp: 2022-08-20 14:34:15.950132\n",
      "resetting env. episode 9064, reward total was -10.0. running mean: -10.700020035677662, timestamp: 2022-08-20 14:34:21.567195\n",
      "resetting env. episode 9065, reward total was -14.0. running mean: -10.733019835320885, timestamp: 2022-08-20 14:34:26.058252\n",
      "resetting env. episode 9066, reward total was -14.0. running mean: -10.765689636967677, timestamp: 2022-08-20 14:34:30.956305\n",
      "resetting env. episode 9067, reward total was -12.0. running mean: -10.778032740597999, timestamp: 2022-08-20 14:34:37.008371\n",
      "resetting env. episode 9068, reward total was -10.0. running mean: -10.770252413192019, timestamp: 2022-08-20 14:34:42.493435\n",
      "resetting env. episode 9069, reward total was -10.0. running mean: -10.762549889060098, timestamp: 2022-08-20 14:34:49.178513\n",
      "resetting env. episode 9070, reward total was -11.0. running mean: -10.764924390169497, timestamp: 2022-08-20 14:34:54.201567\n",
      "resetting env. episode 9071, reward total was -13.0. running mean: -10.787275146267802, timestamp: 2022-08-20 14:34:59.726630\n",
      "resetting env. episode 9072, reward total was -9.0. running mean: -10.769402394805125, timestamp: 2022-08-20 14:35:06.422233\n",
      "resetting env. episode 9073, reward total was -12.0. running mean: -10.781708370857073, timestamp: 2022-08-20 14:35:11.386294\n",
      "resetting env. episode 9074, reward total was -11.0. running mean: -10.783891287148501, timestamp: 2022-08-20 14:35:17.746366\n",
      "resetting env. episode 9075, reward total was -7.0. running mean: -10.746052374277017, timestamp: 2022-08-20 14:35:23.393953\n",
      "resetting env. episode 9076, reward total was -15.0. running mean: -10.788591850534248, timestamp: 2022-08-20 14:35:27.455051\n",
      "resetting env. episode 9077, reward total was -14.0. running mean: -10.820705932028906, timestamp: 2022-08-20 14:35:32.333629\n",
      "resetting env. episode 9078, reward total was -16.0. running mean: -10.872498872708617, timestamp: 2022-08-20 14:35:37.226683\n",
      "resetting env. episode 9079, reward total was -5.0. running mean: -10.813773883981531, timestamp: 2022-08-20 14:35:43.287753\n",
      "resetting env. episode 9080, reward total was -2.0. running mean: -10.725636145141715, timestamp: 2022-08-20 14:35:49.964828\n",
      "resetting env. episode 9081, reward total was -13.0. running mean: -10.748379783690298, timestamp: 2022-08-20 14:35:55.863423\n",
      "resetting env. episode 9082, reward total was -7.0. running mean: -10.710895985853396, timestamp: 2022-08-20 14:36:01.788493\n",
      "resetting env. episode 9083, reward total was -6.0. running mean: -10.663787025994862, timestamp: 2022-08-20 14:36:09.939586\n",
      "resetting env. episode 9084, reward total was -6.0. running mean: -10.617149155734914, timestamp: 2022-08-20 14:36:16.742661\n",
      "resetting env. episode 9085, reward total was -15.0. running mean: -10.660977664177565, timestamp: 2022-08-20 14:36:20.552707\n",
      "resetting env. episode 9086, reward total was -15.0. running mean: -10.70436788753579, timestamp: 2022-08-20 14:36:26.305771\n",
      "resetting env. episode 9087, reward total was -7.0. running mean: -10.667324208660432, timestamp: 2022-08-20 14:36:31.977836\n",
      "resetting env. episode 9088, reward total was -16.0. running mean: -10.720650966573828, timestamp: 2022-08-20 14:36:36.771890\n",
      "resetting env. episode 9089, reward total was -9.0. running mean: -10.70344445690809, timestamp: 2022-08-20 14:36:42.958964\n",
      "resetting env. episode 9090, reward total was -17.0. running mean: -10.766410012339009, timestamp: 2022-08-20 14:36:46.578002\n",
      "resetting env. episode 9091, reward total was -11.0. running mean: -10.768745912215618, timestamp: 2022-08-20 14:36:51.954067\n",
      "resetting env. episode 9092, reward total was -10.0. running mean: -10.761058453093462, timestamp: 2022-08-20 14:36:57.828660\n",
      "resetting env. episode 9093, reward total was -5.0. running mean: -10.703447868562527, timestamp: 2022-08-20 14:37:04.498737\n",
      "resetting env. episode 9094, reward total was -6.0. running mean: -10.656413389876903, timestamp: 2022-08-20 14:37:12.026823\n",
      "resetting env. episode 9095, reward total was -3.0. running mean: -10.579849255978132, timestamp: 2022-08-20 14:37:20.009917\n",
      "resetting env. episode 9096, reward total was 1.0. running mean: -10.464050763418351, timestamp: 2022-08-20 14:37:26.993519\n",
      "resetting env. episode 9097, reward total was -12.0. running mean: -10.479410255784167, timestamp: 2022-08-20 14:37:32.707584\n",
      "resetting env. episode 9098, reward total was -1.0. running mean: -10.384616153226325, timestamp: 2022-08-20 14:37:40.536677\n",
      "resetting env. episode 9099, reward total was -9.0. running mean: -10.370769991694061, timestamp: 2022-08-20 14:37:46.499744\n",
      "resetting env. episode 9100, reward total was -13.0. running mean: -10.397062291777122, timestamp: 2022-08-20 14:37:52.189809\n",
      "resetting env. episode 9101, reward total was -12.0. running mean: -10.41309166885935, timestamp: 2022-08-20 14:37:57.616874\n",
      "resetting env. episode 9102, reward total was -4.0. running mean: -10.348960752170756, timestamp: 2022-08-20 14:38:04.199947\n",
      "resetting env. episode 9103, reward total was -5.0. running mean: -10.29547114464905, timestamp: 2022-08-20 14:38:10.349017\n",
      "resetting env. episode 9104, reward total was -17.0. running mean: -10.36251643320256, timestamp: 2022-08-20 14:38:14.464065\n",
      "resetting env. episode 9105, reward total was -4.0. running mean: -10.298891268870532, timestamp: 2022-08-20 14:38:21.227142\n",
      "resetting env. episode 9106, reward total was -14.0. running mean: -10.335902356181828, timestamp: 2022-08-20 14:38:26.662204\n",
      "resetting env. episode 9107, reward total was -17.0. running mean: -10.40254333262001, timestamp: 2022-08-20 14:38:31.412259\n",
      "resetting env. episode 9108, reward total was -16.0. running mean: -10.45851789929381, timestamp: 2022-08-20 14:38:35.646310\n",
      "resetting env. episode 9109, reward total was -10.0. running mean: -10.453932720300871, timestamp: 2022-08-20 14:38:40.583365\n",
      "resetting env. episode 9110, reward total was -12.0. running mean: -10.469393393097862, timestamp: 2022-08-20 14:38:46.112428\n",
      "resetting env. episode 9111, reward total was -8.0. running mean: -10.444699459166884, timestamp: 2022-08-20 14:38:52.134546\n",
      "resetting env. episode 9112, reward total was -9.0. running mean: -10.430252464575215, timestamp: 2022-08-20 14:38:58.240616\n",
      "resetting env. episode 9113, reward total was -11.0. running mean: -10.435949939929463, timestamp: 2022-08-20 14:39:04.519688\n",
      "resetting env. episode 9114, reward total was -11.0. running mean: -10.441590440530168, timestamp: 2022-08-20 14:39:10.166757\n",
      "resetting env. episode 9115, reward total was -11.0. running mean: -10.447174536124866, timestamp: 2022-08-20 14:39:15.318815\n",
      "resetting env. episode 9116, reward total was -11.0. running mean: -10.452702790763617, timestamp: 2022-08-20 14:39:20.371873\n",
      "resetting env. episode 9117, reward total was 3.0. running mean: -10.318175762855981, timestamp: 2022-08-20 14:39:27.322474\n",
      "resetting env. episode 9118, reward total was -2.0. running mean: -10.23499400522742, timestamp: 2022-08-20 14:39:34.446556\n",
      "resetting env. episode 9119, reward total was -15.0. running mean: -10.282644065175147, timestamp: 2022-08-20 14:39:39.399614\n",
      "resetting env. episode 9120, reward total was -13.0. running mean: -10.309817624523395, timestamp: 2022-08-20 14:39:45.450687\n",
      "resetting env. episode 9121, reward total was -5.0. running mean: -10.256719448278162, timestamp: 2022-08-20 14:39:51.834763\n",
      "resetting env. episode 9122, reward total was -5.0. running mean: -10.20415225379538, timestamp: 2022-08-20 14:39:59.277845\n",
      "resetting env. episode 9123, reward total was -11.0. running mean: -10.212110731257425, timestamp: 2022-08-20 14:40:04.859910\n",
      "resetting env. episode 9124, reward total was -14.0. running mean: -10.24998962394485, timestamp: 2022-08-20 14:40:09.310963\n",
      "resetting env. episode 9125, reward total was -12.0. running mean: -10.267489727705401, timestamp: 2022-08-20 14:40:15.240029\n",
      "resetting env. episode 9126, reward total was -16.0. running mean: -10.324814830428346, timestamp: 2022-08-20 14:40:18.918073\n",
      "resetting env. episode 9127, reward total was -13.0. running mean: -10.351566682124064, timestamp: 2022-08-20 14:40:24.770138\n",
      "resetting env. episode 9128, reward total was -5.0. running mean: -10.298051015302823, timestamp: 2022-08-20 14:40:31.037213\n",
      "resetting env. episode 9129, reward total was -4.0. running mean: -10.235070505149794, timestamp: 2022-08-20 14:40:38.110295\n",
      "resetting env. episode 9130, reward total was -16.0. running mean: -10.292719800098297, timestamp: 2022-08-20 14:40:43.305356\n",
      "resetting env. episode 9131, reward total was -11.0. running mean: -10.299792602097313, timestamp: 2022-08-20 14:40:49.577426\n",
      "resetting env. episode 9132, reward total was -15.0. running mean: -10.346794676076339, timestamp: 2022-08-20 14:40:55.379496\n",
      "resetting env. episode 9133, reward total was -9.0. running mean: -10.333326729315575, timestamp: 2022-08-20 14:41:01.199563\n",
      "resetting env. episode 9134, reward total was -15.0. running mean: -10.37999346202242, timestamp: 2022-08-20 14:41:06.419622\n",
      "resetting env. episode 9135, reward total was -13.0. running mean: -10.406193527402197, timestamp: 2022-08-20 14:41:11.180679\n",
      "resetting env. episode 9136, reward total was -1.0. running mean: -10.312131592128175, timestamp: 2022-08-20 14:41:18.546766\n",
      "resetting env. episode 9137, reward total was -9.0. running mean: -10.299010276206893, timestamp: 2022-08-20 14:41:26.321855\n",
      "resetting env. episode 9138, reward total was -9.0. running mean: -10.286020173444824, timestamp: 2022-08-20 14:41:31.746916\n",
      "resetting env. episode 9139, reward total was -17.0. running mean: -10.353159971710376, timestamp: 2022-08-20 14:41:37.009980\n",
      "resetting env. episode 9140, reward total was -15.0. running mean: -10.399628371993272, timestamp: 2022-08-20 14:41:42.229039\n",
      "resetting env. episode 9141, reward total was -6.0. running mean: -10.355632088273339, timestamp: 2022-08-20 14:41:48.279114\n",
      "resetting env. episode 9142, reward total was -18.0. running mean: -10.432075767390605, timestamp: 2022-08-20 14:41:53.157690\n",
      "resetting env. episode 9143, reward total was -9.0. running mean: -10.4177550097167, timestamp: 2022-08-20 14:41:58.939753\n",
      "resetting env. episode 9144, reward total was -14.0. running mean: -10.453577459619533, timestamp: 2022-08-20 14:42:03.576810\n",
      "resetting env. episode 9145, reward total was -14.0. running mean: -10.489041685023338, timestamp: 2022-08-20 14:42:08.118859\n",
      "resetting env. episode 9146, reward total was -13.0. running mean: -10.514151268173105, timestamp: 2022-08-20 14:42:13.428922\n",
      "resetting env. episode 9147, reward total was -13.0. running mean: -10.539009755491374, timestamp: 2022-08-20 14:42:19.294990\n",
      "resetting env. episode 9148, reward total was -9.0. running mean: -10.523619657936461, timestamp: 2022-08-20 14:42:24.855052\n",
      "resetting env. episode 9149, reward total was -10.0. running mean: -10.518383461357097, timestamp: 2022-08-20 14:42:30.940123\n",
      "resetting env. episode 9150, reward total was -8.0. running mean: -10.493199626743525, timestamp: 2022-08-20 14:42:37.121717\n",
      "resetting env. episode 9151, reward total was -12.0. running mean: -10.50826763047609, timestamp: 2022-08-20 14:42:42.822782\n",
      "resetting env. episode 9152, reward total was -19.0. running mean: -10.593184954171328, timestamp: 2022-08-20 14:42:46.818828\n",
      "resetting env. episode 9153, reward total was -19.0. running mean: -10.677253104629614, timestamp: 2022-08-20 14:42:52.016889\n",
      "resetting env. episode 9154, reward total was -17.0. running mean: -10.740480573583318, timestamp: 2022-08-20 14:42:57.424952\n",
      "resetting env. episode 9155, reward total was -13.0. running mean: -10.763075767847486, timestamp: 2022-08-20 14:43:02.022003\n",
      "resetting env. episode 9156, reward total was -14.0. running mean: -10.795445010169011, timestamp: 2022-08-20 14:43:07.306069\n",
      "resetting env. episode 9157, reward total was -10.0. running mean: -10.78749056006732, timestamp: 2022-08-20 14:43:12.974129\n",
      "resetting env. episode 9158, reward total was -13.0. running mean: -10.809615654466649, timestamp: 2022-08-20 14:43:17.891186\n",
      "resetting env. episode 9159, reward total was -9.0. running mean: -10.791519497921982, timestamp: 2022-08-20 14:43:23.639255\n",
      "resetting env. episode 9160, reward total was -12.0. running mean: -10.80360430294276, timestamp: 2022-08-20 14:43:29.025363\n",
      "resetting env. episode 9161, reward total was -15.0. running mean: -10.845568259913334, timestamp: 2022-08-20 14:43:33.323414\n",
      "resetting env. episode 9162, reward total was -15.0. running mean: -10.8871125773142, timestamp: 2022-08-20 14:43:38.631474\n",
      "resetting env. episode 9163, reward total was -11.0. running mean: -10.888241451541058, timestamp: 2022-08-20 14:43:44.179536\n",
      "resetting env. episode 9164, reward total was -14.0. running mean: -10.919359037025648, timestamp: 2022-08-20 14:43:49.106595\n",
      "resetting env. episode 9165, reward total was -9.0. running mean: -10.900165446655391, timestamp: 2022-08-20 14:43:56.721686\n",
      "resetting env. episode 9166, reward total was -3.0. running mean: -10.821163792188836, timestamp: 2022-08-20 14:44:04.499774\n",
      "resetting env. episode 9167, reward total was -10.0. running mean: -10.812952154266947, timestamp: 2022-08-20 14:44:10.732847\n",
      "resetting env. episode 9168, reward total was -7.0. running mean: -10.774822632724277, timestamp: 2022-08-20 14:44:17.449924\n",
      "resetting env. episode 9169, reward total was -12.0. running mean: -10.787074406397034, timestamp: 2022-08-20 14:44:22.183972\n",
      "resetting env. episode 9170, reward total was -15.0. running mean: -10.829203662333065, timestamp: 2022-08-20 14:44:27.450036\n",
      "resetting env. episode 9171, reward total was -9.0. running mean: -10.810911625709734, timestamp: 2022-08-20 14:44:34.583116\n",
      "resetting env. episode 9172, reward total was -7.0. running mean: -10.772802509452637, timestamp: 2022-08-20 14:44:41.387200\n",
      "resetting env. episode 9173, reward total was -13.0. running mean: -10.79507448435811, timestamp: 2022-08-20 14:44:47.202261\n",
      "resetting env. episode 9174, reward total was -10.0. running mean: -10.787123739514529, timestamp: 2022-08-20 14:44:54.098350\n",
      "resetting env. episode 9175, reward total was -12.0. running mean: -10.799252502119383, timestamp: 2022-08-20 14:45:01.379431\n",
      "resetting env. episode 9176, reward total was -16.0. running mean: -10.85125997709819, timestamp: 2022-08-20 14:45:07.501497\n",
      "resetting env. episode 9177, reward total was -13.0. running mean: -10.872747377327208, timestamp: 2022-08-20 14:45:12.326554\n",
      "resetting env. episode 9178, reward total was -14.0. running mean: -10.904019903553937, timestamp: 2022-08-20 14:45:17.027605\n",
      "resetting env. episode 9179, reward total was -14.0. running mean: -10.934979704518398, timestamp: 2022-08-20 14:45:22.816721\n",
      "resetting env. episode 9180, reward total was -9.0. running mean: -10.915629907473214, timestamp: 2022-08-20 14:45:29.269797\n",
      "resetting env. episode 9181, reward total was -11.0. running mean: -10.916473608398482, timestamp: 2022-08-20 14:45:34.801862\n",
      "resetting env. episode 9182, reward total was -10.0. running mean: -10.907308872314497, timestamp: 2022-08-20 14:45:40.843930\n",
      "resetting env. episode 9183, reward total was -13.0. running mean: -10.928235783591353, timestamp: 2022-08-20 14:45:46.120992\n",
      "resetting env. episode 9184, reward total was -15.0. running mean: -10.968953425755439, timestamp: 2022-08-20 14:45:50.567042\n",
      "resetting env. episode 9185, reward total was -7.0. running mean: -10.929263891497884, timestamp: 2022-08-20 14:45:56.460106\n",
      "resetting env. episode 9186, reward total was -12.0. running mean: -10.939971252582904, timestamp: 2022-08-20 14:46:00.842158\n",
      "resetting env. episode 9187, reward total was 1.0. running mean: -10.820571540057076, timestamp: 2022-08-20 14:46:08.545249\n",
      "resetting env. episode 9188, reward total was -7.0. running mean: -10.782365824656505, timestamp: 2022-08-20 14:46:15.110325\n",
      "resetting env. episode 9189, reward total was -5.0. running mean: -10.724542166409941, timestamp: 2022-08-20 14:46:21.797403\n",
      "resetting env. episode 9190, reward total was -7.0. running mean: -10.687296744745842, timestamp: 2022-08-20 14:46:28.093471\n",
      "resetting env. episode 9191, reward total was -8.0. running mean: -10.660423777298384, timestamp: 2022-08-20 14:46:34.875549\n",
      "resetting env. episode 9192, reward total was -19.0. running mean: -10.743819539525399, timestamp: 2022-08-20 14:46:39.644604\n",
      "resetting env. episode 9193, reward total was -16.0. running mean: -10.796381344130145, timestamp: 2022-08-20 14:46:44.576660\n",
      "resetting env. episode 9194, reward total was -12.0. running mean: -10.808417530688843, timestamp: 2022-08-20 14:46:49.531722\n",
      "resetting env. episode 9195, reward total was -1.0. running mean: -10.710333355381954, timestamp: 2022-08-20 14:46:57.751339\n",
      "resetting env. episode 9196, reward total was -8.0. running mean: -10.683230021828134, timestamp: 2022-08-20 14:47:04.190412\n",
      "resetting env. episode 9197, reward total was -10.0. running mean: -10.676397721609852, timestamp: 2022-08-20 14:47:11.185492\n",
      "resetting env. episode 9198, reward total was -13.0. running mean: -10.699633744393754, timestamp: 2022-08-20 14:47:15.929548\n",
      "resetting env. episode 9199, reward total was -8.0. running mean: -10.672637406949816, timestamp: 2022-08-20 14:47:21.541615\n",
      "resetting env. episode 9200, reward total was -16.0. running mean: -10.725911032880317, timestamp: 2022-08-20 14:47:26.066664\n",
      "resetting env. episode 9201, reward total was -11.0. running mean: -10.728651922551514, timestamp: 2022-08-20 14:47:32.342735\n",
      "resetting env. episode 9202, reward total was -14.0. running mean: -10.761365403326, timestamp: 2022-08-20 14:47:37.546802\n",
      "resetting env. episode 9203, reward total was -14.0. running mean: -10.79375174929274, timestamp: 2022-08-20 14:47:43.027862\n",
      "resetting env. episode 9204, reward total was -17.0. running mean: -10.855814231799812, timestamp: 2022-08-20 14:47:47.714490\n",
      "resetting env. episode 9205, reward total was -6.0. running mean: -10.807256089481815, timestamp: 2022-08-20 14:47:54.621569\n",
      "resetting env. episode 9206, reward total was -13.0. running mean: -10.829183528586997, timestamp: 2022-08-20 14:48:00.061633\n",
      "resetting env. episode 9207, reward total was -15.0. running mean: -10.870891693301127, timestamp: 2022-08-20 14:48:04.644729\n",
      "resetting env. episode 9208, reward total was -15.0. running mean: -10.912182776368116, timestamp: 2022-08-20 14:48:08.825779\n",
      "resetting env. episode 9209, reward total was -13.0. running mean: -10.933060948604435, timestamp: 2022-08-20 14:48:14.751846\n",
      "resetting env. episode 9210, reward total was -19.0. running mean: -11.013730339118391, timestamp: 2022-08-20 14:48:19.249900\n",
      "resetting env. episode 9211, reward total was -12.0. running mean: -11.023593035727206, timestamp: 2022-08-20 14:48:24.655483\n",
      "resetting env. episode 9212, reward total was -14.0. running mean: -11.053357105369935, timestamp: 2022-08-20 14:48:29.354537\n",
      "resetting env. episode 9213, reward total was -17.0. running mean: -11.112823534316236, timestamp: 2022-08-20 14:48:34.047588\n",
      "resetting env. episode 9214, reward total was -9.0. running mean: -11.091695298973073, timestamp: 2022-08-20 14:48:39.571654\n",
      "resetting env. episode 9215, reward total was -7.0. running mean: -11.050778345983343, timestamp: 2022-08-20 14:48:47.321740\n",
      "resetting env. episode 9216, reward total was -7.0. running mean: -11.010270562523509, timestamp: 2022-08-20 14:48:53.747330\n",
      "resetting env. episode 9217, reward total was -13.0. running mean: -11.030167856898274, timestamp: 2022-08-20 14:48:59.518400\n",
      "resetting env. episode 9218, reward total was -10.0. running mean: -11.019866178329291, timestamp: 2022-08-20 14:49:06.669482\n",
      "resetting env. episode 9219, reward total was -10.0. running mean: -11.009667516545997, timestamp: 2022-08-20 14:49:14.402092\n",
      "resetting env. episode 9220, reward total was -15.0. running mean: -11.049570841380538, timestamp: 2022-08-20 14:49:20.172158\n",
      "resetting env. episode 9221, reward total was -10.0. running mean: -11.039075132966731, timestamp: 2022-08-20 14:49:27.935246\n",
      "resetting env. episode 9222, reward total was -1.0. running mean: -10.938684381637064, timestamp: 2022-08-20 14:49:35.311330\n",
      "resetting env. episode 9223, reward total was -1.0. running mean: -10.839297537820693, timestamp: 2022-08-20 14:49:42.688415\n",
      "resetting env. episode 9224, reward total was -8.0. running mean: -10.810904562442486, timestamp: 2022-08-20 14:49:48.983488\n",
      "resetting env. episode 9225, reward total was -15.0. running mean: -10.85279551681806, timestamp: 2022-08-20 14:49:54.387547\n",
      "resetting env. episode 9226, reward total was 3.0. running mean: -10.71426756164988, timestamp: 2022-08-20 14:50:00.648144\n",
      "resetting env. episode 9227, reward total was -19.0. running mean: -10.79712488603338, timestamp: 2022-08-20 14:50:04.533184\n",
      "resetting env. episode 9228, reward total was -6.0. running mean: -10.749153637173047, timestamp: 2022-08-20 14:50:11.444306\n",
      "resetting env. episode 9229, reward total was -15.0. running mean: -10.791662100801316, timestamp: 2022-08-20 14:50:16.982368\n",
      "resetting env. episode 9230, reward total was -5.0. running mean: -10.733745479793305, timestamp: 2022-08-20 14:50:24.347452\n",
      "resetting env. episode 9231, reward total was -7.0. running mean: -10.696408024995371, timestamp: 2022-08-20 14:50:32.347065\n",
      "resetting env. episode 9232, reward total was -16.0. running mean: -10.749443944745417, timestamp: 2022-08-20 14:50:36.917118\n",
      "resetting env. episode 9233, reward total was -9.0. running mean: -10.731949505297964, timestamp: 2022-08-20 14:50:43.433193\n",
      "resetting env. episode 9234, reward total was -3.0. running mean: -10.654630010244983, timestamp: 2022-08-20 14:50:50.637273\n",
      "resetting env. episode 9235, reward total was -8.0. running mean: -10.628083710142533, timestamp: 2022-08-20 14:50:58.238359\n",
      "resetting env. episode 9236, reward total was -8.0. running mean: -10.601802873041109, timestamp: 2022-08-20 14:51:05.146439\n",
      "resetting env. episode 9237, reward total was -10.0. running mean: -10.595784844310698, timestamp: 2022-08-20 14:51:11.770516\n",
      "resetting env. episode 9238, reward total was -13.0. running mean: -10.61982699586759, timestamp: 2022-08-20 14:51:17.978586\n",
      "resetting env. episode 9239, reward total was -10.0. running mean: -10.613628725908914, timestamp: 2022-08-20 14:51:23.330646\n",
      "resetting env. episode 9240, reward total was 4.0. running mean: -10.467492438649826, timestamp: 2022-08-20 14:51:30.740731\n",
      "resetting env. episode 9241, reward total was -14.0. running mean: -10.502817514263327, timestamp: 2022-08-20 14:51:36.133791\n",
      "resetting env. episode 9242, reward total was -9.0. running mean: -10.487789339120694, timestamp: 2022-08-20 14:51:43.252927\n",
      "resetting env. episode 9243, reward total was -19.0. running mean: -10.572911445729487, timestamp: 2022-08-20 14:51:48.216982\n",
      "resetting env. episode 9244, reward total was -7.0. running mean: -10.537182331272192, timestamp: 2022-08-20 14:51:53.806565\n",
      "resetting env. episode 9245, reward total was -15.0. running mean: -10.581810507959469, timestamp: 2022-08-20 14:51:59.591153\n",
      "resetting env. episode 9246, reward total was -13.0. running mean: -10.605992402879876, timestamp: 2022-08-20 14:52:05.770224\n",
      "resetting env. episode 9247, reward total was -17.0. running mean: -10.669932478851077, timestamp: 2022-08-20 14:52:09.977793\n",
      "resetting env. episode 9248, reward total was -14.0. running mean: -10.703233154062566, timestamp: 2022-08-20 14:52:15.279852\n",
      "resetting env. episode 9249, reward total was -14.0. running mean: -10.73620082252194, timestamp: 2022-08-20 14:52:20.956916\n",
      "resetting env. episode 9250, reward total was -11.0. running mean: -10.73883881429672, timestamp: 2022-08-20 14:52:26.205977\n",
      "resetting env. episode 9251, reward total was -1.0. running mean: -10.641450426153753, timestamp: 2022-08-20 14:52:33.875066\n",
      "resetting env. episode 9252, reward total was -11.0. running mean: -10.645035921892214, timestamp: 2022-08-20 14:52:39.456133\n",
      "resetting env. episode 9253, reward total was -12.0. running mean: -10.658585562673291, timestamp: 2022-08-20 14:52:45.274717\n",
      "resetting env. episode 9254, reward total was -7.0. running mean: -10.621999707046559, timestamp: 2022-08-20 14:52:51.705792\n",
      "resetting env. episode 9255, reward total was -5.0. running mean: -10.565779709976093, timestamp: 2022-08-20 14:52:58.631918\n",
      "resetting env. episode 9256, reward total was -13.0. running mean: -10.590121912876333, timestamp: 2022-08-20 14:53:05.597522\n",
      "resetting env. episode 9257, reward total was -8.0. running mean: -10.564220693747568, timestamp: 2022-08-20 14:53:12.413599\n",
      "resetting env. episode 9258, reward total was -12.0. running mean: -10.578578486810091, timestamp: 2022-08-20 14:53:18.831674\n",
      "resetting env. episode 9259, reward total was -7.0. running mean: -10.542792701941991, timestamp: 2022-08-20 14:53:25.518749\n",
      "resetting env. episode 9260, reward total was -7.0. running mean: -10.507364774922571, timestamp: 2022-08-20 14:53:31.756821\n",
      "resetting env. episode 9261, reward total was -13.0. running mean: -10.532291127173346, timestamp: 2022-08-20 14:53:38.075894\n",
      "resetting env. episode 9262, reward total was -16.0. running mean: -10.586968215901614, timestamp: 2022-08-20 14:53:42.584520\n",
      "resetting env. episode 9263, reward total was -13.0. running mean: -10.611098533742599, timestamp: 2022-08-20 14:53:48.732118\n",
      "resetting env. episode 9264, reward total was 4.0. running mean: -10.464987548405173, timestamp: 2022-08-20 14:53:55.658195\n",
      "resetting env. episode 9265, reward total was -10.0. running mean: -10.46033767292112, timestamp: 2022-08-20 14:54:01.475261\n",
      "resetting env. episode 9266, reward total was -15.0. running mean: -10.50573429619191, timestamp: 2022-08-20 14:54:05.935314\n",
      "resetting env. episode 9267, reward total was -7.0. running mean: -10.470676953229992, timestamp: 2022-08-20 14:54:12.363391\n",
      "resetting env. episode 9268, reward total was -11.0. running mean: -10.475970183697692, timestamp: 2022-08-20 14:54:17.408450\n",
      "resetting env. episode 9269, reward total was -10.0. running mean: -10.471210481860714, timestamp: 2022-08-20 14:54:23.417516\n",
      "resetting env. episode 9270, reward total was -18.0. running mean: -10.546498377042107, timestamp: 2022-08-20 14:54:27.459563\n",
      "resetting env. episode 9271, reward total was -12.0. running mean: -10.561033393271686, timestamp: 2022-08-20 14:54:32.492623\n",
      "resetting env. episode 9272, reward total was -4.0. running mean: -10.495423059338968, timestamp: 2022-08-20 14:54:39.594706\n",
      "resetting env. episode 9273, reward total was -13.0. running mean: -10.52046882874558, timestamp: 2022-08-20 14:54:45.406770\n",
      "resetting env. episode 9274, reward total was -14.0. running mean: -10.555264140458124, timestamp: 2022-08-20 14:54:50.260823\n",
      "resetting env. episode 9275, reward total was -10.0. running mean: -10.549711499053542, timestamp: 2022-08-20 14:54:55.263883\n",
      "resetting env. episode 9276, reward total was -16.0. running mean: -10.604214384063006, timestamp: 2022-08-20 14:54:59.938936\n",
      "resetting env. episode 9277, reward total was -6.0. running mean: -10.558172240222376, timestamp: 2022-08-20 14:55:07.660070\n",
      "resetting env. episode 9278, reward total was -15.0. running mean: -10.602590517820152, timestamp: 2022-08-20 14:55:12.940131\n",
      "resetting env. episode 9279, reward total was -10.0. running mean: -10.59656461264195, timestamp: 2022-08-20 14:55:18.444713\n",
      "resetting env. episode 9280, reward total was -10.0. running mean: -10.59059896651553, timestamp: 2022-08-20 14:55:23.545772\n",
      "resetting env. episode 9281, reward total was -13.0. running mean: -10.614692976850376, timestamp: 2022-08-20 14:55:29.111836\n",
      "resetting env. episode 9282, reward total was -13.0. running mean: -10.638546047081872, timestamp: 2022-08-20 14:55:36.163917\n",
      "resetting env. episode 9283, reward total was -10.0. running mean: -10.632160586611054, timestamp: 2022-08-20 14:55:41.796499\n",
      "resetting env. episode 9284, reward total was -14.0. running mean: -10.665838980744944, timestamp: 2022-08-20 14:55:47.221562\n",
      "resetting env. episode 9285, reward total was -8.0. running mean: -10.639180590937494, timestamp: 2022-08-20 14:55:52.534624\n",
      "resetting env. episode 9286, reward total was -12.0. running mean: -10.652788785028118, timestamp: 2022-08-20 14:55:58.301217\n",
      "resetting env. episode 9287, reward total was -14.0. running mean: -10.686260897177837, timestamp: 2022-08-20 14:56:04.390288\n",
      "resetting env. episode 9288, reward total was -13.0. running mean: -10.709398288206058, timestamp: 2022-08-20 14:56:08.913338\n",
      "resetting env. episode 9289, reward total was -6.0. running mean: -10.662304305323998, timestamp: 2022-08-20 14:56:15.986421\n",
      "resetting env. episode 9290, reward total was -14.0. running mean: -10.695681262270758, timestamp: 2022-08-20 14:56:20.944477\n",
      "resetting env. episode 9291, reward total was -9.0. running mean: -10.678724449648051, timestamp: 2022-08-20 14:56:27.559555\n",
      "resetting env. episode 9292, reward total was -9.0. running mean: -10.66193720515157, timestamp: 2022-08-20 14:56:33.242622\n",
      "resetting env. episode 9293, reward total was -19.0. running mean: -10.745317833100055, timestamp: 2022-08-20 14:56:37.162193\n",
      "resetting env. episode 9294, reward total was -6.0. running mean: -10.697864654769054, timestamp: 2022-08-20 14:56:44.406269\n",
      "resetting env. episode 9295, reward total was -10.0. running mean: -10.690886008221364, timestamp: 2022-08-20 14:56:50.374343\n",
      "resetting env. episode 9296, reward total was -13.0. running mean: -10.71397714813915, timestamp: 2022-08-20 14:56:56.118407\n",
      "resetting env. episode 9297, reward total was -16.0. running mean: -10.76683737665776, timestamp: 2022-08-20 14:57:00.311455\n",
      "resetting env. episode 9298, reward total was -13.0. running mean: -10.789169002891184, timestamp: 2022-08-20 14:57:05.115512\n",
      "resetting env. episode 9299, reward total was -16.0. running mean: -10.841277312862271, timestamp: 2022-08-20 14:57:10.386578\n",
      "resetting env. episode 9300, reward total was -9.0. running mean: -10.822864539733649, timestamp: 2022-08-20 14:57:15.980640\n",
      "resetting env. episode 9301, reward total was -17.0. running mean: -10.884635894336313, timestamp: 2022-08-20 14:57:20.499689\n",
      "resetting env. episode 9302, reward total was -16.0. running mean: -10.93578953539295, timestamp: 2022-08-20 14:57:25.212749\n",
      "resetting env. episode 9303, reward total was -12.0. running mean: -10.94643164003902, timestamp: 2022-08-20 14:57:30.155801\n",
      "resetting env. episode 9304, reward total was -14.0. running mean: -10.97696732363863, timestamp: 2022-08-20 14:57:34.980858\n",
      "resetting env. episode 9305, reward total was -12.0. running mean: -10.987197650402244, timestamp: 2022-08-20 14:57:40.309920\n",
      "resetting env. episode 9306, reward total was -9.0. running mean: -10.967325673898221, timestamp: 2022-08-20 14:57:47.074999\n",
      "resetting env. episode 9307, reward total was -6.0. running mean: -10.917652417159239, timestamp: 2022-08-20 14:57:53.400077\n",
      "resetting env. episode 9308, reward total was -15.0. running mean: -10.958475892987646, timestamp: 2022-08-20 14:57:59.110138\n",
      "resetting env. episode 9309, reward total was -15.0. running mean: -10.99889113405777, timestamp: 2022-08-20 14:58:05.516214\n",
      "resetting env. episode 9310, reward total was -7.0. running mean: -10.958902222717192, timestamp: 2022-08-20 14:58:11.464282\n",
      "resetting env. episode 9311, reward total was -13.0. running mean: -10.97931320049002, timestamp: 2022-08-20 14:58:16.866344\n",
      "resetting env. episode 9312, reward total was -4.0. running mean: -10.909520068485119, timestamp: 2022-08-20 14:58:24.033427\n",
      "resetting env. episode 9313, reward total was -11.0. running mean: -10.910424867800266, timestamp: 2022-08-20 14:58:29.970497\n",
      "resetting env. episode 9314, reward total was -18.0. running mean: -10.981320619122263, timestamp: 2022-08-20 14:58:34.751551\n",
      "resetting env. episode 9315, reward total was -12.0. running mean: -10.991507412931039, timestamp: 2022-08-20 14:58:40.166615\n",
      "resetting env. episode 9316, reward total was -7.0. running mean: -10.95159233880173, timestamp: 2022-08-20 14:58:47.250701\n",
      "resetting env. episode 9317, reward total was -11.0. running mean: -10.952076415413712, timestamp: 2022-08-20 14:58:53.422769\n",
      "resetting env. episode 9318, reward total was -14.0. running mean: -10.982555651259576, timestamp: 2022-08-20 14:58:59.637842\n",
      "resetting env. episode 9319, reward total was -1.0. running mean: -10.882730094746979, timestamp: 2022-08-20 14:59:07.525936\n",
      "resetting env. episode 9320, reward total was -15.0. running mean: -10.92390279379951, timestamp: 2022-08-20 14:59:12.235987\n",
      "resetting env. episode 9321, reward total was -4.0. running mean: -10.854663765861513, timestamp: 2022-08-20 14:59:19.913078\n",
      "resetting env. episode 9322, reward total was -15.0. running mean: -10.8961171282029, timestamp: 2022-08-20 14:59:24.976137\n",
      "resetting env. episode 9323, reward total was -10.0. running mean: -10.88715595692087, timestamp: 2022-08-20 14:59:30.770728\n",
      "resetting env. episode 9324, reward total was -13.0. running mean: -10.908284397351661, timestamp: 2022-08-20 14:59:36.384800\n",
      "resetting env. episode 9325, reward total was -7.0. running mean: -10.869201553378145, timestamp: 2022-08-20 14:59:42.310864\n",
      "resetting env. episode 9326, reward total was -8.0. running mean: -10.840509537844364, timestamp: 2022-08-20 14:59:48.970941\n",
      "resetting env. episode 9327, reward total was -15.0. running mean: -10.88210444246592, timestamp: 2022-08-20 14:59:53.652524\n",
      "resetting env. episode 9328, reward total was -16.0. running mean: -10.933283398041262, timestamp: 2022-08-20 14:59:59.365590\n",
      "resetting env. episode 9329, reward total was -11.0. running mean: -10.933950564060849, timestamp: 2022-08-20 15:00:04.454692\n",
      "resetting env. episode 9330, reward total was -15.0. running mean: -10.97461105842024, timestamp: 2022-08-20 15:00:08.521739\n",
      "resetting env. episode 9331, reward total was -11.0. running mean: -10.974864947836037, timestamp: 2022-08-20 15:00:14.420811\n",
      "resetting env. episode 9332, reward total was -18.0. running mean: -11.045116298357676, timestamp: 2022-08-20 15:00:18.290854\n",
      "resetting env. episode 9333, reward total was -12.0. running mean: -11.0546651353741, timestamp: 2022-08-20 15:00:23.209909\n",
      "resetting env. episode 9334, reward total was -16.0. running mean: -11.104118484020358, timestamp: 2022-08-20 15:00:26.924953\n",
      "resetting env. episode 9335, reward total was -16.0. running mean: -11.153077299180154, timestamp: 2022-08-20 15:00:30.853521\n",
      "resetting env. episode 9336, reward total was -18.0. running mean: -11.221546526188352, timestamp: 2022-08-20 15:00:34.855565\n",
      "resetting env. episode 9337, reward total was -13.0. running mean: -11.23933106092647, timestamp: 2022-08-20 15:00:39.780624\n",
      "resetting env. episode 9338, reward total was -18.0. running mean: -11.306937750317203, timestamp: 2022-08-20 15:00:44.460679\n",
      "resetting env. episode 9339, reward total was -7.0. running mean: -11.263868372814033, timestamp: 2022-08-20 15:00:51.103756\n",
      "resetting env. episode 9340, reward total was -16.0. running mean: -11.311229689085891, timestamp: 2022-08-20 15:00:55.998810\n",
      "resetting env. episode 9341, reward total was -7.0. running mean: -11.268117392195032, timestamp: 2022-08-20 15:01:02.929893\n",
      "resetting env. episode 9342, reward total was -16.0. running mean: -11.315436218273081, timestamp: 2022-08-20 15:01:07.847472\n",
      "resetting env. episode 9343, reward total was -11.0. running mean: -11.31228185609035, timestamp: 2022-08-20 15:01:12.962532\n",
      "resetting env. episode 9344, reward total was -11.0. running mean: -11.309159037529446, timestamp: 2022-08-20 15:01:18.415648\n",
      "resetting env. episode 9345, reward total was -17.0. running mean: -11.366067447154151, timestamp: 2022-08-20 15:01:23.336704\n",
      "resetting env. episode 9346, reward total was -11.0. running mean: -11.36240677268261, timestamp: 2022-08-20 15:01:29.778778\n",
      "resetting env. episode 9347, reward total was -3.0. running mean: -11.278782704955782, timestamp: 2022-08-20 15:01:37.692868\n",
      "resetting env. episode 9348, reward total was -8.0. running mean: -11.245994877906224, timestamp: 2022-08-20 15:01:44.152944\n",
      "resetting env. episode 9349, reward total was -10.0. running mean: -11.233534929127162, timestamp: 2022-08-20 15:01:51.725029\n",
      "resetting env. episode 9350, reward total was -7.0. running mean: -11.19119957983589, timestamp: 2022-08-20 15:01:57.967101\n",
      "resetting env. episode 9351, reward total was -7.0. running mean: -11.149287584037532, timestamp: 2022-08-20 15:02:04.814180\n",
      "resetting env. episode 9352, reward total was -14.0. running mean: -11.177794708197158, timestamp: 2022-08-20 15:02:10.735249\n",
      "resetting env. episode 9353, reward total was -11.0. running mean: -11.176016761115186, timestamp: 2022-08-20 15:02:16.407315\n",
      "resetting env. episode 9354, reward total was -9.0. running mean: -11.154256593504034, timestamp: 2022-08-20 15:02:23.647394\n",
      "resetting env. episode 9355, reward total was -17.0. running mean: -11.212714027568992, timestamp: 2022-08-20 15:02:27.730448\n",
      "resetting env. episode 9356, reward total was -18.0. running mean: -11.280586887293302, timestamp: 2022-08-20 15:02:32.105494\n",
      "resetting env. episode 9357, reward total was -11.0. running mean: -11.277781018420368, timestamp: 2022-08-20 15:02:37.140075\n",
      "resetting env. episode 9358, reward total was -10.0. running mean: -11.265003208236164, timestamp: 2022-08-20 15:02:42.513143\n",
      "resetting env. episode 9359, reward total was -15.0. running mean: -11.302353176153803, timestamp: 2022-08-20 15:02:47.447193\n",
      "resetting env. episode 9360, reward total was 2.0. running mean: -11.169329644392265, timestamp: 2022-08-20 15:02:54.209269\n",
      "resetting env. episode 9361, reward total was -4.0. running mean: -11.097636347948342, timestamp: 2022-08-20 15:03:01.257350\n",
      "resetting env. episode 9362, reward total was -11.0. running mean: -11.096659984468857, timestamp: 2022-08-20 15:03:07.449422\n",
      "resetting env. episode 9363, reward total was -4.0. running mean: -11.025693384624168, timestamp: 2022-08-20 15:03:15.003512\n",
      "resetting env. episode 9364, reward total was -19.0. running mean: -11.105436450777926, timestamp: 2022-08-20 15:03:19.702563\n",
      "resetting env. episode 9365, reward total was -16.0. running mean: -11.154382086270147, timestamp: 2022-08-20 15:03:25.074957\n",
      "resetting env. episode 9366, reward total was -19.0. running mean: -11.232838265407445, timestamp: 2022-08-20 15:03:29.146524\n",
      "resetting env. episode 9367, reward total was -11.0. running mean: -11.230509882753369, timestamp: 2022-08-20 15:03:35.335595\n",
      "resetting env. episode 9368, reward total was -17.0. running mean: -11.288204783925835, timestamp: 2022-08-20 15:03:40.514653\n",
      "resetting env. episode 9369, reward total was -14.0. running mean: -11.315322736086577, timestamp: 2022-08-20 15:03:45.167243\n",
      "resetting env. episode 9370, reward total was -12.0. running mean: -11.32216950872571, timestamp: 2022-08-20 15:03:51.179313\n",
      "resetting env. episode 9371, reward total was -7.0. running mean: -11.278947813638453, timestamp: 2022-08-20 15:03:58.647444\n",
      "resetting env. episode 9372, reward total was -6.0. running mean: -11.226158335502069, timestamp: 2022-08-20 15:04:05.392521\n",
      "resetting env. episode 9373, reward total was -15.0. running mean: -11.263896752147048, timestamp: 2022-08-20 15:04:10.440579\n",
      "resetting env. episode 9374, reward total was -14.0. running mean: -11.291257784625577, timestamp: 2022-08-20 15:04:15.229634\n",
      "resetting env. episode 9375, reward total was -9.0. running mean: -11.26834520677932, timestamp: 2022-08-20 15:04:22.289717\n",
      "resetting env. episode 9376, reward total was -13.0. running mean: -11.285661754711528, timestamp: 2022-08-20 15:04:27.589776\n",
      "resetting env. episode 9377, reward total was -13.0. running mean: -11.302805137164414, timestamp: 2022-08-20 15:04:33.426844\n",
      "resetting env. episode 9378, reward total was -17.0. running mean: -11.35977708579277, timestamp: 2022-08-20 15:04:37.515889\n",
      "resetting env. episode 9379, reward total was -17.0. running mean: -11.416179314934842, timestamp: 2022-08-20 15:04:41.106932\n",
      "resetting env. episode 9380, reward total was -18.0. running mean: -11.482017521785494, timestamp: 2022-08-20 15:04:44.878976\n",
      "resetting env. episode 9381, reward total was -7.0. running mean: -11.43719734656764, timestamp: 2022-08-20 15:04:52.477589\n",
      "resetting env. episode 9382, reward total was -7.0. running mean: -11.392825373101964, timestamp: 2022-08-20 15:05:01.192690\n",
      "resetting env. episode 9383, reward total was -13.0. running mean: -11.408897119370945, timestamp: 2022-08-20 15:05:07.498764\n",
      "resetting env. episode 9384, reward total was -12.0. running mean: -11.414808148177235, timestamp: 2022-08-20 15:05:13.404356\n",
      "resetting env. episode 9385, reward total was -15.0. running mean: -11.450660066695463, timestamp: 2022-08-20 15:05:17.937410\n",
      "resetting env. episode 9386, reward total was -14.0. running mean: -11.476153466028508, timestamp: 2022-08-20 15:05:23.563470\n",
      "resetting env. episode 9387, reward total was -9.0. running mean: -11.451391931368223, timestamp: 2022-08-20 15:05:29.762546\n",
      "resetting env. episode 9388, reward total was -17.0. running mean: -11.50687801205454, timestamp: 2022-08-20 15:05:34.521597\n",
      "resetting env. episode 9389, reward total was -11.0. running mean: -11.501809231933995, timestamp: 2022-08-20 15:05:41.080673\n",
      "resetting env. episode 9390, reward total was -13.0. running mean: -11.516791139614655, timestamp: 2022-08-20 15:05:47.772751\n",
      "resetting env. episode 9391, reward total was -8.0. running mean: -11.481623228218508, timestamp: 2022-08-20 15:05:54.658829\n",
      "resetting env. episode 9392, reward total was -3.0. running mean: -11.396806995936322, timestamp: 2022-08-20 15:06:03.459931\n",
      "resetting env. episode 9393, reward total was -10.0. running mean: -11.382838925976959, timestamp: 2022-08-20 15:06:09.440998\n",
      "resetting env. episode 9394, reward total was -11.0. running mean: -11.379010536717189, timestamp: 2022-08-20 15:06:16.351606\n",
      "resetting env. episode 9395, reward total was -16.0. running mean: -11.425220431350017, timestamp: 2022-08-20 15:06:20.918182\n",
      "resetting env. episode 9396, reward total was -13.0. running mean: -11.440968227036517, timestamp: 2022-08-20 15:06:26.162246\n",
      "resetting env. episode 9397, reward total was -15.0. running mean: -11.476558544766153, timestamp: 2022-08-20 15:06:32.691322\n",
      "resetting env. episode 9398, reward total was -10.0. running mean: -11.46179295931849, timestamp: 2022-08-20 15:06:38.606384\n",
      "resetting env. episode 9399, reward total was -12.0. running mean: -11.467175029725304, timestamp: 2022-08-20 15:06:44.389453\n",
      "resetting env. episode 9400, reward total was -8.0. running mean: -11.432503279428051, timestamp: 2022-08-20 15:06:50.568520\n",
      "resetting env. episode 9401, reward total was -15.0. running mean: -11.468178246633771, timestamp: 2022-08-20 15:06:56.385120\n",
      "resetting env. episode 9402, reward total was -5.0. running mean: -11.403496464167434, timestamp: 2022-08-20 15:07:03.738200\n",
      "resetting env. episode 9403, reward total was -18.0. running mean: -11.469461499525758, timestamp: 2022-08-20 15:07:08.799257\n",
      "resetting env. episode 9404, reward total was -10.0. running mean: -11.4547668845305, timestamp: 2022-08-20 15:07:14.999328\n",
      "resetting env. episode 9405, reward total was -10.0. running mean: -11.440219215685195, timestamp: 2022-08-20 15:07:21.016396\n",
      "resetting env. episode 9406, reward total was -15.0. running mean: -11.475817023528343, timestamp: 2022-08-20 15:07:25.226442\n",
      "resetting env. episode 9407, reward total was -16.0. running mean: -11.52105885329306, timestamp: 2022-08-20 15:07:30.336502\n",
      "resetting env. episode 9408, reward total was -11.0. running mean: -11.515848264760129, timestamp: 2022-08-20 15:07:36.385623\n",
      "resetting env. episode 9409, reward total was -8.0. running mean: -11.480689782112528, timestamp: 2022-08-20 15:07:44.322715\n",
      "resetting env. episode 9410, reward total was -14.0. running mean: -11.505882884291402, timestamp: 2022-08-20 15:07:49.481295\n",
      "resetting env. episode 9411, reward total was -11.0. running mean: -11.500824055448488, timestamp: 2022-08-20 15:07:54.839357\n",
      "resetting env. episode 9412, reward total was -7.0. running mean: -11.455815814894004, timestamp: 2022-08-20 15:08:00.722427\n",
      "resetting env. episode 9413, reward total was -14.0. running mean: -11.481257656745065, timestamp: 2022-08-20 15:08:06.661494\n",
      "resetting env. episode 9414, reward total was -15.0. running mean: -11.516445080177615, timestamp: 2022-08-20 15:08:12.183559\n",
      "resetting env. episode 9415, reward total was -3.0. running mean: -11.431280629375838, timestamp: 2022-08-20 15:08:18.830631\n",
      "resetting env. episode 9416, reward total was -14.0. running mean: -11.45696782308208, timestamp: 2022-08-20 15:08:24.785223\n",
      "resetting env. episode 9417, reward total was -11.0. running mean: -11.452398144851259, timestamp: 2022-08-20 15:08:30.419287\n",
      "resetting env. episode 9418, reward total was -19.0. running mean: -11.527874163402746, timestamp: 2022-08-20 15:08:34.431332\n",
      "resetting env. episode 9419, reward total was -13.0. running mean: -11.54259542176872, timestamp: 2022-08-20 15:08:39.579393\n",
      "resetting env. episode 9420, reward total was -17.0. running mean: -11.597169467551032, timestamp: 2022-08-20 15:08:44.395447\n",
      "resetting env. episode 9421, reward total was 3.0. running mean: -11.451197772875522, timestamp: 2022-08-20 15:08:50.978521\n",
      "resetting env. episode 9422, reward total was -12.0. running mean: -11.456685795146766, timestamp: 2022-08-20 15:08:56.765589\n",
      "resetting env. episode 9423, reward total was -14.0. running mean: -11.482118937195299, timestamp: 2022-08-20 15:09:01.490644\n",
      "resetting env. episode 9424, reward total was -19.0. running mean: -11.557297747823345, timestamp: 2022-08-20 15:09:05.294685\n",
      "resetting env. episode 9425, reward total was -13.0. running mean: -11.571724770345112, timestamp: 2022-08-20 15:09:10.534267\n",
      "resetting env. episode 9426, reward total was -1.0. running mean: -11.466007522641661, timestamp: 2022-08-20 15:09:18.516359\n",
      "resetting env. episode 9427, reward total was -15.0. running mean: -11.501347447415245, timestamp: 2022-08-20 15:09:23.515420\n",
      "resetting env. episode 9428, reward total was -12.0. running mean: -11.506333972941093, timestamp: 2022-08-20 15:09:29.196482\n",
      "resetting env. episode 9429, reward total was -14.0. running mean: -11.531270633211681, timestamp: 2022-08-20 15:09:34.583540\n",
      "resetting env. episode 9430, reward total was -8.0. running mean: -11.495957926879564, timestamp: 2022-08-20 15:09:40.688611\n",
      "resetting env. episode 9431, reward total was -13.0. running mean: -11.51099834761077, timestamp: 2022-08-20 15:09:46.060674\n",
      "resetting env. episode 9432, reward total was -14.0. running mean: -11.535888364134662, timestamp: 2022-08-20 15:09:51.158730\n",
      "resetting env. episode 9433, reward total was -17.0. running mean: -11.590529480493315, timestamp: 2022-08-20 15:09:54.984783\n",
      "resetting env. episode 9434, reward total was -12.0. running mean: -11.59462418568838, timestamp: 2022-08-20 15:10:01.406847\n",
      "resetting env. episode 9435, reward total was -14.0. running mean: -11.618677943831496, timestamp: 2022-08-20 15:10:06.798908\n",
      "resetting env. episode 9436, reward total was -19.0. running mean: -11.69249116439318, timestamp: 2022-08-20 15:10:11.534961\n",
      "resetting env. episode 9437, reward total was -11.0. running mean: -11.685566252749249, timestamp: 2022-08-20 15:10:18.374043\n",
      "resetting env. episode 9438, reward total was -5.0. running mean: -11.618710590221756, timestamp: 2022-08-20 15:10:26.094130\n",
      "resetting env. episode 9439, reward total was -7.0. running mean: -11.57252348431954, timestamp: 2022-08-20 15:10:33.346213\n",
      "resetting env. episode 9440, reward total was -9.0. running mean: -11.546798249476344, timestamp: 2022-08-20 15:10:39.231808\n",
      "resetting env. episode 9441, reward total was -12.0. running mean: -11.55133026698158, timestamp: 2022-08-20 15:10:45.194396\n",
      "resetting env. episode 9442, reward total was -12.0. running mean: -11.555816964311763, timestamp: 2022-08-20 15:10:51.187465\n",
      "resetting env. episode 9443, reward total was -11.0. running mean: -11.550258794668645, timestamp: 2022-08-20 15:10:56.977532\n",
      "resetting env. episode 9444, reward total was -16.0. running mean: -11.594756206721959, timestamp: 2022-08-20 15:11:01.316585\n",
      "resetting env. episode 9445, reward total was -5.0. running mean: -11.52880864465474, timestamp: 2022-08-20 15:11:07.637665\n",
      "resetting env. episode 9446, reward total was -17.0. running mean: -11.583520558208193, timestamp: 2022-08-20 15:11:12.451711\n",
      "resetting env. episode 9447, reward total was -10.0. running mean: -11.56768535262611, timestamp: 2022-08-20 15:11:18.801303\n",
      "resetting env. episode 9448, reward total was -17.0. running mean: -11.622008499099849, timestamp: 2022-08-20 15:11:22.989351\n",
      "resetting env. episode 9449, reward total was -16.0. running mean: -11.66578841410885, timestamp: 2022-08-20 15:11:28.198416\n",
      "resetting env. episode 9450, reward total was -16.0. running mean: -11.70913052996776, timestamp: 2022-08-20 15:11:32.795465\n",
      "resetting env. episode 9451, reward total was -12.0. running mean: -11.712039224668082, timestamp: 2022-08-20 15:11:39.791599\n",
      "resetting env. episode 9452, reward total was -7.0. running mean: -11.664918832421401, timestamp: 2022-08-20 15:11:46.839679\n",
      "resetting env. episode 9453, reward total was -2.0. running mean: -11.568269644097187, timestamp: 2022-08-20 15:11:54.120286\n",
      "resetting env. episode 9454, reward total was -17.0. running mean: -11.622586947656215, timestamp: 2022-08-20 15:11:58.860341\n",
      "resetting env. episode 9455, reward total was -7.0. running mean: -11.576361078179653, timestamp: 2022-08-20 15:12:06.306427\n",
      "resetting env. episode 9456, reward total was -14.0. running mean: -11.600597467397858, timestamp: 2022-08-20 15:12:10.896480\n",
      "resetting env. episode 9457, reward total was -13.0. running mean: -11.61459149272388, timestamp: 2022-08-20 15:12:16.608554\n",
      "resetting env. episode 9458, reward total was -9.0. running mean: -11.58844557779664, timestamp: 2022-08-20 15:12:22.832144\n",
      "resetting env. episode 9459, reward total was -16.0. running mean: -11.632561122018675, timestamp: 2022-08-20 15:12:28.009202\n",
      "resetting env. episode 9460, reward total was -19.0. running mean: -11.706235510798487, timestamp: 2022-08-20 15:12:32.991262\n",
      "resetting env. episode 9461, reward total was -14.0. running mean: -11.729173155690503, timestamp: 2022-08-20 15:12:38.230845\n",
      "resetting env. episode 9462, reward total was -11.0. running mean: -11.721881424133597, timestamp: 2022-08-20 15:12:44.329912\n",
      "resetting env. episode 9463, reward total was -13.0. running mean: -11.734662609892261, timestamp: 2022-08-20 15:12:49.877976\n",
      "resetting env. episode 9464, reward total was -16.0. running mean: -11.777315983793338, timestamp: 2022-08-20 15:12:55.297039\n",
      "resetting env. episode 9465, reward total was -12.0. running mean: -11.779542823955405, timestamp: 2022-08-20 15:13:01.678113\n",
      "resetting env. episode 9466, reward total was -11.0. running mean: -11.771747395715849, timestamp: 2022-08-20 15:13:07.970187\n",
      "resetting env. episode 9467, reward total was -16.0. running mean: -11.81402992175869, timestamp: 2022-08-20 15:13:12.760242\n",
      "resetting env. episode 9468, reward total was -9.0. running mean: -11.785889622541104, timestamp: 2022-08-20 15:13:19.204316\n",
      "resetting env. episode 9469, reward total was -13.0. running mean: -11.798030726315694, timestamp: 2022-08-20 15:13:23.192887\n",
      "resetting env. episode 9470, reward total was -14.0. running mean: -11.820050419052539, timestamp: 2022-08-20 15:13:27.769938\n",
      "resetting env. episode 9471, reward total was -20.0. running mean: -11.901849914862012, timestamp: 2022-08-20 15:13:30.926496\n",
      "resetting env. episode 9472, reward total was -7.0. running mean: -11.852831415713393, timestamp: 2022-08-20 15:13:36.907613\n",
      "resetting env. episode 9473, reward total was -5.0. running mean: -11.78430310155626, timestamp: 2022-08-20 15:13:43.843689\n",
      "resetting env. episode 9474, reward total was -15.0. running mean: -11.816460070540698, timestamp: 2022-08-20 15:13:48.352742\n",
      "resetting env. episode 9475, reward total was -7.0. running mean: -11.76829546983529, timestamp: 2022-08-20 15:13:55.599826\n",
      "resetting env. episode 9476, reward total was -17.0. running mean: -11.820612515136938, timestamp: 2022-08-20 15:14:00.480895\n",
      "resetting env. episode 9477, reward total was -12.0. running mean: -11.822406389985568, timestamp: 2022-08-20 15:14:05.660945\n",
      "resetting env. episode 9478, reward total was -14.0. running mean: -11.844182326085713, timestamp: 2022-08-20 15:14:10.573001\n",
      "resetting env. episode 9479, reward total was -13.0. running mean: -11.855740502824856, timestamp: 2022-08-20 15:14:16.789077\n",
      "resetting env. episode 9480, reward total was -17.0. running mean: -11.907183097796608, timestamp: 2022-08-20 15:14:21.743128\n",
      "resetting env. episode 9481, reward total was -18.0. running mean: -11.968111266818642, timestamp: 2022-08-20 15:14:26.111182\n",
      "resetting env. episode 9482, reward total was -9.0. running mean: -11.938430154150456, timestamp: 2022-08-20 15:14:32.010784\n",
      "resetting env. episode 9483, reward total was -17.0. running mean: -11.989045852608951, timestamp: 2022-08-20 15:14:37.032876\n",
      "resetting env. episode 9484, reward total was -6.0. running mean: -11.929155394082862, timestamp: 2022-08-20 15:14:42.917945\n",
      "resetting env. episode 9485, reward total was -11.0. running mean: -11.919863840142034, timestamp: 2022-08-20 15:14:50.208036\n",
      "resetting env. episode 9486, reward total was -15.0. running mean: -11.950665201740614, timestamp: 2022-08-20 15:14:56.739106\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "file_name = 'hist1_H200_E10000_LR10E2_last_.csv'\n",
    "%time hist1,hist_2 = train_model(env, model, total_episodes=10000)\n",
    "print(f'End time: {datetime.now()}')\n",
    "np.savetxt(file_name, hist1, delimiter =\",\", fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "def plot_graph2(data):\n",
    "    for line in data:\n",
    "        xs.append(float(line[0]))\n",
    "        ys.append(float(line[1]))\n",
    "        ax1.clear()\n",
    "        \n",
    "    ax1.plot(xs, ys)\n",
    "    plt.pause(1)\n",
    "    plt.show()\n",
    "\n",
    "plot_graph2(hist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHYCDYwhlVLV",
    "outputId": "44023870-3ed0-46f5-84e7-df559e94ffc0"
   },
   "outputs": [],
   "source": [
    "#%time hist2 = train_model(env, model, total_episodes=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "8fheN9DRlWXQ",
    "outputId": "23490ad9-3ac8-4899-824b-44400caa8afd"
   },
   "outputs": [],
   "source": [
    "#play_game(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AxOcQhIsKow",
    "outputId": "68d93a54-196d-4d91-a6f6-731aa0de23c4"
   },
   "outputs": [],
   "source": [
    "#%time hist3 = train_model(env, model, total_episodes=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "w2NblmwDsL3y",
    "outputId": "f3dc32bf-ab84-418d-b830-407510690d12"
   },
   "outputs": [],
   "source": [
    "#play_game(env, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "H=200 le-4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea2d5fd90987848081bf8639bc2a6955965d1ac41956e8a19667342fc3d5a5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
