{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cWACPRL869I4"
   },
   "outputs": [],
   "source": [
    "# C0797202 JAY PANCHAL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: memory_profiler in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from memory_profiler) (5.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (1.23.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JSAnimation in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.36.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[accept-rom-license,atari] in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (2.1.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (1.23.2)\n",
      "Requirement already satisfied: ale-py~=0.7.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.7.5)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gym[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.28.1)\n",
      "Requirement already satisfied: click in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jaypanchal\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "UsageError: Line magic function `%%file` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install memory_profiler\n",
    "%load_ext memory_profiler\n",
    "%pip install gym\n",
    "%pip install JSAnimation\n",
    "%pip install matplotlib\n",
    "%pip install -U gym >= 0.21.0\n",
    "%pip install -U gym[atari,accept-rom-license]\n",
    "\n",
    "%%file training.py\n",
    "\n",
    "%%python -m memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wotUOa_e6edP"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "from matplotlib import animation\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "from JSAnimation.IPython_display import display_animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def display_frames_as_gif(frames):\n",
    "    \"\"\"\n",
    "    Displays a list of frames as a gif, with controls\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R66_INeZ9nYX"
   },
   "source": [
    "## Initiating Ping Pong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtT2GyK_6edc",
    "outputId": "6ef17a84-3563-4157-caf3-2c50438190ae"
   },
   "outputs": [],
   "source": [
    "# Importing gym library and creating environment\n",
    "import gym\n",
    "env = gym.make('Pong-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRE6WmXQJ1Z0",
    "outputId": "41a4b484-4f7e-4fd6-fc69-e626adec0523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "trwRXI-h6eeI",
    "outputId": "42368b9e-2477-41ef-fb42-30ced75282c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished without success, accumulated reward = -20.0\n"
     ]
    }
   ],
   "source": [
    "# Run a demo of the environment\n",
    "observation = env.reset()\n",
    "cumulated_reward = 0\n",
    "\n",
    "frames = []\n",
    "for t in range(1000):\n",
    "#     print(observation)\n",
    "    frames.append(env.render(mode = 'rgb_array'))\n",
    "    # very stupid agent, just makes a random action within the allowd action space\n",
    "    action = env.action_space.sample()\n",
    "#     print(\"Action: {}\".format(t+1))    \n",
    "    observation, reward, done, info = env.step(action)\n",
    "#     print(reward)\n",
    "    cumulated_reward += reward\n",
    "    if done:\n",
    "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
    "        break\n",
    "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3zZTecVWLLes"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): \n",
    "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
    "\n",
    "def prepro(I):\n",
    "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "  I = I[35:195] # crop\n",
    "  I = I[::2,::2,0] # downsample by factor of 2\n",
    "  I[I == 144] = 0 # erase background (background type 1)\n",
    "  I[I == 109] = 0 # erase background (background type 2)\n",
    "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "  return I.astype(np.float).ravel()\n",
    "\n",
    "def policy_forward(x):\n",
    "  h = np.dot(model['W1'], x)\n",
    "  h[h<0] = 0 # ReLU nonlinearity\n",
    "  logp = np.dot(model['W2'], h)\n",
    "  p = sigmoid(logp)\n",
    "  return p, h # return probability of taking action 2, and hidden state\n",
    "\n",
    "def model_step(model, observation, prev_x):\n",
    "  # preprocess the observation, set input to network to be difference image\n",
    "  cur_x = prepro(observation)\n",
    "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "  prev_x = cur_x\n",
    "  \n",
    "  # forward the policy network and sample an action from the returned probability\n",
    "  aprob, _ = policy_forward(x)\n",
    "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
    "  \n",
    "  return action, prev_x\n",
    "\n",
    "def play_game(env, model):\n",
    "  observation = env.reset()\n",
    "\n",
    "  frames = []\n",
    "  cumulated_reward = 0\n",
    "\n",
    "  prev_x = None # used in computing the difference frame\n",
    "\n",
    "  for t in range(1000):\n",
    "      frames.append(env.render(mode = 'rgb_array'))\n",
    "      action, prev_x = model_step(model, observation, prev_x)\n",
    "      observation, reward, done, info = env.step(action)\n",
    "      cumulated_reward += reward\n",
    "      if done:\n",
    "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
    "          break\n",
    "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
    "  display_frames_as_gif(frames)\n",
    "  env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gWvZQ7AQLQt"
   },
   "source": [
    "# Logic behind the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eqFm7hqcItWl"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Init the model\n",
    "\n",
    "# number of neurons\n",
    "H = 600 \n",
    "\n",
    "# input dimensionality: 80x80 grid\n",
    "D = 80 * 80 \n",
    "\n",
    "model = {}\n",
    "def update_neurons(neurons = 600):\n",
    "    H = neurons\n",
    "    \n",
    "    # \"Xavier\" initialization\n",
    "    \n",
    "    model['W1'] = np.random.randn(H,D) / np.sqrt(D)\n",
    "    model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
    "\n",
    "update_neurons(H)\n",
    "\n",
    "# import pickle\n",
    "#  model = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TwjiwKisQM19"
   },
   "outputs": [],
   "source": [
    "\n",
    "# hyperparameters\n",
    "batch_size = 10 # every how many episodes to do a param update?\n",
    "\n",
    "# learning_rate = 1e-4\n",
    "learning_rate = 1e-4\n",
    " \n",
    "# discount factor for reward\n",
    "gamma = 0.99 \n",
    "\n",
    "# decay factor for RMSProp leaky sum of grad^2\n",
    "decay_rate = 0.99 \n",
    "  \n",
    "# update buffers that add up gradients over a batch\n",
    "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } \n",
    "\n",
    "# rmsprop memory\n",
    "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } \n",
    "\n",
    "def discount_rewards(r):\n",
    "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
    "  running_add = 0\n",
    "  for t in reversed(range(0, r.size)):\n",
    "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
    "    running_add = running_add * gamma + r[t]\n",
    "    discounted_r[t] = running_add\n",
    "  return discounted_r\n",
    "\n",
    "def policy_backward(epx, eph, epdlogp):\n",
    "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
    "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
    "  dh = np.outer(epdlogp, model['W2'])\n",
    "  dh[eph <= 0] = 0 # backpro prelu\n",
    "  dW1 = np.dot(dh.T, epx)\n",
    "  return {'W1':dW1, 'W2':dW2}\n",
    "\n",
    "\n",
    "def train_model(env, model, total_episodes = 100):\n",
    "  hist = []\n",
    "  hist_2 = []\n",
    "  observation = env.reset()\n",
    "\n",
    "  prev_x = None # used in computing the difference frame\n",
    "  xs,hs,dlogps,drs = [],[],[],[]\n",
    "  running_reward = None\n",
    "  reward_sum = 0\n",
    "  episode_number = 0\n",
    "\n",
    "  from datetime import datetime\n",
    "\n",
    "  now = datetime.now()\n",
    "\n",
    "  print(f'Start time: {now}')\n",
    "\n",
    "  last_export_time = now\n",
    "\n",
    "  while True:\n",
    "    # preprocess the observation, set input to network to be difference image\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # forward the policy network and sample an action from the returned probability\n",
    "    aprob, h = policy_forward(x)\n",
    "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
    "\n",
    "    # record various intermediates (needed later for backprop)\n",
    "    xs.append(x) # observation\n",
    "    hs.append(h) # hidden state\n",
    "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
    "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
    "\n",
    "    # step the environment and get new measurements\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    reward_sum += reward\n",
    "\n",
    "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
    "\n",
    "    if done: # an episode finished\n",
    "      episode_number += 1\n",
    "\n",
    "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
    "      epx = np.vstack(xs)\n",
    "      eph = np.vstack(hs)\n",
    "      epdlogp = np.vstack(dlogps)\n",
    "      epr = np.vstack(drs)\n",
    "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
    "\n",
    "      # compute the discounted reward backwards through time\n",
    "      discounted_epr = discount_rewards(epr)\n",
    "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "      discounted_epr -= np.mean(discounted_epr)\n",
    "      discounted_epr /= np.std(discounted_epr)\n",
    "\n",
    "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
    "      grad = policy_backward(epx, eph, epdlogp)\n",
    "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
    "\n",
    "      # perform rmsprop parameter update every batch_size episodes\n",
    "      if episode_number % batch_size == 0:\n",
    "        for k,v in model.items():\n",
    "          g = grad_buffer[k] # gradient\n",
    "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
    "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
    "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
    "\n",
    "      # boring book-keeping\n",
    "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "      hist.append((episode_number, reward_sum, running_reward,datetime.now()))\n",
    "      hist_2.append((episode_number, running_reward))\n",
    "      \n",
    "      if ((datetime.now() - last_export_time).total_seconds() > 30):\n",
    "        file_name = 'hist1_'+ str(total_episodes) + '.csv'\n",
    "        np.savetxt(file_name, hist, delimiter =\",\", fmt ='% s')\n",
    "        last_export_time = datetime.now()\n",
    "        \n",
    "      print (f'resetting env. episode {episode_number}, reward total was {reward_sum}. running mean: {running_reward}, timestamp: {datetime.now()}')\n",
    "            \n",
    "      reward_sum = 0\n",
    "      observation = env.reset() # reset env\n",
    "      prev_x = None\n",
    "      if episode_number == total_episodes:\n",
    "        return hist, hist_2\n",
    "\n",
    "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
    "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6Ka_5Vl9Orm",
    "outputId": "75de5744-f8e4-4aea-c00f-2cb2977a38cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2022-08-19 04:25:49.149865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaypanchal\\AppData\\Local\\Temp\\ipykernel_10020\\1818632268.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return I.astype(np.float).ravel()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode 1, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-19 04:25:51.569879\n",
      "resetting env. episode 2, reward total was -21.0. running mean: -21.0, timestamp: 2022-08-19 04:25:53.933894\n",
      "resetting env. episode 3, reward total was -20.0. running mean: -20.99, timestamp: 2022-08-19 04:25:56.772055\n",
      "resetting env. episode 4, reward total was -21.0. running mean: -20.990099999999998, timestamp: 2022-08-19 04:25:58.678315\n",
      "resetting env. episode 5, reward total was -20.0. running mean: -20.980199, timestamp: 2022-08-19 04:26:00.956682\n",
      "resetting env. episode 6, reward total was -19.0. running mean: -20.96039701, timestamp: 2022-08-19 04:26:03.717191\n",
      "resetting env. episode 7, reward total was -21.0. running mean: -20.9607930399, timestamp: 2022-08-19 04:26:05.731928\n",
      "resetting env. episode 8, reward total was -21.0. running mean: -20.961185109501002, timestamp: 2022-08-19 04:26:07.607613\n",
      "resetting env. episode 9, reward total was -21.0. running mean: -20.961573258405995, timestamp: 2022-08-19 04:26:09.810403\n",
      "resetting env. episode 10, reward total was -20.0. running mean: -20.951957525821935, timestamp: 2022-08-19 04:26:11.940480\n",
      "resetting env. episode 11, reward total was -20.0. running mean: -20.942437950563715, timestamp: 2022-08-19 04:26:14.397819\n",
      "resetting env. episode 12, reward total was -21.0. running mean: -20.943013571058078, timestamp: 2022-08-19 04:26:16.332504\n",
      "resetting env. episode 13, reward total was -21.0. running mean: -20.9435834353475, timestamp: 2022-08-19 04:26:18.587218\n",
      "resetting env. episode 14, reward total was -19.0. running mean: -20.924147600994026, timestamp: 2022-08-19 04:26:20.729756\n",
      "resetting env. episode 15, reward total was -19.0. running mean: -20.904906124984088, timestamp: 2022-08-19 04:26:23.138563\n",
      "resetting env. episode 16, reward total was -19.0. running mean: -20.885857063734246, timestamp: 2022-08-19 04:26:25.391877\n",
      "resetting env. episode 17, reward total was -21.0. running mean: -20.886998493096904, timestamp: 2022-08-19 04:26:27.503249\n",
      "resetting env. episode 18, reward total was -21.0. running mean: -20.888128508165934, timestamp: 2022-08-19 04:26:29.978226\n",
      "resetting env. episode 19, reward total was -21.0. running mean: -20.889247223084276, timestamp: 2022-08-19 04:26:32.378985\n",
      "resetting env. episode 20, reward total was -21.0. running mean: -20.890354750853433, timestamp: 2022-08-19 04:26:34.431113\n",
      "resetting env. episode 21, reward total was -18.0. running mean: -20.8614512033449, timestamp: 2022-08-19 04:26:37.443583\n",
      "resetting env. episode 22, reward total was -21.0. running mean: -20.86283669131145, timestamp: 2022-08-19 04:26:40.133515\n",
      "resetting env. episode 23, reward total was -21.0. running mean: -20.864208324398337, timestamp: 2022-08-19 04:26:41.922342\n",
      "resetting env. episode 24, reward total was -18.0. running mean: -20.835566241154353, timestamp: 2022-08-19 04:26:45.958640\n",
      "resetting env. episode 25, reward total was -21.0. running mean: -20.83721057874281, timestamp: 2022-08-19 04:26:49.436666\n",
      "resetting env. episode 26, reward total was -19.0. running mean: -20.81883847295538, timestamp: 2022-08-19 04:26:52.708687\n",
      "resetting env. episode 27, reward total was -21.0. running mean: -20.82065008822583, timestamp: 2022-08-19 04:26:54.946703\n",
      "resetting env. episode 28, reward total was -20.0. running mean: -20.81244358734357, timestamp: 2022-08-19 04:26:57.849722\n",
      "resetting env. episode 29, reward total was -20.0. running mean: -20.804319151470132, timestamp: 2022-08-19 04:27:00.144740\n",
      "resetting env. episode 30, reward total was -20.0. running mean: -20.79627595995543, timestamp: 2022-08-19 04:27:02.863758\n",
      "resetting env. episode 31, reward total was -18.0. running mean: -20.768313200355877, timestamp: 2022-08-19 04:27:06.078780\n",
      "resetting env. episode 32, reward total was -21.0. running mean: -20.770630068352318, timestamp: 2022-08-19 04:27:08.405798\n",
      "resetting env. episode 33, reward total was -21.0. running mean: -20.772923767668797, timestamp: 2022-08-19 04:27:10.762812\n",
      "resetting env. episode 34, reward total was -21.0. running mean: -20.77519452999211, timestamp: 2022-08-19 04:27:13.168830\n",
      "resetting env. episode 35, reward total was -21.0. running mean: -20.77744258469219, timestamp: 2022-08-19 04:27:15.182849\n",
      "resetting env. episode 36, reward total was -21.0. running mean: -20.77966815884527, timestamp: 2022-08-19 04:27:17.928890\n",
      "resetting env. episode 37, reward total was -20.0. running mean: -20.771871477256816, timestamp: 2022-08-19 04:27:20.584374\n",
      "resetting env. episode 38, reward total was -20.0. running mean: -20.764152762484247, timestamp: 2022-08-19 04:27:23.390393\n",
      "resetting env. episode 39, reward total was -21.0. running mean: -20.766511234859404, timestamp: 2022-08-19 04:27:26.819419\n",
      "resetting env. episode 40, reward total was -18.0. running mean: -20.73884612251081, timestamp: 2022-08-19 04:27:30.380442\n",
      "resetting env. episode 41, reward total was -20.0. running mean: -20.731457661285702, timestamp: 2022-08-19 04:27:32.740457\n",
      "resetting env. episode 42, reward total was -20.0. running mean: -20.724143084672846, timestamp: 2022-08-19 04:27:35.162478\n",
      "resetting env. episode 43, reward total was -21.0. running mean: -20.72690165382612, timestamp: 2022-08-19 04:27:37.252492\n",
      "resetting env. episode 44, reward total was -21.0. running mean: -20.729632637287857, timestamp: 2022-08-19 04:27:39.225509\n",
      "resetting env. episode 45, reward total was -21.0. running mean: -20.732336310914977, timestamp: 2022-08-19 04:27:41.477521\n",
      "resetting env. episode 46, reward total was -21.0. running mean: -20.735012947805828, timestamp: 2022-08-19 04:27:43.436535\n",
      "resetting env. episode 47, reward total was -19.0. running mean: -20.71766281832777, timestamp: 2022-08-19 04:27:46.173556\n",
      "resetting env. episode 48, reward total was -20.0. running mean: -20.710486190144493, timestamp: 2022-08-19 04:27:49.556583\n",
      "resetting env. episode 49, reward total was -20.0. running mean: -20.703381328243047, timestamp: 2022-08-19 04:27:52.281601\n",
      "resetting env. episode 50, reward total was -21.0. running mean: -20.70634751496062, timestamp: 2022-08-19 04:27:54.684621\n",
      "resetting env. episode 51, reward total was -21.0. running mean: -20.709284039811013, timestamp: 2022-08-19 04:27:56.755638\n",
      "resetting env. episode 52, reward total was -21.0. running mean: -20.712191199412903, timestamp: 2022-08-19 04:27:58.902650\n",
      "resetting env. episode 53, reward total was -18.0. running mean: -20.685069287418774, timestamp: 2022-08-19 04:28:01.907674\n",
      "resetting env. episode 54, reward total was -21.0. running mean: -20.688218594544587, timestamp: 2022-08-19 04:28:04.395691\n",
      "resetting env. episode 55, reward total was -21.0. running mean: -20.691336408599142, timestamp: 2022-08-19 04:28:06.348706\n",
      "resetting env. episode 56, reward total was -21.0. running mean: -20.69442304451315, timestamp: 2022-08-19 04:28:08.608722\n",
      "resetting env. episode 57, reward total was -20.0. running mean: -20.68747881406802, timestamp: 2022-08-19 04:28:11.072745\n",
      "resetting env. episode 58, reward total was -21.0. running mean: -20.69060402592734, timestamp: 2022-08-19 04:28:13.044760\n",
      "resetting env. episode 59, reward total was -20.0. running mean: -20.683697985668065, timestamp: 2022-08-19 04:28:15.675779\n",
      "resetting env. episode 60, reward total was -21.0. running mean: -20.686861005811384, timestamp: 2022-08-19 04:28:18.311797\n",
      "resetting env. episode 61, reward total was -20.0. running mean: -20.67999239575327, timestamp: 2022-08-19 04:28:20.501815\n",
      "resetting env. episode 62, reward total was -21.0. running mean: -20.68319247179574, timestamp: 2022-08-19 04:28:22.332827\n",
      "resetting env. episode 63, reward total was -20.0. running mean: -20.67636054707778, timestamp: 2022-08-19 04:28:25.084847\n",
      "resetting env. episode 64, reward total was -21.0. running mean: -20.679596941607002, timestamp: 2022-08-19 04:28:27.855869\n",
      "resetting env. episode 65, reward total was -21.0. running mean: -20.682800972190932, timestamp: 2022-08-19 04:28:30.619890\n",
      "resetting env. episode 66, reward total was -21.0. running mean: -20.685972962469023, timestamp: 2022-08-19 04:28:33.070911\n",
      "resetting env. episode 67, reward total was -21.0. running mean: -20.689113232844335, timestamp: 2022-08-19 04:28:35.342925\n",
      "resetting env. episode 68, reward total was -21.0. running mean: -20.69222210051589, timestamp: 2022-08-19 04:28:37.558941\n",
      "resetting env. episode 69, reward total was -20.0. running mean: -20.685299879510733, timestamp: 2022-08-19 04:28:40.147968\n",
      "resetting env. episode 70, reward total was -21.0. running mean: -20.688446880715627, timestamp: 2022-08-19 04:28:42.164977\n",
      "resetting env. episode 71, reward total was -20.0. running mean: -20.68156241190847, timestamp: 2022-08-19 04:28:44.668998\n",
      "resetting env. episode 72, reward total was -21.0. running mean: -20.684746787789386, timestamp: 2022-08-19 04:28:46.940013\n",
      "resetting env. episode 73, reward total was -20.0. running mean: -20.677899319911493, timestamp: 2022-08-19 04:28:49.503033\n",
      "resetting env. episode 74, reward total was -21.0. running mean: -20.681120326712378, timestamp: 2022-08-19 04:28:51.519049\n",
      "resetting env. episode 75, reward total was -20.0. running mean: -20.674309123445255, timestamp: 2022-08-19 04:28:54.245071\n",
      "resetting env. episode 76, reward total was -20.0. running mean: -20.6675660322108, timestamp: 2022-08-19 04:28:56.968092\n",
      "resetting env. episode 77, reward total was -21.0. running mean: -20.670890371888692, timestamp: 2022-08-19 04:28:59.065107\n",
      "resetting env. episode 78, reward total was -20.0. running mean: -20.664181468169804, timestamp: 2022-08-19 04:29:01.541130\n",
      "resetting env. episode 79, reward total was -19.0. running mean: -20.647539653488106, timestamp: 2022-08-19 04:29:04.045146\n",
      "resetting env. episode 80, reward total was -20.0. running mean: -20.641064256953225, timestamp: 2022-08-19 04:29:06.605167\n",
      "resetting env. episode 81, reward total was -21.0. running mean: -20.644653614383692, timestamp: 2022-08-19 04:29:08.557186\n",
      "resetting env. episode 82, reward total was -20.0. running mean: -20.638207078239855, timestamp: 2022-08-19 04:29:11.613205\n",
      "resetting env. episode 83, reward total was -21.0. running mean: -20.641825007457456, timestamp: 2022-08-19 04:29:13.995224\n",
      "resetting env. episode 84, reward total was -20.0. running mean: -20.63540675738288, timestamp: 2022-08-19 04:29:16.725245\n",
      "resetting env. episode 85, reward total was -20.0. running mean: -20.62905268980905, timestamp: 2022-08-19 04:29:19.248265\n",
      "resetting env. episode 86, reward total was -20.0. running mean: -20.62276216291096, timestamp: 2022-08-19 04:29:21.502284\n",
      "resetting env. episode 87, reward total was -20.0. running mean: -20.616534541281847, timestamp: 2022-08-19 04:29:23.892300\n",
      "resetting env. episode 88, reward total was -20.0. running mean: -20.61036919586903, timestamp: 2022-08-19 04:29:26.404322\n",
      "resetting env. episode 89, reward total was -20.0. running mean: -20.604265503910337, timestamp: 2022-08-19 04:29:29.201344\n",
      "resetting env. episode 90, reward total was -21.0. running mean: -20.608222848871236, timestamp: 2022-08-19 04:29:31.335361\n",
      "resetting env. episode 91, reward total was -21.0. running mean: -20.612140620382526, timestamp: 2022-08-19 04:29:33.353377\n",
      "resetting env. episode 92, reward total was -20.0. running mean: -20.6060192141787, timestamp: 2022-08-19 04:29:35.987396\n",
      "resetting env. episode 93, reward total was -19.0. running mean: -20.589959022036915, timestamp: 2022-08-19 04:29:38.788422\n",
      "resetting env. episode 94, reward total was -21.0. running mean: -20.594059431816547, timestamp: 2022-08-19 04:29:41.245439\n",
      "resetting env. episode 95, reward total was -20.0. running mean: -20.58811883749838, timestamp: 2022-08-19 04:29:43.822458\n",
      "resetting env. episode 96, reward total was -18.0. running mean: -20.562237649123396, timestamp: 2022-08-19 04:29:46.949486\n",
      "resetting env. episode 97, reward total was -20.0. running mean: -20.55661527263216, timestamp: 2022-08-19 04:29:49.804506\n",
      "resetting env. episode 98, reward total was -21.0. running mean: -20.56104911990584, timestamp: 2022-08-19 04:29:52.375526\n",
      "resetting env. episode 99, reward total was -21.0. running mean: -20.56543862870678, timestamp: 2022-08-19 04:29:54.907548\n",
      "resetting env. episode 100, reward total was -20.0. running mean: -20.55978424241971, timestamp: 2022-08-19 04:29:57.469567\n",
      "resetting env. episode 101, reward total was -21.0. running mean: -20.564186399995513, timestamp: 2022-08-19 04:29:59.445583\n",
      "resetting env. episode 102, reward total was -21.0. running mean: -20.56854453599556, timestamp: 2022-08-19 04:30:01.563602\n",
      "resetting env. episode 103, reward total was -20.0. running mean: -20.562859090635605, timestamp: 2022-08-19 04:30:04.225622\n",
      "resetting env. episode 104, reward total was -20.0. running mean: -20.557230499729247, timestamp: 2022-08-19 04:30:06.494644\n",
      "resetting env. episode 105, reward total was -21.0. running mean: -20.561658194731955, timestamp: 2022-08-19 04:30:08.708660\n",
      "resetting env. episode 106, reward total was -21.0. running mean: -20.566041612784634, timestamp: 2022-08-19 04:30:11.405680\n",
      "resetting env. episode 107, reward total was -20.0. running mean: -20.560381196656788, timestamp: 2022-08-19 04:30:13.800698\n",
      "resetting env. episode 108, reward total was -21.0. running mean: -20.56477738469022, timestamp: 2022-08-19 04:30:16.053720\n",
      "resetting env. episode 109, reward total was -21.0. running mean: -20.56912961084332, timestamp: 2022-08-19 04:30:18.882744\n",
      "resetting env. episode 110, reward total was -21.0. running mean: -20.573438314734886, timestamp: 2022-08-19 04:30:21.044758\n",
      "resetting env. episode 111, reward total was -21.0. running mean: -20.57770393158754, timestamp: 2022-08-19 04:30:23.762790\n",
      "resetting env. episode 112, reward total was -20.0. running mean: -20.571926892271662, timestamp: 2022-08-19 04:30:26.448802\n",
      "resetting env. episode 113, reward total was -20.0. running mean: -20.566207623348944, timestamp: 2022-08-19 04:30:28.770833\n",
      "resetting env. episode 114, reward total was -20.0. running mean: -20.560545547115453, timestamp: 2022-08-19 04:30:32.026848\n",
      "resetting env. episode 115, reward total was -20.0. running mean: -20.554940091644298, timestamp: 2022-08-19 04:30:34.795874\n",
      "resetting env. episode 116, reward total was -21.0. running mean: -20.559390690727856, timestamp: 2022-08-19 04:30:38.115898\n",
      "resetting env. episode 117, reward total was -21.0. running mean: -20.563796783820578, timestamp: 2022-08-19 04:30:40.988921\n",
      "resetting env. episode 118, reward total was -21.0. running mean: -20.568158815982372, timestamp: 2022-08-19 04:30:43.334942\n",
      "resetting env. episode 119, reward total was -21.0. running mean: -20.57247722782255, timestamp: 2022-08-19 04:30:46.602372\n",
      "resetting env. episode 120, reward total was -19.0. running mean: -20.556752455544324, timestamp: 2022-08-19 04:30:49.627040\n",
      "resetting env. episode 121, reward total was -18.0. running mean: -20.53118493098888, timestamp: 2022-08-19 04:30:53.333070\n",
      "resetting env. episode 122, reward total was -20.0. running mean: -20.525873081678988, timestamp: 2022-08-19 04:30:56.134092\n",
      "resetting env. episode 123, reward total was -21.0. running mean: -20.530614350862198, timestamp: 2022-08-19 04:30:58.625112\n",
      "resetting env. episode 124, reward total was -17.0. running mean: -20.495308207353578, timestamp: 2022-08-19 04:31:02.317144\n",
      "resetting env. episode 125, reward total was -20.0. running mean: -20.49035512528004, timestamp: 2022-08-19 04:31:04.923167\n",
      "resetting env. episode 126, reward total was -21.0. running mean: -20.49545157402724, timestamp: 2022-08-19 04:31:08.487195\n",
      "resetting env. episode 127, reward total was -21.0. running mean: -20.500497058286967, timestamp: 2022-08-19 04:31:10.952215\n",
      "resetting env. episode 128, reward total was -21.0. running mean: -20.5054920877041, timestamp: 2022-08-19 04:31:14.180249\n",
      "resetting env. episode 129, reward total was -21.0. running mean: -20.510437166827057, timestamp: 2022-08-19 04:31:16.445260\n",
      "resetting env. episode 130, reward total was -21.0. running mean: -20.515332795158788, timestamp: 2022-08-19 04:31:19.144281\n",
      "resetting env. episode 131, reward total was -20.0. running mean: -20.510179467207198, timestamp: 2022-08-19 04:31:22.145308\n",
      "resetting env. episode 132, reward total was -21.0. running mean: -20.515077672535128, timestamp: 2022-08-19 04:31:24.849329\n",
      "resetting env. episode 133, reward total was -21.0. running mean: -20.51992689580978, timestamp: 2022-08-19 04:31:27.200348\n",
      "resetting env. episode 134, reward total was -19.0. running mean: -20.504727626851682, timestamp: 2022-08-19 04:31:30.143372\n",
      "resetting env. episode 135, reward total was -21.0. running mean: -20.509680350583167, timestamp: 2022-08-19 04:31:33.137402\n",
      "resetting env. episode 136, reward total was -21.0. running mean: -20.514583547077336, timestamp: 2022-08-19 04:31:35.738419\n",
      "resetting env. episode 137, reward total was -21.0. running mean: -20.519437711606564, timestamp: 2022-08-19 04:31:38.839448\n",
      "resetting env. episode 138, reward total was -19.0. running mean: -20.5042433344905, timestamp: 2022-08-19 04:31:41.693477\n",
      "resetting env. episode 139, reward total was -20.0. running mean: -20.499200901145596, timestamp: 2022-08-19 04:31:44.103490\n",
      "resetting env. episode 140, reward total was -21.0. running mean: -20.50420889213414, timestamp: 2022-08-19 04:31:46.653511\n",
      "resetting env. episode 141, reward total was -19.0. running mean: -20.4891668032128, timestamp: 2022-08-19 04:31:49.405534\n",
      "resetting env. episode 142, reward total was -21.0. running mean: -20.494275135180672, timestamp: 2022-08-19 04:31:51.401552\n",
      "resetting env. episode 143, reward total was -20.0. running mean: -20.489332383828863, timestamp: 2022-08-19 04:31:53.762570\n",
      "resetting env. episode 144, reward total was -21.0. running mean: -20.494439059990576, timestamp: 2022-08-19 04:31:56.657598\n",
      "resetting env. episode 145, reward total was -19.0. running mean: -20.47949466939067, timestamp: 2022-08-19 04:31:59.116619\n",
      "resetting env. episode 146, reward total was -21.0. running mean: -20.484699722696767, timestamp: 2022-08-19 04:32:01.358634\n",
      "resetting env. episode 147, reward total was -21.0. running mean: -20.4898527254698, timestamp: 2022-08-19 04:32:04.000657\n",
      "resetting env. episode 148, reward total was -20.0. running mean: -20.4849541982151, timestamp: 2022-08-19 04:32:06.672678\n",
      "resetting env. episode 149, reward total was -21.0. running mean: -20.490104656232948, timestamp: 2022-08-19 04:32:09.148698\n",
      "resetting env. episode 150, reward total was -20.0. running mean: -20.485203609670616, timestamp: 2022-08-19 04:32:11.833722\n",
      "resetting env. episode 151, reward total was -20.0. running mean: -20.48035157357391, timestamp: 2022-08-19 04:32:14.991749\n",
      "resetting env. episode 152, reward total was -21.0. running mean: -20.48554805783817, timestamp: 2022-08-19 04:32:18.125774\n",
      "resetting env. episode 153, reward total was -21.0. running mean: -20.49069257725979, timestamp: 2022-08-19 04:32:20.211793\n",
      "resetting env. episode 154, reward total was -19.0. running mean: -20.475785651487193, timestamp: 2022-08-19 04:32:23.897827\n",
      "resetting env. episode 155, reward total was -21.0. running mean: -20.481027794972324, timestamp: 2022-08-19 04:32:26.058845\n",
      "resetting env. episode 156, reward total was -21.0. running mean: -20.486217517022602, timestamp: 2022-08-19 04:32:28.424864\n",
      "resetting env. episode 157, reward total was -21.0. running mean: -20.491355341852376, timestamp: 2022-08-19 04:32:30.928886\n",
      "resetting env. episode 158, reward total was -20.0. running mean: -20.48644178843385, timestamp: 2022-08-19 04:32:33.161900\n",
      "resetting env. episode 159, reward total was -21.0. running mean: -20.491577370549514, timestamp: 2022-08-19 04:32:35.632925\n",
      "resetting env. episode 160, reward total was -21.0. running mean: -20.49666159684402, timestamp: 2022-08-19 04:32:37.785939\n",
      "resetting env. episode 161, reward total was -20.0. running mean: -20.49169498087558, timestamp: 2022-08-19 04:32:40.470964\n",
      "resetting env. episode 162, reward total was -20.0. running mean: -20.486778031066823, timestamp: 2022-08-19 04:32:43.313988\n",
      "resetting env. episode 163, reward total was -21.0. running mean: -20.491910250756156, timestamp: 2022-08-19 04:32:46.389014\n",
      "resetting env. episode 164, reward total was -20.0. running mean: -20.486991148248595, timestamp: 2022-08-19 04:32:49.080034\n",
      "resetting env. episode 165, reward total was -21.0. running mean: -20.49212123676611, timestamp: 2022-08-19 04:32:51.535055\n",
      "resetting env. episode 166, reward total was -21.0. running mean: -20.49720002439845, timestamp: 2022-08-19 04:32:54.278081\n",
      "resetting env. episode 167, reward total was -19.0. running mean: -20.482228024154466, timestamp: 2022-08-19 04:32:56.735099\n",
      "resetting env. episode 168, reward total was -20.0. running mean: -20.47740574391292, timestamp: 2022-08-19 04:32:59.228120\n",
      "resetting env. episode 169, reward total was -21.0. running mean: -20.482631686473795, timestamp: 2022-08-19 04:33:02.121146\n",
      "resetting env. episode 170, reward total was -21.0. running mean: -20.487805369609056, timestamp: 2022-08-19 04:33:04.309165\n",
      "resetting env. episode 171, reward total was -21.0. running mean: -20.492927315912965, timestamp: 2022-08-19 04:33:06.767184\n",
      "resetting env. episode 172, reward total was -21.0. running mean: -20.497998042753835, timestamp: 2022-08-19 04:33:10.179213\n",
      "resetting env. episode 173, reward total was -21.0. running mean: -20.503018062326298, timestamp: 2022-08-19 04:33:12.771237\n",
      "resetting env. episode 174, reward total was -21.0. running mean: -20.507987881703034, timestamp: 2022-08-19 04:33:14.763254\n",
      "resetting env. episode 175, reward total was -21.0. running mean: -20.512908002886004, timestamp: 2022-08-19 04:33:17.395273\n",
      "resetting env. episode 176, reward total was -21.0. running mean: -20.517778922857143, timestamp: 2022-08-19 04:33:19.429291\n",
      "resetting env. episode 177, reward total was -21.0. running mean: -20.522601133628573, timestamp: 2022-08-19 04:33:21.730310\n",
      "resetting env. episode 178, reward total was -21.0. running mean: -20.527375122292288, timestamp: 2022-08-19 04:33:24.043328\n",
      "resetting env. episode 179, reward total was -20.0. running mean: -20.522101371069365, timestamp: 2022-08-19 04:33:26.907353\n",
      "resetting env. episode 180, reward total was -20.0. running mean: -20.51688035735867, timestamp: 2022-08-19 04:33:29.493374\n",
      "resetting env. episode 181, reward total was -20.0. running mean: -20.51171155378508, timestamp: 2022-08-19 04:33:31.990397\n",
      "resetting env. episode 182, reward total was -20.0. running mean: -20.506594438247227, timestamp: 2022-08-19 04:33:34.510418\n",
      "resetting env. episode 183, reward total was -21.0. running mean: -20.511528493864756, timestamp: 2022-08-19 04:33:36.798437\n",
      "resetting env. episode 184, reward total was -21.0. running mean: -20.51641320892611, timestamp: 2022-08-19 04:33:39.239457\n",
      "resetting env. episode 185, reward total was -21.0. running mean: -20.52124907683685, timestamp: 2022-08-19 04:33:41.528480\n",
      "resetting env. episode 186, reward total was -21.0. running mean: -20.526036586068482, timestamp: 2022-08-19 04:33:43.941500\n",
      "resetting env. episode 187, reward total was -19.0. running mean: -20.5107762202078, timestamp: 2022-08-19 04:33:46.810522\n",
      "resetting env. episode 188, reward total was -21.0. running mean: -20.51566845800572, timestamp: 2022-08-19 04:33:49.066542\n",
      "resetting env. episode 189, reward total was -21.0. running mean: -20.520511773425664, timestamp: 2022-08-19 04:33:51.625561\n",
      "resetting env. episode 190, reward total was -21.0. running mean: -20.52530665569141, timestamp: 2022-08-19 04:33:54.234582\n",
      "resetting env. episode 191, reward total was -20.0. running mean: -20.520053589134495, timestamp: 2022-08-19 04:33:56.912606\n",
      "resetting env. episode 192, reward total was -19.0. running mean: -20.50485305324315, timestamp: 2022-08-19 04:34:00.560639\n",
      "resetting env. episode 193, reward total was -21.0. running mean: -20.50980452271072, timestamp: 2022-08-19 04:34:02.719654\n",
      "resetting env. episode 194, reward total was -17.0. running mean: -20.474706477483615, timestamp: 2022-08-19 04:34:05.482677\n",
      "resetting env. episode 195, reward total was -20.0. running mean: -20.46995941270878, timestamp: 2022-08-19 04:34:08.600706\n",
      "resetting env. episode 196, reward total was -20.0. running mean: -20.46525981858169, timestamp: 2022-08-19 04:34:11.066728\n",
      "resetting env. episode 197, reward total was -21.0. running mean: -20.470607220395873, timestamp: 2022-08-19 04:34:13.050744\n",
      "resetting env. episode 198, reward total was -19.0. running mean: -20.455901148191916, timestamp: 2022-08-19 04:34:15.827766\n",
      "resetting env. episode 199, reward total was -21.0. running mean: -20.461342136709998, timestamp: 2022-08-19 04:34:18.709791\n",
      "resetting env. episode 200, reward total was -20.0. running mean: -20.456728715342898, timestamp: 2022-08-19 04:34:21.770813\n",
      "resetting env. episode 201, reward total was -21.0. running mean: -20.462161428189468, timestamp: 2022-08-19 04:34:24.206839\n",
      "resetting env. episode 202, reward total was -20.0. running mean: -20.457539813907573, timestamp: 2022-08-19 04:34:27.441863\n",
      "resetting env. episode 203, reward total was -21.0. running mean: -20.462964415768496, timestamp: 2022-08-19 04:34:29.611884\n",
      "resetting env. episode 204, reward total was -20.0. running mean: -20.45833477161081, timestamp: 2022-08-19 04:34:32.477905\n",
      "resetting env. episode 205, reward total was -21.0. running mean: -20.463751423894703, timestamp: 2022-08-19 04:34:35.512931\n",
      "resetting env. episode 206, reward total was -21.0. running mean: -20.469113909655757, timestamp: 2022-08-19 04:34:38.128956\n",
      "resetting env. episode 207, reward total was -21.0. running mean: -20.4744227705592, timestamp: 2022-08-19 04:34:40.853977\n",
      "resetting env. episode 208, reward total was -19.0. running mean: -20.45967854285361, timestamp: 2022-08-19 04:34:43.786001\n",
      "resetting env. episode 209, reward total was -21.0. running mean: -20.465081757425075, timestamp: 2022-08-19 04:34:46.549027\n",
      "resetting env. episode 210, reward total was -21.0. running mean: -20.470430939850825, timestamp: 2022-08-19 04:34:49.016045\n",
      "resetting env. episode 211, reward total was -20.0. running mean: -20.465726630452316, timestamp: 2022-08-19 04:34:51.920070\n",
      "resetting env. episode 212, reward total was -20.0. running mean: -20.461069364147793, timestamp: 2022-08-19 04:34:54.171090\n",
      "resetting env. episode 213, reward total was -20.0. running mean: -20.456458670506315, timestamp: 2022-08-19 04:34:57.194115\n",
      "resetting env. episode 214, reward total was -21.0. running mean: -20.46189408380125, timestamp: 2022-08-19 04:35:00.463145\n",
      "resetting env. episode 215, reward total was -21.0. running mean: -20.46727514296324, timestamp: 2022-08-19 04:35:03.004167\n",
      "resetting env. episode 216, reward total was -21.0. running mean: -20.472602391533606, timestamp: 2022-08-19 04:35:05.291185\n",
      "resetting env. episode 217, reward total was -21.0. running mean: -20.477876367618272, timestamp: 2022-08-19 04:35:07.499205\n",
      "resetting env. episode 218, reward total was -20.0. running mean: -20.473097603942087, timestamp: 2022-08-19 04:35:09.738221\n",
      "resetting env. episode 219, reward total was -21.0. running mean: -20.478366627902666, timestamp: 2022-08-19 04:35:12.487247\n",
      "resetting env. episode 220, reward total was -20.0. running mean: -20.473582961623638, timestamp: 2022-08-19 04:35:15.295268\n",
      "resetting env. episode 221, reward total was -21.0. running mean: -20.478847132007402, timestamp: 2022-08-19 04:35:18.166298\n",
      "resetting env. episode 222, reward total was -20.0. running mean: -20.474058660687326, timestamp: 2022-08-19 04:35:20.711319\n",
      "resetting env. episode 223, reward total was -21.0. running mean: -20.479318074080453, timestamp: 2022-08-19 04:35:23.759985\n",
      "resetting env. episode 224, reward total was -20.0. running mean: -20.474524893339648, timestamp: 2022-08-19 04:35:26.598161\n",
      "resetting env. episode 225, reward total was -21.0. running mean: -20.479779644406253, timestamp: 2022-08-19 04:35:29.055115\n",
      "resetting env. episode 226, reward total was -21.0. running mean: -20.484981847962192, timestamp: 2022-08-19 04:35:31.174138\n",
      "resetting env. episode 227, reward total was -21.0. running mean: -20.49013202948257, timestamp: 2022-08-19 04:35:34.484158\n",
      "resetting env. episode 228, reward total was -19.0. running mean: -20.475230709187745, timestamp: 2022-08-19 04:35:37.393183\n",
      "resetting env. episode 229, reward total was -20.0. running mean: -20.470478402095868, timestamp: 2022-08-19 04:35:39.588201\n",
      "resetting env. episode 230, reward total was -20.0. running mean: -20.46577361807491, timestamp: 2022-08-19 04:35:42.346224\n",
      "resetting env. episode 231, reward total was -20.0. running mean: -20.46111588189416, timestamp: 2022-08-19 04:35:45.427252\n",
      "resetting env. episode 232, reward total was -21.0. running mean: -20.466504723075218, timestamp: 2022-08-19 04:35:47.803271\n",
      "resetting env. episode 233, reward total was -20.0. running mean: -20.461839675844466, timestamp: 2022-08-19 04:35:50.652295\n",
      "resetting env. episode 234, reward total was -21.0. running mean: -20.467221279086022, timestamp: 2022-08-19 04:35:53.536319\n",
      "resetting env. episode 235, reward total was -21.0. running mean: -20.472549066295162, timestamp: 2022-08-19 04:35:56.803348\n",
      "resetting env. episode 236, reward total was -21.0. running mean: -20.47782357563221, timestamp: 2022-08-19 04:35:59.340370\n",
      "resetting env. episode 237, reward total was -21.0. running mean: -20.48304533987589, timestamp: 2022-08-19 04:36:01.468390\n",
      "resetting env. episode 238, reward total was -21.0. running mean: -20.48821488647713, timestamp: 2022-08-19 04:36:04.056409\n",
      "resetting env. episode 239, reward total was -20.0. running mean: -20.483332737612358, timestamp: 2022-08-19 04:36:06.430429\n",
      "resetting env. episode 240, reward total was -21.0. running mean: -20.488499410236233, timestamp: 2022-08-19 04:36:08.896451\n",
      "resetting env. episode 241, reward total was -21.0. running mean: -20.493614416133873, timestamp: 2022-08-19 04:36:11.166478\n",
      "resetting env. episode 242, reward total was -20.0. running mean: -20.48867827197253, timestamp: 2022-08-19 04:36:13.727494\n",
      "resetting env. episode 243, reward total was -19.0. running mean: -20.473791489252807, timestamp: 2022-08-19 04:36:16.562518\n",
      "resetting env. episode 244, reward total was -20.0. running mean: -20.469053574360277, timestamp: 2022-08-19 04:36:19.163538\n",
      "resetting env. episode 245, reward total was -19.0. running mean: -20.454363038616677, timestamp: 2022-08-19 04:36:22.359565\n",
      "resetting env. episode 246, reward total was -21.0. running mean: -20.459819408230512, timestamp: 2022-08-19 04:36:24.696584\n",
      "resetting env. episode 247, reward total was -21.0. running mean: -20.465221214148208, timestamp: 2022-08-19 04:36:27.281608\n",
      "resetting env. episode 248, reward total was -21.0. running mean: -20.470569002006727, timestamp: 2022-08-19 04:36:30.026634\n",
      "resetting env. episode 249, reward total was -20.0. running mean: -20.46586331198666, timestamp: 2022-08-19 04:36:32.435655\n",
      "resetting env. episode 250, reward total was -20.0. running mean: -20.461204678866793, timestamp: 2022-08-19 04:36:35.102672\n",
      "resetting env. episode 251, reward total was -19.0. running mean: -20.446592632078126, timestamp: 2022-08-19 04:36:38.484702\n",
      "resetting env. episode 252, reward total was -21.0. running mean: -20.452126705757344, timestamp: 2022-08-19 04:36:40.477723\n",
      "resetting env. episode 253, reward total was -21.0. running mean: -20.457605438699773, timestamp: 2022-08-19 04:36:42.657737\n",
      "resetting env. episode 254, reward total was -21.0. running mean: -20.463029384312776, timestamp: 2022-08-19 04:36:44.646754\n",
      "resetting env. episode 255, reward total was -19.0. running mean: -20.44839909046965, timestamp: 2022-08-19 04:36:47.100776\n",
      "resetting env. episode 256, reward total was -20.0. running mean: -20.443915099564954, timestamp: 2022-08-19 04:36:50.042799\n",
      "resetting env. episode 257, reward total was -19.0. running mean: -20.429475948569305, timestamp: 2022-08-19 04:36:53.485830\n",
      "resetting env. episode 258, reward total was -21.0. running mean: -20.43518118908361, timestamp: 2022-08-19 04:36:55.760851\n",
      "resetting env. episode 259, reward total was -21.0. running mean: -20.440829377192774, timestamp: 2022-08-19 04:36:58.599878\n",
      "resetting env. episode 260, reward total was -21.0. running mean: -20.446421083420848, timestamp: 2022-08-19 04:37:00.824894\n",
      "resetting env. episode 261, reward total was -19.0. running mean: -20.43195687258664, timestamp: 2022-08-19 04:37:03.886918\n",
      "resetting env. episode 262, reward total was -21.0. running mean: -20.43763730386077, timestamp: 2022-08-19 04:37:06.261939\n",
      "resetting env. episode 263, reward total was -21.0. running mean: -20.443260930822163, timestamp: 2022-08-19 04:37:08.702480\n",
      "resetting env. episode 264, reward total was -20.0. running mean: -20.43882832151394, timestamp: 2022-08-19 04:37:12.487513\n",
      "resetting env. episode 265, reward total was -21.0. running mean: -20.444440038298804, timestamp: 2022-08-19 04:37:15.682539\n",
      "resetting env. episode 266, reward total was -20.0. running mean: -20.439995637915814, timestamp: 2022-08-19 04:37:18.391566\n",
      "resetting env. episode 267, reward total was -18.0. running mean: -20.415595681536654, timestamp: 2022-08-19 04:37:21.328589\n",
      "resetting env. episode 268, reward total was -21.0. running mean: -20.42143972472129, timestamp: 2022-08-19 04:37:23.982610\n",
      "resetting env. episode 269, reward total was -21.0. running mean: -20.427225327474076, timestamp: 2022-08-19 04:37:26.324630\n",
      "resetting env. episode 270, reward total was -19.0. running mean: -20.412953074199336, timestamp: 2022-08-19 04:37:28.972654\n",
      "resetting env. episode 271, reward total was -19.0. running mean: -20.398823543457343, timestamp: 2022-08-19 04:37:31.490675\n",
      "resetting env. episode 272, reward total was -21.0. running mean: -20.404835308022772, timestamp: 2022-08-19 04:37:34.190702\n",
      "resetting env. episode 273, reward total was -21.0. running mean: -20.410786954942544, timestamp: 2022-08-19 04:37:36.702717\n",
      "resetting env. episode 274, reward total was -21.0. running mean: -20.41667908539312, timestamp: 2022-08-19 04:37:39.039738\n",
      "resetting env. episode 275, reward total was -20.0. running mean: -20.412512294539187, timestamp: 2022-08-19 04:37:41.624761\n",
      "resetting env. episode 276, reward total was -21.0. running mean: -20.418387171593796, timestamp: 2022-08-19 04:37:43.815784\n",
      "resetting env. episode 277, reward total was -20.0. running mean: -20.414203299877858, timestamp: 2022-08-19 04:37:46.160797\n",
      "resetting env. episode 278, reward total was -21.0. running mean: -20.42006126687908, timestamp: 2022-08-19 04:37:49.242826\n",
      "resetting env. episode 279, reward total was -21.0. running mean: -20.42586065421029, timestamp: 2022-08-19 04:37:51.954850\n",
      "resetting env. episode 280, reward total was -20.0. running mean: -20.421602047668184, timestamp: 2022-08-19 04:37:54.367867\n",
      "resetting env. episode 281, reward total was -21.0. running mean: -20.427386027191503, timestamp: 2022-08-19 04:37:56.428884\n",
      "resetting env. episode 282, reward total was -21.0. running mean: -20.43311216691959, timestamp: 2022-08-19 04:37:58.829903\n",
      "resetting env. episode 283, reward total was -21.0. running mean: -20.438781045250394, timestamp: 2022-08-19 04:38:01.237925\n",
      "resetting env. episode 284, reward total was -19.0. running mean: -20.42439323479789, timestamp: 2022-08-19 04:38:04.428951\n",
      "resetting env. episode 285, reward total was -20.0. running mean: -20.42014930244991, timestamp: 2022-08-19 04:38:07.618976\n",
      "resetting env. episode 286, reward total was -21.0. running mean: -20.425947809425413, timestamp: 2022-08-19 04:38:09.904999\n",
      "resetting env. episode 287, reward total was -21.0. running mean: -20.43168833133116, timestamp: 2022-08-19 04:38:12.571018\n",
      "resetting env. episode 288, reward total was -20.0. running mean: -20.427371448017848, timestamp: 2022-08-19 04:38:15.098039\n",
      "resetting env. episode 289, reward total was -18.0. running mean: -20.40309773353767, timestamp: 2022-08-19 04:38:18.152069\n",
      "resetting env. episode 290, reward total was -21.0. running mean: -20.409066756202293, timestamp: 2022-08-19 04:38:21.019089\n",
      "resetting env. episode 291, reward total was -21.0. running mean: -20.41497608864027, timestamp: 2022-08-19 04:38:23.744116\n",
      "resetting env. episode 292, reward total was -21.0. running mean: -20.42082632775387, timestamp: 2022-08-19 04:38:26.397135\n",
      "resetting env. episode 293, reward total was -21.0. running mean: -20.42661806447633, timestamp: 2022-08-19 04:38:28.651153\n",
      "resetting env. episode 294, reward total was -21.0. running mean: -20.43235188383157, timestamp: 2022-08-19 04:38:31.108178\n",
      "resetting env. episode 295, reward total was -21.0. running mean: -20.438028364993254, timestamp: 2022-08-19 04:38:33.623198\n",
      "resetting env. episode 296, reward total was -21.0. running mean: -20.443648081343323, timestamp: 2022-08-19 04:38:36.575220\n",
      "resetting env. episode 297, reward total was -21.0. running mean: -20.44921160052989, timestamp: 2022-08-19 04:38:39.638250\n",
      "resetting env. episode 298, reward total was -20.0. running mean: -20.44471948452459, timestamp: 2022-08-19 04:38:41.941267\n",
      "resetting env. episode 299, reward total was -21.0. running mean: -20.450272289679344, timestamp: 2022-08-19 04:38:44.584292\n",
      "resetting env. episode 300, reward total was -21.0. running mean: -20.45576956678255, timestamp: 2022-08-19 04:38:46.639307\n",
      "resetting env. episode 301, reward total was -21.0. running mean: -20.461211871114724, timestamp: 2022-08-19 04:38:49.572335\n",
      "resetting env. episode 302, reward total was -20.0. running mean: -20.456599752403577, timestamp: 2022-08-19 04:38:52.388356\n",
      "resetting env. episode 303, reward total was -20.0. running mean: -20.45203375487954, timestamp: 2022-08-19 04:38:55.300380\n",
      "resetting env. episode 304, reward total was -21.0. running mean: -20.457513417330745, timestamp: 2022-08-19 04:38:58.169402\n",
      "resetting env. episode 305, reward total was -20.0. running mean: -20.452938283157437, timestamp: 2022-08-19 04:39:00.589423\n",
      "resetting env. episode 306, reward total was -20.0. running mean: -20.448408900325862, timestamp: 2022-08-19 04:39:03.242446\n",
      "resetting env. episode 307, reward total was -19.0. running mean: -20.433924811322605, timestamp: 2022-08-19 04:39:05.753469\n",
      "resetting env. episode 308, reward total was -20.0. running mean: -20.42958556320938, timestamp: 2022-08-19 04:39:09.038498\n",
      "resetting env. episode 309, reward total was -20.0. running mean: -20.425289707577285, timestamp: 2022-08-19 04:39:11.863522\n",
      "resetting env. episode 310, reward total was -21.0. running mean: -20.431036810501514, timestamp: 2022-08-19 04:39:14.699542\n",
      "resetting env. episode 311, reward total was -18.0. running mean: -20.406726442396497, timestamp: 2022-08-19 04:39:17.974569\n",
      "resetting env. episode 312, reward total was -21.0. running mean: -20.412659177972532, timestamp: 2022-08-19 04:39:21.124597\n",
      "resetting env. episode 313, reward total was -21.0. running mean: -20.418532586192807, timestamp: 2022-08-19 04:39:23.073615\n",
      "resetting env. episode 314, reward total was -21.0. running mean: -20.42434726033088, timestamp: 2022-08-19 04:39:25.580633\n",
      "resetting env. episode 315, reward total was -20.0. running mean: -20.42010378772757, timestamp: 2022-08-19 04:39:27.892652\n",
      "resetting env. episode 316, reward total was -19.0. running mean: -20.405902749850295, timestamp: 2022-08-19 04:39:30.622675\n",
      "resetting env. episode 317, reward total was -21.0. running mean: -20.411843722351794, timestamp: 2022-08-19 04:39:32.764697\n",
      "resetting env. episode 318, reward total was -21.0. running mean: -20.417725285128277, timestamp: 2022-08-19 04:39:35.117713\n",
      "resetting env. episode 319, reward total was -19.0. running mean: -20.403548032276994, timestamp: 2022-08-19 04:39:37.989742\n",
      "resetting env. episode 320, reward total was -20.0. running mean: -20.399512551954224, timestamp: 2022-08-19 04:39:40.488760\n",
      "resetting env. episode 321, reward total was -21.0. running mean: -20.40551742643468, timestamp: 2022-08-19 04:39:42.552776\n",
      "resetting env. episode 322, reward total was -20.0. running mean: -20.401462252170333, timestamp: 2022-08-19 04:39:45.208799\n",
      "resetting env. episode 323, reward total was -21.0. running mean: -20.40744762964863, timestamp: 2022-08-19 04:39:47.162818\n",
      "resetting env. episode 324, reward total was -21.0. running mean: -20.413373153352143, timestamp: 2022-08-19 04:39:49.095830\n",
      "resetting env. episode 325, reward total was -21.0. running mean: -20.419239421818624, timestamp: 2022-08-19 04:39:51.850859\n",
      "resetting env. episode 326, reward total was -19.0. running mean: -20.40504702760044, timestamp: 2022-08-19 04:39:54.461880\n",
      "resetting env. episode 327, reward total was -21.0. running mean: -20.410996557324435, timestamp: 2022-08-19 04:39:56.517897\n",
      "resetting env. episode 328, reward total was -21.0. running mean: -20.41688659175119, timestamp: 2022-08-19 04:39:59.404919\n",
      "resetting env. episode 329, reward total was -21.0. running mean: -20.422717725833678, timestamp: 2022-08-19 04:40:01.922941\n",
      "resetting env. episode 330, reward total was -20.0. running mean: -20.418490548575342, timestamp: 2022-08-19 04:40:04.364959\n",
      "resetting env. episode 331, reward total was -21.0. running mean: -20.42430564308959, timestamp: 2022-08-19 04:40:06.477976\n",
      "resetting env. episode 332, reward total was -20.0. running mean: -20.42006258665869, timestamp: 2022-08-19 04:40:09.643006\n",
      "resetting env. episode 333, reward total was -20.0. running mean: -20.415861960792103, timestamp: 2022-08-19 04:40:11.954025\n",
      "resetting env. episode 334, reward total was -21.0. running mean: -20.421703341184184, timestamp: 2022-08-19 04:40:14.102040\n",
      "resetting env. episode 335, reward total was -21.0. running mean: -20.427486307772345, timestamp: 2022-08-19 04:40:16.708065\n",
      "resetting env. episode 336, reward total was -21.0. running mean: -20.43321144469462, timestamp: 2022-08-19 04:40:19.415088\n",
      "resetting env. episode 337, reward total was -19.0. running mean: -20.418879330247677, timestamp: 2022-08-19 04:40:22.169108\n",
      "resetting env. episode 338, reward total was -21.0. running mean: -20.4246905369452, timestamp: 2022-08-19 04:40:24.770129\n",
      "resetting env. episode 339, reward total was -19.0. running mean: -20.41044363157575, timestamp: 2022-08-19 04:40:28.238158\n",
      "resetting env. episode 340, reward total was -21.0. running mean: -20.416339195259994, timestamp: 2022-08-19 04:40:30.824180\n",
      "resetting env. episode 341, reward total was -21.0. running mean: -20.422175803307393, timestamp: 2022-08-19 04:40:32.962199\n",
      "resetting env. episode 342, reward total was -21.0. running mean: -20.42795404527432, timestamp: 2022-08-19 04:40:35.487218\n",
      "resetting env. episode 343, reward total was -20.0. running mean: -20.423674504821577, timestamp: 2022-08-19 04:40:38.070238\n",
      "resetting env. episode 344, reward total was -20.0. running mean: -20.41943775977336, timestamp: 2022-08-19 04:40:40.237258\n",
      "resetting env. episode 345, reward total was -20.0. running mean: -20.415243382175625, timestamp: 2022-08-19 04:40:42.784278\n",
      "resetting env. episode 346, reward total was -19.0. running mean: -20.40109094835387, timestamp: 2022-08-19 04:40:45.993305\n",
      "resetting env. episode 347, reward total was -20.0. running mean: -20.397080038870328, timestamp: 2022-08-19 04:40:49.042331\n",
      "resetting env. episode 348, reward total was -19.0. running mean: -20.383109238481627, timestamp: 2022-08-19 04:40:51.719356\n",
      "resetting env. episode 349, reward total was -20.0. running mean: -20.37927814609681, timestamp: 2022-08-19 04:40:54.428375\n",
      "resetting env. episode 350, reward total was -21.0. running mean: -20.38548536463584, timestamp: 2022-08-19 04:40:56.873397\n",
      "resetting env. episode 351, reward total was -20.0. running mean: -20.38163051098948, timestamp: 2022-08-19 04:40:59.521417\n",
      "resetting env. episode 352, reward total was -19.0. running mean: -20.367814205879586, timestamp: 2022-08-19 04:41:02.596442\n",
      "resetting env. episode 353, reward total was -21.0. running mean: -20.374136063820792, timestamp: 2022-08-19 04:41:05.211466\n",
      "resetting env. episode 354, reward total was -19.0. running mean: -20.360394703182585, timestamp: 2022-08-19 04:41:07.680489\n",
      "resetting env. episode 355, reward total was -20.0. running mean: -20.356790756150758, timestamp: 2022-08-19 04:41:10.003503\n",
      "resetting env. episode 356, reward total was -18.0. running mean: -20.33322284858925, timestamp: 2022-08-19 04:41:12.728047\n",
      "resetting env. episode 357, reward total was -21.0. running mean: -20.33989062010336, timestamp: 2022-08-19 04:41:15.080074\n",
      "resetting env. episode 358, reward total was -21.0. running mean: -20.346491713902328, timestamp: 2022-08-19 04:41:17.526087\n",
      "resetting env. episode 359, reward total was -21.0. running mean: -20.353026796763306, timestamp: 2022-08-19 04:41:20.208109\n",
      "resetting env. episode 360, reward total was -21.0. running mean: -20.359496528795674, timestamp: 2022-08-19 04:41:22.260125\n",
      "resetting env. episode 361, reward total was -20.0. running mean: -20.355901563507718, timestamp: 2022-08-19 04:41:24.620149\n",
      "resetting env. episode 362, reward total was -21.0. running mean: -20.362342547872643, timestamp: 2022-08-19 04:41:27.608171\n",
      "resetting env. episode 363, reward total was -20.0. running mean: -20.358719122393914, timestamp: 2022-08-19 04:41:31.388202\n",
      "resetting env. episode 364, reward total was -20.0. running mean: -20.355131931169975, timestamp: 2022-08-19 04:41:34.044227\n",
      "resetting env. episode 365, reward total was -21.0. running mean: -20.361580611858276, timestamp: 2022-08-19 04:41:36.116239\n",
      "resetting env. episode 366, reward total was -21.0. running mean: -20.367964805739692, timestamp: 2022-08-19 04:41:38.512263\n",
      "resetting env. episode 367, reward total was -21.0. running mean: -20.374285157682298, timestamp: 2022-08-19 04:41:40.649279\n",
      "resetting env. episode 368, reward total was -19.0. running mean: -20.360542306105476, timestamp: 2022-08-19 04:41:43.894306\n",
      "resetting env. episode 369, reward total was -20.0. running mean: -20.35693688304442, timestamp: 2022-08-19 04:41:47.314333\n",
      "resetting env. episode 370, reward total was -20.0. running mean: -20.353367514213975, timestamp: 2022-08-19 04:41:49.712350\n",
      "resetting env. episode 371, reward total was -21.0. running mean: -20.359833839071836, timestamp: 2022-08-19 04:41:52.077374\n",
      "resetting env. episode 372, reward total was -21.0. running mean: -20.366235500681118, timestamp: 2022-08-19 04:41:54.449392\n",
      "resetting env. episode 373, reward total was -20.0. running mean: -20.362573145674304, timestamp: 2022-08-19 04:41:57.057415\n",
      "resetting env. episode 374, reward total was -21.0. running mean: -20.368947414217562, timestamp: 2022-08-19 04:41:59.137430\n",
      "resetting env. episode 375, reward total was -21.0. running mean: -20.375257940075386, timestamp: 2022-08-19 04:42:02.232456\n",
      "resetting env. episode 376, reward total was -19.0. running mean: -20.361505360674634, timestamp: 2022-08-19 04:42:04.840480\n",
      "resetting env. episode 377, reward total was -20.0. running mean: -20.357890307067887, timestamp: 2022-08-19 04:42:07.339496\n",
      "resetting env. episode 378, reward total was -20.0. running mean: -20.354311403997208, timestamp: 2022-08-19 04:42:10.428522\n",
      "resetting env. episode 379, reward total was -20.0. running mean: -20.350768289957234, timestamp: 2022-08-19 04:42:12.882541\n",
      "resetting env. episode 380, reward total was -21.0. running mean: -20.35726060705766, timestamp: 2022-08-19 04:42:15.667563\n",
      "resetting env. episode 381, reward total was -20.0. running mean: -20.353688000987084, timestamp: 2022-08-19 04:42:18.250588\n",
      "resetting env. episode 382, reward total was -20.0. running mean: -20.350151120977213, timestamp: 2022-08-19 04:42:20.761609\n",
      "resetting env. episode 383, reward total was -21.0. running mean: -20.35664960976744, timestamp: 2022-08-19 04:42:23.073624\n",
      "resetting env. episode 384, reward total was -20.0. running mean: -20.353083113669765, timestamp: 2022-08-19 04:42:25.562647\n",
      "resetting env. episode 385, reward total was -21.0. running mean: -20.35955228253307, timestamp: 2022-08-19 04:42:27.491661\n",
      "resetting env. episode 386, reward total was -20.0. running mean: -20.355956759707738, timestamp: 2022-08-19 04:42:30.547687\n",
      "resetting env. episode 387, reward total was -21.0. running mean: -20.36239719211066, timestamp: 2022-08-19 04:42:33.186711\n",
      "resetting env. episode 388, reward total was -20.0. running mean: -20.35877322018955, timestamp: 2022-08-19 04:42:35.799728\n",
      "resetting env. episode 389, reward total was -19.0. running mean: -20.345185487987656, timestamp: 2022-08-19 04:42:38.481751\n",
      "resetting env. episode 390, reward total was -20.0. running mean: -20.34173363310778, timestamp: 2022-08-19 04:42:41.473776\n",
      "resetting env. episode 391, reward total was -21.0. running mean: -20.3483162967767, timestamp: 2022-08-19 04:42:43.868800\n",
      "resetting env. episode 392, reward total was -20.0. running mean: -20.344833133808933, timestamp: 2022-08-19 04:42:46.359816\n",
      "resetting env. episode 393, reward total was -21.0. running mean: -20.351384802470843, timestamp: 2022-08-19 04:42:48.601834\n",
      "resetting env. episode 394, reward total was -20.0. running mean: -20.347870954446133, timestamp: 2022-08-19 04:42:51.310857\n",
      "resetting env. episode 395, reward total was -21.0. running mean: -20.35439224490167, timestamp: 2022-08-19 04:42:53.831880\n",
      "resetting env. episode 396, reward total was -19.0. running mean: -20.340848322452654, timestamp: 2022-08-19 04:42:56.344899\n",
      "resetting env. episode 397, reward total was -21.0. running mean: -20.347439839228127, timestamp: 2022-08-19 04:42:58.647919\n",
      "resetting env. episode 398, reward total was -21.0. running mean: -20.353965440835847, timestamp: 2022-08-19 04:43:01.418940\n",
      "resetting env. episode 399, reward total was -21.0. running mean: -20.360425786427488, timestamp: 2022-08-19 04:43:04.166965\n",
      "resetting env. episode 400, reward total was -21.0. running mean: -20.366821528563214, timestamp: 2022-08-19 04:43:06.630981\n",
      "resetting env. episode 401, reward total was -21.0. running mean: -20.373153313277584, timestamp: 2022-08-19 04:43:08.819004\n",
      "resetting env. episode 402, reward total was -20.0. running mean: -20.36942178014481, timestamp: 2022-08-19 04:43:11.838027\n",
      "resetting env. episode 403, reward total was -21.0. running mean: -20.37572756234336, timestamp: 2022-08-19 04:43:14.222048\n",
      "resetting env. episode 404, reward total was -21.0. running mean: -20.381970286719927, timestamp: 2022-08-19 04:43:17.230593\n",
      "resetting env. episode 405, reward total was -20.0. running mean: -20.378150583852726, timestamp: 2022-08-19 04:43:19.670615\n",
      "resetting env. episode 406, reward total was -21.0. running mean: -20.3843690780142, timestamp: 2022-08-19 04:43:22.327159\n",
      "resetting env. episode 407, reward total was -21.0. running mean: -20.390525387234057, timestamp: 2022-08-19 04:43:25.483702\n",
      "resetting env. episode 408, reward total was -21.0. running mean: -20.396620133361715, timestamp: 2022-08-19 04:43:27.858696\n",
      "resetting env. episode 409, reward total was -21.0. running mean: -20.402653932028098, timestamp: 2022-08-19 04:43:30.517816\n",
      "resetting env. episode 410, reward total was -21.0. running mean: -20.408627392707817, timestamp: 2022-08-19 04:43:32.745838\n",
      "resetting env. episode 411, reward total was -21.0. running mean: -20.41454111878074, timestamp: 2022-08-19 04:43:35.259856\n",
      "resetting env. episode 412, reward total was -20.0. running mean: -20.410395707592933, timestamp: 2022-08-19 04:43:37.802876\n",
      "resetting env. episode 413, reward total was -21.0. running mean: -20.416291750517004, timestamp: 2022-08-19 04:43:40.247897\n",
      "resetting env. episode 414, reward total was -20.0. running mean: -20.412128833011835, timestamp: 2022-08-19 04:43:43.670921\n",
      "resetting env. episode 415, reward total was -20.0. running mean: -20.408007544681716, timestamp: 2022-08-19 04:43:46.326944\n",
      "resetting env. episode 416, reward total was -21.0. running mean: -20.4139274692349, timestamp: 2022-08-19 04:43:48.606966\n",
      "resetting env. episode 417, reward total was -20.0. running mean: -20.40978819454255, timestamp: 2022-08-19 04:43:51.174986\n",
      "resetting env. episode 418, reward total was -21.0. running mean: -20.415690312597125, timestamp: 2022-08-19 04:43:53.167999\n",
      "resetting env. episode 419, reward total was -21.0. running mean: -20.421533409471156, timestamp: 2022-08-19 04:43:55.729023\n",
      "resetting env. episode 420, reward total was -21.0. running mean: -20.427318075376444, timestamp: 2022-08-19 04:43:58.076038\n",
      "resetting env. episode 421, reward total was -21.0. running mean: -20.43304489462268, timestamp: 2022-08-19 04:44:00.721063\n",
      "resetting env. episode 422, reward total was -19.0. running mean: -20.418714445676454, timestamp: 2022-08-19 04:44:03.886089\n",
      "resetting env. episode 423, reward total was -20.0. running mean: -20.41452730121969, timestamp: 2022-08-19 04:44:07.253116\n",
      "resetting env. episode 424, reward total was -21.0. running mean: -20.42038202820749, timestamp: 2022-08-19 04:44:10.803145\n",
      "resetting env. episode 425, reward total was -21.0. running mean: -20.426178207925417, timestamp: 2022-08-19 04:44:13.580168\n",
      "resetting env. episode 426, reward total was -21.0. running mean: -20.431916425846165, timestamp: 2022-08-19 04:44:16.544187\n",
      "resetting env. episode 427, reward total was -20.0. running mean: -20.427597261587703, timestamp: 2022-08-19 04:44:19.916215\n",
      "resetting env. episode 428, reward total was -20.0. running mean: -20.423321288971824, timestamp: 2022-08-19 04:44:23.508247\n",
      "resetting env. episode 429, reward total was -21.0. running mean: -20.429088076082106, timestamp: 2022-08-19 04:44:26.883273\n",
      "resetting env. episode 430, reward total was -21.0. running mean: -20.434797195321284, timestamp: 2022-08-19 04:44:30.514305\n",
      "resetting env. episode 431, reward total was -20.0. running mean: -20.430449223368072, timestamp: 2022-08-19 04:44:34.885341\n",
      "resetting env. episode 432, reward total was -21.0. running mean: -20.43614473113439, timestamp: 2022-08-19 04:44:37.951364\n",
      "resetting env. episode 433, reward total was -20.0. running mean: -20.431783283823044, timestamp: 2022-08-19 04:44:40.326383\n",
      "resetting env. episode 434, reward total was -21.0. running mean: -20.437465450984813, timestamp: 2022-08-19 04:44:42.710403\n",
      "resetting env. episode 435, reward total was -21.0. running mean: -20.443090796474966, timestamp: 2022-08-19 04:44:45.271424\n",
      "resetting env. episode 436, reward total was -21.0. running mean: -20.448659888510218, timestamp: 2022-08-19 04:44:48.137448\n",
      "resetting env. episode 437, reward total was -20.0. running mean: -20.444173289625116, timestamp: 2022-08-19 04:44:51.083475\n",
      "resetting env. episode 438, reward total was -20.0. running mean: -20.439731556728862, timestamp: 2022-08-19 04:44:53.870499\n",
      "resetting env. episode 439, reward total was -21.0. running mean: -20.445334241161575, timestamp: 2022-08-19 04:44:56.380517\n",
      "resetting env. episode 440, reward total was -21.0. running mean: -20.45088089874996, timestamp: 2022-08-19 04:44:58.779536\n",
      "resetting env. episode 441, reward total was -20.0. running mean: -20.44637208976246, timestamp: 2022-08-19 04:45:01.106560\n",
      "resetting env. episode 442, reward total was -21.0. running mean: -20.451908368864835, timestamp: 2022-08-19 04:45:03.459578\n",
      "resetting env. episode 443, reward total was -20.0. running mean: -20.447389285176186, timestamp: 2022-08-19 04:45:06.725608\n",
      "resetting env. episode 444, reward total was -21.0. running mean: -20.452915392324424, timestamp: 2022-08-19 04:45:09.932633\n",
      "resetting env. episode 445, reward total was -21.0. running mean: -20.458386238401182, timestamp: 2022-08-19 04:45:12.336655\n",
      "resetting env. episode 446, reward total was -18.0. running mean: -20.43380237601717, timestamp: 2022-08-19 04:45:15.369681\n",
      "resetting env. episode 447, reward total was -21.0. running mean: -20.439464352256998, timestamp: 2022-08-19 04:45:17.975701\n",
      "resetting env. episode 448, reward total was -18.0. running mean: -20.41506970873443, timestamp: 2022-08-19 04:45:21.283733\n",
      "resetting env. episode 449, reward total was -19.0. running mean: -20.400919011647087, timestamp: 2022-08-19 04:45:23.995753\n",
      "resetting env. episode 450, reward total was -20.0. running mean: -20.396909821530617, timestamp: 2022-08-19 04:45:27.187780\n",
      "resetting env. episode 451, reward total was -20.0. running mean: -20.39294072331531, timestamp: 2022-08-19 04:45:30.487810\n",
      "resetting env. episode 452, reward total was -19.0. running mean: -20.379011316082156, timestamp: 2022-08-19 04:45:33.518836\n",
      "resetting env. episode 453, reward total was -19.0. running mean: -20.365221202921337, timestamp: 2022-08-19 04:45:36.058859\n",
      "resetting env. episode 454, reward total was -21.0. running mean: -20.371568990892126, timestamp: 2022-08-19 04:45:38.723884\n",
      "resetting env. episode 455, reward total was -20.0. running mean: -20.367853300983203, timestamp: 2022-08-19 04:45:41.116903\n",
      "resetting env. episode 456, reward total was -21.0. running mean: -20.374174767973372, timestamp: 2022-08-19 04:45:43.324922\n",
      "resetting env. episode 457, reward total was -21.0. running mean: -20.38043302029364, timestamp: 2022-08-19 04:45:45.604945\n",
      "resetting env. episode 458, reward total was -20.0. running mean: -20.376628690090705, timestamp: 2022-08-19 04:45:48.422967\n",
      "resetting env. episode 459, reward total was -21.0. running mean: -20.382862403189797, timestamp: 2022-08-19 04:45:51.016989\n",
      "resetting env. episode 460, reward total was -21.0. running mean: -20.3890337791579, timestamp: 2022-08-19 04:45:54.227018\n",
      "resetting env. episode 461, reward total was -21.0. running mean: -20.39514344136632, timestamp: 2022-08-19 04:45:57.047046\n",
      "resetting env. episode 462, reward total was -21.0. running mean: -20.401192006952655, timestamp: 2022-08-19 04:45:59.048064\n",
      "resetting env. episode 463, reward total was -21.0. running mean: -20.40718008688313, timestamp: 2022-08-19 04:46:00.961077\n",
      "resetting env. episode 464, reward total was -20.0. running mean: -20.403108286014298, timestamp: 2022-08-19 04:46:03.493099\n",
      "resetting env. episode 465, reward total was -21.0. running mean: -20.409077203154155, timestamp: 2022-08-19 04:46:05.980120\n",
      "resetting env. episode 466, reward total was -21.0. running mean: -20.414986431122614, timestamp: 2022-08-19 04:46:08.779149\n",
      "resetting env. episode 467, reward total was -20.0. running mean: -20.410836566811387, timestamp: 2022-08-19 04:46:11.666170\n",
      "resetting env. episode 468, reward total was -21.0. running mean: -20.416728201143275, timestamp: 2022-08-19 04:46:14.110192\n",
      "resetting env. episode 469, reward total was -21.0. running mean: -20.422560919131843, timestamp: 2022-08-19 04:46:16.646217\n",
      "resetting env. episode 470, reward total was -21.0. running mean: -20.428335309940525, timestamp: 2022-08-19 04:46:19.163237\n",
      "resetting env. episode 471, reward total was -21.0. running mean: -20.43405195684112, timestamp: 2022-08-19 04:46:21.806261\n",
      "resetting env. episode 472, reward total was -21.0. running mean: -20.43971143727271, timestamp: 2022-08-19 04:46:24.093282\n",
      "resetting env. episode 473, reward total was -20.0. running mean: -20.43531432289998, timestamp: 2022-08-19 04:46:26.879308\n",
      "resetting env. episode 474, reward total was -21.0. running mean: -20.440961179670982, timestamp: 2022-08-19 04:46:29.511331\n",
      "resetting env. episode 475, reward total was -20.0. running mean: -20.43655156787427, timestamp: 2022-08-19 04:46:32.205357\n",
      "resetting env. episode 476, reward total was -20.0. running mean: -20.43218605219553, timestamp: 2022-08-19 04:46:34.773377\n",
      "resetting env. episode 477, reward total was -19.0. running mean: -20.417864191673576, timestamp: 2022-08-19 04:46:37.570406\n",
      "resetting env. episode 478, reward total was -20.0. running mean: -20.41368554975684, timestamp: 2022-08-19 04:46:40.166425\n",
      "resetting env. episode 479, reward total was -21.0. running mean: -20.41954869425927, timestamp: 2022-08-19 04:46:42.872449\n",
      "resetting env. episode 480, reward total was -20.0. running mean: -20.415353207316677, timestamp: 2022-08-19 04:46:46.215481\n",
      "resetting env. episode 481, reward total was -20.0. running mean: -20.41119967524351, timestamp: 2022-08-19 04:46:49.374509\n",
      "resetting env. episode 482, reward total was -20.0. running mean: -20.407087678491074, timestamp: 2022-08-19 04:46:52.447539\n",
      "resetting env. episode 483, reward total was -21.0. running mean: -20.413016801706164, timestamp: 2022-08-19 04:46:55.671568\n",
      "resetting env. episode 484, reward total was -21.0. running mean: -20.4188866336891, timestamp: 2022-08-19 04:46:59.661603\n",
      "resetting env. episode 485, reward total was -21.0. running mean: -20.42469776735221, timestamp: 2022-08-19 04:47:02.499626\n",
      "resetting env. episode 486, reward total was -21.0. running mean: -20.430450789678687, timestamp: 2022-08-19 04:47:04.875649\n",
      "resetting env. episode 487, reward total was -20.0. running mean: -20.4261462817819, timestamp: 2022-08-19 04:47:07.284673\n",
      "resetting env. episode 488, reward total was -20.0. running mean: -20.42188481896408, timestamp: 2022-08-19 04:47:09.417692\n",
      "resetting env. episode 489, reward total was -21.0. running mean: -20.42766597077444, timestamp: 2022-08-19 04:47:11.607711\n",
      "resetting env. episode 490, reward total was -20.0. running mean: -20.423389311066696, timestamp: 2022-08-19 04:47:14.353735\n",
      "resetting env. episode 491, reward total was -21.0. running mean: -20.42915541795603, timestamp: 2022-08-19 04:47:16.491279\n",
      "resetting env. episode 492, reward total was -21.0. running mean: -20.434863863776467, timestamp: 2022-08-19 04:47:18.577298\n",
      "resetting env. episode 493, reward total was -20.0. running mean: -20.430515225138702, timestamp: 2022-08-19 04:47:22.011338\n",
      "resetting env. episode 494, reward total was -20.0. running mean: -20.426210072887315, timestamp: 2022-08-19 04:47:24.751195\n",
      "resetting env. episode 495, reward total was -21.0. running mean: -20.431947972158444, timestamp: 2022-08-19 04:47:26.851002\n",
      "resetting env. episode 496, reward total was -19.0. running mean: -20.41762849243686, timestamp: 2022-08-19 04:47:29.751416\n",
      "resetting env. episode 497, reward total was -21.0. running mean: -20.423452207512494, timestamp: 2022-08-19 04:47:32.188967\n",
      "resetting env. episode 498, reward total was -20.0. running mean: -20.419217685437367, timestamp: 2022-08-19 04:47:34.642084\n",
      "resetting env. episode 499, reward total was -20.0. running mean: -20.415025508582993, timestamp: 2022-08-19 04:47:36.953779\n",
      "resetting env. episode 500, reward total was -21.0. running mean: -20.42087525349716, timestamp: 2022-08-19 04:47:41.170565\n",
      "resetting env. episode 501, reward total was -21.0. running mean: -20.42666650096219, timestamp: 2022-08-19 04:47:43.670592\n",
      "resetting env. episode 502, reward total was -21.0. running mean: -20.43239983595257, timestamp: 2022-08-19 04:47:46.080612\n",
      "resetting env. episode 503, reward total was -21.0. running mean: -20.438075837593043, timestamp: 2022-08-19 04:47:48.204637\n",
      "resetting env. episode 504, reward total was -19.0. running mean: -20.423695079217115, timestamp: 2022-08-19 04:47:51.078659\n",
      "resetting env. episode 505, reward total was -21.0. running mean: -20.429458128424944, timestamp: 2022-08-19 04:47:53.741682\n",
      "resetting env. episode 506, reward total was -20.0. running mean: -20.425163547140695, timestamp: 2022-08-19 04:47:56.531712\n",
      "resetting env. episode 507, reward total was -20.0. running mean: -20.420911911669286, timestamp: 2022-08-19 04:47:59.009730\n",
      "resetting env. episode 508, reward total was -21.0. running mean: -20.426702792552593, timestamp: 2022-08-19 04:48:01.709756\n",
      "resetting env. episode 509, reward total was -21.0. running mean: -20.43243576462707, timestamp: 2022-08-19 04:48:04.211779\n",
      "resetting env. episode 510, reward total was -21.0. running mean: -20.4381114069808, timestamp: 2022-08-19 04:48:07.119809\n",
      "resetting env. episode 511, reward total was -20.0. running mean: -20.43373029291099, timestamp: 2022-08-19 04:48:10.364838\n",
      "resetting env. episode 512, reward total was -21.0. running mean: -20.43939298998188, timestamp: 2022-08-19 04:48:13.000861\n",
      "resetting env. episode 513, reward total was -21.0. running mean: -20.44499906008206, timestamp: 2022-08-19 04:48:15.540886\n",
      "resetting env. episode 514, reward total was -21.0. running mean: -20.45054906948124, timestamp: 2022-08-19 04:48:17.903910\n",
      "resetting env. episode 515, reward total was -20.0. running mean: -20.446043578786426, timestamp: 2022-08-19 04:48:20.661932\n",
      "resetting env. episode 516, reward total was -21.0. running mean: -20.45158314299856, timestamp: 2022-08-19 04:48:23.297957\n",
      "resetting env. episode 517, reward total was -20.0. running mean: -20.447067311568574, timestamp: 2022-08-19 04:48:25.460978\n",
      "resetting env. episode 518, reward total was -21.0. running mean: -20.45259663845289, timestamp: 2022-08-19 04:48:27.734001\n",
      "resetting env. episode 519, reward total was -19.0. running mean: -20.43807067206836, timestamp: 2022-08-19 04:48:31.063032\n",
      "resetting env. episode 520, reward total was -20.0. running mean: -20.433689965347675, timestamp: 2022-08-19 04:48:33.771057\n",
      "resetting env. episode 521, reward total was -20.0. running mean: -20.429353065694198, timestamp: 2022-08-19 04:48:36.258078\n",
      "resetting env. episode 522, reward total was -19.0. running mean: -20.41505953503726, timestamp: 2022-08-19 04:48:39.187109\n",
      "resetting env. episode 523, reward total was -20.0. running mean: -20.410908939686884, timestamp: 2022-08-19 04:48:42.067134\n",
      "resetting env. episode 524, reward total was -20.0. running mean: -20.406799850290014, timestamp: 2022-08-19 04:48:44.580162\n",
      "resetting env. episode 525, reward total was -21.0. running mean: -20.412731851787115, timestamp: 2022-08-19 04:48:46.557174\n",
      "resetting env. episode 526, reward total was -21.0. running mean: -20.418604533269246, timestamp: 2022-08-19 04:48:49.623207\n",
      "resetting env. episode 527, reward total was -21.0. running mean: -20.424418487936553, timestamp: 2022-08-19 04:48:52.284229\n",
      "resetting env. episode 528, reward total was -19.0. running mean: -20.41017430305719, timestamp: 2022-08-19 04:48:55.311257\n",
      "resetting env. episode 529, reward total was -20.0. running mean: -20.406072560026615, timestamp: 2022-08-19 04:48:58.148286\n",
      "resetting env. episode 530, reward total was -20.0. running mean: -20.402011834426347, timestamp: 2022-08-19 04:49:01.016311\n",
      "resetting env. episode 531, reward total was -21.0. running mean: -20.407991716082083, timestamp: 2022-08-19 04:49:03.386333\n",
      "resetting env. episode 532, reward total was -21.0. running mean: -20.413911798921262, timestamp: 2022-08-19 04:49:05.786358\n",
      "resetting env. episode 533, reward total was -20.0. running mean: -20.409772680932047, timestamp: 2022-08-19 04:49:09.000394\n",
      "resetting env. episode 534, reward total was -20.0. running mean: -20.405674954122727, timestamp: 2022-08-19 04:49:11.553412\n",
      "resetting env. episode 535, reward total was -21.0. running mean: -20.4116182045815, timestamp: 2022-08-19 04:49:14.730438\n",
      "resetting env. episode 536, reward total was -21.0. running mean: -20.417502022535686, timestamp: 2022-08-19 04:49:17.681472\n",
      "resetting env. episode 537, reward total was -18.0. running mean: -20.39332700231033, timestamp: 2022-08-19 04:49:20.813499\n",
      "resetting env. episode 538, reward total was -20.0. running mean: -20.389393732287225, timestamp: 2022-08-19 04:49:23.564522\n",
      "resetting env. episode 539, reward total was -21.0. running mean: -20.395499794964355, timestamp: 2022-08-19 04:49:25.538543\n",
      "resetting env. episode 540, reward total was -19.0. running mean: -20.381544797014712, timestamp: 2022-08-19 04:49:28.337566\n",
      "resetting env. episode 541, reward total was -21.0. running mean: -20.387729349044566, timestamp: 2022-08-19 04:49:30.733592\n",
      "resetting env. episode 542, reward total was -20.0. running mean: -20.38385205555412, timestamp: 2022-08-19 04:49:32.991611\n",
      "resetting env. episode 543, reward total was -21.0. running mean: -20.390013534998577, timestamp: 2022-08-19 04:49:35.137631\n",
      "resetting env. episode 544, reward total was -21.0. running mean: -20.39611339964859, timestamp: 2022-08-19 04:49:37.734657\n",
      "resetting env. episode 545, reward total was -21.0. running mean: -20.402152265652106, timestamp: 2022-08-19 04:49:40.166680\n",
      "resetting env. episode 546, reward total was -20.0. running mean: -20.398130742995583, timestamp: 2022-08-19 04:49:42.951710\n",
      "resetting env. episode 547, reward total was -19.0. running mean: -20.38414943556563, timestamp: 2022-08-19 04:49:45.540733\n",
      "resetting env. episode 548, reward total was -19.0. running mean: -20.370307941209973, timestamp: 2022-08-19 04:49:47.976756\n",
      "resetting env. episode 549, reward total was -21.0. running mean: -20.376604861797873, timestamp: 2022-08-19 04:49:50.093773\n",
      "resetting env. episode 550, reward total was -20.0. running mean: -20.372838813179893, timestamp: 2022-08-19 04:49:52.857801\n",
      "resetting env. episode 551, reward total was -20.0. running mean: -20.369110425048092, timestamp: 2022-08-19 04:49:56.026835\n",
      "resetting env. episode 552, reward total was -20.0. running mean: -20.36541932079761, timestamp: 2022-08-19 04:49:59.234862\n",
      "resetting env. episode 553, reward total was -19.0. running mean: -20.351765127589633, timestamp: 2022-08-19 04:50:02.226897\n",
      "resetting env. episode 554, reward total was -20.0. running mean: -20.348247476313738, timestamp: 2022-08-19 04:50:04.729918\n",
      "resetting env. episode 555, reward total was -21.0. running mean: -20.3547650015506, timestamp: 2022-08-19 04:50:06.973937\n",
      "resetting env. episode 556, reward total was -20.0. running mean: -20.351217351535094, timestamp: 2022-08-19 04:50:09.494961\n",
      "resetting env. episode 557, reward total was -18.0. running mean: -20.327705178019745, timestamp: 2022-08-19 04:50:12.843994\n",
      "resetting env. episode 558, reward total was -19.0. running mean: -20.314428126239548, timestamp: 2022-08-19 04:50:15.396018\n",
      "resetting env. episode 559, reward total was -21.0. running mean: -20.321283844977152, timestamp: 2022-08-19 04:50:17.634039\n",
      "resetting env. episode 560, reward total was -21.0. running mean: -20.32807100652738, timestamp: 2022-08-19 04:50:20.138066\n",
      "resetting env. episode 561, reward total was -20.0. running mean: -20.324790296462105, timestamp: 2022-08-19 04:50:22.632086\n",
      "resetting env. episode 562, reward total was -20.0. running mean: -20.321542393497484, timestamp: 2022-08-19 04:50:25.571110\n",
      "resetting env. episode 563, reward total was -21.0. running mean: -20.32832696956251, timestamp: 2022-08-19 04:50:27.967136\n",
      "resetting env. episode 564, reward total was -21.0. running mean: -20.335043699866887, timestamp: 2022-08-19 04:50:30.545165\n",
      "resetting env. episode 565, reward total was -20.0. running mean: -20.331693262868217, timestamp: 2022-08-19 04:50:33.779189\n",
      "resetting env. episode 566, reward total was -20.0. running mean: -20.328376330239536, timestamp: 2022-08-19 04:50:36.089212\n",
      "resetting env. episode 567, reward total was -21.0. running mean: -20.335092566937142, timestamp: 2022-08-19 04:50:38.318236\n",
      "resetting env. episode 568, reward total was -20.0. running mean: -20.33174164126777, timestamp: 2022-08-19 04:50:40.621255\n",
      "resetting env. episode 569, reward total was -18.0. running mean: -20.30842422485509, timestamp: 2022-08-19 04:50:43.366282\n",
      "resetting env. episode 570, reward total was -21.0. running mean: -20.31533998260654, timestamp: 2022-08-19 04:50:45.522304\n",
      "resetting env. episode 571, reward total was -21.0. running mean: -20.32218658278048, timestamp: 2022-08-19 04:50:47.873324\n",
      "resetting env. episode 572, reward total was -19.0. running mean: -20.308964716952676, timestamp: 2022-08-19 04:50:50.501352\n",
      "resetting env. episode 573, reward total was -19.0. running mean: -20.29587506978315, timestamp: 2022-08-19 04:50:54.466389\n",
      "resetting env. episode 574, reward total was -21.0. running mean: -20.30291631908532, timestamp: 2022-08-19 04:50:56.608408\n",
      "resetting env. episode 575, reward total was -21.0. running mean: -20.30988715589447, timestamp: 2022-08-19 04:50:58.605429\n",
      "resetting env. episode 576, reward total was -21.0. running mean: -20.316788284335523, timestamp: 2022-08-19 04:51:01.162457\n",
      "resetting env. episode 577, reward total was -21.0. running mean: -20.323620401492168, timestamp: 2022-08-19 04:51:04.250483\n",
      "resetting env. episode 578, reward total was -20.0. running mean: -20.320384197477246, timestamp: 2022-08-19 04:51:06.602504\n",
      "resetting env. episode 579, reward total was -19.0. running mean: -20.307180355502474, timestamp: 2022-08-19 04:51:09.199532\n",
      "resetting env. episode 580, reward total was -20.0. running mean: -20.304108551947447, timestamp: 2022-08-19 04:51:12.246559\n",
      "resetting env. episode 581, reward total was -20.0. running mean: -20.301067466427973, timestamp: 2022-08-19 04:51:15.090592\n",
      "resetting env. episode 582, reward total was -20.0. running mean: -20.298056791763692, timestamp: 2022-08-19 04:51:17.430609\n",
      "resetting env. episode 583, reward total was -21.0. running mean: -20.305076223846054, timestamp: 2022-08-19 04:51:20.241636\n",
      "resetting env. episode 584, reward total was -21.0. running mean: -20.312025461607593, timestamp: 2022-08-19 04:51:22.622660\n",
      "resetting env. episode 585, reward total was -20.0. running mean: -20.308905206991515, timestamp: 2022-08-19 04:51:24.949692\n",
      "resetting env. episode 586, reward total was -21.0. running mean: -20.3158161549216, timestamp: 2022-08-19 04:51:27.609706\n",
      "resetting env. episode 587, reward total was -21.0. running mean: -20.322657993372385, timestamp: 2022-08-19 04:51:30.135742\n",
      "resetting env. episode 588, reward total was -19.0. running mean: -20.309431413438663, timestamp: 2022-08-19 04:51:32.982769\n",
      "resetting env. episode 589, reward total was -20.0. running mean: -20.306337099304276, timestamp: 2022-08-19 04:51:35.460786\n",
      "resetting env. episode 590, reward total was -20.0. running mean: -20.303273728311233, timestamp: 2022-08-19 04:51:37.922807\n",
      "resetting env. episode 591, reward total was -21.0. running mean: -20.31024099102812, timestamp: 2022-08-19 04:51:40.413829\n",
      "resetting env. episode 592, reward total was -20.0. running mean: -20.307138581117837, timestamp: 2022-08-19 04:51:42.861854\n",
      "resetting env. episode 593, reward total was -20.0. running mean: -20.304067195306658, timestamp: 2022-08-19 04:51:45.070874\n",
      "resetting env. episode 594, reward total was -21.0. running mean: -20.311026523353593, timestamp: 2022-08-19 04:51:47.193896\n",
      "resetting env. episode 595, reward total was -20.0. running mean: -20.307916258120056, timestamp: 2022-08-19 04:51:49.825923\n",
      "resetting env. episode 596, reward total was -21.0. running mean: -20.314837095538856, timestamp: 2022-08-19 04:51:51.984945\n",
      "resetting env. episode 597, reward total was -21.0. running mean: -20.321688724583467, timestamp: 2022-08-19 04:51:53.969961\n",
      "resetting env. episode 598, reward total was -21.0. running mean: -20.328471837337634, timestamp: 2022-08-19 04:51:56.162981\n",
      "resetting env. episode 599, reward total was -20.0. running mean: -20.32518711896426, timestamp: 2022-08-19 04:51:58.999008\n",
      "resetting env. episode 600, reward total was -21.0. running mean: -20.331935247774616, timestamp: 2022-08-19 04:52:02.096037\n",
      "resetting env. episode 601, reward total was -21.0. running mean: -20.338615895296872, timestamp: 2022-08-19 04:52:04.390060\n",
      "resetting env. episode 602, reward total was -18.0. running mean: -20.315229736343902, timestamp: 2022-08-19 04:52:07.477090\n",
      "resetting env. episode 603, reward total was -20.0. running mean: -20.312077438980463, timestamp: 2022-08-19 04:52:10.431118\n",
      "resetting env. episode 604, reward total was -20.0. running mean: -20.308956664590657, timestamp: 2022-08-19 04:52:13.159147\n",
      "resetting env. episode 605, reward total was -21.0. running mean: -20.31586709794475, timestamp: 2022-08-19 04:52:15.077162\n",
      "resetting env. episode 606, reward total was -20.0. running mean: -20.3127084269653, timestamp: 2022-08-19 04:52:17.560186\n",
      "resetting env. episode 607, reward total was -21.0. running mean: -20.31958134269565, timestamp: 2022-08-19 04:52:20.221220\n",
      "resetting env. episode 608, reward total was -21.0. running mean: -20.326385529268695, timestamp: 2022-08-19 04:52:23.145239\n",
      "resetting env. episode 609, reward total was -20.0. running mean: -20.323121673976008, timestamp: 2022-08-19 04:52:25.862266\n",
      "resetting env. episode 610, reward total was -20.0. running mean: -20.319890457236248, timestamp: 2022-08-19 04:52:28.550291\n",
      "resetting env. episode 611, reward total was -21.0. running mean: -20.326691552663885, timestamp: 2022-08-19 04:52:30.713313\n",
      "resetting env. episode 612, reward total was -21.0. running mean: -20.333424637137245, timestamp: 2022-08-19 04:52:33.406339\n",
      "resetting env. episode 613, reward total was -21.0. running mean: -20.340090390765873, timestamp: 2022-08-19 04:52:36.055363\n",
      "resetting env. episode 614, reward total was -18.0. running mean: -20.316689486858213, timestamp: 2022-08-19 04:52:39.640397\n",
      "resetting env. episode 615, reward total was -20.0. running mean: -20.313522591989628, timestamp: 2022-08-19 04:52:42.250423\n",
      "resetting env. episode 616, reward total was -21.0. running mean: -20.32038736606973, timestamp: 2022-08-19 04:52:44.590445\n",
      "resetting env. episode 617, reward total was -19.0. running mean: -20.307183492409035, timestamp: 2022-08-19 04:52:47.562473\n",
      "resetting env. episode 618, reward total was -20.0. running mean: -20.304111657484942, timestamp: 2022-08-19 04:52:50.197508\n",
      "resetting env. episode 619, reward total was -19.0. running mean: -20.291070540910095, timestamp: 2022-08-19 04:52:54.462544\n",
      "resetting env. episode 620, reward total was -18.0. running mean: -20.26815983550099, timestamp: 2022-08-19 04:52:58.125577\n",
      "resetting env. episode 621, reward total was -18.0. running mean: -20.24547823714598, timestamp: 2022-08-19 04:53:01.455605\n",
      "resetting env. episode 622, reward total was -20.0. running mean: -20.24302345477452, timestamp: 2022-08-19 04:53:03.573628\n",
      "resetting env. episode 623, reward total was -19.0. running mean: -20.230593220226776, timestamp: 2022-08-19 04:53:06.556654\n",
      "resetting env. episode 624, reward total was -19.0. running mean: -20.21828728802451, timestamp: 2022-08-19 04:53:09.768696\n",
      "resetting env. episode 625, reward total was -20.0. running mean: -20.21610441514426, timestamp: 2022-08-19 04:53:12.520711\n",
      "resetting env. episode 626, reward total was -21.0. running mean: -20.22394337099282, timestamp: 2022-08-19 04:53:14.464733\n",
      "resetting env. episode 627, reward total was -21.0. running mean: -20.231703937282894, timestamp: 2022-08-19 04:53:16.424748\n",
      "resetting env. episode 628, reward total was -20.0. running mean: -20.229386897910064, timestamp: 2022-08-19 04:53:19.550780\n",
      "resetting env. episode 629, reward total was -21.0. running mean: -20.237093028930964, timestamp: 2022-08-19 04:53:21.480799\n",
      "resetting env. episode 630, reward total was -19.0. running mean: -20.224722098641656, timestamp: 2022-08-19 04:53:25.068833\n",
      "resetting env. episode 631, reward total was -20.0. running mean: -20.222474877655237, timestamp: 2022-08-19 04:53:28.302861\n",
      "resetting env. episode 632, reward total was -20.0. running mean: -20.220250128878686, timestamp: 2022-08-19 04:53:31.342889\n",
      "resetting env. episode 633, reward total was -21.0. running mean: -20.2280476275899, timestamp: 2022-08-19 04:53:33.970913\n",
      "resetting env. episode 634, reward total was -17.0. running mean: -20.195767151314, timestamp: 2022-08-19 04:53:37.695950\n",
      "resetting env. episode 635, reward total was -21.0. running mean: -20.203809479800864, timestamp: 2022-08-19 04:53:40.199973\n",
      "resetting env. episode 636, reward total was -21.0. running mean: -20.211771385002855, timestamp: 2022-08-19 04:53:42.738996\n",
      "resetting env. episode 637, reward total was -21.0. running mean: -20.219653671152827, timestamp: 2022-08-19 04:53:45.608024\n",
      "resetting env. episode 638, reward total was -21.0. running mean: -20.2274571344413, timestamp: 2022-08-19 04:53:47.733044\n",
      "resetting env. episode 639, reward total was -20.0. running mean: -20.225182563096883, timestamp: 2022-08-19 04:53:50.686072\n",
      "resetting env. episode 640, reward total was -19.0. running mean: -20.212930737465914, timestamp: 2022-08-19 04:53:54.367107\n",
      "resetting env. episode 641, reward total was -21.0. running mean: -20.220801430091257, timestamp: 2022-08-19 04:53:57.154137\n",
      "resetting env. episode 642, reward total was -21.0. running mean: -20.228593415790346, timestamp: 2022-08-19 04:53:59.894161\n",
      "resetting env. episode 643, reward total was -20.0. running mean: -20.226307481632443, timestamp: 2022-08-19 04:54:02.872191\n",
      "resetting env. episode 644, reward total was -21.0. running mean: -20.234044406816118, timestamp: 2022-08-19 04:54:05.466214\n",
      "resetting env. episode 645, reward total was -20.0. running mean: -20.231703962747954, timestamp: 2022-08-19 04:54:08.168238\n",
      "resetting env. episode 646, reward total was -21.0. running mean: -20.239386923120474, timestamp: 2022-08-19 04:54:10.806268\n",
      "resetting env. episode 647, reward total was -21.0. running mean: -20.24699305388927, timestamp: 2022-08-19 04:54:13.241290\n",
      "resetting env. episode 648, reward total was -21.0. running mean: -20.254523123350378, timestamp: 2022-08-19 04:54:15.237307\n",
      "resetting env. episode 649, reward total was -21.0. running mean: -20.261977892116875, timestamp: 2022-08-19 04:54:17.354327\n",
      "resetting env. episode 650, reward total was -21.0. running mean: -20.269358113195707, timestamp: 2022-08-19 04:54:20.399356\n",
      "resetting env. episode 651, reward total was -21.0. running mean: -20.27666453206375, timestamp: 2022-08-19 04:54:22.872383\n",
      "resetting env. episode 652, reward total was -20.0. running mean: -20.273897886743114, timestamp: 2022-08-19 04:54:25.534408\n",
      "resetting env. episode 653, reward total was -20.0. running mean: -20.271158907875684, timestamp: 2022-08-19 04:54:28.740435\n",
      "resetting env. episode 654, reward total was -20.0. running mean: -20.268447318796927, timestamp: 2022-08-19 04:54:31.397463\n",
      "resetting env. episode 655, reward total was -18.0. running mean: -20.245762845608958, timestamp: 2022-08-19 04:54:34.836493\n",
      "resetting env. episode 656, reward total was -21.0. running mean: -20.253305217152867, timestamp: 2022-08-19 04:54:37.518522\n",
      "resetting env. episode 657, reward total was -21.0. running mean: -20.26077216498134, timestamp: 2022-08-19 04:54:39.767540\n",
      "resetting env. episode 658, reward total was -21.0. running mean: -20.26816444333153, timestamp: 2022-08-19 04:54:41.734562\n",
      "resetting env. episode 659, reward total was -21.0. running mean: -20.275482798898214, timestamp: 2022-08-19 04:54:44.250584\n",
      "resetting env. episode 660, reward total was -20.0. running mean: -20.27272797090923, timestamp: 2022-08-19 04:54:47.754619\n",
      "resetting env. episode 661, reward total was -20.0. running mean: -20.27000069120014, timestamp: 2022-08-19 04:54:51.561655\n",
      "resetting env. episode 662, reward total was -17.0. running mean: -20.23730068428814, timestamp: 2022-08-19 04:54:54.796688\n",
      "resetting env. episode 663, reward total was -20.0. running mean: -20.234927677445256, timestamp: 2022-08-19 04:54:58.023713\n",
      "resetting env. episode 664, reward total was -21.0. running mean: -20.242578400670805, timestamp: 2022-08-19 04:55:00.658743\n",
      "resetting env. episode 665, reward total was -21.0. running mean: -20.2501526166641, timestamp: 2022-08-19 04:55:02.831762\n",
      "resetting env. episode 666, reward total was -20.0. running mean: -20.247651090497456, timestamp: 2022-08-19 04:55:05.597789\n",
      "resetting env. episode 667, reward total was -21.0. running mean: -20.25517457959248, timestamp: 2022-08-19 04:55:08.198814\n",
      "resetting env. episode 668, reward total was -21.0. running mean: -20.262622833796556, timestamp: 2022-08-19 04:55:11.075837\n",
      "resetting env. episode 669, reward total was -21.0. running mean: -20.26999660545859, timestamp: 2022-08-19 04:55:13.487862\n",
      "resetting env. episode 670, reward total was -21.0. running mean: -20.277296639404007, timestamp: 2022-08-19 04:55:15.852885\n",
      "resetting env. episode 671, reward total was -20.0. running mean: -20.274523673009966, timestamp: 2022-08-19 04:55:18.342908\n",
      "resetting env. episode 672, reward total was -21.0. running mean: -20.28177843627987, timestamp: 2022-08-19 04:55:20.858934\n",
      "resetting env. episode 673, reward total was -21.0. running mean: -20.28896065191707, timestamp: 2022-08-19 04:55:23.281954\n",
      "resetting env. episode 674, reward total was -20.0. running mean: -20.286071045397897, timestamp: 2022-08-19 04:55:26.217984\n",
      "resetting env. episode 675, reward total was -21.0. running mean: -20.293210334943918, timestamp: 2022-08-19 04:55:29.395012\n",
      "resetting env. episode 676, reward total was -20.0. running mean: -20.290278231594478, timestamp: 2022-08-19 04:55:32.203038\n",
      "resetting env. episode 677, reward total was -21.0. running mean: -20.297375449278533, timestamp: 2022-08-19 04:55:34.303059\n",
      "resetting env. episode 678, reward total was -20.0. running mean: -20.294401694785748, timestamp: 2022-08-19 04:55:37.005087\n",
      "resetting env. episode 679, reward total was -20.0. running mean: -20.29145767783789, timestamp: 2022-08-19 04:55:39.894115\n",
      "resetting env. episode 680, reward total was -20.0. running mean: -20.28854310105951, timestamp: 2022-08-19 04:55:42.715141\n",
      "resetting env. episode 681, reward total was -19.0. running mean: -20.275657670048915, timestamp: 2022-08-19 04:55:45.416166\n",
      "resetting env. episode 682, reward total was -20.0. running mean: -20.272901093348423, timestamp: 2022-08-19 04:55:47.936187\n",
      "resetting env. episode 683, reward total was -20.0. running mean: -20.270172082414938, timestamp: 2022-08-19 04:55:50.558212\n",
      "resetting env. episode 684, reward total was -20.0. running mean: -20.26747036159079, timestamp: 2022-08-19 04:55:53.133238\n",
      "resetting env. episode 685, reward total was -21.0. running mean: -20.27479565797488, timestamp: 2022-08-19 04:55:56.058264\n",
      "resetting env. episode 686, reward total was -21.0. running mean: -20.282047701395133, timestamp: 2022-08-19 04:55:58.528291\n",
      "resetting env. episode 687, reward total was -21.0. running mean: -20.289227224381182, timestamp: 2022-08-19 04:56:00.484310\n",
      "resetting env. episode 688, reward total was -21.0. running mean: -20.29633495213737, timestamp: 2022-08-19 04:56:02.845328\n",
      "resetting env. episode 689, reward total was -21.0. running mean: -20.303371602616, timestamp: 2022-08-19 04:56:04.956348\n",
      "resetting env. episode 690, reward total was -21.0. running mean: -20.310337886589842, timestamp: 2022-08-19 04:56:07.782374\n",
      "resetting env. episode 691, reward total was -20.0. running mean: -20.307234507723944, timestamp: 2022-08-19 04:56:10.263398\n",
      "resetting env. episode 692, reward total was -21.0. running mean: -20.314162162646706, timestamp: 2022-08-19 04:56:12.670420\n",
      "resetting env. episode 693, reward total was -21.0. running mean: -20.32102054102024, timestamp: 2022-08-19 04:56:15.096443\n",
      "resetting env. episode 694, reward total was -21.0. running mean: -20.32781033561004, timestamp: 2022-08-19 04:56:17.679471\n",
      "resetting env. episode 695, reward total was -19.0. running mean: -20.31453223225394, timestamp: 2022-08-19 04:56:20.382495\n",
      "resetting env. episode 696, reward total was -20.0. running mean: -20.311386909931397, timestamp: 2022-08-19 04:56:23.016517\n",
      "resetting env. episode 697, reward total was -21.0. running mean: -20.318273040832082, timestamp: 2022-08-19 04:56:25.687545\n",
      "resetting env. episode 698, reward total was -19.0. running mean: -20.30509031042376, timestamp: 2022-08-19 04:56:28.562573\n",
      "resetting env. episode 699, reward total was -21.0. running mean: -20.312039407319524, timestamp: 2022-08-19 04:56:31.168596\n",
      "resetting env. episode 700, reward total was -21.0. running mean: -20.31891901324633, timestamp: 2022-08-19 04:56:33.434616\n",
      "resetting env. episode 701, reward total was -21.0. running mean: -20.325729823113868, timestamp: 2022-08-19 04:56:35.658638\n",
      "resetting env. episode 702, reward total was -19.0. running mean: -20.31247252488273, timestamp: 2022-08-19 04:56:38.297663\n",
      "resetting env. episode 703, reward total was -20.0. running mean: -20.3093477996339, timestamp: 2022-08-19 04:56:41.805698\n",
      "resetting env. episode 704, reward total was -20.0. running mean: -20.30625432163756, timestamp: 2022-08-19 04:56:44.442720\n",
      "resetting env. episode 705, reward total was -19.0. running mean: -20.293191778421185, timestamp: 2022-08-19 04:56:47.230748\n",
      "resetting env. episode 706, reward total was -21.0. running mean: -20.300259860636974, timestamp: 2022-08-19 04:56:49.175763\n",
      "resetting env. episode 707, reward total was -19.0. running mean: -20.287257262030604, timestamp: 2022-08-19 04:56:52.415796\n",
      "resetting env. episode 708, reward total was -21.0. running mean: -20.294384689410297, timestamp: 2022-08-19 04:56:54.472813\n",
      "resetting env. episode 709, reward total was -21.0. running mean: -20.301440842516193, timestamp: 2022-08-19 04:56:56.706839\n",
      "resetting env. episode 710, reward total was -19.0. running mean: -20.288426434091033, timestamp: 2022-08-19 04:56:59.864863\n",
      "resetting env. episode 711, reward total was -20.0. running mean: -20.285542169750123, timestamp: 2022-08-19 04:57:02.251887\n",
      "resetting env. episode 712, reward total was -21.0. running mean: -20.29268674805262, timestamp: 2022-08-19 04:57:04.774912\n",
      "resetting env. episode 713, reward total was -21.0. running mean: -20.299759880572093, timestamp: 2022-08-19 04:57:07.222933\n",
      "resetting env. episode 714, reward total was -20.0. running mean: -20.296762281766373, timestamp: 2022-08-19 04:57:09.671955\n",
      "resetting env. episode 715, reward total was -21.0. running mean: -20.30379465894871, timestamp: 2022-08-19 04:57:12.354980\n",
      "resetting env. episode 716, reward total was -19.0. running mean: -20.290756712359226, timestamp: 2022-08-19 04:57:15.067005\n",
      "resetting env. episode 717, reward total was -20.0. running mean: -20.287849145235633, timestamp: 2022-08-19 04:57:17.410028\n",
      "resetting env. episode 718, reward total was -21.0. running mean: -20.294970653783277, timestamp: 2022-08-19 04:57:21.037061\n",
      "resetting env. episode 719, reward total was -20.0. running mean: -20.292020947245444, timestamp: 2022-08-19 04:57:24.072093\n",
      "resetting env. episode 720, reward total was -18.0. running mean: -20.269100737772987, timestamp: 2022-08-19 04:57:27.115116\n",
      "resetting env. episode 721, reward total was -18.0. running mean: -20.246409730395257, timestamp: 2022-08-19 04:57:29.764148\n",
      "resetting env. episode 722, reward total was -21.0. running mean: -20.253945633091305, timestamp: 2022-08-19 04:57:32.152168\n",
      "resetting env. episode 723, reward total was -20.0. running mean: -20.25140617676039, timestamp: 2022-08-19 04:57:34.663191\n",
      "resetting env. episode 724, reward total was -18.0. running mean: -20.228892114992785, timestamp: 2022-08-19 04:57:37.625219\n",
      "resetting env. episode 725, reward total was -18.0. running mean: -20.206603193842856, timestamp: 2022-08-19 04:57:41.701252\n",
      "resetting env. episode 726, reward total was -21.0. running mean: -20.214537161904428, timestamp: 2022-08-19 04:57:44.218276\n",
      "resetting env. episode 727, reward total was -21.0. running mean: -20.222391790285386, timestamp: 2022-08-19 04:57:46.995301\n",
      "resetting env. episode 728, reward total was -20.0. running mean: -20.220167872382532, timestamp: 2022-08-19 04:57:49.155326\n",
      "resetting env. episode 729, reward total was -20.0. running mean: -20.217966193658707, timestamp: 2022-08-19 04:57:51.955352\n",
      "resetting env. episode 730, reward total was -21.0. running mean: -20.22578653172212, timestamp: 2022-08-19 04:57:53.978369\n",
      "resetting env. episode 731, reward total was -21.0. running mean: -20.2335286664049, timestamp: 2022-08-19 04:57:56.517390\n",
      "resetting env. episode 732, reward total was -20.0. running mean: -20.23119337974085, timestamp: 2022-08-19 04:57:59.278417\n",
      "resetting env. episode 733, reward total was -21.0. running mean: -20.238881445943445, timestamp: 2022-08-19 04:58:01.830443\n",
      "resetting env. episode 734, reward total was -19.0. running mean: -20.22649263148401, timestamp: 2022-08-19 04:58:04.358464\n",
      "resetting env. episode 735, reward total was -21.0. running mean: -20.23422770516917, timestamp: 2022-08-19 04:58:06.762487\n",
      "resetting env. episode 736, reward total was -21.0. running mean: -20.24188542811748, timestamp: 2022-08-19 04:58:09.294510\n",
      "resetting env. episode 737, reward total was -21.0. running mean: -20.249466573836308, timestamp: 2022-08-19 04:58:11.786532\n",
      "resetting env. episode 738, reward total was -21.0. running mean: -20.256971908097945, timestamp: 2022-08-19 04:58:14.069557\n",
      "resetting env. episode 739, reward total was -21.0. running mean: -20.264402189016966, timestamp: 2022-08-19 04:58:16.989585\n",
      "resetting env. episode 740, reward total was -21.0. running mean: -20.271758167126798, timestamp: 2022-08-19 04:58:19.296606\n",
      "resetting env. episode 741, reward total was -21.0. running mean: -20.27904058545553, timestamp: 2022-08-19 04:58:21.734624\n",
      "resetting env. episode 742, reward total was -21.0. running mean: -20.286250179600977, timestamp: 2022-08-19 04:58:24.718652\n",
      "resetting env. episode 743, reward total was -19.0. running mean: -20.27338767780497, timestamp: 2022-08-19 04:58:27.206679\n",
      "resetting env. episode 744, reward total was -20.0. running mean: -20.270653801026917, timestamp: 2022-08-19 04:58:30.337706\n",
      "resetting env. episode 745, reward total was -20.0. running mean: -20.267947263016648, timestamp: 2022-08-19 04:58:33.032730\n",
      "resetting env. episode 746, reward total was -21.0. running mean: -20.275267790386483, timestamp: 2022-08-19 04:58:35.785756\n",
      "resetting env. episode 747, reward total was -21.0. running mean: -20.282515112482617, timestamp: 2022-08-19 04:58:37.776774\n",
      "resetting env. episode 748, reward total was -18.0. running mean: -20.25968996135779, timestamp: 2022-08-19 04:58:40.811805\n",
      "resetting env. episode 749, reward total was -19.0. running mean: -20.247093061744213, timestamp: 2022-08-19 04:58:44.242837\n",
      "resetting env. episode 750, reward total was -21.0. running mean: -20.254622131126773, timestamp: 2022-08-19 04:58:47.020391\n",
      "resetting env. episode 751, reward total was -21.0. running mean: -20.262075909815504, timestamp: 2022-08-19 04:58:49.100409\n",
      "resetting env. episode 752, reward total was -20.0. running mean: -20.259455150717347, timestamp: 2022-08-19 04:58:51.576436\n",
      "resetting env. episode 753, reward total was -21.0. running mean: -20.266860599210172, timestamp: 2022-08-19 04:58:53.803457\n",
      "resetting env. episode 754, reward total was -21.0. running mean: -20.27419199321807, timestamp: 2022-08-19 04:58:56.028476\n",
      "resetting env. episode 755, reward total was -19.0. running mean: -20.261450073285893, timestamp: 2022-08-19 04:58:58.881503\n",
      "resetting env. episode 756, reward total was -21.0. running mean: -20.268835572553034, timestamp: 2022-08-19 04:59:01.916531\n",
      "resetting env. episode 757, reward total was -20.0. running mean: -20.266147216827502, timestamp: 2022-08-19 04:59:04.547554\n",
      "resetting env. episode 758, reward total was -21.0. running mean: -20.273485744659226, timestamp: 2022-08-19 04:59:06.545572\n",
      "resetting env. episode 759, reward total was -21.0. running mean: -20.280750887212633, timestamp: 2022-08-19 04:59:08.656594\n",
      "resetting env. episode 760, reward total was -19.0. running mean: -20.267943378340508, timestamp: 2022-08-19 04:59:11.678619\n",
      "resetting env. episode 761, reward total was -18.0. running mean: -20.245263944557102, timestamp: 2022-08-19 04:59:15.341652\n",
      "resetting env. episode 762, reward total was -20.0. running mean: -20.24281130511153, timestamp: 2022-08-19 04:59:17.810674\n",
      "resetting env. episode 763, reward total was -17.0. running mean: -20.210383192060416, timestamp: 2022-08-19 04:59:21.084703\n",
      "resetting env. episode 764, reward total was -20.0. running mean: -20.208279360139812, timestamp: 2022-08-19 04:59:23.991734\n",
      "resetting env. episode 765, reward total was -21.0. running mean: -20.216196566538414, timestamp: 2022-08-19 04:59:25.928748\n",
      "resetting env. episode 766, reward total was -21.0. running mean: -20.224034600873033, timestamp: 2022-08-19 04:59:28.016769\n",
      "resetting env. episode 767, reward total was -21.0. running mean: -20.231794254864305, timestamp: 2022-08-19 04:59:30.538795\n",
      "resetting env. episode 768, reward total was -19.0. running mean: -20.219476312315663, timestamp: 2022-08-19 04:59:33.238817\n",
      "resetting env. episode 769, reward total was -20.0. running mean: -20.217281549192506, timestamp: 2022-08-19 04:59:36.082845\n",
      "resetting env. episode 770, reward total was -20.0. running mean: -20.215108733700582, timestamp: 2022-08-19 04:59:38.459866\n",
      "resetting env. episode 771, reward total was -21.0. running mean: -20.222957646363575, timestamp: 2022-08-19 04:59:40.553884\n",
      "resetting env. episode 772, reward total was -20.0. running mean: -20.220728069899938, timestamp: 2022-08-19 04:59:43.754915\n",
      "resetting env. episode 773, reward total was -21.0. running mean: -20.22852078920094, timestamp: 2022-08-19 04:59:46.406938\n",
      "resetting env. episode 774, reward total was -21.0. running mean: -20.23623558130893, timestamp: 2022-08-19 04:59:48.928963\n",
      "resetting env. episode 775, reward total was -21.0. running mean: -20.24387322549584, timestamp: 2022-08-19 04:59:51.164980\n",
      "resetting env. episode 776, reward total was -21.0. running mean: -20.251434493240883, timestamp: 2022-08-19 04:59:53.607007\n",
      "resetting env. episode 777, reward total was -20.0. running mean: -20.24892014830847, timestamp: 2022-08-19 04:59:56.224033\n",
      "resetting env. episode 778, reward total was -19.0. running mean: -20.236430946825386, timestamp: 2022-08-19 04:59:59.934060\n",
      "resetting env. episode 779, reward total was -21.0. running mean: -20.244066637357133, timestamp: 2022-08-19 05:00:02.154080\n",
      "resetting env. episode 780, reward total was -21.0. running mean: -20.25162597098356, timestamp: 2022-08-19 05:00:04.811105\n",
      "resetting env. episode 781, reward total was -21.0. running mean: -20.259109711273727, timestamp: 2022-08-19 05:00:06.794122\n",
      "resetting env. episode 782, reward total was -19.0. running mean: -20.24651861416099, timestamp: 2022-08-19 05:00:09.938154\n",
      "resetting env. episode 783, reward total was -21.0. running mean: -20.254053428019382, timestamp: 2022-08-19 05:00:12.520177\n",
      "resetting env. episode 784, reward total was -18.0. running mean: -20.23151289373919, timestamp: 2022-08-19 05:00:16.136210\n",
      "resetting env. episode 785, reward total was -19.0. running mean: -20.219197764801798, timestamp: 2022-08-19 05:00:19.178235\n",
      "resetting env. episode 786, reward total was -20.0. running mean: -20.21700578715378, timestamp: 2022-08-19 05:00:21.559260\n",
      "resetting env. episode 787, reward total was -21.0. running mean: -20.224835729282244, timestamp: 2022-08-19 05:00:23.784281\n",
      "resetting env. episode 788, reward total was -21.0. running mean: -20.23258737198942, timestamp: 2022-08-19 05:00:26.369301\n",
      "resetting env. episode 789, reward total was -20.0. running mean: -20.230261498269527, timestamp: 2022-08-19 05:00:28.729323\n",
      "resetting env. episode 790, reward total was -20.0. running mean: -20.22795888328683, timestamp: 2022-08-19 05:00:31.023345\n",
      "resetting env. episode 791, reward total was -21.0. running mean: -20.235679294453963, timestamp: 2022-08-19 05:00:33.459366\n",
      "resetting env. episode 792, reward total was -21.0. running mean: -20.243322501509425, timestamp: 2022-08-19 05:00:36.529396\n",
      "resetting env. episode 793, reward total was -21.0. running mean: -20.25088927649433, timestamp: 2022-08-19 05:00:38.694413\n",
      "resetting env. episode 794, reward total was -20.0. running mean: -20.248380383729387, timestamp: 2022-08-19 05:00:41.471439\n",
      "resetting env. episode 795, reward total was -20.0. running mean: -20.245896579892094, timestamp: 2022-08-19 05:00:43.593460\n",
      "resetting env. episode 796, reward total was -21.0. running mean: -20.253437614093173, timestamp: 2022-08-19 05:00:45.863477\n",
      "resetting env. episode 797, reward total was -21.0. running mean: -20.260903237952242, timestamp: 2022-08-19 05:00:48.388502\n",
      "resetting env. episode 798, reward total was -18.0. running mean: -20.238294205572718, timestamp: 2022-08-19 05:00:51.445528\n",
      "resetting env. episode 799, reward total was -21.0. running mean: -20.24591126351699, timestamp: 2022-08-19 05:00:53.676550\n",
      "resetting env. episode 800, reward total was -20.0. running mean: -20.24345215088182, timestamp: 2022-08-19 05:00:56.209573\n",
      "resetting env. episode 801, reward total was -19.0. running mean: -20.231017629373003, timestamp: 2022-08-19 05:00:58.737592\n",
      "resetting env. episode 802, reward total was -20.0. running mean: -20.228707453079274, timestamp: 2022-08-19 05:01:01.085617\n",
      "resetting env. episode 803, reward total was -21.0. running mean: -20.23642037854848, timestamp: 2022-08-19 05:01:03.489636\n",
      "resetting env. episode 804, reward total was -18.0. running mean: -20.214056174762995, timestamp: 2022-08-19 05:01:06.481666\n",
      "resetting env. episode 805, reward total was -21.0. running mean: -20.221915613015366, timestamp: 2022-08-19 05:01:09.633694\n",
      "resetting env. episode 806, reward total was -20.0. running mean: -20.21969645688521, timestamp: 2022-08-19 05:01:11.921714\n",
      "resetting env. episode 807, reward total was -21.0. running mean: -20.22749949231636, timestamp: 2022-08-19 05:01:14.508740\n",
      "resetting env. episode 808, reward total was -21.0. running mean: -20.235224497393194, timestamp: 2022-08-19 05:01:16.940756\n",
      "resetting env. episode 809, reward total was -21.0. running mean: -20.24287225241926, timestamp: 2022-08-19 05:01:19.267783\n",
      "resetting env. episode 810, reward total was -20.0. running mean: -20.240443529895067, timestamp: 2022-08-19 05:01:21.975803\n",
      "resetting env. episode 811, reward total was -21.0. running mean: -20.248039094596116, timestamp: 2022-08-19 05:01:24.657832\n",
      "resetting env. episode 812, reward total was -20.0. running mean: -20.245558703650154, timestamp: 2022-08-19 05:01:27.224854\n",
      "resetting env. episode 813, reward total was -20.0. running mean: -20.24310311661365, timestamp: 2022-08-19 05:01:29.899877\n",
      "resetting env. episode 814, reward total was -21.0. running mean: -20.250672085447516, timestamp: 2022-08-19 05:01:32.975905\n",
      "resetting env. episode 815, reward total was -18.0. running mean: -20.22816536459304, timestamp: 2022-08-19 05:01:36.007932\n",
      "resetting env. episode 816, reward total was -20.0. running mean: -20.22588371094711, timestamp: 2022-08-19 05:01:38.840960\n",
      "resetting env. episode 817, reward total was -21.0. running mean: -20.233624873837638, timestamp: 2022-08-19 05:01:41.307981\n",
      "resetting env. episode 818, reward total was -20.0. running mean: -20.23128862509926, timestamp: 2022-08-19 05:01:44.284009\n",
      "resetting env. episode 819, reward total was -20.0. running mean: -20.228975738848266, timestamp: 2022-08-19 05:01:46.779033\n",
      "resetting env. episode 820, reward total was -21.0. running mean: -20.236685981459786, timestamp: 2022-08-19 05:01:50.098065\n",
      "resetting env. episode 821, reward total was -21.0. running mean: -20.244319121645187, timestamp: 2022-08-19 05:01:52.289083\n",
      "resetting env. episode 822, reward total was -19.0. running mean: -20.231875930428735, timestamp: 2022-08-19 05:01:55.057107\n",
      "resetting env. episode 823, reward total was -21.0. running mean: -20.23955717112445, timestamp: 2022-08-19 05:01:57.836133\n",
      "resetting env. episode 824, reward total was -21.0. running mean: -20.247161599413204, timestamp: 2022-08-19 05:02:00.096155\n",
      "resetting env. episode 825, reward total was -21.0. running mean: -20.254689983419073, timestamp: 2022-08-19 05:02:02.382177\n",
      "resetting env. episode 826, reward total was -20.0. running mean: -20.252143083584883, timestamp: 2022-08-19 05:02:05.138204\n",
      "resetting env. episode 827, reward total was -21.0. running mean: -20.259621652749036, timestamp: 2022-08-19 05:02:07.218223\n",
      "resetting env. episode 828, reward total was -20.0. running mean: -20.257025436221546, timestamp: 2022-08-19 05:02:09.846247\n",
      "resetting env. episode 829, reward total was -21.0. running mean: -20.264455181859333, timestamp: 2022-08-19 05:02:11.956271\n",
      "resetting env. episode 830, reward total was -21.0. running mean: -20.27181063004074, timestamp: 2022-08-19 05:02:14.376291\n",
      "resetting env. episode 831, reward total was -20.0. running mean: -20.26909252374033, timestamp: 2022-08-19 05:02:16.727315\n",
      "resetting env. episode 832, reward total was -20.0. running mean: -20.266401598502927, timestamp: 2022-08-19 05:02:19.680341\n",
      "resetting env. episode 833, reward total was -20.0. running mean: -20.263737582517898, timestamp: 2022-08-19 05:02:22.495371\n",
      "resetting env. episode 834, reward total was -19.0. running mean: -20.25110020669272, timestamp: 2022-08-19 05:02:25.285396\n",
      "resetting env. episode 835, reward total was -21.0. running mean: -20.258589204625792, timestamp: 2022-08-19 05:02:27.784419\n",
      "resetting env. episode 836, reward total was -21.0. running mean: -20.266003312579535, timestamp: 2022-08-19 05:02:30.468446\n",
      "resetting env. episode 837, reward total was -19.0. running mean: -20.25334327945374, timestamp: 2022-08-19 05:02:33.152470\n",
      "resetting env. episode 838, reward total was -19.0. running mean: -20.240809846659204, timestamp: 2022-08-19 05:02:36.089502\n",
      "resetting env. episode 839, reward total was -21.0. running mean: -20.248401748192613, timestamp: 2022-08-19 05:02:38.620527\n",
      "resetting env. episode 840, reward total was -21.0. running mean: -20.25591773071069, timestamp: 2022-08-19 05:02:41.128550\n",
      "resetting env. episode 841, reward total was -21.0. running mean: -20.26335855340358, timestamp: 2022-08-19 05:02:43.380571\n",
      "resetting env. episode 842, reward total was -18.0. running mean: -20.240724967869543, timestamp: 2022-08-19 05:02:46.287597\n",
      "resetting env. episode 843, reward total was -21.0. running mean: -20.248317718190847, timestamp: 2022-08-19 05:02:49.445628\n",
      "resetting env. episode 844, reward total was -20.0. running mean: -20.24583454100894, timestamp: 2022-08-19 05:02:51.602648\n",
      "resetting env. episode 845, reward total was -21.0. running mean: -20.25337619559885, timestamp: 2022-08-19 05:02:53.831671\n",
      "resetting env. episode 846, reward total was -21.0. running mean: -20.260842433642864, timestamp: 2022-08-19 05:02:56.497697\n",
      "resetting env. episode 847, reward total was -21.0. running mean: -20.268234009306436, timestamp: 2022-08-19 05:02:58.706719\n",
      "resetting env. episode 848, reward total was -21.0. running mean: -20.27555166921337, timestamp: 2022-08-19 05:03:01.839755\n",
      "resetting env. episode 849, reward total was -20.0. running mean: -20.272796152521238, timestamp: 2022-08-19 05:03:04.132770\n",
      "resetting env. episode 850, reward total was -20.0. running mean: -20.270068190996025, timestamp: 2022-08-19 05:03:07.218801\n",
      "resetting env. episode 851, reward total was -20.0. running mean: -20.267367509086064, timestamp: 2022-08-19 05:03:09.976831\n",
      "resetting env. episode 852, reward total was -20.0. running mean: -20.264693833995203, timestamp: 2022-08-19 05:03:12.170854\n",
      "resetting env. episode 853, reward total was -21.0. running mean: -20.27204689565525, timestamp: 2022-08-19 05:03:14.093871\n",
      "resetting env. episode 854, reward total was -21.0. running mean: -20.2793264266987, timestamp: 2022-08-19 05:03:16.783899\n",
      "resetting env. episode 855, reward total was -21.0. running mean: -20.286533162431713, timestamp: 2022-08-19 05:03:18.875915\n",
      "resetting env. episode 856, reward total was -20.0. running mean: -20.283667830807396, timestamp: 2022-08-19 05:03:21.526473\n",
      "resetting env. episode 857, reward total was -18.0. running mean: -20.26083115249932, timestamp: 2022-08-19 05:03:24.178499\n",
      "resetting env. episode 858, reward total was -21.0. running mean: -20.268222840974328, timestamp: 2022-08-19 05:03:26.378518\n",
      "resetting env. episode 859, reward total was -20.0. running mean: -20.265540612564585, timestamp: 2022-08-19 05:03:28.855544\n",
      "resetting env. episode 860, reward total was -21.0. running mean: -20.27288520643894, timestamp: 2022-08-19 05:03:31.924574\n",
      "resetting env. episode 861, reward total was -21.0. running mean: -20.28015635437455, timestamp: 2022-08-19 05:03:34.325597\n",
      "resetting env. episode 862, reward total was -21.0. running mean: -20.287354790830808, timestamp: 2022-08-19 05:03:37.535628\n",
      "resetting env. episode 863, reward total was -21.0. running mean: -20.2944812429225, timestamp: 2022-08-19 05:03:39.552647\n",
      "resetting env. episode 864, reward total was -19.0. running mean: -20.281536430493276, timestamp: 2022-08-19 05:03:42.610679\n",
      "resetting env. episode 865, reward total was -21.0. running mean: -20.288721066188344, timestamp: 2022-08-19 05:03:44.595698\n",
      "resetting env. episode 866, reward total was -21.0. running mean: -20.29583385552646, timestamp: 2022-08-19 05:03:47.003726\n",
      "resetting env. episode 867, reward total was -19.0. running mean: -20.282875516971195, timestamp: 2022-08-19 05:03:49.554748\n",
      "resetting env. episode 868, reward total was -21.0. running mean: -20.290046761801484, timestamp: 2022-08-19 05:03:51.978774\n",
      "resetting env. episode 869, reward total was -20.0. running mean: -20.28714629418347, timestamp: 2022-08-19 05:03:55.095804\n",
      "resetting env. episode 870, reward total was -19.0. running mean: -20.274274831241634, timestamp: 2022-08-19 05:03:58.791987\n",
      "resetting env. episode 871, reward total was -21.0. running mean: -20.281532082929218, timestamp: 2022-08-19 05:04:00.838356\n",
      "resetting env. episode 872, reward total was -21.0. running mean: -20.288716762099927, timestamp: 2022-08-19 05:04:03.167022\n",
      "resetting env. episode 873, reward total was -21.0. running mean: -20.295829594478928, timestamp: 2022-08-19 05:04:05.323538\n",
      "resetting env. episode 874, reward total was -21.0. running mean: -20.30287129853414, timestamp: 2022-08-19 05:04:07.370196\n",
      "resetting env. episode 875, reward total was -21.0. running mean: -20.3098425855488, timestamp: 2022-08-19 05:04:09.713969\n",
      "resetting env. episode 876, reward total was -21.0. running mean: -20.316744159693314, timestamp: 2022-08-19 05:04:11.863221\n",
      "resetting env. episode 877, reward total was -20.0. running mean: -20.31357671809638, timestamp: 2022-08-19 05:04:13.903451\n",
      "resetting env. episode 878, reward total was -20.0. running mean: -20.310440950915417, timestamp: 2022-08-19 05:04:16.288962\n",
      "resetting env. episode 879, reward total was -19.0. running mean: -20.297336541406263, timestamp: 2022-08-19 05:04:19.728406\n",
      "resetting env. episode 880, reward total was -21.0. running mean: -20.3043631759922, timestamp: 2022-08-19 05:04:21.561187\n",
      "resetting env. episode 881, reward total was -21.0. running mean: -20.31131954423228, timestamp: 2022-08-19 05:04:24.376914\n",
      "resetting env. episode 882, reward total was -21.0. running mean: -20.318206348789957, timestamp: 2022-08-19 05:04:26.891380\n",
      "resetting env. episode 883, reward total was -20.0. running mean: -20.315024285302055, timestamp: 2022-08-19 05:04:29.729886\n",
      "resetting env. episode 884, reward total was -20.0. running mean: -20.311874042449034, timestamp: 2022-08-19 05:04:32.271832\n",
      "resetting env. episode 885, reward total was -20.0. running mean: -20.308755302024544, timestamp: 2022-08-19 05:04:34.815472\n",
      "resetting env. episode 886, reward total was -21.0. running mean: -20.315667749004298, timestamp: 2022-08-19 05:04:36.680372\n",
      "resetting env. episode 887, reward total was -19.0. running mean: -20.302511071514257, timestamp: 2022-08-19 05:04:39.780576\n",
      "resetting env. episode 888, reward total was -21.0. running mean: -20.309485960799115, timestamp: 2022-08-19 05:04:42.252713\n",
      "resetting env. episode 889, reward total was -21.0. running mean: -20.316391101191126, timestamp: 2022-08-19 05:04:44.582842\n",
      "resetting env. episode 890, reward total was -18.0. running mean: -20.293227190179213, timestamp: 2022-08-19 05:04:47.565777\n",
      "resetting env. episode 891, reward total was -20.0. running mean: -20.290294918277418, timestamp: 2022-08-19 05:04:49.857543\n",
      "resetting env. episode 892, reward total was -21.0. running mean: -20.297391969094644, timestamp: 2022-08-19 05:04:51.745754\n",
      "resetting env. episode 893, reward total was -21.0. running mean: -20.304418049403697, timestamp: 2022-08-19 05:04:54.178172\n",
      "resetting env. episode 894, reward total was -20.0. running mean: -20.30137386890966, timestamp: 2022-08-19 05:04:56.366672\n",
      "resetting env. episode 895, reward total was -21.0. running mean: -20.308360130220564, timestamp: 2022-08-19 05:04:58.476675\n",
      "resetting env. episode 896, reward total was -21.0. running mean: -20.315276528918357, timestamp: 2022-08-19 05:05:00.433251\n",
      "resetting env. episode 897, reward total was -19.0. running mean: -20.302123763629176, timestamp: 2022-08-19 05:05:02.523672\n",
      "resetting env. episode 898, reward total was -19.0. running mean: -20.289102525992885, timestamp: 2022-08-19 05:05:05.069165\n",
      "resetting env. episode 899, reward total was -20.0. running mean: -20.286211500732954, timestamp: 2022-08-19 05:05:07.287298\n",
      "resetting env. episode 900, reward total was -21.0. running mean: -20.293349385725623, timestamp: 2022-08-19 05:05:09.729940\n",
      "resetting env. episode 901, reward total was -19.0. running mean: -20.28041589186837, timestamp: 2022-08-19 05:05:12.244483\n",
      "resetting env. episode 902, reward total was -20.0. running mean: -20.277611732949683, timestamp: 2022-08-19 05:05:14.978407\n",
      "resetting env. episode 903, reward total was -21.0. running mean: -20.28483561562019, timestamp: 2022-08-19 05:05:17.334358\n",
      "resetting env. episode 904, reward total was -21.0. running mean: -20.291987259463987, timestamp: 2022-08-19 05:05:19.161993\n",
      "resetting env. episode 905, reward total was -21.0. running mean: -20.299067386869346, timestamp: 2022-08-19 05:05:21.182066\n",
      "resetting env. episode 906, reward total was -21.0. running mean: -20.306076713000653, timestamp: 2022-08-19 05:05:23.540511\n",
      "resetting env. episode 907, reward total was -21.0. running mean: -20.313015945870646, timestamp: 2022-08-19 05:05:26.450688\n",
      "resetting env. episode 908, reward total was -20.0. running mean: -20.30988578641194, timestamp: 2022-08-19 05:05:28.547862\n",
      "resetting env. episode 909, reward total was -21.0. running mean: -20.31678692854782, timestamp: 2022-08-19 05:05:30.871064\n",
      "resetting env. episode 910, reward total was -20.0. running mean: -20.31361905926234, timestamp: 2022-08-19 05:05:33.087698\n",
      "resetting env. episode 911, reward total was -21.0. running mean: -20.320482868669718, timestamp: 2022-08-19 05:05:35.366133\n",
      "resetting env. episode 912, reward total was -20.0. running mean: -20.31727803998302, timestamp: 2022-08-19 05:05:37.821316\n",
      "resetting env. episode 913, reward total was -21.0. running mean: -20.32410525958319, timestamp: 2022-08-19 05:05:40.194422\n",
      "resetting env. episode 914, reward total was -20.0. running mean: -20.32086420698736, timestamp: 2022-08-19 05:05:42.337034\n",
      "resetting env. episode 915, reward total was -20.0. running mean: -20.317655564917484, timestamp: 2022-08-19 05:05:44.945950\n",
      "resetting env. episode 916, reward total was -21.0. running mean: -20.32447900926831, timestamp: 2022-08-19 05:05:47.382863\n",
      "resetting env. episode 917, reward total was -18.0. running mean: -20.301234219175626, timestamp: 2022-08-19 05:05:50.111174\n",
      "resetting env. episode 918, reward total was -18.0. running mean: -20.27822187698387, timestamp: 2022-08-19 05:05:52.550062\n",
      "resetting env. episode 919, reward total was -20.0. running mean: -20.27543965821403, timestamp: 2022-08-19 05:05:54.710951\n",
      "resetting env. episode 920, reward total was -21.0. running mean: -20.28268526163189, timestamp: 2022-08-19 05:05:56.899550\n",
      "resetting env. episode 921, reward total was -20.0. running mean: -20.27985840901557, timestamp: 2022-08-19 05:05:59.371342\n",
      "resetting env. episode 922, reward total was -21.0. running mean: -20.287059824925414, timestamp: 2022-08-19 05:06:01.699484\n",
      "resetting env. episode 923, reward total was -21.0. running mean: -20.29418922667616, timestamp: 2022-08-19 05:06:04.004652\n",
      "resetting env. episode 924, reward total was -21.0. running mean: -20.3012473344094, timestamp: 2022-08-19 05:06:05.978116\n",
      "resetting env. episode 925, reward total was -21.0. running mean: -20.308234861065305, timestamp: 2022-08-19 05:06:08.214659\n",
      "resetting env. episode 926, reward total was -21.0. running mean: -20.315152512454652, timestamp: 2022-08-19 05:06:10.501895\n",
      "resetting env. episode 927, reward total was -20.0. running mean: -20.312000987330105, timestamp: 2022-08-19 05:06:13.182382\n",
      "resetting env. episode 928, reward total was -21.0. running mean: -20.318880977456804, timestamp: 2022-08-19 05:06:15.076473\n",
      "resetting env. episode 929, reward total was -21.0. running mean: -20.325692167682234, timestamp: 2022-08-19 05:06:17.726334\n",
      "resetting env. episode 930, reward total was -21.0. running mean: -20.332435246005414, timestamp: 2022-08-19 05:06:20.179367\n",
      "resetting env. episode 931, reward total was -21.0. running mean: -20.33911089354536, timestamp: 2022-08-19 05:06:22.384567\n",
      "resetting env. episode 932, reward total was -20.0. running mean: -20.335719784609907, timestamp: 2022-08-19 05:06:24.216073\n",
      "resetting env. episode 933, reward total was -20.0. running mean: -20.332362586763807, timestamp: 2022-08-19 05:06:26.427949\n",
      "resetting env. episode 934, reward total was -21.0. running mean: -20.33903896089617, timestamp: 2022-08-19 05:06:28.673105\n",
      "resetting env. episode 935, reward total was -19.0. running mean: -20.325648571287207, timestamp: 2022-08-19 05:06:31.632129\n",
      "resetting env. episode 936, reward total was -20.0. running mean: -20.322392085574332, timestamp: 2022-08-19 05:06:33.992124\n",
      "resetting env. episode 937, reward total was -20.0. running mean: -20.319168164718587, timestamp: 2022-08-19 05:06:36.176189\n",
      "resetting env. episode 938, reward total was -20.0. running mean: -20.3159764830714, timestamp: 2022-08-19 05:06:38.491435\n",
      "resetting env. episode 939, reward total was -21.0. running mean: -20.322816718240684, timestamp: 2022-08-19 05:06:40.837775\n",
      "resetting env. episode 940, reward total was -20.0. running mean: -20.319588551058278, timestamp: 2022-08-19 05:06:42.984316\n",
      "resetting env. episode 941, reward total was -19.0. running mean: -20.306392665547698, timestamp: 2022-08-19 05:06:45.231058\n",
      "resetting env. episode 942, reward total was -20.0. running mean: -20.30332873889222, timestamp: 2022-08-19 05:06:47.573033\n",
      "resetting env. episode 943, reward total was -21.0. running mean: -20.310295451503297, timestamp: 2022-08-19 05:06:49.517158\n",
      "resetting env. episode 944, reward total was -21.0. running mean: -20.317192496988266, timestamp: 2022-08-19 05:06:51.814457\n",
      "resetting env. episode 945, reward total was -21.0. running mean: -20.324020572018384, timestamp: 2022-08-19 05:06:54.488961\n",
      "resetting env. episode 946, reward total was -19.0. running mean: -20.3107803662982, timestamp: 2022-08-19 05:06:57.830736\n",
      "resetting env. episode 947, reward total was -21.0. running mean: -20.31767256263522, timestamp: 2022-08-19 05:07:00.700652\n",
      "resetting env. episode 948, reward total was -21.0. running mean: -20.324495837008868, timestamp: 2022-08-19 05:07:02.736255\n",
      "resetting env. episode 949, reward total was -20.0. running mean: -20.32125087863878, timestamp: 2022-08-19 05:07:05.461624\n",
      "resetting env. episode 950, reward total was -21.0. running mean: -20.32803836985239, timestamp: 2022-08-19 05:07:07.947532\n",
      "resetting env. episode 951, reward total was -21.0. running mean: -20.334757986153868, timestamp: 2022-08-19 05:07:10.397958\n",
      "resetting env. episode 952, reward total was -21.0. running mean: -20.34141040629233, timestamp: 2022-08-19 05:07:13.119777\n",
      "resetting env. episode 953, reward total was -20.0. running mean: -20.337996302229406, timestamp: 2022-08-19 05:07:15.987166\n",
      "resetting env. episode 954, reward total was -19.0. running mean: -20.324616339207115, timestamp: 2022-08-19 05:07:18.949171\n",
      "resetting env. episode 955, reward total was -20.0. running mean: -20.321370175815044, timestamp: 2022-08-19 05:07:21.698690\n",
      "resetting env. episode 956, reward total was -21.0. running mean: -20.328156474056893, timestamp: 2022-08-19 05:07:24.267567\n",
      "resetting env. episode 957, reward total was -20.0. running mean: -20.324874909316325, timestamp: 2022-08-19 05:07:26.628128\n",
      "resetting env. episode 958, reward total was -21.0. running mean: -20.331626160223163, timestamp: 2022-08-19 05:07:29.054740\n",
      "resetting env. episode 959, reward total was -20.0. running mean: -20.32830989862093, timestamp: 2022-08-19 05:07:31.635751\n",
      "resetting env. episode 960, reward total was -21.0. running mean: -20.335026799634722, timestamp: 2022-08-19 05:07:33.712468\n",
      "resetting env. episode 961, reward total was -20.0. running mean: -20.331676531638372, timestamp: 2022-08-19 05:07:36.322088\n",
      "resetting env. episode 962, reward total was -19.0. running mean: -20.31835976632199, timestamp: 2022-08-19 05:07:38.597787\n",
      "resetting env. episode 963, reward total was -21.0. running mean: -20.32517616865877, timestamp: 2022-08-19 05:07:40.612235\n",
      "resetting env. episode 964, reward total was -20.0. running mean: -20.321924406972183, timestamp: 2022-08-19 05:07:43.159885\n",
      "resetting env. episode 965, reward total was -19.0. running mean: -20.308705162902463, timestamp: 2022-08-19 05:07:46.746772\n",
      "resetting env. episode 966, reward total was -21.0. running mean: -20.315618111273437, timestamp: 2022-08-19 05:07:49.012100\n",
      "resetting env. episode 967, reward total was -21.0. running mean: -20.322461930160703, timestamp: 2022-08-19 05:07:51.394398\n",
      "resetting env. episode 968, reward total was -21.0. running mean: -20.329237310859096, timestamp: 2022-08-19 05:07:53.913181\n",
      "resetting env. episode 969, reward total was -19.0. running mean: -20.315944937750505, timestamp: 2022-08-19 05:07:56.283481\n",
      "resetting env. episode 970, reward total was -20.0. running mean: -20.312785488373, timestamp: 2022-08-19 05:07:58.256853\n",
      "resetting env. episode 971, reward total was -21.0. running mean: -20.31965763348927, timestamp: 2022-08-19 05:08:00.646593\n",
      "resetting env. episode 972, reward total was -20.0. running mean: -20.316461057154378, timestamp: 2022-08-19 05:08:03.391639\n",
      "resetting env. episode 973, reward total was -21.0. running mean: -20.323296446582834, timestamp: 2022-08-19 05:08:05.569552\n",
      "resetting env. episode 974, reward total was -19.0. running mean: -20.310063482117005, timestamp: 2022-08-19 05:08:08.278925\n",
      "resetting env. episode 975, reward total was -18.0. running mean: -20.286962847295836, timestamp: 2022-08-19 05:08:10.782409\n",
      "resetting env. episode 976, reward total was -21.0. running mean: -20.29409321882288, timestamp: 2022-08-19 05:08:12.949185\n",
      "resetting env. episode 977, reward total was -21.0. running mean: -20.30115228663465, timestamp: 2022-08-19 05:08:15.059226\n",
      "resetting env. episode 978, reward total was -21.0. running mean: -20.308140763768304, timestamp: 2022-08-19 05:08:17.163557\n",
      "resetting env. episode 979, reward total was -21.0. running mean: -20.31505935613062, timestamp: 2022-08-19 05:08:19.122968\n",
      "resetting env. episode 980, reward total was -21.0. running mean: -20.321908762569315, timestamp: 2022-08-19 05:08:21.085118\n",
      "resetting env. episode 981, reward total was -20.0. running mean: -20.31868967494362, timestamp: 2022-08-19 05:08:24.037972\n",
      "resetting env. episode 982, reward total was -20.0. running mean: -20.315502778194183, timestamp: 2022-08-19 05:08:26.203862\n",
      "resetting env. episode 983, reward total was -21.0. running mean: -20.32234775041224, timestamp: 2022-08-19 05:08:28.314642\n",
      "resetting env. episode 984, reward total was -20.0. running mean: -20.31912427290812, timestamp: 2022-08-19 05:08:30.628728\n",
      "resetting env. episode 985, reward total was -21.0. running mean: -20.32593303017904, timestamp: 2022-08-19 05:08:32.729420\n",
      "resetting env. episode 986, reward total was -21.0. running mean: -20.33267369987725, timestamp: 2022-08-19 05:08:34.967429\n",
      "resetting env. episode 987, reward total was -21.0. running mean: -20.33934696287848, timestamp: 2022-08-19 05:08:37.365587\n",
      "resetting env. episode 988, reward total was -19.0. running mean: -20.325953493249695, timestamp: 2022-08-19 05:08:39.982434\n",
      "resetting env. episode 989, reward total was -21.0. running mean: -20.3326939583172, timestamp: 2022-08-19 05:08:42.337520\n",
      "resetting env. episode 990, reward total was -20.0. running mean: -20.32936701873403, timestamp: 2022-08-19 05:08:44.436103\n",
      "resetting env. episode 991, reward total was -20.0. running mean: -20.32607334854669, timestamp: 2022-08-19 05:08:46.952104\n",
      "resetting env. episode 992, reward total was -20.0. running mean: -20.32281261506122, timestamp: 2022-08-19 05:08:49.098976\n",
      "resetting env. episode 993, reward total was -20.0. running mean: -20.319584488910607, timestamp: 2022-08-19 05:08:51.131827\n",
      "resetting env. episode 994, reward total was -21.0. running mean: -20.326388644021502, timestamp: 2022-08-19 05:08:53.766528\n",
      "resetting env. episode 995, reward total was -21.0. running mean: -20.333124757581288, timestamp: 2022-08-19 05:08:55.877825\n",
      "resetting env. episode 996, reward total was -21.0. running mean: -20.339793510005475, timestamp: 2022-08-19 05:08:58.647227\n",
      "resetting env. episode 997, reward total was -20.0. running mean: -20.33639557490542, timestamp: 2022-08-19 05:09:01.451327\n",
      "resetting env. episode 998, reward total was -19.0. running mean: -20.323031619156367, timestamp: 2022-08-19 05:09:04.441139\n",
      "resetting env. episode 999, reward total was -20.0. running mean: -20.3198013029648, timestamp: 2022-08-19 05:09:06.722740\n",
      "resetting env. episode 1000, reward total was -17.0. running mean: -20.286603289935154, timestamp: 2022-08-19 05:09:09.406557\n",
      "resetting env. episode 1001, reward total was -19.0. running mean: -20.273737257035805, timestamp: 2022-08-19 05:09:11.779626\n",
      "resetting env. episode 1002, reward total was -19.0. running mean: -20.26099988446545, timestamp: 2022-08-19 05:09:15.092101\n",
      "resetting env. episode 1003, reward total was -19.0. running mean: -20.248389885620796, timestamp: 2022-08-19 05:09:17.570627\n",
      "resetting env. episode 1004, reward total was -19.0. running mean: -20.23590598676459, timestamp: 2022-08-19 05:09:19.950373\n",
      "resetting env. episode 1005, reward total was -20.0. running mean: -20.233546926896942, timestamp: 2022-08-19 05:09:22.261991\n",
      "resetting env. episode 1006, reward total was -20.0. running mean: -20.23121145762797, timestamp: 2022-08-19 05:09:25.054162\n",
      "resetting env. episode 1007, reward total was -20.0. running mean: -20.22889934305169, timestamp: 2022-08-19 05:09:27.342801\n",
      "resetting env. episode 1008, reward total was -20.0. running mean: -20.226610349621172, timestamp: 2022-08-19 05:09:29.995617\n",
      "resetting env. episode 1009, reward total was -21.0. running mean: -20.234344246124962, timestamp: 2022-08-19 05:09:31.863818\n",
      "resetting env. episode 1010, reward total was -20.0. running mean: -20.232000803663713, timestamp: 2022-08-19 05:09:34.461933\n",
      "resetting env. episode 1011, reward total was -21.0. running mean: -20.239680795627077, timestamp: 2022-08-19 05:09:36.514563\n",
      "resetting env. episode 1012, reward total was -20.0. running mean: -20.237283987670807, timestamp: 2022-08-19 05:09:38.559533\n",
      "resetting env. episode 1013, reward total was -19.0. running mean: -20.2249111477941, timestamp: 2022-08-19 05:09:41.050150\n",
      "resetting env. episode 1014, reward total was -21.0. running mean: -20.23266203631616, timestamp: 2022-08-19 05:09:42.943895\n",
      "resetting env. episode 1015, reward total was -21.0. running mean: -20.240335415953, timestamp: 2022-08-19 05:09:45.032881\n",
      "resetting env. episode 1016, reward total was -21.0. running mean: -20.24793206179347, timestamp: 2022-08-19 05:09:47.550548\n",
      "resetting env. episode 1017, reward total was -21.0. running mean: -20.255452741175535, timestamp: 2022-08-19 05:09:50.009827\n",
      "resetting env. episode 1018, reward total was -21.0. running mean: -20.26289821376378, timestamp: 2022-08-19 05:09:52.353636\n",
      "resetting env. episode 1019, reward total was -19.0. running mean: -20.25026923162614, timestamp: 2022-08-19 05:09:54.820795\n",
      "resetting env. episode 1020, reward total was -21.0. running mean: -20.25776653930988, timestamp: 2022-08-19 05:09:56.835679\n",
      "resetting env. episode 1021, reward total was -19.0. running mean: -20.24518887391678, timestamp: 2022-08-19 05:09:59.319518\n",
      "resetting env. episode 1022, reward total was -20.0. running mean: -20.24273698517761, timestamp: 2022-08-19 05:10:02.252753\n",
      "resetting env. episode 1023, reward total was -20.0. running mean: -20.240309615325835, timestamp: 2022-08-19 05:10:04.852233\n",
      "resetting env. episode 1024, reward total was -21.0. running mean: -20.247906519172577, timestamp: 2022-08-19 05:10:06.948672\n",
      "resetting env. episode 1025, reward total was -21.0. running mean: -20.255427453980854, timestamp: 2022-08-19 05:10:08.969179\n",
      "resetting env. episode 1026, reward total was -20.0. running mean: -20.252873179441046, timestamp: 2022-08-19 05:10:11.339813\n",
      "resetting env. episode 1027, reward total was -17.0. running mean: -20.22034444764664, timestamp: 2022-08-19 05:10:14.405365\n",
      "resetting env. episode 1028, reward total was -20.0. running mean: -20.21814100317017, timestamp: 2022-08-19 05:10:16.703398\n",
      "resetting env. episode 1029, reward total was -21.0. running mean: -20.22595959313847, timestamp: 2022-08-19 05:10:19.117532\n",
      "resetting env. episode 1030, reward total was -20.0. running mean: -20.223699997207085, timestamp: 2022-08-19 05:10:21.892706\n",
      "resetting env. episode 1031, reward total was -19.0. running mean: -20.211462997235014, timestamp: 2022-08-19 05:10:24.885930\n",
      "resetting env. episode 1032, reward total was -21.0. running mean: -20.219348367262665, timestamp: 2022-08-19 05:10:27.024199\n",
      "resetting env. episode 1033, reward total was -20.0. running mean: -20.217154883590037, timestamp: 2022-08-19 05:10:29.318493\n",
      "resetting env. episode 1034, reward total was -21.0. running mean: -20.22498333475414, timestamp: 2022-08-19 05:10:31.413798\n",
      "resetting env. episode 1035, reward total was -19.0. running mean: -20.2127335014066, timestamp: 2022-08-19 05:10:34.142735\n",
      "resetting env. episode 1036, reward total was -21.0. running mean: -20.220606166392535, timestamp: 2022-08-19 05:10:36.270630\n",
      "resetting env. episode 1037, reward total was -20.0. running mean: -20.21840010472861, timestamp: 2022-08-19 05:10:38.630008\n",
      "resetting env. episode 1038, reward total was -21.0. running mean: -20.226216103681324, timestamp: 2022-08-19 05:10:40.632325\n",
      "resetting env. episode 1039, reward total was -19.0. running mean: -20.213953942644512, timestamp: 2022-08-19 05:10:43.121026\n",
      "resetting env. episode 1040, reward total was -20.0. running mean: -20.211814403218067, timestamp: 2022-08-19 05:10:45.353469\n",
      "resetting env. episode 1041, reward total was -21.0. running mean: -20.219696259185888, timestamp: 2022-08-19 05:10:48.170175\n",
      "resetting env. episode 1042, reward total was -19.0. running mean: -20.20749929659403, timestamp: 2022-08-19 05:10:50.913092\n",
      "resetting env. episode 1043, reward total was -20.0. running mean: -20.20542430362809, timestamp: 2022-08-19 05:10:53.550853\n",
      "resetting env. episode 1044, reward total was -21.0. running mean: -20.21337006059181, timestamp: 2022-08-19 05:10:55.826000\n",
      "resetting env. episode 1045, reward total was -21.0. running mean: -20.22123635998589, timestamp: 2022-08-19 05:10:58.057191\n",
      "resetting env. episode 1046, reward total was -21.0. running mean: -20.229023996386033, timestamp: 2022-08-19 05:11:00.091807\n",
      "resetting env. episode 1047, reward total was -18.0. running mean: -20.20673375642217, timestamp: 2022-08-19 05:11:02.555957\n",
      "resetting env. episode 1048, reward total was -21.0. running mean: -20.21466641885795, timestamp: 2022-08-19 05:11:04.420212\n",
      "resetting env. episode 1049, reward total was -21.0. running mean: -20.22251975466937, timestamp: 2022-08-19 05:11:06.293166\n",
      "resetting env. episode 1050, reward total was -21.0. running mean: -20.23029455712268, timestamp: 2022-08-19 05:11:08.513487\n",
      "resetting env. episode 1051, reward total was -21.0. running mean: -20.237991611551454, timestamp: 2022-08-19 05:11:10.719410\n",
      "resetting env. episode 1052, reward total was -19.0. running mean: -20.22561169543594, timestamp: 2022-08-19 05:11:13.145415\n",
      "resetting env. episode 1053, reward total was -21.0. running mean: -20.233355578481582, timestamp: 2022-08-19 05:11:15.708683\n",
      "resetting env. episode 1054, reward total was -21.0. running mean: -20.241022022696768, timestamp: 2022-08-19 05:11:17.664861\n",
      "resetting env. episode 1055, reward total was -20.0. running mean: -20.238611802469798, timestamp: 2022-08-19 05:11:19.853841\n",
      "resetting env. episode 1056, reward total was -20.0. running mean: -20.2362256844451, timestamp: 2022-08-19 05:11:22.415214\n",
      "resetting env. episode 1057, reward total was -21.0. running mean: -20.243863427600647, timestamp: 2022-08-19 05:11:24.254582\n",
      "resetting env. episode 1058, reward total was -19.0. running mean: -20.231424793324642, timestamp: 2022-08-19 05:11:26.512833\n",
      "resetting env. episode 1059, reward total was -21.0. running mean: -20.239110545391398, timestamp: 2022-08-19 05:11:28.458905\n",
      "resetting env. episode 1060, reward total was -21.0. running mean: -20.246719439937486, timestamp: 2022-08-19 05:11:30.630474\n",
      "resetting env. episode 1061, reward total was -17.0. running mean: -20.214252245538113, timestamp: 2022-08-19 05:11:33.877687\n",
      "resetting env. episode 1062, reward total was -20.0. running mean: -20.21210972308273, timestamp: 2022-08-19 05:11:36.602072\n",
      "resetting env. episode 1063, reward total was -20.0. running mean: -20.209988625851903, timestamp: 2022-08-19 05:11:38.984399\n",
      "resetting env. episode 1064, reward total was -21.0. running mean: -20.217888739593384, timestamp: 2022-08-19 05:11:41.358593\n",
      "resetting env. episode 1065, reward total was -20.0. running mean: -20.21570985219745, timestamp: 2022-08-19 05:11:44.060622\n",
      "resetting env. episode 1066, reward total was -20.0. running mean: -20.213552753675472, timestamp: 2022-08-19 05:11:46.571865\n",
      "resetting env. episode 1067, reward total was -20.0. running mean: -20.211417226138717, timestamp: 2022-08-19 05:11:49.036999\n",
      "resetting env. episode 1068, reward total was -21.0. running mean: -20.21930305387733, timestamp: 2022-08-19 05:11:51.720398\n",
      "resetting env. episode 1069, reward total was -21.0. running mean: -20.227110023338557, timestamp: 2022-08-19 05:11:54.503797\n",
      "resetting env. episode 1070, reward total was -20.0. running mean: -20.22483892310517, timestamp: 2022-08-19 05:11:56.753932\n",
      "resetting env. episode 1071, reward total was -21.0. running mean: -20.23259053387412, timestamp: 2022-08-19 05:11:59.537909\n",
      "resetting env. episode 1072, reward total was -20.0. running mean: -20.230264628535377, timestamp: 2022-08-19 05:12:01.875124\n",
      "resetting env. episode 1073, reward total was -21.0. running mean: -20.237961982250024, timestamp: 2022-08-19 05:12:04.358543\n",
      "resetting env. episode 1074, reward total was -21.0. running mean: -20.245582362427523, timestamp: 2022-08-19 05:12:06.393581\n",
      "resetting env. episode 1075, reward total was -21.0. running mean: -20.253126538803247, timestamp: 2022-08-19 05:12:08.730242\n",
      "resetting env. episode 1076, reward total was -20.0. running mean: -20.250595273415215, timestamp: 2022-08-19 05:12:11.318737\n",
      "resetting env. episode 1077, reward total was -21.0. running mean: -20.258089320681062, timestamp: 2022-08-19 05:12:13.094608\n",
      "resetting env. episode 1078, reward total was -20.0. running mean: -20.25550842747425, timestamp: 2022-08-19 05:12:15.311782\n",
      "resetting env. episode 1079, reward total was -21.0. running mean: -20.26295334319951, timestamp: 2022-08-19 05:12:17.687843\n",
      "resetting env. episode 1080, reward total was -19.0. running mean: -20.250323809767515, timestamp: 2022-08-19 05:12:20.584175\n",
      "resetting env. episode 1081, reward total was -21.0. running mean: -20.25782057166984, timestamp: 2022-08-19 05:12:22.470013\n",
      "resetting env. episode 1082, reward total was -20.0. running mean: -20.25524236595314, timestamp: 2022-08-19 05:12:24.553138\n",
      "resetting env. episode 1083, reward total was -19.0. running mean: -20.24268994229361, timestamp: 2022-08-19 05:12:27.560856\n",
      "resetting env. episode 1084, reward total was -20.0. running mean: -20.240263042870673, timestamp: 2022-08-19 05:12:30.224111\n",
      "resetting env. episode 1085, reward total was -20.0. running mean: -20.237860412441965, timestamp: 2022-08-19 05:12:32.557924\n",
      "resetting env. episode 1086, reward total was -21.0. running mean: -20.245481808317546, timestamp: 2022-08-19 05:12:34.933910\n",
      "resetting env. episode 1087, reward total was -21.0. running mean: -20.25302699023437, timestamp: 2022-08-19 05:12:37.140823\n",
      "resetting env. episode 1088, reward total was -21.0. running mean: -20.26049672033203, timestamp: 2022-08-19 05:12:39.134868\n",
      "resetting env. episode 1089, reward total was -20.0. running mean: -20.257891753128707, timestamp: 2022-08-19 05:12:41.868112\n",
      "resetting env. episode 1090, reward total was -21.0. running mean: -20.26531283559742, timestamp: 2022-08-19 05:12:44.738277\n",
      "resetting env. episode 1091, reward total was -20.0. running mean: -20.262659707241447, timestamp: 2022-08-19 05:12:47.422168\n",
      "resetting env. episode 1092, reward total was -21.0. running mean: -20.270033110169035, timestamp: 2022-08-19 05:12:49.641216\n",
      "resetting env. episode 1093, reward total was -19.0. running mean: -20.257332779067344, timestamp: 2022-08-19 05:12:52.621606\n",
      "resetting env. episode 1094, reward total was -21.0. running mean: -20.26475945127667, timestamp: 2022-08-19 05:12:54.734906\n",
      "resetting env. episode 1095, reward total was -20.0. running mean: -20.2621118567639, timestamp: 2022-08-19 05:12:56.807769\n",
      "resetting env. episode 1096, reward total was -20.0. running mean: -20.259490738196263, timestamp: 2022-08-19 05:12:59.434796\n",
      "resetting env. episode 1097, reward total was -21.0. running mean: -20.266895830814303, timestamp: 2022-08-19 05:13:01.547780\n",
      "resetting env. episode 1098, reward total was -20.0. running mean: -20.264226872506157, timestamp: 2022-08-19 05:13:03.725523\n",
      "resetting env. episode 1099, reward total was -20.0. running mean: -20.261584603781095, timestamp: 2022-08-19 05:13:06.075859\n",
      "resetting env. episode 1100, reward total was -21.0. running mean: -20.268968757743284, timestamp: 2022-08-19 05:13:08.199014\n",
      "resetting env. episode 1101, reward total was -19.0. running mean: -20.256279070165853, timestamp: 2022-08-19 05:13:10.872806\n",
      "resetting env. episode 1102, reward total was -21.0. running mean: -20.263716279464195, timestamp: 2022-08-19 05:13:13.600284\n",
      "resetting env. episode 1103, reward total was -19.0. running mean: -20.251079116669555, timestamp: 2022-08-19 05:13:16.548139\n",
      "resetting env. episode 1104, reward total was -20.0. running mean: -20.24856832550286, timestamp: 2022-08-19 05:13:19.503383\n",
      "resetting env. episode 1105, reward total was -19.0. running mean: -20.236082642247833, timestamp: 2022-08-19 05:13:21.954038\n",
      "resetting env. episode 1106, reward total was -19.0. running mean: -20.223721815825357, timestamp: 2022-08-19 05:13:24.834999\n",
      "resetting env. episode 1107, reward total was -21.0. running mean: -20.231484597667105, timestamp: 2022-08-19 05:13:27.197284\n",
      "resetting env. episode 1108, reward total was -20.0. running mean: -20.229169751690435, timestamp: 2022-08-19 05:13:29.367398\n",
      "resetting env. episode 1109, reward total was -21.0. running mean: -20.23687805417353, timestamp: 2022-08-19 05:13:31.542107\n",
      "resetting env. episode 1110, reward total was -21.0. running mean: -20.244509273631795, timestamp: 2022-08-19 05:13:33.782300\n",
      "resetting env. episode 1111, reward total was -20.0. running mean: -20.242064180895476, timestamp: 2022-08-19 05:13:36.311083\n",
      "resetting env. episode 1112, reward total was -20.0. running mean: -20.23964353908652, timestamp: 2022-08-19 05:13:38.418007\n",
      "resetting env. episode 1113, reward total was -21.0. running mean: -20.247247103695653, timestamp: 2022-08-19 05:13:40.850786\n",
      "resetting env. episode 1114, reward total was -20.0. running mean: -20.244774632658697, timestamp: 2022-08-19 05:13:43.623488\n",
      "resetting env. episode 1115, reward total was -20.0. running mean: -20.24232688633211, timestamp: 2022-08-19 05:13:45.956641\n",
      "resetting env. episode 1116, reward total was -20.0. running mean: -20.239903617468787, timestamp: 2022-08-19 05:13:48.267930\n",
      "resetting env. episode 1117, reward total was -20.0. running mean: -20.237504581294097, timestamp: 2022-08-19 05:13:50.763047\n",
      "resetting env. episode 1118, reward total was -21.0. running mean: -20.245129535481155, timestamp: 2022-08-19 05:13:53.369654\n",
      "resetting env. episode 1119, reward total was -18.0. running mean: -20.222678240126342, timestamp: 2022-08-19 05:13:56.666341\n",
      "resetting env. episode 1120, reward total was -21.0. running mean: -20.230451457725078, timestamp: 2022-08-19 05:13:58.901530\n",
      "resetting env. episode 1121, reward total was -21.0. running mean: -20.23814694314783, timestamp: 2022-08-19 05:14:01.022049\n",
      "resetting env. episode 1122, reward total was -21.0. running mean: -20.24576547371635, timestamp: 2022-08-19 05:14:03.414628\n",
      "resetting env. episode 1123, reward total was -20.0. running mean: -20.243307818979186, timestamp: 2022-08-19 05:14:05.716989\n",
      "resetting env. episode 1124, reward total was -21.0. running mean: -20.250874740789396, timestamp: 2022-08-19 05:14:08.393709\n",
      "resetting env. episode 1125, reward total was -21.0. running mean: -20.258365993381503, timestamp: 2022-08-19 05:14:10.254228\n",
      "resetting env. episode 1126, reward total was -21.0. running mean: -20.26578233344769, timestamp: 2022-08-19 05:14:12.478839\n",
      "resetting env. episode 1127, reward total was -21.0. running mean: -20.273124510113213, timestamp: 2022-08-19 05:14:14.469449\n",
      "resetting env. episode 1128, reward total was -19.0. running mean: -20.26039326501208, timestamp: 2022-08-19 05:14:16.728388\n",
      "resetting env. episode 1129, reward total was -21.0. running mean: -20.26778933236196, timestamp: 2022-08-19 05:14:19.400911\n",
      "resetting env. episode 1130, reward total was -21.0. running mean: -20.27511143903834, timestamp: 2022-08-19 05:14:21.367916\n",
      "resetting env. episode 1131, reward total was -18.0. running mean: -20.252360324647956, timestamp: 2022-08-19 05:14:24.001518\n",
      "resetting env. episode 1132, reward total was -20.0. running mean: -20.249836721401476, timestamp: 2022-08-19 05:14:26.753306\n",
      "resetting env. episode 1133, reward total was -19.0. running mean: -20.23733835418746, timestamp: 2022-08-19 05:14:29.610765\n",
      "resetting env. episode 1134, reward total was -21.0. running mean: -20.244964970645587, timestamp: 2022-08-19 05:14:31.887064\n",
      "resetting env. episode 1135, reward total was -21.0. running mean: -20.252515320939132, timestamp: 2022-08-19 05:14:34.004269\n",
      "resetting env. episode 1136, reward total was -21.0. running mean: -20.25999016772974, timestamp: 2022-08-19 05:14:37.026844\n",
      "resetting env. episode 1137, reward total was -21.0. running mean: -20.26739026605244, timestamp: 2022-08-19 05:14:38.977478\n",
      "resetting env. episode 1138, reward total was -21.0. running mean: -20.274716363391917, timestamp: 2022-08-19 05:14:41.898016\n",
      "resetting env. episode 1139, reward total was -21.0. running mean: -20.281969199758, timestamp: 2022-08-19 05:14:44.031853\n",
      "resetting env. episode 1140, reward total was -21.0. running mean: -20.28914950776042, timestamp: 2022-08-19 05:14:47.181940\n",
      "resetting env. episode 1141, reward total was -21.0. running mean: -20.296258012682816, timestamp: 2022-08-19 05:14:49.334654\n",
      "resetting env. episode 1142, reward total was -21.0. running mean: -20.303295432555988, timestamp: 2022-08-19 05:14:52.095543\n",
      "resetting env. episode 1143, reward total was -20.0. running mean: -20.300262478230426, timestamp: 2022-08-19 05:14:55.188383\n",
      "resetting env. episode 1144, reward total was -21.0. running mean: -20.307259853448123, timestamp: 2022-08-19 05:14:57.294773\n",
      "resetting env. episode 1145, reward total was -21.0. running mean: -20.31418725491364, timestamp: 2022-08-19 05:14:59.668378\n",
      "resetting env. episode 1146, reward total was -20.0. running mean: -20.311045382364505, timestamp: 2022-08-19 05:15:02.347493\n",
      "resetting env. episode 1147, reward total was -21.0. running mean: -20.31793492854086, timestamp: 2022-08-19 05:15:04.689095\n",
      "resetting env. episode 1148, reward total was -21.0. running mean: -20.324755579255452, timestamp: 2022-08-19 05:15:06.918475\n",
      "resetting env. episode 1149, reward total was -20.0. running mean: -20.321508023462897, timestamp: 2022-08-19 05:15:09.153050\n",
      "resetting env. episode 1150, reward total was -21.0. running mean: -20.32829294322827, timestamp: 2022-08-19 05:15:11.264320\n",
      "resetting env. episode 1151, reward total was -21.0. running mean: -20.335010013795987, timestamp: 2022-08-19 05:15:13.018257\n",
      "resetting env. episode 1152, reward total was -21.0. running mean: -20.341659913658027, timestamp: 2022-08-19 05:15:15.003264\n",
      "resetting env. episode 1153, reward total was -19.0. running mean: -20.328243314521448, timestamp: 2022-08-19 05:15:17.694676\n",
      "resetting env. episode 1154, reward total was -21.0. running mean: -20.334960881376233, timestamp: 2022-08-19 05:15:19.920039\n",
      "resetting env. episode 1155, reward total was -20.0. running mean: -20.33161127256247, timestamp: 2022-08-19 05:15:22.347907\n",
      "resetting env. episode 1156, reward total was -20.0. running mean: -20.328295159836845, timestamp: 2022-08-19 05:15:25.267815\n",
      "resetting env. episode 1157, reward total was -20.0. running mean: -20.325012208238476, timestamp: 2022-08-19 05:15:27.344947\n",
      "resetting env. episode 1158, reward total was -19.0. running mean: -20.311762086156094, timestamp: 2022-08-19 05:15:29.992116\n",
      "resetting env. episode 1159, reward total was -21.0. running mean: -20.318644465294533, timestamp: 2022-08-19 05:15:32.130856\n",
      "resetting env. episode 1160, reward total was -20.0. running mean: -20.315458020641586, timestamp: 2022-08-19 05:15:34.298693\n",
      "resetting env. episode 1161, reward total was -20.0. running mean: -20.31230344043517, timestamp: 2022-08-19 05:15:37.187571\n",
      "resetting env. episode 1162, reward total was -21.0. running mean: -20.319180406030817, timestamp: 2022-08-19 05:15:39.315213\n",
      "resetting env. episode 1163, reward total was -20.0. running mean: -20.31598860197051, timestamp: 2022-08-19 05:15:41.486733\n",
      "resetting env. episode 1164, reward total was -21.0. running mean: -20.322828715950806, timestamp: 2022-08-19 05:15:43.908619\n",
      "resetting env. episode 1165, reward total was -21.0. running mean: -20.3296004287913, timestamp: 2022-08-19 05:15:46.016919\n",
      "resetting env. episode 1166, reward total was -21.0. running mean: -20.336304424503385, timestamp: 2022-08-19 05:15:47.852557\n",
      "resetting env. episode 1167, reward total was -20.0. running mean: -20.33294138025835, timestamp: 2022-08-19 05:15:50.439887\n",
      "resetting env. episode 1168, reward total was -18.0. running mean: -20.309611966455765, timestamp: 2022-08-19 05:15:54.285012\n",
      "resetting env. episode 1169, reward total was -20.0. running mean: -20.306515846791207, timestamp: 2022-08-19 05:15:58.002518\n",
      "resetting env. episode 1170, reward total was -21.0. running mean: -20.313450688323297, timestamp: 2022-08-19 05:16:00.658735\n",
      "resetting env. episode 1171, reward total was -21.0. running mean: -20.320316181440063, timestamp: 2022-08-19 05:16:03.268124\n",
      "resetting env. episode 1172, reward total was -20.0. running mean: -20.317113019625662, timestamp: 2022-08-19 05:16:05.783812\n",
      "resetting env. episode 1173, reward total was -20.0. running mean: -20.313941889429405, timestamp: 2022-08-19 05:16:08.471356\n",
      "resetting env. episode 1174, reward total was -21.0. running mean: -20.32080247053511, timestamp: 2022-08-19 05:16:11.643223\n",
      "resetting env. episode 1175, reward total was -21.0. running mean: -20.32759444582976, timestamp: 2022-08-19 05:16:14.127666\n",
      "resetting env. episode 1176, reward total was -21.0. running mean: -20.334318501371463, timestamp: 2022-08-19 05:16:16.608489\n",
      "resetting env. episode 1177, reward total was -21.0. running mean: -20.34097531635775, timestamp: 2022-08-19 05:16:19.184518\n",
      "resetting env. episode 1178, reward total was -21.0. running mean: -20.347565563194173, timestamp: 2022-08-19 05:16:22.012545\n",
      "resetting env. episode 1179, reward total was -21.0. running mean: -20.354089907562233, timestamp: 2022-08-19 05:16:24.843574\n",
      "resetting env. episode 1180, reward total was -21.0. running mean: -20.36054900848661, timestamp: 2022-08-19 05:16:27.799599\n",
      "resetting env. episode 1181, reward total was -20.0. running mean: -20.356943518401746, timestamp: 2022-08-19 05:16:30.926632\n",
      "resetting env. episode 1182, reward total was -18.0. running mean: -20.333374083217727, timestamp: 2022-08-19 05:16:34.512667\n",
      "resetting env. episode 1183, reward total was -21.0. running mean: -20.34004034238555, timestamp: 2022-08-19 05:16:36.455687\n",
      "resetting env. episode 1184, reward total was -21.0. running mean: -20.346639938961694, timestamp: 2022-08-19 05:16:38.796709\n",
      "resetting env. episode 1185, reward total was -21.0. running mean: -20.353173539572076, timestamp: 2022-08-19 05:16:41.379735\n",
      "resetting env. episode 1186, reward total was -20.0. running mean: -20.349641804176354, timestamp: 2022-08-19 05:16:43.559760\n",
      "resetting env. episode 1187, reward total was -20.0. running mean: -20.34614538613459, timestamp: 2022-08-19 05:16:46.635786\n",
      "resetting env. episode 1188, reward total was -21.0. running mean: -20.352683932273244, timestamp: 2022-08-19 05:16:48.828809\n",
      "resetting env. episode 1189, reward total was -21.0. running mean: -20.35915709295051, timestamp: 2022-08-19 05:16:51.224831\n",
      "resetting env. episode 1190, reward total was -21.0. running mean: -20.365565522021008, timestamp: 2022-08-19 05:16:53.686857\n",
      "resetting env. episode 1191, reward total was -19.0. running mean: -20.3519098668008, timestamp: 2022-08-19 05:16:56.994890\n",
      "resetting env. episode 1192, reward total was -21.0. running mean: -20.358390768132793, timestamp: 2022-08-19 05:16:59.633920\n",
      "resetting env. episode 1193, reward total was -20.0. running mean: -20.354806860451465, timestamp: 2022-08-19 05:17:02.856947\n",
      "resetting env. episode 1194, reward total was -21.0. running mean: -20.36125879184695, timestamp: 2022-08-19 05:17:05.851980\n",
      "resetting env. episode 1195, reward total was -21.0. running mean: -20.36764620392848, timestamp: 2022-08-19 05:17:08.163999\n",
      "resetting env. episode 1196, reward total was -20.0. running mean: -20.363969741889193, timestamp: 2022-08-19 05:17:10.749028\n",
      "resetting env. episode 1197, reward total was -21.0. running mean: -20.3703300444703, timestamp: 2022-08-19 05:17:13.056048\n",
      "resetting env. episode 1198, reward total was -18.0. running mean: -20.346626744025595, timestamp: 2022-08-19 05:17:16.922090\n",
      "resetting env. episode 1199, reward total was -21.0. running mean: -20.35316047658534, timestamp: 2022-08-19 05:17:19.479115\n",
      "resetting env. episode 1200, reward total was -20.0. running mean: -20.349628871819487, timestamp: 2022-08-19 05:17:22.439140\n",
      "resetting env. episode 1201, reward total was -20.0. running mean: -20.34613258310129, timestamp: 2022-08-19 05:17:24.939165\n",
      "resetting env. episode 1202, reward total was -20.0. running mean: -20.342671257270275, timestamp: 2022-08-19 05:17:27.376192\n",
      "resetting env. episode 1203, reward total was -20.0. running mean: -20.33924454469757, timestamp: 2022-08-19 05:17:30.310222\n",
      "resetting env. episode 1204, reward total was -21.0. running mean: -20.345852099250596, timestamp: 2022-08-19 05:17:32.602241\n",
      "resetting env. episode 1205, reward total was -19.0. running mean: -20.332393578258092, timestamp: 2022-08-19 05:17:35.763272\n",
      "resetting env. episode 1206, reward total was -21.0. running mean: -20.33906964247551, timestamp: 2022-08-19 05:17:38.021299\n",
      "resetting env. episode 1207, reward total was -20.0. running mean: -20.335678946050756, timestamp: 2022-08-19 05:17:40.380319\n",
      "resetting env. episode 1208, reward total was -19.0. running mean: -20.32232215659025, timestamp: 2022-08-19 05:17:43.692351\n",
      "resetting env. episode 1209, reward total was -21.0. running mean: -20.329098935024348, timestamp: 2022-08-19 05:17:45.917377\n",
      "resetting env. episode 1210, reward total was -21.0. running mean: -20.335807945674105, timestamp: 2022-08-19 05:17:48.040395\n",
      "resetting env. episode 1211, reward total was -21.0. running mean: -20.342449866217365, timestamp: 2022-08-19 05:17:50.776422\n",
      "resetting env. episode 1212, reward total was -20.0. running mean: -20.33902536755519, timestamp: 2022-08-19 05:17:53.395447\n",
      "resetting env. episode 1213, reward total was -18.0. running mean: -20.31563511387964, timestamp: 2022-08-19 05:17:55.879473\n",
      "resetting env. episode 1214, reward total was -21.0. running mean: -20.322478762740843, timestamp: 2022-08-19 05:17:58.569501\n",
      "resetting env. episode 1215, reward total was -19.0. running mean: -20.309253975113435, timestamp: 2022-08-19 05:18:01.708530\n",
      "resetting env. episode 1216, reward total was -21.0. running mean: -20.3161614353623, timestamp: 2022-08-19 05:18:04.514556\n",
      "resetting env. episode 1217, reward total was -21.0. running mean: -20.32299982100868, timestamp: 2022-08-19 05:18:07.155581\n",
      "resetting env. episode 1218, reward total was -20.0. running mean: -20.31976982279859, timestamp: 2022-08-19 05:18:11.269623\n",
      "resetting env. episode 1219, reward total was -20.0. running mean: -20.316572124570605, timestamp: 2022-08-19 05:18:13.611645\n",
      "resetting env. episode 1220, reward total was -21.0. running mean: -20.3234064033249, timestamp: 2022-08-19 05:18:16.701676\n",
      "resetting env. episode 1221, reward total was -18.0. running mean: -20.30017233929165, timestamp: 2022-08-19 05:18:20.637715\n",
      "resetting env. episode 1222, reward total was -20.0. running mean: -20.297170615898732, timestamp: 2022-08-19 05:18:23.134737\n",
      "resetting env. episode 1223, reward total was -19.0. running mean: -20.284198909739747, timestamp: 2022-08-19 05:18:25.606766\n",
      "resetting env. episode 1224, reward total was -21.0. running mean: -20.29135692064235, timestamp: 2022-08-19 05:18:28.836326\n",
      "resetting env. episode 1225, reward total was -21.0. running mean: -20.298443351435928, timestamp: 2022-08-19 05:18:32.102355\n",
      "resetting env. episode 1226, reward total was -21.0. running mean: -20.30545891792157, timestamp: 2022-08-19 05:18:34.830386\n",
      "resetting env. episode 1227, reward total was -20.0. running mean: -20.30240432874235, timestamp: 2022-08-19 05:18:38.741424\n",
      "resetting env. episode 1228, reward total was -20.0. running mean: -20.299380285454927, timestamp: 2022-08-19 05:18:42.269458\n",
      "resetting env. episode 1229, reward total was -20.0. running mean: -20.296386482600376, timestamp: 2022-08-19 05:18:45.376488\n",
      "resetting env. episode 1230, reward total was -21.0. running mean: -20.303422617774373, timestamp: 2022-08-19 05:18:48.081513\n",
      "resetting env. episode 1231, reward total was -20.0. running mean: -20.300388391596627, timestamp: 2022-08-19 05:18:50.670540\n",
      "resetting env. episode 1232, reward total was -21.0. running mean: -20.307384507680663, timestamp: 2022-08-19 05:18:53.257566\n",
      "resetting env. episode 1233, reward total was -19.0. running mean: -20.294310662603856, timestamp: 2022-08-19 05:18:56.688601\n",
      "resetting env. episode 1234, reward total was -19.0. running mean: -20.28136755597782, timestamp: 2022-08-19 05:18:59.977635\n",
      "resetting env. episode 1235, reward total was -20.0. running mean: -20.27855388041804, timestamp: 2022-08-19 05:19:02.577658\n",
      "resetting env. episode 1236, reward total was -20.0. running mean: -20.27576834161386, timestamp: 2022-08-19 05:19:04.776685\n",
      "resetting env. episode 1237, reward total was -20.0. running mean: -20.27301065819772, timestamp: 2022-08-19 05:19:08.315718\n",
      "resetting env. episode 1238, reward total was -20.0. running mean: -20.27028055161574, timestamp: 2022-08-19 05:19:11.582750\n",
      "resetting env. episode 1239, reward total was -19.0. running mean: -20.257577746099585, timestamp: 2022-08-19 05:19:14.985788\n",
      "resetting env. episode 1240, reward total was -21.0. running mean: -20.26500196863859, timestamp: 2022-08-19 05:19:17.923814\n",
      "resetting env. episode 1241, reward total was -21.0. running mean: -20.272351948952203, timestamp: 2022-08-19 05:19:20.956849\n",
      "resetting env. episode 1242, reward total was -21.0. running mean: -20.279628429462683, timestamp: 2022-08-19 05:19:22.905864\n",
      "resetting env. episode 1243, reward total was -21.0. running mean: -20.286832145168056, timestamp: 2022-08-19 05:19:25.647896\n",
      "resetting env. episode 1244, reward total was -20.0. running mean: -20.283963823716373, timestamp: 2022-08-19 05:19:28.937927\n",
      "resetting env. episode 1245, reward total was -19.0. running mean: -20.27112418547921, timestamp: 2022-08-19 05:19:31.783960\n",
      "resetting env. episode 1246, reward total was -21.0. running mean: -20.278412943624417, timestamp: 2022-08-19 05:19:34.376983\n",
      "resetting env. episode 1247, reward total was -20.0. running mean: -20.27562881418817, timestamp: 2022-08-19 05:19:36.743009\n",
      "resetting env. episode 1248, reward total was -19.0. running mean: -20.26287252604629, timestamp: 2022-08-19 05:19:39.757037\n",
      "resetting env. episode 1249, reward total was -18.0. running mean: -20.240243800785827, timestamp: 2022-08-19 05:19:42.437066\n",
      "resetting env. episode 1250, reward total was -20.0. running mean: -20.237841362777967, timestamp: 2022-08-19 05:19:45.246094\n",
      "resetting env. episode 1251, reward total was -19.0. running mean: -20.225462949150188, timestamp: 2022-08-19 05:19:48.354127\n",
      "resetting env. episode 1252, reward total was -20.0. running mean: -20.223208319658685, timestamp: 2022-08-19 05:19:50.997158\n",
      "resetting env. episode 1253, reward total was -21.0. running mean: -20.230976236462098, timestamp: 2022-08-19 05:19:53.838185\n",
      "resetting env. episode 1254, reward total was -20.0. running mean: -20.228666474097476, timestamp: 2022-08-19 05:19:56.148209\n",
      "resetting env. episode 1255, reward total was -21.0. running mean: -20.236379809356503, timestamp: 2022-08-19 05:19:58.736233\n",
      "resetting env. episode 1256, reward total was -20.0. running mean: -20.234016011262938, timestamp: 2022-08-19 05:20:01.570268\n",
      "resetting env. episode 1257, reward total was -21.0. running mean: -20.24167585115031, timestamp: 2022-08-19 05:20:04.010289\n",
      "resetting env. episode 1258, reward total was -19.0. running mean: -20.229259092638806, timestamp: 2022-08-19 05:20:07.160325\n",
      "resetting env. episode 1259, reward total was -21.0. running mean: -20.23696650171242, timestamp: 2022-08-19 05:20:09.863349\n",
      "resetting env. episode 1260, reward total was -21.0. running mean: -20.244596836695298, timestamp: 2022-08-19 05:20:12.566381\n",
      "resetting env. episode 1261, reward total was -21.0. running mean: -20.252150868328346, timestamp: 2022-08-19 05:20:15.137409\n",
      "resetting env. episode 1262, reward total was -21.0. running mean: -20.259629359645064, timestamp: 2022-08-19 05:20:17.913438\n",
      "resetting env. episode 1263, reward total was -19.0. running mean: -20.247033066048616, timestamp: 2022-08-19 05:20:20.738463\n",
      "resetting env. episode 1264, reward total was -21.0. running mean: -20.25456273538813, timestamp: 2022-08-19 05:20:23.592496\n",
      "resetting env. episode 1265, reward total was -21.0. running mean: -20.26201710803425, timestamp: 2022-08-19 05:20:26.343522\n",
      "resetting env. episode 1266, reward total was -20.0. running mean: -20.259396936953905, timestamp: 2022-08-19 05:20:28.680548\n",
      "resetting env. episode 1267, reward total was -20.0. running mean: -20.256802967584367, timestamp: 2022-08-19 05:20:32.288585\n",
      "resetting env. episode 1268, reward total was -20.0. running mean: -20.25423493790852, timestamp: 2022-08-19 05:20:35.286616\n",
      "resetting env. episode 1269, reward total was -21.0. running mean: -20.261692588529435, timestamp: 2022-08-19 05:20:38.645651\n",
      "resetting env. episode 1270, reward total was -21.0. running mean: -20.26907566264414, timestamp: 2022-08-19 05:20:41.633682\n",
      "resetting env. episode 1271, reward total was -20.0. running mean: -20.2663849060177, timestamp: 2022-08-19 05:20:44.261713\n",
      "resetting env. episode 1272, reward total was -19.0. running mean: -20.253721056957524, timestamp: 2022-08-19 05:20:46.973744\n",
      "resetting env. episode 1273, reward total was -20.0. running mean: -20.25118384638795, timestamp: 2022-08-19 05:20:49.591768\n",
      "resetting env. episode 1274, reward total was -21.0. running mean: -20.25867200792407, timestamp: 2022-08-19 05:20:52.316798\n",
      "resetting env. episode 1275, reward total was -20.0. running mean: -20.256085287844826, timestamp: 2022-08-19 05:20:55.353831\n",
      "resetting env. episode 1276, reward total was -20.0. running mean: -20.253524434966376, timestamp: 2022-08-19 05:20:57.928859\n",
      "resetting env. episode 1277, reward total was -20.0. running mean: -20.25098919061671, timestamp: 2022-08-19 05:21:01.126896\n",
      "resetting env. episode 1278, reward total was -19.0. running mean: -20.238479298710544, timestamp: 2022-08-19 05:21:04.613932\n",
      "resetting env. episode 1279, reward total was -20.0. running mean: -20.23609450572344, timestamp: 2022-08-19 05:21:07.211958\n",
      "resetting env. episode 1280, reward total was -20.0. running mean: -20.233733560666206, timestamp: 2022-08-19 05:21:10.008986\n",
      "resetting env. episode 1281, reward total was -20.0. running mean: -20.231396225059544, timestamp: 2022-08-19 05:21:13.480025\n",
      "resetting env. episode 1282, reward total was -20.0. running mean: -20.229082262808948, timestamp: 2022-08-19 05:21:15.843053\n",
      "resetting env. episode 1283, reward total was -21.0. running mean: -20.23679144018086, timestamp: 2022-08-19 05:21:19.181087\n",
      "resetting env. episode 1284, reward total was -20.0. running mean: -20.23442352577905, timestamp: 2022-08-19 05:21:21.422111\n",
      "resetting env. episode 1285, reward total was -20.0. running mean: -20.23207929052126, timestamp: 2022-08-19 05:21:24.356143\n",
      "resetting env. episode 1286, reward total was -21.0. running mean: -20.239758497616048, timestamp: 2022-08-19 05:21:27.011172\n",
      "resetting env. episode 1287, reward total was -20.0. running mean: -20.237360912639886, timestamp: 2022-08-19 05:21:30.280206\n",
      "resetting env. episode 1288, reward total was -21.0. running mean: -20.244987303513486, timestamp: 2022-08-19 05:21:33.015235\n",
      "resetting env. episode 1289, reward total was -19.0. running mean: -20.232537430478352, timestamp: 2022-08-19 05:21:36.160273\n",
      "resetting env. episode 1290, reward total was -20.0. running mean: -20.230212056173567, timestamp: 2022-08-19 05:21:38.761298\n",
      "resetting env. episode 1291, reward total was -19.0. running mean: -20.217909935611832, timestamp: 2022-08-19 05:21:41.376326\n",
      "resetting env. episode 1292, reward total was -19.0. running mean: -20.205730836255714, timestamp: 2022-08-19 05:21:44.192356\n",
      "resetting env. episode 1293, reward total was -19.0. running mean: -20.193673527893157, timestamp: 2022-08-19 05:21:47.051391\n",
      "resetting env. episode 1294, reward total was -20.0. running mean: -20.191736792614225, timestamp: 2022-08-19 05:21:49.375413\n",
      "resetting env. episode 1295, reward total was -19.0. running mean: -20.179819424688084, timestamp: 2022-08-19 05:21:52.127445\n",
      "resetting env. episode 1296, reward total was -20.0. running mean: -20.178021230441203, timestamp: 2022-08-19 05:21:55.436478\n",
      "resetting env. episode 1297, reward total was -20.0. running mean: -20.17624101813679, timestamp: 2022-08-19 05:21:58.790518\n",
      "resetting env. episode 1298, reward total was -19.0. running mean: -20.164478607955424, timestamp: 2022-08-19 05:22:01.747549\n",
      "resetting env. episode 1299, reward total was -21.0. running mean: -20.17283382187587, timestamp: 2022-08-19 05:22:04.182572\n",
      "resetting env. episode 1300, reward total was -18.0. running mean: -20.151105483657112, timestamp: 2022-08-19 05:22:07.091604\n",
      "resetting env. episode 1301, reward total was -21.0. running mean: -20.15959442882054, timestamp: 2022-08-19 05:22:09.650635\n",
      "resetting env. episode 1302, reward total was -21.0. running mean: -20.167998484532337, timestamp: 2022-08-19 05:22:12.806667\n",
      "resetting env. episode 1303, reward total was -21.0. running mean: -20.176318499687014, timestamp: 2022-08-19 05:22:15.876700\n",
      "resetting env. episode 1304, reward total was -20.0. running mean: -20.174555314690142, timestamp: 2022-08-19 05:22:19.400742\n",
      "resetting env. episode 1305, reward total was -20.0. running mean: -20.17280976154324, timestamp: 2022-08-19 05:22:22.138768\n",
      "resetting env. episode 1306, reward total was -20.0. running mean: -20.171081663927804, timestamp: 2022-08-19 05:22:24.914798\n",
      "resetting env. episode 1307, reward total was -20.0. running mean: -20.169370847288526, timestamp: 2022-08-19 05:22:27.650828\n",
      "resetting env. episode 1308, reward total was -20.0. running mean: -20.16767713881564, timestamp: 2022-08-19 05:22:30.653863\n",
      "resetting env. episode 1309, reward total was -21.0. running mean: -20.176000367427484, timestamp: 2022-08-19 05:22:33.661894\n",
      "resetting env. episode 1310, reward total was -19.0. running mean: -20.164240363753212, timestamp: 2022-08-19 05:22:36.762929\n",
      "resetting env. episode 1311, reward total was -21.0. running mean: -20.17259796011568, timestamp: 2022-08-19 05:22:39.445958\n",
      "resetting env. episode 1312, reward total was -21.0. running mean: -20.180871980514524, timestamp: 2022-08-19 05:22:41.956985\n",
      "resetting env. episode 1313, reward total was -20.0. running mean: -20.179063260709377, timestamp: 2022-08-19 05:22:44.243011\n",
      "resetting env. episode 1314, reward total was -19.0. running mean: -20.167272628102285, timestamp: 2022-08-19 05:22:47.592046\n",
      "resetting env. episode 1315, reward total was -16.0. running mean: -20.125599901821264, timestamp: 2022-08-19 05:22:51.387087\n",
      "resetting env. episode 1316, reward total was -18.0. running mean: -20.104343902803052, timestamp: 2022-08-19 05:22:55.454133\n",
      "resetting env. episode 1317, reward total was -20.0. running mean: -20.10330046377502, timestamp: 2022-08-19 05:22:58.356164\n",
      "resetting env. episode 1318, reward total was -21.0. running mean: -20.11226745913727, timestamp: 2022-08-19 05:23:01.077196\n",
      "resetting env. episode 1319, reward total was -20.0. running mean: -20.111144784545896, timestamp: 2022-08-19 05:23:03.500220\n",
      "resetting env. episode 1320, reward total was -19.0. running mean: -20.100033336700438, timestamp: 2022-08-19 05:23:06.811255\n",
      "resetting env. episode 1321, reward total was -21.0. running mean: -20.109033003333433, timestamp: 2022-08-19 05:23:08.766276\n",
      "resetting env. episode 1322, reward total was -21.0. running mean: -20.1179426733001, timestamp: 2022-08-19 05:23:11.518309\n",
      "resetting env. episode 1323, reward total was -20.0. running mean: -20.116763246567096, timestamp: 2022-08-19 05:23:14.149339\n",
      "resetting env. episode 1324, reward total was -19.0. running mean: -20.105595614101425, timestamp: 2022-08-19 05:23:17.693380\n",
      "resetting env. episode 1325, reward total was -19.0. running mean: -20.09453965796041, timestamp: 2022-08-19 05:23:21.609418\n",
      "resetting env. episode 1326, reward total was -21.0. running mean: -20.103594261380806, timestamp: 2022-08-19 05:23:23.977445\n",
      "resetting env. episode 1327, reward total was -21.0. running mean: -20.112558318767, timestamp: 2022-08-19 05:23:26.626473\n",
      "resetting env. episode 1328, reward total was -21.0. running mean: -20.12143273557933, timestamp: 2022-08-19 05:23:29.444505\n",
      "resetting env. episode 1329, reward total was -20.0. running mean: -20.120218408223536, timestamp: 2022-08-19 05:23:32.237536\n",
      "resetting env. episode 1330, reward total was -20.0. running mean: -20.1190162241413, timestamp: 2022-08-19 05:23:34.759564\n",
      "resetting env. episode 1331, reward total was -21.0. running mean: -20.12782606189989, timestamp: 2022-08-19 05:23:37.202593\n",
      "resetting env. episode 1332, reward total was -21.0. running mean: -20.13654780128089, timestamp: 2022-08-19 05:23:39.887622\n",
      "resetting env. episode 1333, reward total was -20.0. running mean: -20.13518232326808, timestamp: 2022-08-19 05:23:42.443649\n",
      "resetting env. episode 1334, reward total was -18.0. running mean: -20.113830500035398, timestamp: 2022-08-19 05:23:45.868687\n",
      "resetting env. episode 1335, reward total was -21.0. running mean: -20.122692195035043, timestamp: 2022-08-19 05:23:49.295725\n",
      "resetting env. episode 1336, reward total was -21.0. running mean: -20.131465273084693, timestamp: 2022-08-19 05:23:52.095753\n",
      "resetting env. episode 1337, reward total was -20.0. running mean: -20.130150620353845, timestamp: 2022-08-19 05:23:55.489791\n",
      "resetting env. episode 1338, reward total was -21.0. running mean: -20.138849114150307, timestamp: 2022-08-19 05:23:57.928818\n",
      "resetting env. episode 1339, reward total was -20.0. running mean: -20.137460623008803, timestamp: 2022-08-19 05:24:00.267845\n",
      "resetting env. episode 1340, reward total was -21.0. running mean: -20.146086016778714, timestamp: 2022-08-19 05:24:02.578872\n",
      "resetting env. episode 1341, reward total was -21.0. running mean: -20.154625156610926, timestamp: 2022-08-19 05:24:04.864897\n",
      "resetting env. episode 1342, reward total was -21.0. running mean: -20.163078905044816, timestamp: 2022-08-19 05:24:07.851931\n",
      "resetting env. episode 1343, reward total was -20.0. running mean: -20.161448115994368, timestamp: 2022-08-19 05:24:11.077966\n",
      "resetting env. episode 1344, reward total was -20.0. running mean: -20.159833634834424, timestamp: 2022-08-19 05:24:13.978000\n",
      "resetting env. episode 1345, reward total was -20.0. running mean: -20.15823529848608, timestamp: 2022-08-19 05:24:16.548028\n",
      "resetting env. episode 1346, reward total was -21.0. running mean: -20.16665294550122, timestamp: 2022-08-19 05:24:19.345058\n",
      "resetting env. episode 1347, reward total was -20.0. running mean: -20.164986416046208, timestamp: 2022-08-19 05:24:22.308092\n",
      "resetting env. episode 1348, reward total was -19.0. running mean: -20.153336551885747, timestamp: 2022-08-19 05:24:25.537125\n",
      "resetting env. episode 1349, reward total was -20.0. running mean: -20.151803186366887, timestamp: 2022-08-19 05:24:28.148152\n",
      "resetting env. episode 1350, reward total was -19.0. running mean: -20.14028515450322, timestamp: 2022-08-19 05:24:31.668193\n",
      "resetting env. episode 1351, reward total was -21.0. running mean: -20.14888230295819, timestamp: 2022-08-19 05:24:34.530224\n",
      "resetting env. episode 1352, reward total was -20.0. running mean: -20.147393479928606, timestamp: 2022-08-19 05:24:37.363256\n",
      "resetting env. episode 1353, reward total was -21.0. running mean: -20.155919545129322, timestamp: 2022-08-19 05:24:40.538291\n",
      "resetting env. episode 1354, reward total was -20.0. running mean: -20.15436034967803, timestamp: 2022-08-19 05:24:43.687325\n",
      "resetting env. episode 1355, reward total was -19.0. running mean: -20.14281674618125, timestamp: 2022-08-19 05:24:46.660362\n",
      "resetting env. episode 1356, reward total was -21.0. running mean: -20.151388578719438, timestamp: 2022-08-19 05:24:49.825398\n",
      "resetting env. episode 1357, reward total was -20.0. running mean: -20.149874692932244, timestamp: 2022-08-19 05:24:52.653426\n",
      "resetting env. episode 1358, reward total was -20.0. running mean: -20.148375946002922, timestamp: 2022-08-19 05:24:55.335458\n",
      "resetting env. episode 1359, reward total was -19.0. running mean: -20.136892186542894, timestamp: 2022-08-19 05:24:58.925494\n",
      "resetting env. episode 1360, reward total was -19.0. running mean: -20.125523264677465, timestamp: 2022-08-19 05:25:01.987528\n",
      "resetting env. episode 1361, reward total was -19.0. running mean: -20.11426803203069, timestamp: 2022-08-19 05:25:05.473570\n",
      "resetting env. episode 1362, reward total was -20.0. running mean: -20.113125351710384, timestamp: 2022-08-19 05:25:08.006597\n",
      "resetting env. episode 1363, reward total was -21.0. running mean: -20.12199409819328, timestamp: 2022-08-19 05:25:10.656628\n",
      "resetting env. episode 1364, reward total was -21.0. running mean: -20.13077415721135, timestamp: 2022-08-19 05:25:13.529657\n",
      "resetting env. episode 1365, reward total was -21.0. running mean: -20.139466415639237, timestamp: 2022-08-19 05:25:16.438689\n",
      "resetting env. episode 1366, reward total was -19.0. running mean: -20.128071751482846, timestamp: 2022-08-19 05:25:19.469724\n",
      "resetting env. episode 1367, reward total was -20.0. running mean: -20.126791033968015, timestamp: 2022-08-19 05:25:22.428757\n",
      "resetting env. episode 1368, reward total was -21.0. running mean: -20.135523123628335, timestamp: 2022-08-19 05:25:24.745786\n",
      "resetting env. episode 1369, reward total was -16.0. running mean: -20.09416789239205, timestamp: 2022-08-19 05:25:27.955821\n",
      "resetting env. episode 1370, reward total was -20.0. running mean: -20.093226213468128, timestamp: 2022-08-19 05:25:30.699846\n",
      "resetting env. episode 1371, reward total was -21.0. running mean: -20.102293951333447, timestamp: 2022-08-19 05:25:33.746880\n",
      "resetting env. episode 1372, reward total was -21.0. running mean: -20.111271011820115, timestamp: 2022-08-19 05:25:35.600904\n",
      "resetting env. episode 1373, reward total was -21.0. running mean: -20.120158301701913, timestamp: 2022-08-19 05:25:38.603934\n",
      "resetting env. episode 1374, reward total was -20.0. running mean: -20.118956718684892, timestamp: 2022-08-19 05:25:40.827964\n",
      "resetting env. episode 1375, reward total was -21.0. running mean: -20.127767151498045, timestamp: 2022-08-19 05:25:43.571989\n",
      "resetting env. episode 1376, reward total was -19.0. running mean: -20.116489479983066, timestamp: 2022-08-19 05:25:46.455026\n",
      "resetting env. episode 1377, reward total was -21.0. running mean: -20.125324585183236, timestamp: 2022-08-19 05:25:48.734049\n",
      "resetting env. episode 1378, reward total was -21.0. running mean: -20.134071339331406, timestamp: 2022-08-19 05:25:50.766073\n",
      "resetting env. episode 1379, reward total was -19.0. running mean: -20.122730625938093, timestamp: 2022-08-19 05:25:53.884103\n",
      "resetting env. episode 1380, reward total was -20.0. running mean: -20.121503319678713, timestamp: 2022-08-19 05:25:56.839137\n",
      "resetting env. episode 1381, reward total was -21.0. running mean: -20.130288286481925, timestamp: 2022-08-19 05:25:59.520164\n",
      "resetting env. episode 1382, reward total was -19.0. running mean: -20.118985403617106, timestamp: 2022-08-19 05:26:01.954192\n",
      "resetting env. episode 1383, reward total was -21.0. running mean: -20.127795549580934, timestamp: 2022-08-19 05:26:04.744222\n",
      "resetting env. episode 1384, reward total was -20.0. running mean: -20.126517594085126, timestamp: 2022-08-19 05:26:07.511254\n",
      "resetting env. episode 1385, reward total was -16.0. running mean: -20.085252418144275, timestamp: 2022-08-19 05:26:11.159293\n",
      "resetting env. episode 1386, reward total was -21.0. running mean: -20.094399893962834, timestamp: 2022-08-19 05:26:14.223327\n",
      "resetting env. episode 1387, reward total was -20.0. running mean: -20.093455895023205, timestamp: 2022-08-19 05:26:16.659353\n",
      "resetting env. episode 1388, reward total was -21.0. running mean: -20.10252133607297, timestamp: 2022-08-19 05:26:19.535386\n",
      "resetting env. episode 1389, reward total was -20.0. running mean: -20.10149612271224, timestamp: 2022-08-19 05:26:22.282416\n",
      "resetting env. episode 1390, reward total was -21.0. running mean: -20.11048116148512, timestamp: 2022-08-19 05:26:24.740444\n",
      "resetting env. episode 1391, reward total was -20.0. running mean: -20.109376349870267, timestamp: 2022-08-19 05:26:27.914481\n",
      "resetting env. episode 1392, reward total was -21.0. running mean: -20.118282586371564, timestamp: 2022-08-19 05:26:30.338504\n",
      "resetting env. episode 1393, reward total was -20.0. running mean: -20.11709976050785, timestamp: 2022-08-19 05:26:33.413538\n",
      "resetting env. episode 1394, reward total was -18.0. running mean: -20.09592876290277, timestamp: 2022-08-19 05:26:36.729097\n",
      "resetting env. episode 1395, reward total was -21.0. running mean: -20.10496947527374, timestamp: 2022-08-19 05:26:39.065128\n",
      "resetting env. episode 1396, reward total was -20.0. running mean: -20.103919780521004, timestamp: 2022-08-19 05:26:41.733152\n",
      "resetting env. episode 1397, reward total was -18.0. running mean: -20.08288058271579, timestamp: 2022-08-19 05:26:44.428183\n",
      "resetting env. episode 1398, reward total was -20.0. running mean: -20.082051776888633, timestamp: 2022-08-19 05:26:47.253213\n",
      "resetting env. episode 1399, reward total was -21.0. running mean: -20.09123125911975, timestamp: 2022-08-19 05:26:49.533240\n",
      "resetting env. episode 1400, reward total was -20.0. running mean: -20.09031894652855, timestamp: 2022-08-19 05:26:52.144267\n",
      "resetting env. episode 1401, reward total was -20.0. running mean: -20.089415757063264, timestamp: 2022-08-19 05:26:54.827298\n",
      "resetting env. episode 1402, reward total was -20.0. running mean: -20.08852159949263, timestamp: 2022-08-19 05:26:57.441325\n",
      "resetting env. episode 1403, reward total was -19.0. running mean: -20.077636383497705, timestamp: 2022-08-19 05:27:00.050353\n",
      "resetting env. episode 1404, reward total was -19.0. running mean: -20.06686001966273, timestamp: 2022-08-19 05:27:02.576381\n",
      "resetting env. episode 1405, reward total was -20.0. running mean: -20.0661914194661, timestamp: 2022-08-19 05:27:05.094409\n",
      "resetting env. episode 1406, reward total was -21.0. running mean: -20.07552950527144, timestamp: 2022-08-19 05:27:07.697441\n",
      "resetting env. episode 1407, reward total was -19.0. running mean: -20.064774210218726, timestamp: 2022-08-19 05:27:10.731479\n",
      "resetting env. episode 1408, reward total was -21.0. running mean: -20.07412646811654, timestamp: 2022-08-19 05:27:12.885498\n",
      "resetting env. episode 1409, reward total was -20.0. running mean: -20.07338520343537, timestamp: 2022-08-19 05:27:15.283522\n",
      "resetting env. episode 1410, reward total was -21.0. running mean: -20.08265135140102, timestamp: 2022-08-19 05:27:18.742558\n",
      "resetting env. episode 1411, reward total was -21.0. running mean: -20.09182483788701, timestamp: 2022-08-19 05:27:21.158591\n",
      "resetting env. episode 1412, reward total was -20.0. running mean: -20.09090658950814, timestamp: 2022-08-19 05:27:23.599616\n",
      "resetting env. episode 1413, reward total was -21.0. running mean: -20.09999752361306, timestamp: 2022-08-19 05:27:26.262646\n",
      "resetting env. episode 1414, reward total was -18.0. running mean: -20.07899754837693, timestamp: 2022-08-19 05:27:29.839684\n",
      "resetting env. episode 1415, reward total was -21.0. running mean: -20.08820757289316, timestamp: 2022-08-19 05:27:32.499711\n",
      "resetting env. episode 1416, reward total was -21.0. running mean: -20.09732549716423, timestamp: 2022-08-19 05:27:34.800738\n",
      "resetting env. episode 1417, reward total was -21.0. running mean: -20.10635224219259, timestamp: 2022-08-19 05:27:37.211766\n",
      "resetting env. episode 1418, reward total was -21.0. running mean: -20.115288719770664, timestamp: 2022-08-19 05:27:39.655793\n",
      "resetting env. episode 1419, reward total was -20.0. running mean: -20.114135832572956, timestamp: 2022-08-19 05:27:42.011815\n",
      "resetting env. episode 1420, reward total was -18.0. running mean: -20.092994474247227, timestamp: 2022-08-19 05:27:45.034850\n",
      "resetting env. episode 1421, reward total was -20.0. running mean: -20.092064529504754, timestamp: 2022-08-19 05:27:48.103882\n",
      "resetting env. episode 1422, reward total was -18.0. running mean: -20.071143884209704, timestamp: 2022-08-19 05:27:51.120919\n",
      "resetting env. episode 1423, reward total was -21.0. running mean: -20.080432445367606, timestamp: 2022-08-19 05:27:53.538947\n",
      "resetting env. episode 1424, reward total was -21.0. running mean: -20.08962812091393, timestamp: 2022-08-19 05:27:55.553971\n",
      "resetting env. episode 1425, reward total was -20.0. running mean: -20.08873183970479, timestamp: 2022-08-19 05:27:57.928992\n",
      "resetting env. episode 1426, reward total was -21.0. running mean: -20.097844521307742, timestamp: 2022-08-19 05:28:00.739026\n",
      "resetting env. episode 1427, reward total was -19.0. running mean: -20.086866076094665, timestamp: 2022-08-19 05:28:03.180052\n",
      "resetting env. episode 1428, reward total was -19.0. running mean: -20.07599741533372, timestamp: 2022-08-19 05:28:06.794087\n",
      "resetting env. episode 1429, reward total was -21.0. running mean: -20.085237441180382, timestamp: 2022-08-19 05:28:08.806110\n",
      "resetting env. episode 1430, reward total was -21.0. running mean: -20.09438506676858, timestamp: 2022-08-19 05:28:11.559139\n",
      "resetting env. episode 1431, reward total was -20.0. running mean: -20.093441216100896, timestamp: 2022-08-19 05:28:13.772168\n",
      "resetting env. episode 1432, reward total was -20.0. running mean: -20.092506803939887, timestamp: 2022-08-19 05:28:16.186195\n",
      "resetting env. episode 1433, reward total was -20.0. running mean: -20.091581735900487, timestamp: 2022-08-19 05:28:19.171228\n",
      "resetting env. episode 1434, reward total was -20.0. running mean: -20.090665918541482, timestamp: 2022-08-19 05:28:22.194257\n",
      "resetting env. episode 1435, reward total was -21.0. running mean: -20.09975925935607, timestamp: 2022-08-19 05:28:24.452283\n",
      "resetting env. episode 1436, reward total was -21.0. running mean: -20.10876166676251, timestamp: 2022-08-19 05:28:26.626310\n",
      "resetting env. episode 1437, reward total was -21.0. running mean: -20.117674050094887, timestamp: 2022-08-19 05:28:28.807334\n",
      "resetting env. episode 1438, reward total was -18.0. running mean: -20.09649730959394, timestamp: 2022-08-19 05:28:31.579361\n",
      "resetting env. episode 1439, reward total was -18.0. running mean: -20.075532336498, timestamp: 2022-08-19 05:28:34.658394\n",
      "resetting env. episode 1440, reward total was -21.0. running mean: -20.08477701313302, timestamp: 2022-08-19 05:28:37.049420\n",
      "resetting env. episode 1441, reward total was -21.0. running mean: -20.093929243001693, timestamp: 2022-08-19 05:28:39.886455\n",
      "resetting env. episode 1442, reward total was -19.0. running mean: -20.082989950571676, timestamp: 2022-08-19 05:28:42.781484\n",
      "resetting env. episode 1443, reward total was -21.0. running mean: -20.09216005106596, timestamp: 2022-08-19 05:28:45.461513\n",
      "resetting env. episode 1444, reward total was -21.0. running mean: -20.1012384505553, timestamp: 2022-08-19 05:28:47.911543\n",
      "resetting env. episode 1445, reward total was -21.0. running mean: -20.110226066049748, timestamp: 2022-08-19 05:28:50.681573\n",
      "resetting env. episode 1446, reward total was -21.0. running mean: -20.11912380538925, timestamp: 2022-08-19 05:28:53.395602\n",
      "resetting env. episode 1447, reward total was -21.0. running mean: -20.12793256733536, timestamp: 2022-08-19 05:28:55.750625\n",
      "resetting env. episode 1448, reward total was -20.0. running mean: -20.126653241662005, timestamp: 2022-08-19 05:28:58.138654\n",
      "resetting env. episode 1449, reward total was -21.0. running mean: -20.135386709245385, timestamp: 2022-08-19 05:29:00.446677\n",
      "resetting env. episode 1450, reward total was -20.0. running mean: -20.13403284215293, timestamp: 2022-08-19 05:29:03.345709\n",
      "resetting env. episode 1451, reward total was -20.0. running mean: -20.1326925137314, timestamp: 2022-08-19 05:29:05.675737\n",
      "resetting env. episode 1452, reward total was -18.0. running mean: -20.111365588594087, timestamp: 2022-08-19 05:29:08.580764\n",
      "resetting env. episode 1453, reward total was -21.0. running mean: -20.120251932708147, timestamp: 2022-08-19 05:29:10.584789\n",
      "resetting env. episode 1454, reward total was -21.0. running mean: -20.129049413381065, timestamp: 2022-08-19 05:29:12.788810\n",
      "resetting env. episode 1455, reward total was -21.0. running mean: -20.137758919247254, timestamp: 2022-08-19 05:29:15.311839\n",
      "resetting env. episode 1456, reward total was -20.0. running mean: -20.136381330054782, timestamp: 2022-08-19 05:29:18.451873\n",
      "resetting env. episode 1457, reward total was -19.0. running mean: -20.125017516754234, timestamp: 2022-08-19 05:29:21.222905\n",
      "resetting env. episode 1458, reward total was -21.0. running mean: -20.133767341586694, timestamp: 2022-08-19 05:29:24.135934\n",
      "resetting env. episode 1459, reward total was -21.0. running mean: -20.142429668170827, timestamp: 2022-08-19 05:29:26.164956\n",
      "resetting env. episode 1460, reward total was -21.0. running mean: -20.15100537148912, timestamp: 2022-08-19 05:29:28.490982\n",
      "resetting env. episode 1461, reward total was -20.0. running mean: -20.149495317774228, timestamp: 2022-08-19 05:29:31.362014\n",
      "resetting env. episode 1462, reward total was -20.0. running mean: -20.148000364596484, timestamp: 2022-08-19 05:29:33.834039\n",
      "resetting env. episode 1463, reward total was -19.0. running mean: -20.13652036095052, timestamp: 2022-08-19 05:29:36.426068\n",
      "resetting env. episode 1464, reward total was -20.0. running mean: -20.135155157341014, timestamp: 2022-08-19 05:29:38.791095\n",
      "resetting env. episode 1465, reward total was -19.0. running mean: -20.123803605767606, timestamp: 2022-08-19 05:29:41.963128\n",
      "resetting env. episode 1466, reward total was -20.0. running mean: -20.122565569709927, timestamp: 2022-08-19 05:29:44.494157\n",
      "resetting env. episode 1467, reward total was -19.0. running mean: -20.111339914012827, timestamp: 2022-08-19 05:29:47.617189\n",
      "resetting env. episode 1468, reward total was -20.0. running mean: -20.110226514872696, timestamp: 2022-08-19 05:29:49.675214\n",
      "resetting env. episode 1469, reward total was -20.0. running mean: -20.10912424972397, timestamp: 2022-08-19 05:29:52.426242\n",
      "resetting env. episode 1470, reward total was -21.0. running mean: -20.11803300722673, timestamp: 2022-08-19 05:29:54.420262\n",
      "resetting env. episode 1471, reward total was -21.0. running mean: -20.126852677154464, timestamp: 2022-08-19 05:29:56.686292\n",
      "resetting env. episode 1472, reward total was -19.0. running mean: -20.11558415038292, timestamp: 2022-08-19 05:29:59.059317\n",
      "resetting env. episode 1473, reward total was -21.0. running mean: -20.12442830887909, timestamp: 2022-08-19 05:30:01.803343\n",
      "resetting env. episode 1474, reward total was -20.0. running mean: -20.123184025790298, timestamp: 2022-08-19 05:30:05.418382\n",
      "resetting env. episode 1475, reward total was -21.0. running mean: -20.131952185532395, timestamp: 2022-08-19 05:30:07.695407\n",
      "resetting env. episode 1476, reward total was -21.0. running mean: -20.14063266367707, timestamp: 2022-08-19 05:30:10.391436\n",
      "resetting env. episode 1477, reward total was -21.0. running mean: -20.1492263370403, timestamp: 2022-08-19 05:30:12.462457\n",
      "resetting env. episode 1478, reward total was -20.0. running mean: -20.147734073669895, timestamp: 2022-08-19 05:30:14.812483\n",
      "resetting env. episode 1479, reward total was -20.0. running mean: -20.146256732933196, timestamp: 2022-08-19 05:30:17.257510\n",
      "resetting env. episode 1480, reward total was -21.0. running mean: -20.154794165603864, timestamp: 2022-08-19 05:30:19.732537\n",
      "resetting env. episode 1481, reward total was -20.0. running mean: -20.153246223947825, timestamp: 2022-08-19 05:30:22.387566\n",
      "resetting env. episode 1482, reward total was -19.0. running mean: -20.14171376170835, timestamp: 2022-08-19 05:30:26.035608\n",
      "resetting env. episode 1483, reward total was -20.0. running mean: -20.140296624091263, timestamp: 2022-08-19 05:30:28.998639\n",
      "resetting env. episode 1484, reward total was -21.0. running mean: -20.14889365785035, timestamp: 2022-08-19 05:30:31.567667\n",
      "resetting env. episode 1485, reward total was -21.0. running mean: -20.15740472127185, timestamp: 2022-08-19 05:30:34.151696\n",
      "resetting env. episode 1486, reward total was -21.0. running mean: -20.16583067405913, timestamp: 2022-08-19 05:30:36.395716\n",
      "resetting env. episode 1487, reward total was -21.0. running mean: -20.17417236731854, timestamp: 2022-08-19 05:30:38.781742\n",
      "resetting env. episode 1488, reward total was -20.0. running mean: -20.172430643645352, timestamp: 2022-08-19 05:30:41.598770\n",
      "resetting env. episode 1489, reward total was -20.0. running mean: -20.170706337208898, timestamp: 2022-08-19 05:30:44.327800\n",
      "resetting env. episode 1490, reward total was -21.0. running mean: -20.17899927383681, timestamp: 2022-08-19 05:30:46.836826\n",
      "resetting env. episode 1491, reward total was -20.0. running mean: -20.17720928109844, timestamp: 2022-08-19 05:30:49.230855\n",
      "resetting env. episode 1492, reward total was -21.0. running mean: -20.185437188287455, timestamp: 2022-08-19 05:30:51.743886\n",
      "resetting env. episode 1493, reward total was -21.0. running mean: -20.193582816404582, timestamp: 2022-08-19 05:30:54.584909\n",
      "resetting env. episode 1494, reward total was -21.0. running mean: -20.201646988240537, timestamp: 2022-08-19 05:30:57.399940\n",
      "resetting env. episode 1495, reward total was -21.0. running mean: -20.209630518358132, timestamp: 2022-08-19 05:31:00.131969\n",
      "resetting env. episode 1496, reward total was -21.0. running mean: -20.217534213174552, timestamp: 2022-08-19 05:31:02.543999\n",
      "resetting env. episode 1497, reward total was -21.0. running mean: -20.225358871042808, timestamp: 2022-08-19 05:31:04.711018\n",
      "resetting env. episode 1498, reward total was -20.0. running mean: -20.22310528233238, timestamp: 2022-08-19 05:31:07.824056\n",
      "resetting env. episode 1499, reward total was -19.0. running mean: -20.210874229509056, timestamp: 2022-08-19 05:31:10.752087\n",
      "resetting env. episode 1500, reward total was -18.0. running mean: -20.188765487213963, timestamp: 2022-08-19 05:31:14.395122\n",
      "resetting env. episode 1501, reward total was -19.0. running mean: -20.176877832341823, timestamp: 2022-08-19 05:31:18.030163\n",
      "resetting env. episode 1502, reward total was -19.0. running mean: -20.165109054018405, timestamp: 2022-08-19 05:31:21.598200\n",
      "resetting env. episode 1503, reward total was -21.0. running mean: -20.17345796347822, timestamp: 2022-08-19 05:31:24.432230\n",
      "resetting env. episode 1504, reward total was -21.0. running mean: -20.18172338384344, timestamp: 2022-08-19 05:31:26.561254\n",
      "resetting env. episode 1505, reward total was -20.0. running mean: -20.179906150005007, timestamp: 2022-08-19 05:31:29.126283\n",
      "resetting env. episode 1506, reward total was -21.0. running mean: -20.188107088504957, timestamp: 2022-08-19 05:31:32.111319\n",
      "resetting env. episode 1507, reward total was -20.0. running mean: -20.186226017619905, timestamp: 2022-08-19 05:31:34.442338\n",
      "resetting env. episode 1508, reward total was -20.0. running mean: -20.184363757443705, timestamp: 2022-08-19 05:31:37.393371\n",
      "resetting env. episode 1509, reward total was -19.0. running mean: -20.17252011986927, timestamp: 2022-08-19 05:31:40.032396\n",
      "resetting env. episode 1510, reward total was -20.0. running mean: -20.170794918670577, timestamp: 2022-08-19 05:31:42.729429\n",
      "resetting env. episode 1511, reward total was -21.0. running mean: -20.179086969483873, timestamp: 2022-08-19 05:31:45.551459\n",
      "resetting env. episode 1512, reward total was -20.0. running mean: -20.177296099789032, timestamp: 2022-08-19 05:31:48.512487\n",
      "resetting env. episode 1513, reward total was -20.0. running mean: -20.175523138791142, timestamp: 2022-08-19 05:31:50.702512\n",
      "resetting env. episode 1514, reward total was -21.0. running mean: -20.183767907403233, timestamp: 2022-08-19 05:31:53.802546\n",
      "resetting env. episode 1515, reward total was -21.0. running mean: -20.191930228329202, timestamp: 2022-08-19 05:31:56.288571\n",
      "resetting env. episode 1516, reward total was -21.0. running mean: -20.20001092604591, timestamp: 2022-08-19 05:31:58.929602\n",
      "resetting env. episode 1517, reward total was -19.0. running mean: -20.18801081678545, timestamp: 2022-08-19 05:32:01.927633\n",
      "resetting env. episode 1518, reward total was -21.0. running mean: -20.196130708617595, timestamp: 2022-08-19 05:32:04.889665\n",
      "resetting env. episode 1519, reward total was -20.0. running mean: -20.19416940153142, timestamp: 2022-08-19 05:32:07.918697\n",
      "resetting env. episode 1520, reward total was -19.0. running mean: -20.182227707516105, timestamp: 2022-08-19 05:32:11.406731\n",
      "resetting env. episode 1521, reward total was -21.0. running mean: -20.190405430440943, timestamp: 2022-08-19 05:32:13.718761\n",
      "resetting env. episode 1522, reward total was -21.0. running mean: -20.198501376136534, timestamp: 2022-08-19 05:32:16.597788\n",
      "resetting env. episode 1523, reward total was -20.0. running mean: -20.196516362375167, timestamp: 2022-08-19 05:32:19.573819\n",
      "resetting env. episode 1524, reward total was -21.0. running mean: -20.204551198751417, timestamp: 2022-08-19 05:32:21.922848\n",
      "resetting env. episode 1525, reward total was -21.0. running mean: -20.212505686763905, timestamp: 2022-08-19 05:32:24.627873\n",
      "resetting env. episode 1526, reward total was -20.0. running mean: -20.210380629896264, timestamp: 2022-08-19 05:32:26.848900\n",
      "resetting env. episode 1527, reward total was -20.0. running mean: -20.208276823597302, timestamp: 2022-08-19 05:32:29.519925\n",
      "resetting env. episode 1528, reward total was -21.0. running mean: -20.21619405536133, timestamp: 2022-08-19 05:32:31.493950\n",
      "resetting env. episode 1529, reward total was -20.0. running mean: -20.21403211480772, timestamp: 2022-08-19 05:32:34.419978\n",
      "resetting env. episode 1530, reward total was -20.0. running mean: -20.21189179365964, timestamp: 2022-08-19 05:32:36.823004\n",
      "resetting env. episode 1531, reward total was -19.0. running mean: -20.199772875723042, timestamp: 2022-08-19 05:32:39.345031\n",
      "resetting env. episode 1532, reward total was -21.0. running mean: -20.207775146965812, timestamp: 2022-08-19 05:32:41.805059\n",
      "resetting env. episode 1533, reward total was -20.0. running mean: -20.205697395496152, timestamp: 2022-08-19 05:32:44.708086\n",
      "resetting env. episode 1534, reward total was -21.0. running mean: -20.213640421541193, timestamp: 2022-08-19 05:32:47.260115\n",
      "resetting env. episode 1535, reward total was -21.0. running mean: -20.22150401732578, timestamp: 2022-08-19 05:32:50.452147\n",
      "resetting env. episode 1536, reward total was -21.0. running mean: -20.229288977152525, timestamp: 2022-08-19 05:32:53.421709\n",
      "resetting env. episode 1537, reward total was -20.0. running mean: -20.226996087381, timestamp: 2022-08-19 05:32:57.074750\n",
      "resetting env. episode 1538, reward total was -18.0. running mean: -20.20472612650719, timestamp: 2022-08-19 05:33:00.734786\n",
      "resetting env. episode 1539, reward total was -21.0. running mean: -20.21267886524212, timestamp: 2022-08-19 05:33:03.434814\n",
      "resetting env. episode 1540, reward total was -20.0. running mean: -20.210552076589696, timestamp: 2022-08-19 05:33:06.433847\n",
      "resetting env. episode 1541, reward total was -21.0. running mean: -20.2184465558238, timestamp: 2022-08-19 05:33:10.086887\n",
      "resetting env. episode 1542, reward total was -21.0. running mean: -20.22626209026556, timestamp: 2022-08-19 05:33:12.452910\n",
      "resetting env. episode 1543, reward total was -19.0. running mean: -20.213999469362907, timestamp: 2022-08-19 05:33:16.067947\n",
      "resetting env. episode 1544, reward total was -19.0. running mean: -20.20185947466928, timestamp: 2022-08-19 05:33:18.894979\n",
      "resetting env. episode 1545, reward total was -21.0. running mean: -20.209840879922588, timestamp: 2022-08-19 05:33:20.931001\n",
      "resetting env. episode 1546, reward total was -20.0. running mean: -20.20774247112336, timestamp: 2022-08-19 05:33:24.142031\n",
      "resetting env. episode 1547, reward total was -19.0. running mean: -20.195665046412127, timestamp: 2022-08-19 05:33:26.986061\n",
      "resetting env. episode 1548, reward total was -21.0. running mean: -20.203708395948006, timestamp: 2022-08-19 05:33:29.864095\n",
      "resetting env. episode 1549, reward total was -20.0. running mean: -20.201671311988523, timestamp: 2022-08-19 05:33:32.324118\n",
      "resetting env. episode 1550, reward total was -21.0. running mean: -20.20965459886864, timestamp: 2022-08-19 05:33:34.590143\n",
      "resetting env. episode 1551, reward total was -20.0. running mean: -20.20755805287995, timestamp: 2022-08-19 05:33:36.882165\n",
      "resetting env. episode 1552, reward total was -18.0. running mean: -20.18548247235115, timestamp: 2022-08-19 05:33:39.928201\n",
      "resetting env. episode 1553, reward total was -20.0. running mean: -20.183627647627638, timestamp: 2022-08-19 05:33:42.692227\n",
      "resetting env. episode 1554, reward total was -20.0. running mean: -20.181791371151363, timestamp: 2022-08-19 05:33:46.204263\n",
      "resetting env. episode 1555, reward total was -20.0. running mean: -20.179973457439846, timestamp: 2022-08-19 05:33:49.552299\n",
      "resetting env. episode 1556, reward total was -19.0. running mean: -20.16817372286545, timestamp: 2022-08-19 05:33:52.037325\n",
      "resetting env. episode 1557, reward total was -21.0. running mean: -20.176491985636797, timestamp: 2022-08-19 05:33:55.188361\n",
      "resetting env. episode 1558, reward total was -21.0. running mean: -20.18472706578043, timestamp: 2022-08-19 05:33:57.760387\n",
      "resetting env. episode 1559, reward total was -21.0. running mean: -20.192879795122625, timestamp: 2022-08-19 05:34:00.950418\n",
      "resetting env. episode 1560, reward total was -19.0. running mean: -20.1809509971714, timestamp: 2022-08-19 05:34:03.735447\n",
      "resetting env. episode 1561, reward total was -21.0. running mean: -20.189141487199688, timestamp: 2022-08-19 05:34:06.747482\n",
      "resetting env. episode 1562, reward total was -21.0. running mean: -20.19725007232769, timestamp: 2022-08-19 05:34:09.307505\n",
      "resetting env. episode 1563, reward total was -21.0. running mean: -20.205277571604416, timestamp: 2022-08-19 05:34:12.480539\n",
      "resetting env. episode 1564, reward total was -20.0. running mean: -20.20322479588837, timestamp: 2022-08-19 05:34:15.609571\n",
      "resetting env. episode 1565, reward total was -20.0. running mean: -20.201192547929487, timestamp: 2022-08-19 05:34:18.942609\n",
      "resetting env. episode 1566, reward total was -20.0. running mean: -20.199180622450193, timestamp: 2022-08-19 05:34:22.711647\n",
      "resetting env. episode 1567, reward total was -21.0. running mean: -20.207188816225692, timestamp: 2022-08-19 05:34:25.361672\n",
      "resetting env. episode 1568, reward total was -21.0. running mean: -20.215116928063434, timestamp: 2022-08-19 05:34:29.526716\n",
      "resetting env. episode 1569, reward total was -20.0. running mean: -20.2129657587828, timestamp: 2022-08-19 05:34:33.173757\n",
      "resetting env. episode 1570, reward total was -17.0. running mean: -20.180836101194974, timestamp: 2022-08-19 05:34:37.894802\n",
      "resetting env. episode 1571, reward total was -20.0. running mean: -20.179027740183024, timestamp: 2022-08-19 05:34:40.837832\n",
      "resetting env. episode 1572, reward total was -20.0. running mean: -20.177237462781193, timestamp: 2022-08-19 05:34:43.926868\n",
      "resetting env. episode 1573, reward total was -21.0. running mean: -20.185465088153382, timestamp: 2022-08-19 05:34:46.319894\n",
      "resetting env. episode 1574, reward total was -20.0. running mean: -20.18361043727185, timestamp: 2022-08-19 05:34:49.543923\n",
      "resetting env. episode 1575, reward total was -20.0. running mean: -20.181774332899128, timestamp: 2022-08-19 05:34:52.648955\n",
      "resetting env. episode 1576, reward total was -20.0. running mean: -20.179956589570136, timestamp: 2022-08-19 05:34:55.406985\n",
      "resetting env. episode 1577, reward total was -18.0. running mean: -20.158157023674434, timestamp: 2022-08-19 05:34:58.433014\n",
      "resetting env. episode 1578, reward total was -19.0. running mean: -20.14657545343769, timestamp: 2022-08-19 05:35:01.859049\n",
      "resetting env. episode 1579, reward total was -17.0. running mean: -20.115109698903314, timestamp: 2022-08-19 05:35:05.034087\n",
      "resetting env. episode 1580, reward total was -20.0. running mean: -20.11395860191428, timestamp: 2022-08-19 05:35:07.956112\n",
      "resetting env. episode 1581, reward total was -20.0. running mean: -20.112819015895138, timestamp: 2022-08-19 05:35:10.287137\n",
      "resetting env. episode 1582, reward total was -20.0. running mean: -20.111690825736186, timestamp: 2022-08-19 05:35:13.072175\n",
      "resetting env. episode 1583, reward total was -20.0. running mean: -20.110573917478824, timestamp: 2022-08-19 05:35:15.743192\n",
      "resetting env. episode 1584, reward total was -21.0. running mean: -20.119468178304036, timestamp: 2022-08-19 05:35:18.444222\n",
      "resetting env. episode 1585, reward total was -21.0. running mean: -20.128273496520997, timestamp: 2022-08-19 05:35:21.097247\n",
      "resetting env. episode 1586, reward total was -19.0. running mean: -20.116990761555787, timestamp: 2022-08-19 05:35:24.744285\n",
      "resetting env. episode 1587, reward total was -19.0. running mean: -20.10582085394023, timestamp: 2022-08-19 05:35:27.892317\n",
      "resetting env. episode 1588, reward total was -18.0. running mean: -20.084762645400826, timestamp: 2022-08-19 05:35:31.003352\n",
      "resetting env. episode 1589, reward total was -19.0. running mean: -20.073915018946817, timestamp: 2022-08-19 05:35:33.936385\n",
      "resetting env. episode 1590, reward total was -21.0. running mean: -20.08317586875735, timestamp: 2022-08-19 05:35:36.258404\n",
      "resetting env. episode 1591, reward total was -21.0. running mean: -20.092344110069778, timestamp: 2022-08-19 05:35:39.411438\n",
      "resetting env. episode 1592, reward total was -20.0. running mean: -20.09142066896908, timestamp: 2022-08-19 05:35:43.185477\n",
      "resetting env. episode 1593, reward total was -20.0. running mean: -20.090506462279386, timestamp: 2022-08-19 05:35:46.293509\n",
      "resetting env. episode 1594, reward total was -21.0. running mean: -20.099601397656592, timestamp: 2022-08-19 05:35:49.371546\n",
      "resetting env. episode 1595, reward total was -20.0. running mean: -20.098605383680024, timestamp: 2022-08-19 05:35:52.086571\n",
      "resetting env. episode 1596, reward total was -21.0. running mean: -20.107619329843224, timestamp: 2022-08-19 05:35:54.818600\n",
      "resetting env. episode 1597, reward total was -19.0. running mean: -20.096543136544792, timestamp: 2022-08-19 05:35:58.153640\n",
      "resetting env. episode 1598, reward total was -21.0. running mean: -20.105577705179346, timestamp: 2022-08-19 05:36:00.760662\n",
      "resetting env. episode 1599, reward total was -20.0. running mean: -20.104521928127554, timestamp: 2022-08-19 05:36:03.685697\n",
      "resetting env. episode 1600, reward total was -20.0. running mean: -20.103476708846276, timestamp: 2022-08-19 05:36:06.239723\n",
      "resetting env. episode 1601, reward total was -21.0. running mean: -20.112441941757815, timestamp: 2022-08-19 05:36:08.765748\n",
      "resetting env. episode 1602, reward total was -20.0. running mean: -20.111317522340237, timestamp: 2022-08-19 05:36:11.356777\n",
      "resetting env. episode 1603, reward total was -21.0. running mean: -20.120204347116836, timestamp: 2022-08-19 05:36:13.846804\n",
      "resetting env. episode 1604, reward total was -19.0. running mean: -20.109002303645667, timestamp: 2022-08-19 05:36:17.436843\n",
      "resetting env. episode 1605, reward total was -20.0. running mean: -20.10791228060921, timestamp: 2022-08-19 05:36:20.389874\n",
      "resetting env. episode 1606, reward total was -19.0. running mean: -20.09683315780312, timestamp: 2022-08-19 05:36:24.442917\n",
      "resetting env. episode 1607, reward total was -18.0. running mean: -20.075864826225086, timestamp: 2022-08-19 05:36:28.380959\n",
      "resetting env. episode 1608, reward total was -20.0. running mean: -20.075106177962834, timestamp: 2022-08-19 05:36:31.432992\n",
      "resetting env. episode 1609, reward total was -19.0. running mean: -20.064355116183208, timestamp: 2022-08-19 05:36:34.018022\n",
      "resetting env. episode 1610, reward total was -21.0. running mean: -20.073711565021377, timestamp: 2022-08-19 05:36:36.609046\n",
      "resetting env. episode 1611, reward total was -20.0. running mean: -20.072974449371163, timestamp: 2022-08-19 05:36:39.175080\n",
      "resetting env. episode 1612, reward total was -21.0. running mean: -20.082244704877454, timestamp: 2022-08-19 05:36:41.688103\n",
      "resetting env. episode 1613, reward total was -20.0. running mean: -20.081422257828677, timestamp: 2022-08-19 05:36:44.175133\n",
      "resetting env. episode 1614, reward total was -21.0. running mean: -20.09060803525039, timestamp: 2022-08-19 05:36:46.834158\n",
      "resetting env. episode 1615, reward total was -19.0. running mean: -20.07970195489789, timestamp: 2022-08-19 05:36:49.529189\n",
      "resetting env. episode 1616, reward total was -21.0. running mean: -20.08890493534891, timestamp: 2022-08-19 05:36:52.474223\n",
      "resetting env. episode 1617, reward total was -20.0. running mean: -20.08801588599542, timestamp: 2022-08-19 05:36:55.211250\n",
      "resetting env. episode 1618, reward total was -21.0. running mean: -20.097135727135466, timestamp: 2022-08-19 05:36:58.112285\n",
      "resetting env. episode 1619, reward total was -21.0. running mean: -20.10616436986411, timestamp: 2022-08-19 05:37:01.409322\n",
      "resetting env. episode 1620, reward total was -19.0. running mean: -20.09510272616547, timestamp: 2022-08-19 05:37:05.019359\n",
      "resetting env. episode 1621, reward total was -20.0. running mean: -20.094151698903815, timestamp: 2022-08-19 05:37:07.779388\n",
      "resetting env. episode 1622, reward total was -21.0. running mean: -20.10321018191478, timestamp: 2022-08-19 05:37:10.622424\n",
      "resetting env. episode 1623, reward total was -20.0. running mean: -20.10217808009563, timestamp: 2022-08-19 05:37:13.319451\n",
      "resetting env. episode 1624, reward total was -18.0. running mean: -20.081156299294673, timestamp: 2022-08-19 05:37:16.803488\n",
      "resetting env. episode 1625, reward total was -21.0. running mean: -20.090344736301727, timestamp: 2022-08-19 05:37:19.252520\n",
      "resetting env. episode 1626, reward total was -20.0. running mean: -20.08944128893871, timestamp: 2022-08-19 05:37:21.890544\n",
      "resetting env. episode 1627, reward total was -18.0. running mean: -20.06854687604932, timestamp: 2022-08-19 05:37:25.648589\n",
      "resetting env. episode 1628, reward total was -20.0. running mean: -20.067861407288827, timestamp: 2022-08-19 05:37:28.895624\n",
      "resetting env. episode 1629, reward total was -20.0. running mean: -20.067182793215938, timestamp: 2022-08-19 05:37:32.134661\n",
      "resetting env. episode 1630, reward total was -21.0. running mean: -20.07651096528378, timestamp: 2022-08-19 05:37:34.421683\n",
      "resetting env. episode 1631, reward total was -21.0. running mean: -20.085745855630943, timestamp: 2022-08-19 05:37:37.597718\n",
      "resetting env. episode 1632, reward total was -20.0. running mean: -20.084888397074632, timestamp: 2022-08-19 05:37:41.026756\n",
      "resetting env. episode 1633, reward total was -21.0. running mean: -20.094039513103887, timestamp: 2022-08-19 05:37:43.483783\n",
      "resetting env. episode 1634, reward total was -20.0. running mean: -20.093099117972848, timestamp: 2022-08-19 05:37:46.831824\n",
      "resetting env. episode 1635, reward total was -21.0. running mean: -20.10216812679312, timestamp: 2022-08-19 05:37:49.698852\n",
      "resetting env. episode 1636, reward total was -21.0. running mean: -20.11114644552519, timestamp: 2022-08-19 05:37:52.527885\n",
      "resetting env. episode 1637, reward total was -19.0. running mean: -20.10003498106994, timestamp: 2022-08-19 05:37:54.978911\n",
      "resetting env. episode 1638, reward total was -21.0. running mean: -20.10903463125924, timestamp: 2022-08-19 05:37:57.187464\n",
      "resetting env. episode 1639, reward total was -19.0. running mean: -20.09794428494665, timestamp: 2022-08-19 05:38:01.401508\n",
      "resetting env. episode 1640, reward total was -18.0. running mean: -20.076964842097183, timestamp: 2022-08-19 05:38:05.098547\n",
      "resetting env. episode 1641, reward total was -21.0. running mean: -20.08619519367621, timestamp: 2022-08-19 05:38:07.694581\n",
      "resetting env. episode 1642, reward total was -19.0. running mean: -20.07533324173945, timestamp: 2022-08-19 05:38:10.526611\n",
      "resetting env. episode 1643, reward total was -19.0. running mean: -20.064579909322056, timestamp: 2022-08-19 05:38:13.545644\n",
      "resetting env. episode 1644, reward total was -20.0. running mean: -20.063934110228836, timestamp: 2022-08-19 05:38:15.903669\n",
      "resetting env. episode 1645, reward total was -19.0. running mean: -20.05329476912655, timestamp: 2022-08-19 05:38:19.577711\n",
      "resetting env. episode 1646, reward total was -21.0. running mean: -20.062761821435284, timestamp: 2022-08-19 05:38:22.342743\n",
      "resetting env. episode 1647, reward total was -21.0. running mean: -20.072134203220934, timestamp: 2022-08-19 05:38:24.836773\n",
      "resetting env. episode 1648, reward total was -19.0. running mean: -20.061412861188725, timestamp: 2022-08-19 05:38:27.505801\n",
      "resetting env. episode 1649, reward total was -20.0. running mean: -20.060798732576835, timestamp: 2022-08-19 05:38:30.611836\n",
      "resetting env. episode 1650, reward total was -21.0. running mean: -20.070190745251068, timestamp: 2022-08-19 05:38:33.453866\n",
      "resetting env. episode 1651, reward total was -20.0. running mean: -20.069488837798556, timestamp: 2022-08-19 05:38:36.650903\n",
      "resetting env. episode 1652, reward total was -19.0. running mean: -20.058793949420572, timestamp: 2022-08-19 05:38:39.289934\n",
      "resetting env. episode 1653, reward total was -20.0. running mean: -20.058206009926366, timestamp: 2022-08-19 05:38:42.192968\n",
      "resetting env. episode 1654, reward total was -21.0. running mean: -20.0676239498271, timestamp: 2022-08-19 05:38:44.898995\n",
      "resetting env. episode 1655, reward total was -21.0. running mean: -20.07694771032883, timestamp: 2022-08-19 05:38:47.249023\n",
      "resetting env. episode 1656, reward total was -20.0. running mean: -20.07617823322554, timestamp: 2022-08-19 05:38:49.721054\n",
      "resetting env. episode 1657, reward total was -21.0. running mean: -20.085416450893288, timestamp: 2022-08-19 05:38:52.371082\n",
      "resetting env. episode 1658, reward total was -21.0. running mean: -20.094562286384356, timestamp: 2022-08-19 05:38:54.804108\n",
      "resetting env. episode 1659, reward total was -20.0. running mean: -20.09361666352051, timestamp: 2022-08-19 05:38:57.161134\n",
      "resetting env. episode 1660, reward total was -20.0. running mean: -20.092680496885304, timestamp: 2022-08-19 05:38:59.859166\n",
      "resetting env. episode 1661, reward total was -21.0. running mean: -20.101753691916453, timestamp: 2022-08-19 05:39:02.854203\n",
      "resetting env. episode 1662, reward total was -20.0. running mean: -20.10073615499729, timestamp: 2022-08-19 05:39:06.376239\n",
      "resetting env. episode 1663, reward total was -21.0. running mean: -20.109728793447317, timestamp: 2022-08-19 05:39:09.401274\n",
      "resetting env. episode 1664, reward total was -21.0. running mean: -20.118631505512845, timestamp: 2022-08-19 05:39:11.531297\n",
      "resetting env. episode 1665, reward total was -20.0. running mean: -20.117445190457715, timestamp: 2022-08-19 05:39:14.014325\n",
      "resetting env. episode 1666, reward total was -19.0. running mean: -20.10627073855314, timestamp: 2022-08-19 05:39:16.822357\n",
      "resetting env. episode 1667, reward total was -20.0. running mean: -20.105208031167606, timestamp: 2022-08-19 05:39:19.411387\n",
      "resetting env. episode 1668, reward total was -19.0. running mean: -20.09415595085593, timestamp: 2022-08-19 05:39:22.343420\n",
      "resetting env. episode 1669, reward total was -21.0. running mean: -20.10321439134737, timestamp: 2022-08-19 05:39:24.517447\n",
      "resetting env. episode 1670, reward total was -21.0. running mean: -20.1121822474339, timestamp: 2022-08-19 05:39:27.436478\n",
      "resetting env. episode 1671, reward total was -21.0. running mean: -20.121060424959563, timestamp: 2022-08-19 05:39:29.445504\n",
      "resetting env. episode 1672, reward total was -20.0. running mean: -20.119849820709966, timestamp: 2022-08-19 05:39:32.112532\n",
      "resetting env. episode 1673, reward total was -20.0. running mean: -20.118651322502867, timestamp: 2022-08-19 05:39:34.731563\n",
      "resetting env. episode 1674, reward total was -18.0. running mean: -20.097464809277838, timestamp: 2022-08-19 05:39:37.719597\n",
      "resetting env. episode 1675, reward total was -21.0. running mean: -20.10649016118506, timestamp: 2022-08-19 05:39:40.342625\n",
      "resetting env. episode 1676, reward total was -19.0. running mean: -20.09542525957321, timestamp: 2022-08-19 05:39:43.054656\n",
      "resetting env. episode 1677, reward total was -18.0. running mean: -20.07447100697748, timestamp: 2022-08-19 05:39:45.615682\n",
      "resetting env. episode 1678, reward total was -19.0. running mean: -20.063726296907706, timestamp: 2022-08-19 05:39:47.940709\n",
      "resetting env. episode 1679, reward total was -17.0. running mean: -20.03308903393863, timestamp: 2022-08-19 05:39:50.698745\n",
      "resetting env. episode 1680, reward total was -21.0. running mean: -20.042758143599244, timestamp: 2022-08-19 05:39:53.065766\n",
      "resetting env. episode 1681, reward total was -19.0. running mean: -20.032330562163253, timestamp: 2022-08-19 05:39:56.246803\n",
      "resetting env. episode 1682, reward total was -19.0. running mean: -20.02200725654162, timestamp: 2022-08-19 05:39:58.870833\n",
      "resetting env. episode 1683, reward total was -21.0. running mean: -20.031787183976206, timestamp: 2022-08-19 05:40:02.529876\n",
      "resetting env. episode 1684, reward total was -21.0. running mean: -20.041469312136446, timestamp: 2022-08-19 05:40:05.781916\n",
      "resetting env. episode 1685, reward total was -21.0. running mean: -20.051054619015083, timestamp: 2022-08-19 05:40:08.194939\n",
      "resetting env. episode 1686, reward total was -21.0. running mean: -20.060544072824932, timestamp: 2022-08-19 05:40:10.517967\n",
      "resetting env. episode 1687, reward total was -20.0. running mean: -20.05993863209668, timestamp: 2022-08-19 05:40:13.193001\n",
      "resetting env. episode 1688, reward total was -21.0. running mean: -20.069339245775716, timestamp: 2022-08-19 05:40:16.083030\n",
      "resetting env. episode 1689, reward total was -20.0. running mean: -20.068645853317957, timestamp: 2022-08-19 05:40:18.912068\n",
      "resetting env. episode 1690, reward total was -21.0. running mean: -20.077959394784777, timestamp: 2022-08-19 05:40:21.306089\n",
      "resetting env. episode 1691, reward total was -21.0. running mean: -20.08717980083693, timestamp: 2022-08-19 05:40:24.022121\n",
      "resetting env. episode 1692, reward total was -21.0. running mean: -20.096308002828565, timestamp: 2022-08-19 05:40:26.494150\n",
      "resetting env. episode 1693, reward total was -20.0. running mean: -20.09534492280028, timestamp: 2022-08-19 05:40:29.768191\n",
      "resetting env. episode 1694, reward total was -20.0. running mean: -20.094391473572276, timestamp: 2022-08-19 05:40:32.352218\n",
      "resetting env. episode 1695, reward total was -20.0. running mean: -20.09344755883655, timestamp: 2022-08-19 05:40:35.126250\n",
      "resetting env. episode 1696, reward total was -20.0. running mean: -20.092513083248186, timestamp: 2022-08-19 05:40:38.101283\n",
      "resetting env. episode 1697, reward total was -21.0. running mean: -20.101587952415706, timestamp: 2022-08-19 05:40:41.147318\n",
      "resetting env. episode 1698, reward total was -21.0. running mean: -20.11057207289155, timestamp: 2022-08-19 05:40:43.117344\n",
      "resetting env. episode 1699, reward total was -21.0. running mean: -20.119466352162636, timestamp: 2022-08-19 05:40:45.821375\n",
      "resetting env. episode 1700, reward total was -19.0. running mean: -20.10827168864101, timestamp: 2022-08-19 05:40:48.873409\n",
      "resetting env. episode 1701, reward total was -20.0. running mean: -20.1071889717546, timestamp: 2022-08-19 05:40:51.530439\n",
      "resetting env. episode 1702, reward total was -21.0. running mean: -20.116117082037054, timestamp: 2022-08-19 05:40:53.688464\n",
      "resetting env. episode 1703, reward total was -21.0. running mean: -20.124955911216684, timestamp: 2022-08-19 05:40:55.790490\n",
      "resetting env. episode 1704, reward total was -21.0. running mean: -20.133706352104518, timestamp: 2022-08-19 05:40:58.743524\n",
      "resetting env. episode 1705, reward total was -21.0. running mean: -20.142369288583474, timestamp: 2022-08-19 05:41:01.339552\n",
      "resetting env. episode 1706, reward total was -20.0. running mean: -20.140945595697637, timestamp: 2022-08-19 05:41:04.511587\n",
      "resetting env. episode 1707, reward total was -19.0. running mean: -20.12953613974066, timestamp: 2022-08-19 05:41:07.499623\n",
      "resetting env. episode 1708, reward total was -20.0. running mean: -20.128240778343255, timestamp: 2022-08-19 05:41:09.820652\n",
      "resetting env. episode 1709, reward total was -19.0. running mean: -20.116958370559825, timestamp: 2022-08-19 05:41:12.391679\n",
      "resetting env. episode 1710, reward total was -20.0. running mean: -20.115788786854225, timestamp: 2022-08-19 05:41:15.276710\n",
      "resetting env. episode 1711, reward total was -21.0. running mean: -20.124630898985682, timestamp: 2022-08-19 05:41:19.143757\n",
      "resetting env. episode 1712, reward total was -21.0. running mean: -20.133384589995828, timestamp: 2022-08-19 05:41:21.796789\n",
      "resetting env. episode 1713, reward total was -21.0. running mean: -20.14205074409587, timestamp: 2022-08-19 05:41:24.384816\n",
      "resetting env. episode 1714, reward total was -18.0. running mean: -20.12063023665491, timestamp: 2022-08-19 05:41:28.078862\n",
      "resetting env. episode 1715, reward total was -20.0. running mean: -20.11942393428836, timestamp: 2022-08-19 05:41:30.454887\n",
      "resetting env. episode 1716, reward total was -21.0. running mean: -20.128229694945478, timestamp: 2022-08-19 05:41:33.524921\n",
      "resetting env. episode 1717, reward total was -21.0. running mean: -20.136947397996025, timestamp: 2022-08-19 05:41:36.217952\n",
      "resetting env. episode 1718, reward total was -20.0. running mean: -20.135577924016065, timestamp: 2022-08-19 05:41:38.740985\n",
      "resetting env. episode 1719, reward total was -21.0. running mean: -20.144222144775906, timestamp: 2022-08-19 05:41:41.190009\n",
      "resetting env. episode 1720, reward total was -21.0. running mean: -20.152779923328147, timestamp: 2022-08-19 05:41:43.947042\n",
      "resetting env. episode 1721, reward total was -18.0. running mean: -20.131252124094864, timestamp: 2022-08-19 05:41:47.599084\n",
      "resetting env. episode 1722, reward total was -21.0. running mean: -20.139939602853914, timestamp: 2022-08-19 05:41:50.589120\n",
      "resetting env. episode 1723, reward total was -20.0. running mean: -20.138540206825375, timestamp: 2022-08-19 05:41:53.952158\n",
      "resetting env. episode 1724, reward total was -21.0. running mean: -20.147154804757122, timestamp: 2022-08-19 05:41:56.095184\n",
      "resetting env. episode 1725, reward total was -21.0. running mean: -20.15568325670955, timestamp: 2022-08-19 05:41:59.195216\n",
      "resetting env. episode 1726, reward total was -20.0. running mean: -20.154126424142454, timestamp: 2022-08-19 05:42:02.532255\n",
      "resetting env. episode 1727, reward total was -21.0. running mean: -20.16258515990103, timestamp: 2022-08-19 05:42:05.030288\n",
      "resetting env. episode 1728, reward total was -21.0. running mean: -20.17095930830202, timestamp: 2022-08-19 05:42:08.110318\n",
      "resetting env. episode 1729, reward total was -17.0. running mean: -20.139249715219, timestamp: 2022-08-19 05:42:11.362360\n",
      "resetting env. episode 1730, reward total was -21.0. running mean: -20.14785721806681, timestamp: 2022-08-19 05:42:13.903385\n",
      "resetting env. episode 1731, reward total was -21.0. running mean: -20.156378645886143, timestamp: 2022-08-19 05:42:17.409429\n",
      "resetting env. episode 1732, reward total was -20.0. running mean: -20.15481485942728, timestamp: 2022-08-19 05:42:20.087464\n",
      "resetting env. episode 1733, reward total was -21.0. running mean: -20.163266710833007, timestamp: 2022-08-19 05:42:22.481495\n",
      "resetting env. episode 1734, reward total was -20.0. running mean: -20.161634043724675, timestamp: 2022-08-19 05:42:25.864532\n",
      "resetting env. episode 1735, reward total was -21.0. running mean: -20.170017703287428, timestamp: 2022-08-19 05:42:27.798552\n",
      "resetting env. episode 1736, reward total was -14.0. running mean: -20.108317526254552, timestamp: 2022-08-19 05:42:32.342606\n",
      "resetting env. episode 1737, reward total was -20.0. running mean: -20.107234350992005, timestamp: 2022-08-19 05:42:34.966636\n",
      "resetting env. episode 1738, reward total was -20.0. running mean: -20.106162007482084, timestamp: 2022-08-19 05:42:37.324665\n",
      "resetting env. episode 1739, reward total was -21.0. running mean: -20.115100387407264, timestamp: 2022-08-19 05:42:40.600704\n",
      "resetting env. episode 1740, reward total was -21.0. running mean: -20.12394938353319, timestamp: 2022-08-19 05:42:43.062738\n",
      "resetting env. episode 1741, reward total was -20.0. running mean: -20.12270988969786, timestamp: 2022-08-19 05:42:45.842765\n",
      "resetting env. episode 1742, reward total was -20.0. running mean: -20.12148279080088, timestamp: 2022-08-19 05:42:48.925797\n",
      "resetting env. episode 1743, reward total was -20.0. running mean: -20.12026796289287, timestamp: 2022-08-19 05:42:51.994836\n",
      "resetting env. episode 1744, reward total was -20.0. running mean: -20.119065283263943, timestamp: 2022-08-19 05:42:54.794868\n",
      "resetting env. episode 1745, reward total was -21.0. running mean: -20.127874630431304, timestamp: 2022-08-19 05:42:57.887909\n",
      "resetting env. episode 1746, reward total was -21.0. running mean: -20.13659588412699, timestamp: 2022-08-19 05:43:00.892937\n",
      "resetting env. episode 1747, reward total was -19.0. running mean: -20.125229925285723, timestamp: 2022-08-19 05:43:04.310975\n",
      "resetting env. episode 1748, reward total was -21.0. running mean: -20.133977626032866, timestamp: 2022-08-19 05:43:07.072006\n",
      "resetting env. episode 1749, reward total was -21.0. running mean: -20.142637849772537, timestamp: 2022-08-19 05:43:09.186033\n",
      "resetting env. episode 1750, reward total was -20.0. running mean: -20.14121147127481, timestamp: 2022-08-19 05:43:12.589071\n",
      "resetting env. episode 1751, reward total was -20.0. running mean: -20.13979935656206, timestamp: 2022-08-19 05:43:15.442103\n",
      "resetting env. episode 1752, reward total was -19.0. running mean: -20.128401362996442, timestamp: 2022-08-19 05:43:18.825141\n",
      "resetting env. episode 1753, reward total was -21.0. running mean: -20.137117349366477, timestamp: 2022-08-19 05:43:21.982182\n",
      "resetting env. episode 1754, reward total was -19.0. running mean: -20.125746175872813, timestamp: 2022-08-19 05:43:24.710211\n",
      "resetting env. episode 1755, reward total was -20.0. running mean: -20.124488714114083, timestamp: 2022-08-19 05:43:28.609255\n",
      "resetting env. episode 1756, reward total was -20.0. running mean: -20.123243826972942, timestamp: 2022-08-19 05:43:31.816296\n",
      "resetting env. episode 1757, reward total was -21.0. running mean: -20.132011388703212, timestamp: 2022-08-19 05:43:34.508324\n",
      "resetting env. episode 1758, reward total was -20.0. running mean: -20.13069127481618, timestamp: 2022-08-19 05:43:37.846364\n",
      "resetting env. episode 1759, reward total was -21.0. running mean: -20.139384362068018, timestamp: 2022-08-19 05:43:40.712397\n",
      "resetting env. episode 1760, reward total was -21.0. running mean: -20.147990518447337, timestamp: 2022-08-19 05:43:43.032421\n",
      "resetting env. episode 1761, reward total was -19.0. running mean: -20.136510613262864, timestamp: 2022-08-19 05:43:47.294469\n",
      "resetting env. episode 1762, reward total was -21.0. running mean: -20.145145507130238, timestamp: 2022-08-19 05:43:50.393505\n",
      "resetting env. episode 1763, reward total was -21.0. running mean: -20.153694052058935, timestamp: 2022-08-19 05:43:53.230537\n",
      "resetting env. episode 1764, reward total was -19.0. running mean: -20.142157111538346, timestamp: 2022-08-19 05:43:56.467575\n",
      "resetting env. episode 1765, reward total was -16.0. running mean: -20.100735540422964, timestamp: 2022-08-19 05:44:00.199619\n",
      "resetting env. episode 1766, reward total was -21.0. running mean: -20.109728185018735, timestamp: 2022-08-19 05:44:02.839647\n",
      "resetting env. episode 1767, reward total was -21.0. running mean: -20.118630903168548, timestamp: 2022-08-19 05:44:05.839689\n",
      "resetting env. episode 1768, reward total was -21.0. running mean: -20.12744459413686, timestamp: 2022-08-19 05:44:08.702715\n",
      "resetting env. episode 1769, reward total was -21.0. running mean: -20.136170148195493, timestamp: 2022-08-19 05:44:11.278745\n",
      "resetting env. episode 1770, reward total was -21.0. running mean: -20.14480844671354, timestamp: 2022-08-19 05:44:13.892774\n",
      "resetting env. episode 1771, reward total was -19.0. running mean: -20.133360362246407, timestamp: 2022-08-19 05:44:16.499806\n",
      "resetting env. episode 1772, reward total was -21.0. running mean: -20.142026758623942, timestamp: 2022-08-19 05:44:19.355839\n",
      "resetting env. episode 1773, reward total was -18.0. running mean: -20.1206064910377, timestamp: 2022-08-19 05:44:22.822880\n",
      "resetting env. episode 1774, reward total was -18.0. running mean: -20.099400426127325, timestamp: 2022-08-19 05:44:27.078931\n",
      "resetting env. episode 1775, reward total was -21.0. running mean: -20.108406421866054, timestamp: 2022-08-19 05:44:29.965959\n",
      "resetting env. episode 1776, reward total was -21.0. running mean: -20.117322357647392, timestamp: 2022-08-19 05:44:33.436000\n",
      "resetting env. episode 1777, reward total was -21.0. running mean: -20.126149134070918, timestamp: 2022-08-19 05:44:35.827028\n",
      "resetting env. episode 1778, reward total was -20.0. running mean: -20.124887642730208, timestamp: 2022-08-19 05:44:39.492067\n",
      "resetting env. episode 1779, reward total was -19.0. running mean: -20.113638766302905, timestamp: 2022-08-19 05:44:43.830117\n",
      "resetting env. episode 1780, reward total was -20.0. running mean: -20.112502378639874, timestamp: 2022-08-19 05:44:47.642734\n",
      "resetting env. episode 1781, reward total was -20.0. running mean: -20.111377354853474, timestamp: 2022-08-19 05:44:53.355801\n",
      "resetting env. episode 1782, reward total was -19.0. running mean: -20.10026358130494, timestamp: 2022-08-19 05:45:01.463942\n",
      "resetting env. episode 1783, reward total was -19.0. running mean: -20.08926094549189, timestamp: 2022-08-19 05:45:06.852005\n",
      "resetting env. episode 1784, reward total was -21.0. running mean: -20.098368336036973, timestamp: 2022-08-19 05:45:10.638048\n",
      "resetting env. episode 1785, reward total was -20.0. running mean: -20.097384652676602, timestamp: 2022-08-19 05:45:14.609093\n",
      "resetting env. episode 1786, reward total was -19.0. running mean: -20.08641080614984, timestamp: 2022-08-19 05:45:19.080142\n",
      "resetting env. episode 1787, reward total was -20.0. running mean: -20.08554669808834, timestamp: 2022-08-19 05:45:22.805185\n",
      "resetting env. episode 1788, reward total was -20.0. running mean: -20.084691231107456, timestamp: 2022-08-19 05:45:25.979221\n",
      "resetting env. episode 1789, reward total was -19.0. running mean: -20.073844318796382, timestamp: 2022-08-19 05:45:30.283270\n",
      "resetting env. episode 1790, reward total was -19.0. running mean: -20.063105875608418, timestamp: 2022-08-19 05:45:33.721306\n",
      "resetting env. episode 1791, reward total was -21.0. running mean: -20.072474816852335, timestamp: 2022-08-19 05:45:37.891357\n",
      "resetting env. episode 1792, reward total was -20.0. running mean: -20.071750068683812, timestamp: 2022-08-19 05:45:41.466396\n",
      "resetting env. episode 1793, reward total was -21.0. running mean: -20.081032567996974, timestamp: 2022-08-19 05:45:45.366439\n",
      "resetting env. episode 1794, reward total was -20.0. running mean: -20.080222242317003, timestamp: 2022-08-19 05:45:49.969494\n",
      "resetting env. episode 1795, reward total was -19.0. running mean: -20.069420019893833, timestamp: 2022-08-19 05:45:53.025528\n",
      "resetting env. episode 1796, reward total was -20.0. running mean: -20.068725819694894, timestamp: 2022-08-19 05:45:56.117563\n",
      "resetting env. episode 1797, reward total was -21.0. running mean: -20.078038561497944, timestamp: 2022-08-19 05:45:58.256584\n",
      "resetting env. episode 1798, reward total was -21.0. running mean: -20.087258175882965, timestamp: 2022-08-19 05:46:00.967619\n",
      "resetting env. episode 1799, reward total was -20.0. running mean: -20.086385594124135, timestamp: 2022-08-19 05:46:03.406643\n",
      "resetting env. episode 1800, reward total was -20.0. running mean: -20.08552173818289, timestamp: 2022-08-19 05:46:06.286674\n",
      "resetting env. episode 1801, reward total was -18.0. running mean: -20.06466652080106, timestamp: 2022-08-19 05:46:09.452712\n",
      "resetting env. episode 1802, reward total was -21.0. running mean: -20.07401985559305, timestamp: 2022-08-19 05:46:12.482745\n",
      "resetting env. episode 1803, reward total was -20.0. running mean: -20.07327965703712, timestamp: 2022-08-19 05:46:15.190779\n",
      "resetting env. episode 1804, reward total was -20.0. running mean: -20.072546860466748, timestamp: 2022-08-19 05:46:17.649806\n",
      "resetting env. episode 1805, reward total was -21.0. running mean: -20.081821391862082, timestamp: 2022-08-19 05:46:20.333834\n",
      "resetting env. episode 1806, reward total was -21.0. running mean: -20.091003177943463, timestamp: 2022-08-19 05:46:22.368858\n",
      "resetting env. episode 1807, reward total was -21.0. running mean: -20.100093146164028, timestamp: 2022-08-19 05:46:25.358895\n",
      "resetting env. episode 1808, reward total was -21.0. running mean: -20.10909221470239, timestamp: 2022-08-19 05:46:28.005922\n",
      "resetting env. episode 1809, reward total was -21.0. running mean: -20.118001292555366, timestamp: 2022-08-19 05:46:31.161958\n",
      "resetting env. episode 1810, reward total was -20.0. running mean: -20.11682127962981, timestamp: 2022-08-19 05:46:33.798985\n",
      "resetting env. episode 1811, reward total was -20.0. running mean: -20.115653066833513, timestamp: 2022-08-19 05:46:36.561017\n",
      "resetting env. episode 1812, reward total was -19.0. running mean: -20.10449653616518, timestamp: 2022-08-19 05:46:38.873047\n",
      "resetting env. episode 1813, reward total was -17.0. running mean: -20.073451570803527, timestamp: 2022-08-19 05:46:42.066082\n",
      "resetting env. episode 1814, reward total was -20.0. running mean: -20.07271705509549, timestamp: 2022-08-19 05:46:44.744113\n",
      "resetting env. episode 1815, reward total was -17.0. running mean: -20.041989884544538, timestamp: 2022-08-19 05:46:48.411151\n",
      "resetting env. episode 1816, reward total was -19.0. running mean: -20.031569985699093, timestamp: 2022-08-19 05:46:52.061195\n",
      "resetting env. episode 1817, reward total was -19.0. running mean: -20.021254285842105, timestamp: 2022-08-19 05:46:55.388230\n",
      "resetting env. episode 1818, reward total was -20.0. running mean: -20.021041742983684, timestamp: 2022-08-19 05:46:57.997266\n",
      "resetting env. episode 1819, reward total was -19.0. running mean: -20.01083132555385, timestamp: 2022-08-19 05:47:02.462309\n",
      "resetting env. episode 1820, reward total was -21.0. running mean: -20.020723012298312, timestamp: 2022-08-19 05:47:05.604346\n",
      "resetting env. episode 1821, reward total was -21.0. running mean: -20.03051578217533, timestamp: 2022-08-19 05:47:07.607371\n",
      "resetting env. episode 1822, reward total was -19.0. running mean: -20.020210624353577, timestamp: 2022-08-19 05:47:10.641402\n",
      "resetting env. episode 1823, reward total was -21.0. running mean: -20.03000851811004, timestamp: 2022-08-19 05:47:13.801440\n",
      "resetting env. episode 1824, reward total was -20.0. running mean: -20.02970843292894, timestamp: 2022-08-19 05:47:16.732472\n",
      "resetting env. episode 1825, reward total was -20.0. running mean: -20.02941134859965, timestamp: 2022-08-19 05:47:18.910500\n",
      "resetting env. episode 1826, reward total was -20.0. running mean: -20.029117235113652, timestamp: 2022-08-19 05:47:21.535525\n",
      "resetting env. episode 1827, reward total was -21.0. running mean: -20.038826062762517, timestamp: 2022-08-19 05:47:24.075553\n",
      "resetting env. episode 1828, reward total was -20.0. running mean: -20.03843780213489, timestamp: 2022-08-19 05:47:26.444582\n",
      "resetting env. episode 1829, reward total was -21.0. running mean: -20.04805342411354, timestamp: 2022-08-19 05:47:29.374616\n",
      "resetting env. episode 1830, reward total was -18.0. running mean: -20.027572889872403, timestamp: 2022-08-19 05:47:33.591659\n",
      "resetting env. episode 1831, reward total was -16.0. running mean: -19.98729716097368, timestamp: 2022-08-19 05:47:37.564704\n",
      "resetting env. episode 1832, reward total was -21.0. running mean: -19.997424189363944, timestamp: 2022-08-19 05:47:41.137744\n",
      "resetting env. episode 1833, reward total was -20.0. running mean: -19.997449947470304, timestamp: 2022-08-19 05:47:44.154778\n",
      "resetting env. episode 1834, reward total was -20.0. running mean: -19.9974754479956, timestamp: 2022-08-19 05:47:47.487817\n",
      "resetting env. episode 1835, reward total was -19.0. running mean: -19.987500693515646, timestamp: 2022-08-19 05:47:51.088856\n",
      "resetting env. episode 1836, reward total was -19.0. running mean: -19.97762568658049, timestamp: 2022-08-19 05:47:54.447896\n",
      "resetting env. episode 1837, reward total was -21.0. running mean: -19.987849429714686, timestamp: 2022-08-19 05:47:56.849923\n",
      "resetting env. episode 1838, reward total was -20.0. running mean: -19.98797093541754, timestamp: 2022-08-19 05:47:59.476950\n",
      "resetting env. episode 1839, reward total was -20.0. running mean: -19.988091226063364, timestamp: 2022-08-19 05:48:02.465986\n",
      "resetting env. episode 1840, reward total was -19.0. running mean: -19.97821031380273, timestamp: 2022-08-19 05:48:06.246025\n",
      "resetting env. episode 1841, reward total was -20.0. running mean: -19.978428210664703, timestamp: 2022-08-19 05:48:09.102061\n",
      "resetting env. episode 1842, reward total was -21.0. running mean: -19.988643928558055, timestamp: 2022-08-19 05:48:12.174091\n",
      "resetting env. episode 1843, reward total was -19.0. running mean: -19.978757489272475, timestamp: 2022-08-19 05:48:15.376127\n",
      "resetting env. episode 1844, reward total was -21.0. running mean: -19.98896991437975, timestamp: 2022-08-19 05:48:18.430161\n",
      "resetting env. episode 1845, reward total was -21.0. running mean: -19.999080215235956, timestamp: 2022-08-19 05:48:21.161191\n",
      "resetting env. episode 1846, reward total was -21.0. running mean: -20.009089413083597, timestamp: 2022-08-19 05:48:24.468755\n",
      "resetting env. episode 1847, reward total was -20.0. running mean: -20.00899851895276, timestamp: 2022-08-19 05:48:27.641788\n",
      "resetting env. episode 1848, reward total was -19.0. running mean: -19.998908533763235, timestamp: 2022-08-19 05:48:31.056824\n",
      "resetting env. episode 1849, reward total was -20.0. running mean: -19.9989194484256, timestamp: 2022-08-19 05:48:33.354850\n",
      "resetting env. episode 1850, reward total was -20.0. running mean: -19.998930253941342, timestamp: 2022-08-19 05:48:35.779874\n",
      "resetting env. episode 1851, reward total was -19.0. running mean: -19.98894095140193, timestamp: 2022-08-19 05:48:38.843909\n",
      "resetting env. episode 1852, reward total was -21.0. running mean: -19.999051541887912, timestamp: 2022-08-19 05:48:40.960932\n",
      "resetting env. episode 1853, reward total was -20.0. running mean: -19.999061026469032, timestamp: 2022-08-19 05:48:43.942965\n",
      "resetting env. episode 1854, reward total was -21.0. running mean: -20.00907041620434, timestamp: 2022-08-19 05:48:46.812996\n",
      "resetting env. episode 1855, reward total was -20.0. running mean: -20.008979712042297, timestamp: 2022-08-19 05:48:49.697030\n",
      "resetting env. episode 1856, reward total was -21.0. running mean: -20.018889914921875, timestamp: 2022-08-19 05:48:51.687051\n",
      "resetting env. episode 1857, reward total was -21.0. running mean: -20.028701015772658, timestamp: 2022-08-19 05:48:54.825089\n",
      "resetting env. episode 1858, reward total was -21.0. running mean: -20.038414005614932, timestamp: 2022-08-19 05:48:57.648119\n",
      "resetting env. episode 1859, reward total was -21.0. running mean: -20.04802986555878, timestamp: 2022-08-19 05:49:00.685155\n",
      "resetting env. episode 1860, reward total was -21.0. running mean: -20.057549566903194, timestamp: 2022-08-19 05:49:02.676173\n",
      "resetting env. episode 1861, reward total was -20.0. running mean: -20.056974071234162, timestamp: 2022-08-19 05:49:05.917210\n",
      "resetting env. episode 1862, reward total was -17.0. running mean: -20.02640433052182, timestamp: 2022-08-19 05:49:09.202248\n",
      "resetting env. episode 1863, reward total was -21.0. running mean: -20.036140287216604, timestamp: 2022-08-19 05:49:12.845289\n",
      "resetting env. episode 1864, reward total was -19.0. running mean: -20.02577888434444, timestamp: 2022-08-19 05:49:16.226327\n",
      "resetting env. episode 1865, reward total was -20.0. running mean: -20.025521095500995, timestamp: 2022-08-19 05:49:19.028355\n",
      "resetting env. episode 1866, reward total was -20.0. running mean: -20.025265884545984, timestamp: 2022-08-19 05:49:22.091390\n",
      "resetting env. episode 1867, reward total was -18.0. running mean: -20.005013225700523, timestamp: 2022-08-19 05:49:25.360426\n",
      "resetting env. episode 1868, reward total was -17.0. running mean: -19.97496309344352, timestamp: 2022-08-19 05:49:28.790465\n",
      "resetting env. episode 1869, reward total was -21.0. running mean: -19.985213462509087, timestamp: 2022-08-19 05:49:31.831498\n",
      "resetting env. episode 1870, reward total was -19.0. running mean: -19.975361327884, timestamp: 2022-08-19 05:49:34.936528\n",
      "resetting env. episode 1871, reward total was -20.0. running mean: -19.975607714605157, timestamp: 2022-08-19 05:49:38.142564\n",
      "resetting env. episode 1872, reward total was -19.0. running mean: -19.965851637459107, timestamp: 2022-08-19 05:49:42.101607\n",
      "resetting env. episode 1873, reward total was -19.0. running mean: -19.956193121084517, timestamp: 2022-08-19 05:49:44.751636\n",
      "resetting env. episode 1874, reward total was -20.0. running mean: -19.956631189873672, timestamp: 2022-08-19 05:49:47.547668\n",
      "resetting env. episode 1875, reward total was -21.0. running mean: -19.967064877974938, timestamp: 2022-08-19 05:49:49.826695\n",
      "resetting env. episode 1876, reward total was -19.0. running mean: -19.957394229195188, timestamp: 2022-08-19 05:49:53.142729\n",
      "resetting env. episode 1877, reward total was -16.0. running mean: -19.917820286903236, timestamp: 2022-08-19 05:49:57.136774\n",
      "resetting env. episode 1878, reward total was -21.0. running mean: -19.928642084034205, timestamp: 2022-08-19 05:49:59.686805\n",
      "resetting env. episode 1879, reward total was -19.0. running mean: -19.919355663193866, timestamp: 2022-08-19 05:50:03.234844\n",
      "resetting env. episode 1880, reward total was -19.0. running mean: -19.910162106561927, timestamp: 2022-08-19 05:50:06.765880\n",
      "resetting env. episode 1881, reward total was -20.0. running mean: -19.911060485496307, timestamp: 2022-08-19 05:50:10.110916\n",
      "resetting env. episode 1882, reward total was -20.0. running mean: -19.911949880641345, timestamp: 2022-08-19 05:50:13.051949\n",
      "resetting env. episode 1883, reward total was -20.0. running mean: -19.91283038183493, timestamp: 2022-08-19 05:50:15.780986\n",
      "resetting env. episode 1884, reward total was -19.0. running mean: -19.903702078016583, timestamp: 2022-08-19 05:50:19.216016\n",
      "resetting env. episode 1885, reward total was -21.0. running mean: -19.914665057236416, timestamp: 2022-08-19 05:50:21.382041\n",
      "resetting env. episode 1886, reward total was -18.0. running mean: -19.895518406664053, timestamp: 2022-08-19 05:50:24.353073\n",
      "resetting env. episode 1887, reward total was -21.0. running mean: -19.906563222597413, timestamp: 2022-08-19 05:50:27.146103\n",
      "resetting env. episode 1888, reward total was -21.0. running mean: -19.91749759037144, timestamp: 2022-08-19 05:50:29.336128\n",
      "resetting env. episode 1889, reward total was -20.0. running mean: -19.918322614467723, timestamp: 2022-08-19 05:50:32.212158\n",
      "resetting env. episode 1890, reward total was -21.0. running mean: -19.929139388323048, timestamp: 2022-08-19 05:50:34.312183\n",
      "resetting env. episode 1891, reward total was -20.0. running mean: -19.929847994439815, timestamp: 2022-08-19 05:50:37.703222\n",
      "resetting env. episode 1892, reward total was -19.0. running mean: -19.920549514495416, timestamp: 2022-08-19 05:50:40.276247\n",
      "resetting env. episode 1893, reward total was -20.0. running mean: -19.92134401935046, timestamp: 2022-08-19 05:50:42.974275\n",
      "resetting env. episode 1894, reward total was -21.0. running mean: -19.932130579156958, timestamp: 2022-08-19 05:50:45.459304\n",
      "resetting env. episode 1895, reward total was -20.0. running mean: -19.932809273365386, timestamp: 2022-08-19 05:50:47.954331\n",
      "resetting env. episode 1896, reward total was -21.0. running mean: -19.943481180631732, timestamp: 2022-08-19 05:50:50.029357\n",
      "resetting env. episode 1897, reward total was -21.0. running mean: -19.954046368825416, timestamp: 2022-08-19 05:50:52.983387\n",
      "resetting env. episode 1898, reward total was -20.0. running mean: -19.95450590513716, timestamp: 2022-08-19 05:50:55.475414\n",
      "resetting env. episode 1899, reward total was -18.0. running mean: -19.93496084608579, timestamp: 2022-08-19 05:50:57.982439\n",
      "resetting env. episode 1900, reward total was -20.0. running mean: -19.935611237624933, timestamp: 2022-08-19 05:51:00.842469\n",
      "resetting env. episode 1901, reward total was -19.0. running mean: -19.926255125248684, timestamp: 2022-08-19 05:51:03.895508\n",
      "resetting env. episode 1902, reward total was -20.0. running mean: -19.926992573996195, timestamp: 2022-08-19 05:51:06.582533\n",
      "resetting env. episode 1903, reward total was -19.0. running mean: -19.917722648256234, timestamp: 2022-08-19 05:51:09.895570\n",
      "resetting env. episode 1904, reward total was -20.0. running mean: -19.918545421773672, timestamp: 2022-08-19 05:51:13.168609\n",
      "resetting env. episode 1905, reward total was -19.0. running mean: -19.909359967555936, timestamp: 2022-08-19 05:51:16.118639\n",
      "resetting env. episode 1906, reward total was -19.0. running mean: -19.900266367880377, timestamp: 2022-08-19 05:51:19.708679\n",
      "resetting env. episode 1907, reward total was -21.0. running mean: -19.911263704201573, timestamp: 2022-08-19 05:51:23.776722\n",
      "resetting env. episode 1908, reward total was -20.0. running mean: -19.912151067159556, timestamp: 2022-08-19 05:51:27.270759\n",
      "resetting env. episode 1909, reward total was -21.0. running mean: -19.92302955648796, timestamp: 2022-08-19 05:51:29.760790\n",
      "resetting env. episode 1910, reward total was -21.0. running mean: -19.93379926092308, timestamp: 2022-08-19 05:51:32.885820\n",
      "resetting env. episode 1911, reward total was -19.0. running mean: -19.924461268313852, timestamp: 2022-08-19 05:51:36.583860\n",
      "resetting env. episode 1912, reward total was -20.0. running mean: -19.925216655630713, timestamp: 2022-08-19 05:51:39.826899\n",
      "resetting env. episode 1913, reward total was -19.0. running mean: -19.91596448907441, timestamp: 2022-08-19 05:51:42.743927\n",
      "resetting env. episode 1914, reward total was -21.0. running mean: -19.926804844183664, timestamp: 2022-08-19 05:51:45.210956\n",
      "resetting env. episode 1915, reward total was -20.0. running mean: -19.927536795741826, timestamp: 2022-08-19 05:51:47.972982\n",
      "resetting env. episode 1916, reward total was -18.0. running mean: -19.908261427784407, timestamp: 2022-08-19 05:51:50.848014\n",
      "resetting env. episode 1917, reward total was -19.0. running mean: -19.899178813506563, timestamp: 2022-08-19 05:51:54.186050\n",
      "resetting env. episode 1918, reward total was -20.0. running mean: -19.900187025371498, timestamp: 2022-08-19 05:51:56.713077\n",
      "resetting env. episode 1919, reward total was -21.0. running mean: -19.911185155117785, timestamp: 2022-08-19 05:51:59.197109\n",
      "resetting env. episode 1920, reward total was -21.0. running mean: -19.92207330356661, timestamp: 2022-08-19 05:52:01.884132\n",
      "resetting env. episode 1921, reward total was -19.0. running mean: -19.912852570530944, timestamp: 2022-08-19 05:52:04.968168\n",
      "resetting env. episode 1922, reward total was -18.0. running mean: -19.893724044825635, timestamp: 2022-08-19 05:52:08.102200\n",
      "resetting env. episode 1923, reward total was -21.0. running mean: -19.90478680437738, timestamp: 2022-08-19 05:52:10.505227\n",
      "resetting env. episode 1924, reward total was -18.0. running mean: -19.885738936333606, timestamp: 2022-08-19 05:52:13.423262\n",
      "resetting env. episode 1925, reward total was -21.0. running mean: -19.89688154697027, timestamp: 2022-08-19 05:52:15.625284\n",
      "resetting env. episode 1926, reward total was -21.0. running mean: -19.90791273150057, timestamp: 2022-08-19 05:52:18.347309\n",
      "resetting env. episode 1927, reward total was -21.0. running mean: -19.918833604185565, timestamp: 2022-08-19 05:52:21.703349\n",
      "resetting env. episode 1928, reward total was -21.0. running mean: -19.92964526814371, timestamp: 2022-08-19 05:52:24.293374\n",
      "resetting env. episode 1929, reward total was -21.0. running mean: -19.940348815462272, timestamp: 2022-08-19 05:52:27.175404\n",
      "resetting env. episode 1930, reward total was -21.0. running mean: -19.95094532730765, timestamp: 2022-08-19 05:52:30.101435\n",
      "resetting env. episode 1931, reward total was -21.0. running mean: -19.961435874034574, timestamp: 2022-08-19 05:52:33.516473\n",
      "resetting env. episode 1932, reward total was -20.0. running mean: -19.96182151529423, timestamp: 2022-08-19 05:52:36.666508\n",
      "resetting env. episode 1933, reward total was -20.0. running mean: -19.962203300141287, timestamp: 2022-08-19 05:52:39.761538\n",
      "resetting env. episode 1934, reward total was -20.0. running mean: -19.96258126713987, timestamp: 2022-08-19 05:52:42.852576\n",
      "resetting env. episode 1935, reward total was -18.0. running mean: -19.94295545446847, timestamp: 2022-08-19 05:52:46.140612\n",
      "resetting env. episode 1936, reward total was -21.0. running mean: -19.953525899923786, timestamp: 2022-08-19 05:52:48.758637\n",
      "resetting env. episode 1937, reward total was -19.0. running mean: -19.94399064092455, timestamp: 2022-08-19 05:52:51.456666\n",
      "resetting env. episode 1938, reward total was -21.0. running mean: -19.954550734515305, timestamp: 2022-08-19 05:52:53.785694\n",
      "resetting env. episode 1939, reward total was -19.0. running mean: -19.945005227170153, timestamp: 2022-08-19 05:52:56.907729\n",
      "resetting env. episode 1940, reward total was -21.0. running mean: -19.955555174898453, timestamp: 2022-08-19 05:52:59.376752\n",
      "resetting env. episode 1941, reward total was -21.0. running mean: -19.965999623149468, timestamp: 2022-08-19 05:53:01.666779\n",
      "resetting env. episode 1942, reward total was -18.0. running mean: -19.946339626917972, timestamp: 2022-08-19 05:53:04.661809\n",
      "resetting env. episode 1943, reward total was -20.0. running mean: -19.94687623064879, timestamp: 2022-08-19 05:53:07.467841\n",
      "resetting env. episode 1944, reward total was -19.0. running mean: -19.937407468342304, timestamp: 2022-08-19 05:53:11.376885\n",
      "resetting env. episode 1945, reward total was -20.0. running mean: -19.93803339365888, timestamp: 2022-08-19 05:53:14.200916\n",
      "resetting env. episode 1946, reward total was -20.0. running mean: -19.93865305972229, timestamp: 2022-08-19 05:53:17.446951\n",
      "resetting env. episode 1947, reward total was -19.0. running mean: -19.92926652912507, timestamp: 2022-08-19 05:53:20.827988\n",
      "resetting env. episode 1948, reward total was -19.0. running mean: -19.91997386383382, timestamp: 2022-08-19 05:53:23.672023\n",
      "resetting env. episode 1949, reward total was -21.0. running mean: -19.930774125195484, timestamp: 2022-08-19 05:53:26.525052\n",
      "resetting env. episode 1950, reward total was -18.0. running mean: -19.91146638394353, timestamp: 2022-08-19 05:53:30.177094\n",
      "resetting env. episode 1951, reward total was -20.0. running mean: -19.912351720104095, timestamp: 2022-08-19 05:53:33.218126\n",
      "resetting env. episode 1952, reward total was -20.0. running mean: -19.913228202903053, timestamp: 2022-08-19 05:53:36.620165\n",
      "resetting env. episode 1953, reward total was -17.0. running mean: -19.884095920874024, timestamp: 2022-08-19 05:53:40.926217\n",
      "resetting env. episode 1954, reward total was -20.0. running mean: -19.885254961665282, timestamp: 2022-08-19 05:53:44.033252\n",
      "resetting env. episode 1955, reward total was -19.0. running mean: -19.87640241204863, timestamp: 2022-08-19 05:53:47.287287\n",
      "resetting env. episode 1956, reward total was -17.0. running mean: -19.847638387928146, timestamp: 2022-08-19 05:53:50.869327\n",
      "resetting env. episode 1957, reward total was -20.0. running mean: -19.849162004048864, timestamp: 2022-08-19 05:53:53.524359\n",
      "resetting env. episode 1958, reward total was -21.0. running mean: -19.860670384008376, timestamp: 2022-08-19 05:53:56.238391\n",
      "resetting env. episode 1959, reward total was -21.0. running mean: -19.872063680168292, timestamp: 2022-08-19 05:53:58.248409\n",
      "resetting env. episode 1960, reward total was -20.0. running mean: -19.87334304336661, timestamp: 2022-08-19 05:54:00.906440\n",
      "resetting env. episode 1961, reward total was -21.0. running mean: -19.884609612932945, timestamp: 2022-08-19 05:54:03.769475\n",
      "resetting env. episode 1962, reward total was -21.0. running mean: -19.895763516803616, timestamp: 2022-08-19 05:54:06.685509\n",
      "resetting env. episode 1963, reward total was -21.0. running mean: -19.90680588163558, timestamp: 2022-08-19 05:54:10.281550\n",
      "resetting env. episode 1964, reward total was -20.0. running mean: -19.907737822819225, timestamp: 2022-08-19 05:54:13.391583\n",
      "resetting env. episode 1965, reward total was -20.0. running mean: -19.908660444591032, timestamp: 2022-08-19 05:54:15.792614\n",
      "resetting env. episode 1966, reward total was -21.0. running mean: -19.919573840145123, timestamp: 2022-08-19 05:54:18.506642\n",
      "resetting env. episode 1967, reward total was -21.0. running mean: -19.930378101743674, timestamp: 2022-08-19 05:54:21.147672\n",
      "resetting env. episode 1968, reward total was -21.0. running mean: -19.941074320726237, timestamp: 2022-08-19 05:54:23.774705\n",
      "resetting env. episode 1969, reward total was -19.0. running mean: -19.931663577518975, timestamp: 2022-08-19 05:54:26.645737\n",
      "resetting env. episode 1970, reward total was -20.0. running mean: -19.932346941743784, timestamp: 2022-08-19 05:54:29.784770\n",
      "resetting env. episode 1971, reward total was -20.0. running mean: -19.933023472326344, timestamp: 2022-08-19 05:54:32.310799\n",
      "resetting env. episode 1972, reward total was -21.0. running mean: -19.94369323760308, timestamp: 2022-08-19 05:54:35.021830\n",
      "resetting env. episode 1973, reward total was -20.0. running mean: -19.94425630522705, timestamp: 2022-08-19 05:54:38.109866\n",
      "resetting env. episode 1974, reward total was -20.0. running mean: -19.94481374217478, timestamp: 2022-08-19 05:54:40.773900\n",
      "resetting env. episode 1975, reward total was -18.0. running mean: -19.925365604753033, timestamp: 2022-08-19 05:54:43.725935\n",
      "resetting env. episode 1976, reward total was -21.0. running mean: -19.936111948705502, timestamp: 2022-08-19 05:54:46.535964\n",
      "resetting env. episode 1977, reward total was -19.0. running mean: -19.92675082921845, timestamp: 2022-08-19 05:54:49.797001\n",
      "resetting env. episode 1978, reward total was -21.0. running mean: -19.937483320926265, timestamp: 2022-08-19 05:54:51.829026\n",
      "resetting env. episode 1979, reward total was -19.0. running mean: -19.928108487717004, timestamp: 2022-08-19 05:54:55.110063\n",
      "resetting env. episode 1980, reward total was -20.0. running mean: -19.928827402839833, timestamp: 2022-08-19 05:54:57.954098\n",
      "resetting env. episode 1981, reward total was -20.0. running mean: -19.929539128811435, timestamp: 2022-08-19 05:55:01.883150\n",
      "resetting env. episode 1982, reward total was -21.0. running mean: -19.94024373752332, timestamp: 2022-08-19 05:55:04.282169\n",
      "resetting env. episode 1983, reward total was -20.0. running mean: -19.940841300148087, timestamp: 2022-08-19 05:55:07.574209\n",
      "resetting env. episode 1984, reward total was -20.0. running mean: -19.941432887146604, timestamp: 2022-08-19 05:55:11.294251\n",
      "resetting env. episode 1985, reward total was -21.0. running mean: -19.95201855827514, timestamp: 2022-08-19 05:55:14.104286\n",
      "resetting env. episode 1986, reward total was -20.0. running mean: -19.952498372692386, timestamp: 2022-08-19 05:55:16.853315\n",
      "resetting env. episode 1987, reward total was -18.0. running mean: -19.93297338896546, timestamp: 2022-08-19 05:55:20.648360\n",
      "resetting env. episode 1988, reward total was -19.0. running mean: -19.923643655075807, timestamp: 2022-08-19 05:55:23.991399\n",
      "resetting env. episode 1989, reward total was -17.0. running mean: -19.89440721852505, timestamp: 2022-08-19 05:55:28.005445\n",
      "resetting env. episode 1990, reward total was -18.0. running mean: -19.8754631463398, timestamp: 2022-08-19 05:55:31.037480\n",
      "resetting env. episode 1991, reward total was -20.0. running mean: -19.876708514876402, timestamp: 2022-08-19 05:55:33.619514\n",
      "resetting env. episode 1992, reward total was -20.0. running mean: -19.877941429727638, timestamp: 2022-08-19 05:55:36.003543\n",
      "resetting env. episode 1993, reward total was -20.0. running mean: -19.87916201543036, timestamp: 2022-08-19 05:55:38.893575\n",
      "resetting env. episode 1994, reward total was -21.0. running mean: -19.890370395276058, timestamp: 2022-08-19 05:55:41.343603\n",
      "resetting env. episode 1995, reward total was -21.0. running mean: -19.901466691323296, timestamp: 2022-08-19 05:55:43.606629\n",
      "resetting env. episode 1996, reward total was -19.0. running mean: -19.892452024410066, timestamp: 2022-08-19 05:55:47.075672\n",
      "resetting env. episode 1997, reward total was -18.0. running mean: -19.873527504165963, timestamp: 2022-08-19 05:55:50.745713\n",
      "resetting env. episode 1998, reward total was -16.0. running mean: -19.834792229124304, timestamp: 2022-08-19 05:55:54.172751\n",
      "resetting env. episode 1999, reward total was -21.0. running mean: -19.84644430683306, timestamp: 2022-08-19 05:55:57.546793\n",
      "resetting env. episode 2000, reward total was -21.0. running mean: -19.85797986376473, timestamp: 2022-08-19 05:55:59.934820\n",
      "resetting env. episode 2001, reward total was -18.0. running mean: -19.83940006512708, timestamp: 2022-08-19 05:56:03.076861\n",
      "resetting env. episode 2002, reward total was -20.0. running mean: -19.84100606447581, timestamp: 2022-08-19 05:56:06.730905\n",
      "resetting env. episode 2003, reward total was -21.0. running mean: -19.852596003831053, timestamp: 2022-08-19 05:56:09.196930\n",
      "resetting env. episode 2004, reward total was -21.0. running mean: -19.864070043792744, timestamp: 2022-08-19 05:56:11.608961\n",
      "resetting env. episode 2005, reward total was -19.0. running mean: -19.855429343354817, timestamp: 2022-08-19 05:56:15.013998\n",
      "resetting env. episode 2006, reward total was -20.0. running mean: -19.856875049921268, timestamp: 2022-08-19 05:56:17.965036\n",
      "resetting env. episode 2007, reward total was -18.0. running mean: -19.838306299422054, timestamp: 2022-08-19 05:56:21.801090\n",
      "resetting env. episode 2008, reward total was -18.0. running mean: -19.819923236427833, timestamp: 2022-08-19 05:56:25.674127\n",
      "resetting env. episode 2009, reward total was -21.0. running mean: -19.831724004063556, timestamp: 2022-08-19 05:56:28.125152\n",
      "resetting env. episode 2010, reward total was -21.0. running mean: -19.84340676402292, timestamp: 2022-08-19 05:56:31.298192\n",
      "resetting env. episode 2011, reward total was -19.0. running mean: -19.834972696382692, timestamp: 2022-08-19 05:56:34.360228\n",
      "resetting env. episode 2012, reward total was -20.0. running mean: -19.836622969418865, timestamp: 2022-08-19 05:56:37.590268\n",
      "resetting env. episode 2013, reward total was -21.0. running mean: -19.84825673972468, timestamp: 2022-08-19 05:56:41.162308\n",
      "resetting env. episode 2014, reward total was -19.0. running mean: -19.839774172327434, timestamp: 2022-08-19 05:56:43.737337\n",
      "resetting env. episode 2015, reward total was -19.0. running mean: -19.831376430604163, timestamp: 2022-08-19 05:56:47.312380\n",
      "resetting env. episode 2016, reward total was -20.0. running mean: -19.83306266629812, timestamp: 2022-08-19 05:56:49.817413\n",
      "resetting env. episode 2017, reward total was -19.0. running mean: -19.82473203963514, timestamp: 2022-08-19 05:56:52.897446\n",
      "resetting env. episode 2018, reward total was -20.0. running mean: -19.82648471923879, timestamp: 2022-08-19 05:56:56.253484\n",
      "resetting env. episode 2019, reward total was -20.0. running mean: -19.8282198720464, timestamp: 2022-08-19 05:56:58.881516\n",
      "resetting env. episode 2020, reward total was -19.0. running mean: -19.81993767332594, timestamp: 2022-08-19 05:57:01.405548\n",
      "resetting env. episode 2021, reward total was -20.0. running mean: -19.821738296592677, timestamp: 2022-08-19 05:57:04.276582\n",
      "resetting env. episode 2022, reward total was -21.0. running mean: -19.833520913626753, timestamp: 2022-08-19 05:57:06.739614\n",
      "resetting env. episode 2023, reward total was -21.0. running mean: -19.845185704490486, timestamp: 2022-08-19 05:57:09.330641\n",
      "resetting env. episode 2024, reward total was -21.0. running mean: -19.856733847445582, timestamp: 2022-08-19 05:57:12.137679\n",
      "resetting env. episode 2025, reward total was -21.0. running mean: -19.86816650897113, timestamp: 2022-08-19 05:57:14.988712\n",
      "resetting env. episode 2026, reward total was -20.0. running mean: -19.869484843881416, timestamp: 2022-08-19 05:57:17.410738\n",
      "resetting env. episode 2027, reward total was -20.0. running mean: -19.8707899954426, timestamp: 2022-08-19 05:57:20.578776\n",
      "resetting env. episode 2028, reward total was -20.0. running mean: -19.872082095488175, timestamp: 2022-08-19 05:57:23.425810\n",
      "resetting env. episode 2029, reward total was -20.0. running mean: -19.87336127453329, timestamp: 2022-08-19 05:57:26.694850\n",
      "resetting env. episode 2030, reward total was -19.0. running mean: -19.86462766178796, timestamp: 2022-08-19 05:57:30.210891\n",
      "resetting env. episode 2031, reward total was -21.0. running mean: -19.875981385170082, timestamp: 2022-08-19 05:57:33.226932\n",
      "resetting env. episode 2032, reward total was -20.0. running mean: -19.87722157131838, timestamp: 2022-08-19 05:57:35.663966\n",
      "resetting env. episode 2033, reward total was -20.0. running mean: -19.878449355605195, timestamp: 2022-08-19 05:57:38.415991\n",
      "resetting env. episode 2034, reward total was -18.0. running mean: -19.859664862049144, timestamp: 2022-08-19 05:57:41.236027\n",
      "resetting env. episode 2035, reward total was -19.0. running mean: -19.851068213428654, timestamp: 2022-08-19 05:57:44.227060\n",
      "resetting env. episode 2036, reward total was -20.0. running mean: -19.852557531294366, timestamp: 2022-08-19 05:57:47.032098\n",
      "resetting env. episode 2037, reward total was -20.0. running mean: -19.854031955981423, timestamp: 2022-08-19 05:57:50.029128\n",
      "resetting env. episode 2038, reward total was -20.0. running mean: -19.855491636421608, timestamp: 2022-08-19 05:57:52.736165\n",
      "resetting env. episode 2039, reward total was -21.0. running mean: -19.866936720057392, timestamp: 2022-08-19 05:57:54.926188\n",
      "resetting env. episode 2040, reward total was -21.0. running mean: -19.87826735285682, timestamp: 2022-08-19 05:57:57.022215\n",
      "resetting env. episode 2041, reward total was -21.0. running mean: -19.889484679328252, timestamp: 2022-08-19 05:57:59.853247\n",
      "resetting env. episode 2042, reward total was -20.0. running mean: -19.890589832534967, timestamp: 2022-08-19 05:58:02.155274\n",
      "resetting env. episode 2043, reward total was -21.0. running mean: -19.90168393420962, timestamp: 2022-08-19 05:58:04.870310\n",
      "resetting env. episode 2044, reward total was -18.0. running mean: -19.88266709486752, timestamp: 2022-08-19 05:58:08.188350\n",
      "resetting env. episode 2045, reward total was -21.0. running mean: -19.893840423918846, timestamp: 2022-08-19 05:58:10.925382\n",
      "resetting env. episode 2046, reward total was -19.0. running mean: -19.884902019679657, timestamp: 2022-08-19 05:58:14.095422\n",
      "resetting env. episode 2047, reward total was -18.0. running mean: -19.86605299948286, timestamp: 2022-08-19 05:58:17.186454\n",
      "resetting env. episode 2048, reward total was -20.0. running mean: -19.86739246948803, timestamp: 2022-08-19 05:58:20.038493\n",
      "resetting env. episode 2049, reward total was -21.0. running mean: -19.878718544793152, timestamp: 2022-08-19 05:58:22.756522\n",
      "resetting env. episode 2050, reward total was -21.0. running mean: -19.889931359345223, timestamp: 2022-08-19 05:58:25.110552\n",
      "resetting env. episode 2051, reward total was -21.0. running mean: -19.901032045751773, timestamp: 2022-08-19 05:58:27.671580\n",
      "resetting env. episode 2052, reward total was -20.0. running mean: -19.902021725294254, timestamp: 2022-08-19 05:58:30.792619\n",
      "resetting env. episode 2053, reward total was -21.0. running mean: -19.91300150804131, timestamp: 2022-08-19 05:58:34.449664\n",
      "resetting env. episode 2054, reward total was -20.0. running mean: -19.913871492960897, timestamp: 2022-08-19 05:58:37.212699\n",
      "resetting env. episode 2055, reward total was -21.0. running mean: -19.924732778031288, timestamp: 2022-08-19 05:58:39.737726\n",
      "resetting env. episode 2056, reward total was -21.0. running mean: -19.935485450250976, timestamp: 2022-08-19 05:58:41.891751\n",
      "resetting env. episode 2057, reward total was -20.0. running mean: -19.936130595748466, timestamp: 2022-08-19 05:58:44.631787\n",
      "resetting env. episode 2058, reward total was -20.0. running mean: -19.93676928979098, timestamp: 2022-08-19 05:58:47.041817\n",
      "resetting env. episode 2059, reward total was -20.0. running mean: -19.93740159689307, timestamp: 2022-08-19 05:58:49.966852\n",
      "resetting env. episode 2060, reward total was -21.0. running mean: -19.94802758092414, timestamp: 2022-08-19 05:58:52.204876\n",
      "resetting env. episode 2061, reward total was -18.0. running mean: -19.928547305114897, timestamp: 2022-08-19 05:58:55.467916\n",
      "resetting env. episode 2062, reward total was -21.0. running mean: -19.93926183206375, timestamp: 2022-08-19 05:58:58.108947\n",
      "resetting env. episode 2063, reward total was -17.0. running mean: -19.909869213743114, timestamp: 2022-08-19 05:59:01.523989\n",
      "resetting env. episode 2064, reward total was -20.0. running mean: -19.91077052160568, timestamp: 2022-08-19 05:59:04.885036\n",
      "resetting env. episode 2065, reward total was -19.0. running mean: -19.901662816389624, timestamp: 2022-08-19 05:59:07.689062\n",
      "resetting env. episode 2066, reward total was -21.0. running mean: -19.91264618822573, timestamp: 2022-08-19 05:59:10.883104\n",
      "resetting env. episode 2067, reward total was -19.0. running mean: -19.90351972634347, timestamp: 2022-08-19 05:59:14.821148\n",
      "resetting env. episode 2068, reward total was -21.0. running mean: -19.91448452908004, timestamp: 2022-08-19 05:59:19.702207\n",
      "resetting env. episode 2069, reward total was -20.0. running mean: -19.915339683789238, timestamp: 2022-08-19 05:59:23.094252\n",
      "resetting env. episode 2070, reward total was -21.0. running mean: -19.926186286951346, timestamp: 2022-08-19 05:59:26.909294\n",
      "resetting env. episode 2071, reward total was -20.0. running mean: -19.926924424081832, timestamp: 2022-08-19 05:59:30.891349\n",
      "resetting env. episode 2072, reward total was -20.0. running mean: -19.927655179841015, timestamp: 2022-08-19 05:59:35.381921\n",
      "resetting env. episode 2073, reward total was -16.0. running mean: -19.888378628042606, timestamp: 2022-08-19 05:59:39.636972\n",
      "resetting env. episode 2074, reward total was -18.0. running mean: -19.86949484176218, timestamp: 2022-08-19 05:59:43.401017\n",
      "resetting env. episode 2075, reward total was -20.0. running mean: -19.870799893344557, timestamp: 2022-08-19 05:59:45.592044\n",
      "resetting env. episode 2076, reward total was -21.0. running mean: -19.88209189441111, timestamp: 2022-08-19 05:59:48.317075\n",
      "resetting env. episode 2077, reward total was -20.0. running mean: -19.883270975467, timestamp: 2022-08-19 05:59:51.105111\n",
      "resetting env. episode 2078, reward total was -19.0. running mean: -19.87443826571233, timestamp: 2022-08-19 05:59:53.895140\n",
      "resetting env. episode 2079, reward total was -21.0. running mean: -19.885693883055207, timestamp: 2022-08-19 05:59:56.770177\n",
      "resetting env. episode 2080, reward total was -21.0. running mean: -19.896836944224656, timestamp: 2022-08-19 06:00:00.328218\n",
      "resetting env. episode 2081, reward total was -20.0. running mean: -19.897868574782407, timestamp: 2022-08-19 06:00:03.125252\n",
      "resetting env. episode 2082, reward total was -20.0. running mean: -19.89888988903458, timestamp: 2022-08-19 06:00:05.711281\n",
      "resetting env. episode 2083, reward total was -21.0. running mean: -19.909900990144237, timestamp: 2022-08-19 06:00:08.352314\n",
      "resetting env. episode 2084, reward total was -21.0. running mean: -19.920801980242796, timestamp: 2022-08-19 06:00:11.349350\n",
      "resetting env. episode 2085, reward total was -21.0. running mean: -19.93159396044037, timestamp: 2022-08-19 06:00:13.583375\n",
      "resetting env. episode 2086, reward total was -20.0. running mean: -19.932278020835966, timestamp: 2022-08-19 06:00:16.447410\n",
      "resetting env. episode 2087, reward total was -21.0. running mean: -19.942955240627608, timestamp: 2022-08-19 06:00:18.666439\n",
      "resetting env. episode 2088, reward total was -21.0. running mean: -19.953525688221333, timestamp: 2022-08-19 06:00:21.368467\n",
      "resetting env. episode 2089, reward total was -19.0. running mean: -19.94399043133912, timestamp: 2022-08-19 06:00:23.782497\n",
      "resetting env. episode 2090, reward total was -21.0. running mean: -19.95455052702573, timestamp: 2022-08-19 06:00:26.943533\n",
      "resetting env. episode 2091, reward total was -21.0. running mean: -19.965005021755474, timestamp: 2022-08-19 06:00:29.545566\n",
      "resetting env. episode 2092, reward total was -21.0. running mean: -19.975354971537918, timestamp: 2022-08-19 06:00:31.738591\n",
      "resetting env. episode 2093, reward total was -19.0. running mean: -19.96560142182254, timestamp: 2022-08-19 06:00:35.196633\n",
      "resetting env. episode 2094, reward total was -21.0. running mean: -19.975945407604318, timestamp: 2022-08-19 06:00:38.125667\n",
      "resetting env. episode 2095, reward total was -18.0. running mean: -19.956185953528273, timestamp: 2022-08-19 06:00:42.220719\n",
      "resetting env. episode 2096, reward total was -18.0. running mean: -19.93662409399299, timestamp: 2022-08-19 06:00:45.198751\n",
      "resetting env. episode 2097, reward total was -19.0. running mean: -19.92725785305306, timestamp: 2022-08-19 06:00:48.199791\n",
      "resetting env. episode 2098, reward total was -21.0. running mean: -19.93798527452253, timestamp: 2022-08-19 06:00:50.701822\n",
      "resetting env. episode 2099, reward total was -21.0. running mean: -19.948605421777305, timestamp: 2022-08-19 06:00:53.668855\n",
      "resetting env. episode 2100, reward total was -20.0. running mean: -19.949119367559533, timestamp: 2022-08-19 06:00:56.569889\n",
      "resetting env. episode 2101, reward total was -19.0. running mean: -19.93962817388394, timestamp: 2022-08-19 06:00:59.266926\n",
      "resetting env. episode 2102, reward total was -21.0. running mean: -19.9502318921451, timestamp: 2022-08-19 06:01:02.072958\n",
      "resetting env. episode 2103, reward total was -20.0. running mean: -19.95072957322365, timestamp: 2022-08-19 06:01:04.574988\n",
      "resetting env. episode 2104, reward total was -21.0. running mean: -19.961222277491416, timestamp: 2022-08-19 06:01:06.986014\n",
      "resetting env. episode 2105, reward total was -18.0. running mean: -19.941610054716502, timestamp: 2022-08-19 06:01:10.542057\n",
      "resetting env. episode 2106, reward total was -20.0. running mean: -19.942193954169337, timestamp: 2022-08-19 06:01:13.682094\n",
      "resetting env. episode 2107, reward total was -19.0. running mean: -19.932772014627645, timestamp: 2022-08-19 06:01:17.372138\n",
      "resetting env. episode 2108, reward total was -20.0. running mean: -19.93344429448137, timestamp: 2022-08-19 06:01:19.827169\n",
      "resetting env. episode 2109, reward total was -21.0. running mean: -19.944109851536556, timestamp: 2022-08-19 06:01:22.941204\n",
      "resetting env. episode 2110, reward total was -21.0. running mean: -19.954668753021192, timestamp: 2022-08-19 06:01:26.145241\n",
      "resetting env. episode 2111, reward total was -20.0. running mean: -19.95512206549098, timestamp: 2022-08-19 06:01:29.233283\n",
      "resetting env. episode 2112, reward total was -20.0. running mean: -19.955570844836068, timestamp: 2022-08-19 06:01:32.048311\n",
      "resetting env. episode 2113, reward total was -21.0. running mean: -19.966015136387707, timestamp: 2022-08-19 06:01:34.758344\n",
      "resetting env. episode 2114, reward total was -18.0. running mean: -19.94635498502383, timestamp: 2022-08-19 06:01:37.831382\n",
      "resetting env. episode 2115, reward total was -21.0. running mean: -19.956891435173592, timestamp: 2022-08-19 06:01:40.741420\n",
      "resetting env. episode 2116, reward total was -20.0. running mean: -19.957322520821855, timestamp: 2022-08-19 06:01:43.349447\n",
      "resetting env. episode 2117, reward total was -20.0. running mean: -19.957749295613635, timestamp: 2022-08-19 06:01:46.467485\n",
      "resetting env. episode 2118, reward total was -20.0. running mean: -19.958171802657496, timestamp: 2022-08-19 06:01:49.522521\n",
      "resetting env. episode 2119, reward total was -19.0. running mean: -19.948590084630922, timestamp: 2022-08-19 06:01:52.755558\n",
      "resetting env. episode 2120, reward total was -21.0. running mean: -19.959104183784614, timestamp: 2022-08-19 06:01:56.021599\n",
      "resetting env. episode 2121, reward total was -20.0. running mean: -19.95951314194677, timestamp: 2022-08-19 06:01:58.730629\n",
      "resetting env. episode 2122, reward total was -21.0. running mean: -19.9699180105273, timestamp: 2022-08-19 06:02:01.325661\n",
      "resetting env. episode 2123, reward total was -20.0. running mean: -19.970218830422027, timestamp: 2022-08-19 06:02:04.402698\n",
      "resetting env. episode 2124, reward total was -21.0. running mean: -19.98051664211781, timestamp: 2022-08-19 06:02:06.854725\n",
      "resetting env. episode 2125, reward total was -21.0. running mean: -19.99071147569663, timestamp: 2022-08-19 06:02:09.569759\n",
      "resetting env. episode 2126, reward total was -21.0. running mean: -20.000804360939664, timestamp: 2022-08-19 06:02:12.215795\n",
      "resetting env. episode 2127, reward total was -19.0. running mean: -19.99079631733027, timestamp: 2022-08-19 06:02:15.547830\n",
      "resetting env. episode 2128, reward total was -20.0. running mean: -19.990888354156965, timestamp: 2022-08-19 06:02:18.682869\n",
      "resetting env. episode 2129, reward total was -21.0. running mean: -20.000979470615395, timestamp: 2022-08-19 06:02:21.069898\n",
      "resetting env. episode 2130, reward total was -19.0. running mean: -19.99096967590924, timestamp: 2022-08-19 06:02:23.855926\n",
      "resetting env. episode 2131, reward total was -18.0. running mean: -19.971059979150148, timestamp: 2022-08-19 06:02:26.992965\n",
      "resetting env. episode 2132, reward total was -20.0. running mean: -19.971349379358646, timestamp: 2022-08-19 06:02:29.784997\n",
      "resetting env. episode 2133, reward total was -21.0. running mean: -19.98163588556506, timestamp: 2022-08-19 06:02:32.615031\n",
      "resetting env. episode 2134, reward total was -21.0. running mean: -19.99181952670941, timestamp: 2022-08-19 06:02:35.219065\n",
      "resetting env. episode 2135, reward total was -21.0. running mean: -20.001901331442316, timestamp: 2022-08-19 06:02:37.463089\n",
      "resetting env. episode 2136, reward total was -20.0. running mean: -20.00188231812789, timestamp: 2022-08-19 06:02:40.069118\n",
      "resetting env. episode 2137, reward total was -20.0. running mean: -20.001863494946612, timestamp: 2022-08-19 06:02:43.097156\n",
      "resetting env. episode 2138, reward total was -21.0. running mean: -20.011844859997147, timestamp: 2022-08-19 06:02:45.783185\n",
      "resetting env. episode 2139, reward total was -20.0. running mean: -20.011726411397174, timestamp: 2022-08-19 06:02:48.792221\n",
      "resetting env. episode 2140, reward total was -20.0. running mean: -20.011609147283203, timestamp: 2022-08-19 06:02:51.832260\n",
      "resetting env. episode 2141, reward total was -21.0. running mean: -20.02149305581037, timestamp: 2022-08-19 06:02:53.974282\n",
      "resetting env. episode 2142, reward total was -21.0. running mean: -20.031278125252268, timestamp: 2022-08-19 06:02:56.799315\n",
      "resetting env. episode 2143, reward total was -19.0. running mean: -20.020965343999745, timestamp: 2022-08-19 06:02:59.205346\n",
      "resetting env. episode 2144, reward total was -20.0. running mean: -20.020755690559746, timestamp: 2022-08-19 06:03:01.861379\n",
      "resetting env. episode 2145, reward total was -20.0. running mean: -20.02054813365415, timestamp: 2022-08-19 06:03:05.010412\n",
      "resetting env. episode 2146, reward total was -19.0. running mean: -20.010342652317608, timestamp: 2022-08-19 06:03:07.790446\n",
      "resetting env. episode 2147, reward total was -21.0. running mean: -20.02023922579443, timestamp: 2022-08-19 06:03:10.801483\n",
      "resetting env. episode 2148, reward total was -18.0. running mean: -20.000036833536484, timestamp: 2022-08-19 06:03:13.541514\n",
      "resetting env. episode 2149, reward total was -18.0. running mean: -19.98003646520112, timestamp: 2022-08-19 06:03:16.340548\n",
      "resetting env. episode 2150, reward total was -17.0. running mean: -19.950236100549112, timestamp: 2022-08-19 06:03:20.261592\n",
      "resetting env. episode 2151, reward total was -19.0. running mean: -19.94073373954362, timestamp: 2022-08-19 06:03:22.982629\n",
      "resetting env. episode 2152, reward total was -21.0. running mean: -19.951326402148187, timestamp: 2022-08-19 06:03:25.700656\n",
      "resetting env. episode 2153, reward total was -20.0. running mean: -19.951813138126703, timestamp: 2022-08-19 06:03:28.095684\n",
      "resetting env. episode 2154, reward total was -21.0. running mean: -19.962295006745435, timestamp: 2022-08-19 06:03:30.824717\n",
      "resetting env. episode 2155, reward total was -20.0. running mean: -19.96267205667798, timestamp: 2022-08-19 06:03:33.757754\n",
      "resetting env. episode 2156, reward total was -20.0. running mean: -19.9630453361112, timestamp: 2022-08-19 06:03:36.778786\n",
      "resetting env. episode 2157, reward total was -20.0. running mean: -19.963414882750087, timestamp: 2022-08-19 06:03:39.535819\n",
      "resetting env. episode 2158, reward total was -21.0. running mean: -19.973780733922588, timestamp: 2022-08-19 06:03:42.087847\n",
      "resetting env. episode 2159, reward total was -21.0. running mean: -19.984042926583363, timestamp: 2022-08-19 06:03:44.307875\n",
      "resetting env. episode 2160, reward total was -18.0. running mean: -19.96420249731753, timestamp: 2022-08-19 06:03:47.901916\n",
      "resetting env. episode 2161, reward total was -20.0. running mean: -19.964560472344353, timestamp: 2022-08-19 06:03:50.564951\n",
      "resetting env. episode 2162, reward total was -20.0. running mean: -19.96491486762091, timestamp: 2022-08-19 06:03:53.802985\n",
      "resetting env. episode 2163, reward total was -21.0. running mean: -19.9752657189447, timestamp: 2022-08-19 06:03:56.765022\n",
      "resetting env. episode 2164, reward total was -20.0. running mean: -19.975513061755255, timestamp: 2022-08-19 06:04:00.146059\n",
      "resetting env. episode 2165, reward total was -21.0. running mean: -19.9857579311377, timestamp: 2022-08-19 06:04:03.153099\n",
      "resetting env. episode 2166, reward total was -21.0. running mean: -19.995900351826325, timestamp: 2022-08-19 06:04:06.116134\n",
      "resetting env. episode 2167, reward total was -20.0. running mean: -19.99594134830806, timestamp: 2022-08-19 06:04:08.867161\n",
      "resetting env. episode 2168, reward total was -21.0. running mean: -20.00598193482498, timestamp: 2022-08-19 06:04:11.349191\n",
      "resetting env. episode 2169, reward total was -20.0. running mean: -20.00592211547673, timestamp: 2022-08-19 06:04:14.084223\n",
      "resetting env. episode 2170, reward total was -20.0. running mean: -20.00586289432196, timestamp: 2022-08-19 06:04:17.000257\n",
      "resetting env. episode 2171, reward total was -19.0. running mean: -19.99580426537874, timestamp: 2022-08-19 06:04:19.973295\n",
      "resetting env. episode 2172, reward total was -20.0. running mean: -19.995846222724953, timestamp: 2022-08-19 06:04:22.857324\n",
      "resetting env. episode 2173, reward total was -18.0. running mean: -19.975887760497702, timestamp: 2022-08-19 06:04:26.082363\n",
      "resetting env. episode 2174, reward total was -21.0. running mean: -19.986128882892725, timestamp: 2022-08-19 06:04:29.027397\n",
      "resetting env. episode 2175, reward total was -21.0. running mean: -19.9962675940638, timestamp: 2022-08-19 06:04:31.472427\n",
      "resetting env. episode 2176, reward total was -21.0. running mean: -20.00630491812316, timestamp: 2022-08-19 06:04:34.013455\n",
      "resetting env. episode 2177, reward total was -20.0. running mean: -20.006241868941927, timestamp: 2022-08-19 06:04:37.559497\n",
      "resetting env. episode 2178, reward total was -21.0. running mean: -20.01617945025251, timestamp: 2022-08-19 06:04:40.490532\n",
      "resetting env. episode 2179, reward total was -21.0. running mean: -20.026017655749985, timestamp: 2022-08-19 06:04:43.017560\n",
      "resetting env. episode 2180, reward total was -16.0. running mean: -19.985757479192486, timestamp: 2022-08-19 06:04:47.124612\n",
      "resetting env. episode 2181, reward total was -21.0. running mean: -19.995899904400563, timestamp: 2022-08-19 06:04:50.189649\n",
      "resetting env. episode 2182, reward total was -21.0. running mean: -20.005940905356557, timestamp: 2022-08-19 06:04:53.538684\n",
      "resetting env. episode 2183, reward total was -18.0. running mean: -19.98588149630299, timestamp: 2022-08-19 06:04:57.022724\n",
      "resetting env. episode 2184, reward total was -20.0. running mean: -19.98602268133996, timestamp: 2022-08-19 06:04:59.984763\n",
      "resetting env. episode 2185, reward total was -21.0. running mean: -19.996162454526562, timestamp: 2022-08-19 06:05:03.239800\n",
      "resetting env. episode 2186, reward total was -20.0. running mean: -19.996200829981294, timestamp: 2022-08-19 06:05:06.064829\n",
      "resetting env. episode 2187, reward total was -20.0. running mean: -19.99623882168148, timestamp: 2022-08-19 06:05:08.957863\n",
      "resetting env. episode 2188, reward total was -19.0. running mean: -19.986276433464667, timestamp: 2022-08-19 06:05:11.666894\n",
      "resetting env. episode 2189, reward total was -20.0. running mean: -19.98641366913002, timestamp: 2022-08-19 06:05:14.594927\n",
      "resetting env. episode 2190, reward total was -21.0. running mean: -19.99654953243872, timestamp: 2022-08-19 06:05:17.026958\n",
      "resetting env. episode 2191, reward total was -19.0. running mean: -19.986584037114334, timestamp: 2022-08-19 06:05:19.951992\n",
      "resetting env. episode 2192, reward total was -21.0. running mean: -19.996718196743192, timestamp: 2022-08-19 06:05:22.259020\n",
      "resetting env. episode 2193, reward total was -17.0. running mean: -19.966751014775763, timestamp: 2022-08-19 06:05:26.533067\n",
      "resetting env. episode 2194, reward total was -18.0. running mean: -19.947083504628004, timestamp: 2022-08-19 06:05:29.513102\n",
      "resetting env. episode 2195, reward total was -19.0. running mean: -19.937612669581725, timestamp: 2022-08-19 06:05:32.802139\n",
      "resetting env. episode 2196, reward total was -20.0. running mean: -19.938236542885907, timestamp: 2022-08-19 06:05:36.876190\n",
      "resetting env. episode 2197, reward total was -21.0. running mean: -19.948854177457047, timestamp: 2022-08-19 06:05:40.043228\n",
      "resetting env. episode 2198, reward total was -19.0. running mean: -19.939365635682478, timestamp: 2022-08-19 06:05:43.325262\n",
      "resetting env. episode 2199, reward total was -19.0. running mean: -19.929971979325654, timestamp: 2022-08-19 06:05:46.337297\n",
      "resetting env. episode 2200, reward total was -20.0. running mean: -19.930672259532397, timestamp: 2022-08-19 06:05:49.457334\n",
      "resetting env. episode 2201, reward total was -20.0. running mean: -19.931365536937072, timestamp: 2022-08-19 06:05:52.169362\n",
      "resetting env. episode 2202, reward total was -21.0. running mean: -19.942051881567703, timestamp: 2022-08-19 06:05:55.324400\n",
      "resetting env. episode 2203, reward total was -21.0. running mean: -19.952631362752026, timestamp: 2022-08-19 06:05:57.620430\n",
      "resetting env. episode 2204, reward total was -19.0. running mean: -19.943105049124508, timestamp: 2022-08-19 06:05:59.965457\n",
      "resetting env. episode 2205, reward total was -18.0. running mean: -19.923673998633262, timestamp: 2022-08-19 06:06:03.736500\n",
      "resetting env. episode 2206, reward total was -20.0. running mean: -19.92443725864693, timestamp: 2022-08-19 06:06:06.763531\n",
      "resetting env. episode 2207, reward total was -21.0. running mean: -19.93519288606046, timestamp: 2022-08-19 06:06:09.313564\n",
      "resetting env. episode 2208, reward total was -21.0. running mean: -19.945840957199856, timestamp: 2022-08-19 06:06:12.138592\n",
      "resetting env. episode 2209, reward total was -20.0. running mean: -19.946382547627856, timestamp: 2022-08-19 06:06:15.137627\n",
      "resetting env. episode 2210, reward total was -21.0. running mean: -19.956918722151578, timestamp: 2022-08-19 06:06:17.541654\n",
      "resetting env. episode 2211, reward total was -20.0. running mean: -19.95734953493006, timestamp: 2022-08-19 06:06:20.585690\n",
      "resetting env. episode 2212, reward total was -19.0. running mean: -19.94777603958076, timestamp: 2022-08-19 06:06:25.612747\n",
      "resetting env. episode 2213, reward total was -20.0. running mean: -19.94829827918495, timestamp: 2022-08-19 06:06:28.627785\n",
      "resetting env. episode 2214, reward total was -21.0. running mean: -19.9588152963931, timestamp: 2022-08-19 06:06:30.678806\n",
      "resetting env. episode 2215, reward total was -21.0. running mean: -19.969227143429173, timestamp: 2022-08-19 06:06:33.454839\n",
      "resetting env. episode 2216, reward total was -18.0. running mean: -19.94953487199488, timestamp: 2022-08-19 06:06:36.584876\n",
      "resetting env. episode 2217, reward total was -20.0. running mean: -19.95003952327493, timestamp: 2022-08-19 06:06:38.783899\n",
      "resetting env. episode 2218, reward total was -20.0. running mean: -19.95053912804218, timestamp: 2022-08-19 06:06:41.853936\n",
      "resetting env. episode 2219, reward total was -19.0. running mean: -19.94103373676176, timestamp: 2022-08-19 06:06:44.688969\n",
      "resetting env. episode 2220, reward total was -20.0. running mean: -19.941623399394143, timestamp: 2022-08-19 06:06:47.512998\n",
      "resetting env. episode 2221, reward total was -19.0. running mean: -19.932207165400204, timestamp: 2022-08-19 06:06:50.739039\n",
      "resetting env. episode 2222, reward total was -21.0. running mean: -19.942885093746202, timestamp: 2022-08-19 06:06:52.919065\n",
      "resetting env. episode 2223, reward total was -20.0. running mean: -19.94345624280874, timestamp: 2022-08-19 06:06:55.018088\n",
      "resetting env. episode 2224, reward total was -20.0. running mean: -19.94402168038065, timestamp: 2022-08-19 06:06:57.675116\n",
      "resetting env. episode 2225, reward total was -21.0. running mean: -19.954581463576844, timestamp: 2022-08-19 06:07:00.652980\n",
      "resetting env. episode 2226, reward total was -21.0. running mean: -19.965035648941075, timestamp: 2022-08-19 06:07:03.760013\n",
      "resetting env. episode 2227, reward total was -19.0. running mean: -19.955385292451666, timestamp: 2022-08-19 06:07:07.466057\n",
      "resetting env. episode 2228, reward total was -21.0. running mean: -19.96583143952715, timestamp: 2022-08-19 06:07:09.804088\n",
      "resetting env. episode 2229, reward total was -16.0. running mean: -19.92617312513188, timestamp: 2022-08-19 06:07:13.657127\n",
      "resetting env. episode 2230, reward total was -20.0. running mean: -19.92691139388056, timestamp: 2022-08-19 06:07:16.231157\n",
      "resetting env. episode 2231, reward total was -20.0. running mean: -19.927642279941754, timestamp: 2022-08-19 06:07:18.581182\n",
      "resetting env. episode 2232, reward total was -20.0. running mean: -19.928365857142335, timestamp: 2022-08-19 06:07:21.153215\n",
      "resetting env. episode 2233, reward total was -17.0. running mean: -19.899082198570913, timestamp: 2022-08-19 06:07:24.589251\n",
      "resetting env. episode 2234, reward total was -19.0. running mean: -19.890091376585204, timestamp: 2022-08-19 06:07:27.885288\n",
      "resetting env. episode 2235, reward total was -20.0. running mean: -19.891190462819353, timestamp: 2022-08-19 06:07:30.887324\n",
      "resetting env. episode 2236, reward total was -21.0. running mean: -19.90227855819116, timestamp: 2022-08-19 06:07:34.409362\n",
      "resetting env. episode 2237, reward total was -19.0. running mean: -19.89325577260925, timestamp: 2022-08-19 06:07:37.315395\n",
      "resetting env. episode 2238, reward total was -19.0. running mean: -19.88432321488316, timestamp: 2022-08-19 06:07:40.194426\n",
      "resetting env. episode 2239, reward total was -20.0. running mean: -19.885479982734328, timestamp: 2022-08-19 06:07:43.225460\n",
      "resetting env. episode 2240, reward total was -21.0. running mean: -19.896625182906984, timestamp: 2022-08-19 06:07:46.423496\n",
      "resetting env. episode 2241, reward total was -21.0. running mean: -19.907658931077915, timestamp: 2022-08-19 06:07:48.987526\n",
      "resetting env. episode 2242, reward total was -20.0. running mean: -19.908582341767136, timestamp: 2022-08-19 06:07:52.154561\n",
      "resetting env. episode 2243, reward total was -20.0. running mean: -19.909496518349464, timestamp: 2022-08-19 06:07:54.720594\n",
      "resetting env. episode 2244, reward total was -20.0. running mean: -19.91040155316597, timestamp: 2022-08-19 06:07:57.106620\n",
      "resetting env. episode 2245, reward total was -19.0. running mean: -19.90129753763431, timestamp: 2022-08-19 06:08:00.644660\n",
      "resetting env. episode 2246, reward total was -20.0. running mean: -19.902284562257964, timestamp: 2022-08-19 06:08:03.597365\n",
      "resetting env. episode 2247, reward total was -20.0. running mean: -19.903261716635384, timestamp: 2022-08-19 06:08:06.152391\n",
      "resetting env. episode 2248, reward total was -20.0. running mean: -19.90422909946903, timestamp: 2022-08-19 06:08:08.430417\n",
      "resetting env. episode 2249, reward total was -21.0. running mean: -19.915186808474342, timestamp: 2022-08-19 06:08:10.700447\n",
      "resetting env. episode 2250, reward total was -21.0. running mean: -19.9260349403896, timestamp: 2022-08-19 06:08:13.744480\n",
      "resetting env. episode 2251, reward total was -19.0. running mean: -19.916774590985703, timestamp: 2022-08-19 06:08:16.755515\n",
      "resetting env. episode 2252, reward total was -15.0. running mean: -19.867606845075844, timestamp: 2022-08-19 06:08:20.409553\n",
      "resetting env. episode 2253, reward total was -17.0. running mean: -19.838930776625087, timestamp: 2022-08-19 06:08:24.430599\n",
      "resetting env. episode 2254, reward total was -18.0. running mean: -19.820541468858835, timestamp: 2022-08-19 06:08:27.433632\n",
      "resetting env. episode 2255, reward total was -21.0. running mean: -19.83233605417025, timestamp: 2022-08-19 06:08:29.924664\n",
      "resetting env. episode 2256, reward total was -20.0. running mean: -19.834012693628544, timestamp: 2022-08-19 06:08:33.017696\n",
      "resetting env. episode 2257, reward total was -21.0. running mean: -19.845672566692258, timestamp: 2022-08-19 06:08:35.828730\n",
      "resetting env. episode 2258, reward total was -19.0. running mean: -19.837215841025337, timestamp: 2022-08-19 06:08:38.711760\n",
      "resetting env. episode 2259, reward total was -20.0. running mean: -19.83884368261508, timestamp: 2022-08-19 06:08:41.560792\n",
      "resetting env. episode 2260, reward total was -20.0. running mean: -19.84045524578893, timestamp: 2022-08-19 06:08:45.028830\n",
      "resetting env. episode 2261, reward total was -19.0. running mean: -19.83205069333104, timestamp: 2022-08-19 06:08:48.320868\n",
      "resetting env. episode 2262, reward total was -20.0. running mean: -19.83373018639773, timestamp: 2022-08-19 06:08:50.460894\n",
      "resetting env. episode 2263, reward total was -20.0. running mean: -19.835392884533753, timestamp: 2022-08-19 06:08:53.604931\n",
      "resetting env. episode 2264, reward total was -20.0. running mean: -19.837038955688413, timestamp: 2022-08-19 06:08:56.291961\n",
      "resetting env. episode 2265, reward total was -20.0. running mean: -19.838668566131528, timestamp: 2022-08-19 06:09:00.135004\n",
      "resetting env. episode 2266, reward total was -20.0. running mean: -19.84028188047021, timestamp: 2022-08-19 06:09:02.595030\n",
      "resetting env. episode 2267, reward total was -20.0. running mean: -19.84187906166551, timestamp: 2022-08-19 06:09:05.317059\n",
      "resetting env. episode 2268, reward total was -21.0. running mean: -19.853460271048853, timestamp: 2022-08-19 06:09:07.957088\n",
      "resetting env. episode 2269, reward total was -20.0. running mean: -19.854925668338364, timestamp: 2022-08-19 06:09:10.640122\n",
      "resetting env. episode 2270, reward total was -21.0. running mean: -19.86637641165498, timestamp: 2022-08-19 06:09:13.765154\n",
      "resetting env. episode 2271, reward total was -18.0. running mean: -19.84771264753843, timestamp: 2022-08-19 06:09:17.078193\n",
      "resetting env. episode 2272, reward total was -18.0. running mean: -19.829235521063044, timestamp: 2022-08-19 06:09:21.004234\n",
      "resetting env. episode 2273, reward total was -21.0. running mean: -19.840943165852416, timestamp: 2022-08-19 06:09:23.666268\n",
      "resetting env. episode 2274, reward total was -19.0. running mean: -19.83253373419389, timestamp: 2022-08-19 06:09:26.893303\n",
      "resetting env. episode 2275, reward total was -20.0. running mean: -19.834208396851952, timestamp: 2022-08-19 06:09:29.686332\n",
      "resetting env. episode 2276, reward total was -21.0. running mean: -19.845866312883434, timestamp: 2022-08-19 06:09:32.739369\n",
      "resetting env. episode 2277, reward total was -19.0. running mean: -19.8374076497546, timestamp: 2022-08-19 06:09:35.542396\n",
      "resetting env. episode 2278, reward total was -21.0. running mean: -19.849033573257053, timestamp: 2022-08-19 06:09:37.662420\n",
      "resetting env. episode 2279, reward total was -17.0. running mean: -19.820543237524483, timestamp: 2022-08-19 06:09:40.942462\n",
      "resetting env. episode 2280, reward total was -19.0. running mean: -19.812337805149237, timestamp: 2022-08-19 06:09:44.036492\n",
      "resetting env. episode 2281, reward total was -21.0. running mean: -19.824214427097747, timestamp: 2022-08-19 06:09:46.059515\n",
      "resetting env. episode 2282, reward total was -20.0. running mean: -19.82597228282677, timestamp: 2022-08-19 06:09:49.038552\n",
      "resetting env. episode 2283, reward total was -19.0. running mean: -19.8177125599985, timestamp: 2022-08-19 06:09:52.470589\n",
      "resetting env. episode 2284, reward total was -21.0. running mean: -19.829535434398515, timestamp: 2022-08-19 06:09:55.046622\n",
      "resetting env. episode 2285, reward total was -20.0. running mean: -19.831240080054528, timestamp: 2022-08-19 06:09:58.266653\n",
      "resetting env. episode 2286, reward total was -21.0. running mean: -19.842927679253982, timestamp: 2022-08-19 06:10:01.994699\n",
      "resetting env. episode 2287, reward total was -21.0. running mean: -19.85449840246144, timestamp: 2022-08-19 06:10:04.990735\n",
      "resetting env. episode 2288, reward total was -20.0. running mean: -19.855953418436826, timestamp: 2022-08-19 06:10:08.118769\n",
      "resetting env. episode 2289, reward total was -21.0. running mean: -19.867393884252458, timestamp: 2022-08-19 06:10:10.552797\n",
      "resetting env. episode 2290, reward total was -20.0. running mean: -19.868719945409932, timestamp: 2022-08-19 06:10:13.574828\n",
      "resetting env. episode 2291, reward total was -17.0. running mean: -19.840032745955835, timestamp: 2022-08-19 06:10:17.233873\n",
      "resetting env. episode 2292, reward total was -17.0. running mean: -19.811632418496277, timestamp: 2022-08-19 06:10:20.339911\n",
      "resetting env. episode 2293, reward total was -21.0. running mean: -19.823516094311316, timestamp: 2022-08-19 06:10:23.028938\n",
      "resetting env. episode 2294, reward total was -19.0. running mean: -19.815280933368204, timestamp: 2022-08-19 06:10:26.246977\n",
      "resetting env. episode 2295, reward total was -20.0. running mean: -19.81712812403452, timestamp: 2022-08-19 06:10:29.474012\n",
      "resetting env. episode 2296, reward total was -21.0. running mean: -19.828956842794177, timestamp: 2022-08-19 06:10:32.015040\n",
      "resetting env. episode 2297, reward total was -18.0. running mean: -19.810667274366235, timestamp: 2022-08-19 06:10:34.912077\n",
      "resetting env. episode 2298, reward total was -19.0. running mean: -19.802560601622574, timestamp: 2022-08-19 06:10:38.025115\n",
      "resetting env. episode 2299, reward total was -20.0. running mean: -19.804534995606346, timestamp: 2022-08-19 06:10:40.610140\n",
      "resetting env. episode 2300, reward total was -19.0. running mean: -19.796489645650283, timestamp: 2022-08-19 06:10:43.936179\n",
      "resetting env. episode 2301, reward total was -18.0. running mean: -19.778524749193778, timestamp: 2022-08-19 06:10:47.981225\n",
      "resetting env. episode 2302, reward total was -20.0. running mean: -19.780739501701838, timestamp: 2022-08-19 06:10:50.849262\n",
      "resetting env. episode 2303, reward total was -21.0. running mean: -19.79293210668482, timestamp: 2022-08-19 06:10:53.434291\n",
      "resetting env. episode 2304, reward total was -21.0. running mean: -19.805002785617972, timestamp: 2022-08-19 06:10:56.483656\n",
      "resetting env. episode 2305, reward total was -21.0. running mean: -19.816952757761793, timestamp: 2022-08-19 06:10:59.448692\n",
      "resetting env. episode 2306, reward total was -19.0. running mean: -19.808783230184176, timestamp: 2022-08-19 06:11:01.631714\n",
      "resetting env. episode 2307, reward total was -20.0. running mean: -19.810695397882334, timestamp: 2022-08-19 06:11:04.260745\n",
      "resetting env. episode 2308, reward total was -19.0. running mean: -19.802588443903513, timestamp: 2022-08-19 06:11:07.584785\n",
      "resetting env. episode 2309, reward total was -21.0. running mean: -19.814562559464477, timestamp: 2022-08-19 06:11:11.412830\n",
      "resetting env. episode 2310, reward total was -20.0. running mean: -19.81641693386983, timestamp: 2022-08-19 06:11:15.590877\n",
      "resetting env. episode 2311, reward total was -19.0. running mean: -19.808252764531133, timestamp: 2022-08-19 06:11:18.234910\n",
      "resetting env. episode 2312, reward total was -18.0. running mean: -19.79017023688582, timestamp: 2022-08-19 06:11:21.674950\n",
      "resetting env. episode 2313, reward total was -21.0. running mean: -19.802268534516962, timestamp: 2022-08-19 06:11:24.751985\n",
      "resetting env. episode 2314, reward total was -20.0. running mean: -19.804245849171792, timestamp: 2022-08-19 06:11:27.718022\n",
      "resetting env. episode 2315, reward total was -21.0. running mean: -19.816203390680077, timestamp: 2022-08-19 06:11:31.164065\n",
      "resetting env. episode 2316, reward total was -21.0. running mean: -19.828041356773277, timestamp: 2022-08-19 06:11:33.972099\n",
      "resetting env. episode 2317, reward total was -18.0. running mean: -19.809760943205543, timestamp: 2022-08-19 06:11:36.738130\n",
      "resetting env. episode 2318, reward total was -19.0. running mean: -19.80166333377349, timestamp: 2022-08-19 06:11:39.550161\n",
      "resetting env. episode 2319, reward total was -21.0. running mean: -19.813646700435758, timestamp: 2022-08-19 06:11:42.032190\n",
      "resetting env. episode 2320, reward total was -21.0. running mean: -19.8255102334314, timestamp: 2022-08-19 06:11:45.587347\n",
      "resetting env. episode 2321, reward total was -20.0. running mean: -19.827255131097086, timestamp: 2022-08-19 06:11:48.682388\n",
      "resetting env. episode 2322, reward total was -20.0. running mean: -19.828982579786114, timestamp: 2022-08-19 06:11:51.304417\n",
      "resetting env. episode 2323, reward total was -20.0. running mean: -19.830692753988252, timestamp: 2022-08-19 06:11:53.884450\n",
      "resetting env. episode 2324, reward total was -18.0. running mean: -19.81238582644837, timestamp: 2022-08-19 06:11:57.599491\n",
      "resetting env. episode 2325, reward total was -19.0. running mean: -19.804261968183887, timestamp: 2022-08-19 06:12:00.358525\n",
      "resetting env. episode 2326, reward total was -20.0. running mean: -19.806219348502047, timestamp: 2022-08-19 06:12:03.702568\n",
      "resetting env. episode 2327, reward total was -21.0. running mean: -19.818157155017026, timestamp: 2022-08-19 06:12:06.526604\n",
      "resetting env. episode 2328, reward total was -19.0. running mean: -19.80997558346686, timestamp: 2022-08-19 06:12:10.147647\n",
      "resetting env. episode 2329, reward total was -21.0. running mean: -19.82187582763219, timestamp: 2022-08-19 06:12:13.549683\n",
      "resetting env. episode 2330, reward total was -18.0. running mean: -19.803657069355868, timestamp: 2022-08-19 06:12:17.041791\n",
      "resetting env. episode 2331, reward total was -17.0. running mean: -19.77562049866231, timestamp: 2022-08-19 06:12:20.933834\n",
      "resetting env. episode 2332, reward total was -19.0. running mean: -19.76786429367569, timestamp: 2022-08-19 06:12:23.452866\n",
      "resetting env. episode 2333, reward total was -19.0. running mean: -19.760185650738933, timestamp: 2022-08-19 06:12:27.301913\n",
      "resetting env. episode 2334, reward total was -18.0. running mean: -19.742583794231543, timestamp: 2022-08-19 06:12:30.226949\n",
      "resetting env. episode 2335, reward total was -19.0. running mean: -19.73515795628923, timestamp: 2022-08-19 06:12:33.113988\n",
      "resetting env. episode 2336, reward total was -20.0. running mean: -19.737806376726336, timestamp: 2022-08-19 06:12:36.465023\n",
      "resetting env. episode 2337, reward total was -18.0. running mean: -19.720428312959072, timestamp: 2022-08-19 06:12:39.425057\n",
      "resetting env. episode 2338, reward total was -19.0. running mean: -19.713224029829483, timestamp: 2022-08-19 06:12:42.117091\n",
      "resetting env. episode 2339, reward total was -21.0. running mean: -19.72609178953119, timestamp: 2022-08-19 06:12:44.877123\n",
      "resetting env. episode 2340, reward total was -21.0. running mean: -19.738830871635876, timestamp: 2022-08-19 06:12:47.950160\n",
      "resetting env. episode 2341, reward total was -19.0. running mean: -19.73144256291952, timestamp: 2022-08-19 06:12:50.655283\n",
      "resetting env. episode 2342, reward total was -21.0. running mean: -19.744128137290325, timestamp: 2022-08-19 06:12:53.229314\n",
      "resetting env. episode 2343, reward total was -21.0. running mean: -19.756686855917422, timestamp: 2022-08-19 06:12:55.533345\n",
      "resetting env. episode 2344, reward total was -21.0. running mean: -19.76911998735825, timestamp: 2022-08-19 06:12:58.327377\n",
      "resetting env. episode 2345, reward total was -21.0. running mean: -19.781428787484668, timestamp: 2022-08-19 06:13:01.223414\n",
      "resetting env. episode 2346, reward total was -19.0. running mean: -19.77361449960982, timestamp: 2022-08-19 06:13:04.038448\n",
      "resetting env. episode 2347, reward total was -21.0. running mean: -19.785878354613722, timestamp: 2022-08-19 06:13:06.602481\n",
      "resetting env. episode 2348, reward total was -21.0. running mean: -19.798019571067584, timestamp: 2022-08-19 06:13:08.992509\n",
      "resetting env. episode 2349, reward total was -19.0. running mean: -19.79003937535691, timestamp: 2022-08-19 06:13:12.090542\n",
      "resetting env. episode 2350, reward total was -19.0. running mean: -19.78213898160334, timestamp: 2022-08-19 06:13:14.973577\n",
      "resetting env. episode 2351, reward total was -21.0. running mean: -19.794317591787305, timestamp: 2022-08-19 06:13:17.460608\n",
      "resetting env. episode 2352, reward total was -19.0. running mean: -19.78637441586943, timestamp: 2022-08-19 06:13:20.872651\n",
      "resetting env. episode 2353, reward total was -18.0. running mean: -19.768510671710736, timestamp: 2022-08-19 06:13:24.094687\n",
      "resetting env. episode 2354, reward total was -21.0. running mean: -19.78082556499363, timestamp: 2022-08-19 06:13:26.383715\n",
      "resetting env. episode 2355, reward total was -20.0. running mean: -19.783017309343695, timestamp: 2022-08-19 06:13:29.098749\n",
      "resetting env. episode 2356, reward total was -19.0. running mean: -19.77518713625026, timestamp: 2022-08-19 06:13:31.898782\n",
      "resetting env. episode 2357, reward total was -19.0. running mean: -19.76743526488776, timestamp: 2022-08-19 06:13:34.762821\n",
      "resetting env. episode 2358, reward total was -21.0. running mean: -19.77976091223888, timestamp: 2022-08-19 06:13:37.405853\n",
      "resetting env. episode 2359, reward total was -20.0. running mean: -19.78196330311649, timestamp: 2022-08-19 06:13:40.228885\n",
      "resetting env. episode 2360, reward total was -21.0. running mean: -19.794143670085326, timestamp: 2022-08-19 06:13:43.051918\n",
      "resetting env. episode 2361, reward total was -19.0. running mean: -19.786202233384472, timestamp: 2022-08-19 06:13:46.993967\n",
      "resetting env. episode 2362, reward total was -21.0. running mean: -19.79834021105063, timestamp: 2022-08-19 06:13:49.424996\n",
      "resetting env. episode 2363, reward total was -20.0. running mean: -19.800356808940123, timestamp: 2022-08-19 06:13:52.427035\n",
      "resetting env. episode 2364, reward total was -21.0. running mean: -19.812353240850722, timestamp: 2022-08-19 06:13:55.430070\n",
      "resetting env. episode 2365, reward total was -20.0. running mean: -19.814229708442213, timestamp: 2022-08-19 06:13:58.903115\n",
      "resetting env. episode 2366, reward total was -20.0. running mean: -19.81608741135779, timestamp: 2022-08-19 06:14:02.378155\n",
      "resetting env. episode 2367, reward total was -18.0. running mean: -19.79792653724421, timestamp: 2022-08-19 06:14:05.236189\n",
      "resetting env. episode 2368, reward total was -18.0. running mean: -19.779947271871766, timestamp: 2022-08-19 06:14:08.580231\n",
      "resetting env. episode 2369, reward total was -21.0. running mean: -19.79214779915305, timestamp: 2022-08-19 06:14:11.030260\n",
      "resetting env. episode 2370, reward total was -20.0. running mean: -19.794226321161517, timestamp: 2022-08-19 06:14:13.863294\n",
      "resetting env. episode 2371, reward total was -21.0. running mean: -19.806284057949902, timestamp: 2022-08-19 06:14:16.423328\n",
      "resetting env. episode 2372, reward total was -19.0. running mean: -19.798221217370404, timestamp: 2022-08-19 06:14:19.439901\n",
      "resetting env. episode 2373, reward total was -18.0. running mean: -19.780239005196698, timestamp: 2022-08-19 06:14:22.440045\n",
      "resetting env. episode 2374, reward total was -21.0. running mean: -19.79243661514473, timestamp: 2022-08-19 06:14:25.777085\n",
      "resetting env. episode 2375, reward total was -20.0. running mean: -19.794512248993282, timestamp: 2022-08-19 06:14:27.978117\n",
      "resetting env. episode 2376, reward total was -21.0. running mean: -19.80656712650335, timestamp: 2022-08-19 06:14:30.701148\n",
      "resetting env. episode 2377, reward total was -20.0. running mean: -19.808501455238314, timestamp: 2022-08-19 06:14:34.038189\n",
      "resetting env. episode 2378, reward total was -21.0. running mean: -19.820416440685932, timestamp: 2022-08-19 06:14:36.880220\n",
      "resetting env. episode 2379, reward total was -20.0. running mean: -19.82221227627907, timestamp: 2022-08-19 06:14:39.921261\n",
      "resetting env. episode 2380, reward total was -21.0. running mean: -19.833990153516282, timestamp: 2022-08-19 06:14:42.391291\n",
      "resetting env. episode 2381, reward total was -20.0. running mean: -19.835650251981118, timestamp: 2022-08-19 06:14:45.370326\n",
      "resetting env. episode 2382, reward total was -20.0. running mean: -19.837293749461306, timestamp: 2022-08-19 06:14:48.650365\n",
      "resetting env. episode 2383, reward total was -20.0. running mean: -19.83892081196669, timestamp: 2022-08-19 06:14:51.485399\n",
      "resetting env. episode 2384, reward total was -18.0. running mean: -19.820531603847023, timestamp: 2022-08-19 06:14:55.123447\n",
      "resetting env. episode 2385, reward total was -21.0. running mean: -19.832326287808552, timestamp: 2022-08-19 06:14:57.724479\n",
      "resetting env. episode 2386, reward total was -21.0. running mean: -19.84400302493047, timestamp: 2022-08-19 06:15:00.375508\n",
      "resetting env. episode 2387, reward total was -20.0. running mean: -19.845562994681163, timestamp: 2022-08-19 06:15:03.164546\n",
      "resetting env. episode 2388, reward total was -17.0. running mean: -19.817107364734355, timestamp: 2022-08-19 06:15:06.564584\n",
      "resetting env. episode 2389, reward total was -21.0. running mean: -19.82893629108701, timestamp: 2022-08-19 06:15:10.043630\n",
      "resetting env. episode 2390, reward total was -20.0. running mean: -19.83064692817614, timestamp: 2022-08-19 06:15:12.646661\n",
      "resetting env. episode 2391, reward total was -21.0. running mean: -19.84234045889438, timestamp: 2022-08-19 06:15:14.840686\n",
      "resetting env. episode 2392, reward total was -20.0. running mean: -19.843917054305436, timestamp: 2022-08-19 06:15:18.004728\n",
      "resetting env. episode 2393, reward total was -21.0. running mean: -19.855477883762383, timestamp: 2022-08-19 06:15:20.920760\n",
      "resetting env. episode 2394, reward total was -20.0. running mean: -19.856923104924757, timestamp: 2022-08-19 06:15:23.846798\n",
      "resetting env. episode 2395, reward total was -21.0. running mean: -19.86835387387551, timestamp: 2022-08-19 06:15:27.779847\n",
      "resetting env. episode 2396, reward total was -20.0. running mean: -19.869670335136753, timestamp: 2022-08-19 06:15:30.600882\n",
      "resetting env. episode 2397, reward total was -20.0. running mean: -19.870973631785386, timestamp: 2022-08-19 06:15:33.577920\n",
      "resetting env. episode 2398, reward total was -21.0. running mean: -19.88226389546753, timestamp: 2022-08-19 06:15:35.828945\n",
      "resetting env. episode 2399, reward total was -17.0. running mean: -19.85344125651286, timestamp: 2022-08-19 06:15:39.497992\n",
      "resetting env. episode 2400, reward total was -21.0. running mean: -19.864906843947733, timestamp: 2022-08-19 06:15:41.961021\n",
      "resetting env. episode 2401, reward total was -17.0. running mean: -19.83625777550826, timestamp: 2022-08-19 06:15:45.642065\n",
      "resetting env. episode 2402, reward total was -21.0. running mean: -19.847895197753175, timestamp: 2022-08-19 06:15:48.214100\n",
      "resetting env. episode 2403, reward total was -21.0. running mean: -19.859416245775645, timestamp: 2022-08-19 06:15:52.333148\n",
      "resetting env. episode 2404, reward total was -20.0. running mean: -19.86082208331789, timestamp: 2022-08-19 06:15:55.732188\n",
      "resetting env. episode 2405, reward total was -19.0. running mean: -19.85221386248471, timestamp: 2022-08-19 06:15:59.243233\n",
      "resetting env. episode 2406, reward total was -20.0. running mean: -19.85369172385986, timestamp: 2022-08-19 06:16:02.358271\n",
      "resetting env. episode 2407, reward total was -21.0. running mean: -19.865154806621263, timestamp: 2022-08-19 06:16:05.121306\n",
      "resetting env. episode 2408, reward total was -21.0. running mean: -19.87650325855505, timestamp: 2022-08-19 06:16:07.647340\n",
      "resetting env. episode 2409, reward total was -21.0. running mean: -19.8877382259695, timestamp: 2022-08-19 06:16:10.570374\n",
      "resetting env. episode 2410, reward total was -19.0. running mean: -19.878860843709806, timestamp: 2022-08-19 06:16:13.534408\n",
      "resetting env. episode 2411, reward total was -21.0. running mean: -19.890072235272708, timestamp: 2022-08-19 06:16:16.407443\n",
      "resetting env. episode 2412, reward total was -19.0. running mean: -19.88117151291998, timestamp: 2022-08-19 06:16:19.327480\n",
      "resetting env. episode 2413, reward total was -21.0. running mean: -19.892359797790782, timestamp: 2022-08-19 06:16:21.582510\n",
      "resetting env. episode 2414, reward total was -21.0. running mean: -19.903436199812873, timestamp: 2022-08-19 06:16:24.995547\n",
      "resetting env. episode 2415, reward total was -21.0. running mean: -19.914401837814744, timestamp: 2022-08-19 06:16:27.440579\n",
      "resetting env. episode 2416, reward total was -18.0. running mean: -19.895257819436594, timestamp: 2022-08-19 06:16:31.701631\n",
      "resetting env. episode 2417, reward total was -21.0. running mean: -19.90630524124223, timestamp: 2022-08-19 06:16:34.479665\n",
      "resetting env. episode 2418, reward total was -21.0. running mean: -19.917242188829807, timestamp: 2022-08-19 06:16:36.965698\n",
      "resetting env. episode 2419, reward total was -21.0. running mean: -19.92806976694151, timestamp: 2022-08-19 06:16:39.821730\n",
      "resetting env. episode 2420, reward total was -19.0. running mean: -19.918789069272094, timestamp: 2022-08-19 06:16:43.206774\n",
      "resetting env. episode 2421, reward total was -21.0. running mean: -19.929601178579375, timestamp: 2022-08-19 06:16:46.859821\n",
      "resetting env. episode 2422, reward total was -21.0. running mean: -19.940305166793582, timestamp: 2022-08-19 06:16:50.416862\n",
      "resetting env. episode 2423, reward total was -21.0. running mean: -19.950902115125647, timestamp: 2022-08-19 06:16:53.419899\n",
      "resetting env. episode 2424, reward total was -21.0. running mean: -19.96139309397439, timestamp: 2022-08-19 06:16:56.249935\n",
      "resetting env. episode 2425, reward total was -21.0. running mean: -19.971779163034647, timestamp: 2022-08-19 06:16:58.868965\n",
      "resetting env. episode 2426, reward total was -20.0. running mean: -19.9720613714043, timestamp: 2022-08-19 06:17:01.757999\n",
      "resetting env. episode 2427, reward total was -21.0. running mean: -19.98234075769026, timestamp: 2022-08-19 06:17:04.985044\n",
      "resetting env. episode 2428, reward total was -18.0. running mean: -19.962517350113355, timestamp: 2022-08-19 06:17:08.058076\n",
      "resetting env. episode 2429, reward total was -17.0. running mean: -19.932892176612224, timestamp: 2022-08-19 06:17:11.654121\n",
      "resetting env. episode 2430, reward total was -21.0. running mean: -19.943563254846104, timestamp: 2022-08-19 06:17:14.585158\n",
      "resetting env. episode 2431, reward total was -20.0. running mean: -19.944127622297643, timestamp: 2022-08-19 06:17:17.010185\n",
      "resetting env. episode 2432, reward total was -21.0. running mean: -19.954686346074666, timestamp: 2022-08-19 06:17:20.382511\n",
      "resetting env. episode 2433, reward total was -20.0. running mean: -19.95513948261392, timestamp: 2022-08-19 06:17:23.964551\n",
      "resetting env. episode 2434, reward total was -20.0. running mean: -19.95558808778778, timestamp: 2022-08-19 06:17:26.952591\n",
      "resetting env. episode 2435, reward total was -19.0. running mean: -19.946032206909905, timestamp: 2022-08-19 06:17:30.297629\n",
      "resetting env. episode 2436, reward total was -21.0. running mean: -19.956571884840805, timestamp: 2022-08-19 06:17:33.244665\n",
      "resetting env. episode 2437, reward total was -18.0. running mean: -19.937006165992397, timestamp: 2022-08-19 06:17:36.892713\n",
      "resetting env. episode 2438, reward total was -21.0. running mean: -19.947636104332474, timestamp: 2022-08-19 06:17:39.233742\n",
      "resetting env. episode 2439, reward total was -20.0. running mean: -19.94815974328915, timestamp: 2022-08-19 06:17:41.782768\n",
      "resetting env. episode 2440, reward total was -20.0. running mean: -19.948678145856256, timestamp: 2022-08-19 06:17:44.601804\n",
      "resetting env. episode 2441, reward total was -19.0. running mean: -19.939191364397693, timestamp: 2022-08-19 06:17:47.721841\n",
      "resetting env. episode 2442, reward total was -19.0. running mean: -19.929799450753716, timestamp: 2022-08-19 06:17:50.688881\n",
      "resetting env. episode 2443, reward total was -21.0. running mean: -19.940501456246178, timestamp: 2022-08-19 06:17:53.712915\n",
      "resetting env. episode 2444, reward total was -21.0. running mean: -19.951096441683717, timestamp: 2022-08-19 06:17:57.051955\n",
      "resetting env. episode 2445, reward total was -19.0. running mean: -19.94158547726688, timestamp: 2022-08-19 06:17:59.708987\n",
      "resetting env. episode 2446, reward total was -19.0. running mean: -19.93216962249421, timestamp: 2022-08-19 06:18:03.111028\n",
      "resetting env. episode 2447, reward total was -21.0. running mean: -19.94284792626927, timestamp: 2022-08-19 06:18:05.518059\n",
      "resetting env. episode 2448, reward total was -20.0. running mean: -19.943419447006576, timestamp: 2022-08-19 06:18:08.834102\n",
      "resetting env. episode 2449, reward total was -19.0. running mean: -19.933985252536512, timestamp: 2022-08-19 06:18:11.942136\n",
      "resetting env. episode 2450, reward total was -19.0. running mean: -19.924645400011148, timestamp: 2022-08-19 06:18:15.022176\n",
      "resetting env. episode 2451, reward total was -21.0. running mean: -19.935398946011038, timestamp: 2022-08-19 06:18:18.062218\n",
      "resetting env. episode 2452, reward total was -19.0. running mean: -19.92604495655093, timestamp: 2022-08-19 06:18:20.784247\n",
      "resetting env. episode 2453, reward total was -21.0. running mean: -19.93678450698542, timestamp: 2022-08-19 06:18:23.889287\n",
      "resetting env. episode 2454, reward total was -21.0. running mean: -19.947416661915565, timestamp: 2022-08-19 06:18:26.573316\n",
      "resetting env. episode 2455, reward total was -19.0. running mean: -19.93794249529641, timestamp: 2022-08-19 06:18:29.692355\n",
      "resetting env. episode 2456, reward total was -20.0. running mean: -19.938563070343445, timestamp: 2022-08-19 06:18:33.341401\n",
      "resetting env. episode 2457, reward total was -19.0. running mean: -19.92917743964001, timestamp: 2022-08-19 06:18:36.785444\n",
      "resetting env. episode 2458, reward total was -20.0. running mean: -19.92988566524361, timestamp: 2022-08-19 06:18:39.805477\n",
      "resetting env. episode 2459, reward total was -21.0. running mean: -19.940586808591174, timestamp: 2022-08-19 06:18:42.218509\n",
      "resetting env. episode 2460, reward total was -19.0. running mean: -19.931180940505264, timestamp: 2022-08-19 06:18:45.855552\n",
      "resetting env. episode 2461, reward total was -19.0. running mean: -19.921869131100213, timestamp: 2022-08-19 06:18:48.708584\n",
      "resetting env. episode 2462, reward total was -19.0. running mean: -19.91265043978921, timestamp: 2022-08-19 06:18:52.329629\n",
      "resetting env. episode 2463, reward total was -19.0. running mean: -19.90352393539132, timestamp: 2022-08-19 06:18:55.593670\n",
      "resetting env. episode 2464, reward total was -19.0. running mean: -19.894488696037406, timestamp: 2022-08-19 06:18:58.579705\n",
      "resetting env. episode 2465, reward total was -19.0. running mean: -19.885543809077035, timestamp: 2022-08-19 06:19:01.572741\n",
      "resetting env. episode 2466, reward total was -20.0. running mean: -19.886688370986263, timestamp: 2022-08-19 06:19:05.108786\n",
      "resetting env. episode 2467, reward total was -21.0. running mean: -19.897821487276403, timestamp: 2022-08-19 06:19:07.132808\n",
      "resetting env. episode 2468, reward total was -21.0. running mean: -19.90884327240364, timestamp: 2022-08-19 06:19:10.077095\n",
      "resetting env. episode 2469, reward total was -21.0. running mean: -19.919754839679605, timestamp: 2022-08-19 06:19:12.808129\n",
      "resetting env. episode 2470, reward total was -20.0. running mean: -19.920557291282808, timestamp: 2022-08-19 06:19:15.856164\n",
      "resetting env. episode 2471, reward total was -18.0. running mean: -19.90135171836998, timestamp: 2022-08-19 06:19:18.429197\n",
      "resetting env. episode 2472, reward total was -19.0. running mean: -19.89233820118628, timestamp: 2022-08-19 06:19:22.135243\n",
      "resetting env. episode 2473, reward total was -21.0. running mean: -19.90341481917442, timestamp: 2022-08-19 06:19:25.114279\n",
      "resetting env. episode 2474, reward total was -21.0. running mean: -19.914380670982677, timestamp: 2022-08-19 06:19:27.729310\n",
      "resetting env. episode 2475, reward total was -20.0. running mean: -19.91523686427285, timestamp: 2022-08-19 06:19:31.898364\n",
      "resetting env. episode 2476, reward total was -20.0. running mean: -19.91608449563012, timestamp: 2022-08-19 06:19:34.619394\n",
      "resetting env. episode 2477, reward total was -20.0. running mean: -19.91692365067382, timestamp: 2022-08-19 06:19:38.306437\n",
      "resetting env. episode 2478, reward total was -20.0. running mean: -19.91775441416708, timestamp: 2022-08-19 06:19:40.822473\n",
      "resetting env. episode 2479, reward total was -19.0. running mean: -19.908576870025414, timestamp: 2022-08-19 06:19:44.355512\n",
      "resetting env. episode 2480, reward total was -18.0. running mean: -19.88949110132516, timestamp: 2022-08-19 06:19:47.716554\n",
      "resetting env. episode 2481, reward total was -18.0. running mean: -19.870596190311907, timestamp: 2022-08-19 06:19:50.756589\n",
      "resetting env. episode 2482, reward total was -21.0. running mean: -19.88189022840879, timestamp: 2022-08-19 06:19:53.435623\n",
      "resetting env. episode 2483, reward total was -18.0. running mean: -19.8630713261247, timestamp: 2022-08-19 06:19:56.994668\n",
      "resetting env. episode 2484, reward total was -19.0. running mean: -19.854440612863453, timestamp: 2022-08-19 06:19:59.455698\n",
      "resetting env. episode 2485, reward total was -20.0. running mean: -19.85589620673482, timestamp: 2022-08-19 06:20:01.962724\n",
      "resetting env. episode 2486, reward total was -20.0. running mean: -19.85733724466747, timestamp: 2022-08-19 06:20:05.274769\n",
      "resetting env. episode 2487, reward total was -18.0. running mean: -19.838763872220795, timestamp: 2022-08-19 06:20:08.354803\n",
      "resetting env. episode 2488, reward total was -19.0. running mean: -19.830376233498587, timestamp: 2022-08-19 06:20:11.622843\n",
      "resetting env. episode 2489, reward total was -19.0. running mean: -19.8220724711636, timestamp: 2022-08-19 06:20:15.643892\n",
      "resetting env. episode 2490, reward total was -19.0. running mean: -19.813851746451967, timestamp: 2022-08-19 06:20:19.058931\n",
      "resetting env. episode 2491, reward total was -19.0. running mean: -19.805713228987447, timestamp: 2022-08-19 06:20:22.599977\n",
      "resetting env. episode 2492, reward total was -21.0. running mean: -19.817656096697572, timestamp: 2022-08-19 06:20:25.892015\n",
      "resetting env. episode 2493, reward total was -21.0. running mean: -19.8294795357306, timestamp: 2022-08-19 06:20:28.430045\n",
      "resetting env. episode 2494, reward total was -21.0. running mean: -19.841184740373293, timestamp: 2022-08-19 06:20:31.649087\n",
      "resetting env. episode 2495, reward total was -21.0. running mean: -19.85277289296956, timestamp: 2022-08-19 06:20:34.476118\n",
      "resetting env. episode 2496, reward total was -21.0. running mean: -19.864245164039865, timestamp: 2022-08-19 06:20:37.183149\n",
      "resetting env. episode 2497, reward total was -17.0. running mean: -19.835602712399467, timestamp: 2022-08-19 06:20:40.160184\n",
      "resetting env. episode 2498, reward total was -21.0. running mean: -19.847246685275472, timestamp: 2022-08-19 06:20:42.538214\n",
      "resetting env. episode 2499, reward total was -20.0. running mean: -19.848774218422715, timestamp: 2022-08-19 06:20:45.060249\n",
      "resetting env. episode 2500, reward total was -21.0. running mean: -19.86028647623849, timestamp: 2022-08-19 06:20:48.188281\n",
      "resetting env. episode 2501, reward total was -21.0. running mean: -19.871683611476104, timestamp: 2022-08-19 06:20:50.687311\n",
      "resetting env. episode 2502, reward total was -21.0. running mean: -19.882966775361343, timestamp: 2022-08-19 06:20:53.445346\n",
      "resetting env. episode 2503, reward total was -20.0. running mean: -19.884137107607728, timestamp: 2022-08-19 06:20:56.250378\n",
      "resetting env. episode 2504, reward total was -19.0. running mean: -19.87529573653165, timestamp: 2022-08-19 06:20:59.798423\n",
      "resetting env. episode 2505, reward total was -18.0. running mean: -19.856542779166332, timestamp: 2022-08-19 06:21:02.868461\n",
      "resetting env. episode 2506, reward total was -20.0. running mean: -19.857977351374668, timestamp: 2022-08-19 06:21:06.233501\n",
      "resetting env. episode 2507, reward total was -21.0. running mean: -19.869397577860923, timestamp: 2022-08-19 06:21:08.447526\n",
      "resetting env. episode 2508, reward total was -20.0. running mean: -19.870703602082312, timestamp: 2022-08-19 06:21:11.421280\n",
      "resetting env. episode 2509, reward total was -20.0. running mean: -19.871996566061487, timestamp: 2022-08-19 06:21:14.126313\n",
      "resetting env. episode 2510, reward total was -21.0. running mean: -19.883276600400873, timestamp: 2022-08-19 06:21:17.070344\n",
      "resetting env. episode 2511, reward total was -20.0. running mean: -19.884443834396862, timestamp: 2022-08-19 06:21:20.032384\n",
      "resetting env. episode 2512, reward total was -21.0. running mean: -19.895599396052894, timestamp: 2022-08-19 06:21:22.515410\n",
      "resetting env. episode 2513, reward total was -20.0. running mean: -19.896643402092366, timestamp: 2022-08-19 06:21:25.099440\n",
      "resetting env. episode 2514, reward total was -20.0. running mean: -19.89767696807144, timestamp: 2022-08-19 06:21:27.919474\n",
      "resetting env. episode 2515, reward total was -20.0. running mean: -19.898700198390724, timestamp: 2022-08-19 06:21:31.552518\n",
      "resetting env. episode 2516, reward total was -21.0. running mean: -19.909713196406816, timestamp: 2022-08-19 06:21:34.620557\n",
      "resetting env. episode 2517, reward total was -20.0. running mean: -19.910616064442745, timestamp: 2022-08-19 06:21:36.854580\n",
      "resetting env. episode 2518, reward total was -20.0. running mean: -19.91150990379832, timestamp: 2022-08-19 06:21:39.256608\n",
      "resetting env. episode 2519, reward total was -18.0. running mean: -19.892394804760336, timestamp: 2022-08-19 06:21:42.379648\n",
      "resetting env. episode 2520, reward total was -20.0. running mean: -19.89347085671273, timestamp: 2022-08-19 06:21:45.640684\n",
      "resetting env. episode 2521, reward total was -19.0. running mean: -19.884536148145607, timestamp: 2022-08-19 06:21:48.809726\n",
      "resetting env. episode 2522, reward total was -19.0. running mean: -19.87569078666415, timestamp: 2022-08-19 06:21:51.710756\n",
      "resetting env. episode 2523, reward total was -19.0. running mean: -19.86693387879751, timestamp: 2022-08-19 06:21:54.860797\n",
      "resetting env. episode 2524, reward total was -19.0. running mean: -19.858264540009536, timestamp: 2022-08-19 06:21:58.026835\n",
      "resetting env. episode 2525, reward total was -20.0. running mean: -19.85968189460944, timestamp: 2022-08-19 06:22:01.870880\n",
      "resetting env. episode 2526, reward total was -21.0. running mean: -19.87108507566335, timestamp: 2022-08-19 06:22:04.509909\n",
      "resetting env. episode 2527, reward total was -20.0. running mean: -19.872374224906714, timestamp: 2022-08-19 06:22:07.918952\n",
      "resetting env. episode 2528, reward total was -20.0. running mean: -19.873650482657645, timestamp: 2022-08-19 06:22:11.581995\n",
      "resetting env. episode 2529, reward total was -19.0. running mean: -19.86491397783107, timestamp: 2022-08-19 06:22:14.714032\n",
      "resetting env. episode 2530, reward total was -19.0. running mean: -19.85626483805276, timestamp: 2022-08-19 06:22:17.837065\n",
      "resetting env. episode 2531, reward total was -21.0. running mean: -19.867702189672233, timestamp: 2022-08-19 06:22:20.696101\n",
      "resetting env. episode 2532, reward total was -20.0. running mean: -19.86902516777551, timestamp: 2022-08-19 06:22:23.163128\n",
      "resetting env. episode 2533, reward total was -21.0. running mean: -19.880334916097755, timestamp: 2022-08-19 06:22:25.928166\n",
      "resetting env. episode 2534, reward total was -17.0. running mean: -19.851531566936778, timestamp: 2022-08-19 06:22:28.998201\n",
      "resetting env. episode 2535, reward total was -17.0. running mean: -19.82301625126741, timestamp: 2022-08-19 06:22:32.792246\n",
      "resetting env. episode 2536, reward total was -18.0. running mean: -19.804786088754735, timestamp: 2022-08-19 06:22:35.970283\n",
      "resetting env. episode 2537, reward total was -21.0. running mean: -19.816738227867187, timestamp: 2022-08-19 06:22:38.945314\n",
      "resetting env. episode 2538, reward total was -21.0. running mean: -19.828570845588516, timestamp: 2022-08-19 06:22:41.404344\n",
      "resetting env. episode 2539, reward total was -20.0. running mean: -19.83028513713263, timestamp: 2022-08-19 06:22:44.385379\n",
      "resetting env. episode 2540, reward total was -20.0. running mean: -19.831982285761303, timestamp: 2022-08-19 06:22:46.946410\n",
      "resetting env. episode 2541, reward total was -20.0. running mean: -19.83366246290369, timestamp: 2022-08-19 06:22:50.081446\n",
      "resetting env. episode 2542, reward total was -20.0. running mean: -19.835325838274652, timestamp: 2022-08-19 06:22:52.450475\n",
      "resetting env. episode 2543, reward total was -20.0. running mean: -19.836972579891906, timestamp: 2022-08-19 06:22:55.238506\n",
      "resetting env. episode 2544, reward total was -20.0. running mean: -19.838602854092986, timestamp: 2022-08-19 06:22:58.599547\n",
      "resetting env. episode 2545, reward total was -20.0. running mean: -19.840216825552055, timestamp: 2022-08-19 06:23:02.400595\n",
      "resetting env. episode 2546, reward total was -20.0. running mean: -19.841814657296535, timestamp: 2022-08-19 06:23:07.273652\n",
      "resetting env. episode 2547, reward total was -21.0. running mean: -19.85339651072357, timestamp: 2022-08-19 06:23:10.342212\n",
      "resetting env. episode 2548, reward total was -18.0. running mean: -19.834862545616335, timestamp: 2022-08-19 06:23:13.232247\n",
      "resetting env. episode 2549, reward total was -21.0. running mean: -19.846513920160174, timestamp: 2022-08-19 06:23:16.475286\n",
      "resetting env. episode 2550, reward total was -18.0. running mean: -19.82804878095857, timestamp: 2022-08-19 06:23:19.522279\n",
      "resetting env. episode 2551, reward total was -21.0. running mean: -19.839768293148985, timestamp: 2022-08-19 06:23:22.460313\n",
      "resetting env. episode 2552, reward total was -21.0. running mean: -19.851370610217497, timestamp: 2022-08-19 06:23:25.465348\n",
      "resetting env. episode 2553, reward total was -20.0. running mean: -19.85285690411532, timestamp: 2022-08-19 06:23:28.538385\n",
      "resetting env. episode 2554, reward total was -21.0. running mean: -19.864328335074166, timestamp: 2022-08-19 06:23:31.926426\n",
      "resetting env. episode 2555, reward total was -17.0. running mean: -19.835685051723427, timestamp: 2022-08-19 06:23:35.082462\n",
      "resetting env. episode 2556, reward total was -20.0. running mean: -19.83732820120619, timestamp: 2022-08-19 06:23:38.236501\n",
      "resetting env. episode 2557, reward total was -20.0. running mean: -19.838954919194126, timestamp: 2022-08-19 06:23:41.520540\n",
      "resetting env. episode 2558, reward total was -17.0. running mean: -19.810565370002188, timestamp: 2022-08-19 06:23:45.751713\n",
      "resetting env. episode 2559, reward total was -21.0. running mean: -19.822459716302166, timestamp: 2022-08-19 06:23:48.650747\n",
      "resetting env. episode 2560, reward total was -20.0. running mean: -19.824235119139143, timestamp: 2022-08-19 06:23:51.521784\n",
      "resetting env. episode 2561, reward total was -17.0. running mean: -19.79599276794775, timestamp: 2022-08-19 06:23:54.739822\n",
      "resetting env. episode 2562, reward total was -21.0. running mean: -19.808032840268275, timestamp: 2022-08-19 06:23:57.648852\n",
      "resetting env. episode 2563, reward total was -21.0. running mean: -19.819952511865594, timestamp: 2022-08-19 06:24:01.433900\n",
      "resetting env. episode 2564, reward total was -21.0. running mean: -19.831752986746938, timestamp: 2022-08-19 06:24:04.841941\n",
      "resetting env. episode 2565, reward total was -21.0. running mean: -19.84343545687947, timestamp: 2022-08-19 06:24:08.518981\n",
      "resetting env. episode 2566, reward total was -21.0. running mean: -19.855001102310673, timestamp: 2022-08-19 06:24:10.895008\n",
      "resetting env. episode 2567, reward total was -21.0. running mean: -19.866451091287566, timestamp: 2022-08-19 06:24:13.519039\n",
      "resetting env. episode 2568, reward total was -20.0. running mean: -19.867786580374688, timestamp: 2022-08-19 06:24:16.460074\n",
      "resetting env. episode 2569, reward total was -20.0. running mean: -19.869108714570938, timestamp: 2022-08-19 06:24:19.340108\n",
      "resetting env. episode 2570, reward total was -18.0. running mean: -19.850417627425227, timestamp: 2022-08-19 06:24:22.566147\n",
      "resetting env. episode 2571, reward total was -19.0. running mean: -19.841913451150976, timestamp: 2022-08-19 06:24:25.235178\n",
      "resetting env. episode 2572, reward total was -19.0. running mean: -19.833494316639467, timestamp: 2022-08-19 06:24:28.638215\n",
      "resetting env. episode 2573, reward total was -21.0. running mean: -19.845159373473074, timestamp: 2022-08-19 06:24:31.629252\n",
      "resetting env. episode 2574, reward total was -17.0. running mean: -19.816707779738344, timestamp: 2022-08-19 06:24:35.140293\n",
      "resetting env. episode 2575, reward total was -19.0. running mean: -19.808540701940963, timestamp: 2022-08-19 06:24:38.687335\n",
      "resetting env. episode 2576, reward total was -20.0. running mean: -19.810455294921553, timestamp: 2022-08-19 06:24:41.869373\n",
      "resetting env. episode 2577, reward total was -20.0. running mean: -19.812350741972338, timestamp: 2022-08-19 06:24:44.664402\n",
      "resetting env. episode 2578, reward total was -21.0. running mean: -19.824227234552616, timestamp: 2022-08-19 06:24:47.696443\n",
      "resetting env. episode 2579, reward total was -21.0. running mean: -19.83598496220709, timestamp: 2022-08-19 06:24:50.533469\n",
      "resetting env. episode 2580, reward total was -21.0. running mean: -19.847625112585018, timestamp: 2022-08-19 06:24:52.516491\n",
      "resetting env. episode 2581, reward total was -20.0. running mean: -19.849148861459167, timestamp: 2022-08-19 06:24:55.527526\n",
      "resetting env. episode 2582, reward total was -20.0. running mean: -19.850657372844573, timestamp: 2022-08-19 06:24:57.829555\n",
      "resetting env. episode 2583, reward total was -21.0. running mean: -19.86215079911613, timestamp: 2022-08-19 06:25:01.063591\n",
      "resetting env. episode 2584, reward total was -19.0. running mean: -19.853529291124968, timestamp: 2022-08-19 06:25:04.063626\n",
      "resetting env. episode 2585, reward total was -19.0. running mean: -19.84499399821372, timestamp: 2022-08-19 06:25:06.747657\n",
      "resetting env. episode 2586, reward total was -20.0. running mean: -19.846544058231583, timestamp: 2022-08-19 06:25:09.815692\n",
      "resetting env. episode 2587, reward total was -21.0. running mean: -19.85807861764927, timestamp: 2022-08-19 06:25:12.997728\n",
      "resetting env. episode 2588, reward total was -20.0. running mean: -19.859497831472776, timestamp: 2022-08-19 06:25:15.316756\n",
      "resetting env. episode 2589, reward total was -21.0. running mean: -19.87090285315805, timestamp: 2022-08-19 06:25:18.977798\n",
      "resetting env. episode 2590, reward total was -20.0. running mean: -19.872193824626468, timestamp: 2022-08-19 06:25:22.708839\n",
      "resetting env. episode 2591, reward total was -21.0. running mean: -19.883471886380203, timestamp: 2022-08-19 06:25:25.524873\n",
      "resetting env. episode 2592, reward total was -20.0. running mean: -19.8846371675164, timestamp: 2022-08-19 06:25:28.596907\n",
      "resetting env. episode 2593, reward total was -21.0. running mean: -19.895790795841236, timestamp: 2022-08-19 06:25:32.645956\n",
      "resetting env. episode 2594, reward total was -21.0. running mean: -19.906832887882825, timestamp: 2022-08-19 06:25:36.514002\n",
      "resetting env. episode 2595, reward total was -20.0. running mean: -19.907764559003997, timestamp: 2022-08-19 06:25:39.233031\n",
      "resetting env. episode 2596, reward total was -20.0. running mean: -19.908686913413955, timestamp: 2022-08-19 06:25:41.803065\n",
      "resetting env. episode 2597, reward total was -21.0. running mean: -19.919600044279818, timestamp: 2022-08-19 06:25:44.334091\n",
      "resetting env. episode 2598, reward total was -18.0. running mean: -19.90040404383702, timestamp: 2022-08-19 06:25:47.809129\n",
      "resetting env. episode 2599, reward total was -19.0. running mean: -19.89140000339865, timestamp: 2022-08-19 06:25:51.191173\n",
      "resetting env. episode 2600, reward total was -20.0. running mean: -19.892486003364663, timestamp: 2022-08-19 06:25:54.388206\n",
      "resetting env. episode 2601, reward total was -19.0. running mean: -19.88356114333102, timestamp: 2022-08-19 06:25:57.750247\n",
      "resetting env. episode 2602, reward total was -21.0. running mean: -19.89472553189771, timestamp: 2022-08-19 06:26:00.090269\n",
      "resetting env. episode 2603, reward total was -19.0. running mean: -19.885778276578733, timestamp: 2022-08-19 06:26:03.497310\n",
      "resetting env. episode 2604, reward total was -21.0. running mean: -19.896920493812946, timestamp: 2022-08-19 06:26:05.662771\n",
      "resetting env. episode 2605, reward total was -20.0. running mean: -19.897951288874815, timestamp: 2022-08-19 06:26:08.368799\n",
      "resetting env. episode 2606, reward total was -21.0. running mean: -19.908971775986068, timestamp: 2022-08-19 06:26:11.082833\n",
      "resetting env. episode 2607, reward total was -17.0. running mean: -19.879882058226208, timestamp: 2022-08-19 06:26:14.214864\n",
      "resetting env. episode 2608, reward total was -20.0. running mean: -19.881083237643946, timestamp: 2022-08-19 06:26:17.580903\n",
      "resetting env. episode 2609, reward total was -20.0. running mean: -19.882272405267507, timestamp: 2022-08-19 06:26:21.022943\n",
      "resetting env. episode 2610, reward total was -20.0. running mean: -19.88344968121483, timestamp: 2022-08-19 06:26:23.747972\n",
      "resetting env. episode 2611, reward total was -20.0. running mean: -19.884615184402683, timestamp: 2022-08-19 06:26:27.102016\n",
      "resetting env. episode 2612, reward total was -18.0. running mean: -19.865769032558656, timestamp: 2022-08-19 06:26:30.344048\n",
      "resetting env. episode 2613, reward total was -20.0. running mean: -19.86711134223307, timestamp: 2022-08-19 06:26:33.612087\n",
      "resetting env. episode 2614, reward total was -21.0. running mean: -19.87844022881074, timestamp: 2022-08-19 06:26:35.944115\n",
      "resetting env. episode 2615, reward total was -19.0. running mean: -19.86965582652263, timestamp: 2022-08-19 06:26:39.531155\n",
      "resetting env. episode 2616, reward total was -19.0. running mean: -19.860959268257407, timestamp: 2022-08-19 06:26:42.366187\n",
      "resetting env. episode 2617, reward total was -20.0. running mean: -19.862349675574833, timestamp: 2022-08-19 06:26:46.147233\n",
      "resetting env. episode 2618, reward total was -21.0. running mean: -19.873726178819087, timestamp: 2022-08-19 06:26:49.211267\n",
      "resetting env. episode 2619, reward total was -20.0. running mean: -19.874988917030894, timestamp: 2022-08-19 06:26:52.288303\n",
      "resetting env. episode 2620, reward total was -21.0. running mean: -19.886239027860587, timestamp: 2022-08-19 06:26:55.386338\n",
      "resetting env. episode 2621, reward total was -20.0. running mean: -19.88737663758198, timestamp: 2022-08-19 06:26:58.163368\n",
      "resetting env. episode 2622, reward total was -20.0. running mean: -19.88850287120616, timestamp: 2022-08-19 06:27:01.118402\n",
      "resetting env. episode 2623, reward total was -16.0. running mean: -19.849617842494098, timestamp: 2022-08-19 06:27:05.018453\n",
      "resetting env. episode 2624, reward total was -21.0. running mean: -19.861121664069156, timestamp: 2022-08-19 06:27:07.588478\n",
      "resetting env. episode 2625, reward total was -21.0. running mean: -19.872510447428464, timestamp: 2022-08-19 06:27:11.067521\n",
      "resetting env. episode 2626, reward total was -20.0. running mean: -19.87378534295418, timestamp: 2022-08-19 06:27:14.682564\n",
      "resetting env. episode 2627, reward total was -17.0. running mean: -19.84504748952464, timestamp: 2022-08-19 06:27:17.739601\n",
      "resetting env. episode 2628, reward total was -20.0. running mean: -19.846597014629392, timestamp: 2022-08-19 06:27:20.396629\n",
      "resetting env. episode 2629, reward total was -21.0. running mean: -19.8581310444831, timestamp: 2022-08-19 06:27:23.222665\n",
      "resetting env. episode 2630, reward total was -21.0. running mean: -19.86954973403827, timestamp: 2022-08-19 06:27:26.239697\n",
      "resetting env. episode 2631, reward total was -21.0. running mean: -19.88085423669789, timestamp: 2022-08-19 06:27:28.518727\n",
      "resetting env. episode 2632, reward total was -19.0. running mean: -19.87204569433091, timestamp: 2022-08-19 06:27:31.373759\n",
      "resetting env. episode 2633, reward total was -17.0. running mean: -19.843325237387603, timestamp: 2022-08-19 06:27:35.439806\n",
      "resetting env. episode 2634, reward total was -19.0. running mean: -19.834891985013726, timestamp: 2022-08-19 06:27:38.222843\n",
      "resetting env. episode 2635, reward total was -17.0. running mean: -19.80654306516359, timestamp: 2022-08-19 06:27:41.349882\n",
      "resetting env. episode 2636, reward total was -20.0. running mean: -19.808477634511956, timestamp: 2022-08-19 06:27:44.093917\n",
      "resetting env. episode 2637, reward total was -21.0. running mean: -19.820392858166837, timestamp: 2022-08-19 06:27:46.844942\n",
      "resetting env. episode 2638, reward total was -19.0. running mean: -19.81218892958517, timestamp: 2022-08-19 06:27:49.674976\n",
      "resetting env. episode 2639, reward total was -20.0. running mean: -19.814067040289316, timestamp: 2022-08-19 06:27:53.368021\n",
      "resetting env. episode 2640, reward total was -21.0. running mean: -19.825926369886425, timestamp: 2022-08-19 06:27:55.935050\n",
      "resetting env. episode 2641, reward total was -19.0. running mean: -19.81766710618756, timestamp: 2022-08-19 06:27:58.737085\n",
      "resetting env. episode 2642, reward total was -20.0. running mean: -19.819490435125683, timestamp: 2022-08-19 06:28:01.741119\n",
      "resetting env. episode 2643, reward total was -21.0. running mean: -19.831295530774426, timestamp: 2022-08-19 06:28:04.731226\n",
      "resetting env. episode 2644, reward total was -21.0. running mean: -19.84298257546668, timestamp: 2022-08-19 06:28:07.487225\n",
      "resetting env. episode 2645, reward total was -20.0. running mean: -19.844552749712015, timestamp: 2022-08-19 06:28:10.209256\n",
      "resetting env. episode 2646, reward total was -20.0. running mean: -19.846107222214894, timestamp: 2022-08-19 06:28:13.449296\n",
      "resetting env. episode 2647, reward total was -19.0. running mean: -19.837646149992747, timestamp: 2022-08-19 06:28:17.069342\n",
      "resetting env. episode 2648, reward total was -19.0. running mean: -19.829269688492822, timestamp: 2022-08-19 06:28:21.016390\n",
      "resetting env. episode 2649, reward total was -21.0. running mean: -19.840976991607896, timestamp: 2022-08-19 06:28:24.048424\n",
      "resetting env. episode 2650, reward total was -21.0. running mean: -19.852567221691817, timestamp: 2022-08-19 06:28:26.732459\n",
      "resetting env. episode 2651, reward total was -19.0. running mean: -19.844041549474902, timestamp: 2022-08-19 06:28:29.548493\n",
      "resetting env. episode 2652, reward total was -20.0. running mean: -19.845601133980153, timestamp: 2022-08-19 06:28:32.450531\n",
      "resetting env. episode 2653, reward total was -20.0. running mean: -19.847145122640352, timestamp: 2022-08-19 06:28:35.635570\n",
      "resetting env. episode 2654, reward total was -21.0. running mean: -19.85867367141395, timestamp: 2022-08-19 06:28:38.505604\n",
      "resetting env. episode 2655, reward total was -19.0. running mean: -19.85008693469981, timestamp: 2022-08-19 06:28:41.185638\n",
      "resetting env. episode 2656, reward total was -21.0. running mean: -19.861586065352814, timestamp: 2022-08-19 06:28:44.345675\n",
      "resetting env. episode 2657, reward total was -21.0. running mean: -19.872970204699286, timestamp: 2022-08-19 06:28:46.940708\n",
      "resetting env. episode 2658, reward total was -21.0. running mean: -19.884240502652293, timestamp: 2022-08-19 06:28:50.043747\n",
      "resetting env. episode 2659, reward total was -21.0. running mean: -19.895398097625772, timestamp: 2022-08-19 06:28:53.427784\n",
      "resetting env. episode 2660, reward total was -20.0. running mean: -19.896444116649516, timestamp: 2022-08-19 06:28:57.131832\n",
      "resetting env. episode 2661, reward total was -21.0. running mean: -19.90747967548302, timestamp: 2022-08-19 06:28:59.926864\n",
      "resetting env. episode 2662, reward total was -21.0. running mean: -19.918404878728193, timestamp: 2022-08-19 06:29:03.552909\n",
      "resetting env. episode 2663, reward total was -20.0. running mean: -19.91922082994091, timestamp: 2022-08-19 06:29:07.491959\n",
      "resetting env. episode 2664, reward total was -20.0. running mean: -19.920028621641503, timestamp: 2022-08-19 06:29:10.897002\n",
      "resetting env. episode 2665, reward total was -21.0. running mean: -19.93082833542509, timestamp: 2022-08-19 06:29:13.582033\n",
      "resetting env. episode 2666, reward total was -19.0. running mean: -19.92152005207084, timestamp: 2022-08-19 06:29:16.633071\n",
      "resetting env. episode 2667, reward total was -20.0. running mean: -19.92230485155013, timestamp: 2022-08-19 06:29:19.720108\n",
      "resetting env. episode 2668, reward total was -20.0. running mean: -19.923081803034627, timestamp: 2022-08-19 06:29:22.697146\n",
      "resetting env. episode 2669, reward total was -20.0. running mean: -19.92385098500428, timestamp: 2022-08-19 06:29:25.399176\n",
      "resetting env. episode 2670, reward total was -17.0. running mean: -19.894612475154236, timestamp: 2022-08-19 06:29:29.480224\n",
      "resetting env. episode 2671, reward total was -20.0. running mean: -19.895666350402692, timestamp: 2022-08-19 06:29:32.961272\n",
      "resetting env. episode 2672, reward total was -20.0. running mean: -19.896709686898664, timestamp: 2022-08-19 06:29:35.669301\n",
      "resetting env. episode 2673, reward total was -20.0. running mean: -19.897742590029676, timestamp: 2022-08-19 06:29:38.872343\n",
      "resetting env. episode 2674, reward total was -19.0. running mean: -19.88876516412938, timestamp: 2022-08-19 06:29:41.682376\n",
      "resetting env. episode 2675, reward total was -20.0. running mean: -19.889877512488088, timestamp: 2022-08-19 06:29:44.462410\n",
      "resetting env. episode 2676, reward total was -19.0. running mean: -19.880978737363208, timestamp: 2022-08-19 06:29:47.357445\n",
      "resetting env. episode 2677, reward total was -19.0. running mean: -19.872168949989575, timestamp: 2022-08-19 06:29:50.387483\n",
      "resetting env. episode 2678, reward total was -19.0. running mean: -19.863447260489682, timestamp: 2022-08-19 06:29:53.859530\n",
      "resetting env. episode 2679, reward total was -17.0. running mean: -19.834812787884786, timestamp: 2022-08-19 06:29:56.944567\n",
      "resetting env. episode 2680, reward total was -20.0. running mean: -19.836464660005937, timestamp: 2022-08-19 06:30:00.104602\n",
      "resetting env. episode 2681, reward total was -21.0. running mean: -19.84810001340588, timestamp: 2022-08-19 06:30:02.632640\n",
      "resetting env. episode 2682, reward total was -20.0. running mean: -19.84961901327182, timestamp: 2022-08-19 06:30:05.322668\n",
      "resetting env. episode 2683, reward total was -17.0. running mean: -19.821122823139103, timestamp: 2022-08-19 06:30:09.577721\n",
      "resetting env. episode 2684, reward total was -21.0. running mean: -19.832911594907713, timestamp: 2022-08-19 06:30:12.272754\n",
      "resetting env. episode 2685, reward total was -20.0. running mean: -19.834582478958634, timestamp: 2022-08-19 06:30:14.434782\n",
      "resetting env. episode 2686, reward total was -19.0. running mean: -19.826236654169048, timestamp: 2022-08-19 06:30:17.833566\n",
      "resetting env. episode 2687, reward total was -21.0. running mean: -19.837974287627357, timestamp: 2022-08-19 06:30:21.021608\n",
      "resetting env. episode 2688, reward total was -19.0. running mean: -19.829594544751085, timestamp: 2022-08-19 06:30:24.362646\n",
      "resetting env. episode 2689, reward total was -18.0. running mean: -19.811298599303573, timestamp: 2022-08-19 06:30:28.295695\n",
      "resetting env. episode 2690, reward total was -20.0. running mean: -19.813185613310537, timestamp: 2022-08-19 06:30:30.798726\n",
      "resetting env. episode 2691, reward total was -19.0. running mean: -19.805053757177433, timestamp: 2022-08-19 06:30:34.210771\n",
      "resetting env. episode 2692, reward total was -20.0. running mean: -19.807003219605658, timestamp: 2022-08-19 06:30:36.902804\n",
      "resetting env. episode 2693, reward total was -21.0. running mean: -19.818933187409602, timestamp: 2022-08-19 06:30:39.898838\n",
      "resetting env. episode 2694, reward total was -19.0. running mean: -19.810743855535506, timestamp: 2022-08-19 06:30:44.241892\n",
      "resetting env. episode 2695, reward total was -20.0. running mean: -19.81263641698015, timestamp: 2022-08-19 06:30:47.505935\n",
      "resetting env. episode 2696, reward total was -21.0. running mean: -19.82451005281035, timestamp: 2022-08-19 06:30:51.236985\n",
      "resetting env. episode 2697, reward total was -20.0. running mean: -19.826264952282244, timestamp: 2022-08-19 06:30:54.141017\n",
      "resetting env. episode 2698, reward total was -21.0. running mean: -19.838002302759424, timestamp: 2022-08-19 06:30:56.984056\n",
      "resetting env. episode 2699, reward total was -18.0. running mean: -19.819622279731828, timestamp: 2022-08-19 06:31:00.414097\n",
      "resetting env. episode 2700, reward total was -20.0. running mean: -19.82142605693451, timestamp: 2022-08-19 06:31:03.907140\n",
      "resetting env. episode 2701, reward total was -20.0. running mean: -19.823211796365165, timestamp: 2022-08-19 06:31:07.316182\n",
      "resetting env. episode 2702, reward total was -20.0. running mean: -19.82497967840151, timestamp: 2022-08-19 06:31:10.339221\n",
      "resetting env. episode 2703, reward total was -21.0. running mean: -19.836729881617497, timestamp: 2022-08-19 06:31:13.133257\n",
      "resetting env. episode 2704, reward total was -19.0. running mean: -19.828362582801322, timestamp: 2022-08-19 06:31:15.888288\n",
      "resetting env. episode 2705, reward total was -20.0. running mean: -19.83007895697331, timestamp: 2022-08-19 06:31:18.315322\n",
      "resetting env. episode 2706, reward total was -21.0. running mean: -19.84177816740358, timestamp: 2022-08-19 06:31:21.678368\n",
      "resetting env. episode 2707, reward total was -20.0. running mean: -19.843360385729543, timestamp: 2022-08-19 06:31:24.828400\n",
      "resetting env. episode 2708, reward total was -20.0. running mean: -19.844926781872246, timestamp: 2022-08-19 06:31:27.431433\n",
      "resetting env. episode 2709, reward total was -17.0. running mean: -19.816477514053524, timestamp: 2022-08-19 06:31:31.662486\n",
      "resetting env. episode 2710, reward total was -20.0. running mean: -19.818312738912987, timestamp: 2022-08-19 06:31:35.847538\n",
      "resetting env. episode 2711, reward total was -21.0. running mean: -19.83012961152386, timestamp: 2022-08-19 06:31:38.619573\n",
      "resetting env. episode 2712, reward total was -20.0. running mean: -19.831828315408618, timestamp: 2022-08-19 06:31:41.687614\n",
      "resetting env. episode 2713, reward total was -19.0. running mean: -19.823510032254532, timestamp: 2022-08-19 06:31:44.668650\n",
      "resetting env. episode 2714, reward total was -20.0. running mean: -19.825274931931986, timestamp: 2022-08-19 06:31:47.670687\n",
      "resetting env. episode 2715, reward total was -21.0. running mean: -19.837022182612667, timestamp: 2022-08-19 06:31:50.080722\n",
      "resetting env. episode 2716, reward total was -20.0. running mean: -19.83865196078654, timestamp: 2022-08-19 06:31:52.983754\n",
      "resetting env. episode 2717, reward total was -21.0. running mean: -19.850265441178674, timestamp: 2022-08-19 06:31:56.270799\n",
      "resetting env. episode 2718, reward total was -18.0. running mean: -19.831762786766888, timestamp: 2022-08-19 06:31:59.185832\n",
      "resetting env. episode 2719, reward total was -20.0. running mean: -19.833445158899217, timestamp: 2022-08-19 06:32:01.962867\n",
      "resetting env. episode 2720, reward total was -21.0. running mean: -19.845110707310226, timestamp: 2022-08-19 06:32:04.302896\n",
      "resetting env. episode 2721, reward total was -19.0. running mean: -19.836659600237127, timestamp: 2022-08-19 06:32:07.024931\n",
      "resetting env. episode 2722, reward total was -20.0. running mean: -19.838293004234753, timestamp: 2022-08-19 06:32:09.917967\n",
      "resetting env. episode 2723, reward total was -18.0. running mean: -19.819910074192403, timestamp: 2022-08-19 06:32:12.738003\n",
      "resetting env. episode 2724, reward total was -20.0. running mean: -19.82171097345048, timestamp: 2022-08-19 06:32:15.507037\n",
      "resetting env. episode 2725, reward total was -19.0. running mean: -19.813493863715976, timestamp: 2022-08-19 06:32:18.896084\n",
      "resetting env. episode 2726, reward total was -19.0. running mean: -19.805358925078817, timestamp: 2022-08-19 06:32:21.896118\n",
      "resetting env. episode 2727, reward total was -21.0. running mean: -19.81730533582803, timestamp: 2022-08-19 06:32:24.895156\n",
      "resetting env. episode 2728, reward total was -19.0. running mean: -19.80913228246975, timestamp: 2022-08-19 06:32:27.861196\n",
      "resetting env. episode 2729, reward total was -21.0. running mean: -19.821040959645053, timestamp: 2022-08-19 06:32:30.553228\n",
      "resetting env. episode 2730, reward total was -20.0. running mean: -19.8228305500486, timestamp: 2022-08-19 06:32:33.209262\n",
      "resetting env. episode 2731, reward total was -19.0. running mean: -19.814602244548116, timestamp: 2022-08-19 06:32:36.066297\n",
      "resetting env. episode 2732, reward total was -20.0. running mean: -19.816456222102634, timestamp: 2022-08-19 06:32:38.290324\n",
      "resetting env. episode 2733, reward total was -19.0. running mean: -19.808291659881608, timestamp: 2022-08-19 06:32:42.142374\n",
      "resetting env. episode 2734, reward total was -20.0. running mean: -19.81020874328279, timestamp: 2022-08-19 06:32:45.164414\n",
      "resetting env. episode 2735, reward total was -20.0. running mean: -19.81210665584996, timestamp: 2022-08-19 06:32:48.198450\n",
      "resetting env. episode 2736, reward total was -21.0. running mean: -19.82398558929146, timestamp: 2022-08-19 06:32:51.227488\n",
      "resetting env. episode 2737, reward total was -19.0. running mean: -19.815745733398547, timestamp: 2022-08-19 06:32:54.154529\n",
      "resetting env. episode 2738, reward total was -20.0. running mean: -19.817588276064562, timestamp: 2022-08-19 06:32:57.321566\n",
      "resetting env. episode 2739, reward total was -21.0. running mean: -19.82941239330392, timestamp: 2022-08-19 06:33:00.301603\n",
      "resetting env. episode 2740, reward total was -20.0. running mean: -19.83111826937088, timestamp: 2022-08-19 06:33:03.397639\n",
      "resetting env. episode 2741, reward total was -19.0. running mean: -19.822807086677173, timestamp: 2022-08-19 06:33:06.078674\n",
      "resetting env. episode 2742, reward total was -18.0. running mean: -19.8045790158104, timestamp: 2022-08-19 06:33:09.251717\n",
      "resetting env. episode 2743, reward total was -20.0. running mean: -19.806533225652295, timestamp: 2022-08-19 06:33:12.419753\n",
      "resetting env. episode 2744, reward total was -20.0. running mean: -19.808467893395772, timestamp: 2022-08-19 06:33:15.709795\n",
      "resetting env. episode 2745, reward total was -21.0. running mean: -19.820383214461813, timestamp: 2022-08-19 06:33:18.628830\n",
      "resetting env. episode 2746, reward total was -20.0. running mean: -19.822179382317195, timestamp: 2022-08-19 06:33:21.638868\n",
      "resetting env. episode 2747, reward total was -20.0. running mean: -19.82395758849402, timestamp: 2022-08-19 06:33:25.048910\n",
      "resetting env. episode 2748, reward total was -21.0. running mean: -19.83571801260908, timestamp: 2022-08-19 06:33:28.482955\n",
      "resetting env. episode 2749, reward total was -19.0. running mean: -19.82736083248299, timestamp: 2022-08-19 06:33:31.089987\n",
      "resetting env. episode 2750, reward total was -21.0. running mean: -19.839087224158163, timestamp: 2022-08-19 06:33:34.039023\n",
      "resetting env. episode 2751, reward total was -19.0. running mean: -19.830696351916583, timestamp: 2022-08-19 06:33:37.356282\n",
      "resetting env. episode 2752, reward total was -21.0. running mean: -19.842389388397418, timestamp: 2022-08-19 06:33:39.943316\n",
      "resetting env. episode 2753, reward total was -17.0. running mean: -19.813965494513447, timestamp: 2022-08-19 06:33:43.762363\n",
      "resetting env. episode 2754, reward total was -21.0. running mean: -19.825825839568314, timestamp: 2022-08-19 06:33:46.527394\n",
      "resetting env. episode 2755, reward total was -19.0. running mean: -19.817567581172632, timestamp: 2022-08-19 06:33:49.453432\n",
      "resetting env. episode 2756, reward total was -18.0. running mean: -19.799391905360906, timestamp: 2022-08-19 06:33:52.760476\n",
      "resetting env. episode 2757, reward total was -21.0. running mean: -19.8113979863073, timestamp: 2022-08-19 06:33:55.566509\n",
      "resetting env. episode 2758, reward total was -19.0. running mean: -19.803284006444226, timestamp: 2022-08-19 06:33:59.697561\n",
      "resetting env. episode 2759, reward total was -20.0. running mean: -19.805251166379783, timestamp: 2022-08-19 06:34:03.042603\n",
      "resetting env. episode 2760, reward total was -21.0. running mean: -19.817198654715988, timestamp: 2022-08-19 06:34:06.106641\n",
      "resetting env. episode 2761, reward total was -20.0. running mean: -19.819026668168828, timestamp: 2022-08-19 06:34:09.223680\n",
      "resetting env. episode 2762, reward total was -21.0. running mean: -19.83083640148714, timestamp: 2022-08-19 06:34:12.929728\n",
      "resetting env. episode 2763, reward total was -20.0. running mean: -19.83252803747227, timestamp: 2022-08-19 06:34:16.377771\n",
      "resetting env. episode 2764, reward total was -21.0. running mean: -19.84420275709755, timestamp: 2022-08-19 06:34:19.945818\n",
      "resetting env. episode 2765, reward total was -20.0. running mean: -19.84576072952657, timestamp: 2022-08-19 06:34:22.565848\n",
      "resetting env. episode 2766, reward total was -19.0. running mean: -19.837303122231308, timestamp: 2022-08-19 06:34:25.713899\n",
      "resetting env. episode 2767, reward total was -20.0. running mean: -19.838930091008994, timestamp: 2022-08-19 06:34:27.957916\n",
      "resetting env. episode 2768, reward total was -19.0. running mean: -19.830540790098905, timestamp: 2022-08-19 06:34:31.072955\n",
      "resetting env. episode 2769, reward total was -19.0. running mean: -19.822235382197917, timestamp: 2022-08-19 06:34:34.851006\n",
      "resetting env. episode 2770, reward total was -21.0. running mean: -19.83401302837594, timestamp: 2022-08-19 06:34:37.696038\n",
      "resetting env. episode 2771, reward total was -21.0. running mean: -19.84567289809218, timestamp: 2022-08-19 06:34:40.430074\n",
      "resetting env. episode 2772, reward total was -19.0. running mean: -19.837216169111258, timestamp: 2022-08-19 06:34:43.802115\n",
      "resetting env. episode 2773, reward total was -13.0. running mean: -19.768844007420146, timestamp: 2022-08-19 06:34:47.872169\n",
      "resetting env. episode 2774, reward total was -21.0. running mean: -19.781155567345944, timestamp: 2022-08-19 06:34:51.033209\n",
      "resetting env. episode 2775, reward total was -21.0. running mean: -19.793344011672485, timestamp: 2022-08-19 06:34:53.913243\n",
      "resetting env. episode 2776, reward total was -21.0. running mean: -19.80541057155576, timestamp: 2022-08-19 06:34:56.798280\n",
      "resetting env. episode 2777, reward total was -17.0. running mean: -19.777356465840207, timestamp: 2022-08-19 06:35:01.475338\n",
      "resetting env. episode 2778, reward total was -21.0. running mean: -19.789582901181806, timestamp: 2022-08-19 06:35:03.962368\n",
      "resetting env. episode 2779, reward total was -20.0. running mean: -19.79168707216999, timestamp: 2022-08-19 06:35:06.233396\n",
      "resetting env. episode 2780, reward total was -21.0. running mean: -19.80377020144829, timestamp: 2022-08-19 06:35:08.756431\n",
      "resetting env. episode 2781, reward total was -20.0. running mean: -19.80573249943381, timestamp: 2022-08-19 06:35:11.971468\n",
      "resetting env. episode 2782, reward total was -19.0. running mean: -19.797675174439473, timestamp: 2022-08-19 06:35:15.370511\n",
      "resetting env. episode 2783, reward total was -17.0. running mean: -19.76969842269508, timestamp: 2022-08-19 06:35:18.257547\n",
      "resetting env. episode 2784, reward total was -19.0. running mean: -19.76200143846813, timestamp: 2022-08-19 06:35:21.570591\n",
      "resetting env. episode 2785, reward total was -20.0. running mean: -19.764381424083446, timestamp: 2022-08-19 06:35:24.224624\n",
      "resetting env. episode 2786, reward total was -20.0. running mean: -19.76673760984261, timestamp: 2022-08-19 06:35:26.575654\n",
      "resetting env. episode 2787, reward total was -19.0. running mean: -19.759070233744186, timestamp: 2022-08-19 06:35:29.356687\n",
      "resetting env. episode 2788, reward total was -21.0. running mean: -19.771479531406744, timestamp: 2022-08-19 06:35:32.343724\n",
      "resetting env. episode 2789, reward total was -20.0. running mean: -19.773764736092676, timestamp: 2022-08-19 06:35:35.052756\n",
      "resetting env. episode 2790, reward total was -19.0. running mean: -19.76602708873175, timestamp: 2022-08-19 06:35:38.375920\n",
      "resetting env. episode 2791, reward total was -20.0. running mean: -19.76836681784443, timestamp: 2022-08-19 06:35:41.434963\n",
      "resetting env. episode 2792, reward total was -20.0. running mean: -19.770683149665985, timestamp: 2022-08-19 06:35:44.607002\n",
      "resetting env. episode 2793, reward total was -20.0. running mean: -19.772976318169324, timestamp: 2022-08-19 06:35:48.186049\n",
      "resetting env. episode 2794, reward total was -20.0. running mean: -19.77524655498763, timestamp: 2022-08-19 06:35:50.903082\n",
      "resetting env. episode 2795, reward total was -21.0. running mean: -19.787494089437754, timestamp: 2022-08-19 06:35:54.020118\n",
      "resetting env. episode 2796, reward total was -19.0. running mean: -19.77961914854338, timestamp: 2022-08-19 06:35:57.775166\n",
      "resetting env. episode 2797, reward total was -21.0. running mean: -19.791822957057946, timestamp: 2022-08-19 06:36:00.250193\n",
      "resetting env. episode 2798, reward total was -20.0. running mean: -19.793904727487366, timestamp: 2022-08-19 06:36:03.258231\n",
      "resetting env. episode 2799, reward total was -18.0. running mean: -19.77596568021249, timestamp: 2022-08-19 06:36:06.741274\n",
      "resetting env. episode 2800, reward total was -20.0. running mean: -19.778206023410366, timestamp: 2022-08-19 06:36:10.879328\n",
      "resetting env. episode 2801, reward total was -20.0. running mean: -19.78042396317626, timestamp: 2022-08-19 06:36:14.567373\n",
      "resetting env. episode 2802, reward total was -19.0. running mean: -19.7726197235445, timestamp: 2022-08-19 06:36:17.300406\n",
      "resetting env. episode 2803, reward total was -21.0. running mean: -19.784893526309055, timestamp: 2022-08-19 06:36:21.585457\n",
      "resetting env. episode 2804, reward total was -19.0. running mean: -19.777044591045964, timestamp: 2022-08-19 06:36:25.186505\n",
      "resetting env. episode 2805, reward total was -19.0. running mean: -19.769274145135505, timestamp: 2022-08-19 06:36:28.573548\n",
      "resetting env. episode 2806, reward total was -21.0. running mean: -19.78158140368415, timestamp: 2022-08-19 06:36:31.175577\n",
      "resetting env. episode 2807, reward total was -17.0. running mean: -19.753765589647312, timestamp: 2022-08-19 06:36:35.024625\n",
      "resetting env. episode 2808, reward total was -20.0. running mean: -19.75622793375084, timestamp: 2022-08-19 06:36:37.869660\n",
      "resetting env. episode 2809, reward total was -18.0. running mean: -19.73866565441333, timestamp: 2022-08-19 06:36:41.570707\n",
      "resetting env. episode 2810, reward total was -21.0. running mean: -19.7512789978692, timestamp: 2022-08-19 06:36:44.104737\n",
      "resetting env. episode 2811, reward total was -20.0. running mean: -19.753766207890507, timestamp: 2022-08-19 06:36:46.897776\n",
      "resetting env. episode 2812, reward total was -17.0. running mean: -19.726228545811605, timestamp: 2022-08-19 06:36:50.859824\n",
      "resetting env. episode 2813, reward total was -20.0. running mean: -19.728966260353488, timestamp: 2022-08-19 06:36:53.807861\n",
      "resetting env. episode 2814, reward total was -20.0. running mean: -19.731676597749953, timestamp: 2022-08-19 06:36:56.752895\n",
      "resetting env. episode 2815, reward total was -20.0. running mean: -19.73435983177245, timestamp: 2022-08-19 06:36:59.356930\n",
      "resetting env. episode 2816, reward total was -19.0. running mean: -19.727016233454727, timestamp: 2022-08-19 06:37:02.524966\n",
      "resetting env. episode 2817, reward total was -18.0. running mean: -19.70974607112018, timestamp: 2022-08-19 06:37:05.818006\n",
      "resetting env. episode 2818, reward total was -20.0. running mean: -19.712648610408976, timestamp: 2022-08-19 06:37:08.906048\n",
      "resetting env. episode 2819, reward total was -20.0. running mean: -19.715522124304886, timestamp: 2022-08-19 06:37:12.104083\n",
      "resetting env. episode 2820, reward total was -20.0. running mean: -19.71836690306184, timestamp: 2022-08-19 06:37:14.439111\n",
      "resetting env. episode 2821, reward total was -20.0. running mean: -19.72118323403122, timestamp: 2022-08-19 06:37:17.492150\n",
      "resetting env. episode 2822, reward total was -20.0. running mean: -19.723971401690907, timestamp: 2022-08-19 06:37:20.255186\n",
      "resetting env. episode 2823, reward total was -21.0. running mean: -19.736731687674, timestamp: 2022-08-19 06:37:23.196223\n",
      "resetting env. episode 2824, reward total was -21.0. running mean: -19.74936437079726, timestamp: 2022-08-19 06:37:26.745263\n",
      "resetting env. episode 2825, reward total was -20.0. running mean: -19.751870727089287, timestamp: 2022-08-19 06:37:29.675301\n",
      "resetting env. episode 2826, reward total was -17.0. running mean: -19.724352019818397, timestamp: 2022-08-19 06:37:34.678362\n",
      "resetting env. episode 2827, reward total was -20.0. running mean: -19.72710849962021, timestamp: 2022-08-19 06:37:39.012419\n",
      "resetting env. episode 2828, reward total was -21.0. running mean: -19.73983741462401, timestamp: 2022-08-19 06:37:42.756461\n",
      "resetting env. episode 2829, reward total was -20.0. running mean: -19.74243904047777, timestamp: 2022-08-19 06:37:46.056504\n",
      "resetting env. episode 2830, reward total was -16.0. running mean: -19.705014650072993, timestamp: 2022-08-19 06:37:49.978549\n",
      "resetting env. episode 2831, reward total was -18.0. running mean: -19.687964503572264, timestamp: 2022-08-19 06:37:53.260593\n",
      "resetting env. episode 2832, reward total was -21.0. running mean: -19.701084858536543, timestamp: 2022-08-19 06:37:57.000652\n",
      "resetting env. episode 2833, reward total was -20.0. running mean: -19.704074009951178, timestamp: 2022-08-19 06:37:59.250662\n",
      "resetting env. episode 2834, reward total was -20.0. running mean: -19.707033269851664, timestamp: 2022-08-19 06:38:02.642706\n",
      "resetting env. episode 2835, reward total was -20.0. running mean: -19.709962937153147, timestamp: 2022-08-19 06:38:05.259736\n",
      "resetting env. episode 2836, reward total was -20.0. running mean: -19.712863307781614, timestamp: 2022-08-19 06:38:07.863768\n",
      "resetting env. episode 2837, reward total was -21.0. running mean: -19.725734674703798, timestamp: 2022-08-19 06:38:10.246798\n",
      "resetting env. episode 2838, reward total was -20.0. running mean: -19.72847732795676, timestamp: 2022-08-19 06:38:13.570841\n",
      "resetting env. episode 2839, reward total was -18.0. running mean: -19.711192554677194, timestamp: 2022-08-19 06:38:16.218871\n",
      "resetting env. episode 2840, reward total was -21.0. running mean: -19.724080629130423, timestamp: 2022-08-19 06:38:19.845916\n",
      "resetting env. episode 2841, reward total was -20.0. running mean: -19.726839822839118, timestamp: 2022-08-19 06:38:22.505949\n",
      "resetting env. episode 2842, reward total was -20.0. running mean: -19.729571424610725, timestamp: 2022-08-19 06:38:25.668988\n",
      "resetting env. episode 2843, reward total was -19.0. running mean: -19.72227571036462, timestamp: 2022-08-19 06:38:28.850026\n",
      "resetting env. episode 2844, reward total was -21.0. running mean: -19.735052953260976, timestamp: 2022-08-19 06:38:31.840067\n",
      "resetting env. episode 2845, reward total was -19.0. running mean: -19.727702423728367, timestamp: 2022-08-19 06:38:35.575110\n",
      "resetting env. episode 2846, reward total was -21.0. running mean: -19.740425399491084, timestamp: 2022-08-19 06:38:38.916156\n",
      "resetting env. episode 2847, reward total was -21.0. running mean: -19.753021145496174, timestamp: 2022-08-19 06:38:41.139179\n",
      "resetting env. episode 2848, reward total was -20.0. running mean: -19.755490934041212, timestamp: 2022-08-19 06:38:44.243216\n",
      "resetting env. episode 2849, reward total was -20.0. running mean: -19.7579360247008, timestamp: 2022-08-19 06:38:47.514257\n",
      "resetting env. episode 2850, reward total was -19.0. running mean: -19.750356664453793, timestamp: 2022-08-19 06:38:50.981299\n",
      "resetting env. episode 2851, reward total was -21.0. running mean: -19.762853097809256, timestamp: 2022-08-19 06:38:53.342328\n",
      "resetting env. episode 2852, reward total was -19.0. running mean: -19.755224566831163, timestamp: 2022-08-19 06:38:56.731369\n",
      "resetting env. episode 2853, reward total was -21.0. running mean: -19.767672321162852, timestamp: 2022-08-19 06:39:00.519416\n",
      "resetting env. episode 2854, reward total was -19.0. running mean: -19.759995597951225, timestamp: 2022-08-19 06:39:03.744455\n",
      "resetting env. episode 2855, reward total was -21.0. running mean: -19.772395641971713, timestamp: 2022-08-19 06:39:07.415501\n",
      "resetting env. episode 2856, reward total was -21.0. running mean: -19.784671685551995, timestamp: 2022-08-19 06:39:10.910541\n",
      "resetting env. episode 2857, reward total was -20.0. running mean: -19.786824968696475, timestamp: 2022-08-19 06:39:13.911583\n",
      "resetting env. episode 2858, reward total was -21.0. running mean: -19.79895671900951, timestamp: 2022-08-19 06:39:16.918619\n",
      "resetting env. episode 2859, reward total was -19.0. running mean: -19.790967151819416, timestamp: 2022-08-19 06:39:20.125654\n",
      "resetting env. episode 2860, reward total was -20.0. running mean: -19.793057480301222, timestamp: 2022-08-19 06:39:23.456695\n",
      "resetting env. episode 2861, reward total was -20.0. running mean: -19.795126905498208, timestamp: 2022-08-19 06:39:26.508733\n",
      "resetting env. episode 2862, reward total was -21.0. running mean: -19.807175636443226, timestamp: 2022-08-19 06:39:29.233770\n",
      "resetting env. episode 2863, reward total was -21.0. running mean: -19.819103880078796, timestamp: 2022-08-19 06:39:32.239805\n",
      "resetting env. episode 2864, reward total was -21.0. running mean: -19.830912841278007, timestamp: 2022-08-19 06:39:35.053835\n",
      "resetting env. episode 2865, reward total was -16.0. running mean: -19.792603712865226, timestamp: 2022-08-19 06:39:38.875882\n",
      "resetting env. episode 2866, reward total was -19.0. running mean: -19.784677675736575, timestamp: 2022-08-19 06:39:42.195924\n",
      "resetting env. episode 2867, reward total was -20.0. running mean: -19.786830898979208, timestamp: 2022-08-19 06:39:45.662964\n",
      "resetting env. episode 2868, reward total was -21.0. running mean: -19.798962589989415, timestamp: 2022-08-19 06:39:47.927991\n",
      "resetting env. episode 2869, reward total was -19.0. running mean: -19.790972964089523, timestamp: 2022-08-19 06:39:51.136034\n",
      "resetting env. episode 2870, reward total was -19.0. running mean: -19.78306323444863, timestamp: 2022-08-19 06:39:54.472072\n",
      "resetting env. episode 2871, reward total was -19.0. running mean: -19.775232602104143, timestamp: 2022-08-19 06:39:58.416770\n",
      "resetting env. episode 2872, reward total was -20.0. running mean: -19.7774802760831, timestamp: 2022-08-19 06:40:01.827341\n",
      "resetting env. episode 2873, reward total was -17.0. running mean: -19.74970547332227, timestamp: 2022-08-19 06:40:06.168394\n",
      "resetting env. episode 2874, reward total was -19.0. running mean: -19.742208418589048, timestamp: 2022-08-19 06:40:09.447434\n",
      "resetting env. episode 2875, reward total was -21.0. running mean: -19.754786334403157, timestamp: 2022-08-19 06:40:12.259470\n",
      "resetting env. episode 2876, reward total was -19.0. running mean: -19.747238471059127, timestamp: 2022-08-19 06:40:14.603498\n",
      "resetting env. episode 2877, reward total was -21.0. running mean: -19.759766086348538, timestamp: 2022-08-19 06:40:17.616531\n",
      "resetting env. episode 2878, reward total was -21.0. running mean: -19.772168425485052, timestamp: 2022-08-19 06:40:20.756574\n",
      "resetting env. episode 2879, reward total was -21.0. running mean: -19.7844467412302, timestamp: 2022-08-19 06:40:23.645605\n",
      "resetting env. episode 2880, reward total was -19.0. running mean: -19.7766022738179, timestamp: 2022-08-19 06:40:26.358637\n",
      "resetting env. episode 2881, reward total was -15.0. running mean: -19.72883625107972, timestamp: 2022-08-19 06:40:29.976684\n",
      "resetting env. episode 2882, reward total was -20.0. running mean: -19.731547888568922, timestamp: 2022-08-19 06:40:33.620725\n",
      "resetting env. episode 2883, reward total was -18.0. running mean: -19.714232409683234, timestamp: 2022-08-19 06:40:36.987767\n",
      "resetting env. episode 2884, reward total was -19.0. running mean: -19.7070900855864, timestamp: 2022-08-19 06:40:40.102804\n",
      "resetting env. episode 2885, reward total was -21.0. running mean: -19.72001918473054, timestamp: 2022-08-19 06:40:43.462844\n",
      "resetting env. episode 2886, reward total was -19.0. running mean: -19.712818992883236, timestamp: 2022-08-19 06:40:46.732882\n",
      "resetting env. episode 2887, reward total was -21.0. running mean: -19.725690802954404, timestamp: 2022-08-19 06:40:49.639921\n",
      "resetting env. episode 2888, reward total was -21.0. running mean: -19.73843389492486, timestamp: 2022-08-19 06:40:52.571953\n",
      "resetting env. episode 2889, reward total was -19.0. running mean: -19.731049555975613, timestamp: 2022-08-19 06:40:55.451345\n",
      "resetting env. episode 2890, reward total was -20.0. running mean: -19.733739060415857, timestamp: 2022-08-19 06:40:58.715382\n",
      "resetting env. episode 2891, reward total was -20.0. running mean: -19.7364016698117, timestamp: 2022-08-19 06:41:02.217429\n",
      "resetting env. episode 2892, reward total was -21.0. running mean: -19.749037653113582, timestamp: 2022-08-19 06:41:05.596466\n",
      "resetting env. episode 2893, reward total was -21.0. running mean: -19.761547276582448, timestamp: 2022-08-19 06:41:07.768492\n",
      "resetting env. episode 2894, reward total was -21.0. running mean: -19.773931803816623, timestamp: 2022-08-19 06:41:10.808529\n",
      "resetting env. episode 2895, reward total was -19.0. running mean: -19.766192485778458, timestamp: 2022-08-19 06:41:14.209568\n",
      "resetting env. episode 2896, reward total was -19.0. running mean: -19.758530560920676, timestamp: 2022-08-19 06:41:17.731611\n",
      "resetting env. episode 2897, reward total was -21.0. running mean: -19.77094525531147, timestamp: 2022-08-19 06:41:21.652662\n",
      "resetting env. episode 2898, reward total was -21.0. running mean: -19.783235802758355, timestamp: 2022-08-19 06:41:24.624696\n",
      "resetting env. episode 2899, reward total was -20.0. running mean: -19.785403444730772, timestamp: 2022-08-19 06:41:27.832732\n",
      "resetting env. episode 2900, reward total was -21.0. running mean: -19.797549410283466, timestamp: 2022-08-19 06:41:30.932769\n",
      "resetting env. episode 2901, reward total was -18.0. running mean: -19.77957391618063, timestamp: 2022-08-19 06:41:34.065811\n",
      "resetting env. episode 2902, reward total was -21.0. running mean: -19.791778177018827, timestamp: 2022-08-19 06:41:36.222832\n",
      "resetting env. episode 2903, reward total was -20.0. running mean: -19.79386039524864, timestamp: 2022-08-19 06:41:40.028879\n",
      "resetting env. episode 2904, reward total was -18.0. running mean: -19.775921791296152, timestamp: 2022-08-19 06:41:43.167916\n",
      "resetting env. episode 2905, reward total was -21.0. running mean: -19.788162573383193, timestamp: 2022-08-19 06:41:46.257106\n",
      "resetting env. episode 2906, reward total was -19.0. running mean: -19.780280947649363, timestamp: 2022-08-19 06:41:49.431145\n",
      "resetting env. episode 2907, reward total was -19.0. running mean: -19.772478138172872, timestamp: 2022-08-19 06:41:53.582197\n",
      "resetting env. episode 2908, reward total was -21.0. running mean: -19.784753356791143, timestamp: 2022-08-19 06:41:56.375231\n",
      "resetting env. episode 2909, reward total was -21.0. running mean: -19.79690582322323, timestamp: 2022-08-19 06:41:58.999267\n",
      "resetting env. episode 2910, reward total was -20.0. running mean: -19.798936764990998, timestamp: 2022-08-19 06:42:02.688306\n",
      "resetting env. episode 2911, reward total was -21.0. running mean: -19.81094739734109, timestamp: 2022-08-19 06:42:05.797348\n",
      "resetting env. episode 2912, reward total was -21.0. running mean: -19.82283792336768, timestamp: 2022-08-19 06:42:08.851385\n",
      "resetting env. episode 2913, reward total was -19.0. running mean: -19.814609544134004, timestamp: 2022-08-19 06:42:11.752419\n",
      "resetting env. episode 2914, reward total was -21.0. running mean: -19.826463448692664, timestamp: 2022-08-19 06:42:15.020453\n",
      "resetting env. episode 2915, reward total was -19.0. running mean: -19.81819881420574, timestamp: 2022-08-19 06:42:18.859504\n",
      "resetting env. episode 2916, reward total was -19.0. running mean: -19.810016826063684, timestamp: 2022-08-19 06:42:21.402529\n",
      "resetting env. episode 2917, reward total was -18.0. running mean: -19.791916657803046, timestamp: 2022-08-19 06:42:24.987575\n",
      "resetting env. episode 2918, reward total was -20.0. running mean: -19.793997491225014, timestamp: 2022-08-19 06:42:28.588616\n",
      "resetting env. episode 2919, reward total was -20.0. running mean: -19.796057516312764, timestamp: 2022-08-19 06:42:31.607650\n",
      "resetting env. episode 2920, reward total was -20.0. running mean: -19.798096941149637, timestamp: 2022-08-19 06:42:34.117679\n",
      "resetting env. episode 2921, reward total was -20.0. running mean: -19.80011597173814, timestamp: 2022-08-19 06:42:37.373719\n",
      "resetting env. episode 2922, reward total was -15.0. running mean: -19.752114812020757, timestamp: 2022-08-19 06:42:41.481768\n",
      "resetting env. episode 2923, reward total was -20.0. running mean: -19.754593663900547, timestamp: 2022-08-19 06:42:45.057811\n",
      "resetting env. episode 2924, reward total was -20.0. running mean: -19.75704772726154, timestamp: 2022-08-19 06:42:48.851857\n",
      "resetting env. episode 2925, reward total was -21.0. running mean: -19.769477249988924, timestamp: 2022-08-19 06:42:51.444886\n",
      "resetting env. episode 2926, reward total was -18.0. running mean: -19.751782477489034, timestamp: 2022-08-19 06:42:54.456921\n",
      "resetting env. episode 2927, reward total was -21.0. running mean: -19.764264652714143, timestamp: 2022-08-19 06:42:57.365955\n",
      "resetting env. episode 2928, reward total was -19.0. running mean: -19.756622006187, timestamp: 2022-08-19 06:43:00.490992\n",
      "resetting env. episode 2929, reward total was -20.0. running mean: -19.75905578612513, timestamp: 2022-08-19 06:43:03.088027\n",
      "resetting env. episode 2930, reward total was -18.0. running mean: -19.74146522826388, timestamp: 2022-08-19 06:43:05.990059\n",
      "resetting env. episode 2931, reward total was -15.0. running mean: -19.69405057598124, timestamp: 2022-08-19 06:43:09.734104\n",
      "resetting env. episode 2932, reward total was -21.0. running mean: -19.70711007022143, timestamp: 2022-08-19 06:43:13.622147\n",
      "resetting env. episode 2933, reward total was -21.0. running mean: -19.720038969519216, timestamp: 2022-08-19 06:43:16.028174\n",
      "resetting env. episode 2934, reward total was -21.0. running mean: -19.732838579824023, timestamp: 2022-08-19 06:43:18.602209\n",
      "resetting env. episode 2935, reward total was -19.0. running mean: -19.725510194025784, timestamp: 2022-08-19 06:43:21.874243\n",
      "resetting env. episode 2936, reward total was -19.0. running mean: -19.718255092085528, timestamp: 2022-08-19 06:43:25.292046\n",
      "resetting env. episode 2937, reward total was -19.0. running mean: -19.711072541164672, timestamp: 2022-08-19 06:43:28.406078\n",
      "resetting env. episode 2938, reward total was -20.0. running mean: -19.713961815753024, timestamp: 2022-08-19 06:43:31.529117\n",
      "resetting env. episode 2939, reward total was -18.0. running mean: -19.696822197595495, timestamp: 2022-08-19 06:43:34.446148\n",
      "resetting env. episode 2940, reward total was -21.0. running mean: -19.70985397561954, timestamp: 2022-08-19 06:43:37.696184\n",
      "resetting env. episode 2941, reward total was -18.0. running mean: -19.692755435863347, timestamp: 2022-08-19 06:43:41.890761\n",
      "resetting env. episode 2942, reward total was -19.0. running mean: -19.685827881504714, timestamp: 2022-08-19 06:43:45.383803\n",
      "resetting env. episode 2943, reward total was -16.0. running mean: -19.648969602689668, timestamp: 2022-08-19 06:43:49.654853\n",
      "resetting env. episode 2944, reward total was -20.0. running mean: -19.65247990666277, timestamp: 2022-08-19 06:43:53.758904\n",
      "resetting env. episode 2945, reward total was -21.0. running mean: -19.665955107596144, timestamp: 2022-08-19 06:43:56.530934\n",
      "resetting env. episode 2946, reward total was -21.0. running mean: -19.679295556520184, timestamp: 2022-08-19 06:44:00.246977\n",
      "resetting env. episode 2947, reward total was -21.0. running mean: -19.692502600954985, timestamp: 2022-08-19 06:44:03.713018\n",
      "resetting env. episode 2948, reward total was -19.0. running mean: -19.685577574945437, timestamp: 2022-08-19 06:44:07.075058\n",
      "resetting env. episode 2949, reward total was -20.0. running mean: -19.68872179919598, timestamp: 2022-08-19 06:44:10.549102\n",
      "resetting env. episode 2950, reward total was -21.0. running mean: -19.70183458120402, timestamp: 2022-08-19 06:44:14.001139\n",
      "resetting env. episode 2951, reward total was -21.0. running mean: -19.714816235391982, timestamp: 2022-08-19 06:44:17.165177\n",
      "resetting env. episode 2952, reward total was -21.0. running mean: -19.727668073038064, timestamp: 2022-08-19 06:44:19.454204\n",
      "resetting env. episode 2953, reward total was -20.0. running mean: -19.730391392307684, timestamp: 2022-08-19 06:44:23.003248\n",
      "resetting env. episode 2954, reward total was -16.0. running mean: -19.69308747838461, timestamp: 2022-08-19 06:44:26.460255\n",
      "resetting env. episode 2955, reward total was -21.0. running mean: -19.706156603600764, timestamp: 2022-08-19 06:44:29.489289\n",
      "resetting env. episode 2956, reward total was -21.0. running mean: -19.719095037564756, timestamp: 2022-08-19 06:44:32.498680\n",
      "resetting env. episode 2957, reward total was -21.0. running mean: -19.731904087189108, timestamp: 2022-08-19 06:44:35.392718\n",
      "resetting env. episode 2958, reward total was -18.0. running mean: -19.714585046317215, timestamp: 2022-08-19 06:44:38.272756\n",
      "resetting env. episode 2959, reward total was -21.0. running mean: -19.727439195854043, timestamp: 2022-08-19 06:44:41.693792\n",
      "resetting env. episode 2960, reward total was -20.0. running mean: -19.7301648038955, timestamp: 2022-08-19 06:44:44.777825\n",
      "resetting env. episode 2961, reward total was -20.0. running mean: -19.732863155856545, timestamp: 2022-08-19 06:44:47.774862\n",
      "resetting env. episode 2962, reward total was -19.0. running mean: -19.72553452429798, timestamp: 2022-08-19 06:44:50.737899\n",
      "resetting env. episode 2963, reward total was -17.0. running mean: -19.698279179055003, timestamp: 2022-08-19 06:44:55.094952\n",
      "resetting env. episode 2964, reward total was -21.0. running mean: -19.711296387264454, timestamp: 2022-08-19 06:44:57.992994\n",
      "resetting env. episode 2965, reward total was -20.0. running mean: -19.71418342339181, timestamp: 2022-08-19 06:45:01.724032\n",
      "resetting env. episode 2966, reward total was -21.0. running mean: -19.727041589157892, timestamp: 2022-08-19 06:45:04.464066\n",
      "resetting env. episode 2967, reward total was -17.0. running mean: -19.699771173266313, timestamp: 2022-08-19 06:45:08.191111\n",
      "resetting env. episode 2968, reward total was -21.0. running mean: -19.71277346153365, timestamp: 2022-08-19 06:45:11.165147\n",
      "resetting env. episode 2969, reward total was -20.0. running mean: -19.715645726918314, timestamp: 2022-08-19 06:45:14.257185\n",
      "resetting env. episode 2970, reward total was -21.0. running mean: -19.72848926964913, timestamp: 2022-08-19 06:45:17.969232\n",
      "resetting env. episode 2971, reward total was -18.0. running mean: -19.71120437695264, timestamp: 2022-08-19 06:45:21.775283\n",
      "resetting env. episode 2972, reward total was -21.0. running mean: -19.724092333183115, timestamp: 2022-08-19 06:45:25.328846\n",
      "resetting env. episode 2973, reward total was -18.0. running mean: -19.706851409851282, timestamp: 2022-08-19 06:45:30.004426\n",
      "resetting env. episode 2974, reward total was -19.0. running mean: -19.69978289575277, timestamp: 2022-08-19 06:45:34.640485\n",
      "resetting env. episode 2975, reward total was -18.0. running mean: -19.68278506679524, timestamp: 2022-08-19 06:45:37.546521\n",
      "resetting env. episode 2976, reward total was -18.0. running mean: -19.66595721612729, timestamp: 2022-08-19 06:45:42.044585\n",
      "resetting env. episode 2977, reward total was -21.0. running mean: -19.679297643966017, timestamp: 2022-08-19 06:45:45.424619\n",
      "resetting env. episode 2978, reward total was -20.0. running mean: -19.682504667526356, timestamp: 2022-08-19 06:45:48.289654\n",
      "resetting env. episode 2979, reward total was -18.0. running mean: -19.66567962085109, timestamp: 2022-08-19 06:45:51.718700\n",
      "resetting env. episode 2980, reward total was -20.0. running mean: -19.66902282464258, timestamp: 2022-08-19 06:45:54.909739\n",
      "resetting env. episode 2981, reward total was -20.0. running mean: -19.672332596396153, timestamp: 2022-08-19 06:45:57.985778\n",
      "resetting env. episode 2982, reward total was -19.0. running mean: -19.665609270432192, timestamp: 2022-08-19 06:46:01.447819\n",
      "resetting env. episode 2983, reward total was -19.0. running mean: -19.65895317772787, timestamp: 2022-08-19 06:46:04.622858\n",
      "resetting env. episode 2984, reward total was -21.0. running mean: -19.672363645950593, timestamp: 2022-08-19 06:46:07.334895\n",
      "resetting env. episode 2985, reward total was -21.0. running mean: -19.685640009491088, timestamp: 2022-08-19 06:46:10.532932\n",
      "resetting env. episode 2986, reward total was -21.0. running mean: -19.698783609396177, timestamp: 2022-08-19 06:46:13.547970\n",
      "resetting env. episode 2987, reward total was -19.0. running mean: -19.691795773302218, timestamp: 2022-08-19 06:46:16.201003\n",
      "resetting env. episode 2988, reward total was -20.0. running mean: -19.694877815569196, timestamp: 2022-08-19 06:46:18.883036\n",
      "resetting env. episode 2989, reward total was -21.0. running mean: -19.707929037413503, timestamp: 2022-08-19 06:46:21.444069\n",
      "resetting env. episode 2990, reward total was -21.0. running mean: -19.72084974703937, timestamp: 2022-08-19 06:46:24.413106\n",
      "resetting env. episode 2991, reward total was -18.0. running mean: -19.703641249568975, timestamp: 2022-08-19 06:46:28.253154\n",
      "resetting env. episode 2992, reward total was -19.0. running mean: -19.696604837073284, timestamp: 2022-08-19 06:46:31.654200\n",
      "resetting env. episode 2993, reward total was -20.0. running mean: -19.69963878870255, timestamp: 2022-08-19 06:46:34.784241\n",
      "resetting env. episode 2994, reward total was -21.0. running mean: -19.712642400815525, timestamp: 2022-08-19 06:46:37.750272\n",
      "resetting env. episode 2995, reward total was -19.0. running mean: -19.705515976807373, timestamp: 2022-08-19 06:46:41.208316\n",
      "resetting env. episode 2996, reward total was -20.0. running mean: -19.7084608170393, timestamp: 2022-08-19 06:46:44.458361\n",
      "resetting env. episode 2997, reward total was -20.0. running mean: -19.711376208868906, timestamp: 2022-08-19 06:46:48.025402\n",
      "resetting env. episode 2998, reward total was -21.0. running mean: -19.724262446780216, timestamp: 2022-08-19 06:46:50.760437\n",
      "resetting env. episode 2999, reward total was -19.0. running mean: -19.717019822312416, timestamp: 2022-08-19 06:46:53.283468\n",
      "resetting env. episode 3000, reward total was -20.0. running mean: -19.719849624089292, timestamp: 2022-08-19 06:46:56.765514\n",
      "resetting env. episode 3001, reward total was -19.0. running mean: -19.7126511278484, timestamp: 2022-08-19 06:47:00.148556\n",
      "resetting env. episode 3002, reward total was -21.0. running mean: -19.725524616569917, timestamp: 2022-08-19 06:47:03.541599\n",
      "resetting env. episode 3003, reward total was -21.0. running mean: -19.73826937040422, timestamp: 2022-08-19 06:47:06.292634\n",
      "resetting env. episode 3004, reward total was -21.0. running mean: -19.750886676700176, timestamp: 2022-08-19 06:47:09.261671\n",
      "resetting env. episode 3005, reward total was -21.0. running mean: -19.763377809933175, timestamp: 2022-08-19 06:47:11.650703\n",
      "resetting env. episode 3006, reward total was -20.0. running mean: -19.765744031833844, timestamp: 2022-08-19 06:47:15.758763\n",
      "resetting env. episode 3007, reward total was -20.0. running mean: -19.768086591515505, timestamp: 2022-08-19 06:47:19.231800\n",
      "resetting env. episode 3008, reward total was -17.0. running mean: -19.74040572560035, timestamp: 2022-08-19 06:47:22.655845\n",
      "resetting env. episode 3009, reward total was -20.0. running mean: -19.743001668344345, timestamp: 2022-08-19 06:47:25.390876\n",
      "resetting env. episode 3010, reward total was -19.0. running mean: -19.7355716516609, timestamp: 2022-08-19 06:47:28.604915\n",
      "resetting env. episode 3011, reward total was -19.0. running mean: -19.728215935144295, timestamp: 2022-08-19 06:47:31.460953\n",
      "resetting env. episode 3012, reward total was -19.0. running mean: -19.720933775792854, timestamp: 2022-08-19 06:47:33.842982\n",
      "resetting env. episode 3013, reward total was -20.0. running mean: -19.723724438034925, timestamp: 2022-08-19 06:47:37.258026\n",
      "resetting env. episode 3014, reward total was -21.0. running mean: -19.736487193654575, timestamp: 2022-08-19 06:47:40.088062\n",
      "resetting env. episode 3015, reward total was -21.0. running mean: -19.74912232171803, timestamp: 2022-08-19 06:47:43.446105\n",
      "resetting env. episode 3016, reward total was -20.0. running mean: -19.751631098500848, timestamp: 2022-08-19 06:47:46.066142\n",
      "resetting env. episode 3017, reward total was -21.0. running mean: -19.76411478751584, timestamp: 2022-08-19 06:47:49.160178\n",
      "resetting env. episode 3018, reward total was -20.0. running mean: -19.76647363964068, timestamp: 2022-08-19 06:47:51.837212\n",
      "resetting env. episode 3019, reward total was -19.0. running mean: -19.758808903244272, timestamp: 2022-08-19 06:47:55.353257\n",
      "resetting env. episode 3020, reward total was -17.0. running mean: -19.73122081421183, timestamp: 2022-08-19 06:47:59.505310\n",
      "resetting env. episode 3021, reward total was -20.0. running mean: -19.73390860606971, timestamp: 2022-08-19 06:48:03.931367\n",
      "resetting env. episode 3022, reward total was -19.0. running mean: -19.726569520009015, timestamp: 2022-08-19 06:48:07.205406\n",
      "resetting env. episode 3023, reward total was -21.0. running mean: -19.739303824808925, timestamp: 2022-08-19 06:48:10.124443\n",
      "resetting env. episode 3024, reward total was -20.0. running mean: -19.741910786560833, timestamp: 2022-08-19 06:48:13.042482\n",
      "resetting env. episode 3025, reward total was -19.0. running mean: -19.734491678695225, timestamp: 2022-08-19 06:48:15.983518\n",
      "resetting env. episode 3026, reward total was -19.0. running mean: -19.727146761908273, timestamp: 2022-08-19 06:48:19.440562\n",
      "resetting env. episode 3027, reward total was -20.0. running mean: -19.72987529428919, timestamp: 2022-08-19 06:48:23.042608\n",
      "resetting env. episode 3028, reward total was -19.0. running mean: -19.7225765413463, timestamp: 2022-08-19 06:48:26.076652\n",
      "resetting env. episode 3029, reward total was -21.0. running mean: -19.735350775932837, timestamp: 2022-08-19 06:48:29.188688\n",
      "resetting env. episode 3030, reward total was -21.0. running mean: -19.74799726817351, timestamp: 2022-08-19 06:48:32.756733\n",
      "resetting env. episode 3031, reward total was -20.0. running mean: -19.750517295491775, timestamp: 2022-08-19 06:48:35.215761\n",
      "resetting env. episode 3032, reward total was -19.0. running mean: -19.743012122536857, timestamp: 2022-08-19 06:48:38.438805\n",
      "resetting env. episode 3033, reward total was -19.0. running mean: -19.73558200131149, timestamp: 2022-08-19 06:48:41.976848\n",
      "resetting env. episode 3034, reward total was -21.0. running mean: -19.748226181298374, timestamp: 2022-08-19 06:48:45.284898\n",
      "resetting env. episode 3035, reward total was -19.0. running mean: -19.740743919485393, timestamp: 2022-08-19 06:48:48.134926\n",
      "resetting env. episode 3036, reward total was -20.0. running mean: -19.743336480290537, timestamp: 2022-08-19 06:48:50.745961\n",
      "resetting env. episode 3037, reward total was -19.0. running mean: -19.735903115487634, timestamp: 2022-08-19 06:48:54.367006\n",
      "resetting env. episode 3038, reward total was -19.0. running mean: -19.72854408433276, timestamp: 2022-08-19 06:48:57.479875\n",
      "resetting env. episode 3039, reward total was -21.0. running mean: -19.741258643489434, timestamp: 2022-08-19 06:49:00.856921\n",
      "resetting env. episode 3040, reward total was -21.0. running mean: -19.75384605705454, timestamp: 2022-08-19 06:49:03.828956\n",
      "resetting env. episode 3041, reward total was -21.0. running mean: -19.766307596483998, timestamp: 2022-08-19 06:49:06.609992\n",
      "resetting env. episode 3042, reward total was -21.0. running mean: -19.77864452051916, timestamp: 2022-08-19 06:49:09.821031\n",
      "resetting env. episode 3043, reward total was -20.0. running mean: -19.780858075313965, timestamp: 2022-08-19 06:49:13.067073\n",
      "resetting env. episode 3044, reward total was -20.0. running mean: -19.783049494560824, timestamp: 2022-08-19 06:49:16.332115\n",
      "resetting env. episode 3045, reward total was -20.0. running mean: -19.785218999615214, timestamp: 2022-08-19 06:49:19.379154\n",
      "resetting env. episode 3046, reward total was -19.0. running mean: -19.777366809619064, timestamp: 2022-08-19 06:49:21.986190\n",
      "resetting env. episode 3047, reward total was -19.0. running mean: -19.769593141522876, timestamp: 2022-08-19 06:49:25.355231\n",
      "resetting env. episode 3048, reward total was -19.0. running mean: -19.761897210107648, timestamp: 2022-08-19 06:49:28.026275\n",
      "resetting env. episode 3049, reward total was -20.0. running mean: -19.764278238006572, timestamp: 2022-08-19 06:49:31.169305\n",
      "resetting env. episode 3050, reward total was -19.0. running mean: -19.75663545562651, timestamp: 2022-08-19 06:49:34.722352\n",
      "resetting env. episode 3051, reward total was -19.0. running mean: -19.749069101070244, timestamp: 2022-08-19 06:49:38.484874\n",
      "resetting env. episode 3052, reward total was -21.0. running mean: -19.761578410059542, timestamp: 2022-08-19 06:49:42.090917\n",
      "resetting env. episode 3053, reward total was -21.0. running mean: -19.773962625958948, timestamp: 2022-08-19 06:49:45.319959\n",
      "resetting env. episode 3054, reward total was -19.0. running mean: -19.76622299969936, timestamp: 2022-08-19 06:49:48.371998\n",
      "resetting env. episode 3055, reward total was -21.0. running mean: -19.778560769702366, timestamp: 2022-08-19 06:49:51.155036\n",
      "resetting env. episode 3056, reward total was -20.0. running mean: -19.78077516200534, timestamp: 2022-08-19 06:49:53.926074\n",
      "resetting env. episode 3057, reward total was -19.0. running mean: -19.772967410385288, timestamp: 2022-08-19 06:49:56.895107\n",
      "resetting env. episode 3058, reward total was -19.0. running mean: -19.765237736281435, timestamp: 2022-08-19 06:49:59.653142\n",
      "resetting env. episode 3059, reward total was -19.0. running mean: -19.75758535891862, timestamp: 2022-08-19 06:50:03.474191\n",
      "resetting env. episode 3060, reward total was -21.0. running mean: -19.770009505329437, timestamp: 2022-08-19 06:50:06.901236\n",
      "resetting env. episode 3061, reward total was -20.0. running mean: -19.77230941027614, timestamp: 2022-08-19 06:50:10.460284\n",
      "resetting env. episode 3062, reward total was -20.0. running mean: -19.774586316173377, timestamp: 2022-08-19 06:50:13.542321\n",
      "resetting env. episode 3063, reward total was -18.0. running mean: -19.75684045301164, timestamp: 2022-08-19 06:50:16.817365\n",
      "resetting env. episode 3064, reward total was -19.0. running mean: -19.749272048481526, timestamp: 2022-08-19 06:50:19.729403\n",
      "resetting env. episode 3065, reward total was -20.0. running mean: -19.751779327996708, timestamp: 2022-08-19 06:50:22.717440\n",
      "resetting env. episode 3066, reward total was -20.0. running mean: -19.75426153471674, timestamp: 2022-08-19 06:50:25.488474\n",
      "resetting env. episode 3067, reward total was -19.0. running mean: -19.746718919369574, timestamp: 2022-08-19 06:50:28.580516\n",
      "resetting env. episode 3068, reward total was -21.0. running mean: -19.75925173017588, timestamp: 2022-08-19 06:50:31.548551\n",
      "resetting env. episode 3069, reward total was -17.0. running mean: -19.731659212874124, timestamp: 2022-08-19 06:50:35.385603\n",
      "resetting env. episode 3070, reward total was -21.0. running mean: -19.744342620745385, timestamp: 2022-08-19 06:50:38.956644\n",
      "resetting env. episode 3071, reward total was -21.0. running mean: -19.756899194537933, timestamp: 2022-08-19 06:50:42.494691\n",
      "resetting env. episode 3072, reward total was -17.0. running mean: -19.729330202592557, timestamp: 2022-08-19 06:50:46.031738\n",
      "resetting env. episode 3073, reward total was -20.0. running mean: -19.73203690056663, timestamp: 2022-08-19 06:50:49.659783\n",
      "resetting env. episode 3074, reward total was -19.0. running mean: -19.724716531560965, timestamp: 2022-08-19 06:50:52.120813\n",
      "resetting env. episode 3075, reward total was -20.0. running mean: -19.727469366245355, timestamp: 2022-08-19 06:50:54.648851\n",
      "resetting env. episode 3076, reward total was -20.0. running mean: -19.7301946725829, timestamp: 2022-08-19 06:50:57.295883\n",
      "resetting env. episode 3077, reward total was -21.0. running mean: -19.74289272585707, timestamp: 2022-08-19 06:51:01.107932\n",
      "resetting env. episode 3078, reward total was -19.0. running mean: -19.735463798598502, timestamp: 2022-08-19 06:51:03.996348\n",
      "resetting env. episode 3079, reward total was -20.0. running mean: -19.738109160612517, timestamp: 2022-08-19 06:51:06.910386\n",
      "resetting env. episode 3080, reward total was -19.0. running mean: -19.730728069006393, timestamp: 2022-08-19 06:51:10.332430\n",
      "resetting env. episode 3081, reward total was -19.0. running mean: -19.72342078831633, timestamp: 2022-08-19 06:51:13.761473\n",
      "resetting env. episode 3082, reward total was -21.0. running mean: -19.736186580433166, timestamp: 2022-08-19 06:51:16.820517\n",
      "resetting env. episode 3083, reward total was -21.0. running mean: -19.748824714628835, timestamp: 2022-08-19 06:51:19.540549\n",
      "resetting env. episode 3084, reward total was -20.0. running mean: -19.751336467482545, timestamp: 2022-08-19 06:51:22.645591\n",
      "resetting env. episode 3085, reward total was -18.0. running mean: -19.73382310280772, timestamp: 2022-08-19 06:51:26.814641\n",
      "resetting env. episode 3086, reward total was -19.0. running mean: -19.726484871779643, timestamp: 2022-08-19 06:51:30.188684\n",
      "resetting env. episode 3087, reward total was -20.0. running mean: -19.729220023061846, timestamp: 2022-08-19 06:51:33.174726\n",
      "resetting env. episode 3088, reward total was -18.0. running mean: -19.71192782283123, timestamp: 2022-08-19 06:51:36.462765\n",
      "resetting env. episode 3089, reward total was -18.0. running mean: -19.694808544602914, timestamp: 2022-08-19 06:51:39.731805\n",
      "resetting env. episode 3090, reward total was -18.0. running mean: -19.677860459156886, timestamp: 2022-08-19 06:51:43.503855\n",
      "resetting env. episode 3091, reward total was -18.0. running mean: -19.661081854565317, timestamp: 2022-08-19 06:51:46.808898\n",
      "resetting env. episode 3092, reward total was -18.0. running mean: -19.644471036019663, timestamp: 2022-08-19 06:51:50.288939\n",
      "resetting env. episode 3093, reward total was -21.0. running mean: -19.658026325659467, timestamp: 2022-08-19 06:51:52.534969\n",
      "resetting env. episode 3094, reward total was -21.0. running mean: -19.67144606240287, timestamp: 2022-08-19 06:51:55.646011\n",
      "resetting env. episode 3095, reward total was -18.0. running mean: -19.654731601778842, timestamp: 2022-08-19 06:51:58.827054\n",
      "resetting env. episode 3096, reward total was -18.0. running mean: -19.638184285761053, timestamp: 2022-08-19 06:52:01.410082\n",
      "resetting env. episode 3097, reward total was -21.0. running mean: -19.651802442903442, timestamp: 2022-08-19 06:52:04.500122\n",
      "resetting env. episode 3098, reward total was -18.0. running mean: -19.635284418474406, timestamp: 2022-08-19 06:52:07.417158\n",
      "resetting env. episode 3099, reward total was -20.0. running mean: -19.63893157428966, timestamp: 2022-08-19 06:52:10.711200\n",
      "resetting env. episode 3100, reward total was -20.0. running mean: -19.64254225854676, timestamp: 2022-08-19 06:52:14.118242\n",
      "resetting env. episode 3101, reward total was -19.0. running mean: -19.636116835961296, timestamp: 2022-08-19 06:52:17.740289\n",
      "resetting env. episode 3102, reward total was -19.0. running mean: -19.629755667601685, timestamp: 2022-08-19 06:52:20.238322\n",
      "resetting env. episode 3103, reward total was -20.0. running mean: -19.633458110925666, timestamp: 2022-08-19 06:52:23.766365\n",
      "resetting env. episode 3104, reward total was -19.0. running mean: -19.627123529816412, timestamp: 2022-08-19 06:52:26.863404\n",
      "resetting env. episode 3105, reward total was -21.0. running mean: -19.64085229451825, timestamp: 2022-08-19 06:52:30.185448\n",
      "resetting env. episode 3106, reward total was -20.0. running mean: -19.644443771573066, timestamp: 2022-08-19 06:52:33.388491\n",
      "resetting env. episode 3107, reward total was -18.0. running mean: -19.627999333857336, timestamp: 2022-08-19 06:52:37.948544\n",
      "resetting env. episode 3108, reward total was -18.0. running mean: -19.61171934051876, timestamp: 2022-08-19 06:52:41.499590\n",
      "resetting env. episode 3109, reward total was -20.0. running mean: -19.615602147113574, timestamp: 2022-08-19 06:52:44.581629\n",
      "resetting env. episode 3110, reward total was -21.0. running mean: -19.62944612564244, timestamp: 2022-08-19 06:52:47.662668\n",
      "resetting env. episode 3111, reward total was -17.0. running mean: -19.603151664386015, timestamp: 2022-08-19 06:52:51.423715\n",
      "resetting env. episode 3112, reward total was -20.0. running mean: -19.607120147742155, timestamp: 2022-08-19 06:52:54.251755\n",
      "resetting env. episode 3113, reward total was -21.0. running mean: -19.621048946264732, timestamp: 2022-08-19 06:52:56.659783\n",
      "resetting env. episode 3114, reward total was -21.0. running mean: -19.634838456802086, timestamp: 2022-08-19 06:52:59.353818\n",
      "resetting env. episode 3115, reward total was -21.0. running mean: -19.648490072234065, timestamp: 2022-08-19 06:53:03.065864\n",
      "resetting env. episode 3116, reward total was -19.0. running mean: -19.642005171511727, timestamp: 2022-08-19 06:53:06.490905\n",
      "resetting env. episode 3117, reward total was -21.0. running mean: -19.65558511979661, timestamp: 2022-08-19 06:53:10.353954\n",
      "resetting env. episode 3118, reward total was -20.0. running mean: -19.65902926859864, timestamp: 2022-08-19 06:53:13.189992\n",
      "resetting env. episode 3119, reward total was -21.0. running mean: -19.672438975912655, timestamp: 2022-08-19 06:53:16.106031\n",
      "resetting env. episode 3120, reward total was -21.0. running mean: -19.68571458615353, timestamp: 2022-08-19 06:53:19.427066\n",
      "resetting env. episode 3121, reward total was -21.0. running mean: -19.698857440291995, timestamp: 2022-08-19 06:53:23.001112\n",
      "resetting env. episode 3122, reward total was -21.0. running mean: -19.711868865889077, timestamp: 2022-08-19 06:53:25.921153\n",
      "resetting env. episode 3123, reward total was -21.0. running mean: -19.724750177230188, timestamp: 2022-08-19 06:53:29.230192\n",
      "resetting env. episode 3124, reward total was -19.0. running mean: -19.717502675457887, timestamp: 2022-08-19 06:53:33.020239\n",
      "resetting env. episode 3125, reward total was -21.0. running mean: -19.73032764870331, timestamp: 2022-08-19 06:53:36.011276\n",
      "resetting env. episode 3126, reward total was -19.0. running mean: -19.723024372216276, timestamp: 2022-08-19 06:53:38.610313\n",
      "resetting env. episode 3127, reward total was -21.0. running mean: -19.735794128494113, timestamp: 2022-08-19 06:53:42.128353\n",
      "resetting env. episode 3128, reward total was -15.0. running mean: -19.68843618720917, timestamp: 2022-08-19 06:53:45.892401\n",
      "resetting env. episode 3129, reward total was -20.0. running mean: -19.69155182533708, timestamp: 2022-08-19 06:53:49.043440\n",
      "resetting env. episode 3130, reward total was -17.0. running mean: -19.66463630708371, timestamp: 2022-08-19 06:53:53.424495\n",
      "resetting env. episode 3131, reward total was -20.0. running mean: -19.667989944012874, timestamp: 2022-08-19 06:53:56.907539\n",
      "resetting env. episode 3132, reward total was -16.0. running mean: -19.631310044572746, timestamp: 2022-08-19 06:54:01.192985\n",
      "resetting env. episode 3133, reward total was -20.0. running mean: -19.634996944127018, timestamp: 2022-08-19 06:54:04.450028\n",
      "resetting env. episode 3134, reward total was -19.0. running mean: -19.628646974685747, timestamp: 2022-08-19 06:54:07.932071\n",
      "resetting env. episode 3135, reward total was -20.0. running mean: -19.632360504938887, timestamp: 2022-08-19 06:54:10.683105\n",
      "resetting env. episode 3136, reward total was -20.0. running mean: -19.636036899889497, timestamp: 2022-08-19 06:54:14.545153\n",
      "resetting env. episode 3137, reward total was -18.0. running mean: -19.6196765308906, timestamp: 2022-08-19 06:54:17.924201\n",
      "resetting env. episode 3138, reward total was -18.0. running mean: -19.603479765581696, timestamp: 2022-08-19 06:54:20.913234\n",
      "resetting env. episode 3139, reward total was -15.0. running mean: -19.55744496792588, timestamp: 2022-08-19 06:54:24.526279\n",
      "resetting env. episode 3140, reward total was -21.0. running mean: -19.57187051824662, timestamp: 2022-08-19 06:54:27.684319\n",
      "resetting env. episode 3141, reward total was -19.0. running mean: -19.566151813064156, timestamp: 2022-08-19 06:54:31.416368\n",
      "resetting env. episode 3142, reward total was -19.0. running mean: -19.560490294933516, timestamp: 2022-08-19 06:54:34.676412\n",
      "resetting env. episode 3143, reward total was -20.0. running mean: -19.56488539198418, timestamp: 2022-08-19 06:54:37.736449\n",
      "resetting env. episode 3144, reward total was -17.0. running mean: -19.53923653806434, timestamp: 2022-08-19 06:54:41.452494\n",
      "resetting env. episode 3145, reward total was -17.0. running mean: -19.513844172683697, timestamp: 2022-08-19 06:54:45.793549\n",
      "resetting env. episode 3146, reward total was -21.0. running mean: -19.52870573095686, timestamp: 2022-08-19 06:54:49.215595\n",
      "resetting env. episode 3147, reward total was -19.0. running mean: -19.523418673647296, timestamp: 2022-08-19 06:54:52.553632\n",
      "resetting env. episode 3148, reward total was -18.0. running mean: -19.50818448691082, timestamp: 2022-08-19 06:54:55.635669\n",
      "resetting env. episode 3149, reward total was -21.0. running mean: -19.523102642041714, timestamp: 2022-08-19 06:54:58.514706\n",
      "resetting env. episode 3150, reward total was -20.0. running mean: -19.527871615621297, timestamp: 2022-08-19 06:55:01.891748\n",
      "resetting env. episode 3151, reward total was -20.0. running mean: -19.532592899465083, timestamp: 2022-08-19 06:55:04.538781\n",
      "resetting env. episode 3152, reward total was -19.0. running mean: -19.527266970470432, timestamp: 2022-08-19 06:55:08.000823\n",
      "resetting env. episode 3153, reward total was -20.0. running mean: -19.531994300765728, timestamp: 2022-08-19 06:55:10.483855\n",
      "resetting env. episode 3154, reward total was -21.0. running mean: -19.54667435775807, timestamp: 2022-08-19 06:55:12.900891\n",
      "resetting env. episode 3155, reward total was -21.0. running mean: -19.561207614180493, timestamp: 2022-08-19 06:55:16.010932\n",
      "resetting env. episode 3156, reward total was -20.0. running mean: -19.565595538038686, timestamp: 2022-08-19 06:55:19.309964\n",
      "resetting env. episode 3157, reward total was -18.0. running mean: -19.549939582658297, timestamp: 2022-08-19 06:55:22.555006\n",
      "resetting env. episode 3158, reward total was -17.0. running mean: -19.524440186831715, timestamp: 2022-08-19 06:55:26.334054\n",
      "resetting env. episode 3159, reward total was -19.0. running mean: -19.519195784963397, timestamp: 2022-08-19 06:55:29.011085\n",
      "resetting env. episode 3160, reward total was -21.0. running mean: -19.534003827113764, timestamp: 2022-08-19 06:55:31.607119\n",
      "resetting env. episode 3161, reward total was -19.0. running mean: -19.52866378884263, timestamp: 2022-08-19 06:55:35.321164\n",
      "resetting env. episode 3162, reward total was -20.0. running mean: -19.533377150954202, timestamp: 2022-08-19 06:55:38.884207\n",
      "resetting env. episode 3163, reward total was -19.0. running mean: -19.52804337944466, timestamp: 2022-08-19 06:55:43.155267\n",
      "resetting env. episode 3164, reward total was -19.0. running mean: -19.522762945650214, timestamp: 2022-08-19 06:55:46.215302\n",
      "resetting env. episode 3165, reward total was -18.0. running mean: -19.50753531619371, timestamp: 2022-08-19 06:55:49.354338\n",
      "resetting env. episode 3166, reward total was -20.0. running mean: -19.512459963031773, timestamp: 2022-08-19 06:55:52.238373\n",
      "resetting env. episode 3167, reward total was -19.0. running mean: -19.507335363401456, timestamp: 2022-08-19 06:55:55.546415\n",
      "resetting env. episode 3168, reward total was -21.0. running mean: -19.52226200976744, timestamp: 2022-08-19 06:55:58.811455\n",
      "resetting env. episode 3169, reward total was -20.0. running mean: -19.527039389669767, timestamp: 2022-08-19 06:56:02.388500\n",
      "resetting env. episode 3170, reward total was -19.0. running mean: -19.52176899577307, timestamp: 2022-08-19 06:56:05.022531\n",
      "resetting env. episode 3171, reward total was -20.0. running mean: -19.52655130581534, timestamp: 2022-08-19 06:56:08.465576\n",
      "resetting env. episode 3172, reward total was -19.0. running mean: -19.521285792757187, timestamp: 2022-08-19 06:56:11.606617\n",
      "resetting env. episode 3173, reward total was -20.0. running mean: -19.526072934829614, timestamp: 2022-08-19 06:56:13.975656\n",
      "resetting env. episode 3174, reward total was -21.0. running mean: -19.54081220548132, timestamp: 2022-08-19 06:56:17.066681\n",
      "resetting env. episode 3175, reward total was -19.0. running mean: -19.535404083426506, timestamp: 2022-08-19 06:56:21.221733\n",
      "resetting env. episode 3176, reward total was -20.0. running mean: -19.54005004259224, timestamp: 2022-08-19 06:56:24.984782\n",
      "resetting env. episode 3177, reward total was -21.0. running mean: -19.55464954216632, timestamp: 2022-08-19 06:56:27.826813\n",
      "resetting env. episode 3178, reward total was -20.0. running mean: -19.559103046744656, timestamp: 2022-08-19 06:56:30.903851\n",
      "resetting env. episode 3179, reward total was -21.0. running mean: -19.57351201627721, timestamp: 2022-08-19 06:56:34.804899\n",
      "resetting env. episode 3180, reward total was -19.0. running mean: -19.567776896114438, timestamp: 2022-08-19 06:56:38.074944\n",
      "resetting env. episode 3181, reward total was -19.0. running mean: -19.562099127153296, timestamp: 2022-08-19 06:56:41.539984\n",
      "resetting env. episode 3182, reward total was -20.0. running mean: -19.566478135881763, timestamp: 2022-08-19 06:56:45.032028\n",
      "resetting env. episode 3183, reward total was -19.0. running mean: -19.560813354522946, timestamp: 2022-08-19 06:56:47.705062\n",
      "resetting env. episode 3184, reward total was -20.0. running mean: -19.565205220977717, timestamp: 2022-08-19 06:56:50.848097\n",
      "resetting env. episode 3185, reward total was -20.0. running mean: -19.56955316876794, timestamp: 2022-08-19 06:56:53.830133\n",
      "resetting env. episode 3186, reward total was -19.0. running mean: -19.56385763708026, timestamp: 2022-08-19 06:56:57.574180\n",
      "resetting env. episode 3187, reward total was -20.0. running mean: -19.568219060709456, timestamp: 2022-08-19 06:57:00.739224\n",
      "resetting env. episode 3188, reward total was -20.0. running mean: -19.57253687010236, timestamp: 2022-08-19 06:57:03.499253\n",
      "resetting env. episode 3189, reward total was -21.0. running mean: -19.58681150140134, timestamp: 2022-08-19 06:57:06.396290\n",
      "resetting env. episode 3190, reward total was -17.0. running mean: -19.560943386387326, timestamp: 2022-08-19 06:57:10.292335\n",
      "resetting env. episode 3191, reward total was -21.0. running mean: -19.575333952523454, timestamp: 2022-08-19 06:57:13.226372\n",
      "resetting env. episode 3192, reward total was -19.0. running mean: -19.56958061299822, timestamp: 2022-08-19 06:57:16.852431\n",
      "resetting env. episode 3193, reward total was -21.0. running mean: -19.583884806868237, timestamp: 2022-08-19 06:57:20.001459\n",
      "resetting env. episode 3194, reward total was -21.0. running mean: -19.598045958799556, timestamp: 2022-08-19 06:57:23.712504\n",
      "resetting env. episode 3195, reward total was -17.0. running mean: -19.57206549921156, timestamp: 2022-08-19 06:57:27.546550\n",
      "resetting env. episode 3196, reward total was -20.0. running mean: -19.576344844219445, timestamp: 2022-08-19 06:57:30.320582\n",
      "resetting env. episode 3197, reward total was -21.0. running mean: -19.590581395777253, timestamp: 2022-08-19 06:57:33.458622\n",
      "resetting env. episode 3198, reward total was -20.0. running mean: -19.59467558181948, timestamp: 2022-08-19 06:57:36.432656\n",
      "resetting env. episode 3199, reward total was -20.0. running mean: -19.598728826001285, timestamp: 2022-08-19 06:57:39.528699\n",
      "resetting env. episode 3200, reward total was -20.0. running mean: -19.60274153774127, timestamp: 2022-08-19 06:57:43.084741\n",
      "resetting env. episode 3201, reward total was -20.0. running mean: -19.606714122363858, timestamp: 2022-08-19 06:57:46.667783\n",
      "resetting env. episode 3202, reward total was -19.0. running mean: -19.60064698114022, timestamp: 2022-08-19 06:57:49.419817\n",
      "resetting env. episode 3203, reward total was -19.0. running mean: -19.59464051132882, timestamp: 2022-08-19 06:57:52.710857\n",
      "resetting env. episode 3204, reward total was -16.0. running mean: -19.55869410621553, timestamp: 2022-08-19 06:57:56.420903\n",
      "resetting env. episode 3205, reward total was -21.0. running mean: -19.573107165153374, timestamp: 2022-08-19 06:57:59.689941\n",
      "resetting env. episode 3206, reward total was -18.0. running mean: -19.55737609350184, timestamp: 2022-08-19 06:58:02.773979\n",
      "resetting env. episode 3207, reward total was -19.0. running mean: -19.551802332566822, timestamp: 2022-08-19 06:58:06.062024\n",
      "resetting env. episode 3208, reward total was -20.0. running mean: -19.556284309241153, timestamp: 2022-08-19 06:58:08.487052\n",
      "resetting env. episode 3209, reward total was -20.0. running mean: -19.560721466148742, timestamp: 2022-08-19 06:58:11.350085\n",
      "resetting env. episode 3210, reward total was -21.0. running mean: -19.575114251487253, timestamp: 2022-08-19 06:58:13.841114\n",
      "resetting env. episode 3211, reward total was -21.0. running mean: -19.589363108972382, timestamp: 2022-08-19 06:58:16.492148\n",
      "resetting env. episode 3212, reward total was -17.0. running mean: -19.56346947788266, timestamp: 2022-08-19 06:58:20.156191\n",
      "resetting env. episode 3213, reward total was -17.0. running mean: -19.537834783103833, timestamp: 2022-08-19 06:58:24.424245\n",
      "resetting env. episode 3214, reward total was -21.0. running mean: -19.552456435272795, timestamp: 2022-08-19 06:58:27.046275\n",
      "resetting env. episode 3215, reward total was -19.0. running mean: -19.54693187092007, timestamp: 2022-08-19 06:58:30.520318\n",
      "resetting env. episode 3216, reward total was -21.0. running mean: -19.56146255221087, timestamp: 2022-08-19 06:58:33.053353\n",
      "resetting env. episode 3217, reward total was -20.0. running mean: -19.56584792668876, timestamp: 2022-08-19 06:58:36.099386\n",
      "resetting env. episode 3218, reward total was -20.0. running mean: -19.57018944742187, timestamp: 2022-08-19 06:58:38.791418\n",
      "resetting env. episode 3219, reward total was -19.0. running mean: -19.564487552947654, timestamp: 2022-08-19 06:58:42.116458\n",
      "resetting env. episode 3220, reward total was -18.0. running mean: -19.548842677418175, timestamp: 2022-08-19 06:58:45.084494\n",
      "resetting env. episode 3221, reward total was -21.0. running mean: -19.563354250643993, timestamp: 2022-08-19 06:58:47.886528\n",
      "resetting env. episode 3222, reward total was -19.0. running mean: -19.557720708137555, timestamp: 2022-08-19 06:58:51.272574\n",
      "resetting env. episode 3223, reward total was -19.0. running mean: -19.552143501056182, timestamp: 2022-08-19 06:58:54.669613\n",
      "resetting env. episode 3224, reward total was -19.0. running mean: -19.54662206604562, timestamp: 2022-08-19 06:58:57.756650\n",
      "resetting env. episode 3225, reward total was -18.0. running mean: -19.531155845385165, timestamp: 2022-08-19 06:59:01.943701\n",
      "resetting env. episode 3226, reward total was -19.0. running mean: -19.525844286931314, timestamp: 2022-08-19 06:59:05.577742\n",
      "resetting env. episode 3227, reward total was -18.0. running mean: -19.510585844062, timestamp: 2022-08-19 06:59:08.994783\n",
      "resetting env. episode 3228, reward total was -18.0. running mean: -19.49547998562138, timestamp: 2022-08-19 06:59:11.550817\n",
      "resetting env. episode 3229, reward total was -17.0. running mean: -19.47052518576517, timestamp: 2022-08-19 06:59:15.295862\n",
      "resetting env. episode 3230, reward total was -21.0. running mean: -19.485819933907518, timestamp: 2022-08-19 06:59:18.431899\n",
      "resetting env. episode 3231, reward total was -19.0. running mean: -19.480961734568442, timestamp: 2022-08-19 06:59:21.365933\n",
      "resetting env. episode 3232, reward total was -21.0. running mean: -19.49615211722276, timestamp: 2022-08-19 06:59:24.457970\n",
      "resetting env. episode 3233, reward total was -18.0. running mean: -19.48119059605053, timestamp: 2022-08-19 06:59:27.858010\n",
      "resetting env. episode 3234, reward total was -21.0. running mean: -19.496378690090026, timestamp: 2022-08-19 06:59:30.928047\n",
      "resetting env. episode 3235, reward total was -19.0. running mean: -19.491414903189128, timestamp: 2022-08-19 06:59:34.936096\n",
      "resetting env. episode 3236, reward total was -21.0. running mean: -19.506500754157237, timestamp: 2022-08-19 06:59:37.786129\n",
      "resetting env. episode 3237, reward total was -20.0. running mean: -19.511435746615664, timestamp: 2022-08-19 06:59:40.809166\n",
      "resetting env. episode 3238, reward total was -20.0. running mean: -19.516321389149507, timestamp: 2022-08-19 06:59:44.675213\n",
      "resetting env. episode 3239, reward total was -19.0. running mean: -19.511158175258014, timestamp: 2022-08-19 06:59:48.988265\n",
      "resetting env. episode 3240, reward total was -19.0. running mean: -19.506046593505435, timestamp: 2022-08-19 06:59:53.411838\n",
      "resetting env. episode 3241, reward total was -20.0. running mean: -19.51098612757038, timestamp: 2022-08-19 06:59:56.290878\n",
      "resetting env. episode 3242, reward total was -18.0. running mean: -19.495876266294676, timestamp: 2022-08-19 07:00:00.098924\n",
      "resetting env. episode 3243, reward total was -19.0. running mean: -19.49091750363173, timestamp: 2022-08-19 07:00:03.287957\n",
      "resetting env. episode 3244, reward total was -20.0. running mean: -19.496008328595412, timestamp: 2022-08-19 07:00:06.040996\n",
      "resetting env. episode 3245, reward total was -20.0. running mean: -19.501048245309455, timestamp: 2022-08-19 07:00:09.587034\n",
      "resetting env. episode 3246, reward total was -20.0. running mean: -19.50603776285636, timestamp: 2022-08-19 07:00:12.830071\n",
      "resetting env. episode 3247, reward total was -19.0. running mean: -19.500977385227795, timestamp: 2022-08-19 07:00:16.217113\n",
      "resetting env. episode 3248, reward total was -19.0. running mean: -19.49596761137552, timestamp: 2022-08-19 07:00:19.212151\n",
      "resetting env. episode 3249, reward total was -18.0. running mean: -19.481007935261765, timestamp: 2022-08-19 07:00:22.823190\n",
      "resetting env. episode 3250, reward total was -18.0. running mean: -19.466197855909147, timestamp: 2022-08-19 07:00:26.332233\n",
      "resetting env. episode 3251, reward total was -21.0. running mean: -19.481535877350055, timestamp: 2022-08-19 07:00:29.339271\n",
      "resetting env. episode 3252, reward total was -21.0. running mean: -19.496720518576556, timestamp: 2022-08-19 07:00:32.124300\n",
      "resetting env. episode 3253, reward total was -17.0. running mean: -19.471753313390792, timestamp: 2022-08-19 07:00:35.485342\n",
      "resetting env. episode 3254, reward total was -18.0. running mean: -19.457035780256884, timestamp: 2022-08-19 07:00:38.876381\n",
      "resetting env. episode 3255, reward total was -20.0. running mean: -19.462465422454315, timestamp: 2022-08-19 07:00:42.452427\n",
      "resetting env. episode 3256, reward total was -19.0. running mean: -19.457840768229772, timestamp: 2022-08-19 07:00:47.009477\n",
      "resetting env. episode 3257, reward total was -20.0. running mean: -19.463262360547475, timestamp: 2022-08-19 07:00:50.244516\n",
      "resetting env. episode 3258, reward total was -20.0. running mean: -19.468629736942, timestamp: 2022-08-19 07:00:54.045562\n",
      "resetting env. episode 3259, reward total was -21.0. running mean: -19.48394343957258, timestamp: 2022-08-19 07:00:57.270604\n",
      "resetting env. episode 3260, reward total was -21.0. running mean: -19.499104005176857, timestamp: 2022-08-19 07:00:59.816633\n",
      "resetting env. episode 3261, reward total was -20.0. running mean: -19.50411296512509, timestamp: 2022-08-19 07:01:02.873674\n",
      "resetting env. episode 3262, reward total was -20.0. running mean: -19.509071835473836, timestamp: 2022-08-19 07:01:06.713715\n",
      "resetting env. episode 3263, reward total was -18.0. running mean: -19.493981117119098, timestamp: 2022-08-19 07:01:09.806755\n",
      "resetting env. episode 3264, reward total was -15.0. running mean: -19.449041305947905, timestamp: 2022-08-19 07:01:14.251813\n",
      "resetting env. episode 3265, reward total was -20.0. running mean: -19.454550892888424, timestamp: 2022-08-19 07:01:17.176843\n",
      "resetting env. episode 3266, reward total was -20.0. running mean: -19.46000538395954, timestamp: 2022-08-19 07:01:20.295884\n",
      "resetting env. episode 3267, reward total was -20.0. running mean: -19.465405330119943, timestamp: 2022-08-19 07:01:23.189916\n",
      "resetting env. episode 3268, reward total was -20.0. running mean: -19.470751276818742, timestamp: 2022-08-19 07:01:26.340956\n",
      "resetting env. episode 3269, reward total was -21.0. running mean: -19.486043764050557, timestamp: 2022-08-19 07:01:28.841988\n",
      "resetting env. episode 3270, reward total was -19.0. running mean: -19.48118332641005, timestamp: 2022-08-19 07:01:32.186025\n",
      "resetting env. episode 3271, reward total was -18.0. running mean: -19.46637149314595, timestamp: 2022-08-19 07:01:35.464069\n",
      "resetting env. episode 3272, reward total was -18.0. running mean: -19.45170777821449, timestamp: 2022-08-19 07:01:39.220111\n",
      "resetting env. episode 3273, reward total was -19.0. running mean: -19.447190700432348, timestamp: 2022-08-19 07:01:42.857158\n",
      "resetting env. episode 3274, reward total was -21.0. running mean: -19.462718793428024, timestamp: 2022-08-19 07:01:46.063201\n",
      "resetting env. episode 3275, reward total was -19.0. running mean: -19.458091605493745, timestamp: 2022-08-19 07:01:49.352241\n",
      "resetting env. episode 3276, reward total was -20.0. running mean: -19.463510689438806, timestamp: 2022-08-19 07:01:52.661279\n",
      "resetting env. episode 3277, reward total was -21.0. running mean: -19.47887558254442, timestamp: 2022-08-19 07:01:55.194308\n",
      "resetting env. episode 3278, reward total was -16.0. running mean: -19.444086826718973, timestamp: 2022-08-19 07:01:59.561363\n",
      "resetting env. episode 3279, reward total was -21.0. running mean: -19.459645958451784, timestamp: 2022-08-19 07:02:02.189394\n",
      "resetting env. episode 3280, reward total was -21.0. running mean: -19.475049498867268, timestamp: 2022-08-19 07:02:05.929442\n",
      "resetting env. episode 3281, reward total was -19.0. running mean: -19.470299003878598, timestamp: 2022-08-19 07:02:09.357485\n",
      "resetting env. episode 3282, reward total was -21.0. running mean: -19.485596013839814, timestamp: 2022-08-19 07:02:13.145530\n",
      "resetting env. episode 3283, reward total was -19.0. running mean: -19.480740053701417, timestamp: 2022-08-19 07:02:16.410572\n",
      "resetting env. episode 3284, reward total was -17.0. running mean: -19.455932653164403, timestamp: 2022-08-19 07:02:20.151619\n",
      "resetting env. episode 3285, reward total was -17.0. running mean: -19.431373326632762, timestamp: 2022-08-19 07:02:23.857664\n",
      "resetting env. episode 3286, reward total was -18.0. running mean: -19.417059593366435, timestamp: 2022-08-19 07:02:27.354709\n",
      "resetting env. episode 3287, reward total was -17.0. running mean: -19.392888997432774, timestamp: 2022-08-19 07:02:30.785752\n",
      "resetting env. episode 3288, reward total was -21.0. running mean: -19.408960107458448, timestamp: 2022-08-19 07:02:33.776788\n",
      "resetting env. episode 3289, reward total was -19.0. running mean: -19.404870506383865, timestamp: 2022-08-19 07:02:37.696838\n",
      "resetting env. episode 3290, reward total was -18.0. running mean: -19.390821801320026, timestamp: 2022-08-19 07:02:40.732875\n",
      "resetting env. episode 3291, reward total was -21.0. running mean: -19.406913583306828, timestamp: 2022-08-19 07:02:44.428922\n",
      "resetting env. episode 3292, reward total was -19.0. running mean: -19.40284444747376, timestamp: 2022-08-19 07:02:47.556962\n",
      "resetting env. episode 3293, reward total was -18.0. running mean: -19.38881600299902, timestamp: 2022-08-19 07:02:50.803000\n",
      "resetting env. episode 3294, reward total was -19.0. running mean: -19.384927842969034, timestamp: 2022-08-19 07:02:54.240047\n",
      "resetting env. episode 3295, reward total was -18.0. running mean: -19.371078564539342, timestamp: 2022-08-19 07:02:57.517087\n",
      "resetting env. episode 3296, reward total was -20.0. running mean: -19.377367778893948, timestamp: 2022-08-19 07:03:00.925129\n",
      "resetting env. episode 3297, reward total was -20.0. running mean: -19.383594101105007, timestamp: 2022-08-19 07:03:04.199175\n",
      "resetting env. episode 3298, reward total was -19.0. running mean: -19.37975816009396, timestamp: 2022-08-19 07:03:07.407213\n",
      "resetting env. episode 3299, reward total was -20.0. running mean: -19.38596057849302, timestamp: 2022-08-19 07:03:11.088271\n",
      "resetting env. episode 3300, reward total was -21.0. running mean: -19.40210097270809, timestamp: 2022-08-19 07:03:15.510315\n",
      "resetting env. episode 3301, reward total was -21.0. running mean: -19.41807996298101, timestamp: 2022-08-19 07:03:17.701341\n",
      "resetting env. episode 3302, reward total was -19.0. running mean: -19.413899163351203, timestamp: 2022-08-19 07:03:21.409395\n",
      "resetting env. episode 3303, reward total was -17.0. running mean: -19.389760171717693, timestamp: 2022-08-19 07:03:25.571441\n",
      "resetting env. episode 3304, reward total was -21.0. running mean: -19.40586257000052, timestamp: 2022-08-19 07:03:29.218491\n",
      "resetting env. episode 3305, reward total was -18.0. running mean: -19.391803944300513, timestamp: 2022-08-19 07:03:33.021538\n",
      "resetting env. episode 3306, reward total was -21.0. running mean: -19.40788590485751, timestamp: 2022-08-19 07:03:35.993582\n",
      "resetting env. episode 3307, reward total was -19.0. running mean: -19.403807045808936, timestamp: 2022-08-19 07:03:38.831609\n",
      "resetting env. episode 3308, reward total was -18.0. running mean: -19.389768975350847, timestamp: 2022-08-19 07:03:42.104655\n",
      "resetting env. episode 3309, reward total was -19.0. running mean: -19.38587128559734, timestamp: 2022-08-19 07:03:45.579695\n",
      "resetting env. episode 3310, reward total was -21.0. running mean: -19.402012572741366, timestamp: 2022-08-19 07:03:49.163742\n",
      "resetting env. episode 3311, reward total was -19.0. running mean: -19.397992447013955, timestamp: 2022-08-19 07:03:52.591782\n",
      "resetting env. episode 3312, reward total was -21.0. running mean: -19.414012522543818, timestamp: 2022-08-19 07:03:56.728838\n",
      "resetting env. episode 3313, reward total was -20.0. running mean: -19.41987239731838, timestamp: 2022-08-19 07:03:59.544873\n",
      "resetting env. episode 3314, reward total was -21.0. running mean: -19.435673673345196, timestamp: 2022-08-19 07:04:02.933919\n",
      "resetting env. episode 3315, reward total was -14.0. running mean: -19.381316936611743, timestamp: 2022-08-19 07:04:07.894982\n",
      "resetting env. episode 3316, reward total was -20.0. running mean: -19.387503767245626, timestamp: 2022-08-19 07:04:11.672030\n",
      "resetting env. episode 3317, reward total was -20.0. running mean: -19.39362872957317, timestamp: 2022-08-19 07:04:14.535064\n",
      "resetting env. episode 3318, reward total was -20.0. running mean: -19.399692442277438, timestamp: 2022-08-19 07:04:17.821105\n",
      "resetting env. episode 3319, reward total was -20.0. running mean: -19.405695517854664, timestamp: 2022-08-19 07:04:21.292149\n",
      "resetting env. episode 3320, reward total was -19.0. running mean: -19.40163856267612, timestamp: 2022-08-19 07:04:25.054199\n",
      "resetting env. episode 3321, reward total was -20.0. running mean: -19.407622177049358, timestamp: 2022-08-19 07:04:28.370241\n",
      "resetting env. episode 3322, reward total was -20.0. running mean: -19.413545955278863, timestamp: 2022-08-19 07:04:31.418280\n",
      "resetting env. episode 3323, reward total was -20.0. running mean: -19.419410495726073, timestamp: 2022-08-19 07:04:34.072317\n",
      "resetting env. episode 3324, reward total was -21.0. running mean: -19.43521639076881, timestamp: 2022-08-19 07:04:37.717359\n",
      "resetting env. episode 3325, reward total was -21.0. running mean: -19.450864226861125, timestamp: 2022-08-19 07:04:40.537399\n",
      "resetting env. episode 3326, reward total was -19.0. running mean: -19.446355584592514, timestamp: 2022-08-19 07:04:43.533435\n",
      "resetting env. episode 3327, reward total was -19.0. running mean: -19.44189202874659, timestamp: 2022-08-19 07:04:46.315474\n",
      "resetting env. episode 3328, reward total was -19.0. running mean: -19.437473108459127, timestamp: 2022-08-19 07:04:50.100518\n",
      "resetting env. episode 3329, reward total was -21.0. running mean: -19.453098377374538, timestamp: 2022-08-19 07:04:52.922554\n",
      "resetting env. episode 3330, reward total was -20.0. running mean: -19.45856739360079, timestamp: 2022-08-19 07:04:56.127597\n",
      "resetting env. episode 3331, reward total was -20.0. running mean: -19.463981719664783, timestamp: 2022-08-19 07:04:59.364638\n",
      "resetting env. episode 3332, reward total was -21.0. running mean: -19.479341902468136, timestamp: 2022-08-19 07:05:02.669684\n",
      "resetting env. episode 3333, reward total was -21.0. running mean: -19.494548483443456, timestamp: 2022-08-19 07:05:05.188711\n",
      "resetting env. episode 3334, reward total was -21.0. running mean: -19.509602998609022, timestamp: 2022-08-19 07:05:08.749762\n",
      "resetting env. episode 3335, reward total was -19.0. running mean: -19.504506968622934, timestamp: 2022-08-19 07:05:11.989800\n",
      "resetting env. episode 3336, reward total was -20.0. running mean: -19.509461898936703, timestamp: 2022-08-19 07:05:15.138841\n",
      "resetting env. episode 3337, reward total was -18.0. running mean: -19.494367279947337, timestamp: 2022-08-19 07:05:18.461885\n",
      "resetting env. episode 3338, reward total was -21.0. running mean: -19.509423607147863, timestamp: 2022-08-19 07:05:21.936927\n",
      "resetting env. episode 3339, reward total was -18.0. running mean: -19.494329371076383, timestamp: 2022-08-19 07:05:25.418974\n",
      "resetting env. episode 3340, reward total was -21.0. running mean: -19.50938607736562, timestamp: 2022-08-19 07:05:28.781018\n",
      "resetting env. episode 3341, reward total was -18.0. running mean: -19.494292216591962, timestamp: 2022-08-19 07:05:32.270060\n",
      "resetting env. episode 3342, reward total was -20.0. running mean: -19.499349294426043, timestamp: 2022-08-19 07:05:34.969098\n",
      "resetting env. episode 3343, reward total was -21.0. running mean: -19.514355801481784, timestamp: 2022-08-19 07:05:38.953146\n",
      "resetting env. episode 3344, reward total was -19.0. running mean: -19.50921224346697, timestamp: 2022-08-19 07:05:42.389194\n",
      "resetting env. episode 3345, reward total was -19.0. running mean: -19.5041201210323, timestamp: 2022-08-19 07:05:45.886236\n",
      "resetting env. episode 3346, reward total was -21.0. running mean: -19.51907891982198, timestamp: 2022-08-19 07:05:49.561284\n",
      "resetting env. episode 3347, reward total was -21.0. running mean: -19.533888130623758, timestamp: 2022-08-19 07:05:52.422321\n",
      "resetting env. episode 3348, reward total was -17.0. running mean: -19.50854924931752, timestamp: 2022-08-19 07:05:56.927386\n",
      "resetting env. episode 3349, reward total was -20.0. running mean: -19.513463756824347, timestamp: 2022-08-19 07:05:59.982420\n",
      "resetting env. episode 3350, reward total was -21.0. running mean: -19.528329119256103, timestamp: 2022-08-19 07:06:03.325461\n",
      "resetting env. episode 3351, reward total was -19.0. running mean: -19.523045828063545, timestamp: 2022-08-19 07:06:06.419502\n",
      "resetting env. episode 3352, reward total was -18.0. running mean: -19.507815369782907, timestamp: 2022-08-19 07:06:09.424540\n",
      "resetting env. episode 3353, reward total was -21.0. running mean: -19.52273721608508, timestamp: 2022-08-19 07:06:12.809585\n",
      "resetting env. episode 3354, reward total was -21.0. running mean: -19.53750984392423, timestamp: 2022-08-19 07:06:15.803625\n",
      "resetting env. episode 3355, reward total was -21.0. running mean: -19.552134745484988, timestamp: 2022-08-19 07:06:19.671672\n",
      "resetting env. episode 3356, reward total was -19.0. running mean: -19.54661339803014, timestamp: 2022-08-19 07:06:23.461722\n",
      "resetting env. episode 3357, reward total was -20.0. running mean: -19.55114726404984, timestamp: 2022-08-19 07:06:26.384759\n",
      "resetting env. episode 3358, reward total was -18.0. running mean: -19.53563579140934, timestamp: 2022-08-19 07:06:29.841807\n",
      "resetting env. episode 3359, reward total was -21.0. running mean: -19.55027943349525, timestamp: 2022-08-19 07:06:32.637838\n",
      "resetting env. episode 3360, reward total was -21.0. running mean: -19.564776639160296, timestamp: 2022-08-19 07:06:36.119884\n",
      "resetting env. episode 3361, reward total was -20.0. running mean: -19.569128872768694, timestamp: 2022-08-19 07:06:39.500928\n",
      "resetting env. episode 3362, reward total was -21.0. running mean: -19.583437584041008, timestamp: 2022-08-19 07:06:42.311964\n",
      "resetting env. episode 3363, reward total was -18.0. running mean: -19.567603208200598, timestamp: 2022-08-19 07:06:45.729008\n",
      "resetting env. episode 3364, reward total was -19.0. running mean: -19.561927176118594, timestamp: 2022-08-19 07:06:49.158056\n",
      "resetting env. episode 3365, reward total was -21.0. running mean: -19.57630790435741, timestamp: 2022-08-19 07:06:53.531110\n",
      "resetting env. episode 3366, reward total was -21.0. running mean: -19.590544825313838, timestamp: 2022-08-19 07:06:56.561149\n",
      "resetting env. episode 3367, reward total was -18.0. running mean: -19.5746393770607, timestamp: 2022-08-19 07:07:00.993208\n",
      "resetting env. episode 3368, reward total was -18.0. running mean: -19.55889298329009, timestamp: 2022-08-19 07:07:03.792240\n",
      "resetting env. episode 3369, reward total was -21.0. running mean: -19.57330405345719, timestamp: 2022-08-19 07:07:07.274290\n",
      "resetting env. episode 3370, reward total was -19.0. running mean: -19.567571012922617, timestamp: 2022-08-19 07:07:10.818333\n",
      "resetting env. episode 3371, reward total was -19.0. running mean: -19.561895302793392, timestamp: 2022-08-19 07:07:13.547368\n",
      "resetting env. episode 3372, reward total was -17.0. running mean: -19.53627634976546, timestamp: 2022-08-19 07:07:16.692413\n",
      "resetting env. episode 3373, reward total was -21.0. running mean: -19.550913586267804, timestamp: 2022-08-19 07:07:19.106438\n",
      "resetting env. episode 3374, reward total was -19.0. running mean: -19.545404450405126, timestamp: 2022-08-19 07:07:22.115351\n",
      "resetting env. episode 3375, reward total was -20.0. running mean: -19.549950405901075, timestamp: 2022-08-19 07:07:26.025408\n",
      "resetting env. episode 3376, reward total was -18.0. running mean: -19.534450901842064, timestamp: 2022-08-19 07:07:29.428446\n",
      "resetting env. episode 3377, reward total was -19.0. running mean: -19.529106392823643, timestamp: 2022-08-19 07:07:32.789488\n",
      "resetting env. episode 3378, reward total was -21.0. running mean: -19.543815328895406, timestamp: 2022-08-19 07:07:36.153534\n",
      "resetting env. episode 3379, reward total was -20.0. running mean: -19.54837717560645, timestamp: 2022-08-19 07:07:40.564590\n",
      "resetting env. episode 3380, reward total was -18.0. running mean: -19.532893403850387, timestamp: 2022-08-19 07:07:44.571641\n",
      "resetting env. episode 3381, reward total was -18.0. running mean: -19.517564469811884, timestamp: 2022-08-19 07:07:48.406691\n",
      "resetting env. episode 3382, reward total was -15.0. running mean: -19.472388825113764, timestamp: 2022-08-19 07:07:52.169739\n",
      "resetting env. episode 3383, reward total was -20.0. running mean: -19.477664936862627, timestamp: 2022-08-19 07:07:54.391768\n",
      "resetting env. episode 3384, reward total was -18.0. running mean: -19.462888287494, timestamp: 2022-08-19 07:07:58.119815\n",
      "resetting env. episode 3385, reward total was -21.0. running mean: -19.47825940461906, timestamp: 2022-08-19 07:08:01.060853\n",
      "resetting env. episode 3386, reward total was -18.0. running mean: -19.463476810572867, timestamp: 2022-08-19 07:08:04.278898\n",
      "resetting env. episode 3387, reward total was -19.0. running mean: -19.45884204246714, timestamp: 2022-08-19 07:08:07.648937\n",
      "resetting env. episode 3388, reward total was -19.0. running mean: -19.45425362204247, timestamp: 2022-08-19 07:08:10.876984\n",
      "resetting env. episode 3389, reward total was -20.0. running mean: -19.459711085822043, timestamp: 2022-08-19 07:08:14.485027\n",
      "resetting env. episode 3390, reward total was -19.0. running mean: -19.455113974963822, timestamp: 2022-08-19 07:08:18.193075\n",
      "resetting env. episode 3391, reward total was -19.0. running mean: -19.450562835214185, timestamp: 2022-08-19 07:08:21.128116\n",
      "resetting env. episode 3392, reward total was -20.0. running mean: -19.45605720686204, timestamp: 2022-08-19 07:08:25.585170\n",
      "resetting env. episode 3393, reward total was -18.0. running mean: -19.44149663479342, timestamp: 2022-08-19 07:08:29.571223\n",
      "resetting env. episode 3394, reward total was -21.0. running mean: -19.457081668445486, timestamp: 2022-08-19 07:08:32.962265\n",
      "resetting env. episode 3395, reward total was -19.0. running mean: -19.452510851761033, timestamp: 2022-08-19 07:08:36.666313\n",
      "resetting env. episode 3396, reward total was -17.0. running mean: -19.427985743243426, timestamp: 2022-08-19 07:08:40.026355\n",
      "resetting env. episode 3397, reward total was -17.0. running mean: -19.403705885810993, timestamp: 2022-08-19 07:08:44.216410\n",
      "resetting env. episode 3398, reward total was -21.0. running mean: -19.419668826952883, timestamp: 2022-08-19 07:08:47.544457\n",
      "resetting env. episode 3399, reward total was -20.0. running mean: -19.425472138683354, timestamp: 2022-08-19 07:08:50.795495\n",
      "resetting env. episode 3400, reward total was -16.0. running mean: -19.39121741729652, timestamp: 2022-08-19 07:08:54.340541\n",
      "resetting env. episode 3401, reward total was -19.0. running mean: -19.387305243123556, timestamp: 2022-08-19 07:08:57.727584\n",
      "resetting env. episode 3402, reward total was -21.0. running mean: -19.40343219069232, timestamp: 2022-08-19 07:09:00.580621\n",
      "resetting env. episode 3403, reward total was -17.0. running mean: -19.3793978687854, timestamp: 2022-08-19 07:09:04.898677\n",
      "resetting env. episode 3404, reward total was -21.0. running mean: -19.395603890097547, timestamp: 2022-08-19 07:09:07.735714\n",
      "resetting env. episode 3405, reward total was -19.0. running mean: -19.391647851196574, timestamp: 2022-08-19 07:09:10.849755\n",
      "resetting env. episode 3406, reward total was -18.0. running mean: -19.377731372684607, timestamp: 2022-08-19 07:09:13.993803\n",
      "resetting env. episode 3407, reward total was -19.0. running mean: -19.37395405895776, timestamp: 2022-08-19 07:09:17.414840\n",
      "resetting env. episode 3408, reward total was -21.0. running mean: -19.390214518368182, timestamp: 2022-08-19 07:09:20.123879\n",
      "resetting env. episode 3409, reward total was -19.0. running mean: -19.386312373184502, timestamp: 2022-08-19 07:09:23.930926\n",
      "resetting env. episode 3410, reward total was -18.0. running mean: -19.372449249452657, timestamp: 2022-08-19 07:09:27.061962\n",
      "resetting env. episode 3411, reward total was -20.0. running mean: -19.37872475695813, timestamp: 2022-08-19 07:09:30.433007\n",
      "resetting env. episode 3412, reward total was -21.0. running mean: -19.394937509388548, timestamp: 2022-08-19 07:09:33.498046\n",
      "resetting env. episode 3413, reward total was -21.0. running mean: -19.410988134294662, timestamp: 2022-08-19 07:09:36.943091\n",
      "resetting env. episode 3414, reward total was -19.0. running mean: -19.406878252951717, timestamp: 2022-08-19 07:09:40.604139\n",
      "resetting env. episode 3415, reward total was -19.0. running mean: -19.402809470422202, timestamp: 2022-08-19 07:09:44.516189\n",
      "resetting env. episode 3416, reward total was -19.0. running mean: -19.39878137571798, timestamp: 2022-08-19 07:09:48.468239\n",
      "resetting env. episode 3417, reward total was -18.0. running mean: -19.3847935619608, timestamp: 2022-08-19 07:09:51.836281\n",
      "resetting env. episode 3418, reward total was -19.0. running mean: -19.380945626341195, timestamp: 2022-08-19 07:09:56.204337\n",
      "resetting env. episode 3419, reward total was -21.0. running mean: -19.397136170077783, timestamp: 2022-08-19 07:09:58.739373\n",
      "resetting env. episode 3420, reward total was -20.0. running mean: -19.403164808377003, timestamp: 2022-08-19 07:10:02.533418\n",
      "resetting env. episode 3421, reward total was -21.0. running mean: -19.419133160293235, timestamp: 2022-08-19 07:10:05.136457\n",
      "resetting env. episode 3422, reward total was -19.0. running mean: -19.414941828690303, timestamp: 2022-08-19 07:10:08.624497\n",
      "resetting env. episode 3423, reward total was -21.0. running mean: -19.430792410403402, timestamp: 2022-08-19 07:10:11.956541\n",
      "resetting env. episode 3424, reward total was -19.0. running mean: -19.42648448629937, timestamp: 2022-08-19 07:10:14.766584\n",
      "resetting env. episode 3425, reward total was -20.0. running mean: -19.432219641436376, timestamp: 2022-08-19 07:10:19.478636\n",
      "resetting env. episode 3426, reward total was -19.0. running mean: -19.427897445022012, timestamp: 2022-08-19 07:10:23.315688\n",
      "resetting env. episode 3427, reward total was -20.0. running mean: -19.43361847057179, timestamp: 2022-08-19 07:10:25.551714\n",
      "resetting env. episode 3428, reward total was -21.0. running mean: -19.449282285866072, timestamp: 2022-08-19 07:10:28.220747\n",
      "resetting env. episode 3429, reward total was -20.0. running mean: -19.454789463007412, timestamp: 2022-08-19 07:10:30.979785\n",
      "resetting env. episode 3430, reward total was -17.0. running mean: -19.43024156837734, timestamp: 2022-08-19 07:10:34.950835\n",
      "resetting env. episode 3431, reward total was -21.0. running mean: -19.44593915269357, timestamp: 2022-08-19 07:10:38.772887\n",
      "resetting env. episode 3432, reward total was -21.0. running mean: -19.461479761166633, timestamp: 2022-08-19 07:10:41.916924\n",
      "resetting env. episode 3433, reward total was -20.0. running mean: -19.466864963554965, timestamp: 2022-08-19 07:10:44.879959\n",
      "resetting env. episode 3434, reward total was -19.0. running mean: -19.462196313919417, timestamp: 2022-08-19 07:10:48.726009\n",
      "resetting env. episode 3435, reward total was -19.0. running mean: -19.457574350780224, timestamp: 2022-08-19 07:10:52.308058\n",
      "resetting env. episode 3436, reward total was -19.0. running mean: -19.452998607272423, timestamp: 2022-08-19 07:10:55.694098\n",
      "resetting env. episode 3437, reward total was -20.0. running mean: -19.4584686211997, timestamp: 2022-08-19 07:10:59.314144\n",
      "resetting env. episode 3438, reward total was -16.0. running mean: -19.423883934987703, timestamp: 2022-08-19 07:11:03.298197\n",
      "resetting env. episode 3439, reward total was -20.0. running mean: -19.429645095637824, timestamp: 2022-08-19 07:11:06.724238\n",
      "resetting env. episode 3440, reward total was -21.0. running mean: -19.445348644681445, timestamp: 2022-08-19 07:11:09.829279\n",
      "resetting env. episode 3441, reward total was -21.0. running mean: -19.46089515823463, timestamp: 2022-08-19 07:11:12.146201\n",
      "resetting env. episode 3442, reward total was -19.0. running mean: -19.456286206652287, timestamp: 2022-08-19 07:11:15.854247\n",
      "resetting env. episode 3443, reward total was -20.0. running mean: -19.461723344585764, timestamp: 2022-08-19 07:11:19.844297\n",
      "resetting env. episode 3444, reward total was -17.0. running mean: -19.437106111139908, timestamp: 2022-08-19 07:11:23.664346\n",
      "resetting env. episode 3445, reward total was -21.0. running mean: -19.452735050028508, timestamp: 2022-08-19 07:11:27.669397\n",
      "resetting env. episode 3446, reward total was -16.0. running mean: -19.418207699528224, timestamp: 2022-08-19 07:11:31.686448\n",
      "resetting env. episode 3447, reward total was -20.0. running mean: -19.42402562253294, timestamp: 2022-08-19 07:11:34.922488\n",
      "resetting env. episode 3448, reward total was -20.0. running mean: -19.429785366307613, timestamp: 2022-08-19 07:11:37.671523\n",
      "resetting env. episode 3449, reward total was -20.0. running mean: -19.435487512644535, timestamp: 2022-08-19 07:11:41.441572\n",
      "resetting env. episode 3450, reward total was -18.0. running mean: -19.421132637518088, timestamp: 2022-08-19 07:11:45.258622\n",
      "resetting env. episode 3451, reward total was -19.0. running mean: -19.416921311142907, timestamp: 2022-08-19 07:11:48.687663\n",
      "resetting env. episode 3452, reward total was -20.0. running mean: -19.422752098031477, timestamp: 2022-08-19 07:11:51.856703\n",
      "resetting env. episode 3453, reward total was -19.0. running mean: -19.418524577051162, timestamp: 2022-08-19 07:11:55.684752\n",
      "resetting env. episode 3454, reward total was -20.0. running mean: -19.42433933128065, timestamp: 2022-08-19 07:11:59.120842\n",
      "resetting env. episode 3455, reward total was -20.0. running mean: -19.43009593796784, timestamp: 2022-08-19 07:12:02.866891\n",
      "resetting env. episode 3456, reward total was -19.0. running mean: -19.425794978588165, timestamp: 2022-08-19 07:12:06.498934\n",
      "resetting env. episode 3457, reward total was -21.0. running mean: -19.441537028802284, timestamp: 2022-08-19 07:12:10.095979\n",
      "resetting env. episode 3458, reward total was -19.0. running mean: -19.43712165851426, timestamp: 2022-08-19 07:12:13.738028\n",
      "resetting env. episode 3459, reward total was -21.0. running mean: -19.45275044192912, timestamp: 2022-08-19 07:12:16.717061\n",
      "resetting env. episode 3460, reward total was -20.0. running mean: -19.458222937509827, timestamp: 2022-08-19 07:12:20.391107\n",
      "resetting env. episode 3461, reward total was -19.0. running mean: -19.45364070813473, timestamp: 2022-08-19 07:12:23.153143\n",
      "resetting env. episode 3462, reward total was -19.0. running mean: -19.449104301053385, timestamp: 2022-08-19 07:12:26.660188\n",
      "resetting env. episode 3463, reward total was -21.0. running mean: -19.464613258042853, timestamp: 2022-08-19 07:12:29.618226\n",
      "resetting env. episode 3464, reward total was -19.0. running mean: -19.459967125462427, timestamp: 2022-08-19 07:12:32.834268\n",
      "resetting env. episode 3465, reward total was -17.0. running mean: -19.435367454207803, timestamp: 2022-08-19 07:12:37.006321\n",
      "resetting env. episode 3466, reward total was -19.0. running mean: -19.431013779665726, timestamp: 2022-08-19 07:12:40.347359\n",
      "resetting env. episode 3467, reward total was -19.0. running mean: -19.426703641869068, timestamp: 2022-08-19 07:12:42.977399\n",
      "resetting env. episode 3468, reward total was -19.0. running mean: -19.42243660545038, timestamp: 2022-08-19 07:12:46.222438\n",
      "resetting env. episode 3469, reward total was -20.0. running mean: -19.428212239395876, timestamp: 2022-08-19 07:12:49.332474\n",
      "resetting env. episode 3470, reward total was -18.0. running mean: -19.413930117001918, timestamp: 2022-08-19 07:12:52.444515\n",
      "resetting env. episode 3471, reward total was -19.0. running mean: -19.4097908158319, timestamp: 2022-08-19 07:12:56.348980\n",
      "resetting env. episode 3472, reward total was -19.0. running mean: -19.405692907673583, timestamp: 2022-08-19 07:12:58.902011\n",
      "resetting env. episode 3473, reward total was -20.0. running mean: -19.411635978596845, timestamp: 2022-08-19 07:13:02.619059\n",
      "resetting env. episode 3474, reward total was -21.0. running mean: -19.427519618810877, timestamp: 2022-08-19 07:13:05.530096\n",
      "resetting env. episode 3475, reward total was -18.0. running mean: -19.413244422622768, timestamp: 2022-08-19 07:13:08.987140\n",
      "resetting env. episode 3476, reward total was -18.0. running mean: -19.39911197839654, timestamp: 2022-08-19 07:13:11.497171\n",
      "resetting env. episode 3477, reward total was -20.0. running mean: -19.405120858612573, timestamp: 2022-08-19 07:13:15.567223\n",
      "resetting env. episode 3478, reward total was -21.0. running mean: -19.42106965002645, timestamp: 2022-08-19 07:13:18.774266\n",
      "resetting env. episode 3479, reward total was -21.0. running mean: -19.436858953526187, timestamp: 2022-08-19 07:13:21.896314\n",
      "resetting env. episode 3480, reward total was -19.0. running mean: -19.432490363990926, timestamp: 2022-08-19 07:13:25.045338\n",
      "resetting env. episode 3481, reward total was -20.0. running mean: -19.438165460351016, timestamp: 2022-08-19 07:13:27.631373\n",
      "resetting env. episode 3482, reward total was -20.0. running mean: -19.443783805747504, timestamp: 2022-08-19 07:13:30.614413\n",
      "resetting env. episode 3483, reward total was -21.0. running mean: -19.45934596769003, timestamp: 2022-08-19 07:13:34.042451\n",
      "resetting env. episode 3484, reward total was -19.0. running mean: -19.45475250801313, timestamp: 2022-08-19 07:13:36.996489\n",
      "resetting env. episode 3485, reward total was -20.0. running mean: -19.460204982932996, timestamp: 2022-08-19 07:13:40.445534\n",
      "resetting env. episode 3486, reward total was -21.0. running mean: -19.475602933103666, timestamp: 2022-08-19 07:13:43.921574\n",
      "resetting env. episode 3487, reward total was -21.0. running mean: -19.49084690377263, timestamp: 2022-08-19 07:13:46.778611\n",
      "resetting env. episode 3488, reward total was -20.0. running mean: -19.495938434734903, timestamp: 2022-08-19 07:13:50.252654\n",
      "resetting env. episode 3489, reward total was -19.0. running mean: -19.490979050387555, timestamp: 2022-08-19 07:13:54.328706\n",
      "resetting env. episode 3490, reward total was -20.0. running mean: -19.49606925988368, timestamp: 2022-08-19 07:13:57.299743\n",
      "resetting env. episode 3491, reward total was -20.0. running mean: -19.50110856728484, timestamp: 2022-08-19 07:14:00.458783\n",
      "resetting env. episode 3492, reward total was -20.0. running mean: -19.50609748161199, timestamp: 2022-08-19 07:14:03.995829\n",
      "resetting env. episode 3493, reward total was -16.0. running mean: -19.471036506795873, timestamp: 2022-08-19 07:14:09.065888\n",
      "resetting env. episode 3494, reward total was -20.0. running mean: -19.476326141727913, timestamp: 2022-08-19 07:14:12.147926\n",
      "resetting env. episode 3495, reward total was -19.0. running mean: -19.471562880310636, timestamp: 2022-08-19 07:14:15.625970\n",
      "resetting env. episode 3496, reward total was -19.0. running mean: -19.46684725150753, timestamp: 2022-08-19 07:14:18.935010\n",
      "resetting env. episode 3497, reward total was -21.0. running mean: -19.482178778992456, timestamp: 2022-08-19 07:14:21.866051\n",
      "resetting env. episode 3498, reward total was -20.0. running mean: -19.48735699120253, timestamp: 2022-08-19 07:14:25.069087\n",
      "resetting env. episode 3499, reward total was -19.0. running mean: -19.482483421290507, timestamp: 2022-08-19 07:14:28.240125\n",
      "resetting env. episode 3500, reward total was -21.0. running mean: -19.497658587077602, timestamp: 2022-08-19 07:14:31.378164\n",
      "resetting env. episode 3501, reward total was -21.0. running mean: -19.512682001206826, timestamp: 2022-08-19 07:14:35.829220\n",
      "resetting env. episode 3502, reward total was -19.0. running mean: -19.50755518119476, timestamp: 2022-08-19 07:14:39.700278\n",
      "resetting env. episode 3503, reward total was -20.0. running mean: -19.512479629382813, timestamp: 2022-08-19 07:14:43.047312\n",
      "resetting env. episode 3504, reward total was -17.0. running mean: -19.487354833088986, timestamp: 2022-08-19 07:14:46.638355\n",
      "resetting env. episode 3505, reward total was -20.0. running mean: -19.492481284758096, timestamp: 2022-08-19 07:14:50.171401\n",
      "resetting env. episode 3506, reward total was -19.0. running mean: -19.487556471910516, timestamp: 2022-08-19 07:14:53.316436\n",
      "resetting env. episode 3507, reward total was -20.0. running mean: -19.49268090719141, timestamp: 2022-08-19 07:14:56.741479\n",
      "resetting env. episode 3508, reward total was -18.0. running mean: -19.477754098119494, timestamp: 2022-08-19 07:15:00.075523\n",
      "resetting env. episode 3509, reward total was -19.0. running mean: -19.4729765571383, timestamp: 2022-08-19 07:15:03.591565\n",
      "resetting env. episode 3510, reward total was -17.0. running mean: -19.448246791566916, timestamp: 2022-08-19 07:15:07.465610\n",
      "resetting env. episode 3511, reward total was -19.0. running mean: -19.443764323651248, timestamp: 2022-08-19 07:15:11.148659\n",
      "resetting env. episode 3512, reward total was -19.0. running mean: -19.439326680414737, timestamp: 2022-08-19 07:15:14.740702\n",
      "resetting env. episode 3513, reward total was -19.0. running mean: -19.43493341361059, timestamp: 2022-08-19 07:15:18.158741\n",
      "resetting env. episode 3514, reward total was -21.0. running mean: -19.450584079474485, timestamp: 2022-08-19 07:15:21.524784\n",
      "resetting env. episode 3515, reward total was -18.0. running mean: -19.43607823867974, timestamp: 2022-08-19 07:15:24.727823\n",
      "resetting env. episode 3516, reward total was -19.0. running mean: -19.431717456292944, timestamp: 2022-08-19 07:15:28.075867\n",
      "resetting env. episode 3517, reward total was -21.0. running mean: -19.447400281730015, timestamp: 2022-08-19 07:15:31.678907\n",
      "resetting env. episode 3518, reward total was -20.0. running mean: -19.452926278912713, timestamp: 2022-08-19 07:15:35.097954\n",
      "resetting env. episode 3519, reward total was -21.0. running mean: -19.468397016123586, timestamp: 2022-08-19 07:15:37.927988\n",
      "resetting env. episode 3520, reward total was -21.0. running mean: -19.48371304596235, timestamp: 2022-08-19 07:15:40.583018\n",
      "resetting env. episode 3521, reward total was -20.0. running mean: -19.488875915502724, timestamp: 2022-08-19 07:15:44.070062\n",
      "resetting env. episode 3522, reward total was -19.0. running mean: -19.4839871563477, timestamp: 2022-08-19 07:15:47.946106\n",
      "resetting env. episode 3523, reward total was -18.0. running mean: -19.46914728478422, timestamp: 2022-08-19 07:15:51.667153\n",
      "resetting env. episode 3524, reward total was -20.0. running mean: -19.474455811936377, timestamp: 2022-08-19 07:15:54.758193\n",
      "resetting env. episode 3525, reward total was -19.0. running mean: -19.469711253817014, timestamp: 2022-08-19 07:15:58.610238\n",
      "resetting env. episode 3526, reward total was -19.0. running mean: -19.465014141278846, timestamp: 2022-08-19 07:16:01.366272\n",
      "resetting env. episode 3527, reward total was -21.0. running mean: -19.480363999866057, timestamp: 2022-08-19 07:16:03.886306\n",
      "resetting env. episode 3528, reward total was -18.0. running mean: -19.465560359867396, timestamp: 2022-08-19 07:16:07.493347\n",
      "resetting env. episode 3529, reward total was -19.0. running mean: -19.460904756268725, timestamp: 2022-08-19 07:16:10.884392\n",
      "resetting env. episode 3530, reward total was -19.0. running mean: -19.45629570870604, timestamp: 2022-08-19 07:16:14.136428\n",
      "resetting env. episode 3531, reward total was -19.0. running mean: -19.45173275161898, timestamp: 2022-08-19 07:16:17.797473\n",
      "resetting env. episode 3532, reward total was -21.0. running mean: -19.46721542410279, timestamp: 2022-08-19 07:16:21.274516\n",
      "resetting env. episode 3533, reward total was -16.0. running mean: -19.43254326986176, timestamp: 2022-08-19 07:16:25.418564\n",
      "resetting env. episode 3534, reward total was -19.0. running mean: -19.428217837163142, timestamp: 2022-08-19 07:16:28.044595\n",
      "resetting env. episode 3535, reward total was -20.0. running mean: -19.43393565879151, timestamp: 2022-08-19 07:16:32.447649\n",
      "resetting env. episode 3536, reward total was -20.0. running mean: -19.439596302203594, timestamp: 2022-08-19 07:16:35.351682\n",
      "resetting env. episode 3537, reward total was -21.0. running mean: -19.45520033918156, timestamp: 2022-08-19 07:16:38.744727\n",
      "resetting env. episode 3538, reward total was -19.0. running mean: -19.450648335789744, timestamp: 2022-08-19 07:16:42.026764\n",
      "resetting env. episode 3539, reward total was -20.0. running mean: -19.456141852431845, timestamp: 2022-08-19 07:16:45.605809\n",
      "resetting env. episode 3540, reward total was -16.0. running mean: -19.421580433907526, timestamp: 2022-08-19 07:16:49.426855\n",
      "resetting env. episode 3541, reward total was -19.0. running mean: -19.41736462956845, timestamp: 2022-08-19 07:16:53.142904\n",
      "resetting env. episode 3542, reward total was -20.0. running mean: -19.423190983272764, timestamp: 2022-08-19 07:16:56.868947\n",
      "resetting env. episode 3543, reward total was -19.0. running mean: -19.41895907344004, timestamp: 2022-08-19 07:17:01.106997\n",
      "resetting env. episode 3544, reward total was -20.0. running mean: -19.42476948270564, timestamp: 2022-08-19 07:17:04.281038\n",
      "resetting env. episode 3545, reward total was -21.0. running mean: -19.440521787878584, timestamp: 2022-08-19 07:17:07.613075\n",
      "resetting env. episode 3546, reward total was -19.0. running mean: -19.4361165699998, timestamp: 2022-08-19 07:17:11.273120\n",
      "resetting env. episode 3547, reward total was -18.0. running mean: -19.4217554042998, timestamp: 2022-08-19 07:17:15.271171\n",
      "resetting env. episode 3548, reward total was -20.0. running mean: -19.427537850256805, timestamp: 2022-08-19 07:17:18.008200\n",
      "resetting env. episode 3549, reward total was -19.0. running mean: -19.42326247175424, timestamp: 2022-08-19 07:17:21.216242\n",
      "resetting env. episode 3550, reward total was -18.0. running mean: -19.409029847036695, timestamp: 2022-08-19 07:17:25.352288\n",
      "resetting env. episode 3551, reward total was -21.0. running mean: -19.42493954856633, timestamp: 2022-08-19 07:17:28.538328\n",
      "resetting env. episode 3552, reward total was -21.0. running mean: -19.440690153080666, timestamp: 2022-08-19 07:17:31.534365\n",
      "resetting env. episode 3553, reward total was -18.0. running mean: -19.426283251549858, timestamp: 2022-08-19 07:17:35.292413\n",
      "resetting env. episode 3554, reward total was -19.0. running mean: -19.42202041903436, timestamp: 2022-08-19 07:17:38.224451\n",
      "resetting env. episode 3555, reward total was -21.0. running mean: -19.437800214844017, timestamp: 2022-08-19 07:17:42.218496\n",
      "resetting env. episode 3556, reward total was -17.0. running mean: -19.41342221269558, timestamp: 2022-08-19 07:17:45.621534\n",
      "resetting env. episode 3557, reward total was -21.0. running mean: -19.429287990568625, timestamp: 2022-08-19 07:17:48.029562\n",
      "resetting env. episode 3558, reward total was -17.0. running mean: -19.40499511066294, timestamp: 2022-08-19 07:17:51.535605\n",
      "resetting env. episode 3559, reward total was -20.0. running mean: -19.410945159556313, timestamp: 2022-08-19 07:17:54.592644\n",
      "resetting env. episode 3560, reward total was -19.0. running mean: -19.406835707960752, timestamp: 2022-08-19 07:17:58.118683\n",
      "resetting env. episode 3561, reward total was -21.0. running mean: -19.422767350881145, timestamp: 2022-08-19 07:18:01.327725\n",
      "resetting env. episode 3562, reward total was -21.0. running mean: -19.438539677372333, timestamp: 2022-08-19 07:18:04.134762\n",
      "resetting env. episode 3563, reward total was -19.0. running mean: -19.434154280598612, timestamp: 2022-08-19 07:18:07.295794\n",
      "resetting env. episode 3564, reward total was -17.0. running mean: -19.409812737792628, timestamp: 2022-08-19 07:18:11.504847\n",
      "resetting env. episode 3565, reward total was -17.0. running mean: -19.385714610414702, timestamp: 2022-08-19 07:18:15.079889\n",
      "resetting env. episode 3566, reward total was -20.0. running mean: -19.391857464310554, timestamp: 2022-08-19 07:18:18.603933\n",
      "resetting env. episode 3567, reward total was -19.0. running mean: -19.38793888966745, timestamp: 2022-08-19 07:18:22.011981\n",
      "resetting env. episode 3568, reward total was -19.0. running mean: -19.384059500770775, timestamp: 2022-08-19 07:18:25.816023\n",
      "resetting env. episode 3569, reward total was -17.0. running mean: -19.36021890576307, timestamp: 2022-08-19 07:18:30.016076\n",
      "resetting env. episode 3570, reward total was -21.0. running mean: -19.37661671670544, timestamp: 2022-08-19 07:18:33.309113\n",
      "resetting env. episode 3571, reward total was -20.0. running mean: -19.382850549538382, timestamp: 2022-08-19 07:18:36.516153\n",
      "resetting env. episode 3572, reward total was -21.0. running mean: -19.399022044043, timestamp: 2022-08-19 07:18:40.406206\n",
      "resetting env. episode 3573, reward total was -16.0. running mean: -19.36503182360257, timestamp: 2022-08-19 07:18:44.164252\n",
      "resetting env. episode 3574, reward total was -20.0. running mean: -19.371381505366543, timestamp: 2022-08-19 07:18:47.876298\n",
      "resetting env. episode 3575, reward total was -19.0. running mean: -19.367667690312878, timestamp: 2022-08-19 07:18:51.720344\n",
      "resetting env. episode 3576, reward total was -20.0. running mean: -19.37399101340975, timestamp: 2022-08-19 07:18:55.246388\n",
      "resetting env. episode 3577, reward total was -19.0. running mean: -19.370251103275653, timestamp: 2022-08-19 07:18:57.666419\n",
      "resetting env. episode 3578, reward total was -19.0. running mean: -19.366548592242896, timestamp: 2022-08-19 07:19:01.302460\n",
      "resetting env. episode 3579, reward total was -18.0. running mean: -19.352883106320466, timestamp: 2022-08-19 07:19:05.205509\n",
      "resetting env. episode 3580, reward total was -19.0. running mean: -19.349354275257262, timestamp: 2022-08-19 07:19:10.314572\n",
      "resetting env. episode 3581, reward total was -17.0. running mean: -19.32586073250469, timestamp: 2022-08-19 07:19:14.087620\n",
      "resetting env. episode 3582, reward total was -20.0. running mean: -19.332602125179644, timestamp: 2022-08-19 07:19:17.057656\n",
      "resetting env. episode 3583, reward total was -17.0. running mean: -19.30927610392785, timestamp: 2022-08-19 07:19:20.959712\n",
      "resetting env. episode 3584, reward total was -20.0. running mean: -19.31618334288857, timestamp: 2022-08-19 07:19:23.430738\n",
      "resetting env. episode 3585, reward total was -19.0. running mean: -19.313021509459688, timestamp: 2022-08-19 07:19:26.531777\n",
      "resetting env. episode 3586, reward total was -21.0. running mean: -19.32989129436509, timestamp: 2022-08-19 07:19:30.254827\n",
      "resetting env. episode 3587, reward total was -20.0. running mean: -19.33659238142144, timestamp: 2022-08-19 07:19:33.312862\n",
      "resetting env. episode 3588, reward total was -17.0. running mean: -19.313226457607225, timestamp: 2022-08-19 07:19:37.050909\n",
      "resetting env. episode 3589, reward total was -21.0. running mean: -19.330094193031155, timestamp: 2022-08-19 07:19:40.603955\n",
      "resetting env. episode 3590, reward total was -20.0. running mean: -19.336793251100843, timestamp: 2022-08-19 07:19:44.030002\n",
      "resetting env. episode 3591, reward total was -20.0. running mean: -19.343425318589833, timestamp: 2022-08-19 07:19:47.291040\n",
      "resetting env. episode 3592, reward total was -21.0. running mean: -19.359991065403936, timestamp: 2022-08-19 07:19:50.282080\n",
      "resetting env. episode 3593, reward total was -19.0. running mean: -19.356391154749897, timestamp: 2022-08-19 07:19:53.576120\n",
      "resetting env. episode 3594, reward total was -21.0. running mean: -19.372827243202398, timestamp: 2022-08-19 07:19:57.120166\n",
      "resetting env. episode 3595, reward total was -21.0. running mean: -19.389098970770373, timestamp: 2022-08-19 07:19:59.596195\n",
      "resetting env. episode 3596, reward total was -18.0. running mean: -19.37520798106267, timestamp: 2022-08-19 07:20:03.963250\n",
      "resetting env. episode 3597, reward total was -21.0. running mean: -19.391455901252044, timestamp: 2022-08-19 07:20:07.106292\n",
      "resetting env. episode 3598, reward total was -19.0. running mean: -19.387541342239526, timestamp: 2022-08-19 07:20:10.767344\n",
      "resetting env. episode 3599, reward total was -20.0. running mean: -19.39366592881713, timestamp: 2022-08-19 07:20:14.012378\n",
      "resetting env. episode 3600, reward total was -20.0. running mean: -19.399729269528958, timestamp: 2022-08-19 07:20:17.344422\n",
      "resetting env. episode 3601, reward total was -19.0. running mean: -19.39573197683367, timestamp: 2022-08-19 07:20:20.940465\n",
      "resetting env. episode 3602, reward total was -19.0. running mean: -19.391774657065334, timestamp: 2022-08-19 07:20:24.786518\n",
      "resetting env. episode 3603, reward total was -21.0. running mean: -19.40785691049468, timestamp: 2022-08-19 07:20:27.404549\n",
      "resetting env. episode 3604, reward total was -18.0. running mean: -19.393778341389734, timestamp: 2022-08-19 07:20:30.365587\n",
      "resetting env. episode 3605, reward total was -19.0. running mean: -19.389840557975837, timestamp: 2022-08-19 07:20:33.956632\n",
      "resetting env. episode 3606, reward total was -20.0. running mean: -19.395942152396078, timestamp: 2022-08-19 07:20:36.985673\n",
      "resetting env. episode 3607, reward total was -20.0. running mean: -19.401982730872117, timestamp: 2022-08-19 07:20:40.829725\n",
      "resetting env. episode 3608, reward total was -21.0. running mean: -19.417962903563396, timestamp: 2022-08-19 07:20:44.770774\n",
      "resetting env. episode 3609, reward total was -19.0. running mean: -19.413783274527763, timestamp: 2022-08-19 07:20:48.766822\n",
      "resetting env. episode 3610, reward total was -21.0. running mean: -19.429645441782487, timestamp: 2022-08-19 07:20:51.947862\n",
      "resetting env. episode 3611, reward total was -18.0. running mean: -19.415348987364663, timestamp: 2022-08-19 07:20:55.793911\n",
      "resetting env. episode 3612, reward total was -20.0. running mean: -19.421195497491016, timestamp: 2022-08-19 07:20:59.279961\n",
      "resetting env. episode 3613, reward total was -20.0. running mean: -19.426983542516105, timestamp: 2022-08-19 07:21:02.844006\n",
      "resetting env. episode 3614, reward total was -19.0. running mean: -19.422713707090946, timestamp: 2022-08-19 07:21:06.036043\n",
      "resetting env. episode 3615, reward total was -20.0. running mean: -19.428486570020034, timestamp: 2022-08-19 07:21:08.654081\n",
      "resetting env. episode 3616, reward total was -21.0. running mean: -19.444201704319834, timestamp: 2022-08-19 07:21:11.954121\n",
      "resetting env. episode 3617, reward total was -18.0. running mean: -19.429759687276636, timestamp: 2022-08-19 07:21:16.087173\n",
      "resetting env. episode 3618, reward total was -17.0. running mean: -19.405462090403873, timestamp: 2022-08-19 07:21:20.291229\n",
      "resetting env. episode 3619, reward total was -20.0. running mean: -19.41140746949983, timestamp: 2022-08-19 07:21:23.366268\n",
      "resetting env. episode 3620, reward total was -21.0. running mean: -19.427293394804835, timestamp: 2022-08-19 07:21:27.290318\n",
      "resetting env. episode 3621, reward total was -18.0. running mean: -19.413020460856785, timestamp: 2022-08-19 07:21:31.601376\n",
      "resetting env. episode 3622, reward total was -20.0. running mean: -19.418890256248215, timestamp: 2022-08-19 07:21:34.991419\n",
      "resetting env. episode 3623, reward total was -18.0. running mean: -19.40470135368573, timestamp: 2022-08-19 07:21:37.660453\n",
      "resetting env. episode 3624, reward total was -18.0. running mean: -19.390654340148874, timestamp: 2022-08-19 07:21:41.276504\n",
      "resetting env. episode 3625, reward total was -19.0. running mean: -19.386747796747386, timestamp: 2022-08-19 07:21:44.730546\n",
      "resetting env. episode 3626, reward total was -19.0. running mean: -19.382880318779915, timestamp: 2022-08-19 07:21:48.071590\n",
      "resetting env. episode 3627, reward total was -15.0. running mean: -19.339051515592114, timestamp: 2022-08-19 07:21:53.120653\n",
      "resetting env. episode 3628, reward total was -20.0. running mean: -19.34566100043619, timestamp: 2022-08-19 07:21:56.723703\n",
      "resetting env. episode 3629, reward total was -19.0. running mean: -19.34220439043183, timestamp: 2022-08-19 07:22:00.280751\n",
      "resetting env. episode 3630, reward total was -17.0. running mean: -19.318782346527513, timestamp: 2022-08-19 07:22:04.151797\n",
      "resetting env. episode 3631, reward total was -18.0. running mean: -19.305594523062236, timestamp: 2022-08-19 07:22:08.309851\n",
      "resetting env. episode 3632, reward total was -20.0. running mean: -19.312538577831614, timestamp: 2022-08-19 07:22:11.488894\n",
      "resetting env. episode 3633, reward total was -19.0. running mean: -19.3094131920533, timestamp: 2022-08-19 07:22:14.652934\n",
      "resetting env. episode 3634, reward total was -18.0. running mean: -19.296319060132767, timestamp: 2022-08-19 07:22:18.360984\n",
      "resetting env. episode 3635, reward total was -21.0. running mean: -19.31335586953144, timestamp: 2022-08-19 07:22:21.702031\n",
      "resetting env. episode 3636, reward total was -21.0. running mean: -19.330222310836124, timestamp: 2022-08-19 07:22:25.025070\n",
      "resetting env. episode 3637, reward total was -20.0. running mean: -19.336920087727762, timestamp: 2022-08-19 07:22:28.778118\n",
      "resetting env. episode 3638, reward total was -17.0. running mean: -19.313550886850486, timestamp: 2022-08-19 07:22:32.541167\n",
      "resetting env. episode 3639, reward total was -17.0. running mean: -19.290415377981983, timestamp: 2022-08-19 07:22:35.787213\n",
      "resetting env. episode 3640, reward total was -21.0. running mean: -19.307511224202162, timestamp: 2022-08-19 07:22:39.375256\n",
      "resetting env. episode 3641, reward total was -21.0. running mean: -19.324436111960143, timestamp: 2022-08-19 07:22:42.532297\n",
      "resetting env. episode 3642, reward total was -21.0. running mean: -19.341191750840544, timestamp: 2022-08-19 07:22:45.453336\n",
      "resetting env. episode 3643, reward total was -20.0. running mean: -19.347779833332137, timestamp: 2022-08-19 07:22:48.406903\n",
      "resetting env. episode 3644, reward total was -21.0. running mean: -19.364302034998815, timestamp: 2022-08-19 07:22:51.419941\n",
      "resetting env. episode 3645, reward total was -19.0. running mean: -19.360659014648828, timestamp: 2022-08-19 07:22:54.613984\n",
      "resetting env. episode 3646, reward total was -17.0. running mean: -19.337052424502343, timestamp: 2022-08-19 07:22:59.096797\n",
      "resetting env. episode 3647, reward total was -19.0. running mean: -19.33368190025732, timestamp: 2022-08-19 07:23:03.683857\n",
      "resetting env. episode 3648, reward total was -19.0. running mean: -19.330345081254748, timestamp: 2022-08-19 07:23:06.256894\n",
      "resetting env. episode 3649, reward total was -20.0. running mean: -19.3370416304422, timestamp: 2022-08-19 07:23:08.999928\n",
      "resetting env. episode 3650, reward total was -19.0. running mean: -19.33367121413778, timestamp: 2022-08-19 07:23:12.150968\n",
      "resetting env. episode 3651, reward total was -19.0. running mean: -19.330334501996404, timestamp: 2022-08-19 07:23:15.150004\n",
      "resetting env. episode 3652, reward total was -19.0. running mean: -19.327031156976442, timestamp: 2022-08-19 07:23:18.669051\n",
      "resetting env. episode 3653, reward total was -20.0. running mean: -19.333760845406676, timestamp: 2022-08-19 07:23:21.507088\n",
      "resetting env. episode 3654, reward total was -20.0. running mean: -19.34042323695261, timestamp: 2022-08-19 07:23:24.842131\n",
      "resetting env. episode 3655, reward total was -21.0. running mean: -19.357019004583083, timestamp: 2022-08-19 07:23:27.138161\n",
      "resetting env. episode 3656, reward total was -19.0. running mean: -19.353448814537252, timestamp: 2022-08-19 07:23:30.653208\n",
      "resetting env. episode 3657, reward total was -18.0. running mean: -19.339914326391877, timestamp: 2022-08-19 07:23:34.608259\n",
      "resetting env. episode 3658, reward total was -17.0. running mean: -19.31651518312796, timestamp: 2022-08-19 07:23:38.497308\n",
      "resetting env. episode 3659, reward total was -19.0. running mean: -19.313350031296682, timestamp: 2022-08-19 07:23:42.196357\n",
      "resetting env. episode 3660, reward total was -18.0. running mean: -19.300216530983715, timestamp: 2022-08-19 07:23:46.714418\n",
      "resetting env. episode 3661, reward total was -19.0. running mean: -19.297214365673877, timestamp: 2022-08-19 07:23:49.906461\n",
      "resetting env. episode 3662, reward total was -20.0. running mean: -19.304242222017137, timestamp: 2022-08-19 07:23:53.512503\n",
      "resetting env. episode 3663, reward total was -21.0. running mean: -19.321199799796968, timestamp: 2022-08-19 07:23:56.903552\n",
      "resetting env. episode 3664, reward total was -19.0. running mean: -19.317987801799, timestamp: 2022-08-19 07:24:00.129594\n",
      "resetting env. episode 3665, reward total was -19.0. running mean: -19.31480792378101, timestamp: 2022-08-19 07:24:03.532637\n",
      "resetting env. episode 3666, reward total was -21.0. running mean: -19.3316598445432, timestamp: 2022-08-19 07:24:07.218685\n",
      "resetting env. episode 3667, reward total was -21.0. running mean: -19.34834324609777, timestamp: 2022-08-19 07:24:10.102723\n",
      "resetting env. episode 3668, reward total was -21.0. running mean: -19.36485981363679, timestamp: 2022-08-19 07:24:13.419764\n",
      "resetting env. episode 3669, reward total was -19.0. running mean: -19.361211215500425, timestamp: 2022-08-19 07:24:16.569804\n",
      "resetting env. episode 3670, reward total was -18.0. running mean: -19.34759910334542, timestamp: 2022-08-19 07:24:21.090864\n",
      "resetting env. episode 3671, reward total was -21.0. running mean: -19.364123112311965, timestamp: 2022-08-19 07:24:23.983899\n",
      "resetting env. episode 3672, reward total was -18.0. running mean: -19.350481881188845, timestamp: 2022-08-19 07:24:27.813951\n",
      "resetting env. episode 3673, reward total was -19.0. running mean: -19.346977062376958, timestamp: 2022-08-19 07:24:31.036994\n",
      "resetting env. episode 3674, reward total was -16.0. running mean: -19.313507291753186, timestamp: 2022-08-19 07:24:34.315035\n",
      "resetting env. episode 3675, reward total was -18.0. running mean: -19.300372218835655, timestamp: 2022-08-19 07:24:37.830083\n",
      "resetting env. episode 3676, reward total was -19.0. running mean: -19.297368496647298, timestamp: 2022-08-19 07:24:41.365126\n",
      "resetting env. episode 3677, reward total was -21.0. running mean: -19.314394811680828, timestamp: 2022-08-19 07:24:45.176181\n",
      "resetting env. episode 3678, reward total was -19.0. running mean: -19.31125086356402, timestamp: 2022-08-19 07:24:48.412218\n",
      "resetting env. episode 3679, reward total was -17.0. running mean: -19.288138354928382, timestamp: 2022-08-19 07:24:51.685260\n",
      "resetting env. episode 3680, reward total was -20.0. running mean: -19.295256971379096, timestamp: 2022-08-19 07:24:54.875300\n",
      "resetting env. episode 3681, reward total was -19.0. running mean: -19.292304401665305, timestamp: 2022-08-19 07:24:58.133346\n",
      "resetting env. episode 3682, reward total was -20.0. running mean: -19.299381357648652, timestamp: 2022-08-19 07:25:01.446387\n",
      "resetting env. episode 3683, reward total was -20.0. running mean: -19.306387544072166, timestamp: 2022-08-19 07:25:04.798431\n",
      "resetting env. episode 3684, reward total was -21.0. running mean: -19.323323668631446, timestamp: 2022-08-19 07:25:09.054488\n",
      "resetting env. episode 3685, reward total was -20.0. running mean: -19.33009043194513, timestamp: 2022-08-19 07:25:12.881538\n",
      "resetting env. episode 3686, reward total was -21.0. running mean: -19.34678952762568, timestamp: 2022-08-19 07:25:15.951580\n",
      "resetting env. episode 3687, reward total was -21.0. running mean: -19.363321632349425, timestamp: 2022-08-19 07:25:19.871631\n",
      "resetting env. episode 3688, reward total was -17.0. running mean: -19.339688416025933, timestamp: 2022-08-19 07:25:23.702677\n",
      "resetting env. episode 3689, reward total was -21.0. running mean: -19.356291531865676, timestamp: 2022-08-19 07:25:27.025721\n",
      "resetting env. episode 3690, reward total was -17.0. running mean: -19.33272861654702, timestamp: 2022-08-19 07:25:30.898771\n",
      "resetting env. episode 3691, reward total was -20.0. running mean: -19.33940133038155, timestamp: 2022-08-19 07:25:34.386817\n",
      "resetting env. episode 3692, reward total was -20.0. running mean: -19.34600731707773, timestamp: 2022-08-19 07:25:37.721859\n",
      "resetting env. episode 3693, reward total was -21.0. running mean: -19.362547243906956, timestamp: 2022-08-19 07:25:41.155909\n",
      "resetting env. episode 3694, reward total was -17.0. running mean: -19.338921771467888, timestamp: 2022-08-19 07:25:45.784965\n",
      "resetting env. episode 3695, reward total was -21.0. running mean: -19.35553255375321, timestamp: 2022-08-19 07:25:49.125008\n",
      "resetting env. episode 3696, reward total was -20.0. running mean: -19.36197722821568, timestamp: 2022-08-19 07:25:51.390038\n",
      "resetting env. episode 3697, reward total was -20.0. running mean: -19.36835745593352, timestamp: 2022-08-19 07:25:55.001084\n",
      "resetting env. episode 3698, reward total was -16.0. running mean: -19.334673881374183, timestamp: 2022-08-19 07:25:59.332145\n",
      "resetting env. episode 3699, reward total was -21.0. running mean: -19.351327142560443, timestamp: 2022-08-19 07:26:03.070193\n",
      "resetting env. episode 3700, reward total was -21.0. running mean: -19.36781387113484, timestamp: 2022-08-19 07:26:05.504223\n",
      "resetting env. episode 3701, reward total was -17.0. running mean: -19.344135732423492, timestamp: 2022-08-19 07:26:10.068279\n",
      "resetting env. episode 3702, reward total was -18.0. running mean: -19.330694375099256, timestamp: 2022-08-19 07:26:14.215335\n",
      "resetting env. episode 3703, reward total was -15.0. running mean: -19.28738743134826, timestamp: 2022-08-19 07:26:17.805383\n",
      "resetting env. episode 3704, reward total was -20.0. running mean: -19.294513557034776, timestamp: 2022-08-19 07:26:22.572444\n",
      "resetting env. episode 3705, reward total was -20.0. running mean: -19.301568421464427, timestamp: 2022-08-19 07:26:24.992474\n",
      "resetting env. episode 3706, reward total was -21.0. running mean: -19.318552737249785, timestamp: 2022-08-19 07:26:28.678524\n",
      "resetting env. episode 3707, reward total was -20.0. running mean: -19.325367209877285, timestamp: 2022-08-19 07:26:32.186568\n",
      "resetting env. episode 3708, reward total was -18.0. running mean: -19.31211353777851, timestamp: 2022-08-19 07:26:36.356623\n",
      "resetting env. episode 3709, reward total was -19.0. running mean: -19.308992402400726, timestamp: 2022-08-19 07:26:40.552677\n",
      "resetting env. episode 3710, reward total was -21.0. running mean: -19.32590247837672, timestamp: 2022-08-19 07:26:44.108727\n",
      "resetting env. episode 3711, reward total was -21.0. running mean: -19.342643453592952, timestamp: 2022-08-19 07:26:47.469767\n",
      "resetting env. episode 3712, reward total was -21.0. running mean: -19.359217019057024, timestamp: 2022-08-19 07:26:50.643808\n",
      "resetting env. episode 3713, reward total was -20.0. running mean: -19.365624848866453, timestamp: 2022-08-19 07:26:54.760860\n",
      "resetting env. episode 3714, reward total was -20.0. running mean: -19.371968600377787, timestamp: 2022-08-19 07:26:58.040906\n",
      "resetting env. episode 3715, reward total was -16.0. running mean: -19.33824891437401, timestamp: 2022-08-19 07:27:02.693963\n",
      "resetting env. episode 3716, reward total was -19.0. running mean: -19.33486642523027, timestamp: 2022-08-19 07:27:06.731015\n",
      "resetting env. episode 3717, reward total was -18.0. running mean: -19.32151776097797, timestamp: 2022-08-19 07:27:09.972060\n",
      "resetting env. episode 3718, reward total was -16.0. running mean: -19.28830258336819, timestamp: 2022-08-19 07:27:14.242112\n",
      "resetting env. episode 3719, reward total was -21.0. running mean: -19.305419557534506, timestamp: 2022-08-19 07:27:17.448154\n",
      "resetting env. episode 3720, reward total was -21.0. running mean: -19.32236536195916, timestamp: 2022-08-19 07:27:21.462205\n",
      "resetting env. episode 3721, reward total was -19.0. running mean: -19.319141708339572, timestamp: 2022-08-19 07:27:24.701249\n",
      "resetting env. episode 3722, reward total was -20.0. running mean: -19.325950291256177, timestamp: 2022-08-19 07:27:28.107291\n",
      "resetting env. episode 3723, reward total was -20.0. running mean: -19.332690788343616, timestamp: 2022-08-19 07:27:32.337347\n",
      "resetting env. episode 3724, reward total was -20.0. running mean: -19.33936388046018, timestamp: 2022-08-19 07:27:35.877394\n",
      "resetting env. episode 3725, reward total was -21.0. running mean: -19.35597024165558, timestamp: 2022-08-19 07:27:39.808441\n",
      "resetting env. episode 3726, reward total was -20.0. running mean: -19.362410539239022, timestamp: 2022-08-19 07:27:42.817484\n",
      "resetting env. episode 3727, reward total was -21.0. running mean: -19.37878643384663, timestamp: 2022-08-19 07:27:47.196539\n",
      "resetting env. episode 3728, reward total was -19.0. running mean: -19.374998569508165, timestamp: 2022-08-19 07:27:51.395591\n",
      "resetting env. episode 3729, reward total was -18.0. running mean: -19.361248583813083, timestamp: 2022-08-19 07:27:54.918639\n",
      "resetting env. episode 3730, reward total was -19.0. running mean: -19.357636097974954, timestamp: 2022-08-19 07:27:58.577682\n",
      "resetting env. episode 3731, reward total was -21.0. running mean: -19.374059736995203, timestamp: 2022-08-19 07:28:02.649735\n",
      "resetting env. episode 3732, reward total was -20.0. running mean: -19.38031913962525, timestamp: 2022-08-19 07:28:05.844778\n",
      "resetting env. episode 3733, reward total was -19.0. running mean: -19.376515948229, timestamp: 2022-08-19 07:28:08.868814\n",
      "resetting env. episode 3734, reward total was -19.0. running mean: -19.37275078874671, timestamp: 2022-08-19 07:28:12.830865\n",
      "resetting env. episode 3735, reward total was -18.0. running mean: -19.359023280859244, timestamp: 2022-08-19 07:28:16.086907\n",
      "resetting env. episode 3736, reward total was -20.0. running mean: -19.36543304805065, timestamp: 2022-08-19 07:28:18.859943\n",
      "resetting env. episode 3737, reward total was -18.0. running mean: -19.351778717570145, timestamp: 2022-08-19 07:28:23.978011\n",
      "resetting env. episode 3738, reward total was -18.0. running mean: -19.338260930394444, timestamp: 2022-08-19 07:28:27.951061\n",
      "resetting env. episode 3739, reward total was -20.0. running mean: -19.344878321090498, timestamp: 2022-08-19 07:28:31.198103\n",
      "resetting env. episode 3740, reward total was -21.0. running mean: -19.361429537879594, timestamp: 2022-08-19 07:28:33.946138\n",
      "resetting env. episode 3741, reward total was -20.0. running mean: -19.367815242500797, timestamp: 2022-08-19 07:28:38.014407\n",
      "resetting env. episode 3742, reward total was -20.0. running mean: -19.374137090075788, timestamp: 2022-08-19 07:28:41.115443\n",
      "resetting env. episode 3743, reward total was -19.0. running mean: -19.370395719175033, timestamp: 2022-08-19 07:28:43.982480\n",
      "resetting env. episode 3744, reward total was -20.0. running mean: -19.37669176198328, timestamp: 2022-08-19 07:28:47.083522\n",
      "resetting env. episode 3745, reward total was -17.0. running mean: -19.35292484436345, timestamp: 2022-08-19 07:28:51.291572\n",
      "resetting env. episode 3746, reward total was -18.0. running mean: -19.339395595919814, timestamp: 2022-08-19 07:28:54.725616\n",
      "resetting env. episode 3747, reward total was -19.0. running mean: -19.336001639960617, timestamp: 2022-08-19 07:28:58.308665\n",
      "resetting env. episode 3748, reward total was -19.0. running mean: -19.332641623561013, timestamp: 2022-08-19 07:29:02.016879\n",
      "resetting env. episode 3749, reward total was -19.0. running mean: -19.329315207325404, timestamp: 2022-08-19 07:29:06.718941\n",
      "resetting env. episode 3750, reward total was -19.0. running mean: -19.32602205525215, timestamp: 2022-08-19 07:29:10.503989\n",
      "resetting env. episode 3751, reward total was -20.0. running mean: -19.332761834699628, timestamp: 2022-08-19 07:29:14.076036\n",
      "resetting env. episode 3752, reward total was -21.0. running mean: -19.349434216352634, timestamp: 2022-08-19 07:29:16.993072\n",
      "resetting env. episode 3753, reward total was -18.0. running mean: -19.33593987418911, timestamp: 2022-08-19 07:29:20.143115\n",
      "resetting env. episode 3754, reward total was -15.0. running mean: -19.292580475447217, timestamp: 2022-08-19 07:29:24.287161\n",
      "resetting env. episode 3755, reward total was -20.0. running mean: -19.299654670692743, timestamp: 2022-08-19 07:29:27.078197\n",
      "resetting env. episode 3756, reward total was -20.0. running mean: -19.306658123985816, timestamp: 2022-08-19 07:29:30.137239\n",
      "resetting env. episode 3757, reward total was -19.0. running mean: -19.30359154274596, timestamp: 2022-08-19 07:29:33.880287\n",
      "resetting env. episode 3758, reward total was -18.0. running mean: -19.2905556273185, timestamp: 2022-08-19 07:29:37.557331\n",
      "resetting env. episode 3759, reward total was -21.0. running mean: -19.307650071045316, timestamp: 2022-08-19 07:29:40.930374\n",
      "resetting env. episode 3760, reward total was -17.0. running mean: -19.284573570334864, timestamp: 2022-08-19 07:29:45.340429\n",
      "resetting env. episode 3761, reward total was -18.0. running mean: -19.271727834631516, timestamp: 2022-08-19 07:29:49.286482\n",
      "resetting env. episode 3762, reward total was -18.0. running mean: -19.2590105562852, timestamp: 2022-08-19 07:29:52.664523\n",
      "resetting env. episode 3763, reward total was -20.0. running mean: -19.266420450722347, timestamp: 2022-08-19 07:29:55.875562\n",
      "resetting env. episode 3764, reward total was -21.0. running mean: -19.283756246215123, timestamp: 2022-08-19 07:30:00.140618\n",
      "resetting env. episode 3765, reward total was -19.0. running mean: -19.280918683752972, timestamp: 2022-08-19 07:30:03.788664\n",
      "resetting env. episode 3766, reward total was -20.0. running mean: -19.288109496915443, timestamp: 2022-08-19 07:30:06.957705\n",
      "resetting env. episode 3767, reward total was -19.0. running mean: -19.285228401946288, timestamp: 2022-08-19 07:30:10.339749\n",
      "resetting env. episode 3768, reward total was -18.0. running mean: -19.272376117926825, timestamp: 2022-08-19 07:30:14.237800\n",
      "resetting env. episode 3769, reward total was -15.0. running mean: -19.229652356747554, timestamp: 2022-08-19 07:30:18.624852\n",
      "resetting env. episode 3770, reward total was -21.0. running mean: -19.24735583318008, timestamp: 2022-08-19 07:30:21.990897\n",
      "resetting env. episode 3771, reward total was -21.0. running mean: -19.26488227484828, timestamp: 2022-08-19 07:30:24.981935\n",
      "resetting env. episode 3772, reward total was -19.0. running mean: -19.262233452099796, timestamp: 2022-08-19 07:30:28.373976\n",
      "resetting env. episode 3773, reward total was -20.0. running mean: -19.269611117578798, timestamp: 2022-08-19 07:30:31.895019\n",
      "resetting env. episode 3774, reward total was -20.0. running mean: -19.27691500640301, timestamp: 2022-08-19 07:30:35.492066\n",
      "resetting env. episode 3775, reward total was -19.0. running mean: -19.27414585633898, timestamp: 2022-08-19 07:30:38.248098\n",
      "resetting env. episode 3776, reward total was -19.0. running mean: -19.27140439777559, timestamp: 2022-08-19 07:30:42.769158\n",
      "resetting env. episode 3777, reward total was -19.0. running mean: -19.268690353797837, timestamp: 2022-08-19 07:30:46.167517\n",
      "resetting env. episode 3778, reward total was -21.0. running mean: -19.28600345025986, timestamp: 2022-08-19 07:30:48.915551\n",
      "resetting env. episode 3779, reward total was -21.0. running mean: -19.303143415757262, timestamp: 2022-08-19 07:30:52.399592\n",
      "resetting env. episode 3780, reward total was -21.0. running mean: -19.32011198159969, timestamp: 2022-08-19 07:30:55.172626\n",
      "resetting env. episode 3781, reward total was -20.0. running mean: -19.326910861783695, timestamp: 2022-08-19 07:30:58.528671\n",
      "resetting env. episode 3782, reward total was -19.0. running mean: -19.32364175316586, timestamp: 2022-08-19 07:31:02.034287\n",
      "resetting env. episode 3783, reward total was -19.0. running mean: -19.320405335634202, timestamp: 2022-08-19 07:31:05.773331\n",
      "resetting env. episode 3784, reward total was -19.0. running mean: -19.31720128227786, timestamp: 2022-08-19 07:31:09.180380\n",
      "resetting env. episode 3785, reward total was -18.0. running mean: -19.304029269455082, timestamp: 2022-08-19 07:31:12.781420\n",
      "resetting env. episode 3786, reward total was -18.0. running mean: -19.29098897676053, timestamp: 2022-08-19 07:31:17.051471\n",
      "resetting env. episode 3787, reward total was -21.0. running mean: -19.308079086992926, timestamp: 2022-08-19 07:31:19.562503\n",
      "resetting env. episode 3788, reward total was -18.0. running mean: -19.294998296122998, timestamp: 2022-08-19 07:31:24.283562\n",
      "resetting env. episode 3789, reward total was -18.0. running mean: -19.282048313161766, timestamp: 2022-08-19 07:31:28.147614\n",
      "resetting env. episode 3790, reward total was -21.0. running mean: -19.299227830030148, timestamp: 2022-08-19 07:31:31.022651\n",
      "resetting env. episode 3791, reward total was -20.0. running mean: -19.306235551729845, timestamp: 2022-08-19 07:31:34.015687\n",
      "resetting env. episode 3792, reward total was -18.0. running mean: -19.293173196212546, timestamp: 2022-08-19 07:31:37.660730\n",
      "resetting env. episode 3793, reward total was -21.0. running mean: -19.31024146425042, timestamp: 2022-08-19 07:31:41.021774\n",
      "resetting env. episode 3794, reward total was -20.0. running mean: -19.317139049607917, timestamp: 2022-08-19 07:31:44.329812\n",
      "resetting env. episode 3795, reward total was -17.0. running mean: -19.29396765911184, timestamp: 2022-08-19 07:31:48.316862\n",
      "resetting env. episode 3796, reward total was -19.0. running mean: -19.29102798252072, timestamp: 2022-08-19 07:31:51.969910\n",
      "resetting env. episode 3797, reward total was -20.0. running mean: -19.298117702695514, timestamp: 2022-08-19 07:31:56.026958\n",
      "resetting env. episode 3798, reward total was -21.0. running mean: -19.31513652566856, timestamp: 2022-08-19 07:31:58.830996\n",
      "resetting env. episode 3799, reward total was -20.0. running mean: -19.321985160411874, timestamp: 2022-08-19 07:32:02.160035\n",
      "resetting env. episode 3800, reward total was -20.0. running mean: -19.328765308807753, timestamp: 2022-08-19 07:32:06.154084\n",
      "resetting env. episode 3801, reward total was -19.0. running mean: -19.325477655719677, timestamp: 2022-08-19 07:32:09.967130\n",
      "resetting env. episode 3802, reward total was -20.0. running mean: -19.33222287916248, timestamp: 2022-08-19 07:32:12.990173\n",
      "resetting env. episode 3803, reward total was -20.0. running mean: -19.338900650370853, timestamp: 2022-08-19 07:32:15.412199\n",
      "resetting env. episode 3804, reward total was -20.0. running mean: -19.345511643867145, timestamp: 2022-08-19 07:32:18.365236\n",
      "resetting env. episode 3805, reward total was -21.0. running mean: -19.362056527428475, timestamp: 2022-08-19 07:32:22.637811\n",
      "resetting env. episode 3806, reward total was -21.0. running mean: -19.378435962154192, timestamp: 2022-08-19 07:32:25.572846\n",
      "resetting env. episode 3807, reward total was -19.0. running mean: -19.37465160253265, timestamp: 2022-08-19 07:32:28.870886\n",
      "resetting env. episode 3808, reward total was -20.0. running mean: -19.380905086507322, timestamp: 2022-08-19 07:32:32.113930\n",
      "resetting env. episode 3809, reward total was -21.0. running mean: -19.39709603564225, timestamp: 2022-08-19 07:32:35.635972\n",
      "resetting env. episode 3810, reward total was -19.0. running mean: -19.393125075285827, timestamp: 2022-08-19 07:32:39.064014\n",
      "resetting env. episode 3811, reward total was -20.0. running mean: -19.39919382453297, timestamp: 2022-08-19 07:32:42.125050\n",
      "resetting env. episode 3812, reward total was -20.0. running mean: -19.40520188628764, timestamp: 2022-08-19 07:32:45.221091\n",
      "resetting env. episode 3813, reward total was -21.0. running mean: -19.421149867424763, timestamp: 2022-08-19 07:32:48.539130\n",
      "resetting env. episode 3814, reward total was -18.0. running mean: -19.406938368750517, timestamp: 2022-08-19 07:32:52.804183\n",
      "resetting env. episode 3815, reward total was -20.0. running mean: -19.41286898506301, timestamp: 2022-08-19 07:32:55.744221\n",
      "resetting env. episode 3816, reward total was -21.0. running mean: -19.428740295212382, timestamp: 2022-08-19 07:32:59.090263\n",
      "resetting env. episode 3817, reward total was -19.0. running mean: -19.42445289226026, timestamp: 2022-08-19 07:33:02.033295\n",
      "resetting env. episode 3818, reward total was -19.0. running mean: -19.420208363337657, timestamp: 2022-08-19 07:33:05.936344\n",
      "resetting env. episode 3819, reward total was -20.0. running mean: -19.42600627970428, timestamp: 2022-08-19 07:33:08.900380\n",
      "resetting env. episode 3820, reward total was -19.0. running mean: -19.421746216907238, timestamp: 2022-08-19 07:33:12.230418\n",
      "resetting env. episode 3821, reward total was -18.0. running mean: -19.407528754738166, timestamp: 2022-08-19 07:33:16.219467\n",
      "resetting env. episode 3822, reward total was -19.0. running mean: -19.403453467190786, timestamp: 2022-08-19 07:33:19.435507\n",
      "resetting env. episode 3823, reward total was -19.0. running mean: -19.39941893251888, timestamp: 2022-08-19 07:33:22.155544\n",
      "resetting env. episode 3824, reward total was -19.0. running mean: -19.395424743193693, timestamp: 2022-08-19 07:33:25.700585\n",
      "resetting env. episode 3825, reward total was -19.0. running mean: -19.39147049576176, timestamp: 2022-08-19 07:33:30.129642\n",
      "resetting env. episode 3826, reward total was -21.0. running mean: -19.407555790804143, timestamp: 2022-08-19 07:33:34.235688\n",
      "resetting env. episode 3827, reward total was -21.0. running mean: -19.4234802328961, timestamp: 2022-08-19 07:33:36.935722\n",
      "resetting env. episode 3828, reward total was -21.0. running mean: -19.43924543056714, timestamp: 2022-08-19 07:33:40.442764\n",
      "resetting env. episode 3829, reward total was -16.0. running mean: -19.40485297626147, timestamp: 2022-08-19 07:33:44.306810\n",
      "resetting env. episode 3830, reward total was -19.0. running mean: -19.400804446498856, timestamp: 2022-08-19 07:33:48.285858\n",
      "resetting env. episode 3831, reward total was -19.0. running mean: -19.396796402033868, timestamp: 2022-08-19 07:33:51.514899\n",
      "resetting env. episode 3832, reward total was -21.0. running mean: -19.41282843801353, timestamp: 2022-08-19 07:33:54.163934\n",
      "resetting env. episode 3833, reward total was -19.0. running mean: -19.408700153633397, timestamp: 2022-08-19 07:33:57.451971\n",
      "resetting env. episode 3834, reward total was -21.0. running mean: -19.424613152097063, timestamp: 2022-08-19 07:34:00.665011\n",
      "resetting env. episode 3835, reward total was -18.0. running mean: -19.410367020576093, timestamp: 2022-08-19 07:34:03.821063\n",
      "resetting env. episode 3836, reward total was -19.0. running mean: -19.406263350370335, timestamp: 2022-08-19 07:34:07.993114\n",
      "resetting env. episode 3837, reward total was -17.0. running mean: -19.38220071686663, timestamp: 2022-08-19 07:34:11.588156\n",
      "resetting env. episode 3838, reward total was -16.0. running mean: -19.348378709697965, timestamp: 2022-08-19 07:34:15.465203\n",
      "resetting env. episode 3839, reward total was -19.0. running mean: -19.344894922600986, timestamp: 2022-08-19 07:34:18.687241\n",
      "resetting env. episode 3840, reward total was -19.0. running mean: -19.341445973374977, timestamp: 2022-08-19 07:34:23.094294\n",
      "resetting env. episode 3841, reward total was -21.0. running mean: -19.35803151364123, timestamp: 2022-08-19 07:34:25.813331\n",
      "resetting env. episode 3842, reward total was -18.0. running mean: -19.344451198504817, timestamp: 2022-08-19 07:34:29.707377\n",
      "resetting env. episode 3843, reward total was -21.0. running mean: -19.36100668651977, timestamp: 2022-08-19 07:34:32.229406\n",
      "resetting env. episode 3844, reward total was -19.0. running mean: -19.357396619654573, timestamp: 2022-08-19 07:34:34.893442\n",
      "resetting env. episode 3845, reward total was -19.0. running mean: -19.353822653458028, timestamp: 2022-08-19 07:34:38.197480\n",
      "resetting env. episode 3846, reward total was -15.0. running mean: -19.310284426923445, timestamp: 2022-08-19 07:34:42.429532\n",
      "resetting env. episode 3847, reward total was -19.0. running mean: -19.307181582654213, timestamp: 2022-08-19 07:34:46.084575\n",
      "resetting env. episode 3848, reward total was -19.0. running mean: -19.304109766827672, timestamp: 2022-08-19 07:34:49.449621\n",
      "resetting env. episode 3849, reward total was -20.0. running mean: -19.311068669159393, timestamp: 2022-08-19 07:34:52.909658\n",
      "resetting env. episode 3850, reward total was -19.0. running mean: -19.3079579824678, timestamp: 2022-08-19 07:34:56.539702\n",
      "resetting env. episode 3851, reward total was -17.0. running mean: -19.284878402643123, timestamp: 2022-08-19 07:35:00.654754\n",
      "resetting env. episode 3852, reward total was -21.0. running mean: -19.302029618616693, timestamp: 2022-08-19 07:35:03.906796\n",
      "resetting env. episode 3853, reward total was -21.0. running mean: -19.319009322430528, timestamp: 2022-08-19 07:35:07.886842\n",
      "resetting env. episode 3854, reward total was -19.0. running mean: -19.315819229206223, timestamp: 2022-08-19 07:35:11.141884\n",
      "resetting env. episode 3855, reward total was -21.0. running mean: -19.33266103691416, timestamp: 2022-08-19 07:35:14.397923\n",
      "resetting env. episode 3856, reward total was -20.0. running mean: -19.33933442654502, timestamp: 2022-08-19 07:35:17.033958\n",
      "resetting env. episode 3857, reward total was -21.0. running mean: -19.355941082279568, timestamp: 2022-08-19 07:35:20.339999\n",
      "resetting env. episode 3858, reward total was -17.0. running mean: -19.332381671456773, timestamp: 2022-08-19 07:35:24.146045\n",
      "resetting env. episode 3859, reward total was -21.0. running mean: -19.349057854742206, timestamp: 2022-08-19 07:35:26.441071\n",
      "resetting env. episode 3860, reward total was -21.0. running mean: -19.365567276194785, timestamp: 2022-08-19 07:35:29.715116\n",
      "resetting env. episode 3861, reward total was -21.0. running mean: -19.381911603432837, timestamp: 2022-08-19 07:35:33.395158\n",
      "resetting env. episode 3862, reward total was -21.0. running mean: -19.398092487398507, timestamp: 2022-08-19 07:35:36.726203\n",
      "resetting env. episode 3863, reward total was -19.0. running mean: -19.39411156252452, timestamp: 2022-08-19 07:35:40.012243\n",
      "resetting env. episode 3864, reward total was -20.0. running mean: -19.400170446899274, timestamp: 2022-08-19 07:35:43.233278\n",
      "resetting env. episode 3865, reward total was -20.0. running mean: -19.406168742430282, timestamp: 2022-08-19 07:35:46.904324\n",
      "resetting env. episode 3866, reward total was -21.0. running mean: -19.42210705500598, timestamp: 2022-08-19 07:35:50.543370\n",
      "resetting env. episode 3867, reward total was -19.0. running mean: -19.41788598445592, timestamp: 2022-08-19 07:35:53.656413\n",
      "resetting env. episode 3868, reward total was -21.0. running mean: -19.433707124611363, timestamp: 2022-08-19 07:35:57.531458\n",
      "resetting env. episode 3869, reward total was -21.0. running mean: -19.44937005336525, timestamp: 2022-08-19 07:36:01.256508\n",
      "resetting env. episode 3870, reward total was -19.0. running mean: -19.4448763528316, timestamp: 2022-08-19 07:36:05.399557\n",
      "resetting env. episode 3871, reward total was -21.0. running mean: -19.460427589303283, timestamp: 2022-08-19 07:36:08.221594\n",
      "resetting env. episode 3872, reward total was -20.0. running mean: -19.465823313410247, timestamp: 2022-08-19 07:36:11.909643\n",
      "resetting env. episode 3873, reward total was -17.0. running mean: -19.441165080276146, timestamp: 2022-08-19 07:36:16.578698\n",
      "resetting env. episode 3874, reward total was -20.0. running mean: -19.446753429473382, timestamp: 2022-08-19 07:36:19.955742\n",
      "resetting env. episode 3875, reward total was -21.0. running mean: -19.46228589517865, timestamp: 2022-08-19 07:36:23.197780\n",
      "resetting env. episode 3876, reward total was -20.0. running mean: -19.467663036226863, timestamp: 2022-08-19 07:36:26.569824\n",
      "resetting env. episode 3877, reward total was -21.0. running mean: -19.482986405864594, timestamp: 2022-08-19 07:36:29.952869\n",
      "resetting env. episode 3878, reward total was -19.0. running mean: -19.478156541805948, timestamp: 2022-08-19 07:36:33.459911\n",
      "resetting env. episode 3879, reward total was -21.0. running mean: -19.49337497638789, timestamp: 2022-08-19 07:36:37.120964\n",
      "resetting env. episode 3880, reward total was -16.0. running mean: -19.45844122662401, timestamp: 2022-08-19 07:36:40.742003\n",
      "resetting env. episode 3881, reward total was -20.0. running mean: -19.46385681435777, timestamp: 2022-08-19 07:36:44.005048\n",
      "resetting env. episode 3882, reward total was -18.0. running mean: -19.44921824621419, timestamp: 2022-08-19 07:36:47.774091\n",
      "resetting env. episode 3883, reward total was -21.0. running mean: -19.46472606375205, timestamp: 2022-08-19 07:36:50.649042\n",
      "resetting env. episode 3884, reward total was -16.0. running mean: -19.43007880311453, timestamp: 2022-08-19 07:36:55.204100\n",
      "resetting env. episode 3885, reward total was -18.0. running mean: -19.415778015083383, timestamp: 2022-08-19 07:36:59.436773\n",
      "resetting env. episode 3886, reward total was -20.0. running mean: -19.421620234932547, timestamp: 2022-08-19 07:37:03.307823\n",
      "resetting env. episode 3887, reward total was -19.0. running mean: -19.417404032583224, timestamp: 2022-08-19 07:37:06.973871\n",
      "resetting env. episode 3888, reward total was -20.0. running mean: -19.42322999225739, timestamp: 2022-08-19 07:37:10.489914\n",
      "resetting env. episode 3889, reward total was -21.0. running mean: -19.438997692334816, timestamp: 2022-08-19 07:37:13.787957\n",
      "resetting env. episode 3890, reward total was -21.0. running mean: -19.45460771541147, timestamp: 2022-08-19 07:37:17.358002\n",
      "resetting env. episode 3891, reward total was -20.0. running mean: -19.460061638257354, timestamp: 2022-08-19 07:37:20.385041\n",
      "resetting env. episode 3892, reward total was -20.0. running mean: -19.46546102187478, timestamp: 2022-08-19 07:37:23.929089\n",
      "resetting env. episode 3893, reward total was -20.0. running mean: -19.47080641165603, timestamp: 2022-08-19 07:37:27.290131\n",
      "resetting env. episode 3894, reward total was -21.0. running mean: -19.48609834753947, timestamp: 2022-08-19 07:37:30.119619\n",
      "resetting env. episode 3895, reward total was -20.0. running mean: -19.491237364064077, timestamp: 2022-08-19 07:37:34.503672\n",
      "resetting env. episode 3896, reward total was -18.0. running mean: -19.476324990423436, timestamp: 2022-08-19 07:37:38.312722\n",
      "resetting env. episode 3897, reward total was -21.0. running mean: -19.491561740519202, timestamp: 2022-08-19 07:37:41.272762\n",
      "resetting env. episode 3898, reward total was -20.0. running mean: -19.496646123114008, timestamp: 2022-08-19 07:37:44.701803\n",
      "resetting env. episode 3899, reward total was -18.0. running mean: -19.48167966188287, timestamp: 2022-08-19 07:37:48.354851\n",
      "resetting env. episode 3900, reward total was -20.0. running mean: -19.48686286526404, timestamp: 2022-08-19 07:37:50.952886\n",
      "resetting env. episode 3901, reward total was -18.0. running mean: -19.4719942366114, timestamp: 2022-08-19 07:37:54.989941\n",
      "resetting env. episode 3902, reward total was -19.0. running mean: -19.46727429424529, timestamp: 2022-08-19 07:37:58.874985\n",
      "resetting env. episode 3903, reward total was -18.0. running mean: -19.452601551302838, timestamp: 2022-08-19 07:38:02.793038\n",
      "resetting env. episode 3904, reward total was -20.0. running mean: -19.45807553578981, timestamp: 2022-08-19 07:38:06.128083\n",
      "resetting env. episode 3905, reward total was -17.0. running mean: -19.433494780431914, timestamp: 2022-08-19 07:38:09.638127\n",
      "resetting env. episode 3906, reward total was -19.0. running mean: -19.429159832627597, timestamp: 2022-08-19 07:38:13.725179\n",
      "resetting env. episode 3907, reward total was -21.0. running mean: -19.44486823430132, timestamp: 2022-08-19 07:38:17.287228\n",
      "resetting env. episode 3908, reward total was -17.0. running mean: -19.42041955195831, timestamp: 2022-08-19 07:38:20.737273\n",
      "resetting env. episode 3909, reward total was -19.0. running mean: -19.41621535643873, timestamp: 2022-08-19 07:38:24.539319\n",
      "resetting env. episode 3910, reward total was -21.0. running mean: -19.432053202874343, timestamp: 2022-08-19 07:38:27.846366\n",
      "resetting env. episode 3911, reward total was -19.0. running mean: -19.4277326708456, timestamp: 2022-08-19 07:38:32.296420\n",
      "resetting env. episode 3912, reward total was -19.0. running mean: -19.423455344137146, timestamp: 2022-08-19 07:38:36.835480\n",
      "resetting env. episode 3913, reward total was -21.0. running mean: -19.439220790695774, timestamp: 2022-08-19 07:38:40.696532\n",
      "resetting env. episode 3914, reward total was -17.0. running mean: -19.414828582788818, timestamp: 2022-08-19 07:38:44.965591\n",
      "resetting env. episode 3915, reward total was -19.0. running mean: -19.41068029696093, timestamp: 2022-08-19 07:38:48.559635\n",
      "resetting env. episode 3916, reward total was -20.0. running mean: -19.41657349399132, timestamp: 2022-08-19 07:38:51.396672\n",
      "resetting env. episode 3917, reward total was -19.0. running mean: -19.412407759051405, timestamp: 2022-08-19 07:38:55.026719\n",
      "resetting env. episode 3918, reward total was -20.0. running mean: -19.41828368146089, timestamp: 2022-08-19 07:38:58.963770\n",
      "resetting env. episode 3919, reward total was -19.0. running mean: -19.41410084464628, timestamp: 2022-08-19 07:39:02.310817\n",
      "resetting env. episode 3920, reward total was -14.0. running mean: -19.35995983619982, timestamp: 2022-08-19 07:39:07.280878\n",
      "resetting env. episode 3921, reward total was -20.0. running mean: -19.36636023783782, timestamp: 2022-08-19 07:39:10.307919\n",
      "resetting env. episode 3922, reward total was -19.0. running mean: -19.362696635459443, timestamp: 2022-08-19 07:39:13.813107\n",
      "resetting env. episode 3923, reward total was -21.0. running mean: -19.37906966910485, timestamp: 2022-08-19 07:39:17.830156\n",
      "resetting env. episode 3924, reward total was -19.0. running mean: -19.375278972413803, timestamp: 2022-08-19 07:39:22.017217\n",
      "resetting env. episode 3925, reward total was -21.0. running mean: -19.391526182689667, timestamp: 2022-08-19 07:39:25.660257\n",
      "resetting env. episode 3926, reward total was -20.0. running mean: -19.397610920862768, timestamp: 2022-08-19 07:39:29.009237\n",
      "resetting env. episode 3927, reward total was -20.0. running mean: -19.40363481165414, timestamp: 2022-08-19 07:39:31.914278\n",
      "resetting env. episode 3928, reward total was -21.0. running mean: -19.4195984635376, timestamp: 2022-08-19 07:39:35.193327\n",
      "resetting env. episode 3929, reward total was -21.0. running mean: -19.435402478902226, timestamp: 2022-08-19 07:39:38.262367\n",
      "resetting env. episode 3930, reward total was -18.0. running mean: -19.421048454113205, timestamp: 2022-08-19 07:39:42.584420\n",
      "resetting env. episode 3931, reward total was -18.0. running mean: -19.406837969572074, timestamp: 2022-08-19 07:39:46.717476\n",
      "resetting env. episode 3932, reward total was -20.0. running mean: -19.41276958987635, timestamp: 2022-08-19 07:39:50.354526\n",
      "resetting env. episode 3933, reward total was -18.0. running mean: -19.398641893977587, timestamp: 2022-08-19 07:39:54.055573\n",
      "resetting env. episode 3934, reward total was -20.0. running mean: -19.40465547503781, timestamp: 2022-08-19 07:39:57.630619\n",
      "resetting env. episode 3935, reward total was -20.0. running mean: -19.41060892028743, timestamp: 2022-08-19 07:40:02.233677\n",
      "resetting env. episode 3936, reward total was -19.0. running mean: -19.406502831084556, timestamp: 2022-08-19 07:40:05.680725\n",
      "resetting env. episode 3937, reward total was -19.0. running mean: -19.40243780277371, timestamp: 2022-08-19 07:40:09.812777\n",
      "resetting env. episode 3938, reward total was -21.0. running mean: -19.418413424745975, timestamp: 2022-08-19 07:40:13.497828\n",
      "resetting env. episode 3939, reward total was -18.0. running mean: -19.404229290498513, timestamp: 2022-08-19 07:40:17.156877\n",
      "resetting env. episode 3940, reward total was -19.0. running mean: -19.40018699759353, timestamp: 2022-08-19 07:40:20.651921\n",
      "resetting env. episode 3941, reward total was -20.0. running mean: -19.406185127617594, timestamp: 2022-08-19 07:40:24.414969\n",
      "resetting env. episode 3942, reward total was -20.0. running mean: -19.41212327634142, timestamp: 2022-08-19 07:40:27.978016\n",
      "resetting env. episode 3943, reward total was -19.0. running mean: -19.408002043578005, timestamp: 2022-08-19 07:40:32.202075\n",
      "resetting env. episode 3944, reward total was -20.0. running mean: -19.413922023142224, timestamp: 2022-08-19 07:40:35.253114\n",
      "resetting env. episode 3945, reward total was -20.0. running mean: -19.4197828029108, timestamp: 2022-08-19 07:40:38.780158\n",
      "resetting env. episode 3946, reward total was -21.0. running mean: -19.435584974881692, timestamp: 2022-08-19 07:40:42.056199\n",
      "resetting env. episode 3947, reward total was -19.0. running mean: -19.431229125132877, timestamp: 2022-08-19 07:40:45.981256\n",
      "resetting env. episode 3948, reward total was -20.0. running mean: -19.436916833881547, timestamp: 2022-08-19 07:40:50.391310\n",
      "resetting env. episode 3949, reward total was -19.0. running mean: -19.43254766554273, timestamp: 2022-08-19 07:40:54.944368\n",
      "resetting env. episode 3950, reward total was -17.0. running mean: -19.408222188887304, timestamp: 2022-08-19 07:40:59.760431\n",
      "resetting env. episode 3951, reward total was -20.0. running mean: -19.41413996699843, timestamp: 2022-08-19 07:41:02.784471\n",
      "resetting env. episode 3952, reward total was -20.0. running mean: -19.419998567328445, timestamp: 2022-08-19 07:41:06.659523\n",
      "resetting env. episode 3953, reward total was -17.0. running mean: -19.39579858165516, timestamp: 2022-08-19 07:41:10.822578\n",
      "resetting env. episode 3954, reward total was -19.0. running mean: -19.39184059583861, timestamp: 2022-08-19 07:41:14.173624\n",
      "resetting env. episode 3955, reward total was -20.0. running mean: -19.397922189880223, timestamp: 2022-08-19 07:41:17.725669\n",
      "resetting env. episode 3956, reward total was -20.0. running mean: -19.40394296798142, timestamp: 2022-08-19 07:41:20.694705\n",
      "resetting env. episode 3957, reward total was -19.0. running mean: -19.399903538301604, timestamp: 2022-08-19 07:41:23.932748\n",
      "resetting env. episode 3958, reward total was -19.0. running mean: -19.39590450291859, timestamp: 2022-08-19 07:41:27.005793\n",
      "resetting env. episode 3959, reward total was -19.0. running mean: -19.391945457889406, timestamp: 2022-08-19 07:41:29.954828\n",
      "resetting env. episode 3960, reward total was -16.0. running mean: -19.358026003310513, timestamp: 2022-08-19 07:41:34.272887\n",
      "resetting env. episode 3961, reward total was -19.0. running mean: -19.35444574327741, timestamp: 2022-08-19 07:41:37.689929\n",
      "resetting env. episode 3962, reward total was -19.0. running mean: -19.350901285844635, timestamp: 2022-08-19 07:41:40.866970\n",
      "resetting env. episode 3963, reward total was -20.0. running mean: -19.35739227298619, timestamp: 2022-08-19 07:41:45.438031\n",
      "resetting env. episode 3964, reward total was -20.0. running mean: -19.363818350256327, timestamp: 2022-08-19 07:41:48.403070\n",
      "resetting env. episode 3965, reward total was -21.0. running mean: -19.380180166753764, timestamp: 2022-08-19 07:41:52.107117\n",
      "resetting env. episode 3966, reward total was -20.0. running mean: -19.386378365086227, timestamp: 2022-08-19 07:41:55.261161\n",
      "resetting env. episode 3967, reward total was -20.0. running mean: -19.392514581435364, timestamp: 2022-08-19 07:41:59.495215\n",
      "resetting env. episode 3968, reward total was -21.0. running mean: -19.40858943562101, timestamp: 2022-08-19 07:42:03.518267\n",
      "resetting env. episode 3969, reward total was -20.0. running mean: -19.4145035412648, timestamp: 2022-08-19 07:42:07.709322\n",
      "resetting env. episode 3970, reward total was -18.0. running mean: -19.40035850585215, timestamp: 2022-08-19 07:42:11.770376\n",
      "resetting env. episode 3971, reward total was -21.0. running mean: -19.41635492079363, timestamp: 2022-08-19 07:42:14.517412\n",
      "resetting env. episode 3972, reward total was -21.0. running mean: -19.432191371585695, timestamp: 2022-08-19 07:42:17.712453\n",
      "resetting env. episode 3973, reward total was -20.0. running mean: -19.437869457869837, timestamp: 2022-08-19 07:42:21.768510\n",
      "resetting env. episode 3974, reward total was -21.0. running mean: -19.45349076329114, timestamp: 2022-08-19 07:42:25.096554\n",
      "resetting env. episode 3975, reward total was -17.0. running mean: -19.42895585565823, timestamp: 2022-08-19 07:42:28.702597\n",
      "resetting env. episode 3976, reward total was -19.0. running mean: -19.42466629710165, timestamp: 2022-08-19 07:42:32.215649\n",
      "resetting env. episode 3977, reward total was -20.0. running mean: -19.43041963413063, timestamp: 2022-08-19 07:42:35.511685\n",
      "resetting env. episode 3978, reward total was -20.0. running mean: -19.436115437789322, timestamp: 2022-08-19 07:42:39.427739\n",
      "resetting env. episode 3979, reward total was -18.0. running mean: -19.421754283411428, timestamp: 2022-08-19 07:42:44.411804\n",
      "resetting env. episode 3980, reward total was -21.0. running mean: -19.437536740577315, timestamp: 2022-08-19 07:42:47.768846\n",
      "resetting env. episode 3981, reward total was -18.0. running mean: -19.423161373171542, timestamp: 2022-08-19 07:42:51.614897\n",
      "resetting env. episode 3982, reward total was -20.0. running mean: -19.428929759439825, timestamp: 2022-08-19 07:42:54.819942\n",
      "resetting env. episode 3983, reward total was -17.0. running mean: -19.40464046184543, timestamp: 2022-08-19 07:42:58.602989\n",
      "resetting env. episode 3984, reward total was -21.0. running mean: -19.420594057226975, timestamp: 2022-08-19 07:43:01.463676\n",
      "resetting env. episode 3985, reward total was -19.0. running mean: -19.416388116654705, timestamp: 2022-08-19 07:43:05.490730\n",
      "resetting env. episode 3986, reward total was -20.0. running mean: -19.42222423548816, timestamp: 2022-08-19 07:43:08.612768\n",
      "resetting env. episode 3987, reward total was -20.0. running mean: -19.428001993133275, timestamp: 2022-08-19 07:43:12.343818\n",
      "resetting env. episode 3988, reward total was -17.0. running mean: -19.403721973201943, timestamp: 2022-08-19 07:43:16.278869\n",
      "resetting env. episode 3989, reward total was -20.0. running mean: -19.40968475346992, timestamp: 2022-08-19 07:43:19.845917\n",
      "resetting env. episode 3990, reward total was -18.0. running mean: -19.395587905935223, timestamp: 2022-08-19 07:43:23.005958\n",
      "resetting env. episode 3991, reward total was -19.0. running mean: -19.39163202687587, timestamp: 2022-08-19 07:43:27.160017\n",
      "resetting env. episode 3992, reward total was -20.0. running mean: -19.397715706607112, timestamp: 2022-08-19 07:43:30.257057\n",
      "resetting env. episode 3993, reward total was -19.0. running mean: -19.39373854954104, timestamp: 2022-08-19 07:43:34.199104\n",
      "resetting env. episode 3994, reward total was -19.0. running mean: -19.389801164045632, timestamp: 2022-08-19 07:43:38.050159\n",
      "resetting env. episode 3995, reward total was -19.0. running mean: -19.385903152405177, timestamp: 2022-08-19 07:43:41.763203\n",
      "resetting env. episode 3996, reward total was -20.0. running mean: -19.392044120881124, timestamp: 2022-08-19 07:43:45.070246\n",
      "resetting env. episode 3997, reward total was -21.0. running mean: -19.408123679672315, timestamp: 2022-08-19 07:43:48.799297\n",
      "resetting env. episode 3998, reward total was -20.0. running mean: -19.41404244287559, timestamp: 2022-08-19 07:43:52.447343\n",
      "resetting env. episode 3999, reward total was -20.0. running mean: -19.419902018446834, timestamp: 2022-08-19 07:43:56.918402\n",
      "resetting env. episode 4000, reward total was -19.0. running mean: -19.41570299826237, timestamp: 2022-08-19 07:44:00.777451\n",
      "resetting env. episode 4001, reward total was -20.0. running mean: -19.421545968279744, timestamp: 2022-08-19 07:44:04.072492\n",
      "resetting env. episode 4002, reward total was -19.0. running mean: -19.417330508596947, timestamp: 2022-08-19 07:44:08.140545\n",
      "resetting env. episode 4003, reward total was -21.0. running mean: -19.43315720351098, timestamp: 2022-08-19 07:44:12.232599\n",
      "resetting env. episode 4004, reward total was -18.0. running mean: -19.41882563147587, timestamp: 2022-08-19 07:44:16.208650\n",
      "resetting env. episode 4005, reward total was -20.0. running mean: -19.424637375161108, timestamp: 2022-08-19 07:44:20.120701\n",
      "resetting env. episode 4006, reward total was -20.0. running mean: -19.430391001409497, timestamp: 2022-08-19 07:44:24.014752\n",
      "resetting env. episode 4007, reward total was -20.0. running mean: -19.4360870913954, timestamp: 2022-08-19 07:44:27.728804\n",
      "resetting env. episode 4008, reward total was -17.0. running mean: -19.411726220481448, timestamp: 2022-08-19 07:44:31.954859\n",
      "resetting env. episode 4009, reward total was -20.0. running mean: -19.41760895827663, timestamp: 2022-08-19 07:44:35.033900\n",
      "resetting env. episode 4010, reward total was -16.0. running mean: -19.383432868693866, timestamp: 2022-08-19 07:44:40.008960\n",
      "resetting env. episode 4011, reward total was -19.0. running mean: -19.379598540006928, timestamp: 2022-08-19 07:44:43.334002\n",
      "resetting env. episode 4012, reward total was -18.0. running mean: -19.36580255460686, timestamp: 2022-08-19 07:44:48.546072\n",
      "resetting env. episode 4013, reward total was -19.0. running mean: -19.362144529060792, timestamp: 2022-08-19 07:44:52.611123\n",
      "resetting env. episode 4014, reward total was -20.0. running mean: -19.368523083770185, timestamp: 2022-08-19 07:44:56.726176\n",
      "resetting env. episode 4015, reward total was -21.0. running mean: -19.384837852932485, timestamp: 2022-08-19 07:45:00.729228\n",
      "resetting env. episode 4016, reward total was -19.0. running mean: -19.38098947440316, timestamp: 2022-08-19 07:45:04.525277\n",
      "resetting env. episode 4017, reward total was -20.0. running mean: -19.38717957965913, timestamp: 2022-08-19 07:45:08.600330\n",
      "resetting env. episode 4018, reward total was -19.0. running mean: -19.383307783862538, timestamp: 2022-08-19 07:45:12.336381\n",
      "resetting env. episode 4019, reward total was -19.0. running mean: -19.379474706023913, timestamp: 2022-08-19 07:45:16.265429\n",
      "resetting env. episode 4020, reward total was -21.0. running mean: -19.395679958963676, timestamp: 2022-08-19 07:45:19.844473\n",
      "resetting env. episode 4021, reward total was -21.0. running mean: -19.41172315937404, timestamp: 2022-08-19 07:45:23.776528\n",
      "resetting env. episode 4022, reward total was -19.0. running mean: -19.407605927780303, timestamp: 2022-08-19 07:45:27.125567\n",
      "resetting env. episode 4023, reward total was -17.0. running mean: -19.3835298685025, timestamp: 2022-08-19 07:45:31.489625\n",
      "resetting env. episode 4024, reward total was -17.0. running mean: -19.359694569817474, timestamp: 2022-08-19 07:45:35.684679\n",
      "resetting env. episode 4025, reward total was -20.0. running mean: -19.3660976241193, timestamp: 2022-08-19 07:45:38.819722\n",
      "resetting env. episode 4026, reward total was -19.0. running mean: -19.362436647878106, timestamp: 2022-08-19 07:45:42.971302\n",
      "resetting env. episode 4027, reward total was -20.0. running mean: -19.368812281399325, timestamp: 2022-08-19 07:45:46.425343\n",
      "resetting env. episode 4028, reward total was -21.0. running mean: -19.385124158585334, timestamp: 2022-08-19 07:45:50.607400\n",
      "resetting env. episode 4029, reward total was -18.0. running mean: -19.37127291699948, timestamp: 2022-08-19 07:45:54.920453\n",
      "resetting env. episode 4030, reward total was -19.0. running mean: -19.367560187829486, timestamp: 2022-08-19 07:45:58.231496\n",
      "resetting env. episode 4031, reward total was -18.0. running mean: -19.353884585951192, timestamp: 2022-08-19 07:46:01.338535\n",
      "resetting env. episode 4032, reward total was -18.0. running mean: -19.34034574009168, timestamp: 2022-08-19 07:46:05.062585\n",
      "resetting env. episode 4033, reward total was -20.0. running mean: -19.346942282690765, timestamp: 2022-08-19 07:46:07.939624\n",
      "resetting env. episode 4034, reward total was -19.0. running mean: -19.34347285986386, timestamp: 2022-08-19 07:46:11.978671\n",
      "resetting env. episode 4035, reward total was -20.0. running mean: -19.35003813126522, timestamp: 2022-08-19 07:46:16.021724\n",
      "resetting env. episode 4036, reward total was -18.0. running mean: -19.336537749952566, timestamp: 2022-08-19 07:46:19.485766\n",
      "resetting env. episode 4037, reward total was -21.0. running mean: -19.35317237245304, timestamp: 2022-08-19 07:46:22.659815\n",
      "resetting env. episode 4038, reward total was -21.0. running mean: -19.369640648728513, timestamp: 2022-08-19 07:46:25.722850\n",
      "resetting env. episode 4039, reward total was -20.0. running mean: -19.37594424224123, timestamp: 2022-08-19 07:46:28.907887\n",
      "resetting env. episode 4040, reward total was -19.0. running mean: -19.372184799818818, timestamp: 2022-08-19 07:46:31.965927\n",
      "resetting env. episode 4041, reward total was -19.0. running mean: -19.368462951820632, timestamp: 2022-08-19 07:46:34.653960\n",
      "resetting env. episode 4042, reward total was -21.0. running mean: -19.384778322302427, timestamp: 2022-08-19 07:46:38.070007\n",
      "resetting env. episode 4043, reward total was -19.0. running mean: -19.380930539079404, timestamp: 2022-08-19 07:46:41.689051\n",
      "resetting env. episode 4044, reward total was -19.0. running mean: -19.377121233688612, timestamp: 2022-08-19 07:46:45.061098\n",
      "resetting env. episode 4045, reward total was -21.0. running mean: -19.393350021351726, timestamp: 2022-08-19 07:46:48.603138\n",
      "resetting env. episode 4046, reward total was -16.0. running mean: -19.359416521138208, timestamp: 2022-08-19 07:46:52.874191\n",
      "resetting env. episode 4047, reward total was -19.0. running mean: -19.355822355926826, timestamp: 2022-08-19 07:46:56.134236\n",
      "resetting env. episode 4048, reward total was -15.0. running mean: -19.312264132367556, timestamp: 2022-08-19 07:47:00.138285\n",
      "resetting env. episode 4049, reward total was -18.0. running mean: -19.29914149104388, timestamp: 2022-08-19 07:47:04.920348\n",
      "resetting env. episode 4050, reward total was -20.0. running mean: -19.30615007613344, timestamp: 2022-08-19 07:47:08.078384\n",
      "resetting env. episode 4051, reward total was -21.0. running mean: -19.323088575372108, timestamp: 2022-08-19 07:47:13.004451\n",
      "resetting env. episode 4052, reward total was -18.0. running mean: -19.309857689618386, timestamp: 2022-08-19 07:47:17.565509\n",
      "resetting env. episode 4053, reward total was -19.0. running mean: -19.306759112722204, timestamp: 2022-08-19 07:47:20.969552\n",
      "resetting env. episode 4054, reward total was -16.0. running mean: -19.273691521594984, timestamp: 2022-08-19 07:47:24.728597\n",
      "resetting env. episode 4055, reward total was -17.0. running mean: -19.250954606379036, timestamp: 2022-08-19 07:47:29.638659\n",
      "resetting env. episode 4056, reward total was -18.0. running mean: -19.238445060315247, timestamp: 2022-08-19 07:47:34.029714\n",
      "resetting env. episode 4057, reward total was -20.0. running mean: -19.246060609712092, timestamp: 2022-08-19 07:47:37.555760\n",
      "resetting env. episode 4058, reward total was -20.0. running mean: -19.25360000361497, timestamp: 2022-08-19 07:47:40.948807\n",
      "resetting env. episode 4059, reward total was -18.0. running mean: -19.24106400357882, timestamp: 2022-08-19 07:47:44.099842\n",
      "resetting env. episode 4060, reward total was -17.0. running mean: -19.218653363543034, timestamp: 2022-08-19 07:47:47.936890\n",
      "resetting env. episode 4061, reward total was -21.0. running mean: -19.236466829907602, timestamp: 2022-08-19 07:47:51.281933\n",
      "resetting env. episode 4062, reward total was -17.0. running mean: -19.214102161608526, timestamp: 2022-08-19 07:47:56.526550\n",
      "resetting env. episode 4063, reward total was -19.0. running mean: -19.211961139992443, timestamp: 2022-08-19 07:48:00.393601\n",
      "resetting env. episode 4064, reward total was -19.0. running mean: -19.20984152859252, timestamp: 2022-08-19 07:48:03.596641\n",
      "resetting env. episode 4065, reward total was -18.0. running mean: -19.197743113306593, timestamp: 2022-08-19 07:48:06.437677\n",
      "resetting env. episode 4066, reward total was -18.0. running mean: -19.18576568217353, timestamp: 2022-08-19 07:48:09.489716\n",
      "resetting env. episode 4067, reward total was -21.0. running mean: -19.203908025351794, timestamp: 2022-08-19 07:48:12.999758\n",
      "resetting env. episode 4068, reward total was -16.0. running mean: -19.171868945098275, timestamp: 2022-08-19 07:48:16.872816\n",
      "resetting env. episode 4069, reward total was -21.0. running mean: -19.190150255647293, timestamp: 2022-08-19 07:48:20.733857\n",
      "resetting env. episode 4070, reward total was -18.0. running mean: -19.17824875309082, timestamp: 2022-08-19 07:48:24.340900\n",
      "resetting env. episode 4071, reward total was -21.0. running mean: -19.196466265559913, timestamp: 2022-08-19 07:48:27.916946\n",
      "resetting env. episode 4072, reward total was -20.0. running mean: -19.204501602904312, timestamp: 2022-08-19 07:48:31.702995\n",
      "resetting env. episode 4073, reward total was -19.0. running mean: -19.202456586875268, timestamp: 2022-08-19 07:48:35.243039\n",
      "resetting env. episode 4074, reward total was -15.0. running mean: -19.160432021006514, timestamp: 2022-08-19 07:48:39.173095\n",
      "resetting env. episode 4075, reward total was -20.0. running mean: -19.16882770079645, timestamp: 2022-08-19 07:48:41.561119\n",
      "resetting env. episode 4076, reward total was -19.0. running mean: -19.167139423788484, timestamp: 2022-08-19 07:48:46.033175\n",
      "resetting env. episode 4077, reward total was -19.0. running mean: -19.1654680295506, timestamp: 2022-08-19 07:48:49.391219\n",
      "resetting env. episode 4078, reward total was -19.0. running mean: -19.163813349255093, timestamp: 2022-08-19 07:48:53.083264\n",
      "resetting env. episode 4079, reward total was -20.0. running mean: -19.172175215762543, timestamp: 2022-08-19 07:48:55.996304\n",
      "resetting env. episode 4080, reward total was -19.0. running mean: -19.170453463604918, timestamp: 2022-08-19 07:48:58.930341\n",
      "resetting env. episode 4081, reward total was -21.0. running mean: -19.18874892896887, timestamp: 2022-08-19 07:49:02.697384\n",
      "resetting env. episode 4082, reward total was -20.0. running mean: -19.196861439679182, timestamp: 2022-08-19 07:49:06.734435\n",
      "resetting env. episode 4083, reward total was -19.0. running mean: -19.19489282528239, timestamp: 2022-08-19 07:49:09.878477\n",
      "resetting env. episode 4084, reward total was -20.0. running mean: -19.202943897029567, timestamp: 2022-08-19 07:49:13.105514\n",
      "resetting env. episode 4085, reward total was -19.0. running mean: -19.200914458059273, timestamp: 2022-08-19 07:49:16.596558\n",
      "resetting env. episode 4086, reward total was -17.0. running mean: -19.178905313478683, timestamp: 2022-08-19 07:49:19.689599\n",
      "resetting env. episode 4087, reward total was -19.0. running mean: -19.177116260343897, timestamp: 2022-08-19 07:49:22.911640\n",
      "resetting env. episode 4088, reward total was -16.0. running mean: -19.14534509774046, timestamp: 2022-08-19 07:49:28.076701\n",
      "resetting env. episode 4089, reward total was -20.0. running mean: -19.153891646763054, timestamp: 2022-08-19 07:49:32.417755\n",
      "resetting env. episode 4090, reward total was -17.0. running mean: -19.132352730295423, timestamp: 2022-08-19 07:49:36.408806\n",
      "resetting env. episode 4091, reward total was -19.0. running mean: -19.13102920299247, timestamp: 2022-08-19 07:49:39.548845\n",
      "resetting env. episode 4092, reward total was -18.0. running mean: -19.119718910962543, timestamp: 2022-08-19 07:49:44.238912\n",
      "resetting env. episode 4093, reward total was -19.0. running mean: -19.118521721852918, timestamp: 2022-08-19 07:49:47.747946\n",
      "resetting env. episode 4094, reward total was -17.0. running mean: -19.09733650463439, timestamp: 2022-08-19 07:49:53.072017\n",
      "resetting env. episode 4095, reward total was -20.0. running mean: -19.106363139588048, timestamp: 2022-08-19 07:49:57.653069\n",
      "resetting env. episode 4096, reward total was -20.0. running mean: -19.115299508192166, timestamp: 2022-08-19 07:50:00.966112\n",
      "resetting env. episode 4097, reward total was -21.0. running mean: -19.134146513110245, timestamp: 2022-08-19 07:50:05.280168\n",
      "resetting env. episode 4098, reward total was -21.0. running mean: -19.152805047979143, timestamp: 2022-08-19 07:50:08.414207\n",
      "resetting env. episode 4099, reward total was -19.0. running mean: -19.15127699749935, timestamp: 2022-08-19 07:50:12.178250\n",
      "resetting env. episode 4100, reward total was -19.0. running mean: -19.149764227524358, timestamp: 2022-08-19 07:50:16.489526\n",
      "resetting env. episode 4101, reward total was -21.0. running mean: -19.168266585249114, timestamp: 2022-08-19 07:50:20.677580\n",
      "resetting env. episode 4102, reward total was -18.0. running mean: -19.156583919396624, timestamp: 2022-08-19 07:50:24.191622\n",
      "resetting env. episode 4103, reward total was -18.0. running mean: -19.145018080202657, timestamp: 2022-08-19 07:50:27.669665\n",
      "resetting env. episode 4104, reward total was -19.0. running mean: -19.143567899400633, timestamp: 2022-08-19 07:50:31.776719\n",
      "resetting env. episode 4105, reward total was -21.0. running mean: -19.162132220406626, timestamp: 2022-08-19 07:50:35.468763\n",
      "resetting env. episode 4106, reward total was -18.0. running mean: -19.15051089820256, timestamp: 2022-08-19 07:50:39.757814\n",
      "resetting env. episode 4107, reward total was -21.0. running mean: -19.169005789220535, timestamp: 2022-08-19 07:50:42.658852\n",
      "resetting env. episode 4108, reward total was -18.0. running mean: -19.157315731328328, timestamp: 2022-08-19 07:50:46.796899\n",
      "resetting env. episode 4109, reward total was -17.0. running mean: -19.135742574015048, timestamp: 2022-08-19 07:50:50.560948\n",
      "resetting env. episode 4110, reward total was -18.0. running mean: -19.124385148274897, timestamp: 2022-08-19 07:50:54.807998\n",
      "resetting env. episode 4111, reward total was -18.0. running mean: -19.113141296792147, timestamp: 2022-08-19 07:50:58.643047\n",
      "resetting env. episode 4112, reward total was -19.0. running mean: -19.112009883824225, timestamp: 2022-08-19 07:51:02.499096\n",
      "resetting env. episode 4113, reward total was -21.0. running mean: -19.130889784985982, timestamp: 2022-08-19 07:51:06.025140\n",
      "resetting env. episode 4114, reward total was -18.0. running mean: -19.11958088713612, timestamp: 2022-08-19 07:51:10.576192\n",
      "resetting env. episode 4115, reward total was -19.0. running mean: -19.11838507826476, timestamp: 2022-08-19 07:51:14.046234\n",
      "resetting env. episode 4116, reward total was -19.0. running mean: -19.117201227482116, timestamp: 2022-08-19 07:51:17.444276\n",
      "resetting env. episode 4117, reward total was -20.0. running mean: -19.126029215207293, timestamp: 2022-08-19 07:51:20.841317\n",
      "resetting env. episode 4118, reward total was -21.0. running mean: -19.14476892305522, timestamp: 2022-08-19 07:51:24.323362\n",
      "resetting env. episode 4119, reward total was -21.0. running mean: -19.163321233824668, timestamp: 2022-08-19 07:51:27.407399\n",
      "resetting env. episode 4120, reward total was -20.0. running mean: -19.17168802148642, timestamp: 2022-08-19 07:51:31.004440\n",
      "resetting env. episode 4121, reward total was -21.0. running mean: -19.189971141271556, timestamp: 2022-08-19 07:51:35.527497\n",
      "resetting env. episode 4122, reward total was -16.0. running mean: -19.15807142985884, timestamp: 2022-08-19 07:51:39.231540\n",
      "resetting env. episode 4123, reward total was -20.0. running mean: -19.16649071556025, timestamp: 2022-08-19 07:51:43.577597\n",
      "resetting env. episode 4124, reward total was -19.0. running mean: -19.16482580840465, timestamp: 2022-08-19 07:51:46.713633\n",
      "resetting env. episode 4125, reward total was -20.0. running mean: -19.173177550320602, timestamp: 2022-08-19 07:51:49.974676\n",
      "resetting env. episode 4126, reward total was -17.0. running mean: -19.151445774817397, timestamp: 2022-08-19 07:51:53.714719\n",
      "resetting env. episode 4127, reward total was -18.0. running mean: -19.139931317069223, timestamp: 2022-08-19 07:51:58.452776\n",
      "resetting env. episode 4128, reward total was -19.0. running mean: -19.138532003898533, timestamp: 2022-08-19 07:52:02.455825\n",
      "resetting env. episode 4129, reward total was -20.0. running mean: -19.147146683859546, timestamp: 2022-08-19 07:52:05.118859\n",
      "resetting env. episode 4130, reward total was -21.0. running mean: -19.16567521702095, timestamp: 2022-08-19 07:52:09.435912\n",
      "resetting env. episode 4131, reward total was -20.0. running mean: -19.17401846485074, timestamp: 2022-08-19 07:52:13.780965\n",
      "resetting env. episode 4132, reward total was -21.0. running mean: -19.19227828020223, timestamp: 2022-08-19 07:52:16.552998\n",
      "resetting env. episode 4133, reward total was -18.0. running mean: -19.180355497400207, timestamp: 2022-08-19 07:52:20.622048\n",
      "resetting env. episode 4134, reward total was -15.0. running mean: -19.138551942426204, timestamp: 2022-08-19 07:52:25.192107\n",
      "resetting env. episode 4135, reward total was -19.0. running mean: -19.137166423001943, timestamp: 2022-08-19 07:52:29.284155\n",
      "resetting env. episode 4136, reward total was -20.0. running mean: -19.145794758771924, timestamp: 2022-08-19 07:52:32.426194\n",
      "resetting env. episode 4137, reward total was -19.0. running mean: -19.144336811184207, timestamp: 2022-08-19 07:52:36.507247\n",
      "resetting env. episode 4138, reward total was -21.0. running mean: -19.162893443072367, timestamp: 2022-08-19 07:52:39.586284\n",
      "resetting env. episode 4139, reward total was -19.0. running mean: -19.161264508641644, timestamp: 2022-08-19 07:52:43.287334\n",
      "resetting env. episode 4140, reward total was -18.0. running mean: -19.149651863555228, timestamp: 2022-08-19 07:52:47.437380\n",
      "resetting env. episode 4141, reward total was -19.0. running mean: -19.148155344919676, timestamp: 2022-08-19 07:52:51.473434\n",
      "resetting env. episode 4142, reward total was -20.0. running mean: -19.156673791470478, timestamp: 2022-08-19 07:52:55.004478\n",
      "resetting env. episode 4143, reward total was -17.0. running mean: -19.135107053555775, timestamp: 2022-08-19 07:52:59.152531\n",
      "resetting env. episode 4144, reward total was -18.0. running mean: -19.123755983020217, timestamp: 2022-08-19 07:53:03.113579\n",
      "resetting env. episode 4145, reward total was -21.0. running mean: -19.142518423190015, timestamp: 2022-08-19 07:53:06.724627\n",
      "resetting env. episode 4146, reward total was -20.0. running mean: -19.151093238958115, timestamp: 2022-08-19 07:53:10.113667\n",
      "resetting env. episode 4147, reward total was -21.0. running mean: -19.169582306568536, timestamp: 2022-08-19 07:53:14.422721\n",
      "resetting env. episode 4148, reward total was -17.0. running mean: -19.14788648350285, timestamp: 2022-08-19 07:53:18.126770\n",
      "resetting env. episode 4149, reward total was -21.0. running mean: -19.166407618667822, timestamp: 2022-08-19 07:53:21.694815\n",
      "resetting env. episode 4150, reward total was -17.0. running mean: -19.144743542481145, timestamp: 2022-08-19 07:53:26.386872\n",
      "resetting env. episode 4151, reward total was -19.0. running mean: -19.143296107056333, timestamp: 2022-08-19 07:53:30.503924\n",
      "resetting env. episode 4152, reward total was -18.0. running mean: -19.13186314598577, timestamp: 2022-08-19 07:53:34.023971\n",
      "resetting env. episode 4153, reward total was -21.0. running mean: -19.15054451452591, timestamp: 2022-08-19 07:53:37.747019\n",
      "resetting env. episode 4154, reward total was -21.0. running mean: -19.169039069380652, timestamp: 2022-08-19 07:53:41.485062\n",
      "resetting env. episode 4155, reward total was -20.0. running mean: -19.177348678686844, timestamp: 2022-08-19 07:53:45.077109\n",
      "resetting env. episode 4156, reward total was -21.0. running mean: -19.195575191899977, timestamp: 2022-08-19 07:53:48.598155\n",
      "resetting env. episode 4157, reward total was -18.0. running mean: -19.183619439980976, timestamp: 2022-08-19 07:53:52.619206\n",
      "resetting env. episode 4158, reward total was -18.0. running mean: -19.171783245581167, timestamp: 2022-08-19 07:53:56.054254\n",
      "resetting env. episode 4159, reward total was -21.0. running mean: -19.190065413125357, timestamp: 2022-08-19 07:54:00.244307\n",
      "resetting env. episode 4160, reward total was -18.0. running mean: -19.178164758994104, timestamp: 2022-08-19 07:54:03.521347\n",
      "resetting env. episode 4161, reward total was -21.0. running mean: -19.196383111404163, timestamp: 2022-08-19 07:54:07.531397\n",
      "resetting env. episode 4162, reward total was -20.0. running mean: -19.20441928029012, timestamp: 2022-08-19 07:54:10.877442\n",
      "resetting env. episode 4163, reward total was -20.0. running mean: -19.21237508748722, timestamp: 2022-08-19 07:54:15.487048\n",
      "resetting env. episode 4164, reward total was -19.0. running mean: -19.210251336612348, timestamp: 2022-08-19 07:54:19.530103\n",
      "resetting env. episode 4165, reward total was -18.0. running mean: -19.198148823246225, timestamp: 2022-08-19 07:54:23.618156\n",
      "resetting env. episode 4166, reward total was -20.0. running mean: -19.206167335013763, timestamp: 2022-08-19 07:54:26.657194\n",
      "resetting env. episode 4167, reward total was -19.0. running mean: -19.204105661663625, timestamp: 2022-08-19 07:54:31.012116\n",
      "resetting env. episode 4168, reward total was -19.0. running mean: -19.20206460504699, timestamp: 2022-08-19 07:54:36.232187\n",
      "resetting env. episode 4169, reward total was -21.0. running mean: -19.22004395899652, timestamp: 2022-08-19 07:54:39.319223\n",
      "resetting env. episode 4170, reward total was -18.0. running mean: -19.207843519406556, timestamp: 2022-08-19 07:54:42.960269\n",
      "resetting env. episode 4171, reward total was -19.0. running mean: -19.20576508421249, timestamp: 2022-08-19 07:54:46.240312\n",
      "resetting env. episode 4172, reward total was -19.0. running mean: -19.20370743337037, timestamp: 2022-08-19 07:54:50.170365\n",
      "resetting env. episode 4173, reward total was -20.0. running mean: -19.211670359036663, timestamp: 2022-08-19 07:54:53.348404\n",
      "resetting env. episode 4174, reward total was -21.0. running mean: -19.2295536554463, timestamp: 2022-08-19 07:54:56.301446\n",
      "resetting env. episode 4175, reward total was -20.0. running mean: -19.237258118891834, timestamp: 2022-08-19 07:54:59.559485\n",
      "resetting env. episode 4176, reward total was -21.0. running mean: -19.254885537702915, timestamp: 2022-08-19 07:55:03.089533\n",
      "resetting env. episode 4177, reward total was -18.0. running mean: -19.242336682325885, timestamp: 2022-08-19 07:55:06.364573\n",
      "resetting env. episode 4178, reward total was -20.0. running mean: -19.249913315502624, timestamp: 2022-08-19 07:55:09.499614\n",
      "resetting env. episode 4179, reward total was -21.0. running mean: -19.267414182347597, timestamp: 2022-08-19 07:55:12.937656\n",
      "resetting env. episode 4180, reward total was -19.0. running mean: -19.26474004052412, timestamp: 2022-08-19 07:55:18.226728\n",
      "resetting env. episode 4181, reward total was -20.0. running mean: -19.272092640118878, timestamp: 2022-08-19 07:55:22.659783\n",
      "resetting env. episode 4182, reward total was -18.0. running mean: -19.259371713717687, timestamp: 2022-08-19 07:55:26.660836\n",
      "resetting env. episode 4183, reward total was -21.0. running mean: -19.27677799658051, timestamp: 2022-08-19 07:55:30.395102\n",
      "resetting env. episode 4184, reward total was -19.0. running mean: -19.274010216614705, timestamp: 2022-08-19 07:55:34.001148\n",
      "resetting env. episode 4185, reward total was -21.0. running mean: -19.291270114448558, timestamp: 2022-08-19 07:55:37.919202\n",
      "resetting env. episode 4186, reward total was -19.0. running mean: -19.288357413304073, timestamp: 2022-08-19 07:55:42.701262\n",
      "resetting env. episode 4187, reward total was -17.0. running mean: -19.265473839171033, timestamp: 2022-08-19 07:55:46.482311\n",
      "resetting env. episode 4188, reward total was -20.0. running mean: -19.272819100779323, timestamp: 2022-08-19 07:55:49.804355\n",
      "resetting env. episode 4189, reward total was -18.0. running mean: -19.260090909771527, timestamp: 2022-08-19 07:55:53.943407\n",
      "resetting env. episode 4190, reward total was -17.0. running mean: -19.237490000673812, timestamp: 2022-08-19 07:55:58.976472\n",
      "resetting env. episode 4191, reward total was -20.0. running mean: -19.245115100667075, timestamp: 2022-08-19 07:56:03.069531\n",
      "resetting env. episode 4192, reward total was -19.0. running mean: -19.242663949660404, timestamp: 2022-08-19 07:56:07.168579\n",
      "resetting env. episode 4193, reward total was -16.0. running mean: -19.2102373101638, timestamp: 2022-08-19 07:56:11.474636\n",
      "resetting env. episode 4194, reward total was -18.0. running mean: -19.198134937062164, timestamp: 2022-08-19 07:56:14.861683\n",
      "resetting env. episode 4195, reward total was -19.0. running mean: -19.196153587691544, timestamp: 2022-08-19 07:56:18.388726\n",
      "resetting env. episode 4196, reward total was -21.0. running mean: -19.214192051814628, timestamp: 2022-08-19 07:56:22.279779\n",
      "resetting env. episode 4197, reward total was -19.0. running mean: -19.212050131296483, timestamp: 2022-08-19 07:56:26.592834\n",
      "resetting env. episode 4198, reward total was -20.0. running mean: -19.21992962998352, timestamp: 2022-08-19 07:56:30.974894\n",
      "resetting env. episode 4199, reward total was -21.0. running mean: -19.237730333683682, timestamp: 2022-08-19 07:56:34.093932\n",
      "resetting env. episode 4200, reward total was -18.0. running mean: -19.225353030346845, timestamp: 2022-08-19 07:56:39.378001\n",
      "resetting env. episode 4201, reward total was -20.0. running mean: -19.233099500043377, timestamp: 2022-08-19 07:56:43.036052\n",
      "resetting env. episode 4202, reward total was -20.0. running mean: -19.240768505042944, timestamp: 2022-08-19 07:56:46.092089\n",
      "resetting env. episode 4203, reward total was -19.0. running mean: -19.238360819992515, timestamp: 2022-08-19 07:56:49.972143\n",
      "resetting env. episode 4204, reward total was -19.0. running mean: -19.23597721179259, timestamp: 2022-08-19 07:56:53.823190\n",
      "resetting env. episode 4205, reward total was -21.0. running mean: -19.253617439674667, timestamp: 2022-08-19 07:56:57.306240\n",
      "resetting env. episode 4206, reward total was -17.0. running mean: -19.231081265277922, timestamp: 2022-08-19 07:57:00.947282\n",
      "resetting env. episode 4207, reward total was -20.0. running mean: -19.238770452625143, timestamp: 2022-08-19 07:57:04.653331\n",
      "resetting env. episode 4208, reward total was -21.0. running mean: -19.256382748098893, timestamp: 2022-08-19 07:57:08.642384\n",
      "resetting env. episode 4209, reward total was -21.0. running mean: -19.273818920617906, timestamp: 2022-08-19 07:57:12.615436\n",
      "resetting env. episode 4210, reward total was -20.0. running mean: -19.281080731411727, timestamp: 2022-08-19 07:57:16.126481\n",
      "resetting env. episode 4211, reward total was -19.0. running mean: -19.27826992409761, timestamp: 2022-08-19 07:57:19.288528\n",
      "resetting env. episode 4212, reward total was -19.0. running mean: -19.275487224856636, timestamp: 2022-08-19 07:57:23.229575\n",
      "resetting env. episode 4213, reward total was -20.0. running mean: -19.28273235260807, timestamp: 2022-08-19 07:57:27.617634\n",
      "resetting env. episode 4214, reward total was -18.0. running mean: -19.269905029081986, timestamp: 2022-08-19 07:57:31.845692\n",
      "resetting env. episode 4215, reward total was -19.0. running mean: -19.267205978791168, timestamp: 2022-08-19 07:57:34.932731\n",
      "resetting env. episode 4216, reward total was -16.0. running mean: -19.234533919003255, timestamp: 2022-08-19 07:57:39.204787\n",
      "resetting env. episode 4217, reward total was -20.0. running mean: -19.24218857981322, timestamp: 2022-08-19 07:57:42.439827\n",
      "resetting env. episode 4218, reward total was -19.0. running mean: -19.23976669401509, timestamp: 2022-08-19 07:57:45.385865\n",
      "resetting env. episode 4219, reward total was -18.0. running mean: -19.227369027074936, timestamp: 2022-08-19 07:57:49.256919\n",
      "resetting env. episode 4220, reward total was -19.0. running mean: -19.225095336804188, timestamp: 2022-08-19 07:57:53.581971\n",
      "resetting env. episode 4221, reward total was -16.0. running mean: -19.192844383436146, timestamp: 2022-08-19 07:57:57.937033\n",
      "resetting env. episode 4222, reward total was -17.0. running mean: -19.170915939601787, timestamp: 2022-08-19 07:58:03.003099\n",
      "resetting env. episode 4223, reward total was -20.0. running mean: -19.179206780205767, timestamp: 2022-08-19 07:58:07.079154\n",
      "resetting env. episode 4224, reward total was -19.0. running mean: -19.17741471240371, timestamp: 2022-08-19 07:58:10.478198\n",
      "resetting env. episode 4225, reward total was -20.0. running mean: -19.185640565279673, timestamp: 2022-08-19 07:58:13.626240\n",
      "resetting env. episode 4226, reward total was -20.0. running mean: -19.193784159626876, timestamp: 2022-08-19 07:58:17.534292\n",
      "resetting env. episode 4227, reward total was -19.0. running mean: -19.19184631803061, timestamp: 2022-08-19 07:58:21.429342\n",
      "resetting env. episode 4228, reward total was -19.0. running mean: -19.189927854850303, timestamp: 2022-08-19 07:58:25.428394\n",
      "resetting env. episode 4229, reward total was -18.0. running mean: -19.1780285763018, timestamp: 2022-08-19 07:58:29.322445\n",
      "resetting env. episode 4230, reward total was -19.0. running mean: -19.176248290538783, timestamp: 2022-08-19 07:58:33.581502\n",
      "resetting env. episode 4231, reward total was -18.0. running mean: -19.164485807633394, timestamp: 2022-08-19 07:58:37.407552\n",
      "resetting env. episode 4232, reward total was -19.0. running mean: -19.16284094955706, timestamp: 2022-08-19 07:58:41.239604\n",
      "resetting env. episode 4233, reward total was -20.0. running mean: -19.17121254006149, timestamp: 2022-08-19 07:58:44.987652\n",
      "resetting env. episode 4234, reward total was -16.0. running mean: -19.139500414660876, timestamp: 2022-08-19 07:58:49.571711\n",
      "resetting env. episode 4235, reward total was -17.0. running mean: -19.118105410514268, timestamp: 2022-08-19 07:58:53.775777\n",
      "resetting env. episode 4236, reward total was -19.0. running mean: -19.116924356409125, timestamp: 2022-08-19 07:58:57.007826\n",
      "resetting env. episode 4237, reward total was -20.0. running mean: -19.125755112845034, timestamp: 2022-08-19 07:59:00.685867\n",
      "resetting env. episode 4238, reward total was -19.0. running mean: -19.124497561716584, timestamp: 2022-08-19 07:59:04.430915\n",
      "resetting env. episode 4239, reward total was -20.0. running mean: -19.133252586099417, timestamp: 2022-08-19 07:59:07.754962\n",
      "resetting env. episode 4240, reward total was -21.0. running mean: -19.151920060238425, timestamp: 2022-08-19 07:59:10.866000\n",
      "resetting env. episode 4241, reward total was -20.0. running mean: -19.160400859636038, timestamp: 2022-08-19 07:59:14.157041\n",
      "resetting env. episode 4242, reward total was -19.0. running mean: -19.15879685103968, timestamp: 2022-08-19 07:59:18.379098\n",
      "resetting env. episode 4243, reward total was -19.0. running mean: -19.157208882529282, timestamp: 2022-08-19 07:59:21.777144\n",
      "resetting env. episode 4244, reward total was -21.0. running mean: -19.17563679370399, timestamp: 2022-08-19 07:59:24.205171\n",
      "resetting env. episode 4245, reward total was -21.0. running mean: -19.193880425766952, timestamp: 2022-08-19 07:59:27.207210\n",
      "resetting env. episode 4246, reward total was -20.0. running mean: -19.20194162150928, timestamp: 2022-08-19 07:59:30.754256\n",
      "resetting env. episode 4247, reward total was -19.0. running mean: -19.19992220529419, timestamp: 2022-08-19 07:59:34.430306\n",
      "resetting env. episode 4248, reward total was -20.0. running mean: -19.207922983241247, timestamp: 2022-08-19 07:59:38.143354\n",
      "resetting env. episode 4249, reward total was -21.0. running mean: -19.225843753408835, timestamp: 2022-08-19 07:59:41.404397\n",
      "resetting env. episode 4250, reward total was -20.0. running mean: -19.233585315874745, timestamp: 2022-08-19 07:59:45.623451\n",
      "resetting env. episode 4251, reward total was -20.0. running mean: -19.241249462715995, timestamp: 2022-08-19 07:59:49.579504\n",
      "resetting env. episode 4252, reward total was -17.0. running mean: -19.218836968088837, timestamp: 2022-08-19 07:59:53.565553\n",
      "resetting env. episode 4253, reward total was -21.0. running mean: -19.23664859840795, timestamp: 2022-08-19 07:59:57.380602\n",
      "resetting env. episode 4254, reward total was -21.0. running mean: -19.25428211242387, timestamp: 2022-08-19 08:00:00.993651\n",
      "resetting env. episode 4255, reward total was -20.0. running mean: -19.26173929129963, timestamp: 2022-08-19 08:00:04.688698\n",
      "resetting env. episode 4256, reward total was -19.0. running mean: -19.259121898386635, timestamp: 2022-08-19 08:00:08.055749\n",
      "resetting env. episode 4257, reward total was -19.0. running mean: -19.25653067940277, timestamp: 2022-08-19 08:00:12.458800\n",
      "resetting env. episode 4258, reward total was -17.0. running mean: -19.233965372608743, timestamp: 2022-08-19 08:00:17.892871\n",
      "resetting env. episode 4259, reward total was -20.0. running mean: -19.241625718882656, timestamp: 2022-08-19 08:00:21.184912\n",
      "resetting env. episode 4260, reward total was -19.0. running mean: -19.23920946169383, timestamp: 2022-08-19 08:00:24.980691\n",
      "resetting env. episode 4261, reward total was -19.0. running mean: -19.236817367076892, timestamp: 2022-08-19 08:00:28.312735\n",
      "resetting env. episode 4262, reward total was -20.0. running mean: -19.244449193406123, timestamp: 2022-08-19 08:00:31.835782\n",
      "resetting env. episode 4263, reward total was -20.0. running mean: -19.25200470147206, timestamp: 2022-08-19 08:00:35.918839\n",
      "resetting env. episode 4264, reward total was -21.0. running mean: -19.26948465445734, timestamp: 2022-08-19 08:00:38.537868\n",
      "resetting env. episode 4265, reward total was -19.0. running mean: -19.26678980791277, timestamp: 2022-08-19 08:00:42.812924\n",
      "resetting env. episode 4266, reward total was -19.0. running mean: -19.26412190983364, timestamp: 2022-08-19 08:00:46.755976\n",
      "resetting env. episode 4267, reward total was -21.0. running mean: -19.281480690735304, timestamp: 2022-08-19 08:00:51.231033\n",
      "resetting env. episode 4268, reward total was -15.0. running mean: -19.23866588382795, timestamp: 2022-08-19 08:00:55.950094\n",
      "resetting env. episode 4269, reward total was -19.0. running mean: -19.23627922498967, timestamp: 2022-08-19 08:01:00.201150\n",
      "resetting env. episode 4270, reward total was -19.0. running mean: -19.233916432739775, timestamp: 2022-08-19 08:01:04.246201\n",
      "resetting env. episode 4271, reward total was -17.0. running mean: -19.21157726841238, timestamp: 2022-08-19 08:01:08.409257\n",
      "resetting env. episode 4272, reward total was -18.0. running mean: -19.199461495728258, timestamp: 2022-08-19 08:01:11.495298\n",
      "resetting env. episode 4273, reward total was -20.0. running mean: -19.207466880770973, timestamp: 2022-08-19 08:01:15.128347\n",
      "resetting env. episode 4274, reward total was -20.0. running mean: -19.215392211963263, timestamp: 2022-08-19 08:01:18.578389\n",
      "resetting env. episode 4275, reward total was -19.0. running mean: -19.21323828984363, timestamp: 2022-08-19 08:01:22.557441\n",
      "resetting env. episode 4276, reward total was -20.0. running mean: -19.221105906945194, timestamp: 2022-08-19 08:01:25.300479\n",
      "resetting env. episode 4277, reward total was -20.0. running mean: -19.22889484787574, timestamp: 2022-08-19 08:01:29.087529\n",
      "resetting env. episode 4278, reward total was -19.0. running mean: -19.226605899396983, timestamp: 2022-08-19 08:01:33.014578\n",
      "resetting env. episode 4279, reward total was -19.0. running mean: -19.224339840403015, timestamp: 2022-08-19 08:01:36.713627\n",
      "resetting env. episode 4280, reward total was -17.0. running mean: -19.202096441998986, timestamp: 2022-08-19 08:01:40.797678\n",
      "resetting env. episode 4281, reward total was -20.0. running mean: -19.210075477578997, timestamp: 2022-08-19 08:01:45.025731\n",
      "resetting env. episode 4282, reward total was -19.0. running mean: -19.207974722803208, timestamp: 2022-08-19 08:01:48.594776\n",
      "resetting env. episode 4283, reward total was -21.0. running mean: -19.225894975575176, timestamp: 2022-08-19 08:01:52.825834\n",
      "resetting env. episode 4284, reward total was -19.0. running mean: -19.223636025819427, timestamp: 2022-08-19 08:01:56.838883\n",
      "resetting env. episode 4285, reward total was -20.0. running mean: -19.23139966556123, timestamp: 2022-08-19 08:02:00.355928\n",
      "resetting env. episode 4286, reward total was -20.0. running mean: -19.239085668905616, timestamp: 2022-08-19 08:02:04.722986\n",
      "resetting env. episode 4287, reward total was -21.0. running mean: -19.256694812216562, timestamp: 2022-08-19 08:02:07.974027\n",
      "resetting env. episode 4288, reward total was -20.0. running mean: -19.264127864094394, timestamp: 2022-08-19 08:02:11.329072\n",
      "resetting env. episode 4289, reward total was -18.0. running mean: -19.25148658545345, timestamp: 2022-08-19 08:02:15.348124\n",
      "resetting env. episode 4290, reward total was -17.0. running mean: -19.228971719598917, timestamp: 2022-08-19 08:02:18.750165\n",
      "resetting env. episode 4291, reward total was -16.0. running mean: -19.196682002402927, timestamp: 2022-08-19 08:02:22.854219\n",
      "resetting env. episode 4292, reward total was -19.0. running mean: -19.1947151823789, timestamp: 2022-08-19 08:02:26.593266\n",
      "resetting env. episode 4293, reward total was -20.0. running mean: -19.20276803055511, timestamp: 2022-08-19 08:02:30.331319\n",
      "resetting env. episode 4294, reward total was -19.0. running mean: -19.20074035024956, timestamp: 2022-08-19 08:02:34.105363\n",
      "resetting env. episode 4295, reward total was -20.0. running mean: -19.208732946747062, timestamp: 2022-08-19 08:02:37.405406\n",
      "resetting env. episode 4296, reward total was -18.0. running mean: -19.196645617279593, timestamp: 2022-08-19 08:02:41.397457\n",
      "resetting env. episode 4297, reward total was -21.0. running mean: -19.214679161106798, timestamp: 2022-08-19 08:02:44.491497\n",
      "resetting env. episode 4298, reward total was -19.0. running mean: -19.21253236949573, timestamp: 2022-08-19 08:02:47.689539\n",
      "resetting env. episode 4299, reward total was -20.0. running mean: -19.220407045800773, timestamp: 2022-08-19 08:02:50.953586\n",
      "resetting env. episode 4300, reward total was -19.0. running mean: -19.218202975342766, timestamp: 2022-08-19 08:02:53.614614\n",
      "resetting env. episode 4301, reward total was -21.0. running mean: -19.23602094558934, timestamp: 2022-08-19 08:02:57.053658\n",
      "resetting env. episode 4302, reward total was -21.0. running mean: -19.253660736133444, timestamp: 2022-08-19 08:03:00.323702\n",
      "resetting env. episode 4303, reward total was -16.0. running mean: -19.22112412877211, timestamp: 2022-08-19 08:03:04.949762\n",
      "resetting env. episode 4304, reward total was -19.0. running mean: -19.21891288748439, timestamp: 2022-08-19 08:03:09.001024\n",
      "resetting env. episode 4305, reward total was -18.0. running mean: -19.206723758609545, timestamp: 2022-08-19 08:03:13.008076\n",
      "resetting env. episode 4306, reward total was -15.0. running mean: -19.16465652102345, timestamp: 2022-08-19 08:03:17.272127\n",
      "resetting env. episode 4307, reward total was -21.0. running mean: -19.183009955813215, timestamp: 2022-08-19 08:03:20.945177\n",
      "resetting env. episode 4308, reward total was -19.0. running mean: -19.181179856255085, timestamp: 2022-08-19 08:03:25.118232\n",
      "resetting env. episode 4309, reward total was -18.0. running mean: -19.169368057692534, timestamp: 2022-08-19 08:03:29.041277\n",
      "resetting env. episode 4310, reward total was -20.0. running mean: -19.177674377115608, timestamp: 2022-08-19 08:03:32.783325\n",
      "resetting env. episode 4311, reward total was -20.0. running mean: -19.18589763334445, timestamp: 2022-08-19 08:03:37.223385\n",
      "resetting env. episode 4312, reward total was -17.0. running mean: -19.164038657011005, timestamp: 2022-08-19 08:03:42.730161\n",
      "resetting env. episode 4313, reward total was -17.0. running mean: -19.142398270440896, timestamp: 2022-08-19 08:03:46.549212\n",
      "resetting env. episode 4314, reward total was -21.0. running mean: -19.160974287736487, timestamp: 2022-08-19 08:03:50.186254\n",
      "resetting env. episode 4315, reward total was -21.0. running mean: -19.179364544859123, timestamp: 2022-08-19 08:03:53.403297\n",
      "resetting env. episode 4316, reward total was -19.0. running mean: -19.177570899410533, timestamp: 2022-08-19 08:03:58.352360\n",
      "resetting env. episode 4317, reward total was -21.0. running mean: -19.19579519041643, timestamp: 2022-08-19 08:04:03.459425\n",
      "resetting env. episode 4318, reward total was -19.0. running mean: -19.193837238512266, timestamp: 2022-08-19 08:04:08.869494\n",
      "resetting env. episode 4319, reward total was -17.0. running mean: -19.171898866127144, timestamp: 2022-08-19 08:04:13.382551\n",
      "resetting env. episode 4320, reward total was -21.0. running mean: -19.190179877465873, timestamp: 2022-08-19 08:04:17.101598\n",
      "resetting env. episode 4321, reward total was -20.0. running mean: -19.198278078691214, timestamp: 2022-08-19 08:04:21.487653\n",
      "resetting env. episode 4322, reward total was -20.0. running mean: -19.2062952979043, timestamp: 2022-08-19 08:04:26.771719\n",
      "resetting env. episode 4323, reward total was -20.0. running mean: -19.214232344925257, timestamp: 2022-08-19 08:04:31.248777\n",
      "resetting env. episode 4324, reward total was -17.0. running mean: -19.192090021476005, timestamp: 2022-08-19 08:04:38.128863\n",
      "resetting env. episode 4325, reward total was -19.0. running mean: -19.190169121261246, timestamp: 2022-08-19 08:04:41.888910\n",
      "resetting env. episode 4326, reward total was -21.0. running mean: -19.208267430048632, timestamp: 2022-08-19 08:04:47.312976\n",
      "resetting env. episode 4327, reward total was -19.0. running mean: -19.206184755748147, timestamp: 2022-08-19 08:04:53.412055\n",
      "resetting env. episode 4328, reward total was -18.0. running mean: -19.194122908190664, timestamp: 2022-08-19 08:04:59.353131\n",
      "resetting env. episode 4329, reward total was -19.0. running mean: -19.19218167910876, timestamp: 2022-08-19 08:05:04.288039\n",
      "resetting env. episode 4330, reward total was -19.0. running mean: -19.190259862317674, timestamp: 2022-08-19 08:05:08.736091\n",
      "resetting env. episode 4331, reward total was -21.0. running mean: -19.2083572636945, timestamp: 2022-08-19 08:05:13.764155\n",
      "resetting env. episode 4332, reward total was -21.0. running mean: -19.226273691057553, timestamp: 2022-08-19 08:05:17.730203\n",
      "resetting env. episode 4333, reward total was -20.0. running mean: -19.234010954146978, timestamp: 2022-08-19 08:05:20.911245\n",
      "resetting env. episode 4334, reward total was -17.0. running mean: -19.21167084460551, timestamp: 2022-08-19 08:05:25.405301\n",
      "resetting env. episode 4335, reward total was -18.0. running mean: -19.199554136159456, timestamp: 2022-08-19 08:05:31.797377\n",
      "resetting env. episode 4336, reward total was -21.0. running mean: -19.21755859479786, timestamp: 2022-08-19 08:05:36.189435\n",
      "resetting env. episode 4337, reward total was -20.0. running mean: -19.22538300884988, timestamp: 2022-08-19 08:05:40.860492\n",
      "resetting env. episode 4338, reward total was -15.0. running mean: -19.18312917876138, timestamp: 2022-08-19 08:05:48.060584\n",
      "resetting env. episode 4339, reward total was -15.0. running mean: -19.141297886973764, timestamp: 2022-08-19 08:05:56.606688\n",
      "resetting env. episode 4340, reward total was -17.0. running mean: -19.119884908104027, timestamp: 2022-08-19 08:06:02.971769\n",
      "resetting env. episode 4341, reward total was -21.0. running mean: -19.138686059022987, timestamp: 2022-08-19 08:06:07.369822\n",
      "resetting env. episode 4342, reward total was -20.0. running mean: -19.147299198432755, timestamp: 2022-08-19 08:06:13.081898\n",
      "resetting env. episode 4343, reward total was -18.0. running mean: -19.135826206448428, timestamp: 2022-08-19 08:06:17.371949\n",
      "resetting env. episode 4344, reward total was -20.0. running mean: -19.144467944383944, timestamp: 2022-08-19 08:06:22.319009\n",
      "resetting env. episode 4345, reward total was -19.0. running mean: -19.143023264940105, timestamp: 2022-08-19 08:06:25.945057\n",
      "resetting env. episode 4346, reward total was -21.0. running mean: -19.161593032290703, timestamp: 2022-08-19 08:06:30.286112\n",
      "resetting env. episode 4347, reward total was -20.0. running mean: -19.169977101967795, timestamp: 2022-08-19 08:06:35.298173\n",
      "resetting env. episode 4348, reward total was -20.0. running mean: -19.178277330948116, timestamp: 2022-08-19 08:06:39.347224\n",
      "resetting env. episode 4349, reward total was -17.0. running mean: -19.156494557638638, timestamp: 2022-08-19 08:06:45.741303\n",
      "resetting env. episode 4350, reward total was -20.0. running mean: -19.164929612062252, timestamp: 2022-08-19 08:06:50.217358\n",
      "resetting env. episode 4351, reward total was -20.0. running mean: -19.17328031594163, timestamp: 2022-08-19 08:06:54.970418\n",
      "resetting env. episode 4352, reward total was -20.0. running mean: -19.18154751278221, timestamp: 2022-08-19 08:07:00.453484\n",
      "resetting env. episode 4353, reward total was -19.0. running mean: -19.17973203765439, timestamp: 2022-08-19 08:07:05.268545\n",
      "resetting env. episode 4354, reward total was -17.0. running mean: -19.157934717277847, timestamp: 2022-08-19 08:07:10.319607\n",
      "resetting env. episode 4355, reward total was -20.0. running mean: -19.166355370105066, timestamp: 2022-08-19 08:07:14.759661\n",
      "resetting env. episode 4356, reward total was -20.0. running mean: -19.174691816404014, timestamp: 2022-08-19 08:07:19.838725\n",
      "resetting env. episode 4357, reward total was -20.0. running mean: -19.182944898239974, timestamp: 2022-08-19 08:07:24.861787\n",
      "resetting env. episode 4358, reward total was -19.0. running mean: -19.181115449257575, timestamp: 2022-08-19 08:07:29.679845\n",
      "resetting env. episode 4359, reward total was -18.0. running mean: -19.169304294765, timestamp: 2022-08-19 08:07:34.581904\n",
      "resetting env. episode 4360, reward total was -21.0. running mean: -19.187611251817348, timestamp: 2022-08-19 08:07:37.997949\n",
      "resetting env. episode 4361, reward total was -17.0. running mean: -19.165735139299176, timestamp: 2022-08-19 08:07:45.283037\n",
      "resetting env. episode 4362, reward total was -17.0. running mean: -19.144077787906188, timestamp: 2022-08-19 08:07:51.078110\n",
      "resetting env. episode 4363, reward total was -17.0. running mean: -19.122637010027127, timestamp: 2022-08-19 08:07:56.473175\n",
      "resetting env. episode 4364, reward total was -17.0. running mean: -19.101410639926858, timestamp: 2022-08-19 08:08:01.612239\n",
      "resetting env. episode 4365, reward total was -21.0. running mean: -19.12039653352759, timestamp: 2022-08-19 08:08:06.641300\n",
      "resetting env. episode 4366, reward total was -18.0. running mean: -19.109192568192313, timestamp: 2022-08-19 08:08:12.274368\n",
      "resetting env. episode 4367, reward total was -19.0. running mean: -19.10810064251039, timestamp: 2022-08-19 08:08:18.016437\n",
      "resetting env. episode 4368, reward total was -21.0. running mean: -19.127019636085286, timestamp: 2022-08-19 08:08:22.817496\n",
      "resetting env. episode 4369, reward total was -19.0. running mean: -19.125749439724434, timestamp: 2022-08-19 08:08:27.834558\n",
      "resetting env. episode 4370, reward total was -20.0. running mean: -19.134491945327188, timestamp: 2022-08-19 08:08:32.442614\n",
      "resetting env. episode 4371, reward total was -19.0. running mean: -19.133147025873917, timestamp: 2022-08-19 08:08:37.916682\n",
      "resetting env. episode 4372, reward total was -21.0. running mean: -19.15181555561518, timestamp: 2022-08-19 08:08:41.880729\n",
      "resetting env. episode 4373, reward total was -16.0. running mean: -19.120297400059027, timestamp: 2022-08-19 08:08:47.586798\n",
      "resetting env. episode 4374, reward total was -15.0. running mean: -19.079094426058436, timestamp: 2022-08-19 08:08:53.954872\n",
      "resetting env. episode 4375, reward total was -17.0. running mean: -19.058303481797854, timestamp: 2022-08-19 08:09:00.256951\n",
      "resetting env. episode 4376, reward total was -19.0. running mean: -19.057720446979875, timestamp: 2022-08-19 08:09:05.260010\n",
      "resetting env. episode 4377, reward total was -20.0. running mean: -19.067143242510074, timestamp: 2022-08-19 08:09:10.271071\n",
      "resetting env. episode 4378, reward total was -18.0. running mean: -19.05647181008497, timestamp: 2022-08-19 08:09:16.149145\n",
      "resetting env. episode 4379, reward total was -19.0. running mean: -19.055907091984125, timestamp: 2022-08-19 08:09:20.594893\n",
      "resetting env. episode 4380, reward total was -18.0. running mean: -19.04534802106428, timestamp: 2022-08-19 08:09:24.780946\n",
      "resetting env. episode 4381, reward total was -19.0. running mean: -19.04489454085364, timestamp: 2022-08-19 08:09:29.521004\n",
      "resetting env. episode 4382, reward total was -21.0. running mean: -19.064445595445104, timestamp: 2022-08-19 08:09:33.175047\n",
      "resetting env. episode 4383, reward total was -18.0. running mean: -19.053801139490652, timestamp: 2022-08-19 08:09:37.370100\n",
      "resetting env. episode 4384, reward total was -15.0. running mean: -19.013263128095744, timestamp: 2022-08-19 08:09:41.658150\n",
      "resetting env. episode 4385, reward total was -20.0. running mean: -19.023130496814787, timestamp: 2022-08-19 08:09:45.422197\n",
      "resetting env. episode 4386, reward total was -20.0. running mean: -19.03289919184664, timestamp: 2022-08-19 08:09:49.200248\n",
      "resetting env. episode 4387, reward total was -21.0. running mean: -19.052570199928173, timestamp: 2022-08-19 08:09:52.855290\n",
      "resetting env. episode 4388, reward total was -19.0. running mean: -19.052044497928893, timestamp: 2022-08-19 08:09:56.707339\n",
      "resetting env. episode 4389, reward total was -19.0. running mean: -19.051524052949606, timestamp: 2022-08-19 08:10:00.962393\n",
      "resetting env. episode 4390, reward total was -19.0. running mean: -19.05100881242011, timestamp: 2022-08-19 08:10:05.104442\n",
      "resetting env. episode 4391, reward total was -16.0. running mean: -19.02049872429591, timestamp: 2022-08-19 08:10:09.600503\n",
      "resetting env. episode 4392, reward total was -19.0. running mean: -19.02029373705295, timestamp: 2022-08-19 08:10:13.459491\n",
      "resetting env. episode 4393, reward total was -21.0. running mean: -19.04009079968242, timestamp: 2022-08-19 08:10:17.458539\n",
      "resetting env. episode 4394, reward total was -20.0. running mean: -19.049689891685595, timestamp: 2022-08-19 08:10:22.781609\n",
      "resetting env. episode 4395, reward total was -21.0. running mean: -19.06919299276874, timestamp: 2022-08-19 08:10:27.917673\n",
      "resetting env. episode 4396, reward total was -20.0. running mean: -19.078501062841053, timestamp: 2022-08-19 08:10:31.746720\n",
      "resetting env. episode 4397, reward total was -20.0. running mean: -19.08771605221264, timestamp: 2022-08-19 08:10:36.753786\n",
      "resetting env. episode 4398, reward total was -17.0. running mean: -19.066838891690516, timestamp: 2022-08-19 08:10:43.132866\n",
      "resetting env. episode 4399, reward total was -18.0. running mean: -19.05617050277361, timestamp: 2022-08-19 08:10:49.022941\n",
      "resetting env. episode 4400, reward total was -20.0. running mean: -19.065608797745874, timestamp: 2022-08-19 08:10:54.035003\n",
      "resetting env. episode 4401, reward total was -19.0. running mean: -19.064952709768416, timestamp: 2022-08-19 08:10:58.141059\n",
      "resetting env. episode 4402, reward total was -19.0. running mean: -19.064303182670734, timestamp: 2022-08-19 08:11:02.872119\n",
      "resetting env. episode 4403, reward total was -19.0. running mean: -19.06366015084403, timestamp: 2022-08-19 08:11:07.535176\n",
      "resetting env. episode 4404, reward total was -21.0. running mean: -19.08302354933559, timestamp: 2022-08-19 08:11:12.492241\n",
      "resetting env. episode 4405, reward total was -21.0. running mean: -19.102193313842236, timestamp: 2022-08-19 08:11:17.197303\n",
      "resetting env. episode 4406, reward total was -20.0. running mean: -19.111171380703812, timestamp: 2022-08-19 08:11:21.801362\n",
      "resetting env. episode 4407, reward total was -18.0. running mean: -19.100059666896772, timestamp: 2022-08-19 08:11:26.868426\n",
      "resetting env. episode 4408, reward total was -15.0. running mean: -19.059059070227804, timestamp: 2022-08-19 08:11:33.607514\n",
      "resetting env. episode 4409, reward total was -17.0. running mean: -19.038468479525527, timestamp: 2022-08-19 08:11:38.026570\n",
      "resetting env. episode 4410, reward total was -19.0. running mean: -19.038083794730273, timestamp: 2022-08-19 08:11:43.507642\n",
      "resetting env. episode 4411, reward total was -19.0. running mean: -19.037702956782972, timestamp: 2022-08-19 08:11:48.684705\n",
      "resetting env. episode 4412, reward total was -20.0. running mean: -19.04732592721514, timestamp: 2022-08-19 08:11:53.962777\n",
      "resetting env. episode 4413, reward total was -20.0. running mean: -19.056852667942987, timestamp: 2022-08-19 08:11:58.107354\n",
      "resetting env. episode 4414, reward total was -17.0. running mean: -19.036284141263558, timestamp: 2022-08-19 08:12:03.426424\n",
      "resetting env. episode 4415, reward total was -21.0. running mean: -19.055921299850922, timestamp: 2022-08-19 08:12:08.521489\n",
      "resetting env. episode 4416, reward total was -20.0. running mean: -19.065362086852414, timestamp: 2022-08-19 08:12:12.645546\n",
      "resetting env. episode 4417, reward total was -20.0. running mean: -19.07470846598389, timestamp: 2022-08-19 08:12:17.052602\n",
      "resetting env. episode 4418, reward total was -19.0. running mean: -19.07396138132405, timestamp: 2022-08-19 08:12:21.925665\n",
      "resetting env. episode 4419, reward total was -18.0. running mean: -19.06322176751081, timestamp: 2022-08-19 08:12:28.625751\n",
      "resetting env. episode 4420, reward total was -20.0. running mean: -19.0725895498357, timestamp: 2022-08-19 08:12:33.553816\n",
      "resetting env. episode 4421, reward total was -17.0. running mean: -19.051863654337346, timestamp: 2022-08-19 08:12:38.872881\n",
      "resetting env. episode 4422, reward total was -20.0. running mean: -19.061345017793972, timestamp: 2022-08-19 08:12:42.277928\n",
      "resetting env. episode 4423, reward total was -20.0. running mean: -19.070731567616033, timestamp: 2022-08-19 08:12:46.517986\n",
      "resetting env. episode 4424, reward total was -19.0. running mean: -19.070024251939873, timestamp: 2022-08-19 08:12:50.180030\n",
      "resetting env. episode 4425, reward total was -17.0. running mean: -19.049324009420477, timestamp: 2022-08-19 08:12:53.471084\n",
      "resetting env. episode 4426, reward total was -21.0. running mean: -19.068830769326272, timestamp: 2022-08-19 08:12:57.161125\n",
      "resetting env. episode 4427, reward total was -20.0. running mean: -19.078142461633007, timestamp: 2022-08-19 08:13:00.576166\n",
      "resetting env. episode 4428, reward total was -21.0. running mean: -19.09736103701668, timestamp: 2022-08-19 08:13:04.233216\n",
      "resetting env. episode 4429, reward total was -21.0. running mean: -19.11638742664651, timestamp: 2022-08-19 08:13:08.487270\n",
      "resetting env. episode 4430, reward total was -17.0. running mean: -19.095223552380048, timestamp: 2022-08-19 08:13:12.372321\n",
      "resetting env. episode 4431, reward total was -21.0. running mean: -19.11427131685625, timestamp: 2022-08-19 08:13:15.923369\n",
      "resetting env. episode 4432, reward total was -21.0. running mean: -19.133128603687688, timestamp: 2022-08-19 08:13:19.794423\n",
      "resetting env. episode 4433, reward total was -20.0. running mean: -19.14179731765081, timestamp: 2022-08-19 08:13:23.085466\n",
      "resetting env. episode 4434, reward total was -17.0. running mean: -19.1203793444743, timestamp: 2022-08-19 08:13:27.086518\n",
      "resetting env. episode 4435, reward total was -18.0. running mean: -19.10917555102956, timestamp: 2022-08-19 08:13:31.954579\n",
      "resetting env. episode 4436, reward total was -19.0. running mean: -19.108083795519264, timestamp: 2022-08-19 08:13:37.893658\n",
      "resetting env. episode 4437, reward total was -20.0. running mean: -19.11700295756407, timestamp: 2022-08-19 08:13:42.661720\n",
      "resetting env. episode 4438, reward total was -19.0. running mean: -19.11583292798843, timestamp: 2022-08-19 08:13:47.958791\n",
      "resetting env. episode 4439, reward total was -17.0. running mean: -19.094674598708547, timestamp: 2022-08-19 08:13:52.470849\n",
      "resetting env. episode 4440, reward total was -18.0. running mean: -19.083727852721463, timestamp: 2022-08-19 08:13:58.168925\n",
      "resetting env. episode 4441, reward total was -16.0. running mean: -19.052890574194247, timestamp: 2022-08-19 08:14:03.664995\n",
      "resetting env. episode 4442, reward total was -21.0. running mean: -19.072361668452306, timestamp: 2022-08-19 08:14:09.002067\n",
      "resetting env. episode 4443, reward total was -18.0. running mean: -19.061638051767783, timestamp: 2022-08-19 08:14:13.744498\n",
      "resetting env. episode 4444, reward total was -18.0. running mean: -19.051021671250105, timestamp: 2022-08-19 08:14:19.783577\n",
      "resetting env. episode 4445, reward total was -16.0. running mean: -19.020511454537605, timestamp: 2022-08-19 08:14:25.598652\n",
      "resetting env. episode 4446, reward total was -19.0. running mean: -19.02030633999223, timestamp: 2022-08-19 08:14:29.806709\n",
      "resetting env. episode 4447, reward total was -21.0. running mean: -19.04010327659231, timestamp: 2022-08-19 08:14:35.989792\n",
      "resetting env. episode 4448, reward total was -19.0. running mean: -19.039702243826387, timestamp: 2022-08-19 08:14:40.545849\n",
      "resetting env. episode 4449, reward total was -21.0. running mean: -19.059305221388122, timestamp: 2022-08-19 08:14:46.263924\n",
      "resetting env. episode 4450, reward total was -20.0. running mean: -19.06871216917424, timestamp: 2022-08-19 08:14:50.277978\n",
      "resetting env. episode 4451, reward total was -19.0. running mean: -19.0680250474825, timestamp: 2022-08-19 08:14:54.853040\n",
      "resetting env. episode 4452, reward total was -20.0. running mean: -19.077344797007676, timestamp: 2022-08-19 08:14:59.733102\n",
      "resetting env. episode 4453, reward total was -20.0. running mean: -19.086571349037598, timestamp: 2022-08-19 08:15:05.221173\n",
      "resetting env. episode 4454, reward total was -19.0. running mean: -19.085705635547225, timestamp: 2022-08-19 08:15:10.310242\n",
      "resetting env. episode 4455, reward total was -20.0. running mean: -19.09484857919175, timestamp: 2022-08-19 08:15:15.639312\n",
      "resetting env. episode 4456, reward total was -19.0. running mean: -19.093900093399835, timestamp: 2022-08-19 08:15:21.095384\n",
      "resetting env. episode 4457, reward total was -17.0. running mean: -19.07296109246584, timestamp: 2022-08-19 08:15:27.372468\n",
      "resetting env. episode 4458, reward total was -20.0. running mean: -19.08223148154118, timestamp: 2022-08-19 08:15:32.239531\n",
      "resetting env. episode 4459, reward total was -21.0. running mean: -19.101409166725766, timestamp: 2022-08-19 08:15:37.356599\n",
      "resetting env. episode 4460, reward total was -18.0. running mean: -19.090395075058506, timestamp: 2022-08-19 08:15:42.317663\n",
      "resetting env. episode 4461, reward total was -19.0. running mean: -19.089491124307923, timestamp: 2022-08-19 08:15:47.700736\n",
      "resetting env. episode 4462, reward total was -19.0. running mean: -19.088596213064843, timestamp: 2022-08-19 08:15:53.209155\n",
      "resetting env. episode 4463, reward total was -19.0. running mean: -19.087710250934197, timestamp: 2022-08-19 08:15:58.356221\n",
      "resetting env. episode 4464, reward total was -20.0. running mean: -19.096833148424853, timestamp: 2022-08-19 08:16:03.205287\n",
      "resetting env. episode 4465, reward total was -18.0. running mean: -19.085864816940603, timestamp: 2022-08-19 08:16:08.919361\n",
      "resetting env. episode 4466, reward total was -16.0. running mean: -19.055006168771197, timestamp: 2022-08-19 08:16:14.289430\n",
      "resetting env. episode 4467, reward total was -17.0. running mean: -19.034456107083486, timestamp: 2022-08-19 08:16:18.820493\n",
      "resetting env. episode 4468, reward total was -20.0. running mean: -19.04411154601265, timestamp: 2022-08-19 08:16:23.104546\n",
      "resetting env. episode 4469, reward total was -20.0. running mean: -19.053670430552522, timestamp: 2022-08-19 08:16:28.076611\n",
      "resetting env. episode 4470, reward total was -20.0. running mean: -19.063133726246996, timestamp: 2022-08-19 08:16:32.377667\n",
      "resetting env. episode 4471, reward total was -20.0. running mean: -19.072502388984525, timestamp: 2022-08-19 08:16:36.841729\n",
      "resetting env. episode 4472, reward total was -19.0. running mean: -19.07177736509468, timestamp: 2022-08-19 08:16:41.274786\n",
      "resetting env. episode 4473, reward total was -20.0. running mean: -19.081059591443733, timestamp: 2022-08-19 08:16:45.914847\n",
      "resetting env. episode 4474, reward total was -20.0. running mean: -19.090248995529294, timestamp: 2022-08-19 08:16:51.133914\n",
      "resetting env. episode 4475, reward total was -20.0. running mean: -19.099346505574, timestamp: 2022-08-19 08:16:55.982978\n",
      "resetting env. episode 4476, reward total was -17.0. running mean: -19.078353040518262, timestamp: 2022-08-19 08:17:01.586052\n",
      "resetting env. episode 4477, reward total was -21.0. running mean: -19.09756951011308, timestamp: 2022-08-19 08:17:07.145127\n",
      "resetting env. episode 4478, reward total was -19.0. running mean: -19.09659381501195, timestamp: 2022-08-19 08:17:12.064190\n",
      "resetting env. episode 4479, reward total was -20.0. running mean: -19.105627876861828, timestamp: 2022-08-19 08:17:16.668248\n",
      "resetting env. episode 4480, reward total was -19.0. running mean: -19.104571598093212, timestamp: 2022-08-19 08:17:22.055320\n",
      "resetting env. episode 4481, reward total was -20.0. running mean: -19.113525882112278, timestamp: 2022-08-19 08:17:25.599367\n",
      "resetting env. episode 4482, reward total was -19.0. running mean: -19.112390623291155, timestamp: 2022-08-19 08:17:30.651433\n",
      "resetting env. episode 4483, reward total was -20.0. running mean: -19.121266717058244, timestamp: 2022-08-19 08:17:35.718500\n",
      "resetting env. episode 4484, reward total was -20.0. running mean: -19.13005404988766, timestamp: 2022-08-19 08:17:39.459549\n",
      "resetting env. episode 4485, reward total was -20.0. running mean: -19.138753509388785, timestamp: 2022-08-19 08:17:44.953619\n",
      "resetting env. episode 4486, reward total was -20.0. running mean: -19.147365974294896, timestamp: 2022-08-19 08:17:49.503679\n",
      "resetting env. episode 4487, reward total was -18.0. running mean: -19.135892314551946, timestamp: 2022-08-19 08:17:57.091224\n",
      "resetting env. episode 4488, reward total was -19.0. running mean: -19.13453339140643, timestamp: 2022-08-19 08:18:02.875297\n",
      "resetting env. episode 4489, reward total was -15.0. running mean: -19.093188057492362, timestamp: 2022-08-19 08:18:09.596386\n",
      "resetting env. episode 4490, reward total was -20.0. running mean: -19.10225617691744, timestamp: 2022-08-19 08:18:14.571448\n",
      "resetting env. episode 4491, reward total was -20.0. running mean: -19.111233615148265, timestamp: 2022-08-19 08:18:21.326538\n",
      "resetting env. episode 4492, reward total was -19.0. running mean: -19.110121278996782, timestamp: 2022-08-19 08:18:26.799608\n",
      "resetting env. episode 4493, reward total was -19.0. running mean: -19.109020066206817, timestamp: 2022-08-19 08:18:32.134679\n",
      "resetting env. episode 4494, reward total was -21.0. running mean: -19.12792986554475, timestamp: 2022-08-19 08:18:36.603737\n",
      "resetting env. episode 4495, reward total was -21.0. running mean: -19.146650566889303, timestamp: 2022-08-19 08:18:40.714788\n",
      "resetting env. episode 4496, reward total was -20.0. running mean: -19.15518406122041, timestamp: 2022-08-19 08:18:44.761841\n",
      "resetting env. episode 4497, reward total was -19.0. running mean: -19.15363222060821, timestamp: 2022-08-19 08:18:50.534917\n",
      "resetting env. episode 4498, reward total was -16.0. running mean: -19.122095898402126, timestamp: 2022-08-19 08:18:55.794984\n",
      "resetting env. episode 4499, reward total was -17.0. running mean: -19.100874939418105, timestamp: 2022-08-19 08:19:01.741587\n",
      "resetting env. episode 4500, reward total was -21.0. running mean: -19.119866190023924, timestamp: 2022-08-19 08:19:05.434632\n",
      "resetting env. episode 4501, reward total was -18.0. running mean: -19.108667528123686, timestamp: 2022-08-19 08:19:09.816688\n",
      "resetting env. episode 4502, reward total was -19.0. running mean: -19.10758085284245, timestamp: 2022-08-19 08:19:14.700755\n",
      "resetting env. episode 4503, reward total was -20.0. running mean: -19.116505044314025, timestamp: 2022-08-19 08:19:18.276799\n",
      "resetting env. episode 4504, reward total was -20.0. running mean: -19.125339993870885, timestamp: 2022-08-19 08:19:22.376853\n",
      "resetting env. episode 4505, reward total was -19.0. running mean: -19.124086593932176, timestamp: 2022-08-19 08:19:26.725907\n",
      "resetting env. episode 4506, reward total was -21.0. running mean: -19.142845727992857, timestamp: 2022-08-19 08:19:31.354965\n",
      "resetting env. episode 4507, reward total was -20.0. running mean: -19.151417270712926, timestamp: 2022-08-19 08:19:35.371022\n",
      "resetting env. episode 4508, reward total was -19.0. running mean: -19.149903098005797, timestamp: 2022-08-19 08:19:38.345057\n",
      "resetting env. episode 4509, reward total was -18.0. running mean: -19.13840406702574, timestamp: 2022-08-19 08:19:41.957102\n",
      "resetting env. episode 4510, reward total was -20.0. running mean: -19.14702002635548, timestamp: 2022-08-19 08:19:44.498139\n",
      "resetting env. episode 4511, reward total was -15.0. running mean: -19.105549826091924, timestamp: 2022-08-19 08:19:49.894208\n",
      "resetting env. episode 4512, reward total was -18.0. running mean: -19.094494327831004, timestamp: 2022-08-19 08:19:54.766268\n",
      "resetting env. episode 4513, reward total was -16.0. running mean: -19.063549384552694, timestamp: 2022-08-19 08:19:59.402329\n",
      "resetting env. episode 4514, reward total was -20.0. running mean: -19.072913890707166, timestamp: 2022-08-19 08:20:03.765387\n",
      "resetting env. episode 4515, reward total was -19.0. running mean: -19.072184751800094, timestamp: 2022-08-19 08:20:08.117445\n",
      "resetting env. episode 4516, reward total was -19.0. running mean: -19.071462904282093, timestamp: 2022-08-19 08:20:12.178496\n",
      "resetting env. episode 4517, reward total was -21.0. running mean: -19.090748275239275, timestamp: 2022-08-19 08:20:16.029545\n",
      "resetting env. episode 4518, reward total was -21.0. running mean: -19.10984079248688, timestamp: 2022-08-19 08:20:20.192600\n",
      "resetting env. episode 4519, reward total was -16.0. running mean: -19.078742384562013, timestamp: 2022-08-19 08:20:23.762642\n",
      "resetting env. episode 4520, reward total was -21.0. running mean: -19.097954960716393, timestamp: 2022-08-19 08:20:27.663692\n",
      "resetting env. episode 4521, reward total was -17.0. running mean: -19.07697541110923, timestamp: 2022-08-19 08:20:31.464744\n",
      "resetting env. episode 4522, reward total was -19.0. running mean: -19.07620565699814, timestamp: 2022-08-19 08:20:35.655799\n",
      "resetting env. episode 4523, reward total was -18.0. running mean: -19.06544360042816, timestamp: 2022-08-19 08:20:40.068853\n",
      "resetting env. episode 4524, reward total was -20.0. running mean: -19.07478916442388, timestamp: 2022-08-19 08:20:43.626900\n",
      "resetting env. episode 4525, reward total was -16.0. running mean: -19.04404127277964, timestamp: 2022-08-19 08:20:48.466963\n",
      "resetting env. episode 4526, reward total was -18.0. running mean: -19.033600860051845, timestamp: 2022-08-19 08:20:52.810018\n",
      "resetting env. episode 4527, reward total was -18.0. running mean: -19.023264851451327, timestamp: 2022-08-19 08:20:56.039060\n",
      "resetting env. episode 4528, reward total was -20.0. running mean: -19.033032202936813, timestamp: 2022-08-19 08:21:00.126112\n",
      "resetting env. episode 4529, reward total was -17.0. running mean: -19.012701880907446, timestamp: 2022-08-19 08:21:05.189174\n",
      "resetting env. episode 4530, reward total was -17.0. running mean: -18.992574862098373, timestamp: 2022-08-19 08:21:08.973221\n",
      "resetting env. episode 4531, reward total was -19.0. running mean: -18.99264911347739, timestamp: 2022-08-19 08:21:12.343267\n",
      "resetting env. episode 4532, reward total was -21.0. running mean: -19.01272262234262, timestamp: 2022-08-19 08:21:16.015315\n",
      "resetting env. episode 4533, reward total was -21.0. running mean: -19.03259539611919, timestamp: 2022-08-19 08:21:19.263355\n",
      "resetting env. episode 4534, reward total was -19.0. running mean: -19.032269442158, timestamp: 2022-08-19 08:21:22.970405\n",
      "resetting env. episode 4535, reward total was -21.0. running mean: -19.05194674773642, timestamp: 2022-08-19 08:21:26.477446\n",
      "resetting env. episode 4536, reward total was -21.0. running mean: -19.071427280259055, timestamp: 2022-08-19 08:21:29.806488\n",
      "resetting env. episode 4537, reward total was -20.0. running mean: -19.080713007456463, timestamp: 2022-08-19 08:21:32.932528\n",
      "resetting env. episode 4538, reward total was -19.0. running mean: -19.0799058773819, timestamp: 2022-08-19 08:21:37.390585\n",
      "resetting env. episode 4539, reward total was -21.0. running mean: -19.09910681860808, timestamp: 2022-08-19 08:21:41.318634\n",
      "resetting env. episode 4540, reward total was -20.0. running mean: -19.108115750422, timestamp: 2022-08-19 08:21:44.091670\n",
      "resetting env. episode 4541, reward total was -20.0. running mean: -19.11703459291778, timestamp: 2022-08-19 08:21:47.592716\n",
      "resetting env. episode 4542, reward total was -20.0. running mean: -19.125864246988602, timestamp: 2022-08-19 08:21:51.297765\n",
      "resetting env. episode 4543, reward total was -21.0. running mean: -19.144605604518716, timestamp: 2022-08-19 08:21:54.651804\n",
      "resetting env. episode 4544, reward total was -19.0. running mean: -19.14315954847353, timestamp: 2022-08-19 08:21:58.485854\n",
      "resetting env. episode 4545, reward total was -17.0. running mean: -19.121727952988795, timestamp: 2022-08-19 08:22:02.595904\n",
      "resetting env. episode 4546, reward total was -17.0. running mean: -19.10051067345891, timestamp: 2022-08-19 08:22:06.156953\n",
      "resetting env. episode 4547, reward total was -19.0. running mean: -19.09950556672432, timestamp: 2022-08-19 08:22:10.790015\n",
      "resetting env. episode 4548, reward total was -21.0. running mean: -19.118510511057078, timestamp: 2022-08-19 08:22:14.656059\n",
      "resetting env. episode 4549, reward total was -20.0. running mean: -19.127325405946507, timestamp: 2022-08-19 08:22:19.801128\n",
      "resetting env. episode 4550, reward total was -19.0. running mean: -19.126052151887045, timestamp: 2022-08-19 08:22:23.988176\n",
      "resetting env. episode 4551, reward total was -19.0. running mean: -19.124791630368176, timestamp: 2022-08-19 08:22:26.809210\n",
      "resetting env. episode 4552, reward total was -18.0. running mean: -19.113543714064495, timestamp: 2022-08-19 08:22:32.248280\n",
      "resetting env. episode 4553, reward total was -20.0. running mean: -19.12240827692385, timestamp: 2022-08-19 08:22:35.363320\n",
      "resetting env. episode 4554, reward total was -19.0. running mean: -19.121184194154612, timestamp: 2022-08-19 08:22:39.814378\n",
      "resetting env. episode 4555, reward total was -21.0. running mean: -19.139972352213068, timestamp: 2022-08-19 08:22:43.354421\n",
      "resetting env. episode 4556, reward total was -20.0. running mean: -19.148572628690935, timestamp: 2022-08-19 08:22:47.628477\n",
      "resetting env. episode 4557, reward total was -21.0. running mean: -19.167086902404026, timestamp: 2022-08-19 08:22:50.510509\n",
      "resetting env. episode 4558, reward total was -20.0. running mean: -19.175416033379985, timestamp: 2022-08-19 08:22:54.699563\n",
      "resetting env. episode 4559, reward total was -18.0. running mean: -19.163661873046184, timestamp: 2022-08-19 08:22:59.028620\n",
      "resetting env. episode 4560, reward total was -21.0. running mean: -19.18202525431572, timestamp: 2022-08-19 08:23:02.778663\n",
      "resetting env. episode 4561, reward total was -19.0. running mean: -19.180205001772567, timestamp: 2022-08-19 08:23:06.421709\n",
      "resetting env. episode 4562, reward total was -18.0. running mean: -19.168402951754842, timestamp: 2022-08-19 08:23:10.546760\n",
      "resetting env. episode 4563, reward total was -18.0. running mean: -19.156718922237292, timestamp: 2022-08-19 08:23:14.806813\n",
      "resetting env. episode 4564, reward total was -17.0. running mean: -19.135151733014922, timestamp: 2022-08-19 08:23:19.468879\n",
      "resetting env. episode 4565, reward total was -20.0. running mean: -19.143800215684774, timestamp: 2022-08-19 08:23:23.046921\n",
      "resetting env. episode 4566, reward total was -20.0. running mean: -19.152362213527926, timestamp: 2022-08-19 08:23:26.380959\n",
      "resetting env. episode 4567, reward total was -20.0. running mean: -19.160838591392647, timestamp: 2022-08-19 08:23:30.681016\n",
      "resetting env. episode 4568, reward total was -20.0. running mean: -19.16923020547872, timestamp: 2022-08-19 08:23:34.312062\n",
      "resetting env. episode 4569, reward total was -19.0. running mean: -19.167537903423934, timestamp: 2022-08-19 08:23:38.727113\n",
      "resetting env. episode 4570, reward total was -19.0. running mean: -19.165862524389695, timestamp: 2022-08-19 08:23:42.707163\n",
      "resetting env. episode 4571, reward total was -19.0. running mean: -19.1642038991458, timestamp: 2022-08-19 08:23:47.005217\n",
      "resetting env. episode 4572, reward total was -19.0. running mean: -19.162561860154344, timestamp: 2022-08-19 08:23:50.840264\n",
      "resetting env. episode 4573, reward total was -21.0. running mean: -19.1809362415528, timestamp: 2022-08-19 08:23:54.688317\n",
      "resetting env. episode 4574, reward total was -20.0. running mean: -19.18912687913727, timestamp: 2022-08-19 08:23:58.326357\n",
      "resetting env. episode 4575, reward total was -20.0. running mean: -19.197235610345896, timestamp: 2022-08-19 08:24:01.994406\n",
      "resetting env. episode 4576, reward total was -21.0. running mean: -19.215263254242437, timestamp: 2022-08-19 08:24:06.521462\n",
      "resetting env. episode 4577, reward total was -21.0. running mean: -19.233110621700014, timestamp: 2022-08-19 08:24:10.611514\n",
      "resetting env. episode 4578, reward total was -17.0. running mean: -19.210779515483015, timestamp: 2022-08-19 08:24:15.535572\n",
      "resetting env. episode 4579, reward total was -20.0. running mean: -19.218671720328185, timestamp: 2022-08-19 08:24:19.278623\n",
      "resetting env. episode 4580, reward total was -21.0. running mean: -19.236485003124905, timestamp: 2022-08-19 08:24:24.519213\n",
      "resetting env. episode 4581, reward total was -17.0. running mean: -19.214120153093656, timestamp: 2022-08-19 08:24:29.086269\n",
      "resetting env. episode 4582, reward total was -20.0. running mean: -19.22197895156272, timestamp: 2022-08-19 08:24:32.485314\n",
      "resetting env. episode 4583, reward total was -18.0. running mean: -19.209759162047092, timestamp: 2022-08-19 08:24:36.049357\n",
      "resetting env. episode 4584, reward total was -19.0. running mean: -19.207661570426623, timestamp: 2022-08-19 08:24:40.694416\n",
      "resetting env. episode 4585, reward total was -17.0. running mean: -19.18558495472236, timestamp: 2022-08-19 08:24:44.715463\n",
      "resetting env. episode 4586, reward total was -17.0. running mean: -19.163729105175136, timestamp: 2022-08-19 08:24:49.987530\n",
      "resetting env. episode 4587, reward total was -17.0. running mean: -19.142091814123386, timestamp: 2022-08-19 08:24:54.209581\n",
      "resetting env. episode 4588, reward total was -17.0. running mean: -19.120670895982155, timestamp: 2022-08-19 08:24:58.294631\n",
      "resetting env. episode 4589, reward total was -20.0. running mean: -19.129464187022332, timestamp: 2022-08-19 08:25:02.353682\n",
      "resetting env. episode 4590, reward total was -19.0. running mean: -19.12816954515211, timestamp: 2022-08-19 08:25:06.599735\n",
      "resetting env. episode 4591, reward total was -19.0. running mean: -19.12688784970059, timestamp: 2022-08-19 08:25:10.363785\n",
      "resetting env. episode 4592, reward total was -20.0. running mean: -19.135618971203584, timestamp: 2022-08-19 08:25:14.178829\n",
      "resetting env. episode 4593, reward total was -17.0. running mean: -19.11426278149155, timestamp: 2022-08-19 08:25:18.635885\n",
      "resetting env. episode 4594, reward total was -18.0. running mean: -19.103120153676635, timestamp: 2022-08-19 08:25:22.588933\n",
      "resetting env. episode 4595, reward total was -20.0. running mean: -19.112088952139867, timestamp: 2022-08-19 08:25:26.491982\n",
      "resetting env. episode 4596, reward total was -19.0. running mean: -19.11096806261847, timestamp: 2022-08-19 08:25:30.557036\n",
      "resetting env. episode 4597, reward total was -19.0. running mean: -19.109858381992286, timestamp: 2022-08-19 08:25:35.348091\n",
      "resetting env. episode 4598, reward total was -19.0. running mean: -19.108759798172365, timestamp: 2022-08-19 08:25:39.146137\n",
      "resetting env. episode 4599, reward total was -16.0. running mean: -19.07767220019064, timestamp: 2022-08-19 08:25:43.405189\n",
      "resetting env. episode 4600, reward total was -20.0. running mean: -19.086895478188733, timestamp: 2022-08-19 08:25:47.418239\n",
      "resetting env. episode 4601, reward total was -18.0. running mean: -19.076026523406846, timestamp: 2022-08-19 08:25:51.015103\n",
      "resetting env. episode 4602, reward total was -17.0. running mean: -19.05526625817278, timestamp: 2022-08-19 08:25:55.990161\n",
      "resetting env. episode 4603, reward total was -21.0. running mean: -19.074713595591053, timestamp: 2022-08-19 08:25:59.934209\n",
      "resetting env. episode 4604, reward total was -20.0. running mean: -19.083966459635143, timestamp: 2022-08-19 08:26:03.514253\n",
      "resetting env. episode 4605, reward total was -19.0. running mean: -19.083126795038794, timestamp: 2022-08-19 08:26:07.403306\n",
      "resetting env. episode 4606, reward total was -17.0. running mean: -19.06229552708841, timestamp: 2022-08-19 08:26:12.123360\n",
      "resetting env. episode 4607, reward total was -20.0. running mean: -19.071672571817523, timestamp: 2022-08-19 08:26:16.461417\n",
      "resetting env. episode 4608, reward total was -17.0. running mean: -19.05095584609935, timestamp: 2022-08-19 08:26:20.784068\n",
      "resetting env. episode 4609, reward total was -16.0. running mean: -19.020446287638354, timestamp: 2022-08-19 08:26:25.447119\n",
      "resetting env. episode 4610, reward total was -19.0. running mean: -19.02024182476197, timestamp: 2022-08-19 08:26:29.571170\n",
      "resetting env. episode 4611, reward total was -17.0. running mean: -19.000039406514354, timestamp: 2022-08-19 08:26:34.160229\n",
      "resetting env. episode 4612, reward total was -18.0. running mean: -18.99003901244921, timestamp: 2022-08-19 08:26:38.491286\n",
      "resetting env. episode 4613, reward total was -19.0. running mean: -18.990138622324718, timestamp: 2022-08-19 08:26:41.732323\n",
      "resetting env. episode 4614, reward total was -19.0. running mean: -18.99023723610147, timestamp: 2022-08-19 08:26:45.184369\n",
      "resetting env. episode 4615, reward total was -21.0. running mean: -19.010334863740457, timestamp: 2022-08-19 08:26:49.942430\n",
      "resetting env. episode 4616, reward total was -19.0. running mean: -19.010231515103055, timestamp: 2022-08-19 08:26:54.874488\n",
      "resetting env. episode 4617, reward total was -21.0. running mean: -19.030129199952025, timestamp: 2022-08-19 08:26:58.031533\n",
      "resetting env. episode 4618, reward total was -19.0. running mean: -19.029827907952505, timestamp: 2022-08-19 08:27:02.780585\n",
      "resetting env. episode 4619, reward total was -15.0. running mean: -18.98952962887298, timestamp: 2022-08-19 08:27:07.111640\n",
      "resetting env. episode 4620, reward total was -18.0. running mean: -18.97963433258425, timestamp: 2022-08-19 08:27:11.681699\n",
      "resetting env. episode 4621, reward total was -20.0. running mean: -18.989837989258408, timestamp: 2022-08-19 08:27:15.152746\n",
      "resetting env. episode 4622, reward total was -20.0. running mean: -18.999939609365825, timestamp: 2022-08-19 08:27:18.673790\n",
      "resetting env. episode 4623, reward total was -21.0. running mean: -19.019940213272168, timestamp: 2022-08-19 08:27:22.737843\n",
      "resetting env. episode 4624, reward total was -21.0. running mean: -19.039740811139445, timestamp: 2022-08-19 08:27:26.602891\n",
      "resetting env. episode 4625, reward total was -20.0. running mean: -19.04934340302805, timestamp: 2022-08-19 08:27:29.810929\n",
      "resetting env. episode 4626, reward total was -18.0. running mean: -19.03884996899777, timestamp: 2022-08-19 08:27:34.149984\n",
      "resetting env. episode 4627, reward total was -21.0. running mean: -19.058461469307794, timestamp: 2022-08-19 08:27:39.741054\n",
      "resetting env. episode 4628, reward total was -19.0. running mean: -19.057876854614715, timestamp: 2022-08-19 08:27:43.865111\n",
      "resetting env. episode 4629, reward total was -20.0. running mean: -19.06729808606857, timestamp: 2022-08-19 08:27:47.600155\n",
      "resetting env. episode 4630, reward total was -21.0. running mean: -19.086625105207883, timestamp: 2022-08-19 08:27:51.667207\n",
      "resetting env. episode 4631, reward total was -17.0. running mean: -19.065758854155806, timestamp: 2022-08-19 08:27:55.879265\n",
      "resetting env. episode 4632, reward total was -21.0. running mean: -19.08510126561425, timestamp: 2022-08-19 08:27:59.675309\n",
      "resetting env. episode 4633, reward total was -18.0. running mean: -19.074250252958105, timestamp: 2022-08-19 08:28:03.568359\n",
      "resetting env. episode 4634, reward total was -20.0. running mean: -19.083507750428524, timestamp: 2022-08-19 08:28:06.515396\n",
      "resetting env. episode 4635, reward total was -20.0. running mean: -19.092672672924238, timestamp: 2022-08-19 08:28:10.633451\n",
      "resetting env. episode 4636, reward total was -20.0. running mean: -19.101745946194995, timestamp: 2022-08-19 08:28:14.375498\n",
      "resetting env. episode 4637, reward total was -19.0. running mean: -19.100728486733047, timestamp: 2022-08-19 08:28:17.851543\n",
      "resetting env. episode 4638, reward total was -18.0. running mean: -19.089721201865714, timestamp: 2022-08-19 08:28:22.147603\n",
      "resetting env. episode 4639, reward total was -18.0. running mean: -19.078823989847056, timestamp: 2022-08-19 08:28:25.987652\n",
      "resetting env. episode 4640, reward total was -21.0. running mean: -19.098035749948586, timestamp: 2022-08-19 08:28:29.428692\n",
      "resetting env. episode 4641, reward total was -14.0. running mean: -19.0470553924491, timestamp: 2022-08-19 08:28:33.847750\n",
      "resetting env. episode 4642, reward total was -20.0. running mean: -19.056584838524607, timestamp: 2022-08-19 08:28:38.184808\n",
      "resetting env. episode 4643, reward total was -21.0. running mean: -19.07601899013936, timestamp: 2022-08-19 08:28:41.993858\n",
      "resetting env. episode 4644, reward total was -18.0. running mean: -19.065258800237967, timestamp: 2022-08-19 08:28:46.404913\n",
      "resetting env. episode 4645, reward total was -18.0. running mean: -19.054606212235587, timestamp: 2022-08-19 08:28:51.208976\n",
      "resetting env. episode 4646, reward total was -20.0. running mean: -19.06406015011323, timestamp: 2022-08-19 08:28:54.860027\n",
      "resetting env. episode 4647, reward total was -18.0. running mean: -19.053419548612098, timestamp: 2022-08-19 08:28:58.809074\n",
      "resetting env. episode 4648, reward total was -14.0. running mean: -19.002885353125976, timestamp: 2022-08-19 08:29:03.619140\n",
      "resetting env. episode 4649, reward total was -20.0. running mean: -19.012856499594715, timestamp: 2022-08-19 08:29:07.195185\n",
      "resetting env. episode 4650, reward total was -21.0. running mean: -19.032727934598768, timestamp: 2022-08-19 08:29:11.213238\n",
      "resetting env. episode 4651, reward total was -17.0. running mean: -19.012400655252783, timestamp: 2022-08-19 08:29:15.396294\n",
      "resetting env. episode 4652, reward total was -19.0. running mean: -19.012276648700258, timestamp: 2022-08-19 08:29:19.103340\n",
      "resetting env. episode 4653, reward total was -19.0. running mean: -19.012153882213255, timestamp: 2022-08-19 08:29:23.607399\n",
      "resetting env. episode 4654, reward total was -16.0. running mean: -18.982032343391122, timestamp: 2022-08-19 08:29:28.331459\n",
      "resetting env. episode 4655, reward total was -19.0. running mean: -18.982212019957213, timestamp: 2022-08-19 08:29:32.863522\n",
      "resetting env. episode 4656, reward total was -19.0. running mean: -18.982389899757642, timestamp: 2022-08-19 08:29:36.859568\n",
      "resetting env. episode 4657, reward total was -19.0. running mean: -18.982566000760066, timestamp: 2022-08-19 08:29:40.962622\n",
      "resetting env. episode 4658, reward total was -21.0. running mean: -19.002740340752467, timestamp: 2022-08-19 08:29:44.625672\n",
      "resetting env. episode 4659, reward total was -20.0. running mean: -19.012712937344943, timestamp: 2022-08-19 08:29:49.029729\n",
      "resetting env. episode 4660, reward total was -20.0. running mean: -19.022585807971492, timestamp: 2022-08-19 08:29:52.535777\n",
      "resetting env. episode 4661, reward total was -21.0. running mean: -19.04235994989178, timestamp: 2022-08-19 08:29:56.089212\n",
      "resetting env. episode 4662, reward total was -17.0. running mean: -19.021936350392863, timestamp: 2022-08-19 08:30:01.337277\n",
      "resetting env. episode 4663, reward total was -21.0. running mean: -19.041716986888936, timestamp: 2022-08-19 08:30:04.705321\n",
      "resetting env. episode 4664, reward total was -19.0. running mean: -19.041299817020047, timestamp: 2022-08-19 08:30:08.834375\n",
      "resetting env. episode 4665, reward total was -18.0. running mean: -19.030886818849847, timestamp: 2022-08-19 08:30:12.612427\n",
      "resetting env. episode 4666, reward total was -19.0. running mean: -19.03057795066135, timestamp: 2022-08-19 08:30:16.173473\n",
      "resetting env. episode 4667, reward total was -21.0. running mean: -19.050272171154738, timestamp: 2022-08-19 08:30:21.363545\n",
      "resetting env. episode 4668, reward total was -20.0. running mean: -19.05976944944319, timestamp: 2022-08-19 08:30:25.369596\n",
      "resetting env. episode 4669, reward total was -20.0. running mean: -19.06917175494876, timestamp: 2022-08-19 08:30:29.422648\n",
      "resetting env. episode 4670, reward total was -18.0. running mean: -19.05848003739927, timestamp: 2022-08-19 08:30:33.397701\n",
      "resetting env. episode 4671, reward total was -19.0. running mean: -19.057895237025278, timestamp: 2022-08-19 08:30:37.401753\n",
      "resetting env. episode 4672, reward total was -17.0. running mean: -19.037316284655027, timestamp: 2022-08-19 08:30:42.436821\n",
      "resetting env. episode 4673, reward total was -19.0. running mean: -19.036943121808477, timestamp: 2022-08-19 08:30:48.073894\n",
      "resetting env. episode 4674, reward total was -21.0. running mean: -19.056573690590394, timestamp: 2022-08-19 08:30:52.572957\n",
      "resetting env. episode 4675, reward total was -19.0. running mean: -19.056007953684492, timestamp: 2022-08-19 08:30:56.029998\n",
      "resetting env. episode 4676, reward total was -16.0. running mean: -19.02544787414765, timestamp: 2022-08-19 08:31:00.419060\n",
      "resetting env. episode 4677, reward total was -21.0. running mean: -19.045193395406173, timestamp: 2022-08-19 08:31:05.783129\n",
      "resetting env. episode 4678, reward total was -18.0. running mean: -19.03474146145211, timestamp: 2022-08-19 08:31:10.260189\n",
      "resetting env. episode 4679, reward total was -16.0. running mean: -19.00439404683759, timestamp: 2022-08-19 08:31:14.743245\n",
      "resetting env. episode 4680, reward total was -19.0. running mean: -19.004350106369216, timestamp: 2022-08-19 08:31:18.553297\n",
      "resetting env. episode 4681, reward total was -15.0. running mean: -18.964306605305524, timestamp: 2022-08-19 08:31:23.673363\n",
      "resetting env. episode 4682, reward total was -20.0. running mean: -18.974663539252468, timestamp: 2022-08-19 08:31:28.410428\n",
      "resetting env. episode 4683, reward total was -21.0. running mean: -18.994916903859945, timestamp: 2022-08-19 08:31:32.722486\n",
      "resetting env. episode 4684, reward total was -18.0. running mean: -18.984967734821346, timestamp: 2022-08-19 08:31:37.755554\n",
      "resetting env. episode 4685, reward total was -17.0. running mean: -18.965118057473134, timestamp: 2022-08-19 08:31:41.445600\n",
      "resetting env. episode 4686, reward total was -18.0. running mean: -18.955466876898402, timestamp: 2022-08-19 08:31:45.681655\n",
      "resetting env. episode 4687, reward total was -21.0. running mean: -18.97591220812942, timestamp: 2022-08-19 08:31:48.888695\n",
      "resetting env. episode 4688, reward total was -20.0. running mean: -18.986153086048123, timestamp: 2022-08-19 08:31:53.073755\n",
      "resetting env. episode 4689, reward total was -20.0. running mean: -18.996291555187643, timestamp: 2022-08-19 08:31:56.508797\n",
      "resetting env. episode 4690, reward total was -19.0. running mean: -18.996328639635767, timestamp: 2022-08-19 08:32:00.904855\n",
      "resetting env. episode 4691, reward total was -19.0. running mean: -18.996365353239412, timestamp: 2022-08-19 08:32:04.747907\n",
      "resetting env. episode 4692, reward total was -21.0. running mean: -19.016401699707018, timestamp: 2022-08-19 08:32:08.875959\n",
      "resetting env. episode 4693, reward total was -18.0. running mean: -19.006237682709948, timestamp: 2022-08-19 08:32:12.741014\n",
      "resetting env. episode 4694, reward total was -17.0. running mean: -18.98617530588285, timestamp: 2022-08-19 08:32:18.210083\n",
      "resetting env. episode 4695, reward total was -18.0. running mean: -18.97631355282402, timestamp: 2022-08-19 08:32:22.642144\n",
      "resetting env. episode 4696, reward total was -21.0. running mean: -18.99655041729578, timestamp: 2022-08-19 08:32:26.023186\n",
      "resetting env. episode 4697, reward total was -18.0. running mean: -18.986584913122822, timestamp: 2022-08-19 08:32:31.852268\n",
      "resetting env. episode 4698, reward total was -15.0. running mean: -18.946719063991594, timestamp: 2022-08-19 08:32:36.762329\n",
      "resetting env. episode 4699, reward total was -16.0. running mean: -18.917251873351677, timestamp: 2022-08-19 08:32:41.510395\n",
      "resetting env. episode 4700, reward total was -15.0. running mean: -18.87807935461816, timestamp: 2022-08-19 08:32:46.163452\n",
      "resetting env. episode 4701, reward total was -19.0. running mean: -18.879298561071977, timestamp: 2022-08-19 08:32:49.071495\n",
      "resetting env. episode 4702, reward total was -21.0. running mean: -18.900505575461256, timestamp: 2022-08-19 08:32:53.309548\n",
      "resetting env. episode 4703, reward total was -17.0. running mean: -18.881500519706645, timestamp: 2022-08-19 08:32:57.225598\n",
      "resetting env. episode 4704, reward total was -17.0. running mean: -18.86268551450958, timestamp: 2022-08-19 08:33:02.164667\n",
      "resetting env. episode 4705, reward total was -17.0. running mean: -18.844058659364485, timestamp: 2022-08-19 08:33:07.230731\n",
      "resetting env. episode 4706, reward total was -19.0. running mean: -18.84561807277084, timestamp: 2022-08-19 08:33:11.173786\n",
      "resetting env. episode 4707, reward total was -17.0. running mean: -18.827161892043133, timestamp: 2022-08-19 08:33:16.461853\n",
      "resetting env. episode 4708, reward total was -18.0. running mean: -18.8188902731227, timestamp: 2022-08-19 08:33:19.917901\n",
      "resetting env. episode 4709, reward total was -20.0. running mean: -18.830701370391473, timestamp: 2022-08-19 08:33:24.032953\n",
      "resetting env. episode 4710, reward total was -20.0. running mean: -18.842394356687556, timestamp: 2022-08-19 08:33:27.041995\n",
      "resetting env. episode 4711, reward total was -19.0. running mean: -18.843970413120683, timestamp: 2022-08-19 08:33:31.244046\n",
      "resetting env. episode 4712, reward total was -17.0. running mean: -18.82553070898948, timestamp: 2022-08-19 08:33:36.060110\n",
      "resetting env. episode 4713, reward total was -18.0. running mean: -18.817275401899582, timestamp: 2022-08-19 08:33:41.335180\n",
      "resetting env. episode 4714, reward total was -21.0. running mean: -18.839102647880587, timestamp: 2022-08-19 08:33:44.980227\n",
      "resetting env. episode 4715, reward total was -20.0. running mean: -18.85071162140178, timestamp: 2022-08-19 08:33:49.354289\n",
      "resetting env. episode 4716, reward total was -20.0. running mean: -18.86220450518776, timestamp: 2022-08-19 08:33:53.935349\n",
      "resetting env. episode 4717, reward total was -19.0. running mean: -18.86358246013588, timestamp: 2022-08-19 08:33:57.972397\n",
      "resetting env. episode 4718, reward total was -21.0. running mean: -18.884946635534522, timestamp: 2022-08-19 08:34:01.618452\n",
      "resetting env. episode 4719, reward total was -18.0. running mean: -18.876097169179175, timestamp: 2022-08-19 08:34:05.842501\n",
      "resetting env. episode 4720, reward total was -19.0. running mean: -18.877336197487384, timestamp: 2022-08-19 08:34:09.795552\n",
      "resetting env. episode 4721, reward total was -21.0. running mean: -18.89856283551251, timestamp: 2022-08-19 08:34:13.617601\n",
      "resetting env. episode 4722, reward total was -19.0. running mean: -18.899577207157385, timestamp: 2022-08-19 08:34:19.410678\n",
      "resetting env. episode 4723, reward total was -21.0. running mean: -18.92058143508581, timestamp: 2022-08-19 08:34:24.112740\n",
      "resetting env. episode 4724, reward total was -19.0. running mean: -18.921375620734953, timestamp: 2022-08-19 08:34:28.788799\n",
      "resetting env. episode 4725, reward total was -19.0. running mean: -18.922161864527606, timestamp: 2022-08-19 08:34:32.670855\n",
      "resetting env. episode 4726, reward total was -21.0. running mean: -18.94294024588233, timestamp: 2022-08-19 08:34:36.200902\n",
      "resetting env. episode 4727, reward total was -16.0. running mean: -18.913510843423506, timestamp: 2022-08-19 08:34:40.568954\n",
      "resetting env. episode 4728, reward total was -19.0. running mean: -18.91437573498927, timestamp: 2022-08-19 08:34:44.761014\n",
      "resetting env. episode 4729, reward total was -21.0. running mean: -18.93523197763938, timestamp: 2022-08-19 08:34:48.244055\n",
      "resetting env. episode 4730, reward total was -19.0. running mean: -18.935879657862987, timestamp: 2022-08-19 08:34:52.522111\n",
      "resetting env. episode 4731, reward total was -19.0. running mean: -18.936520861284357, timestamp: 2022-08-19 08:34:56.154159\n",
      "resetting env. episode 4732, reward total was -18.0. running mean: -18.927155652671512, timestamp: 2022-08-19 08:35:00.283210\n",
      "resetting env. episode 4733, reward total was -17.0. running mean: -18.907884096144798, timestamp: 2022-08-19 08:35:04.027261\n",
      "resetting env. episode 4734, reward total was -19.0. running mean: -18.908805255183353, timestamp: 2022-08-19 08:35:09.627333\n",
      "resetting env. episode 4735, reward total was -18.0. running mean: -18.899717202631518, timestamp: 2022-08-19 08:35:13.152383\n",
      "resetting env. episode 4736, reward total was -19.0. running mean: -18.900720030605203, timestamp: 2022-08-19 08:35:17.182431\n",
      "resetting env. episode 4737, reward total was -21.0. running mean: -18.921712830299153, timestamp: 2022-08-19 08:35:20.369476\n",
      "resetting env. episode 4738, reward total was -21.0. running mean: -18.94249570199616, timestamp: 2022-08-19 08:35:24.387526\n",
      "resetting env. episode 4739, reward total was -16.0. running mean: -18.9130707449762, timestamp: 2022-08-19 08:35:28.533578\n",
      "resetting env. episode 4740, reward total was -20.0. running mean: -18.923940037526435, timestamp: 2022-08-19 08:35:32.562634\n",
      "resetting env. episode 4741, reward total was -18.0. running mean: -18.91470063715117, timestamp: 2022-08-19 08:35:37.186694\n",
      "resetting env. episode 4742, reward total was -19.0. running mean: -18.91555363077966, timestamp: 2022-08-19 08:35:41.614750\n",
      "resetting env. episode 4743, reward total was -17.0. running mean: -18.896398094471863, timestamp: 2022-08-19 08:35:45.846803\n",
      "resetting env. episode 4744, reward total was -19.0. running mean: -18.897434113527144, timestamp: 2022-08-19 08:35:49.081849\n",
      "resetting env. episode 4745, reward total was -18.0. running mean: -18.888459772391872, timestamp: 2022-08-19 08:35:52.538890\n",
      "resetting env. episode 4746, reward total was -19.0. running mean: -18.889575174667954, timestamp: 2022-08-19 08:35:56.761949\n",
      "resetting env. episode 4747, reward total was -18.0. running mean: -18.880679422921272, timestamp: 2022-08-19 08:36:00.343992\n",
      "resetting env. episode 4748, reward total was -19.0. running mean: -18.88187262869206, timestamp: 2022-08-19 08:36:04.140042\n",
      "resetting env. episode 4749, reward total was -20.0. running mean: -18.89305390240514, timestamp: 2022-08-19 08:36:07.785087\n",
      "resetting env. episode 4750, reward total was -20.0. running mean: -18.904123363381085, timestamp: 2022-08-19 08:36:10.994128\n",
      "resetting env. episode 4751, reward total was -19.0. running mean: -18.905082129747274, timestamp: 2022-08-19 08:36:15.545190\n",
      "resetting env. episode 4752, reward total was -19.0. running mean: -18.9060313084498, timestamp: 2022-08-19 08:36:19.859245\n",
      "resetting env. episode 4753, reward total was -18.0. running mean: -18.896970995365304, timestamp: 2022-08-19 08:36:23.705295\n",
      "resetting env. episode 4754, reward total was -18.0. running mean: -18.88800128541165, timestamp: 2022-08-19 08:36:27.794348\n",
      "resetting env. episode 4755, reward total was -18.0. running mean: -18.879121272557533, timestamp: 2022-08-19 08:36:31.320395\n",
      "resetting env. episode 4756, reward total was -21.0. running mean: -18.90033005983196, timestamp: 2022-08-19 08:36:34.833435\n",
      "resetting env. episode 4757, reward total was -16.0. running mean: -18.87132675923364, timestamp: 2022-08-19 08:36:39.755773\n",
      "resetting env. episode 4758, reward total was -19.0. running mean: -18.872613491641303, timestamp: 2022-08-19 08:36:44.715841\n",
      "resetting env. episode 4759, reward total was -20.0. running mean: -18.883887356724887, timestamp: 2022-08-19 08:36:49.052896\n",
      "resetting env. episode 4760, reward total was -18.0. running mean: -18.875048483157638, timestamp: 2022-08-19 08:36:52.792943\n",
      "resetting env. episode 4761, reward total was -18.0. running mean: -18.86629799832606, timestamp: 2022-08-19 08:36:57.507001\n",
      "resetting env. episode 4762, reward total was -18.0. running mean: -18.8576350183428, timestamp: 2022-08-19 08:37:02.250064\n",
      "resetting env. episode 4763, reward total was -16.0. running mean: -18.829058668159373, timestamp: 2022-08-19 08:37:06.402116\n",
      "resetting env. episode 4764, reward total was -18.0. running mean: -18.82076808147778, timestamp: 2022-08-19 08:37:11.669189\n",
      "resetting env. episode 4765, reward total was -21.0. running mean: -18.842560400663004, timestamp: 2022-08-19 08:37:15.243228\n",
      "resetting env. episode 4766, reward total was -20.0. running mean: -18.85413479665637, timestamp: 2022-08-19 08:37:20.093293\n",
      "resetting env. episode 4767, reward total was -21.0. running mean: -18.87559344868981, timestamp: 2022-08-19 08:37:24.394346\n",
      "resetting env. episode 4768, reward total was -18.0. running mean: -18.86683751420291, timestamp: 2022-08-19 08:37:28.210398\n",
      "resetting env. episode 4769, reward total was -18.0. running mean: -18.85816913906088, timestamp: 2022-08-19 08:37:32.153449\n",
      "resetting env. episode 4770, reward total was -19.0. running mean: -18.859587447670272, timestamp: 2022-08-19 08:37:35.886494\n",
      "resetting env. episode 4771, reward total was -21.0. running mean: -18.88099157319357, timestamp: 2022-08-19 08:37:40.023547\n",
      "resetting env. episode 4772, reward total was -20.0. running mean: -18.89218165746163, timestamp: 2022-08-19 08:37:44.654605\n",
      "resetting env. episode 4773, reward total was -17.0. running mean: -18.873259840887016, timestamp: 2022-08-19 08:37:48.325652\n",
      "resetting env. episode 4774, reward total was -21.0. running mean: -18.894527242478148, timestamp: 2022-08-19 08:37:52.565710\n",
      "resetting env. episode 4775, reward total was -19.0. running mean: -18.895581970053367, timestamp: 2022-08-19 08:37:56.675758\n",
      "resetting env. episode 4776, reward total was -20.0. running mean: -18.90662615035283, timestamp: 2022-08-19 08:38:00.227805\n",
      "resetting env. episode 4777, reward total was -21.0. running mean: -18.927559888849306, timestamp: 2022-08-19 08:38:03.475849\n",
      "resetting env. episode 4778, reward total was -20.0. running mean: -18.938284289960812, timestamp: 2022-08-19 08:38:07.421900\n",
      "resetting env. episode 4779, reward total was -20.0. running mean: -18.948901447061203, timestamp: 2022-08-19 08:38:12.691965\n",
      "resetting env. episode 4780, reward total was -18.0. running mean: -18.93941243259059, timestamp: 2022-08-19 08:38:17.022539\n",
      "resetting env. episode 4781, reward total was -19.0. running mean: -18.940018308264687, timestamp: 2022-08-19 08:38:21.779599\n",
      "resetting env. episode 4782, reward total was -20.0. running mean: -18.95061812518204, timestamp: 2022-08-19 08:38:25.589649\n",
      "resetting env. episode 4783, reward total was -21.0. running mean: -18.971111943930218, timestamp: 2022-08-19 08:38:28.154680\n",
      "resetting env. episode 4784, reward total was -18.0. running mean: -18.961400824490916, timestamp: 2022-08-19 08:38:31.949728\n",
      "resetting env. episode 4785, reward total was -18.0. running mean: -18.951786816246006, timestamp: 2022-08-19 08:38:36.635787\n",
      "resetting env. episode 4786, reward total was -19.0. running mean: -18.952268948083546, timestamp: 2022-08-19 08:38:40.254834\n",
      "resetting env. episode 4787, reward total was -19.0. running mean: -18.952746258602712, timestamp: 2022-08-19 08:38:44.231886\n",
      "resetting env. episode 4788, reward total was -20.0. running mean: -18.963218796016683, timestamp: 2022-08-19 08:38:49.650480\n",
      "resetting env. episode 4789, reward total was -20.0. running mean: -18.973586608056515, timestamp: 2022-08-19 08:38:54.250537\n",
      "resetting env. episode 4790, reward total was -21.0. running mean: -18.99385074197595, timestamp: 2022-08-19 08:38:58.516592\n",
      "resetting env. episode 4791, reward total was -18.0. running mean: -18.98391223455619, timestamp: 2022-08-19 08:39:03.304203\n",
      "resetting env. episode 4792, reward total was -17.0. running mean: -18.96407311221063, timestamp: 2022-08-19 08:39:07.925260\n",
      "resetting env. episode 4793, reward total was -21.0. running mean: -18.984432381088524, timestamp: 2022-08-19 08:39:11.622307\n",
      "resetting env. episode 4794, reward total was -21.0. running mean: -19.00458805727764, timestamp: 2022-08-19 08:39:16.223370\n",
      "resetting env. episode 4795, reward total was -21.0. running mean: -19.024542176704866, timestamp: 2022-08-19 08:39:21.172428\n",
      "resetting env. episode 4796, reward total was -21.0. running mean: -19.044296754937818, timestamp: 2022-08-19 08:39:24.918474\n",
      "resetting env. episode 4797, reward total was -18.0. running mean: -19.03385378738844, timestamp: 2022-08-19 08:39:28.663527\n",
      "resetting env. episode 4798, reward total was -19.0. running mean: -19.033515249514558, timestamp: 2022-08-19 08:39:33.476582\n",
      "resetting env. episode 4799, reward total was -19.0. running mean: -19.033180097019414, timestamp: 2022-08-19 08:39:37.599632\n",
      "resetting env. episode 4800, reward total was -21.0. running mean: -19.05284829604922, timestamp: 2022-08-19 08:39:41.536683\n",
      "resetting env. episode 4801, reward total was -21.0. running mean: -19.07231981308873, timestamp: 2022-08-19 08:39:46.176741\n",
      "resetting env. episode 4802, reward total was -21.0. running mean: -19.091596614957844, timestamp: 2022-08-19 08:39:49.943320\n",
      "resetting env. episode 4803, reward total was -21.0. running mean: -19.110680648808266, timestamp: 2022-08-19 08:39:54.067376\n",
      "resetting env. episode 4804, reward total was -20.0. running mean: -19.119573842320182, timestamp: 2022-08-19 08:39:58.729435\n",
      "resetting env. episode 4805, reward total was -18.0. running mean: -19.10837810389698, timestamp: 2022-08-19 08:40:03.016487\n",
      "resetting env. episode 4806, reward total was -19.0. running mean: -19.107294322858014, timestamp: 2022-08-19 08:40:07.018534\n",
      "resetting env. episode 4807, reward total was -21.0. running mean: -19.126221379629435, timestamp: 2022-08-19 08:40:11.386593\n",
      "resetting env. episode 4808, reward total was -20.0. running mean: -19.134959165833138, timestamp: 2022-08-19 08:40:15.138636\n",
      "resetting env. episode 4809, reward total was -18.0. running mean: -19.123609574174807, timestamp: 2022-08-19 08:40:19.066685\n",
      "resetting env. episode 4810, reward total was -21.0. running mean: -19.14237347843306, timestamp: 2022-08-19 08:40:24.053748\n",
      "resetting env. episode 4811, reward total was -18.0. running mean: -19.13094974364873, timestamp: 2022-08-19 08:40:28.139801\n",
      "resetting env. episode 4812, reward total was -19.0. running mean: -19.129640246212244, timestamp: 2022-08-19 08:40:32.640852\n",
      "resetting env. episode 4813, reward total was -20.0. running mean: -19.13834384375012, timestamp: 2022-08-19 08:40:35.897895\n",
      "resetting env. episode 4814, reward total was -19.0. running mean: -19.13696040531262, timestamp: 2022-08-19 08:40:40.929957\n",
      "resetting env. episode 4815, reward total was -20.0. running mean: -19.145590801259495, timestamp: 2022-08-19 08:40:44.089997\n",
      "resetting env. episode 4816, reward total was -18.0. running mean: -19.134134893246898, timestamp: 2022-08-19 08:40:48.401046\n",
      "resetting env. episode 4817, reward total was -18.0. running mean: -19.12279354431443, timestamp: 2022-08-19 08:40:53.430109\n",
      "resetting env. episode 4818, reward total was -19.0. running mean: -19.121565608871286, timestamp: 2022-08-19 08:40:57.806164\n",
      "resetting env. episode 4819, reward total was -17.0. running mean: -19.100349952782576, timestamp: 2022-08-19 08:41:03.166229\n",
      "resetting env. episode 4820, reward total was -21.0. running mean: -19.11934645325475, timestamp: 2022-08-19 08:41:07.799284\n",
      "resetting env. episode 4821, reward total was -21.0. running mean: -19.138152988722204, timestamp: 2022-08-19 08:41:11.769336\n",
      "resetting env. episode 4822, reward total was -19.0. running mean: -19.136771458834982, timestamp: 2022-08-19 08:41:15.391377\n",
      "resetting env. episode 4823, reward total was -17.0. running mean: -19.115403744246635, timestamp: 2022-08-19 08:41:19.433427\n",
      "resetting env. episode 4824, reward total was -21.0. running mean: -19.13424970680417, timestamp: 2022-08-19 08:41:23.517477\n",
      "resetting env. episode 4825, reward total was -21.0. running mean: -19.152907209736128, timestamp: 2022-08-19 08:41:26.796518\n",
      "resetting env. episode 4826, reward total was -19.0. running mean: -19.15137813763877, timestamp: 2022-08-19 08:41:31.118575\n",
      "resetting env. episode 4827, reward total was -18.0. running mean: -19.139864356262382, timestamp: 2022-08-19 08:41:36.027630\n",
      "resetting env. episode 4828, reward total was -20.0. running mean: -19.148465712699757, timestamp: 2022-08-19 08:41:39.998676\n",
      "resetting env. episode 4829, reward total was -16.0. running mean: -19.116981055572758, timestamp: 2022-08-19 08:41:44.581734\n",
      "resetting env. episode 4830, reward total was -18.0. running mean: -19.10581124501703, timestamp: 2022-08-19 08:41:49.194789\n",
      "resetting env. episode 4831, reward total was -19.0. running mean: -19.10475313256686, timestamp: 2022-08-19 08:41:53.377839\n",
      "resetting env. episode 4832, reward total was -19.0. running mean: -19.10370560124119, timestamp: 2022-08-19 08:41:58.041896\n",
      "resetting env. episode 4833, reward total was -17.0. running mean: -19.08266854522878, timestamp: 2022-08-19 08:42:03.157959\n",
      "resetting env. episode 4834, reward total was -15.0. running mean: -19.041841859776493, timestamp: 2022-08-19 08:42:08.851031\n",
      "resetting env. episode 4835, reward total was -18.0. running mean: -19.031423441178728, timestamp: 2022-08-19 08:42:12.915080\n",
      "resetting env. episode 4836, reward total was -18.0. running mean: -19.02110920676694, timestamp: 2022-08-19 08:42:17.414131\n",
      "resetting env. episode 4837, reward total was -15.0. running mean: -18.98089811469927, timestamp: 2022-08-19 08:42:22.216190\n",
      "resetting env. episode 4838, reward total was -17.0. running mean: -18.961089133552278, timestamp: 2022-08-19 08:42:27.610785\n",
      "resetting env. episode 4839, reward total was -19.0. running mean: -18.961478242216756, timestamp: 2022-08-19 08:42:31.290833\n",
      "resetting env. episode 4840, reward total was -21.0. running mean: -18.98186345979459, timestamp: 2022-08-19 08:42:36.443893\n",
      "resetting env. episode 4841, reward total was -19.0. running mean: -18.982044825196645, timestamp: 2022-08-19 08:42:40.018433\n",
      "resetting env. episode 4842, reward total was -19.0. running mean: -18.98222437694468, timestamp: 2022-08-19 08:42:43.714482\n",
      "resetting env. episode 4843, reward total was -19.0. running mean: -18.98240213317523, timestamp: 2022-08-19 08:42:48.099534\n",
      "resetting env. episode 4844, reward total was -21.0. running mean: -19.00257811184348, timestamp: 2022-08-19 08:42:52.137583\n",
      "resetting env. episode 4845, reward total was -19.0. running mean: -19.002552330725045, timestamp: 2022-08-19 08:42:55.878628\n",
      "resetting env. episode 4846, reward total was -21.0. running mean: -19.022526807417794, timestamp: 2022-08-19 08:42:59.590673\n",
      "resetting env. episode 4847, reward total was -17.0. running mean: -19.002301539343616, timestamp: 2022-08-19 08:43:04.041723\n",
      "resetting env. episode 4848, reward total was -20.0. running mean: -19.01227852395018, timestamp: 2022-08-19 08:43:09.284787\n",
      "resetting env. episode 4849, reward total was -17.0. running mean: -18.99215573871068, timestamp: 2022-08-19 08:43:13.768841\n",
      "resetting env. episode 4850, reward total was -19.0. running mean: -18.992234181323575, timestamp: 2022-08-19 08:43:17.899888\n",
      "resetting env. episode 4851, reward total was -18.0. running mean: -18.982311839510338, timestamp: 2022-08-19 08:43:22.972951\n",
      "resetting env. episode 4852, reward total was -21.0. running mean: -19.002488721115235, timestamp: 2022-08-19 08:43:26.515992\n",
      "resetting env. episode 4853, reward total was -20.0. running mean: -19.012463833904082, timestamp: 2022-08-19 08:43:30.274037\n",
      "resetting env. episode 4854, reward total was -19.0. running mean: -19.012339195565044, timestamp: 2022-08-19 08:43:34.067083\n",
      "resetting env. episode 4855, reward total was -19.0. running mean: -19.012215803609394, timestamp: 2022-08-19 08:43:39.164145\n",
      "resetting env. episode 4856, reward total was -17.0. running mean: -18.992093645573302, timestamp: 2022-08-19 08:43:43.114194\n",
      "resetting env. episode 4857, reward total was -18.0. running mean: -18.98217270911757, timestamp: 2022-08-19 08:43:48.363258\n",
      "resetting env. episode 4858, reward total was -17.0. running mean: -18.962350982026397, timestamp: 2022-08-19 08:43:52.626316\n",
      "resetting env. episode 4859, reward total was -18.0. running mean: -18.95272747220613, timestamp: 2022-08-19 08:43:56.783361\n",
      "resetting env. episode 4860, reward total was -21.0. running mean: -18.973200197484072, timestamp: 2022-08-19 08:43:59.958400\n",
      "resetting env. episode 4861, reward total was -20.0. running mean: -18.983468195509232, timestamp: 2022-08-19 08:44:04.448457\n",
      "resetting env. episode 4862, reward total was -14.0. running mean: -18.933633513554142, timestamp: 2022-08-19 08:44:10.386530\n",
      "resetting env. episode 4863, reward total was -20.0. running mean: -18.944297178418598, timestamp: 2022-08-19 08:44:14.943584\n",
      "resetting env. episode 4864, reward total was -17.0. running mean: -18.924854206634414, timestamp: 2022-08-19 08:44:19.986647\n",
      "resetting env. episode 4865, reward total was -21.0. running mean: -18.94560566456807, timestamp: 2022-08-19 08:44:23.036686\n",
      "resetting env. episode 4866, reward total was -19.0. running mean: -18.94614960792239, timestamp: 2022-08-19 08:44:27.348738\n",
      "resetting env. episode 4867, reward total was -18.0. running mean: -18.936688111843164, timestamp: 2022-08-19 08:44:31.832797\n",
      "resetting env. episode 4868, reward total was -19.0. running mean: -18.937321230724734, timestamp: 2022-08-19 08:44:35.267837\n",
      "resetting env. episode 4869, reward total was -18.0. running mean: -18.927948018417485, timestamp: 2022-08-19 08:44:39.944898\n",
      "resetting env. episode 4870, reward total was -19.0. running mean: -18.92866853823331, timestamp: 2022-08-19 08:44:44.085945\n",
      "resetting env. episode 4871, reward total was -19.0. running mean: -18.929381852850977, timestamp: 2022-08-19 08:44:49.186010\n",
      "resetting env. episode 4872, reward total was -21.0. running mean: -18.95008803432247, timestamp: 2022-08-19 08:44:52.470050\n",
      "resetting env. episode 4873, reward total was -20.0. running mean: -18.960587153979244, timestamp: 2022-08-19 08:44:55.872093\n",
      "resetting env. episode 4874, reward total was -17.0. running mean: -18.940981282439452, timestamp: 2022-08-19 08:45:00.742161\n",
      "resetting env. episode 4875, reward total was -21.0. running mean: -18.96157146961506, timestamp: 2022-08-19 08:45:04.212199\n",
      "resetting env. episode 4876, reward total was -19.0. running mean: -18.96195575491891, timestamp: 2022-08-19 08:45:08.348249\n",
      "resetting env. episode 4877, reward total was -20.0. running mean: -18.97233619736972, timestamp: 2022-08-19 08:45:11.568289\n",
      "resetting env. episode 4878, reward total was -17.0. running mean: -18.952612835396025, timestamp: 2022-08-19 08:45:16.070351\n",
      "resetting env. episode 4879, reward total was -17.0. running mean: -18.933086707042065, timestamp: 2022-08-19 08:45:22.083423\n",
      "resetting env. episode 4880, reward total was -21.0. running mean: -18.953755839971645, timestamp: 2022-08-19 08:45:26.162474\n",
      "resetting env. episode 4881, reward total was -21.0. running mean: -18.97421828157193, timestamp: 2022-08-19 08:45:30.622533\n",
      "resetting env. episode 4882, reward total was -16.0. running mean: -18.94447609875621, timestamp: 2022-08-19 08:45:35.239592\n",
      "resetting env. episode 4883, reward total was -20.0. running mean: -18.955031337768645, timestamp: 2022-08-19 08:45:39.370640\n",
      "resetting env. episode 4884, reward total was -21.0. running mean: -18.97548102439096, timestamp: 2022-08-19 08:45:44.298704\n",
      "resetting env. episode 4885, reward total was -21.0. running mean: -18.99572621414705, timestamp: 2022-08-19 08:45:48.613756\n",
      "resetting env. episode 4886, reward total was -20.0. running mean: -19.00576895200558, timestamp: 2022-08-19 08:45:53.671823\n",
      "resetting env. episode 4887, reward total was -19.0. running mean: -19.005711262485526, timestamp: 2022-08-19 08:45:58.444165\n",
      "resetting env. episode 4888, reward total was -19.0. running mean: -19.00565414986067, timestamp: 2022-08-19 08:46:03.563230\n",
      "resetting env. episode 4889, reward total was -20.0. running mean: -19.015597608362064, timestamp: 2022-08-19 08:46:08.111291\n",
      "resetting env. episode 4890, reward total was -19.0. running mean: -19.015441632278446, timestamp: 2022-08-19 08:46:12.879347\n",
      "resetting env. episode 4891, reward total was -19.0. running mean: -19.015287215955663, timestamp: 2022-08-19 08:46:17.822412\n",
      "resetting env. episode 4892, reward total was -19.0. running mean: -19.015134343796106, timestamp: 2022-08-19 08:46:21.716463\n",
      "resetting env. episode 4893, reward total was -18.0. running mean: -19.004983000358145, timestamp: 2022-08-19 08:46:25.975518\n",
      "resetting env. episode 4894, reward total was -21.0. running mean: -19.024933170354565, timestamp: 2022-08-19 08:46:30.123570\n",
      "resetting env. episode 4895, reward total was -18.0. running mean: -19.01468383865102, timestamp: 2022-08-19 08:46:34.201620\n",
      "resetting env. episode 4896, reward total was -19.0. running mean: -19.01453700026451, timestamp: 2022-08-19 08:46:38.753684\n",
      "resetting env. episode 4897, reward total was -18.0. running mean: -19.004391630261864, timestamp: 2022-08-19 08:46:43.901744\n",
      "resetting env. episode 4898, reward total was -20.0. running mean: -19.014347713959246, timestamp: 2022-08-19 08:46:47.895797\n",
      "resetting env. episode 4899, reward total was -16.0. running mean: -18.984204236819654, timestamp: 2022-08-19 08:46:53.288866\n",
      "resetting env. episode 4900, reward total was -18.0. running mean: -18.974362194451455, timestamp: 2022-08-19 08:46:58.267931\n",
      "resetting env. episode 4901, reward total was -18.0. running mean: -18.96461857250694, timestamp: 2022-08-19 08:47:03.143995\n",
      "resetting env. episode 4902, reward total was -19.0. running mean: -18.96497238678187, timestamp: 2022-08-19 08:47:07.507048\n",
      "resetting env. episode 4903, reward total was -16.0. running mean: -18.93532266291405, timestamp: 2022-08-19 08:47:12.024110\n",
      "resetting env. episode 4904, reward total was -15.0. running mean: -18.895969436284908, timestamp: 2022-08-19 08:47:16.146165\n",
      "resetting env. episode 4905, reward total was -20.0. running mean: -18.907009741922057, timestamp: 2022-08-19 08:47:19.622211\n",
      "resetting env. episode 4906, reward total was -17.0. running mean: -18.887939644502836, timestamp: 2022-08-19 08:47:23.976265\n",
      "resetting env. episode 4907, reward total was -20.0. running mean: -18.899060248057808, timestamp: 2022-08-19 08:47:28.220318\n",
      "resetting env. episode 4908, reward total was -21.0. running mean: -18.92006964557723, timestamp: 2022-08-19 08:47:31.942366\n",
      "resetting env. episode 4909, reward total was -18.0. running mean: -18.910868949121458, timestamp: 2022-08-19 08:47:36.567426\n",
      "resetting env. episode 4910, reward total was -17.0. running mean: -18.891760259630246, timestamp: 2022-08-19 08:47:40.259472\n",
      "resetting env. episode 4911, reward total was -17.0. running mean: -18.872842657033946, timestamp: 2022-08-19 08:47:45.090533\n",
      "resetting env. episode 4912, reward total was -21.0. running mean: -18.894114230463607, timestamp: 2022-08-19 08:47:48.994463\n",
      "resetting env. episode 4913, reward total was -17.0. running mean: -18.875173088158974, timestamp: 2022-08-19 08:47:53.747526\n",
      "resetting env. episode 4914, reward total was -21.0. running mean: -18.896421357277383, timestamp: 2022-08-19 08:47:57.643580\n",
      "resetting env. episode 4915, reward total was -18.0. running mean: -18.88745714370461, timestamp: 2022-08-19 08:48:01.625629\n",
      "resetting env. episode 4916, reward total was -20.0. running mean: -18.89858257226756, timestamp: 2022-08-19 08:48:05.818679\n",
      "resetting env. episode 4917, reward total was -19.0. running mean: -18.899596746544887, timestamp: 2022-08-19 08:48:10.259739\n",
      "resetting env. episode 4918, reward total was -20.0. running mean: -18.910600779079438, timestamp: 2022-08-19 08:48:13.423777\n",
      "resetting env. episode 4919, reward total was -17.0. running mean: -18.891494771288645, timestamp: 2022-08-19 08:48:19.234853\n",
      "resetting env. episode 4920, reward total was -20.0. running mean: -18.902579823575756, timestamp: 2022-08-19 08:48:23.784911\n",
      "resetting env. episode 4921, reward total was -19.0. running mean: -18.90355402534, timestamp: 2022-08-19 08:48:27.757963\n",
      "resetting env. episode 4922, reward total was -19.0. running mean: -18.9045184850866, timestamp: 2022-08-19 08:48:31.646015\n",
      "resetting env. episode 4923, reward total was -17.0. running mean: -18.885473300235738, timestamp: 2022-08-19 08:48:35.810065\n",
      "resetting env. episode 4924, reward total was -21.0. running mean: -18.90661856723338, timestamp: 2022-08-19 08:48:39.759117\n",
      "resetting env. episode 4925, reward total was -19.0. running mean: -18.907552381561047, timestamp: 2022-08-19 08:48:44.665180\n",
      "resetting env. episode 4926, reward total was -17.0. running mean: -18.888476857745438, timestamp: 2022-08-19 08:48:48.164225\n",
      "resetting env. episode 4927, reward total was -17.0. running mean: -18.869592089167984, timestamp: 2022-08-19 08:48:53.228290\n",
      "resetting env. episode 4928, reward total was -15.0. running mean: -18.830896168276304, timestamp: 2022-08-19 08:48:58.065357\n",
      "resetting env. episode 4929, reward total was -21.0. running mean: -18.85258720659354, timestamp: 2022-08-19 08:49:01.935408\n",
      "resetting env. episode 4930, reward total was -19.0. running mean: -18.854061334527607, timestamp: 2022-08-19 08:49:05.986455\n",
      "resetting env. episode 4931, reward total was -20.0. running mean: -18.86552072118233, timestamp: 2022-08-19 08:49:10.495519\n",
      "resetting env. episode 4932, reward total was -21.0. running mean: -18.88686551397051, timestamp: 2022-08-19 08:49:15.216576\n",
      "resetting env. episode 4933, reward total was -21.0. running mean: -18.907996858830806, timestamp: 2022-08-19 08:49:19.922639\n",
      "resetting env. episode 4934, reward total was -20.0. running mean: -18.918916890242496, timestamp: 2022-08-19 08:49:23.865686\n",
      "resetting env. episode 4935, reward total was -19.0. running mean: -18.919727721340074, timestamp: 2022-08-19 08:49:28.662751\n",
      "resetting env. episode 4936, reward total was -20.0. running mean: -18.93053044412667, timestamp: 2022-08-19 08:49:34.121819\n",
      "resetting env. episode 4937, reward total was -18.0. running mean: -18.921225139685404, timestamp: 2022-08-19 08:49:39.066885\n",
      "resetting env. episode 4938, reward total was -17.0. running mean: -18.902012888288553, timestamp: 2022-08-19 08:49:43.735944\n",
      "resetting env. episode 4939, reward total was -16.0. running mean: -18.87299275940567, timestamp: 2022-08-19 08:49:49.137541\n",
      "resetting env. episode 4940, reward total was -19.0. running mean: -18.874262831811613, timestamp: 2022-08-19 08:49:54.089603\n",
      "resetting env. episode 4941, reward total was -19.0. running mean: -18.875520203493497, timestamp: 2022-08-19 08:49:58.372662\n",
      "resetting env. episode 4942, reward total was -17.0. running mean: -18.856765001458562, timestamp: 2022-08-19 08:50:03.216725\n",
      "resetting env. episode 4943, reward total was -18.0. running mean: -18.848197351443975, timestamp: 2022-08-19 08:50:07.597779\n",
      "resetting env. episode 4944, reward total was -21.0. running mean: -18.869715377929538, timestamp: 2022-08-19 08:50:11.525831\n",
      "resetting env. episode 4945, reward total was -20.0. running mean: -18.881018224150242, timestamp: 2022-08-19 08:50:15.507881\n",
      "resetting env. episode 4946, reward total was -14.0. running mean: -18.83220804190874, timestamp: 2022-08-19 08:50:20.424683\n",
      "resetting env. episode 4947, reward total was -19.0. running mean: -18.833885961489653, timestamp: 2022-08-19 08:50:24.488737\n",
      "resetting env. episode 4948, reward total was -19.0. running mean: -18.835547101874756, timestamp: 2022-08-19 08:50:29.003791\n",
      "resetting env. episode 4949, reward total was -18.0. running mean: -18.827191630856007, timestamp: 2022-08-19 08:50:33.511847\n",
      "resetting env. episode 4950, reward total was -19.0. running mean: -18.828919714547446, timestamp: 2022-08-19 08:50:37.805902\n",
      "resetting env. episode 4951, reward total was -18.0. running mean: -18.82063051740197, timestamp: 2022-08-19 08:50:42.726965\n",
      "resetting env. episode 4952, reward total was -20.0. running mean: -18.83242421222795, timestamp: 2022-08-19 08:50:46.463014\n",
      "resetting env. episode 4953, reward total was -17.0. running mean: -18.81409997010567, timestamp: 2022-08-19 08:50:51.825082\n",
      "resetting env. episode 4954, reward total was -20.0. running mean: -18.82595897040461, timestamp: 2022-08-19 08:50:56.675146\n",
      "resetting env. episode 4955, reward total was -21.0. running mean: -18.847699380700565, timestamp: 2022-08-19 08:51:00.938203\n",
      "resetting env. episode 4956, reward total was -17.0. running mean: -18.829222386893562, timestamp: 2022-08-19 08:51:05.615261\n",
      "resetting env. episode 4957, reward total was -19.0. running mean: -18.83093016302463, timestamp: 2022-08-19 08:51:08.680299\n",
      "resetting env. episode 4958, reward total was -17.0. running mean: -18.812620861394382, timestamp: 2022-08-19 08:51:13.432360\n",
      "resetting env. episode 4959, reward total was -20.0. running mean: -18.824494652780437, timestamp: 2022-08-19 08:51:18.064419\n",
      "resetting env. episode 4960, reward total was -16.0. running mean: -18.796249706252635, timestamp: 2022-08-19 08:51:22.509474\n",
      "resetting env. episode 4961, reward total was -19.0. running mean: -18.79828720919011, timestamp: 2022-08-19 08:51:26.123521\n",
      "resetting env. episode 4962, reward total was -19.0. running mean: -18.80030433709821, timestamp: 2022-08-19 08:51:30.435577\n",
      "resetting env. episode 4963, reward total was -20.0. running mean: -18.812301293727227, timestamp: 2022-08-19 08:51:34.200626\n",
      "resetting env. episode 4964, reward total was -19.0. running mean: -18.814178280789957, timestamp: 2022-08-19 08:51:38.534681\n",
      "resetting env. episode 4965, reward total was -18.0. running mean: -18.806036497982056, timestamp: 2022-08-19 08:51:43.202746\n",
      "resetting env. episode 4966, reward total was -20.0. running mean: -18.817976133002233, timestamp: 2022-08-19 08:51:47.373795\n",
      "resetting env. episode 4967, reward total was -18.0. running mean: -18.80979637167221, timestamp: 2022-08-19 08:51:51.930856\n",
      "resetting env. episode 4968, reward total was -21.0. running mean: -18.83169840795549, timestamp: 2022-08-19 08:51:56.565910\n",
      "resetting env. episode 4969, reward total was -19.0. running mean: -18.833381423875935, timestamp: 2022-08-19 08:52:00.229960\n",
      "resetting env. episode 4970, reward total was -17.0. running mean: -18.815047609637176, timestamp: 2022-08-19 08:52:04.953016\n",
      "resetting env. episode 4971, reward total was -20.0. running mean: -18.826897133540804, timestamp: 2022-08-19 08:52:08.694065\n",
      "resetting env. episode 4972, reward total was -19.0. running mean: -18.828628162205398, timestamp: 2022-08-19 08:52:12.805116\n",
      "resetting env. episode 4973, reward total was -21.0. running mean: -18.850341880583343, timestamp: 2022-08-19 08:52:16.923168\n",
      "resetting env. episode 4974, reward total was -18.0. running mean: -18.84183846177751, timestamp: 2022-08-19 08:52:20.979220\n",
      "resetting env. episode 4975, reward total was -20.0. running mean: -18.853420077159733, timestamp: 2022-08-19 08:52:24.292267\n",
      "resetting env. episode 4976, reward total was -20.0. running mean: -18.864885876388133, timestamp: 2022-08-19 08:52:28.741320\n",
      "resetting env. episode 4977, reward total was -18.0. running mean: -18.856237017624252, timestamp: 2022-08-19 08:52:33.568380\n",
      "resetting env. episode 4978, reward total was -19.0. running mean: -18.85767464744801, timestamp: 2022-08-19 08:52:37.836436\n",
      "resetting env. episode 4979, reward total was -21.0. running mean: -18.87909790097353, timestamp: 2022-08-19 08:52:40.384468\n",
      "resetting env. episode 4980, reward total was -18.0. running mean: -18.870306921963795, timestamp: 2022-08-19 08:52:44.492518\n",
      "resetting env. episode 4981, reward total was -21.0. running mean: -18.891603852744158, timestamp: 2022-08-19 08:52:48.757574\n",
      "resetting env. episode 4982, reward total was -18.0. running mean: -18.882687814216716, timestamp: 2022-08-19 08:52:53.983639\n",
      "resetting env. episode 4983, reward total was -19.0. running mean: -18.88386093607455, timestamp: 2022-08-19 08:52:57.729692\n",
      "resetting env. episode 4984, reward total was -20.0. running mean: -18.895022326713804, timestamp: 2022-08-19 08:53:02.650753\n",
      "resetting env. episode 4985, reward total was -19.0. running mean: -18.896072103446667, timestamp: 2022-08-19 08:53:06.220795\n",
      "resetting env. episode 4986, reward total was -16.0. running mean: -18.8671113824122, timestamp: 2022-08-19 08:53:10.523852\n",
      "resetting env. episode 4987, reward total was -18.0. running mean: -18.85844026858808, timestamp: 2022-08-19 08:53:14.623899\n",
      "resetting env. episode 4988, reward total was -17.0. running mean: -18.8398558659022, timestamp: 2022-08-19 08:53:19.660967\n",
      "resetting env. episode 4989, reward total was -21.0. running mean: -18.86145730724318, timestamp: 2022-08-19 08:53:23.439015\n",
      "resetting env. episode 4990, reward total was -20.0. running mean: -18.87284273417075, timestamp: 2022-08-19 08:53:28.017073\n",
      "resetting env. episode 4991, reward total was -18.0. running mean: -18.86411430682904, timestamp: 2022-08-19 08:53:32.819128\n",
      "resetting env. episode 4992, reward total was -21.0. running mean: -18.88547316376075, timestamp: 2022-08-19 08:53:37.205187\n",
      "resetting env. episode 4993, reward total was -20.0. running mean: -18.89661843212314, timestamp: 2022-08-19 08:53:41.518238\n",
      "resetting env. episode 4994, reward total was -17.0. running mean: -18.87765224780191, timestamp: 2022-08-19 08:53:45.788292\n",
      "resetting env. episode 4995, reward total was -17.0. running mean: -18.858875725323895, timestamp: 2022-08-19 08:53:50.176352\n",
      "resetting env. episode 4996, reward total was -17.0. running mean: -18.840286968070657, timestamp: 2022-08-19 08:53:54.571405\n",
      "resetting env. episode 4997, reward total was -21.0. running mean: -18.86188409838995, timestamp: 2022-08-19 08:53:59.136461\n",
      "resetting env. episode 4998, reward total was -18.0. running mean: -18.85326525740605, timestamp: 2022-08-19 08:54:04.016520\n",
      "resetting env. episode 4999, reward total was -20.0. running mean: -18.86473260483199, timestamp: 2022-08-19 08:54:08.166573\n",
      "resetting env. episode 5000, reward total was -19.0. running mean: -18.86608527878367, timestamp: 2022-08-19 08:54:12.867632\n",
      "resetting env. episode 5001, reward total was -18.0. running mean: -18.857424425995834, timestamp: 2022-08-19 08:54:17.755693\n",
      "resetting env. episode 5002, reward total was -19.0. running mean: -18.85885018173588, timestamp: 2022-08-19 08:54:21.657742\n",
      "resetting env. episode 5003, reward total was -18.0. running mean: -18.850261679918518, timestamp: 2022-08-19 08:54:25.115785\n",
      "resetting env. episode 5004, reward total was -20.0. running mean: -18.861759063119333, timestamp: 2022-08-19 08:54:28.762832\n",
      "resetting env. episode 5005, reward total was -21.0. running mean: -18.88314147248814, timestamp: 2022-08-19 08:54:32.759880\n",
      "resetting env. episode 5006, reward total was -20.0. running mean: -18.89431005776326, timestamp: 2022-08-19 08:54:36.477926\n",
      "resetting env. episode 5007, reward total was -20.0. running mean: -18.905366957185628, timestamp: 2022-08-19 08:54:41.109988\n",
      "resetting env. episode 5008, reward total was -18.0. running mean: -18.896313287613772, timestamp: 2022-08-19 08:54:44.381025\n",
      "resetting env. episode 5009, reward total was -18.0. running mean: -18.887350154737632, timestamp: 2022-08-19 08:54:48.863082\n",
      "resetting env. episode 5010, reward total was -15.0. running mean: -18.848476653190254, timestamp: 2022-08-19 08:54:53.639139\n",
      "resetting env. episode 5011, reward total was -19.0. running mean: -18.84999188665835, timestamp: 2022-08-19 08:54:57.459190\n",
      "resetting env. episode 5012, reward total was -18.0. running mean: -18.841491967791768, timestamp: 2022-08-19 08:55:01.901243\n",
      "resetting env. episode 5013, reward total was -18.0. running mean: -18.83307704811385, timestamp: 2022-08-19 08:55:06.478297\n",
      "resetting env. episode 5014, reward total was -20.0. running mean: -18.844746277632712, timestamp: 2022-08-19 08:55:11.009358\n",
      "resetting env. episode 5015, reward total was -20.0. running mean: -18.856298814856384, timestamp: 2022-08-19 08:55:15.042407\n",
      "resetting env. episode 5016, reward total was -17.0. running mean: -18.83773582670782, timestamp: 2022-08-19 08:55:20.069466\n",
      "resetting env. episode 5017, reward total was -19.0. running mean: -18.839358468440743, timestamp: 2022-08-19 08:55:23.373508\n",
      "resetting env. episode 5018, reward total was -20.0. running mean: -18.850964883756333, timestamp: 2022-08-19 08:55:26.842548\n",
      "resetting env. episode 5019, reward total was -21.0. running mean: -18.87245523491877, timestamp: 2022-08-19 08:55:30.498977\n",
      "resetting env. episode 5020, reward total was -18.0. running mean: -18.86373068256958, timestamp: 2022-08-19 08:55:34.785030\n",
      "resetting env. episode 5021, reward total was -18.0. running mean: -18.855093375743884, timestamp: 2022-08-19 08:55:38.650080\n",
      "resetting env. episode 5022, reward total was -19.0. running mean: -18.856542441986445, timestamp: 2022-08-19 08:55:42.551126\n",
      "resetting env. episode 5023, reward total was -20.0. running mean: -18.86797701756658, timestamp: 2022-08-19 08:55:46.765179\n",
      "resetting env. episode 5024, reward total was -20.0. running mean: -18.879297247390912, timestamp: 2022-08-19 08:55:51.261239\n",
      "resetting env. episode 5025, reward total was -19.0. running mean: -18.880504274917005, timestamp: 2022-08-19 08:55:55.197281\n",
      "resetting env. episode 5026, reward total was -19.0. running mean: -18.881699232167836, timestamp: 2022-08-19 08:55:59.613339\n",
      "resetting env. episode 5027, reward total was -19.0. running mean: -18.882882239846158, timestamp: 2022-08-19 08:56:04.790400\n",
      "resetting env. episode 5028, reward total was -20.0. running mean: -18.894053417447694, timestamp: 2022-08-19 08:56:08.277440\n",
      "resetting env. episode 5029, reward total was -18.0. running mean: -18.885112883273216, timestamp: 2022-08-19 08:56:12.104490\n",
      "resetting env. episode 5030, reward total was -20.0. running mean: -18.896261754440484, timestamp: 2022-08-19 08:56:15.380528\n",
      "resetting env. episode 5031, reward total was -21.0. running mean: -18.91729913689608, timestamp: 2022-08-19 08:56:19.596581\n",
      "resetting env. episode 5032, reward total was -19.0. running mean: -18.918126145527122, timestamp: 2022-08-19 08:56:23.319624\n",
      "resetting env. episode 5033, reward total was -19.0. running mean: -18.918944884071852, timestamp: 2022-08-19 08:56:27.110671\n",
      "resetting env. episode 5034, reward total was -17.0. running mean: -18.899755435231135, timestamp: 2022-08-19 08:56:31.728727\n",
      "resetting env. episode 5035, reward total was -18.0. running mean: -18.890757880878823, timestamp: 2022-08-19 08:56:36.292782\n",
      "resetting env. episode 5036, reward total was -20.0. running mean: -18.901850302070034, timestamp: 2022-08-19 08:56:38.935816\n",
      "resetting env. episode 5037, reward total was -18.0. running mean: -18.892831799049333, timestamp: 2022-08-19 08:56:42.370860\n",
      "resetting env. episode 5038, reward total was -19.0. running mean: -18.89390348105884, timestamp: 2022-08-19 08:56:47.150915\n",
      "resetting env. episode 5039, reward total was -17.0. running mean: -18.874964446248253, timestamp: 2022-08-19 08:56:51.782973\n",
      "resetting env. episode 5040, reward total was -20.0. running mean: -18.88621480178577, timestamp: 2022-08-19 08:56:56.326024\n",
      "resetting env. episode 5041, reward total was -19.0. running mean: -18.887352653767913, timestamp: 2022-08-19 08:57:00.233074\n",
      "resetting env. episode 5042, reward total was -18.0. running mean: -18.878479127230232, timestamp: 2022-08-19 08:57:04.285123\n",
      "resetting env. episode 5043, reward total was -19.0. running mean: -18.879694335957932, timestamp: 2022-08-19 08:57:09.025179\n",
      "resetting env. episode 5044, reward total was -19.0. running mean: -18.880897392598353, timestamp: 2022-08-19 08:57:12.956228\n",
      "resetting env. episode 5045, reward total was -17.0. running mean: -18.86208841867237, timestamp: 2022-08-19 08:57:18.237880\n",
      "resetting env. episode 5046, reward total was -21.0. running mean: -18.88346753448565, timestamp: 2022-08-19 08:57:22.583995\n",
      "resetting env. episode 5047, reward total was -20.0. running mean: -18.894632859140792, timestamp: 2022-08-19 08:57:26.763041\n",
      "resetting env. episode 5048, reward total was -19.0. running mean: -18.895686530549384, timestamp: 2022-08-19 08:57:31.397096\n",
      "resetting env. episode 5049, reward total was -19.0. running mean: -18.896729665243893, timestamp: 2022-08-19 08:57:35.425149\n",
      "resetting env. episode 5050, reward total was -19.0. running mean: -18.897762368591454, timestamp: 2022-08-19 08:57:40.105200\n",
      "resetting env. episode 5051, reward total was -18.0. running mean: -18.88878474490554, timestamp: 2022-08-19 08:57:44.873257\n",
      "resetting env. episode 5052, reward total was -20.0. running mean: -18.899896897456482, timestamp: 2022-08-19 08:57:48.523305\n",
      "resetting env. episode 5053, reward total was -21.0. running mean: -18.920897928481917, timestamp: 2022-08-19 08:57:53.400360\n",
      "resetting env. episode 5054, reward total was -19.0. running mean: -18.921688949197097, timestamp: 2022-08-19 08:57:56.514401\n",
      "resetting env. episode 5055, reward total was -20.0. running mean: -18.932472059705127, timestamp: 2022-08-19 08:58:00.801453\n",
      "resetting env. episode 5056, reward total was -19.0. running mean: -18.933147339108075, timestamp: 2022-08-19 08:58:03.962489\n",
      "resetting env. episode 5057, reward total was -20.0. running mean: -18.943815865716992, timestamp: 2022-08-19 08:58:08.451540\n",
      "resetting env. episode 5058, reward total was -20.0. running mean: -18.95437770705982, timestamp: 2022-08-19 08:58:13.135600\n",
      "resetting env. episode 5059, reward total was -19.0. running mean: -18.954833929989224, timestamp: 2022-08-19 08:58:17.151648\n",
      "resetting env. episode 5060, reward total was -20.0. running mean: -18.96528559068933, timestamp: 2022-08-19 08:58:21.188694\n",
      "resetting env. episode 5061, reward total was -17.0. running mean: -18.94563273478244, timestamp: 2022-08-19 08:58:26.047751\n",
      "resetting env. episode 5062, reward total was -18.0. running mean: -18.936176407434615, timestamp: 2022-08-19 08:58:29.407792\n",
      "resetting env. episode 5063, reward total was -16.0. running mean: -18.90681464336027, timestamp: 2022-08-19 08:58:34.317851\n",
      "resetting env. episode 5064, reward total was -19.0. running mean: -18.90774649692667, timestamp: 2022-08-19 08:58:37.897895\n",
      "resetting env. episode 5065, reward total was -20.0. running mean: -18.918669031957403, timestamp: 2022-08-19 08:58:42.376946\n",
      "resetting env. episode 5066, reward total was -16.0. running mean: -18.88948234163783, timestamp: 2022-08-19 08:58:48.196015\n",
      "resetting env. episode 5067, reward total was -19.0. running mean: -18.89058751822145, timestamp: 2022-08-19 08:58:51.895062\n",
      "resetting env. episode 5068, reward total was -19.0. running mean: -18.891681643039238, timestamp: 2022-08-19 08:58:56.294115\n",
      "resetting env. episode 5069, reward total was -17.0. running mean: -18.872764826608847, timestamp: 2022-08-19 08:59:00.912701\n",
      "resetting env. episode 5070, reward total was -20.0. running mean: -18.88403717834276, timestamp: 2022-08-19 08:59:04.932747\n",
      "resetting env. episode 5071, reward total was -19.0. running mean: -18.885196806559332, timestamp: 2022-08-19 08:59:08.635791\n",
      "resetting env. episode 5072, reward total was -17.0. running mean: -18.86634483849374, timestamp: 2022-08-19 08:59:14.557862\n",
      "resetting env. episode 5073, reward total was -21.0. running mean: -18.887681390108806, timestamp: 2022-08-19 08:59:19.590919\n",
      "resetting env. episode 5074, reward total was -19.0. running mean: -18.88880457620772, timestamp: 2022-08-19 08:59:23.837970\n",
      "resetting env. episode 5075, reward total was -20.0. running mean: -18.89991653044564, timestamp: 2022-08-19 08:59:27.715018\n",
      "resetting env. episode 5076, reward total was -19.0. running mean: -18.900917365141186, timestamp: 2022-08-19 08:59:31.255060\n",
      "resetting env. episode 5077, reward total was -21.0. running mean: -18.921908191489774, timestamp: 2022-08-19 08:59:34.721104\n",
      "resetting env. episode 5078, reward total was -20.0. running mean: -18.932689109574873, timestamp: 2022-08-19 08:59:38.732149\n",
      "resetting env. episode 5079, reward total was -19.0. running mean: -18.933362218479125, timestamp: 2022-08-19 08:59:43.352201\n",
      "resetting env. episode 5080, reward total was -21.0. running mean: -18.954028596294336, timestamp: 2022-08-19 08:59:47.285246\n",
      "resetting env. episode 5081, reward total was -20.0. running mean: -18.96448831033139, timestamp: 2022-08-19 08:59:51.796299\n",
      "resetting env. episode 5082, reward total was -21.0. running mean: -18.98484342722808, timestamp: 2022-08-19 08:59:55.878347\n",
      "resetting env. episode 5083, reward total was -20.0. running mean: -18.994994992955796, timestamp: 2022-08-19 08:59:59.332388\n",
      "resetting env. episode 5084, reward total was -20.0. running mean: -19.005045043026236, timestamp: 2022-08-19 09:00:03.209435\n",
      "resetting env. episode 5085, reward total was -20.0. running mean: -19.014994592595972, timestamp: 2022-08-19 09:00:07.245481\n",
      "resetting env. episode 5086, reward total was -14.0. running mean: -18.964844646670013, timestamp: 2022-08-19 09:00:11.983544\n",
      "resetting env. episode 5087, reward total was -19.0. running mean: -18.965196200203312, timestamp: 2022-08-19 09:00:16.796597\n",
      "resetting env. episode 5088, reward total was -17.0. running mean: -18.94554423820128, timestamp: 2022-08-19 09:00:21.430648\n",
      "resetting env. episode 5089, reward total was -19.0. running mean: -18.946088795819268, timestamp: 2022-08-19 09:00:25.592698\n",
      "resetting env. episode 5090, reward total was -20.0. running mean: -18.956627907861073, timestamp: 2022-08-19 09:00:29.972748\n",
      "resetting env. episode 5091, reward total was -18.0. running mean: -18.94706162878246, timestamp: 2022-08-19 09:00:32.992785\n",
      "resetting env. episode 5092, reward total was -16.0. running mean: -18.917591012494636, timestamp: 2022-08-19 09:00:36.962830\n",
      "resetting env. episode 5093, reward total was -21.0. running mean: -18.938415102369692, timestamp: 2022-08-19 09:00:40.222870\n",
      "resetting env. episode 5094, reward total was -16.0. running mean: -18.909030951345997, timestamp: 2022-08-19 09:00:45.145929\n",
      "resetting env. episode 5095, reward total was -21.0. running mean: -18.929940641832538, timestamp: 2022-08-19 09:00:51.158531\n",
      "resetting env. episode 5096, reward total was -17.0. running mean: -18.910641235414214, timestamp: 2022-08-19 09:00:55.156575\n",
      "resetting env. episode 5097, reward total was -19.0. running mean: -18.911534823060073, timestamp: 2022-08-19 09:00:59.577629\n",
      "resetting env. episode 5098, reward total was -21.0. running mean: -18.932419474829473, timestamp: 2022-08-19 09:01:03.682679\n",
      "resetting env. episode 5099, reward total was -18.0. running mean: -18.923095280081178, timestamp: 2022-08-19 09:01:07.461727\n",
      "resetting env. episode 5100, reward total was -21.0. running mean: -18.943864327280366, timestamp: 2022-08-19 09:01:11.240769\n",
      "resetting env. episode 5101, reward total was -20.0. running mean: -18.95442568400756, timestamp: 2022-08-19 09:01:14.948813\n",
      "resetting env. episode 5102, reward total was -20.0. running mean: -18.964881427167484, timestamp: 2022-08-19 09:01:20.031875\n",
      "resetting env. episode 5103, reward total was -18.0. running mean: -18.95523261289581, timestamp: 2022-08-19 09:01:24.499931\n",
      "resetting env. episode 5104, reward total was -19.0. running mean: -18.955680286766853, timestamp: 2022-08-19 09:01:28.496982\n",
      "resetting env. episode 5105, reward total was -19.0. running mean: -18.956123483899187, timestamp: 2022-08-19 09:01:33.690042\n",
      "resetting env. episode 5106, reward total was -16.0. running mean: -18.926562249060197, timestamp: 2022-08-19 09:01:37.923091\n",
      "resetting env. episode 5107, reward total was -20.0. running mean: -18.937296626569594, timestamp: 2022-08-19 09:01:42.516147\n",
      "resetting env. episode 5108, reward total was -16.0. running mean: -18.907923660303897, timestamp: 2022-08-19 09:01:46.716198\n",
      "resetting env. episode 5109, reward total was -19.0. running mean: -18.90884442370086, timestamp: 2022-08-19 09:01:52.147265\n",
      "resetting env. episode 5110, reward total was -19.0. running mean: -18.909755979463853, timestamp: 2022-08-19 09:01:56.399316\n",
      "resetting env. episode 5111, reward total was -17.0. running mean: -18.890658419669215, timestamp: 2022-08-19 09:02:00.521368\n",
      "resetting env. episode 5112, reward total was -20.0. running mean: -18.90175183547252, timestamp: 2022-08-19 09:02:04.839422\n",
      "resetting env. episode 5113, reward total was -19.0. running mean: -18.902734317117798, timestamp: 2022-08-19 09:02:09.040474\n",
      "resetting env. episode 5114, reward total was -17.0. running mean: -18.88370697394662, timestamp: 2022-08-19 09:02:13.148523\n",
      "resetting env. episode 5115, reward total was -21.0. running mean: -18.904869904207153, timestamp: 2022-08-19 09:02:16.674565\n",
      "resetting env. episode 5116, reward total was -13.0. running mean: -18.84582120516508, timestamp: 2022-08-19 09:02:22.247639\n",
      "resetting env. episode 5117, reward total was -20.0. running mean: -18.85736299311343, timestamp: 2022-08-19 09:02:26.812697\n",
      "resetting env. episode 5118, reward total was -18.0. running mean: -18.848789363182295, timestamp: 2022-08-19 09:02:31.826751\n",
      "resetting env. episode 5119, reward total was -21.0. running mean: -18.870301469550473, timestamp: 2022-08-19 09:02:35.108794\n",
      "resetting env. episode 5120, reward total was -11.0. running mean: -18.791598454854967, timestamp: 2022-08-19 09:02:40.967865\n",
      "resetting env. episode 5121, reward total was -20.0. running mean: -18.803682470306416, timestamp: 2022-08-19 09:02:44.430907\n",
      "resetting env. episode 5122, reward total was -20.0. running mean: -18.81564564560335, timestamp: 2022-08-19 09:02:48.389955\n",
      "resetting env. episode 5123, reward total was -19.0. running mean: -18.817489189147317, timestamp: 2022-08-19 09:02:52.448010\n",
      "resetting env. episode 5124, reward total was -20.0. running mean: -18.82931429725584, timestamp: 2022-08-19 09:02:58.377080\n",
      "resetting env. episode 5125, reward total was -17.0. running mean: -18.811021154283285, timestamp: 2022-08-19 09:03:02.255129\n",
      "resetting env. episode 5126, reward total was -20.0. running mean: -18.822910942740453, timestamp: 2022-08-19 09:03:05.518169\n",
      "resetting env. episode 5127, reward total was -16.0. running mean: -18.79468183331305, timestamp: 2022-08-19 09:03:10.536236\n",
      "resetting env. episode 5128, reward total was -21.0. running mean: -18.81673501497992, timestamp: 2022-08-19 09:03:15.384290\n",
      "resetting env. episode 5129, reward total was -20.0. running mean: -18.828567664830118, timestamp: 2022-08-19 09:03:18.944338\n",
      "resetting env. episode 5130, reward total was -18.0. running mean: -18.820281988181815, timestamp: 2022-08-19 09:03:22.803383\n",
      "resetting env. episode 5131, reward total was -20.0. running mean: -18.832079168299995, timestamp: 2022-08-19 09:03:27.312442\n",
      "resetting env. episode 5132, reward total was -18.0. running mean: -18.823758376616993, timestamp: 2022-08-19 09:03:31.716493\n",
      "resetting env. episode 5133, reward total was -21.0. running mean: -18.845520792850824, timestamp: 2022-08-19 09:03:35.324542\n",
      "resetting env. episode 5134, reward total was -16.0. running mean: -18.817065584922315, timestamp: 2022-08-19 09:03:41.153612\n",
      "resetting env. episode 5135, reward total was -18.0. running mean: -18.80889492907309, timestamp: 2022-08-19 09:03:45.547668\n",
      "resetting env. episode 5136, reward total was -18.0. running mean: -18.80080597978236, timestamp: 2022-08-19 09:03:49.574720\n",
      "resetting env. episode 5137, reward total was -21.0. running mean: -18.822797919984538, timestamp: 2022-08-19 09:03:53.048764\n",
      "resetting env. episode 5138, reward total was -18.0. running mean: -18.814569940784693, timestamp: 2022-08-19 09:03:57.006813\n",
      "resetting env. episode 5139, reward total was -21.0. running mean: -18.836424241376847, timestamp: 2022-08-19 09:04:01.010863\n",
      "resetting env. episode 5140, reward total was -19.0. running mean: -18.83805999896308, timestamp: 2022-08-19 09:04:06.187925\n",
      "resetting env. episode 5141, reward total was -19.0. running mean: -18.83967939897345, timestamp: 2022-08-19 09:04:09.852972\n",
      "resetting env. episode 5142, reward total was -17.0. running mean: -18.821282604983715, timestamp: 2022-08-19 09:04:14.882034\n",
      "resetting env. episode 5143, reward total was -20.0. running mean: -18.833069778933876, timestamp: 2022-08-19 09:04:18.709081\n",
      "resetting env. episode 5144, reward total was -21.0. running mean: -18.854739081144537, timestamp: 2022-08-19 09:04:23.122135\n",
      "resetting env. episode 5145, reward total was -21.0. running mean: -18.87619169033309, timestamp: 2022-08-19 09:04:26.583184\n",
      "resetting env. episode 5146, reward total was -17.0. running mean: -18.85742977342976, timestamp: 2022-08-19 09:04:31.412239\n",
      "resetting env. episode 5147, reward total was -19.0. running mean: -18.858855475695464, timestamp: 2022-08-19 09:04:36.034297\n",
      "resetting env. episode 5148, reward total was -19.0. running mean: -18.86026692093851, timestamp: 2022-08-19 09:04:40.838358\n",
      "resetting env. episode 5149, reward total was -20.0. running mean: -18.871664251729126, timestamp: 2022-08-19 09:04:44.996409\n",
      "resetting env. episode 5150, reward total was -19.0. running mean: -18.872947609211835, timestamp: 2022-08-19 09:04:49.269462\n",
      "resetting env. episode 5151, reward total was -18.0. running mean: -18.864218133119717, timestamp: 2022-08-19 09:04:53.339513\n",
      "resetting env. episode 5152, reward total was -19.0. running mean: -18.86557595178852, timestamp: 2022-08-19 09:04:58.438581\n",
      "resetting env. episode 5153, reward total was -18.0. running mean: -18.856920192270636, timestamp: 2022-08-19 09:05:03.487646\n",
      "resetting env. episode 5154, reward total was -21.0. running mean: -18.87835099034793, timestamp: 2022-08-19 09:05:08.367701\n",
      "resetting env. episode 5155, reward total was -20.0. running mean: -18.889567480444448, timestamp: 2022-08-19 09:05:12.507755\n",
      "resetting env. episode 5156, reward total was -18.0. running mean: -18.880671805640002, timestamp: 2022-08-19 09:05:17.308813\n",
      "resetting env. episode 5157, reward total was -19.0. running mean: -18.881865087583602, timestamp: 2022-08-19 09:05:21.538396\n",
      "resetting env. episode 5158, reward total was -19.0. running mean: -18.88304643670777, timestamp: 2022-08-19 09:05:25.738447\n",
      "resetting env. episode 5159, reward total was -18.0. running mean: -18.87421597234069, timestamp: 2022-08-19 09:05:30.591513\n",
      "resetting env. episode 5160, reward total was -20.0. running mean: -18.88547381261728, timestamp: 2022-08-19 09:05:33.624546\n",
      "resetting env. episode 5161, reward total was -16.0. running mean: -18.856619074491107, timestamp: 2022-08-19 09:05:38.738611\n",
      "resetting env. episode 5162, reward total was -16.0. running mean: -18.828052883746196, timestamp: 2022-08-19 09:05:43.331672\n",
      "resetting env. episode 5163, reward total was -19.0. running mean: -18.829772354908734, timestamp: 2022-08-19 09:05:48.005730\n",
      "resetting env. episode 5164, reward total was -18.0. running mean: -18.821474631359646, timestamp: 2022-08-19 09:05:52.790791\n",
      "resetting env. episode 5165, reward total was -16.0. running mean: -18.793259885046048, timestamp: 2022-08-19 09:05:57.307848\n",
      "resetting env. episode 5166, reward total was -18.0. running mean: -18.78532728619559, timestamp: 2022-08-19 09:06:02.376909\n",
      "resetting env. episode 5167, reward total was -18.0. running mean: -18.77747401333363, timestamp: 2022-08-19 09:06:05.956952\n",
      "resetting env. episode 5168, reward total was -20.0. running mean: -18.789699273200295, timestamp: 2022-08-19 09:06:10.007003\n",
      "resetting env. episode 5169, reward total was -19.0. running mean: -18.791802280468293, timestamp: 2022-08-19 09:06:13.965056\n",
      "resetting env. episode 5170, reward total was -16.0. running mean: -18.76388425766361, timestamp: 2022-08-19 09:06:18.303110\n",
      "resetting env. episode 5171, reward total was -17.0. running mean: -18.746245415086975, timestamp: 2022-08-19 09:06:22.924168\n",
      "resetting env. episode 5172, reward total was -18.0. running mean: -18.738782960936103, timestamp: 2022-08-19 09:06:27.300224\n",
      "resetting env. episode 5173, reward total was -20.0. running mean: -18.751395131326742, timestamp: 2022-08-19 09:06:32.146280\n",
      "resetting env. episode 5174, reward total was -19.0. running mean: -18.753881180013476, timestamp: 2022-08-19 09:06:36.408338\n",
      "resetting env. episode 5175, reward total was -21.0. running mean: -18.776342368213342, timestamp: 2022-08-19 09:06:40.385384\n",
      "resetting env. episode 5176, reward total was -17.0. running mean: -18.75857894453121, timestamp: 2022-08-19 09:06:45.128447\n",
      "resetting env. episode 5177, reward total was -21.0. running mean: -18.7809931550859, timestamp: 2022-08-19 09:06:49.073491\n",
      "resetting env. episode 5178, reward total was -19.0. running mean: -18.78318322353504, timestamp: 2022-08-19 09:06:53.969556\n",
      "resetting env. episode 5179, reward total was -18.0. running mean: -18.77535139129969, timestamp: 2022-08-19 09:06:58.536613\n",
      "resetting env. episode 5180, reward total was -17.0. running mean: -18.757597877386694, timestamp: 2022-08-19 09:07:02.984665\n",
      "resetting env. episode 5181, reward total was -20.0. running mean: -18.770021898612825, timestamp: 2022-08-19 09:07:06.983717\n",
      "resetting env. episode 5182, reward total was -20.0. running mean: -18.782321679626694, timestamp: 2022-08-19 09:07:10.691765\n",
      "resetting env. episode 5183, reward total was -13.0. running mean: -18.724498462830425, timestamp: 2022-08-19 09:07:15.690828\n",
      "resetting env. episode 5184, reward total was -19.0. running mean: -18.727253478202122, timestamp: 2022-08-19 09:07:20.003881\n",
      "resetting env. episode 5185, reward total was -16.0. running mean: -18.6999809434201, timestamp: 2022-08-19 09:07:24.844941\n",
      "resetting env. episode 5186, reward total was -21.0. running mean: -18.7229811339859, timestamp: 2022-08-19 09:07:27.610976\n",
      "resetting env. episode 5187, reward total was -18.0. running mean: -18.715751322646042, timestamp: 2022-08-19 09:07:31.223021\n",
      "resetting env. episode 5188, reward total was -20.0. running mean: -18.728593809419582, timestamp: 2022-08-19 09:07:35.424078\n",
      "resetting env. episode 5189, reward total was -18.0. running mean: -18.721307871325386, timestamp: 2022-08-19 09:07:40.322136\n",
      "resetting env. episode 5190, reward total was -21.0. running mean: -18.744094792612135, timestamp: 2022-08-19 09:07:44.572190\n",
      "resetting env. episode 5191, reward total was -20.0. running mean: -18.756653844686014, timestamp: 2022-08-19 09:07:48.700244\n",
      "resetting env. episode 5192, reward total was -20.0. running mean: -18.769087306239154, timestamp: 2022-08-19 09:07:52.433290\n",
      "resetting env. episode 5193, reward total was -19.0. running mean: -18.771396433176765, timestamp: 2022-08-19 09:07:56.677345\n",
      "resetting env. episode 5194, reward total was -21.0. running mean: -18.793682468845, timestamp: 2022-08-19 09:08:00.764395\n",
      "resetting env. episode 5195, reward total was -18.0. running mean: -18.78574564415655, timestamp: 2022-08-19 09:08:05.123448\n",
      "resetting env. episode 5196, reward total was -17.0. running mean: -18.767888187714984, timestamp: 2022-08-19 09:08:09.307505\n",
      "resetting env. episode 5197, reward total was -18.0. running mean: -18.760209305837833, timestamp: 2022-08-19 09:08:13.767557\n",
      "resetting env. episode 5198, reward total was -20.0. running mean: -18.772607212779455, timestamp: 2022-08-19 09:08:17.234602\n",
      "resetting env. episode 5199, reward total was -21.0. running mean: -18.79488114065166, timestamp: 2022-08-19 09:08:22.028666\n",
      "resetting env. episode 5200, reward total was -19.0. running mean: -18.796932329245145, timestamp: 2022-08-19 09:08:26.454716\n",
      "resetting env. episode 5201, reward total was -19.0. running mean: -18.798963005952693, timestamp: 2022-08-19 09:08:31.050779\n",
      "resetting env. episode 5202, reward total was -20.0. running mean: -18.810973375893166, timestamp: 2022-08-19 09:08:35.436832\n",
      "resetting env. episode 5203, reward total was -19.0. running mean: -18.812863642134236, timestamp: 2022-08-19 09:08:39.400882\n",
      "resetting env. episode 5204, reward total was -16.0. running mean: -18.784735005712893, timestamp: 2022-08-19 09:08:44.098939\n",
      "resetting env. episode 5205, reward total was -21.0. running mean: -18.806887655655764, timestamp: 2022-08-19 09:08:47.665982\n",
      "resetting env. episode 5206, reward total was -18.0. running mean: -18.798818779099207, timestamp: 2022-08-19 09:08:51.307027\n",
      "resetting env. episode 5207, reward total was -20.0. running mean: -18.810830591308214, timestamp: 2022-08-19 09:08:56.291092\n",
      "resetting env. episode 5208, reward total was -17.0. running mean: -18.792722285395133, timestamp: 2022-08-19 09:09:00.999151\n",
      "resetting env. episode 5209, reward total was -20.0. running mean: -18.80479506254118, timestamp: 2022-08-19 09:09:06.402217\n",
      "resetting env. episode 5210, reward total was -19.0. running mean: -18.806747111915772, timestamp: 2022-08-19 09:09:09.709257\n",
      "resetting env. episode 5211, reward total was -18.0. running mean: -18.798679640796614, timestamp: 2022-08-19 09:09:14.523321\n",
      "resetting env. episode 5212, reward total was -18.0. running mean: -18.790692844388648, timestamp: 2022-08-19 09:09:18.682370\n",
      "resetting env. episode 5213, reward total was -19.0. running mean: -18.792785915944762, timestamp: 2022-08-19 09:09:23.580430\n",
      "resetting env. episode 5214, reward total was -20.0. running mean: -18.804858056785314, timestamp: 2022-08-19 09:09:27.574481\n",
      "resetting env. episode 5215, reward total was -18.0. running mean: -18.79680947621746, timestamp: 2022-08-19 09:09:32.107536\n",
      "resetting env. episode 5216, reward total was -21.0. running mean: -18.818841381455286, timestamp: 2022-08-19 09:09:35.958584\n",
      "resetting env. episode 5217, reward total was -17.0. running mean: -18.800652967640733, timestamp: 2022-08-19 09:09:39.910635\n",
      "resetting env. episode 5218, reward total was -19.0. running mean: -18.802646437964327, timestamp: 2022-08-19 09:09:44.401693\n",
      "resetting env. episode 5219, reward total was -17.0. running mean: -18.784619973584686, timestamp: 2022-08-19 09:09:49.287750\n",
      "resetting env. episode 5220, reward total was -20.0. running mean: -18.796773773848837, timestamp: 2022-08-19 09:09:54.014808\n",
      "resetting env. episode 5221, reward total was -20.0. running mean: -18.808806036110347, timestamp: 2022-08-19 09:09:59.156871\n",
      "resetting env. episode 5222, reward total was -17.0. running mean: -18.790717975749246, timestamp: 2022-08-19 09:10:04.883941\n",
      "resetting env. episode 5223, reward total was -20.0. running mean: -18.802810795991753, timestamp: 2022-08-19 09:10:08.432988\n",
      "resetting env. episode 5224, reward total was -20.0. running mean: -18.814782688031833, timestamp: 2022-08-19 09:10:13.326048\n",
      "resetting env. episode 5225, reward total was -19.0. running mean: -18.816634861151517, timestamp: 2022-08-19 09:10:16.639086\n",
      "resetting env. episode 5226, reward total was -18.0. running mean: -18.808468512540003, timestamp: 2022-08-19 09:10:21.071147\n",
      "resetting env. episode 5227, reward total was -21.0. running mean: -18.830383827414604, timestamp: 2022-08-19 09:10:24.765189\n",
      "resetting env. episode 5228, reward total was -19.0. running mean: -18.83207998914046, timestamp: 2022-08-19 09:10:28.836236\n",
      "resetting env. episode 5229, reward total was -19.0. running mean: -18.833759189249058, timestamp: 2022-08-19 09:10:33.184288\n",
      "resetting env. episode 5230, reward total was -19.0. running mean: -18.835421597356568, timestamp: 2022-08-19 09:10:37.389341\n",
      "resetting env. episode 5231, reward total was -19.0. running mean: -18.837067381383005, timestamp: 2022-08-19 09:10:41.856395\n",
      "resetting env. episode 5232, reward total was -20.0. running mean: -18.848696707569175, timestamp: 2022-08-19 09:10:45.701442\n",
      "resetting env. episode 5233, reward total was -20.0. running mean: -18.86020974049348, timestamp: 2022-08-19 09:10:49.225490\n",
      "resetting env. episode 5234, reward total was -18.0. running mean: -18.851607643088546, timestamp: 2022-08-19 09:10:53.173534\n",
      "resetting env. episode 5235, reward total was -19.0. running mean: -18.85309156665766, timestamp: 2022-08-19 09:10:57.138219\n",
      "resetting env. episode 5236, reward total was -21.0. running mean: -18.874560650991086, timestamp: 2022-08-19 09:11:00.788265\n",
      "resetting env. episode 5237, reward total was -19.0. running mean: -18.875815044481175, timestamp: 2022-08-19 09:11:04.053306\n",
      "resetting env. episode 5238, reward total was -20.0. running mean: -18.887056894036363, timestamp: 2022-08-19 09:11:08.981364\n",
      "resetting env. episode 5239, reward total was -19.0. running mean: -18.888186325096, timestamp: 2022-08-19 09:11:12.633933\n",
      "resetting env. episode 5240, reward total was -20.0. running mean: -18.89930446184504, timestamp: 2022-08-19 09:11:16.148975\n",
      "resetting env. episode 5241, reward total was -21.0. running mean: -18.920311417226593, timestamp: 2022-08-19 09:11:19.898023\n",
      "resetting env. episode 5242, reward total was -19.0. running mean: -18.92110830305433, timestamp: 2022-08-19 09:11:24.420077\n",
      "resetting env. episode 5243, reward total was -19.0. running mean: -18.921897220023787, timestamp: 2022-08-19 09:11:29.125136\n",
      "resetting env. episode 5244, reward total was -19.0. running mean: -18.92267824782355, timestamp: 2022-08-19 09:11:33.830192\n",
      "resetting env. episode 5245, reward total was -19.0. running mean: -18.923451465345316, timestamp: 2022-08-19 09:11:38.880256\n",
      "resetting env. episode 5246, reward total was -20.0. running mean: -18.934216950691862, timestamp: 2022-08-19 09:11:42.440298\n",
      "resetting env. episode 5247, reward total was -20.0. running mean: -18.944874781184943, timestamp: 2022-08-19 09:11:47.027352\n",
      "resetting env. episode 5248, reward total was -18.0. running mean: -18.935426033373094, timestamp: 2022-08-19 09:11:51.007403\n",
      "resetting env. episode 5249, reward total was -19.0. running mean: -18.936071773039366, timestamp: 2022-08-19 09:11:55.728458\n",
      "resetting env. episode 5250, reward total was -16.0. running mean: -18.90671105530897, timestamp: 2022-08-19 09:12:00.828699\n",
      "resetting env. episode 5251, reward total was -19.0. running mean: -18.907643944755883, timestamp: 2022-08-19 09:12:04.375745\n",
      "resetting env. episode 5252, reward total was -18.0. running mean: -18.898567505308325, timestamp: 2022-08-19 09:12:09.212806\n",
      "resetting env. episode 5253, reward total was -17.0. running mean: -18.879581830255244, timestamp: 2022-08-19 09:12:13.962856\n",
      "resetting env. episode 5254, reward total was -19.0. running mean: -18.880786011952694, timestamp: 2022-08-19 09:12:19.058911\n",
      "resetting env. episode 5255, reward total was -19.0. running mean: -18.881978151833167, timestamp: 2022-08-19 09:12:24.348977\n",
      "resetting env. episode 5256, reward total was -16.0. running mean: -18.853158370314834, timestamp: 2022-08-19 09:12:29.067030\n",
      "resetting env. episode 5257, reward total was -20.0. running mean: -18.864626786611684, timestamp: 2022-08-19 09:12:33.412084\n",
      "resetting env. episode 5258, reward total was -18.0. running mean: -18.855980518745568, timestamp: 2022-08-19 09:12:38.043139\n",
      "resetting env. episode 5259, reward total was -21.0. running mean: -18.877420713558113, timestamp: 2022-08-19 09:12:42.195192\n",
      "resetting env. episode 5260, reward total was -17.0. running mean: -18.858646506422534, timestamp: 2022-08-19 09:12:46.563245\n",
      "resetting env. episode 5261, reward total was -21.0. running mean: -18.88006004135831, timestamp: 2022-08-19 09:12:50.867292\n",
      "resetting env. episode 5262, reward total was -18.0. running mean: -18.871259440944726, timestamp: 2022-08-19 09:12:55.613350\n",
      "resetting env. episode 5263, reward total was -19.0. running mean: -18.87254684653528, timestamp: 2022-08-19 09:13:00.321409\n",
      "resetting env. episode 5264, reward total was -17.0. running mean: -18.853821378069927, timestamp: 2022-08-19 09:13:03.916449\n",
      "resetting env. episode 5265, reward total was -17.0. running mean: -18.83528316428923, timestamp: 2022-08-19 09:13:08.128499\n",
      "resetting env. episode 5266, reward total was -21.0. running mean: -18.85693033264634, timestamp: 2022-08-19 09:13:11.979546\n",
      "resetting env. episode 5267, reward total was -18.0. running mean: -18.848361029319875, timestamp: 2022-08-19 09:13:16.071596\n",
      "resetting env. episode 5268, reward total was -19.0. running mean: -18.849877419026676, timestamp: 2022-08-19 09:13:20.641649\n",
      "resetting env. episode 5269, reward total was -20.0. running mean: -18.861378644836407, timestamp: 2022-08-19 09:13:25.031704\n",
      "resetting env. episode 5270, reward total was -20.0. running mean: -18.87276485838804, timestamp: 2022-08-19 09:13:29.391755\n",
      "resetting env. episode 5271, reward total was -20.0. running mean: -18.88403720980416, timestamp: 2022-08-19 09:13:33.326802\n",
      "resetting env. episode 5272, reward total was -17.0. running mean: -18.86519683770612, timestamp: 2022-08-19 09:13:37.125849\n",
      "resetting env. episode 5273, reward total was -21.0. running mean: -18.886544869329057, timestamp: 2022-08-19 09:13:40.463887\n",
      "resetting env. episode 5274, reward total was -18.0. running mean: -18.877679420635765, timestamp: 2022-08-19 09:13:44.808939\n",
      "resetting env. episode 5275, reward total was -19.0. running mean: -18.878902626429408, timestamp: 2022-08-19 09:13:48.692985\n",
      "resetting env. episode 5276, reward total was -19.0. running mean: -18.880113600165114, timestamp: 2022-08-19 09:13:52.485030\n",
      "resetting env. episode 5277, reward total was -19.0. running mean: -18.881312464163464, timestamp: 2022-08-19 09:13:56.602605\n",
      "resetting env. episode 5278, reward total was -21.0. running mean: -18.90249933952183, timestamp: 2022-08-19 09:14:00.916659\n",
      "resetting env. episode 5279, reward total was -19.0. running mean: -18.903474346126615, timestamp: 2022-08-19 09:14:05.078708\n",
      "resetting env. episode 5280, reward total was -20.0. running mean: -18.914439602665347, timestamp: 2022-08-19 09:14:08.648748\n",
      "resetting env. episode 5281, reward total was -20.0. running mean: -18.925295206638694, timestamp: 2022-08-19 09:14:12.455325\n",
      "resetting env. episode 5282, reward total was -19.0. running mean: -18.92604225457231, timestamp: 2022-08-19 09:14:16.198368\n",
      "resetting env. episode 5283, reward total was -19.0. running mean: -18.926781832026588, timestamp: 2022-08-19 09:14:20.533420\n",
      "resetting env. episode 5284, reward total was -18.0. running mean: -18.91751401370632, timestamp: 2022-08-19 09:14:25.076472\n",
      "resetting env. episode 5285, reward total was -19.0. running mean: -18.918338873569258, timestamp: 2022-08-19 09:14:29.725526\n",
      "resetting env. episode 5286, reward total was -21.0. running mean: -18.939155484833567, timestamp: 2022-08-19 09:14:34.206580\n",
      "resetting env. episode 5287, reward total was -20.0. running mean: -18.94976392998523, timestamp: 2022-08-19 09:14:38.342628\n",
      "resetting env. episode 5288, reward total was -17.0. running mean: -18.93026629068538, timestamp: 2022-08-19 09:14:42.822684\n",
      "resetting env. episode 5289, reward total was -19.0. running mean: -18.930963627778528, timestamp: 2022-08-19 09:14:47.148739\n",
      "resetting env. episode 5290, reward total was -17.0. running mean: -18.911653991500746, timestamp: 2022-08-19 09:14:50.994779\n",
      "resetting env. episode 5291, reward total was -19.0. running mean: -18.912537451585738, timestamp: 2022-08-19 09:14:55.841836\n",
      "resetting env. episode 5292, reward total was -19.0. running mean: -18.913412077069882, timestamp: 2022-08-19 09:15:00.666896\n",
      "resetting env. episode 5293, reward total was -20.0. running mean: -18.924277956299182, timestamp: 2022-08-19 09:15:04.513937\n",
      "resetting env. episode 5294, reward total was -20.0. running mean: -18.93503517673619, timestamp: 2022-08-19 09:15:08.144983\n",
      "resetting env. episode 5295, reward total was -16.0. running mean: -18.905684824968827, timestamp: 2022-08-19 09:15:13.170412\n",
      "resetting env. episode 5296, reward total was -20.0. running mean: -18.916627976719138, timestamp: 2022-08-19 09:15:17.102462\n",
      "resetting env. episode 5297, reward total was -17.0. running mean: -18.897461696951947, timestamp: 2022-08-19 09:15:22.359520\n",
      "resetting env. episode 5298, reward total was -18.0. running mean: -18.888487079982426, timestamp: 2022-08-19 09:15:27.594583\n",
      "resetting env. episode 5299, reward total was -17.0. running mean: -18.869602209182602, timestamp: 2022-08-19 09:15:32.569646\n",
      "resetting env. episode 5300, reward total was -20.0. running mean: -18.880906187090776, timestamp: 2022-08-19 09:15:37.732302\n",
      "resetting env. episode 5301, reward total was -20.0. running mean: -18.892097125219866, timestamp: 2022-08-19 09:15:41.762360\n",
      "resetting env. episode 5302, reward total was -17.0. running mean: -18.87317615396767, timestamp: 2022-08-19 09:15:45.910400\n",
      "resetting env. episode 5303, reward total was -16.0. running mean: -18.84444439242799, timestamp: 2022-08-19 09:15:50.920458\n",
      "resetting env. episode 5304, reward total was -20.0. running mean: -18.85599994850371, timestamp: 2022-08-19 09:15:54.786503\n",
      "resetting env. episode 5305, reward total was -19.0. running mean: -18.857439949018676, timestamp: 2022-08-19 09:15:59.447560\n",
      "resetting env. episode 5306, reward total was -19.0. running mean: -18.858865549528492, timestamp: 2022-08-19 09:16:03.169600\n",
      "resetting env. episode 5307, reward total was -18.0. running mean: -18.850276894033207, timestamp: 2022-08-19 09:16:07.491655\n",
      "resetting env. episode 5308, reward total was -15.0. running mean: -18.811774125092874, timestamp: 2022-08-19 09:16:11.753701\n",
      "resetting env. episode 5309, reward total was -21.0. running mean: -18.833656383841948, timestamp: 2022-08-19 09:16:15.509745\n",
      "resetting env. episode 5310, reward total was -21.0. running mean: -18.85531982000353, timestamp: 2022-08-19 09:16:18.867783\n",
      "resetting env. episode 5311, reward total was -21.0. running mean: -18.876766621803494, timestamp: 2022-08-19 09:16:22.889834\n",
      "resetting env. episode 5312, reward total was -17.0. running mean: -18.85799895558546, timestamp: 2022-08-19 09:16:27.414887\n",
      "resetting env. episode 5313, reward total was -19.0. running mean: -18.859418966029608, timestamp: 2022-08-19 09:16:32.732944\n",
      "resetting env. episode 5314, reward total was -18.0. running mean: -18.85082477636931, timestamp: 2022-08-19 09:16:37.196522\n",
      "resetting env. episode 5315, reward total was -21.0. running mean: -18.87231652860562, timestamp: 2022-08-19 09:16:40.592560\n",
      "resetting env. episode 5316, reward total was -17.0. running mean: -18.853593363319565, timestamp: 2022-08-19 09:16:44.931610\n",
      "resetting env. episode 5317, reward total was -18.0. running mean: -18.845057429686367, timestamp: 2022-08-19 09:16:49.520663\n",
      "resetting env. episode 5318, reward total was -19.0. running mean: -18.846606855389506, timestamp: 2022-08-19 09:16:54.422721\n",
      "resetting env. episode 5319, reward total was -19.0. running mean: -18.84814078683561, timestamp: 2022-08-19 09:16:59.272777\n",
      "resetting env. episode 5320, reward total was -21.0. running mean: -18.869659378967256, timestamp: 2022-08-19 09:17:03.639827\n",
      "resetting env. episode 5321, reward total was -17.0. running mean: -18.850962785177586, timestamp: 2022-08-19 09:17:08.394883\n",
      "resetting env. episode 5322, reward total was -19.0. running mean: -18.85245315732581, timestamp: 2022-08-19 09:17:12.013925\n",
      "resetting env. episode 5323, reward total was -13.0. running mean: -18.793928625752553, timestamp: 2022-08-19 09:17:16.817980\n",
      "resetting env. episode 5324, reward total was -19.0. running mean: -18.79598933949503, timestamp: 2022-08-19 09:17:21.340036\n",
      "resetting env. episode 5325, reward total was -18.0. running mean: -18.78802944610008, timestamp: 2022-08-19 09:17:26.002089\n",
      "resetting env. episode 5326, reward total was -18.0. running mean: -18.78014915163908, timestamp: 2022-08-19 09:17:30.535141\n",
      "resetting env. episode 5327, reward total was -21.0. running mean: -18.802347660122688, timestamp: 2022-08-19 09:17:33.581174\n",
      "resetting env. episode 5328, reward total was -20.0. running mean: -18.81432418352146, timestamp: 2022-08-19 09:17:37.808223\n",
      "resetting env. episode 5329, reward total was -19.0. running mean: -18.816180941686248, timestamp: 2022-08-19 09:17:43.002284\n",
      "resetting env. episode 5330, reward total was -15.0. running mean: -18.778019132269385, timestamp: 2022-08-19 09:17:47.319333\n",
      "resetting env. episode 5331, reward total was -20.0. running mean: -18.79023894094669, timestamp: 2022-08-19 09:17:50.870378\n",
      "resetting env. episode 5332, reward total was -18.0. running mean: -18.782336551537224, timestamp: 2022-08-19 09:17:55.088425\n",
      "resetting env. episode 5333, reward total was -19.0. running mean: -18.784513186021854, timestamp: 2022-08-19 09:17:58.642465\n",
      "resetting env. episode 5334, reward total was -19.0. running mean: -18.786668054161638, timestamp: 2022-08-19 09:18:03.319067\n",
      "resetting env. episode 5335, reward total was -19.0. running mean: -18.78880137362002, timestamp: 2022-08-19 09:18:06.770116\n",
      "resetting env. episode 5336, reward total was -18.0. running mean: -18.780913359883822, timestamp: 2022-08-19 09:18:11.245160\n",
      "resetting env. episode 5337, reward total was -21.0. running mean: -18.803104226284983, timestamp: 2022-08-19 09:18:15.273209\n",
      "resetting env. episode 5338, reward total was -20.0. running mean: -18.815073184022133, timestamp: 2022-08-19 09:18:19.069254\n",
      "resetting env. episode 5339, reward total was -20.0. running mean: -18.82692245218191, timestamp: 2022-08-19 09:18:23.651313\n",
      "resetting env. episode 5340, reward total was -20.0. running mean: -18.838653227660092, timestamp: 2022-08-19 09:18:28.051361\n",
      "resetting env. episode 5341, reward total was -21.0. running mean: -18.86026669538349, timestamp: 2022-08-19 09:18:31.683406\n",
      "resetting env. episode 5342, reward total was -18.0. running mean: -18.851664028429656, timestamp: 2022-08-19 09:18:35.575451\n",
      "resetting env. episode 5343, reward total was -18.0. running mean: -18.843147388145358, timestamp: 2022-08-19 09:18:39.502501\n",
      "resetting env. episode 5344, reward total was -19.0. running mean: -18.844715914263904, timestamp: 2022-08-19 09:18:44.751562\n",
      "resetting env. episode 5345, reward total was -17.0. running mean: -18.826268755121266, timestamp: 2022-08-19 09:18:49.412617\n",
      "resetting env. episode 5346, reward total was -18.0. running mean: -18.818006067570053, timestamp: 2022-08-19 09:18:54.586204\n",
      "resetting env. episode 5347, reward total was -20.0. running mean: -18.82982600689435, timestamp: 2022-08-19 09:18:58.377250\n",
      "resetting env. episode 5348, reward total was -19.0. running mean: -18.831527746825408, timestamp: 2022-08-19 09:19:02.182300\n",
      "resetting env. episode 5349, reward total was -19.0. running mean: -18.833212469357154, timestamp: 2022-08-19 09:19:06.511353\n",
      "resetting env. episode 5350, reward total was -21.0. running mean: -18.854880344663584, timestamp: 2022-08-19 09:19:11.238406\n",
      "resetting env. episode 5351, reward total was -15.0. running mean: -18.816331541216947, timestamp: 2022-08-19 09:19:16.162468\n",
      "resetting env. episode 5352, reward total was -18.0. running mean: -18.808168225804778, timestamp: 2022-08-19 09:19:20.490518\n",
      "resetting env. episode 5353, reward total was -20.0. running mean: -18.82008654354673, timestamp: 2022-08-19 09:19:25.300579\n",
      "resetting env. episode 5354, reward total was -18.0. running mean: -18.81188567811126, timestamp: 2022-08-19 09:19:30.160634\n",
      "resetting env. episode 5355, reward total was -20.0. running mean: -18.823766821330146, timestamp: 2022-08-19 09:19:34.469688\n",
      "resetting env. episode 5356, reward total was -21.0. running mean: -18.845529153116846, timestamp: 2022-08-19 09:19:38.781743\n",
      "resetting env. episode 5357, reward total was -17.0. running mean: -18.827073861585678, timestamp: 2022-08-19 09:19:42.445793\n",
      "resetting env. episode 5358, reward total was -16.0. running mean: -18.798803122969822, timestamp: 2022-08-19 09:19:46.904840\n",
      "resetting env. episode 5359, reward total was -16.0. running mean: -18.770815091740126, timestamp: 2022-08-19 09:19:52.003901\n",
      "resetting env. episode 5360, reward total was -18.0. running mean: -18.763106940822723, timestamp: 2022-08-19 09:19:56.677958\n",
      "resetting env. episode 5361, reward total was -17.0. running mean: -18.7454758714145, timestamp: 2022-08-19 09:20:01.817025\n",
      "resetting env. episode 5362, reward total was -18.0. running mean: -18.738021112700352, timestamp: 2022-08-19 09:20:05.301066\n",
      "resetting env. episode 5363, reward total was -19.0. running mean: -18.74064090157335, timestamp: 2022-08-19 09:20:09.723117\n",
      "resetting env. episode 5364, reward total was -19.0. running mean: -18.74323449255762, timestamp: 2022-08-19 09:20:14.420175\n",
      "resetting env. episode 5365, reward total was -18.0. running mean: -18.735802147632043, timestamp: 2022-08-19 09:20:19.171232\n",
      "resetting env. episode 5366, reward total was -20.0. running mean: -18.74844412615572, timestamp: 2022-08-19 09:20:24.020295\n",
      "resetting env. episode 5367, reward total was -20.0. running mean: -18.760959684894164, timestamp: 2022-08-19 09:20:27.744341\n",
      "resetting env. episode 5368, reward total was -21.0. running mean: -18.783350088045225, timestamp: 2022-08-19 09:20:31.641387\n",
      "resetting env. episode 5369, reward total was -18.0. running mean: -18.775516587164773, timestamp: 2022-08-19 09:20:36.141440\n",
      "resetting env. episode 5370, reward total was -21.0. running mean: -18.797761421293128, timestamp: 2022-08-19 09:20:40.150492\n",
      "resetting env. episode 5371, reward total was -21.0. running mean: -18.819783807080196, timestamp: 2022-08-19 09:20:43.639536\n",
      "resetting env. episode 5372, reward total was -21.0. running mean: -18.841585969009394, timestamp: 2022-08-19 09:20:48.044587\n",
      "resetting env. episode 5373, reward total was -16.0. running mean: -18.8131701093193, timestamp: 2022-08-19 09:20:53.125649\n",
      "resetting env. episode 5374, reward total was -20.0. running mean: -18.825038408226106, timestamp: 2022-08-19 09:20:58.092715\n",
      "resetting env. episode 5375, reward total was -19.0. running mean: -18.826788024143845, timestamp: 2022-08-19 09:21:02.077063\n",
      "resetting env. episode 5376, reward total was -21.0. running mean: -18.848520143902405, timestamp: 2022-08-19 09:21:05.848107\n",
      "resetting env. episode 5377, reward total was -19.0. running mean: -18.85003494246338, timestamp: 2022-08-19 09:21:10.176163\n",
      "resetting env. episode 5378, reward total was -19.0. running mean: -18.85153459303875, timestamp: 2022-08-19 09:21:13.461203\n",
      "resetting env. episode 5379, reward total was -20.0. running mean: -18.86301924710836, timestamp: 2022-08-19 09:21:16.726241\n",
      "resetting env. episode 5380, reward total was -14.0. running mean: -18.814389054637278, timestamp: 2022-08-19 09:21:21.998305\n",
      "resetting env. episode 5381, reward total was -19.0. running mean: -18.816245164090905, timestamp: 2022-08-19 09:21:26.552361\n",
      "resetting env. episode 5382, reward total was -17.0. running mean: -18.798082712449997, timestamp: 2022-08-19 09:21:31.562425\n",
      "resetting env. episode 5383, reward total was -21.0. running mean: -18.820101885325496, timestamp: 2022-08-19 09:21:36.280482\n",
      "resetting env. episode 5384, reward total was -20.0. running mean: -18.83190086647224, timestamp: 2022-08-19 09:21:40.199535\n",
      "resetting env. episode 5385, reward total was -19.0. running mean: -18.833581857807516, timestamp: 2022-08-19 09:21:45.122590\n",
      "resetting env. episode 5386, reward total was -17.0. running mean: -18.815246039229443, timestamp: 2022-08-19 09:21:49.063641\n",
      "resetting env. episode 5387, reward total was -19.0. running mean: -18.81709357883715, timestamp: 2022-08-19 09:21:54.061702\n",
      "resetting env. episode 5388, reward total was -19.0. running mean: -18.81892264304878, timestamp: 2022-08-19 09:21:59.647770\n",
      "resetting env. episode 5389, reward total was -20.0. running mean: -18.83073341661829, timestamp: 2022-08-19 09:22:03.987355\n",
      "resetting env. episode 5390, reward total was -20.0. running mean: -18.842426082452107, timestamp: 2022-08-19 09:22:08.247402\n",
      "resetting env. episode 5391, reward total was -19.0. running mean: -18.844001821627586, timestamp: 2022-08-19 09:22:12.740459\n",
      "resetting env. episode 5392, reward total was -17.0. running mean: -18.82556180341131, timestamp: 2022-08-19 09:22:17.159516\n",
      "resetting env. episode 5393, reward total was -19.0. running mean: -18.8273061853772, timestamp: 2022-08-19 09:22:21.190565\n",
      "resetting env. episode 5394, reward total was -21.0. running mean: -18.84903312352343, timestamp: 2022-08-19 09:22:25.386623\n",
      "resetting env. episode 5395, reward total was -20.0. running mean: -18.860542792288197, timestamp: 2022-08-19 09:22:30.231679\n",
      "resetting env. episode 5396, reward total was -19.0. running mean: -18.861937364365314, timestamp: 2022-08-19 09:22:35.033735\n",
      "resetting env. episode 5397, reward total was -20.0. running mean: -18.87331799072166, timestamp: 2022-08-19 09:22:40.240801\n",
      "resetting env. episode 5398, reward total was -20.0. running mean: -18.88458481081444, timestamp: 2022-08-19 09:22:44.806859\n",
      "resetting env. episode 5399, reward total was -18.0. running mean: -18.875738962706297, timestamp: 2022-08-19 09:22:48.778904\n",
      "resetting env. episode 5400, reward total was -17.0. running mean: -18.856981573079235, timestamp: 2022-08-19 09:22:54.282973\n",
      "resetting env. episode 5401, reward total was -20.0. running mean: -18.86841175734844, timestamp: 2022-08-19 09:22:57.736619\n",
      "resetting env. episode 5402, reward total was -18.0. running mean: -18.859727639774956, timestamp: 2022-08-19 09:23:01.804666\n",
      "resetting env. episode 5403, reward total was -19.0. running mean: -18.861130363377207, timestamp: 2022-08-19 09:23:06.580731\n",
      "resetting env. episode 5404, reward total was -19.0. running mean: -18.862519059743434, timestamp: 2022-08-19 09:23:11.136784\n",
      "resetting env. episode 5405, reward total was -19.0. running mean: -18.863893869146, timestamp: 2022-08-19 09:23:14.564829\n",
      "resetting env. episode 5406, reward total was -19.0. running mean: -18.86525493045454, timestamp: 2022-08-19 09:23:19.283887\n",
      "resetting env. episode 5407, reward total was -19.0. running mean: -18.866602381149995, timestamp: 2022-08-19 09:23:24.524949\n",
      "resetting env. episode 5408, reward total was -17.0. running mean: -18.847936357338497, timestamp: 2022-08-19 09:23:29.353011\n",
      "resetting env. episode 5409, reward total was -21.0. running mean: -18.869456993765112, timestamp: 2022-08-19 09:23:33.653063\n",
      "resetting env. episode 5410, reward total was -17.0. running mean: -18.85076242382746, timestamp: 2022-08-19 09:23:37.871114\n",
      "resetting env. episode 5411, reward total was -18.0. running mean: -18.84225479958919, timestamp: 2022-08-19 09:23:43.873728\n",
      "resetting env. episode 5412, reward total was -18.0. running mean: -18.833832251593297, timestamp: 2022-08-19 09:23:48.990787\n",
      "resetting env. episode 5413, reward total was -20.0. running mean: -18.845493929077364, timestamp: 2022-08-19 09:23:51.957826\n",
      "resetting env. episode 5414, reward total was -19.0. running mean: -18.84703898978659, timestamp: 2022-08-19 09:23:56.739886\n",
      "resetting env. episode 5415, reward total was -21.0. running mean: -18.868568599888725, timestamp: 2022-08-19 09:24:00.831935\n",
      "resetting env. episode 5416, reward total was -19.0. running mean: -18.86988291388984, timestamp: 2022-08-19 09:24:05.943000\n",
      "resetting env. episode 5417, reward total was -19.0. running mean: -18.87118408475094, timestamp: 2022-08-19 09:24:10.357055\n",
      "resetting env. episode 5418, reward total was -17.0. running mean: -18.85247224390343, timestamp: 2022-08-19 09:24:14.956114\n",
      "resetting env. episode 5419, reward total was -21.0. running mean: -18.873947521464398, timestamp: 2022-08-19 09:24:19.491173\n",
      "resetting env. episode 5420, reward total was -16.0. running mean: -18.845208046249756, timestamp: 2022-08-19 09:24:26.016250\n",
      "resetting env. episode 5421, reward total was -21.0. running mean: -18.86675596578726, timestamp: 2022-08-19 09:24:29.350296\n",
      "resetting env. episode 5422, reward total was -20.0. running mean: -18.878088406129386, timestamp: 2022-08-19 09:24:33.817351\n",
      "resetting env. episode 5423, reward total was -19.0. running mean: -18.879307522068093, timestamp: 2022-08-19 09:24:38.536408\n",
      "resetting env. episode 5424, reward total was -16.0. running mean: -18.850514446847413, timestamp: 2022-08-19 09:24:42.957460\n",
      "resetting env. episode 5425, reward total was -19.0. running mean: -18.85200930237894, timestamp: 2022-08-19 09:24:47.838524\n",
      "resetting env. episode 5426, reward total was -21.0. running mean: -18.87348920935515, timestamp: 2022-08-19 09:24:51.980573\n",
      "resetting env. episode 5427, reward total was -19.0. running mean: -18.874754317261598, timestamp: 2022-08-19 09:24:56.558632\n",
      "resetting env. episode 5428, reward total was -20.0. running mean: -18.88600677408898, timestamp: 2022-08-19 09:25:02.238705\n",
      "resetting env. episode 5429, reward total was -19.0. running mean: -18.88714670634809, timestamp: 2022-08-19 09:25:07.174758\n",
      "resetting env. episode 5430, reward total was -13.0. running mean: -18.828275239284608, timestamp: 2022-08-19 09:25:12.335823\n",
      "resetting env. episode 5431, reward total was -19.0. running mean: -18.82999248689176, timestamp: 2022-08-19 09:25:18.058894\n",
      "resetting env. episode 5432, reward total was -19.0. running mean: -18.831692562022845, timestamp: 2022-08-19 09:25:22.702954\n",
      "resetting env. episode 5433, reward total was -21.0. running mean: -18.853375636402617, timestamp: 2022-08-19 09:25:26.746002\n",
      "resetting env. episode 5434, reward total was -20.0. running mean: -18.86484188003859, timestamp: 2022-08-19 09:25:31.592060\n",
      "resetting env. episode 5435, reward total was -20.0. running mean: -18.876193461238202, timestamp: 2022-08-19 09:25:36.157115\n",
      "resetting env. episode 5436, reward total was -19.0. running mean: -18.87743152662582, timestamp: 2022-08-19 09:25:40.035166\n",
      "resetting env. episode 5437, reward total was -15.0. running mean: -18.83865721135956, timestamp: 2022-08-19 09:25:45.211226\n",
      "resetting env. episode 5438, reward total was -16.0. running mean: -18.810270639245964, timestamp: 2022-08-19 09:25:51.015303\n",
      "resetting env. episode 5439, reward total was -17.0. running mean: -18.792167932853506, timestamp: 2022-08-19 09:25:54.861349\n",
      "resetting env. episode 5440, reward total was -21.0. running mean: -18.81424625352497, timestamp: 2022-08-19 09:25:58.755393\n",
      "resetting env. episode 5441, reward total was -18.0. running mean: -18.80610379098972, timestamp: 2022-08-19 09:26:02.478439\n",
      "resetting env. episode 5442, reward total was -19.0. running mean: -18.808042753079825, timestamp: 2022-08-19 09:26:07.628502\n",
      "resetting env. episode 5443, reward total was -17.0. running mean: -18.789962325549027, timestamp: 2022-08-19 09:26:12.969569\n",
      "resetting env. episode 5444, reward total was -21.0. running mean: -18.812062702293538, timestamp: 2022-08-19 09:26:17.008620\n",
      "resetting env. episode 5445, reward total was -20.0. running mean: -18.8239420752706, timestamp: 2022-08-19 09:26:21.028669\n",
      "resetting env. episode 5446, reward total was -17.0. running mean: -18.805702654517898, timestamp: 2022-08-19 09:26:24.721720\n",
      "resetting env. episode 5447, reward total was -18.0. running mean: -18.797645627972717, timestamp: 2022-08-19 09:26:29.606772\n",
      "resetting env. episode 5448, reward total was -19.0. running mean: -18.79966917169299, timestamp: 2022-08-19 09:26:34.665832\n",
      "resetting env. episode 5449, reward total was -17.0. running mean: -18.781672479976063, timestamp: 2022-08-19 09:26:39.101887\n",
      "resetting env. episode 5450, reward total was -15.0. running mean: -18.743855755176302, timestamp: 2022-08-19 09:26:44.784956\n",
      "resetting env. episode 5451, reward total was -21.0. running mean: -18.76641719762454, timestamp: 2022-08-19 09:26:49.156014\n",
      "resetting env. episode 5452, reward total was -19.0. running mean: -18.768753025648298, timestamp: 2022-08-19 09:26:53.664064\n",
      "resetting env. episode 5453, reward total was -14.0. running mean: -18.721065495391816, timestamp: 2022-08-19 09:26:58.674127\n",
      "resetting env. episode 5454, reward total was -20.0. running mean: -18.733854840437896, timestamp: 2022-08-19 09:27:04.012196\n",
      "resetting env. episode 5455, reward total was -21.0. running mean: -18.756516292033517, timestamp: 2022-08-19 09:27:07.845238\n",
      "resetting env. episode 5456, reward total was -18.0. running mean: -18.74895112911318, timestamp: 2022-08-19 09:27:12.582296\n",
      "resetting env. episode 5457, reward total was -19.0. running mean: -18.75146161782205, timestamp: 2022-08-19 09:27:16.429343\n",
      "resetting env. episode 5458, reward total was -19.0. running mean: -18.75394700164383, timestamp: 2022-08-19 09:27:20.921399\n",
      "resetting env. episode 5459, reward total was -20.0. running mean: -18.76640753162739, timestamp: 2022-08-19 09:27:25.577459\n",
      "resetting env. episode 5460, reward total was -16.0. running mean: -18.738743456311116, timestamp: 2022-08-19 09:27:30.188299\n",
      "resetting env. episode 5461, reward total was -20.0. running mean: -18.751356021748006, timestamp: 2022-08-19 09:27:34.693357\n",
      "resetting env. episode 5462, reward total was -18.0. running mean: -18.743842461530527, timestamp: 2022-08-19 09:27:40.052422\n",
      "resetting env. episode 5463, reward total was -21.0. running mean: -18.766404036915223, timestamp: 2022-08-19 09:27:44.580479\n",
      "resetting env. episode 5464, reward total was -20.0. running mean: -18.77873999654607, timestamp: 2022-08-19 09:27:48.719524\n",
      "resetting env. episode 5465, reward total was -20.0. running mean: -18.790952596580606, timestamp: 2022-08-19 09:27:52.621573\n",
      "resetting env. episode 5466, reward total was -19.0. running mean: -18.7930430706148, timestamp: 2022-08-19 09:27:57.075630\n",
      "resetting env. episode 5467, reward total was -16.0. running mean: -18.76511263990865, timestamp: 2022-08-19 09:28:01.747685\n",
      "resetting env. episode 5468, reward total was -18.0. running mean: -18.757461513509565, timestamp: 2022-08-19 09:28:05.698734\n",
      "resetting env. episode 5469, reward total was -20.0. running mean: -18.76988689837447, timestamp: 2022-08-19 09:28:09.648778\n",
      "resetting env. episode 5470, reward total was -19.0. running mean: -18.772188029390726, timestamp: 2022-08-19 09:28:14.807841\n",
      "resetting env. episode 5471, reward total was -17.0. running mean: -18.75446614909682, timestamp: 2022-08-19 09:28:19.003890\n",
      "resetting env. episode 5472, reward total was -20.0. running mean: -18.766921487605853, timestamp: 2022-08-19 09:28:23.031940\n",
      "resetting env. episode 5473, reward total was -19.0. running mean: -18.769252272729794, timestamp: 2022-08-19 09:28:27.226990\n",
      "resetting env. episode 5474, reward total was -19.0. running mean: -18.771559750002496, timestamp: 2022-08-19 09:28:31.330042\n",
      "resetting env. episode 5475, reward total was -19.0. running mean: -18.773844152502473, timestamp: 2022-08-19 09:28:35.461090\n",
      "resetting env. episode 5476, reward total was -19.0. running mean: -18.77610571097745, timestamp: 2022-08-19 09:28:39.897143\n",
      "resetting env. episode 5477, reward total was -16.0. running mean: -18.748344653867676, timestamp: 2022-08-19 09:28:46.229220\n",
      "resetting env. episode 5478, reward total was -17.0. running mean: -18.730861207329, timestamp: 2022-08-19 09:28:51.279280\n",
      "resetting env. episode 5479, reward total was -17.0. running mean: -18.71355259525571, timestamp: 2022-08-19 09:28:55.344328\n",
      "resetting env. episode 5480, reward total was -17.0. running mean: -18.696417069303156, timestamp: 2022-08-19 09:29:00.481390\n",
      "resetting env. episode 5481, reward total was -15.0. running mean: -18.659452898610123, timestamp: 2022-08-19 09:29:04.732443\n",
      "resetting env. episode 5482, reward total was -17.0. running mean: -18.642858369624022, timestamp: 2022-08-19 09:29:09.368499\n",
      "resetting env. episode 5483, reward total was -20.0. running mean: -18.65642978592778, timestamp: 2022-08-19 09:29:13.522548\n",
      "resetting env. episode 5484, reward total was -19.0. running mean: -18.659865488068505, timestamp: 2022-08-19 09:29:17.371592\n",
      "resetting env. episode 5485, reward total was -19.0. running mean: -18.66326683318782, timestamp: 2022-08-19 09:29:21.314640\n",
      "resetting env. episode 5486, reward total was -19.0. running mean: -18.666634164855942, timestamp: 2022-08-19 09:29:26.356703\n",
      "resetting env. episode 5487, reward total was -19.0. running mean: -18.669967823207383, timestamp: 2022-08-19 09:29:30.819239\n",
      "resetting env. episode 5488, reward total was -18.0. running mean: -18.66326814497531, timestamp: 2022-08-19 09:29:36.232829\n",
      "resetting env. episode 5489, reward total was -20.0. running mean: -18.676635463525553, timestamp: 2022-08-19 09:29:40.757888\n",
      "resetting env. episode 5490, reward total was -20.0. running mean: -18.689869108890296, timestamp: 2022-08-19 09:29:45.240937\n",
      "resetting env. episode 5491, reward total was -17.0. running mean: -18.672970417801395, timestamp: 2022-08-19 09:29:48.943984\n",
      "resetting env. episode 5492, reward total was -20.0. running mean: -18.68624071362338, timestamp: 2022-08-19 09:29:53.074029\n",
      "resetting env. episode 5493, reward total was -18.0. running mean: -18.679378306487145, timestamp: 2022-08-19 09:29:57.640085\n",
      "resetting env. episode 5494, reward total was -18.0. running mean: -18.672584523422273, timestamp: 2022-08-19 09:30:02.085140\n",
      "resetting env. episode 5495, reward total was -17.0. running mean: -18.655858678188054, timestamp: 2022-08-19 09:30:06.504189\n",
      "resetting env. episode 5496, reward total was -18.0. running mean: -18.64930009140617, timestamp: 2022-08-19 09:30:10.683241\n",
      "resetting env. episode 5497, reward total was -19.0. running mean: -18.65280709049211, timestamp: 2022-08-19 09:30:15.127292\n",
      "resetting env. episode 5498, reward total was -16.0. running mean: -18.62627901958719, timestamp: 2022-08-19 09:30:20.559362\n",
      "resetting env. episode 5499, reward total was -18.0. running mean: -18.620016229391318, timestamp: 2022-08-19 09:30:24.977413\n",
      "resetting env. episode 5500, reward total was -20.0. running mean: -18.633816067097403, timestamp: 2022-08-19 09:30:30.492475\n",
      "resetting env. episode 5501, reward total was -20.0. running mean: -18.647477906426428, timestamp: 2022-08-19 09:30:35.121528\n",
      "resetting env. episode 5502, reward total was -19.0. running mean: -18.651003127362163, timestamp: 2022-08-19 09:30:39.543585\n",
      "resetting env. episode 5503, reward total was -17.0. running mean: -18.634493096088544, timestamp: 2022-08-19 09:30:44.276642\n",
      "resetting env. episode 5504, reward total was -19.0. running mean: -18.63814816512766, timestamp: 2022-08-19 09:30:49.844357\n",
      "resetting env. episode 5505, reward total was -21.0. running mean: -18.661766683476383, timestamp: 2022-08-19 09:30:55.362422\n",
      "resetting env. episode 5506, reward total was -19.0. running mean: -18.66514901664162, timestamp: 2022-08-19 09:31:00.082482\n",
      "resetting env. episode 5507, reward total was -19.0. running mean: -18.668497526475207, timestamp: 2022-08-19 09:31:04.555530\n",
      "resetting env. episode 5508, reward total was -17.0. running mean: -18.651812551210455, timestamp: 2022-08-19 09:31:09.513590\n",
      "resetting env. episode 5509, reward total was -18.0. running mean: -18.64529442569835, timestamp: 2022-08-19 09:31:14.444651\n",
      "resetting env. episode 5510, reward total was -19.0. running mean: -18.648841481441366, timestamp: 2022-08-19 09:31:18.420693\n",
      "resetting env. episode 5511, reward total was -21.0. running mean: -18.672353066626954, timestamp: 2022-08-19 09:31:22.582742\n",
      "resetting env. episode 5512, reward total was -18.0. running mean: -18.665629535960683, timestamp: 2022-08-19 09:31:27.375799\n",
      "resetting env. episode 5513, reward total was -21.0. running mean: -18.688973240601076, timestamp: 2022-08-19 09:31:31.569849\n",
      "resetting env. episode 5514, reward total was -19.0. running mean: -18.692083508195065, timestamp: 2022-08-19 09:31:36.538907\n",
      "resetting env. episode 5515, reward total was -19.0. running mean: -18.695162673113117, timestamp: 2022-08-19 09:31:41.061958\n",
      "resetting env. episode 5516, reward total was -19.0. running mean: -18.69821104638199, timestamp: 2022-08-19 09:31:45.587011\n",
      "resetting env. episode 5517, reward total was -20.0. running mean: -18.711228935918168, timestamp: 2022-08-19 09:31:50.236067\n",
      "resetting env. episode 5518, reward total was -18.0. running mean: -18.704116646558987, timestamp: 2022-08-19 09:31:54.960121\n",
      "resetting env. episode 5519, reward total was -19.0. running mean: -18.707075480093398, timestamp: 2022-08-19 09:31:59.188170\n",
      "resetting env. episode 5520, reward total was -19.0. running mean: -18.710004725292464, timestamp: 2022-08-19 09:32:04.133228\n",
      "resetting env. episode 5521, reward total was -20.0. running mean: -18.722904678039537, timestamp: 2022-08-19 09:32:08.947286\n",
      "resetting env. episode 5522, reward total was -21.0. running mean: -18.745675631259143, timestamp: 2022-08-19 09:32:14.594352\n",
      "resetting env. episode 5523, reward total was -19.0. running mean: -18.748218874946552, timestamp: 2022-08-19 09:32:18.915401\n",
      "resetting env. episode 5524, reward total was -19.0. running mean: -18.750736686197087, timestamp: 2022-08-19 09:32:24.472471\n",
      "resetting env. episode 5525, reward total was -18.0. running mean: -18.743229319335114, timestamp: 2022-08-19 09:32:28.659515\n",
      "resetting env. episode 5526, reward total was -19.0. running mean: -18.745797026141766, timestamp: 2022-08-19 09:32:32.232558\n",
      "resetting env. episode 5527, reward total was -18.0. running mean: -18.73833905588035, timestamp: 2022-08-19 09:32:37.233616\n",
      "resetting env. episode 5528, reward total was -19.0. running mean: -18.740955665321547, timestamp: 2022-08-19 09:32:41.489664\n",
      "resetting env. episode 5529, reward total was -15.0. running mean: -18.70354610866833, timestamp: 2022-08-19 09:32:46.570725\n",
      "resetting env. episode 5530, reward total was -19.0. running mean: -18.70651064758165, timestamp: 2022-08-19 09:32:51.311778\n",
      "resetting env. episode 5531, reward total was -18.0. running mean: -18.69944554110583, timestamp: 2022-08-19 09:32:54.897824\n",
      "resetting env. episode 5532, reward total was -20.0. running mean: -18.712451085694774, timestamp: 2022-08-19 09:32:58.637862\n",
      "resetting env. episode 5533, reward total was -18.0. running mean: -18.705326574837827, timestamp: 2022-08-19 09:33:03.031913\n",
      "resetting env. episode 5534, reward total was -18.0. running mean: -18.698273309089448, timestamp: 2022-08-19 09:33:07.711971\n",
      "resetting env. episode 5535, reward total was -18.0. running mean: -18.691290575998554, timestamp: 2022-08-19 09:33:12.126020\n",
      "resetting env. episode 5536, reward total was -21.0. running mean: -18.71437767023857, timestamp: 2022-08-19 09:33:17.178077\n",
      "resetting env. episode 5537, reward total was -21.0. running mean: -18.737233893536185, timestamp: 2022-08-19 09:33:20.766118\n",
      "resetting env. episode 5538, reward total was -21.0. running mean: -18.759861554600825, timestamp: 2022-08-19 09:33:24.566165\n",
      "resetting env. episode 5539, reward total was -19.0. running mean: -18.762262939054818, timestamp: 2022-08-19 09:33:29.753226\n",
      "resetting env. episode 5540, reward total was -19.0. running mean: -18.76464030966427, timestamp: 2022-08-19 09:33:34.917281\n",
      "resetting env. episode 5541, reward total was -19.0. running mean: -18.766993906567627, timestamp: 2022-08-19 09:33:40.012342\n",
      "resetting env. episode 5542, reward total was -21.0. running mean: -18.78932396750195, timestamp: 2022-08-19 09:33:45.325400\n",
      "resetting env. episode 5543, reward total was -19.0. running mean: -18.79143072782693, timestamp: 2022-08-19 09:33:50.277457\n",
      "resetting env. episode 5544, reward total was -21.0. running mean: -18.813516420548662, timestamp: 2022-08-19 09:33:54.743512\n",
      "resetting env. episode 5545, reward total was -16.0. running mean: -18.785381256343175, timestamp: 2022-08-19 09:33:59.270562\n",
      "resetting env. episode 5546, reward total was -20.0. running mean: -18.797527443779742, timestamp: 2022-08-19 09:34:03.314609\n",
      "resetting env. episode 5547, reward total was -19.0. running mean: -18.799552169341947, timestamp: 2022-08-19 09:34:07.465011\n",
      "resetting env. episode 5548, reward total was -20.0. running mean: -18.811556647648526, timestamp: 2022-08-19 09:34:11.705058\n",
      "resetting env. episode 5549, reward total was -15.0. running mean: -18.773441081172038, timestamp: 2022-08-19 09:34:16.303110\n",
      "resetting env. episode 5550, reward total was -20.0. running mean: -18.785706670360316, timestamp: 2022-08-19 09:34:20.807160\n",
      "resetting env. episode 5551, reward total was -18.0. running mean: -18.777849603656712, timestamp: 2022-08-19 09:34:26.495226\n",
      "resetting env. episode 5552, reward total was -18.0. running mean: -18.770071107620144, timestamp: 2022-08-19 09:34:30.959278\n",
      "resetting env. episode 5553, reward total was -17.0. running mean: -18.752370396543945, timestamp: 2022-08-19 09:34:36.153336\n",
      "resetting env. episode 5554, reward total was -19.0. running mean: -18.754846692578507, timestamp: 2022-08-19 09:34:41.200393\n",
      "resetting env. episode 5555, reward total was -17.0. running mean: -18.737298225652722, timestamp: 2022-08-19 09:34:45.490443\n",
      "resetting env. episode 5556, reward total was -20.0. running mean: -18.749925243396195, timestamp: 2022-08-19 09:34:49.069483\n",
      "resetting env. episode 5557, reward total was -19.0. running mean: -18.752425990962234, timestamp: 2022-08-19 09:34:53.810540\n",
      "resetting env. episode 5558, reward total was -18.0. running mean: -18.74490173105261, timestamp: 2022-08-19 09:34:58.464594\n",
      "resetting env. episode 5559, reward total was -15.0. running mean: -18.707452713742082, timestamp: 2022-08-19 09:35:03.724655\n",
      "resetting env. episode 5560, reward total was -18.0. running mean: -18.70037818660466, timestamp: 2022-08-19 09:35:07.734120\n",
      "resetting env. episode 5561, reward total was -19.0. running mean: -18.703374404738614, timestamp: 2022-08-19 09:35:13.958198\n",
      "resetting env. episode 5562, reward total was -15.0. running mean: -18.666340660691226, timestamp: 2022-08-19 09:35:19.042254\n",
      "resetting env. episode 5563, reward total was -17.0. running mean: -18.649677254084317, timestamp: 2022-08-19 09:35:23.421304\n",
      "resetting env. episode 5564, reward total was -17.0. running mean: -18.633180481543477, timestamp: 2022-08-19 09:35:28.647369\n",
      "resetting env. episode 5565, reward total was -17.0. running mean: -18.616848676728043, timestamp: 2022-08-19 09:35:33.431421\n",
      "resetting env. episode 5566, reward total was -21.0. running mean: -18.640680189960765, timestamp: 2022-08-19 09:35:37.835478\n",
      "resetting env. episode 5567, reward total was -19.0. running mean: -18.64427338806116, timestamp: 2022-08-19 09:35:42.069525\n",
      "resetting env. episode 5568, reward total was -20.0. running mean: -18.657830654180547, timestamp: 2022-08-19 09:35:46.360572\n",
      "resetting env. episode 5569, reward total was -19.0. running mean: -18.661252347638744, timestamp: 2022-08-19 09:35:50.860629\n",
      "resetting env. episode 5570, reward total was -13.0. running mean: -18.604639824162355, timestamp: 2022-08-19 09:35:57.393706\n",
      "resetting env. episode 5571, reward total was -20.0. running mean: -18.618593425920732, timestamp: 2022-08-19 09:36:02.592767\n",
      "resetting env. episode 5572, reward total was -20.0. running mean: -18.632407491661525, timestamp: 2022-08-19 09:36:08.077678\n",
      "resetting env. episode 5573, reward total was -21.0. running mean: -18.65608341674491, timestamp: 2022-08-19 09:36:13.541744\n",
      "resetting env. episode 5574, reward total was -21.0. running mean: -18.679522582577462, timestamp: 2022-08-19 09:36:17.547793\n",
      "resetting env. episode 5575, reward total was -19.0. running mean: -18.682727356751688, timestamp: 2022-08-19 09:36:22.330847\n",
      "resetting env. episode 5576, reward total was -16.0. running mean: -18.65590008318417, timestamp: 2022-08-19 09:36:27.815914\n",
      "resetting env. episode 5577, reward total was -17.0. running mean: -18.63934108235233, timestamp: 2022-08-19 09:36:32.562970\n",
      "resetting env. episode 5578, reward total was -17.0. running mean: -18.62294767152881, timestamp: 2022-08-19 09:36:37.322028\n",
      "resetting env. episode 5579, reward total was -19.0. running mean: -18.626718194813524, timestamp: 2022-08-19 09:36:42.316087\n",
      "resetting env. episode 5580, reward total was -17.0. running mean: -18.61045101286539, timestamp: 2022-08-19 09:36:47.764153\n",
      "resetting env. episode 5581, reward total was -20.0. running mean: -18.624346502736735, timestamp: 2022-08-19 09:36:51.590202\n",
      "resetting env. episode 5582, reward total was -18.0. running mean: -18.618103037709368, timestamp: 2022-08-19 09:36:55.343245\n",
      "resetting env. episode 5583, reward total was -20.0. running mean: -18.631922007332275, timestamp: 2022-08-19 09:36:59.000287\n",
      "resetting env. episode 5584, reward total was -21.0. running mean: -18.655602787258953, timestamp: 2022-08-19 09:37:03.174341\n",
      "resetting env. episode 5585, reward total was -19.0. running mean: -18.659046759386364, timestamp: 2022-08-19 09:37:07.033385\n",
      "resetting env. episode 5586, reward total was -19.0. running mean: -18.662456291792502, timestamp: 2022-08-19 09:37:10.702430\n",
      "resetting env. episode 5587, reward total was -21.0. running mean: -18.68583172887458, timestamp: 2022-08-19 09:37:15.256486\n",
      "resetting env. episode 5588, reward total was -17.0. running mean: -18.668973411585835, timestamp: 2022-08-19 09:37:20.161548\n",
      "resetting env. episode 5589, reward total was -21.0. running mean: -18.692283677469977, timestamp: 2022-08-19 09:37:25.645612\n",
      "resetting env. episode 5590, reward total was -20.0. running mean: -18.705360840695278, timestamp: 2022-08-19 09:37:30.355669\n",
      "resetting env. episode 5591, reward total was -17.0. running mean: -18.688307232288327, timestamp: 2022-08-19 09:37:35.463733\n",
      "resetting env. episode 5592, reward total was -20.0. running mean: -18.701424159965445, timestamp: 2022-08-19 09:37:39.779783\n",
      "resetting env. episode 5593, reward total was -18.0. running mean: -18.69440991836579, timestamp: 2022-08-19 09:37:43.723830\n",
      "resetting env. episode 5594, reward total was -20.0. running mean: -18.70746581918213, timestamp: 2022-08-19 09:37:48.422890\n",
      "resetting env. episode 5595, reward total was -19.0. running mean: -18.71039116099031, timestamp: 2022-08-19 09:37:53.468948\n",
      "resetting env. episode 5596, reward total was -18.0. running mean: -18.703287249380406, timestamp: 2022-08-19 09:37:58.509011\n",
      "resetting env. episode 5597, reward total was -19.0. running mean: -18.7062543768866, timestamp: 2022-08-19 09:38:03.930078\n",
      "resetting env. episode 5598, reward total was -19.0. running mean: -18.709191833117735, timestamp: 2022-08-19 09:38:08.919659\n",
      "resetting env. episode 5599, reward total was -17.0. running mean: -18.69209991478656, timestamp: 2022-08-19 09:38:13.963722\n",
      "resetting env. episode 5600, reward total was -15.0. running mean: -18.655178915638693, timestamp: 2022-08-19 09:38:18.736777\n",
      "resetting env. episode 5601, reward total was -19.0. running mean: -18.65862712648231, timestamp: 2022-08-19 09:38:23.228832\n",
      "resetting env. episode 5602, reward total was -17.0. running mean: -18.642040855217488, timestamp: 2022-08-19 09:38:28.107891\n",
      "resetting env. episode 5603, reward total was -20.0. running mean: -18.655620446665313, timestamp: 2022-08-19 09:38:32.996951\n",
      "resetting env. episode 5604, reward total was -17.0. running mean: -18.63906424219866, timestamp: 2022-08-19 09:38:37.092002\n",
      "resetting env. episode 5605, reward total was -21.0. running mean: -18.662673599776674, timestamp: 2022-08-19 09:38:42.009066\n",
      "resetting env. episode 5606, reward total was -19.0. running mean: -18.66604686377891, timestamp: 2022-08-19 09:38:46.312117\n",
      "resetting env. episode 5607, reward total was -17.0. running mean: -18.64938639514112, timestamp: 2022-08-19 09:38:51.047174\n",
      "resetting env. episode 5608, reward total was -19.0. running mean: -18.65289253118971, timestamp: 2022-08-19 09:38:54.975223\n",
      "resetting env. episode 5609, reward total was -20.0. running mean: -18.666363605877812, timestamp: 2022-08-19 09:38:59.824283\n",
      "resetting env. episode 5610, reward total was -19.0. running mean: -18.669699969819035, timestamp: 2022-08-19 09:39:04.317333\n",
      "resetting env. episode 5611, reward total was -19.0. running mean: -18.673002970120844, timestamp: 2022-08-19 09:39:09.425395\n",
      "resetting env. episode 5612, reward total was -16.0. running mean: -18.646272940419635, timestamp: 2022-08-19 09:39:14.618462\n",
      "resetting env. episode 5613, reward total was -19.0. running mean: -18.64981021101544, timestamp: 2022-08-19 09:39:18.414505\n",
      "resetting env. episode 5614, reward total was -18.0. running mean: -18.643312108905285, timestamp: 2022-08-19 09:39:22.971561\n",
      "resetting env. episode 5615, reward total was -19.0. running mean: -18.646878987816233, timestamp: 2022-08-19 09:39:27.276618\n",
      "resetting env. episode 5616, reward total was -20.0. running mean: -18.66041019793807, timestamp: 2022-08-19 09:39:32.166673\n",
      "resetting env. episode 5617, reward total was -20.0. running mean: -18.67380609595869, timestamp: 2022-08-19 09:39:36.832731\n",
      "resetting env. episode 5618, reward total was -19.0. running mean: -18.677068034999103, timestamp: 2022-08-19 09:39:42.028795\n",
      "resetting env. episode 5619, reward total was -16.0. running mean: -18.650297354649112, timestamp: 2022-08-19 09:39:46.506850\n",
      "resetting env. episode 5620, reward total was -17.0. running mean: -18.63379438110262, timestamp: 2022-08-19 09:39:51.395909\n",
      "resetting env. episode 5621, reward total was -18.0. running mean: -18.627456437291595, timestamp: 2022-08-19 09:39:56.781977\n",
      "resetting env. episode 5622, reward total was -17.0. running mean: -18.61118187291868, timestamp: 2022-08-19 09:40:01.925039\n",
      "resetting env. episode 5623, reward total was -18.0. running mean: -18.605070054189493, timestamp: 2022-08-19 09:40:06.224093\n",
      "resetting env. episode 5624, reward total was -20.0. running mean: -18.619019353647598, timestamp: 2022-08-19 09:40:11.471157\n",
      "resetting env. episode 5625, reward total was -17.0. running mean: -18.602829160111124, timestamp: 2022-08-19 09:40:16.910223\n",
      "resetting env. episode 5626, reward total was -19.0. running mean: -18.606800868510014, timestamp: 2022-08-19 09:40:22.080810\n",
      "resetting env. episode 5627, reward total was -15.0. running mean: -18.57073285982491, timestamp: 2022-08-19 09:40:27.114872\n",
      "resetting env. episode 5628, reward total was -21.0. running mean: -18.595025531226664, timestamp: 2022-08-19 09:40:31.252927\n",
      "resetting env. episode 5629, reward total was -19.0. running mean: -18.599075275914398, timestamp: 2022-08-19 09:40:35.578978\n",
      "resetting env. episode 5630, reward total was -19.0. running mean: -18.603084523155257, timestamp: 2022-08-19 09:40:40.246683\n",
      "resetting env. episode 5631, reward total was -18.0. running mean: -18.597053677923704, timestamp: 2022-08-19 09:40:45.655752\n",
      "resetting env. episode 5632, reward total was -20.0. running mean: -18.611083141144466, timestamp: 2022-08-19 09:40:49.727798\n",
      "resetting env. episode 5633, reward total was -18.0. running mean: -18.60497230973302, timestamp: 2022-08-19 09:40:53.913849\n",
      "resetting env. episode 5634, reward total was -20.0. running mean: -18.61892258663569, timestamp: 2022-08-19 09:40:58.259904\n",
      "resetting env. episode 5635, reward total was -17.0. running mean: -18.602733360769335, timestamp: 2022-08-19 09:41:03.429971\n",
      "resetting env. episode 5636, reward total was -17.0. running mean: -18.586706027161643, timestamp: 2022-08-19 09:41:08.095023\n",
      "resetting env. episode 5637, reward total was -19.0. running mean: -18.59083896689003, timestamp: 2022-08-19 09:41:12.268073\n",
      "resetting env. episode 5638, reward total was -19.0. running mean: -18.59493057722113, timestamp: 2022-08-19 09:41:17.327136\n",
      "resetting env. episode 5639, reward total was -20.0. running mean: -18.60898127144892, timestamp: 2022-08-19 09:41:22.055195\n",
      "resetting env. episode 5640, reward total was -20.0. running mean: -18.62289145873443, timestamp: 2022-08-19 09:41:26.729251\n",
      "resetting env. episode 5641, reward total was -18.0. running mean: -18.616662544147083, timestamp: 2022-08-19 09:41:31.063304\n",
      "resetting env. episode 5642, reward total was -21.0. running mean: -18.640495918705614, timestamp: 2022-08-19 09:41:35.598361\n",
      "resetting env. episode 5643, reward total was -18.0. running mean: -18.63409095951856, timestamp: 2022-08-19 09:41:40.017412\n",
      "resetting env. episode 5644, reward total was -19.0. running mean: -18.637750049923376, timestamp: 2022-08-19 09:41:44.998473\n",
      "resetting env. episode 5645, reward total was -21.0. running mean: -18.661372549424144, timestamp: 2022-08-19 09:41:47.766511\n",
      "resetting env. episode 5646, reward total was -20.0. running mean: -18.674758823929903, timestamp: 2022-08-19 09:41:51.749558\n",
      "resetting env. episode 5647, reward total was -19.0. running mean: -18.678011235690605, timestamp: 2022-08-19 09:41:56.150609\n",
      "resetting env. episode 5648, reward total was -20.0. running mean: -18.691231123333697, timestamp: 2022-08-19 09:42:01.980681\n",
      "resetting env. episode 5649, reward total was -21.0. running mean: -18.714318812100363, timestamp: 2022-08-19 09:42:06.747738\n",
      "resetting env. episode 5650, reward total was -19.0. running mean: -18.71717562397936, timestamp: 2022-08-19 09:42:11.753801\n",
      "resetting env. episode 5651, reward total was -20.0. running mean: -18.730003867739565, timestamp: 2022-08-19 09:42:15.922852\n",
      "resetting env. episode 5652, reward total was -21.0. running mean: -18.75270382906217, timestamp: 2022-08-19 09:42:19.285892\n",
      "resetting env. episode 5653, reward total was -19.0. running mean: -18.75517679077155, timestamp: 2022-08-19 09:42:23.379949\n",
      "resetting env. episode 5654, reward total was -21.0. running mean: -18.777625022863834, timestamp: 2022-08-19 09:42:27.443992\n",
      "resetting env. episode 5655, reward total was -16.0. running mean: -18.749848772635197, timestamp: 2022-08-19 09:42:33.642067\n",
      "resetting env. episode 5656, reward total was -18.0. running mean: -18.742350284908845, timestamp: 2022-08-19 09:42:37.718119\n",
      "resetting env. episode 5657, reward total was -16.0. running mean: -18.714926782059756, timestamp: 2022-08-19 09:42:42.967183\n",
      "resetting env. episode 5658, reward total was -17.0. running mean: -18.69777751423916, timestamp: 2022-08-19 09:42:47.267234\n",
      "resetting env. episode 5659, reward total was -19.0. running mean: -18.70079973909677, timestamp: 2022-08-19 09:42:51.606284\n",
      "resetting env. episode 5660, reward total was -19.0. running mean: -18.703791741705803, timestamp: 2022-08-19 09:42:56.101340\n",
      "resetting env. episode 5661, reward total was -19.0. running mean: -18.706753824288747, timestamp: 2022-08-19 09:43:00.275391\n",
      "resetting env. episode 5662, reward total was -20.0. running mean: -18.719686286045857, timestamp: 2022-08-19 09:43:05.777459\n",
      "resetting env. episode 5663, reward total was -19.0. running mean: -18.7224894231854, timestamp: 2022-08-19 09:43:11.147522\n",
      "resetting env. episode 5664, reward total was -18.0. running mean: -18.715264528953547, timestamp: 2022-08-19 09:43:15.739579\n",
      "resetting env. episode 5665, reward total was -17.0. running mean: -18.698111883664012, timestamp: 2022-08-19 09:43:21.193645\n",
      "resetting env. episode 5666, reward total was -21.0. running mean: -18.72113076482737, timestamp: 2022-08-19 09:43:25.153694\n",
      "resetting env. episode 5667, reward total was -18.0. running mean: -18.7139194571791, timestamp: 2022-08-19 09:43:30.148752\n",
      "resetting env. episode 5668, reward total was -19.0. running mean: -18.71678026260731, timestamp: 2022-08-19 09:43:34.701806\n",
      "resetting env. episode 5669, reward total was -19.0. running mean: -18.719612459981235, timestamp: 2022-08-19 09:43:39.618868\n",
      "resetting env. episode 5670, reward total was -21.0. running mean: -18.742416335381424, timestamp: 2022-08-19 09:43:44.189923\n",
      "resetting env. episode 5671, reward total was -19.0. running mean: -18.74499217202761, timestamp: 2022-08-19 09:43:49.318987\n",
      "resetting env. episode 5672, reward total was -17.0. running mean: -18.727542250307337, timestamp: 2022-08-19 09:43:53.120029\n",
      "resetting env. episode 5673, reward total was -19.0. running mean: -18.730266827804265, timestamp: 2022-08-19 09:43:57.065082\n",
      "resetting env. episode 5674, reward total was -16.0. running mean: -18.70296415952622, timestamp: 2022-08-19 09:44:03.359154\n",
      "resetting env. episode 5675, reward total was -20.0. running mean: -18.715934517930958, timestamp: 2022-08-19 09:44:07.455204\n",
      "resetting env. episode 5676, reward total was -16.0. running mean: -18.688775172751647, timestamp: 2022-08-19 09:44:12.502263\n",
      "resetting env. episode 5677, reward total was -18.0. running mean: -18.68188742102413, timestamp: 2022-08-19 09:44:17.223320\n",
      "resetting env. episode 5678, reward total was -18.0. running mean: -18.675068546813886, timestamp: 2022-08-19 09:44:22.118380\n",
      "resetting env. episode 5679, reward total was -21.0. running mean: -18.69831786134575, timestamp: 2022-08-19 09:44:26.433431\n",
      "resetting env. episode 5680, reward total was -16.0. running mean: -18.671334682732294, timestamp: 2022-08-19 09:44:31.837495\n",
      "resetting env. episode 5681, reward total was -17.0. running mean: -18.654621335904974, timestamp: 2022-08-19 09:44:36.102548\n",
      "resetting env. episode 5682, reward total was -21.0. running mean: -18.678075122545923, timestamp: 2022-08-19 09:44:40.496598\n",
      "resetting env. episode 5683, reward total was -19.0. running mean: -18.681294371320465, timestamp: 2022-08-19 09:44:45.790662\n",
      "resetting env. episode 5684, reward total was -20.0. running mean: -18.69448142760726, timestamp: 2022-08-19 09:44:50.476723\n",
      "resetting env. episode 5685, reward total was -21.0. running mean: -18.71753661333119, timestamp: 2022-08-19 09:44:54.504031\n",
      "resetting env. episode 5686, reward total was -16.0. running mean: -18.690361247197878, timestamp: 2022-08-19 09:44:59.786094\n",
      "resetting env. episode 5687, reward total was -21.0. running mean: -18.7134576347259, timestamp: 2022-08-19 09:45:04.234152\n",
      "resetting env. episode 5688, reward total was -19.0. running mean: -18.71632305837864, timestamp: 2022-08-19 09:45:09.662215\n",
      "resetting env. episode 5689, reward total was -21.0. running mean: -18.739159827794857, timestamp: 2022-08-19 09:45:14.111267\n",
      "resetting env. episode 5690, reward total was -20.0. running mean: -18.75176822951691, timestamp: 2022-08-19 09:45:18.679320\n",
      "resetting env. episode 5691, reward total was -19.0. running mean: -18.75425054722174, timestamp: 2022-08-19 09:45:23.411381\n",
      "resetting env. episode 5692, reward total was -21.0. running mean: -18.776708041749522, timestamp: 2022-08-19 09:45:28.145433\n",
      "resetting env. episode 5693, reward total was -21.0. running mean: -18.79894096133203, timestamp: 2022-08-19 09:45:31.816476\n",
      "resetting env. episode 5694, reward total was -19.0. running mean: -18.80095155171871, timestamp: 2022-08-19 09:45:36.624535\n",
      "resetting env. episode 5695, reward total was -17.0. running mean: -18.782942036201526, timestamp: 2022-08-19 09:45:41.426594\n",
      "resetting env. episode 5696, reward total was -15.0. running mean: -18.74511261583951, timestamp: 2022-08-19 09:45:46.242647\n",
      "resetting env. episode 5697, reward total was -19.0. running mean: -18.747661489681114, timestamp: 2022-08-19 09:45:50.483702\n",
      "resetting env. episode 5698, reward total was -20.0. running mean: -18.7601848747843, timestamp: 2022-08-19 09:45:53.987741\n",
      "resetting env. episode 5699, reward total was -17.0. running mean: -18.74258302603646, timestamp: 2022-08-19 09:45:58.180792\n",
      "resetting env. episode 5700, reward total was -17.0. running mean: -18.725157195776095, timestamp: 2022-08-19 09:46:02.933847\n",
      "resetting env. episode 5701, reward total was -14.0. running mean: -18.677905623818333, timestamp: 2022-08-19 09:46:08.303912\n",
      "resetting env. episode 5702, reward total was -15.0. running mean: -18.641126567580148, timestamp: 2022-08-19 09:46:13.306973\n",
      "resetting env. episode 5703, reward total was -17.0. running mean: -18.62471530190435, timestamp: 2022-08-19 09:46:19.500047\n",
      "resetting env. episode 5704, reward total was -19.0. running mean: -18.628468148885307, timestamp: 2022-08-19 09:46:26.016123\n",
      "resetting env. episode 5705, reward total was -17.0. running mean: -18.612183467396456, timestamp: 2022-08-19 09:46:30.878180\n",
      "resetting env. episode 5706, reward total was -21.0. running mean: -18.63606163272249, timestamp: 2022-08-19 09:46:35.828237\n",
      "resetting env. episode 5707, reward total was -17.0. running mean: -18.61970101639527, timestamp: 2022-08-19 09:46:40.174290\n",
      "resetting env. episode 5708, reward total was -21.0. running mean: -18.643504006231318, timestamp: 2022-08-19 09:46:44.642342\n",
      "resetting env. episode 5709, reward total was -19.0. running mean: -18.647068966169005, timestamp: 2022-08-19 09:46:49.279400\n",
      "resetting env. episode 5710, reward total was -19.0. running mean: -18.650598276507317, timestamp: 2022-08-19 09:46:54.599460\n",
      "resetting env. episode 5711, reward total was -15.0. running mean: -18.614092293742242, timestamp: 2022-08-19 09:46:59.397517\n",
      "resetting env. episode 5712, reward total was -17.0. running mean: -18.59795137080482, timestamp: 2022-08-19 09:47:03.826571\n",
      "resetting env. episode 5713, reward total was -19.0. running mean: -18.601971857096775, timestamp: 2022-08-19 09:47:08.371630\n",
      "resetting env. episode 5714, reward total was -19.0. running mean: -18.605952138525808, timestamp: 2022-08-19 09:47:13.083678\n",
      "resetting env. episode 5715, reward total was -17.0. running mean: -18.589892617140553, timestamp: 2022-08-19 09:47:17.875735\n",
      "resetting env. episode 5716, reward total was -16.0. running mean: -18.56399369096915, timestamp: 2022-08-19 09:47:22.676794\n",
      "resetting env. episode 5717, reward total was -19.0. running mean: -18.56835375405946, timestamp: 2022-08-19 09:47:27.542846\n",
      "resetting env. episode 5718, reward total was -20.0. running mean: -18.582670216518864, timestamp: 2022-08-19 09:47:31.940421\n",
      "resetting env. episode 5719, reward total was -19.0. running mean: -18.586843514353674, timestamp: 2022-08-19 09:47:35.881464\n",
      "resetting env. episode 5720, reward total was -19.0. running mean: -18.59097507921014, timestamp: 2022-08-19 09:47:40.497518\n",
      "resetting env. episode 5721, reward total was -19.0. running mean: -18.595065328418038, timestamp: 2022-08-19 09:47:45.038571\n",
      "resetting env. episode 5722, reward total was -18.0. running mean: -18.589114675133857, timestamp: 2022-08-19 09:47:49.725626\n",
      "resetting env. episode 5723, reward total was -18.0. running mean: -18.58322352838252, timestamp: 2022-08-19 09:47:54.347680\n",
      "resetting env. episode 5724, reward total was -18.0. running mean: -18.577391293098692, timestamp: 2022-08-19 09:47:58.896734\n",
      "resetting env. episode 5725, reward total was -18.0. running mean: -18.571617380167705, timestamp: 2022-08-19 09:48:03.536787\n",
      "resetting env. episode 5726, reward total was -19.0. running mean: -18.57590120636603, timestamp: 2022-08-19 09:48:07.700839\n",
      "resetting env. episode 5727, reward total was -16.0. running mean: -18.55014219430237, timestamp: 2022-08-19 09:48:11.938888\n",
      "resetting env. episode 5728, reward total was -21.0. running mean: -18.57464077235935, timestamp: 2022-08-19 09:48:16.599941\n",
      "resetting env. episode 5729, reward total was -17.0. running mean: -18.558894364635755, timestamp: 2022-08-19 09:48:21.344996\n",
      "resetting env. episode 5730, reward total was -21.0. running mean: -18.583305420989397, timestamp: 2022-08-19 09:48:25.403565\n",
      "resetting env. episode 5731, reward total was -18.0. running mean: -18.577472366779503, timestamp: 2022-08-19 09:48:30.293620\n",
      "resetting env. episode 5732, reward total was -19.0. running mean: -18.58169764311171, timestamp: 2022-08-19 09:48:35.371685\n",
      "resetting env. episode 5733, reward total was -16.0. running mean: -18.555880666680594, timestamp: 2022-08-19 09:48:41.078748\n",
      "resetting env. episode 5734, reward total was -18.0. running mean: -18.55032186001379, timestamp: 2022-08-19 09:48:46.386807\n",
      "resetting env. episode 5735, reward total was -16.0. running mean: -18.52481864141365, timestamp: 2022-08-19 09:48:51.247863\n",
      "resetting env. episode 5736, reward total was -17.0. running mean: -18.509570454999515, timestamp: 2022-08-19 09:48:55.422913\n",
      "resetting env. episode 5737, reward total was -16.0. running mean: -18.48447475044952, timestamp: 2022-08-19 09:48:59.889964\n",
      "resetting env. episode 5738, reward total was -16.0. running mean: -18.459630002945026, timestamp: 2022-08-19 09:49:05.455029\n",
      "resetting env. episode 5739, reward total was -20.0. running mean: -18.475033702915574, timestamp: 2022-08-19 09:49:09.632078\n",
      "resetting env. episode 5740, reward total was -17.0. running mean: -18.46028336588642, timestamp: 2022-08-19 09:49:14.929139\n",
      "resetting env. episode 5741, reward total was -17.0. running mean: -18.445680532227556, timestamp: 2022-08-19 09:49:19.699716\n",
      "resetting env. episode 5742, reward total was -19.0. running mean: -18.45122372690528, timestamp: 2022-08-19 09:49:24.240771\n",
      "resetting env. episode 5743, reward total was -16.0. running mean: -18.426711489636226, timestamp: 2022-08-19 09:49:29.320828\n",
      "resetting env. episode 5744, reward total was -17.0. running mean: -18.412444374739867, timestamp: 2022-08-19 09:49:33.308876\n",
      "resetting env. episode 5745, reward total was -18.0. running mean: -18.408319930992466, timestamp: 2022-08-19 09:49:38.973939\n",
      "resetting env. episode 5746, reward total was -19.0. running mean: -18.414236731682543, timestamp: 2022-08-19 09:49:43.170985\n",
      "resetting env. episode 5747, reward total was -20.0. running mean: -18.430094364365715, timestamp: 2022-08-19 09:49:47.340038\n",
      "resetting env. episode 5748, reward total was -19.0. running mean: -18.43579342072206, timestamp: 2022-08-19 09:49:51.992091\n",
      "resetting env. episode 5749, reward total was -19.0. running mean: -18.44143548651484, timestamp: 2022-08-19 09:49:56.536143\n",
      "resetting env. episode 5750, reward total was -19.0. running mean: -18.447021131649695, timestamp: 2022-08-19 09:50:01.596199\n",
      "resetting env. episode 5751, reward total was -17.0. running mean: -18.4325509203332, timestamp: 2022-08-19 09:50:06.201254\n",
      "resetting env. episode 5752, reward total was -16.0. running mean: -18.408225411129866, timestamp: 2022-08-19 09:50:10.848306\n",
      "resetting env. episode 5753, reward total was -19.0. running mean: -18.414143157018568, timestamp: 2022-08-19 09:50:15.777363\n",
      "resetting env. episode 5754, reward total was -17.0. running mean: -18.400001725448384, timestamp: 2022-08-19 09:50:21.742430\n",
      "resetting env. episode 5755, reward total was -18.0. running mean: -18.3960017081939, timestamp: 2022-08-19 09:50:26.184479\n",
      "resetting env. episode 5756, reward total was -14.0. running mean: -18.35204169111196, timestamp: 2022-08-19 09:50:31.897545\n",
      "resetting env. episode 5757, reward total was -18.0. running mean: -18.34852127420084, timestamp: 2022-08-19 09:50:36.114594\n",
      "resetting env. episode 5758, reward total was -19.0. running mean: -18.355036061458833, timestamp: 2022-08-19 09:50:40.644649\n",
      "resetting env. episode 5759, reward total was -17.0. running mean: -18.341485700844245, timestamp: 2022-08-19 09:50:46.025705\n",
      "resetting env. episode 5760, reward total was -19.0. running mean: -18.348070843835803, timestamp: 2022-08-19 09:50:50.394756\n",
      "resetting env. episode 5761, reward total was -20.0. running mean: -18.364590135397442, timestamp: 2022-08-19 09:50:54.200799\n",
      "resetting env. episode 5762, reward total was -18.0. running mean: -18.36094423404347, timestamp: 2022-08-19 09:50:59.217859\n",
      "resetting env. episode 5763, reward total was -18.0. running mean: -18.357334791703035, timestamp: 2022-08-19 09:51:03.750909\n",
      "resetting env. episode 5764, reward total was -20.0. running mean: -18.373761443786005, timestamp: 2022-08-19 09:51:08.276958\n",
      "resetting env. episode 5765, reward total was -19.0. running mean: -18.380023829348147, timestamp: 2022-08-19 09:51:14.203026\n",
      "resetting env. episode 5766, reward total was -20.0. running mean: -18.396223591054664, timestamp: 2022-08-19 09:51:18.111069\n",
      "resetting env. episode 5767, reward total was -20.0. running mean: -18.412261355144118, timestamp: 2022-08-19 09:51:23.190127\n",
      "resetting env. episode 5768, reward total was -18.0. running mean: -18.408138741592676, timestamp: 2022-08-19 09:51:28.876193\n",
      "resetting env. episode 5769, reward total was -18.0. running mean: -18.40405735417675, timestamp: 2022-08-19 09:51:34.086252\n",
      "resetting env. episode 5770, reward total was -21.0. running mean: -18.430016780634983, timestamp: 2022-08-19 09:51:38.519301\n",
      "resetting env. episode 5771, reward total was -16.0. running mean: -18.405716612828634, timestamp: 2022-08-19 09:51:43.693364\n",
      "resetting env. episode 5772, reward total was -19.0. running mean: -18.411659446700348, timestamp: 2022-08-19 09:51:47.869411\n",
      "resetting env. episode 5773, reward total was -19.0. running mean: -18.417542852233346, timestamp: 2022-08-19 09:51:52.117458\n",
      "resetting env. episode 5774, reward total was -16.0. running mean: -18.393367423711013, timestamp: 2022-08-19 09:51:57.289517\n",
      "resetting env. episode 5775, reward total was -15.0. running mean: -18.3594337494739, timestamp: 2022-08-19 09:52:02.453578\n",
      "resetting env. episode 5776, reward total was -20.0. running mean: -18.37583941197916, timestamp: 2022-08-19 09:52:06.533626\n",
      "resetting env. episode 5777, reward total was -20.0. running mean: -18.39208101785937, timestamp: 2022-08-19 09:52:10.997673\n",
      "resetting env. episode 5778, reward total was -18.0. running mean: -18.388160207680773, timestamp: 2022-08-19 09:52:16.443737\n",
      "resetting env. episode 5779, reward total was -18.0. running mean: -18.384278605603964, timestamp: 2022-08-19 09:52:22.251805\n",
      "resetting env. episode 5780, reward total was -17.0. running mean: -18.370435819547925, timestamp: 2022-08-19 09:52:26.968860\n",
      "resetting env. episode 5781, reward total was -21.0. running mean: -18.396731461352445, timestamp: 2022-08-19 09:52:30.188897\n",
      "resetting env. episode 5782, reward total was -19.0. running mean: -18.40276414673892, timestamp: 2022-08-19 09:52:34.128947\n",
      "resetting env. episode 5783, reward total was -19.0. running mean: -18.408736505271534, timestamp: 2022-08-19 09:52:38.463997\n",
      "resetting env. episode 5784, reward total was -16.0. running mean: -18.38464914021882, timestamp: 2022-08-19 09:52:43.728056\n",
      "resetting env. episode 5785, reward total was -16.0. running mean: -18.36080264881663, timestamp: 2022-08-19 09:52:49.104119\n",
      "resetting env. episode 5786, reward total was -18.0. running mean: -18.357194622328464, timestamp: 2022-08-19 09:52:53.929177\n",
      "resetting env. episode 5787, reward total was -19.0. running mean: -18.36362267610518, timestamp: 2022-08-19 09:52:58.396232\n",
      "resetting env. episode 5788, reward total was -17.0. running mean: -18.34998644934413, timestamp: 2022-08-19 09:53:03.221284\n",
      "resetting env. episode 5789, reward total was -18.0. running mean: -18.346486584850688, timestamp: 2022-08-19 09:53:08.933353\n",
      "resetting env. episode 5790, reward total was -15.0. running mean: -18.31302171900218, timestamp: 2022-08-19 09:53:14.258417\n",
      "resetting env. episode 5791, reward total was -19.0. running mean: -18.319891501812158, timestamp: 2022-08-19 09:53:18.641467\n",
      "resetting env. episode 5792, reward total was -19.0. running mean: -18.32669258679404, timestamp: 2022-08-19 09:53:22.989522\n",
      "resetting env. episode 5793, reward total was -18.0. running mean: -18.323425660926098, timestamp: 2022-08-19 09:53:28.523586\n",
      "resetting env. episode 5794, reward total was -19.0. running mean: -18.33019140431684, timestamp: 2022-08-19 09:53:33.506646\n",
      "resetting env. episode 5795, reward total was -20.0. running mean: -18.346889490273668, timestamp: 2022-08-19 09:53:38.336706\n",
      "resetting env. episode 5796, reward total was -19.0. running mean: -18.35342059537093, timestamp: 2022-08-19 09:53:42.871756\n",
      "resetting env. episode 5797, reward total was -21.0. running mean: -18.379886389417223, timestamp: 2022-08-19 09:53:46.880804\n",
      "resetting env. episode 5798, reward total was -21.0. running mean: -18.406087525523052, timestamp: 2022-08-19 09:53:51.047854\n",
      "resetting env. episode 5799, reward total was -20.0. running mean: -18.42202665026782, timestamp: 2022-08-19 09:53:56.094916\n",
      "resetting env. episode 5800, reward total was -19.0. running mean: -18.427806383765144, timestamp: 2022-08-19 09:54:00.928972\n",
      "resetting env. episode 5801, reward total was -21.0. running mean: -18.453528319927493, timestamp: 2022-08-19 09:54:05.153026\n",
      "resetting env. episode 5802, reward total was -21.0. running mean: -18.47899303672822, timestamp: 2022-08-19 09:54:09.691083\n",
      "resetting env. episode 5803, reward total was -17.0. running mean: -18.464203106360937, timestamp: 2022-08-19 09:54:14.643139\n",
      "resetting env. episode 5804, reward total was -20.0. running mean: -18.479561075297326, timestamp: 2022-08-19 09:54:18.694190\n",
      "resetting env. episode 5805, reward total was -20.0. running mean: -18.49476546454435, timestamp: 2022-08-19 09:54:23.409242\n",
      "resetting env. episode 5806, reward total was -18.0. running mean: -18.489817809898906, timestamp: 2022-08-19 09:54:28.638311\n",
      "resetting env. episode 5807, reward total was -20.0. running mean: -18.504919631799915, timestamp: 2022-08-19 09:54:32.734355\n",
      "resetting env. episode 5808, reward total was -16.0. running mean: -18.479870435481917, timestamp: 2022-08-19 09:54:37.979419\n",
      "resetting env. episode 5809, reward total was -21.0. running mean: -18.5050717311271, timestamp: 2022-08-19 09:54:42.405474\n",
      "resetting env. episode 5810, reward total was -20.0. running mean: -18.52002101381583, timestamp: 2022-08-19 09:54:46.626525\n",
      "resetting env. episode 5811, reward total was -20.0. running mean: -18.53482080367767, timestamp: 2022-08-19 09:54:51.232582\n",
      "resetting env. episode 5812, reward total was -20.0. running mean: -18.54947259564089, timestamp: 2022-08-19 09:54:54.505622\n",
      "resetting env. episode 5813, reward total was -19.0. running mean: -18.55397786968448, timestamp: 2022-08-19 09:54:58.883674\n",
      "resetting env. episode 5814, reward total was -19.0. running mean: -18.558438090987636, timestamp: 2022-08-19 09:55:03.429728\n",
      "resetting env. episode 5815, reward total was -17.0. running mean: -18.54285371007776, timestamp: 2022-08-19 09:55:08.820796\n",
      "resetting env. episode 5816, reward total was -19.0. running mean: -18.547425172976986, timestamp: 2022-08-19 09:55:13.857854\n",
      "resetting env. episode 5817, reward total was -17.0. running mean: -18.53195092124722, timestamp: 2022-08-19 09:55:18.383907\n",
      "resetting env. episode 5818, reward total was -21.0. running mean: -18.556631412034747, timestamp: 2022-08-19 09:55:22.227474\n",
      "resetting env. episode 5819, reward total was -20.0. running mean: -18.5710650979144, timestamp: 2022-08-19 09:55:27.070538\n",
      "resetting env. episode 5820, reward total was -17.0. running mean: -18.555354446935258, timestamp: 2022-08-19 09:55:31.584585\n",
      "resetting env. episode 5821, reward total was -17.0. running mean: -18.539800902465906, timestamp: 2022-08-19 09:55:37.430657\n",
      "resetting env. episode 5822, reward total was -20.0. running mean: -18.554402893441246, timestamp: 2022-08-19 09:55:41.992715\n",
      "resetting env. episode 5823, reward total was -18.0. running mean: -18.548858864506833, timestamp: 2022-08-19 09:55:46.995772\n",
      "resetting env. episode 5824, reward total was -16.0. running mean: -18.523370275861765, timestamp: 2022-08-19 09:55:52.180837\n",
      "resetting env. episode 5825, reward total was -20.0. running mean: -18.538136573103145, timestamp: 2022-08-19 09:55:56.776895\n",
      "resetting env. episode 5826, reward total was -19.0. running mean: -18.542755207372114, timestamp: 2022-08-19 09:56:01.974957\n",
      "resetting env. episode 5827, reward total was -19.0. running mean: -18.547327655298393, timestamp: 2022-08-19 09:56:06.865015\n",
      "resetting env. episode 5828, reward total was -21.0. running mean: -18.57185437874541, timestamp: 2022-08-19 09:56:11.368067\n",
      "resetting env. episode 5829, reward total was -21.0. running mean: -18.596135834957956, timestamp: 2022-08-19 09:56:16.677138\n",
      "resetting env. episode 5830, reward total was -19.0. running mean: -18.600174476608377, timestamp: 2022-08-19 09:56:20.574180\n",
      "resetting env. episode 5831, reward total was -20.0. running mean: -18.61417273184229, timestamp: 2022-08-19 09:56:24.591233\n",
      "resetting env. episode 5832, reward total was -20.0. running mean: -18.62803100452387, timestamp: 2022-08-19 09:56:28.744284\n",
      "resetting env. episode 5833, reward total was -20.0. running mean: -18.64175069447863, timestamp: 2022-08-19 09:56:32.801330\n",
      "resetting env. episode 5834, reward total was -19.0. running mean: -18.645333187533847, timestamp: 2022-08-19 09:56:37.787394\n",
      "resetting env. episode 5835, reward total was -20.0. running mean: -18.65887985565851, timestamp: 2022-08-19 09:56:41.494437\n",
      "resetting env. episode 5836, reward total was -19.0. running mean: -18.662291057101925, timestamp: 2022-08-19 09:56:45.805491\n",
      "resetting env. episode 5837, reward total was -19.0. running mean: -18.665668146530905, timestamp: 2022-08-19 09:56:50.399547\n",
      "resetting env. episode 5838, reward total was -16.0. running mean: -18.639011465065597, timestamp: 2022-08-19 09:56:57.150629\n",
      "resetting env. episode 5839, reward total was -19.0. running mean: -18.64262135041494, timestamp: 2022-08-19 09:57:02.022685\n",
      "resetting env. episode 5840, reward total was -18.0. running mean: -18.636195136910793, timestamp: 2022-08-19 09:57:07.503753\n",
      "resetting env. episode 5841, reward total was -16.0. running mean: -18.609833185541685, timestamp: 2022-08-19 09:57:12.858818\n",
      "resetting env. episode 5842, reward total was -15.0. running mean: -18.57373485368627, timestamp: 2022-08-19 09:57:18.593888\n",
      "resetting env. episode 5843, reward total was -19.0. running mean: -18.57799750514941, timestamp: 2022-08-19 09:57:23.746951\n",
      "resetting env. episode 5844, reward total was -16.0. running mean: -18.552217530097913, timestamp: 2022-08-19 09:57:28.517014\n",
      "resetting env. episode 5845, reward total was -19.0. running mean: -18.556695354796936, timestamp: 2022-08-19 09:57:33.341069\n",
      "resetting env. episode 5846, reward total was -18.0. running mean: -18.551128401248967, timestamp: 2022-08-19 09:57:38.722133\n",
      "resetting env. episode 5847, reward total was -20.0. running mean: -18.565617117236478, timestamp: 2022-08-19 09:57:43.188188\n",
      "resetting env. episode 5848, reward total was -18.0. running mean: -18.559960946064113, timestamp: 2022-08-19 09:57:48.364254\n",
      "resetting env. episode 5849, reward total was -21.0. running mean: -18.58436133660347, timestamp: 2022-08-19 09:57:52.990308\n",
      "resetting env. episode 5850, reward total was -17.0. running mean: -18.568517723237438, timestamp: 2022-08-19 09:57:58.336373\n",
      "resetting env. episode 5851, reward total was -16.0. running mean: -18.542832546005062, timestamp: 2022-08-19 09:58:03.196436\n",
      "resetting env. episode 5852, reward total was -15.0. running mean: -18.50740422054501, timestamp: 2022-08-19 09:58:08.987504\n",
      "resetting env. episode 5853, reward total was -20.0. running mean: -18.52233017833956, timestamp: 2022-08-19 09:58:13.919565\n",
      "resetting env. episode 5854, reward total was -17.0. running mean: -18.507106876556165, timestamp: 2022-08-19 09:58:18.539624\n",
      "resetting env. episode 5855, reward total was -19.0. running mean: -18.512035807790603, timestamp: 2022-08-19 09:58:22.987677\n",
      "resetting env. episode 5856, reward total was -18.0. running mean: -18.506915449712697, timestamp: 2022-08-19 09:58:27.026726\n",
      "resetting env. episode 5857, reward total was -20.0. running mean: -18.521846295215568, timestamp: 2022-08-19 09:58:31.378777\n",
      "resetting env. episode 5858, reward total was -18.0. running mean: -18.51662783226341, timestamp: 2022-08-19 09:58:35.721832\n",
      "resetting env. episode 5859, reward total was -18.0. running mean: -18.511461553940777, timestamp: 2022-08-19 09:58:40.565887\n",
      "resetting env. episode 5860, reward total was -19.0. running mean: -18.51634693840137, timestamp: 2022-08-19 09:58:45.685950\n",
      "resetting env. episode 5861, reward total was -19.0. running mean: -18.521183469017355, timestamp: 2022-08-19 09:58:49.822001\n",
      "resetting env. episode 5862, reward total was -19.0. running mean: -18.52597163432718, timestamp: 2022-08-19 09:58:55.746071\n",
      "resetting env. episode 5863, reward total was -21.0. running mean: -18.55071191798391, timestamp: 2022-08-19 09:58:59.205112\n",
      "resetting env. episode 5864, reward total was -19.0. running mean: -18.555204798804073, timestamp: 2022-08-19 09:59:03.396163\n",
      "resetting env. episode 5865, reward total was -19.0. running mean: -18.559652750816035, timestamp: 2022-08-19 09:59:08.034223\n",
      "resetting env. episode 5866, reward total was -16.0. running mean: -18.534056223307875, timestamp: 2022-08-19 09:59:13.342285\n",
      "resetting env. episode 5867, reward total was -18.0. running mean: -18.528715661074795, timestamp: 2022-08-19 09:59:18.378346\n",
      "resetting env. episode 5868, reward total was -19.0. running mean: -18.533428504464048, timestamp: 2022-08-19 09:59:23.198406\n",
      "resetting env. episode 5869, reward total was -17.0. running mean: -18.51809421941941, timestamp: 2022-08-19 09:59:27.993465\n",
      "resetting env. episode 5870, reward total was -19.0. running mean: -18.522913277225218, timestamp: 2022-08-19 09:59:32.734517\n",
      "resetting env. episode 5871, reward total was -21.0. running mean: -18.547684144452965, timestamp: 2022-08-19 09:59:36.382562\n",
      "resetting env. episode 5872, reward total was -19.0. running mean: -18.552207303008437, timestamp: 2022-08-19 09:59:40.423611\n",
      "resetting env. episode 5873, reward total was -18.0. running mean: -18.54668522997835, timestamp: 2022-08-19 09:59:44.994666\n",
      "resetting env. episode 5874, reward total was -19.0. running mean: -18.55121837767857, timestamp: 2022-08-19 09:59:49.972728\n",
      "resetting env. episode 5875, reward total was -17.0. running mean: -18.535706193901785, timestamp: 2022-08-19 09:59:55.681797\n",
      "resetting env. episode 5876, reward total was -21.0. running mean: -18.560349131962766, timestamp: 2022-08-19 10:00:00.799858\n",
      "resetting env. episode 5877, reward total was -21.0. running mean: -18.58474564064314, timestamp: 2022-08-19 10:00:06.811932\n",
      "resetting env. episode 5878, reward total was -21.0. running mean: -18.608898184236708, timestamp: 2022-08-19 10:00:11.645990\n",
      "resetting env. episode 5879, reward total was -16.0. running mean: -18.58280920239434, timestamp: 2022-08-19 10:00:15.715040\n",
      "resetting env. episode 5880, reward total was -17.0. running mean: -18.5669811103704, timestamp: 2022-08-19 10:00:20.429097\n",
      "resetting env. episode 5881, reward total was -19.0. running mean: -18.571311299266696, timestamp: 2022-08-19 10:00:24.844148\n",
      "resetting env. episode 5882, reward total was -18.0. running mean: -18.56559818627403, timestamp: 2022-08-19 10:00:29.870210\n",
      "resetting env. episode 5883, reward total was -18.0. running mean: -18.55994220441129, timestamp: 2022-08-19 10:00:35.130271\n",
      "resetting env. episode 5884, reward total was -19.0. running mean: -18.564342782367177, timestamp: 2022-08-19 10:00:39.244321\n",
      "resetting env. episode 5885, reward total was -20.0. running mean: -18.578699354543506, timestamp: 2022-08-19 10:00:43.884378\n",
      "resetting env. episode 5886, reward total was -19.0. running mean: -18.582912360998073, timestamp: 2022-08-19 10:00:48.520436\n",
      "resetting env. episode 5887, reward total was -18.0. running mean: -18.57708323738809, timestamp: 2022-08-19 10:00:52.563482\n",
      "resetting env. episode 5888, reward total was -17.0. running mean: -18.561312405014213, timestamp: 2022-08-19 10:00:56.491533\n",
      "resetting env. episode 5889, reward total was -20.0. running mean: -18.57569928096407, timestamp: 2022-08-19 10:01:00.599581\n",
      "resetting env. episode 5890, reward total was -19.0. running mean: -18.57994228815443, timestamp: 2022-08-19 10:01:05.191633\n",
      "resetting env. episode 5891, reward total was -21.0. running mean: -18.604142865272888, timestamp: 2022-08-19 10:01:09.476685\n",
      "resetting env. episode 5892, reward total was -19.0. running mean: -18.60810143662016, timestamp: 2022-08-19 10:01:13.914742\n",
      "resetting env. episode 5893, reward total was -18.0. running mean: -18.602020422253958, timestamp: 2022-08-19 10:01:19.842810\n",
      "resetting env. episode 5894, reward total was -17.0. running mean: -18.58600021803142, timestamp: 2022-08-19 10:01:24.872871\n",
      "resetting env. episode 5895, reward total was -20.0. running mean: -18.600140215851106, timestamp: 2022-08-19 10:01:29.311640\n",
      "resetting env. episode 5896, reward total was -21.0. running mean: -18.624138813692596, timestamp: 2022-08-19 10:01:34.827703\n",
      "resetting env. episode 5897, reward total was -18.0. running mean: -18.617897425555668, timestamp: 2022-08-19 10:01:39.575764\n",
      "resetting env. episode 5898, reward total was -16.0. running mean: -18.59171845130011, timestamp: 2022-08-19 10:01:44.542823\n",
      "resetting env. episode 5899, reward total was -18.0. running mean: -18.585801266787108, timestamp: 2022-08-19 10:01:49.644880\n",
      "resetting env. episode 5900, reward total was -20.0. running mean: -18.599943254119236, timestamp: 2022-08-19 10:01:54.550938\n",
      "resetting env. episode 5901, reward total was -17.0. running mean: -18.583943821578046, timestamp: 2022-08-19 10:02:00.236010\n",
      "resetting env. episode 5902, reward total was -15.0. running mean: -18.548104383362265, timestamp: 2022-08-19 10:02:05.312069\n",
      "resetting env. episode 5903, reward total was -20.0. running mean: -18.562623339528642, timestamp: 2022-08-19 10:02:11.051134\n",
      "resetting env. episode 5904, reward total was -19.0. running mean: -18.566997106133357, timestamp: 2022-08-19 10:02:15.957204\n",
      "resetting env. episode 5905, reward total was -21.0. running mean: -18.591327135072024, timestamp: 2022-08-19 10:02:20.169245\n",
      "resetting env. episode 5906, reward total was -19.0. running mean: -18.595413863721305, timestamp: 2022-08-19 10:02:24.230294\n",
      "resetting env. episode 5907, reward total was -20.0. running mean: -18.60945972508409, timestamp: 2022-08-19 10:02:29.826358\n",
      "resetting env. episode 5908, reward total was -16.0. running mean: -18.58336512783325, timestamp: 2022-08-19 10:02:34.783419\n",
      "resetting env. episode 5909, reward total was -21.0. running mean: -18.607531476554918, timestamp: 2022-08-19 10:02:40.005480\n",
      "resetting env. episode 5910, reward total was -19.0. running mean: -18.61145616178937, timestamp: 2022-08-19 10:02:44.601535\n",
      "resetting env. episode 5911, reward total was -20.0. running mean: -18.625341600171474, timestamp: 2022-08-19 10:02:49.439591\n",
      "resetting env. episode 5912, reward total was -16.0. running mean: -18.59908818416976, timestamp: 2022-08-19 10:02:54.141649\n",
      "resetting env. episode 5913, reward total was -17.0. running mean: -18.583097302328063, timestamp: 2022-08-19 10:02:59.673713\n",
      "resetting env. episode 5914, reward total was -16.0. running mean: -18.55726632930478, timestamp: 2022-08-19 10:03:04.261768\n",
      "resetting env. episode 5915, reward total was -16.0. running mean: -18.531693666011734, timestamp: 2022-08-19 10:03:10.080834\n",
      "resetting env. episode 5916, reward total was -16.0. running mean: -18.506376729351615, timestamp: 2022-08-19 10:03:15.103894\n",
      "resetting env. episode 5917, reward total was -19.0. running mean: -18.5113129620581, timestamp: 2022-08-19 10:03:18.536937\n",
      "resetting env. episode 5918, reward total was -17.0. running mean: -18.49619983243752, timestamp: 2022-08-19 10:03:23.260993\n",
      "resetting env. episode 5919, reward total was -19.0. running mean: -18.501237834113144, timestamp: 2022-08-19 10:03:27.352037\n",
      "resetting env. episode 5920, reward total was -16.0. running mean: -18.476225455772013, timestamp: 2022-08-19 10:03:31.802090\n",
      "resetting env. episode 5921, reward total was -21.0. running mean: -18.501463201214293, timestamp: 2022-08-19 10:03:35.679136\n",
      "resetting env. episode 5922, reward total was -19.0. running mean: -18.50644856920215, timestamp: 2022-08-19 10:03:40.257198\n",
      "resetting env. episode 5923, reward total was -21.0. running mean: -18.53138408351013, timestamp: 2022-08-19 10:03:45.839258\n",
      "resetting env. episode 5924, reward total was -19.0. running mean: -18.53607024267503, timestamp: 2022-08-19 10:03:50.513311\n",
      "resetting env. episode 5925, reward total was -17.0. running mean: -18.520709540248284, timestamp: 2022-08-19 10:03:55.262366\n",
      "resetting env. episode 5926, reward total was -17.0. running mean: -18.505502444845803, timestamp: 2022-08-19 10:03:59.583418\n",
      "resetting env. episode 5927, reward total was -19.0. running mean: -18.510447420397345, timestamp: 2022-08-19 10:04:05.052502\n",
      "resetting env. episode 5928, reward total was -21.0. running mean: -18.53534294619337, timestamp: 2022-08-19 10:04:10.174562\n",
      "resetting env. episode 5929, reward total was -20.0. running mean: -18.549989516731436, timestamp: 2022-08-19 10:04:14.382611\n",
      "resetting env. episode 5930, reward total was -19.0. running mean: -18.554489621564123, timestamp: 2022-08-19 10:04:18.122174\n",
      "resetting env. episode 5931, reward total was -19.0. running mean: -18.558944725348482, timestamp: 2022-08-19 10:04:22.841233\n",
      "resetting env. episode 5932, reward total was -19.0. running mean: -18.563355278095, timestamp: 2022-08-19 10:04:27.248288\n",
      "resetting env. episode 5933, reward total was -18.0. running mean: -18.55772172531405, timestamp: 2022-08-19 10:04:30.826322\n",
      "resetting env. episode 5934, reward total was -18.0. running mean: -18.55214450806091, timestamp: 2022-08-19 10:04:35.704380\n",
      "resetting env. episode 5935, reward total was -17.0. running mean: -18.5366230629803, timestamp: 2022-08-19 10:04:40.280438\n",
      "resetting env. episode 5936, reward total was -19.0. running mean: -18.5412568323505, timestamp: 2022-08-19 10:04:44.708487\n",
      "resetting env. episode 5937, reward total was -18.0. running mean: -18.53584426402699, timestamp: 2022-08-19 10:04:48.813535\n",
      "resetting env. episode 5938, reward total was -17.0. running mean: -18.520485821386725, timestamp: 2022-08-19 10:04:53.848601\n",
      "resetting env. episode 5939, reward total was -19.0. running mean: -18.525280963172857, timestamp: 2022-08-19 10:04:58.360644\n",
      "resetting env. episode 5940, reward total was -20.0. running mean: -18.54002815354113, timestamp: 2022-08-19 10:05:03.449708\n",
      "resetting env. episode 5941, reward total was -18.0. running mean: -18.534627872005718, timestamp: 2022-08-19 10:05:07.498753\n",
      "resetting env. episode 5942, reward total was -20.0. running mean: -18.54928159328566, timestamp: 2022-08-19 10:05:12.324812\n",
      "resetting env. episode 5943, reward total was -19.0. running mean: -18.553788777352803, timestamp: 2022-08-19 10:05:16.880859\n",
      "resetting env. episode 5944, reward total was -18.0. running mean: -18.548250889579275, timestamp: 2022-08-19 10:05:22.730932\n",
      "resetting env. episode 5945, reward total was -18.0. running mean: -18.542768380683484, timestamp: 2022-08-19 10:05:27.301980\n",
      "resetting env. episode 5946, reward total was -17.0. running mean: -18.52734069687665, timestamp: 2022-08-19 10:05:32.639044\n",
      "resetting env. episode 5947, reward total was -20.0. running mean: -18.542067289907884, timestamp: 2022-08-19 10:05:36.706089\n",
      "resetting env. episode 5948, reward total was -15.0. running mean: -18.506646617008805, timestamp: 2022-08-19 10:05:42.217155\n",
      "resetting env. episode 5949, reward total was -16.0. running mean: -18.481580150838717, timestamp: 2022-08-19 10:05:46.566207\n",
      "resetting env. episode 5950, reward total was -16.0. running mean: -18.456764349330328, timestamp: 2022-08-19 10:05:52.574276\n",
      "resetting env. episode 5951, reward total was -19.0. running mean: -18.462196705837027, timestamp: 2022-08-19 10:05:58.180339\n",
      "resetting env. episode 5952, reward total was -17.0. running mean: -18.44757473877866, timestamp: 2022-08-19 10:06:02.655396\n",
      "resetting env. episode 5953, reward total was -18.0. running mean: -18.443098991390872, timestamp: 2022-08-19 10:06:07.934454\n",
      "resetting env. episode 5954, reward total was -16.0. running mean: -18.418668001476963, timestamp: 2022-08-19 10:06:12.452503\n",
      "resetting env. episode 5955, reward total was -17.0. running mean: -18.404481321462196, timestamp: 2022-08-19 10:06:17.629560\n",
      "resetting env. episode 5956, reward total was -17.0. running mean: -18.390436508247575, timestamp: 2022-08-19 10:06:22.413615\n",
      "resetting env. episode 5957, reward total was -17.0. running mean: -18.3765321431651, timestamp: 2022-08-19 10:06:27.130669\n",
      "resetting env. episode 5958, reward total was -17.0. running mean: -18.36276682173345, timestamp: 2022-08-19 10:06:31.823727\n",
      "resetting env. episode 5959, reward total was -19.0. running mean: -18.36913915351612, timestamp: 2022-08-19 10:06:37.109788\n",
      "resetting env. episode 5960, reward total was -17.0. running mean: -18.355447761980958, timestamp: 2022-08-19 10:06:41.573836\n",
      "resetting env. episode 5961, reward total was -20.0. running mean: -18.371893284361146, timestamp: 2022-08-19 10:06:46.357893\n",
      "resetting env. episode 5962, reward total was -17.0. running mean: -18.358174351517537, timestamp: 2022-08-19 10:06:51.059946\n",
      "resetting env. episode 5963, reward total was -18.0. running mean: -18.35459260800236, timestamp: 2022-08-19 10:06:54.798990\n",
      "resetting env. episode 5964, reward total was -18.0. running mean: -18.351046681922337, timestamp: 2022-08-19 10:06:59.589042\n",
      "resetting env. episode 5965, reward total was -20.0. running mean: -18.36753621510311, timestamp: 2022-08-19 10:07:03.547087\n",
      "resetting env. episode 5966, reward total was -19.0. running mean: -18.37386085295208, timestamp: 2022-08-19 10:07:08.367141\n",
      "resetting env. episode 5967, reward total was -11.0. running mean: -18.30012224442256, timestamp: 2022-08-19 10:07:14.675216\n",
      "resetting env. episode 5968, reward total was -19.0. running mean: -18.307121021978336, timestamp: 2022-08-19 10:07:19.455269\n",
      "resetting env. episode 5969, reward total was -18.0. running mean: -18.304049811758553, timestamp: 2022-08-19 10:07:24.855336\n",
      "resetting env. episode 5970, reward total was -18.0. running mean: -18.301009313640968, timestamp: 2022-08-19 10:07:29.025377\n",
      "resetting env. episode 5971, reward total was -17.0. running mean: -18.28799922050456, timestamp: 2022-08-19 10:07:33.390428\n",
      "resetting env. episode 5972, reward total was -21.0. running mean: -18.315119228299515, timestamp: 2022-08-19 10:07:38.047481\n",
      "resetting env. episode 5973, reward total was -21.0. running mean: -18.34196803601652, timestamp: 2022-08-19 10:07:42.231527\n",
      "resetting env. episode 5974, reward total was -21.0. running mean: -18.368548355656355, timestamp: 2022-08-19 10:07:46.261576\n",
      "resetting env. episode 5975, reward total was -20.0. running mean: -18.38486287209979, timestamp: 2022-08-19 10:07:50.272620\n",
      "resetting env. episode 5976, reward total was -19.0. running mean: -18.391014243378795, timestamp: 2022-08-19 10:07:55.560679\n",
      "resetting env. episode 5977, reward total was -18.0. running mean: -18.387104100945006, timestamp: 2022-08-19 10:08:00.735741\n",
      "resetting env. episode 5978, reward total was -19.0. running mean: -18.393233059935557, timestamp: 2022-08-19 10:08:04.705785\n",
      "resetting env. episode 5979, reward total was -19.0. running mean: -18.399300729336204, timestamp: 2022-08-19 10:08:09.158364\n",
      "resetting env. episode 5980, reward total was -19.0. running mean: -18.405307722042842, timestamp: 2022-08-19 10:08:14.502423\n",
      "resetting env. episode 5981, reward total was -19.0. running mean: -18.411254644822414, timestamp: 2022-08-19 10:08:19.426478\n",
      "resetting env. episode 5982, reward total was -19.0. running mean: -18.41714209837419, timestamp: 2022-08-19 10:08:24.168536\n",
      "resetting env. episode 5983, reward total was -16.0. running mean: -18.392970677390448, timestamp: 2022-08-19 10:08:29.723596\n",
      "resetting env. episode 5984, reward total was -19.0. running mean: -18.399040970616543, timestamp: 2022-08-19 10:08:34.144644\n",
      "resetting env. episode 5985, reward total was -20.0. running mean: -18.415050560910377, timestamp: 2022-08-19 10:08:38.273693\n",
      "resetting env. episode 5986, reward total was -18.0. running mean: -18.410900055301273, timestamp: 2022-08-19 10:08:44.231762\n",
      "resetting env. episode 5987, reward total was -19.0. running mean: -18.416791054748263, timestamp: 2022-08-19 10:08:48.435811\n",
      "resetting env. episode 5988, reward total was -19.0. running mean: -18.42262314420078, timestamp: 2022-08-19 10:08:52.725858\n",
      "resetting env. episode 5989, reward total was -19.0. running mean: -18.428396912758775, timestamp: 2022-08-19 10:08:58.209921\n",
      "resetting env. episode 5990, reward total was -19.0. running mean: -18.434112943631188, timestamp: 2022-08-19 10:09:02.700971\n",
      "resetting env. episode 5991, reward total was -20.0. running mean: -18.449771814194875, timestamp: 2022-08-19 10:09:06.702019\n",
      "resetting env. episode 5992, reward total was -18.0. running mean: -18.445274096052927, timestamp: 2022-08-19 10:09:11.529074\n",
      "resetting env. episode 5993, reward total was -17.0. running mean: -18.430821355092398, timestamp: 2022-08-19 10:09:16.711133\n",
      "resetting env. episode 5994, reward total was -20.0. running mean: -18.446513141541473, timestamp: 2022-08-19 10:09:20.620181\n",
      "resetting env. episode 5995, reward total was -19.0. running mean: -18.45204801012606, timestamp: 2022-08-19 10:09:25.474233\n",
      "resetting env. episode 5996, reward total was -17.0. running mean: -18.437527530024802, timestamp: 2022-08-19 10:09:30.595293\n",
      "resetting env. episode 5997, reward total was -18.0. running mean: -18.433152254724554, timestamp: 2022-08-19 10:09:34.423337\n",
      "resetting env. episode 5998, reward total was -17.0. running mean: -18.41882073217731, timestamp: 2022-08-19 10:09:39.862400\n",
      "resetting env. episode 5999, reward total was -21.0. running mean: -18.444632524855535, timestamp: 2022-08-19 10:09:43.720446\n",
      "resetting env. episode 6000, reward total was -21.0. running mean: -18.47018619960698, timestamp: 2022-08-19 10:09:48.048495\n",
      "resetting env. episode 6001, reward total was -18.0. running mean: -18.46548433761091, timestamp: 2022-08-19 10:09:52.312547\n",
      "resetting env. episode 6002, reward total was -21.0. running mean: -18.490829494234802, timestamp: 2022-08-19 10:09:57.669608\n",
      "resetting env. episode 6003, reward total was -19.0. running mean: -18.495921199292454, timestamp: 2022-08-19 10:10:02.283662\n",
      "resetting env. episode 6004, reward total was -18.0. running mean: -18.490961987299528, timestamp: 2022-08-19 10:10:07.119718\n",
      "resetting env. episode 6005, reward total was -15.0. running mean: -18.45605236742653, timestamp: 2022-08-19 10:10:12.400782\n",
      "resetting env. episode 6006, reward total was -16.0. running mean: -18.431491843752266, timestamp: 2022-08-19 10:10:18.001847\n",
      "resetting env. episode 6007, reward total was -21.0. running mean: -18.457176925314744, timestamp: 2022-08-19 10:10:22.094896\n",
      "resetting env. episode 6008, reward total was -18.0. running mean: -18.452605156061598, timestamp: 2022-08-19 10:10:27.375959\n",
      "resetting env. episode 6009, reward total was -21.0. running mean: -18.47807910450098, timestamp: 2022-08-19 10:10:33.204029\n",
      "resetting env. episode 6010, reward total was -21.0. running mean: -18.50329831345597, timestamp: 2022-08-19 10:10:37.758080\n",
      "resetting env. episode 6011, reward total was -15.0. running mean: -18.46826533032141, timestamp: 2022-08-19 10:10:44.090154\n",
      "resetting env. episode 6012, reward total was -17.0. running mean: -18.4535826770182, timestamp: 2022-08-19 10:10:49.483744\n",
      "resetting env. episode 6013, reward total was -19.0. running mean: -18.45904685024802, timestamp: 2022-08-19 10:10:53.653792\n",
      "resetting env. episode 6014, reward total was -19.0. running mean: -18.46445638174554, timestamp: 2022-08-19 10:10:59.898871\n",
      "resetting env. episode 6015, reward total was -18.0. running mean: -18.45981181792808, timestamp: 2022-08-19 10:11:04.793924\n",
      "resetting env. episode 6016, reward total was -18.0. running mean: -18.4552136997488, timestamp: 2022-08-19 10:11:10.643998\n",
      "resetting env. episode 6017, reward total was -19.0. running mean: -18.460661562751312, timestamp: 2022-08-19 10:11:15.322050\n",
      "resetting env. episode 6018, reward total was -21.0. running mean: -18.4860549471238, timestamp: 2022-08-19 10:11:20.380109\n",
      "resetting env. episode 6019, reward total was -19.0. running mean: -18.491194397652563, timestamp: 2022-08-19 10:11:25.085166\n",
      "resetting env. episode 6020, reward total was -17.0. running mean: -18.47628245367604, timestamp: 2022-08-19 10:11:30.269230\n",
      "resetting env. episode 6021, reward total was -19.0. running mean: -18.481519629139278, timestamp: 2022-08-19 10:11:34.897285\n",
      "resetting env. episode 6022, reward total was -19.0. running mean: -18.486704432847887, timestamp: 2022-08-19 10:11:40.040346\n",
      "resetting env. episode 6023, reward total was -18.0. running mean: -18.48183738851941, timestamp: 2022-08-19 10:11:45.544411\n",
      "resetting env. episode 6024, reward total was -16.0. running mean: -18.457019014634216, timestamp: 2022-08-19 10:11:51.021479\n",
      "resetting env. episode 6025, reward total was -15.0. running mean: -18.422448824487873, timestamp: 2022-08-19 10:11:56.639546\n",
      "resetting env. episode 6026, reward total was -20.0. running mean: -18.438224336242993, timestamp: 2022-08-19 10:12:01.423604\n",
      "resetting env. episode 6027, reward total was -20.0. running mean: -18.45384209288056, timestamp: 2022-08-19 10:12:05.221650\n",
      "resetting env. episode 6028, reward total was -21.0. running mean: -18.479303671951754, timestamp: 2022-08-19 10:12:09.588704\n",
      "resetting env. episode 6029, reward total was -21.0. running mean: -18.504510635232236, timestamp: 2022-08-19 10:12:15.367294\n",
      "resetting env. episode 6030, reward total was -21.0. running mean: -18.529465528879914, timestamp: 2022-08-19 10:12:19.865347\n",
      "resetting env. episode 6031, reward total was -18.0. running mean: -18.524170873591114, timestamp: 2022-08-19 10:12:24.343405\n",
      "resetting env. episode 6032, reward total was -20.0. running mean: -18.5389291648552, timestamp: 2022-08-19 10:12:28.881461\n",
      "resetting env. episode 6033, reward total was -18.0. running mean: -18.53353987320665, timestamp: 2022-08-19 10:12:33.835517\n",
      "resetting env. episode 6034, reward total was -13.0. running mean: -18.47820447447458, timestamp: 2022-08-19 10:12:38.906576\n",
      "resetting env. episode 6035, reward total was -19.0. running mean: -18.483422429729835, timestamp: 2022-08-19 10:12:43.468635\n",
      "resetting env. episode 6036, reward total was -13.0. running mean: -18.428588205432536, timestamp: 2022-08-19 10:12:49.407709\n",
      "resetting env. episode 6037, reward total was -21.0. running mean: -18.45430232337821, timestamp: 2022-08-19 10:12:54.842767\n",
      "resetting env. episode 6038, reward total was -18.0. running mean: -18.44975930014443, timestamp: 2022-08-19 10:12:59.175824\n",
      "resetting env. episode 6039, reward total was -16.0. running mean: -18.425261707142983, timestamp: 2022-08-19 10:13:05.494898\n",
      "resetting env. episode 6040, reward total was -20.0. running mean: -18.441009090071553, timestamp: 2022-08-19 10:13:10.461958\n",
      "resetting env. episode 6041, reward total was -21.0. running mean: -18.466598999170838, timestamp: 2022-08-19 10:13:14.829010\n",
      "resetting env. episode 6042, reward total was -19.0. running mean: -18.471933009179132, timestamp: 2022-08-19 10:13:19.917599\n",
      "resetting env. episode 6043, reward total was -17.0. running mean: -18.457213679087342, timestamp: 2022-08-19 10:13:24.467654\n",
      "resetting env. episode 6044, reward total was -21.0. running mean: -18.48264154229647, timestamp: 2022-08-19 10:13:29.354712\n",
      "resetting env. episode 6045, reward total was -20.0. running mean: -18.497815126873505, timestamp: 2022-08-19 10:13:34.713781\n",
      "resetting env. episode 6046, reward total was -18.0. running mean: -18.49283697560477, timestamp: 2022-08-19 10:13:39.799844\n",
      "resetting env. episode 6047, reward total was -17.0. running mean: -18.477908605848725, timestamp: 2022-08-19 10:13:44.262893\n",
      "resetting env. episode 6048, reward total was -18.0. running mean: -18.473129519790238, timestamp: 2022-08-19 10:13:48.960950\n",
      "resetting env. episode 6049, reward total was -18.0. running mean: -18.468398224592335, timestamp: 2022-08-19 10:13:53.404005\n",
      "resetting env. episode 6050, reward total was -19.0. running mean: -18.47371424234641, timestamp: 2022-08-19 10:13:59.151074\n",
      "resetting env. episode 6051, reward total was -17.0. running mean: -18.458977099922947, timestamp: 2022-08-19 10:14:04.774143\n",
      "resetting env. episode 6052, reward total was -19.0. running mean: -18.46438732892372, timestamp: 2022-08-19 10:14:10.432214\n",
      "resetting env. episode 6053, reward total was -20.0. running mean: -18.479743455634484, timestamp: 2022-08-19 10:14:15.380271\n",
      "resetting env. episode 6054, reward total was -19.0. running mean: -18.48494602107814, timestamp: 2022-08-19 10:14:20.622337\n",
      "resetting env. episode 6055, reward total was -19.0. running mean: -18.49009656086736, timestamp: 2022-08-19 10:14:26.120401\n",
      "resetting env. episode 6056, reward total was -17.0. running mean: -18.47519559525869, timestamp: 2022-08-19 10:14:31.915475\n",
      "resetting env. episode 6057, reward total was -18.0. running mean: -18.4704436393061, timestamp: 2022-08-19 10:14:37.752540\n",
      "resetting env. episode 6058, reward total was -17.0. running mean: -18.45573920291304, timestamp: 2022-08-19 10:14:43.569611\n",
      "resetting env. episode 6059, reward total was -17.0. running mean: -18.44118181088391, timestamp: 2022-08-19 10:14:48.576676\n",
      "resetting env. episode 6060, reward total was -21.0. running mean: -18.466769992775074, timestamp: 2022-08-19 10:14:54.126738\n",
      "resetting env. episode 6061, reward total was -20.0. running mean: -18.482102292847323, timestamp: 2022-08-19 10:14:59.035799\n",
      "resetting env. episode 6062, reward total was -17.0. running mean: -18.46728126991885, timestamp: 2022-08-19 10:15:04.624865\n",
      "resetting env. episode 6063, reward total was -20.0. running mean: -18.482608457219662, timestamp: 2022-08-19 10:15:09.557925\n",
      "resetting env. episode 6064, reward total was -19.0. running mean: -18.487782372647466, timestamp: 2022-08-19 10:15:14.638990\n",
      "resetting env. episode 6065, reward total was -20.0. running mean: -18.50290454892099, timestamp: 2022-08-19 10:15:20.748062\n",
      "resetting env. episode 6066, reward total was -21.0. running mean: -18.527875503431783, timestamp: 2022-08-19 10:15:25.822125\n",
      "resetting env. episode 6067, reward total was -19.0. running mean: -18.532596748397467, timestamp: 2022-08-19 10:15:30.520181\n",
      "resetting env. episode 6068, reward total was -21.0. running mean: -18.55727078091349, timestamp: 2022-08-19 10:15:35.813242\n",
      "resetting env. episode 6069, reward total was -17.0. running mean: -18.541698073104357, timestamp: 2022-08-19 10:15:41.444313\n",
      "resetting env. episode 6070, reward total was -18.0. running mean: -18.53628109237331, timestamp: 2022-08-19 10:15:46.631900\n",
      "resetting env. episode 6071, reward total was -18.0. running mean: -18.530918281449576, timestamp: 2022-08-19 10:15:51.379962\n",
      "resetting env. episode 6072, reward total was -19.0. running mean: -18.53560909863508, timestamp: 2022-08-19 10:15:55.009002\n",
      "resetting env. episode 6073, reward total was -14.0. running mean: -18.490253007648732, timestamp: 2022-08-19 10:16:02.166089\n",
      "resetting env. episode 6074, reward total was -19.0. running mean: -18.495350477572245, timestamp: 2022-08-19 10:16:07.951160\n",
      "resetting env. episode 6075, reward total was -15.0. running mean: -18.46039697279652, timestamp: 2022-08-19 10:16:13.639226\n",
      "resetting env. episode 6076, reward total was -19.0. running mean: -18.465793003068555, timestamp: 2022-08-19 10:16:18.609290\n",
      "resetting env. episode 6077, reward total was -14.0. running mean: -18.42113507303787, timestamp: 2022-08-19 10:16:24.193355\n",
      "resetting env. episode 6078, reward total was -15.0. running mean: -18.38692372230749, timestamp: 2022-08-19 10:16:29.650419\n",
      "resetting env. episode 6079, reward total was -21.0. running mean: -18.413054485084416, timestamp: 2022-08-19 10:16:33.840475\n",
      "resetting env. episode 6080, reward total was -18.0. running mean: -18.40892394023357, timestamp: 2022-08-19 10:16:37.945522\n",
      "resetting env. episode 6081, reward total was -18.0. running mean: -18.404834700831234, timestamp: 2022-08-19 10:16:43.287582\n",
      "resetting env. episode 6082, reward total was -19.0. running mean: -18.410786353822925, timestamp: 2022-08-19 10:16:48.409645\n",
      "resetting env. episode 6083, reward total was -17.0. running mean: -18.396678490284696, timestamp: 2022-08-19 10:16:54.327716\n",
      "resetting env. episode 6084, reward total was -19.0. running mean: -18.40271170538185, timestamp: 2022-08-19 10:16:59.494778\n",
      "resetting env. episode 6085, reward total was -15.0. running mean: -18.36868458832803, timestamp: 2022-08-19 10:17:04.019832\n",
      "resetting env. episode 6086, reward total was -17.0. running mean: -18.354997742444752, timestamp: 2022-08-19 10:17:10.361909\n",
      "resetting env. episode 6087, reward total was -21.0. running mean: -18.381447765020305, timestamp: 2022-08-19 10:17:15.706972\n",
      "resetting env. episode 6088, reward total was -19.0. running mean: -18.387633287370104, timestamp: 2022-08-19 10:17:20.349029\n",
      "resetting env. episode 6089, reward total was -19.0. running mean: -18.393756954496403, timestamp: 2022-08-19 10:17:25.789093\n",
      "resetting env. episode 6090, reward total was -21.0. running mean: -18.419819384951442, timestamp: 2022-08-19 10:17:30.964154\n",
      "resetting env. episode 6091, reward total was -15.0. running mean: -18.385621191101926, timestamp: 2022-08-19 10:17:36.836226\n",
      "resetting env. episode 6092, reward total was -19.0. running mean: -18.391764979190906, timestamp: 2022-08-19 10:17:41.011279\n",
      "resetting env. episode 6093, reward total was -18.0. running mean: -18.387847329398998, timestamp: 2022-08-19 10:17:46.321340\n",
      "resetting env. episode 6094, reward total was -17.0. running mean: -18.37396885610501, timestamp: 2022-08-19 10:17:50.839392\n",
      "resetting env. episode 6095, reward total was -19.0. running mean: -18.38022916754396, timestamp: 2022-08-19 10:17:56.460462\n",
      "resetting env. episode 6096, reward total was -20.0. running mean: -18.396426875868517, timestamp: 2022-08-19 10:18:02.031525\n",
      "resetting env. episode 6097, reward total was -18.0. running mean: -18.39246260710983, timestamp: 2022-08-19 10:18:06.762583\n",
      "resetting env. episode 6098, reward total was -17.0. running mean: -18.378537981038733, timestamp: 2022-08-19 10:18:13.038656\n",
      "resetting env. episode 6099, reward total was -19.0. running mean: -18.384752601228346, timestamp: 2022-08-19 10:18:18.061720\n",
      "resetting env. episode 6100, reward total was -18.0. running mean: -18.380905075216063, timestamp: 2022-08-19 10:18:23.440781\n",
      "resetting env. episode 6101, reward total was -18.0. running mean: -18.377096024463903, timestamp: 2022-08-19 10:18:29.456851\n",
      "resetting env. episode 6102, reward total was -20.0. running mean: -18.393325064219262, timestamp: 2022-08-19 10:18:34.419914\n",
      "resetting env. episode 6103, reward total was -17.0. running mean: -18.379391813577072, timestamp: 2022-08-19 10:18:40.020979\n",
      "resetting env. episode 6104, reward total was -17.0. running mean: -18.365597895441304, timestamp: 2022-08-19 10:18:44.164027\n",
      "resetting env. episode 6105, reward total was -20.0. running mean: -18.38194191648689, timestamp: 2022-08-19 10:18:49.499094\n",
      "resetting env. episode 6106, reward total was -20.0. running mean: -18.39812249732202, timestamp: 2022-08-19 10:18:54.541151\n",
      "resetting env. episode 6107, reward total was -19.0. running mean: -18.404141272348802, timestamp: 2022-08-19 10:18:59.608212\n",
      "resetting env. episode 6108, reward total was -15.0. running mean: -18.370099859625313, timestamp: 2022-08-19 10:19:05.159278\n",
      "resetting env. episode 6109, reward total was -17.0. running mean: -18.35639886102906, timestamp: 2022-08-19 10:19:10.652345\n",
      "resetting env. episode 6110, reward total was -21.0. running mean: -18.38283487241877, timestamp: 2022-08-19 10:19:15.582399\n",
      "resetting env. episode 6111, reward total was -14.0. running mean: -18.339006523694582, timestamp: 2022-08-19 10:19:21.938476\n",
      "resetting env. episode 6112, reward total was -19.0. running mean: -18.345616458457638, timestamp: 2022-08-19 10:19:26.936534\n",
      "resetting env. episode 6113, reward total was -19.0. running mean: -18.352160293873062, timestamp: 2022-08-19 10:19:32.029593\n",
      "resetting env. episode 6114, reward total was -18.0. running mean: -18.34863869093433, timestamp: 2022-08-19 10:19:36.837650\n",
      "resetting env. episode 6115, reward total was -19.0. running mean: -18.355152304024987, timestamp: 2022-08-19 10:19:41.361707\n",
      "resetting env. episode 6116, reward total was -18.0. running mean: -18.351600780984736, timestamp: 2022-08-19 10:19:46.805770\n",
      "resetting env. episode 6117, reward total was -18.0. running mean: -18.34808477317489, timestamp: 2022-08-19 10:19:52.234832\n",
      "resetting env. episode 6118, reward total was -21.0. running mean: -18.374603925443143, timestamp: 2022-08-19 10:19:57.452894\n",
      "resetting env. episode 6119, reward total was -18.0. running mean: -18.370857886188713, timestamp: 2022-08-19 10:20:02.631953\n",
      "resetting env. episode 6120, reward total was -15.0. running mean: -18.337149307326825, timestamp: 2022-08-19 10:20:10.019042\n",
      "resetting env. episode 6121, reward total was -21.0. running mean: -18.36377781425356, timestamp: 2022-08-19 10:20:14.928098\n",
      "resetting env. episode 6122, reward total was -14.0. running mean: -18.320140036111024, timestamp: 2022-08-19 10:20:20.838168\n",
      "resetting env. episode 6123, reward total was -18.0. running mean: -18.316938635749914, timestamp: 2022-08-19 10:20:25.416221\n",
      "resetting env. episode 6124, reward total was -21.0. running mean: -18.343769249392416, timestamp: 2022-08-19 10:20:30.230276\n",
      "resetting env. episode 6125, reward total was -17.0. running mean: -18.330331556898493, timestamp: 2022-08-19 10:20:35.039333\n",
      "resetting env. episode 6126, reward total was -21.0. running mean: -18.35702824132951, timestamp: 2022-08-19 10:20:39.710392\n",
      "resetting env. episode 6127, reward total was -15.0. running mean: -18.32345795891621, timestamp: 2022-08-19 10:20:45.827461\n",
      "resetting env. episode 6128, reward total was -21.0. running mean: -18.35022337932705, timestamp: 2022-08-19 10:20:50.856520\n",
      "resetting env. episode 6129, reward total was -18.0. running mean: -18.34672114553378, timestamp: 2022-08-19 10:20:56.022579\n",
      "resetting env. episode 6130, reward total was -16.0. running mean: -18.323253934078444, timestamp: 2022-08-19 10:21:01.644644\n",
      "resetting env. episode 6131, reward total was -21.0. running mean: -18.35002139473766, timestamp: 2022-08-19 10:21:06.372701\n",
      "resetting env. episode 6132, reward total was -21.0. running mean: -18.376521180790284, timestamp: 2022-08-19 10:21:10.138747\n",
      "resetting env. episode 6133, reward total was -19.0. running mean: -18.382755968982384, timestamp: 2022-08-19 10:21:15.779810\n",
      "resetting env. episode 6134, reward total was -20.0. running mean: -18.39892840929256, timestamp: 2022-08-19 10:21:21.131872\n",
      "resetting env. episode 6135, reward total was -21.0. running mean: -18.424939125199632, timestamp: 2022-08-19 10:21:25.129921\n",
      "resetting env. episode 6136, reward total was -17.0. running mean: -18.41068973394764, timestamp: 2022-08-19 10:21:30.691984\n",
      "resetting env. episode 6137, reward total was -19.0. running mean: -18.416582836608164, timestamp: 2022-08-19 10:21:35.385038\n",
      "resetting env. episode 6138, reward total was -19.0. running mean: -18.422417008242082, timestamp: 2022-08-19 10:21:40.274098\n",
      "resetting env. episode 6139, reward total was -19.0. running mean: -18.428192838159664, timestamp: 2022-08-19 10:21:45.329152\n",
      "resetting env. episode 6140, reward total was -19.0. running mean: -18.433910909778067, timestamp: 2022-08-19 10:21:50.354211\n",
      "resetting env. episode 6141, reward total was -18.0. running mean: -18.429571800680286, timestamp: 2022-08-19 10:21:54.645264\n",
      "resetting env. episode 6142, reward total was -18.0. running mean: -18.42527608267348, timestamp: 2022-08-19 10:22:00.134326\n",
      "resetting env. episode 6143, reward total was -15.0. running mean: -18.391023321846745, timestamp: 2022-08-19 10:22:05.443389\n",
      "resetting env. episode 6144, reward total was -19.0. running mean: -18.39711308862828, timestamp: 2022-08-19 10:22:11.743463\n",
      "resetting env. episode 6145, reward total was -19.0. running mean: -18.403141957741997, timestamp: 2022-08-19 10:22:17.902535\n",
      "resetting env. episode 6146, reward total was -19.0. running mean: -18.40911053816458, timestamp: 2022-08-19 10:22:22.469582\n",
      "resetting env. episode 6147, reward total was -19.0. running mean: -18.415019432782934, timestamp: 2022-08-19 10:22:26.841633\n",
      "resetting env. episode 6148, reward total was -13.0. running mean: -18.360869238455102, timestamp: 2022-08-19 10:22:33.706713\n",
      "resetting env. episode 6149, reward total was -18.0. running mean: -18.35726054607055, timestamp: 2022-08-19 10:22:39.217778\n",
      "resetting env. episode 6150, reward total was -21.0. running mean: -18.383687940609843, timestamp: 2022-08-19 10:22:43.973830\n",
      "resetting env. episode 6151, reward total was -19.0. running mean: -18.389851061203746, timestamp: 2022-08-19 10:22:48.972887\n",
      "resetting env. episode 6152, reward total was -17.0. running mean: -18.37595255059171, timestamp: 2022-08-19 10:22:54.015946\n",
      "resetting env. episode 6153, reward total was -18.0. running mean: -18.372193025085792, timestamp: 2022-08-19 10:22:59.365010\n",
      "resetting env. episode 6154, reward total was -19.0. running mean: -18.378471094834936, timestamp: 2022-08-19 10:23:03.836062\n",
      "resetting env. episode 6155, reward total was -16.0. running mean: -18.354686383886587, timestamp: 2022-08-19 10:23:08.874116\n",
      "resetting env. episode 6156, reward total was -15.0. running mean: -18.32113952004772, timestamp: 2022-08-19 10:23:15.213190\n",
      "resetting env. episode 6157, reward total was -18.0. running mean: -18.317928124847242, timestamp: 2022-08-19 10:23:20.841256\n",
      "resetting env. episode 6158, reward total was -19.0. running mean: -18.32474884359877, timestamp: 2022-08-19 10:23:25.713309\n",
      "resetting env. episode 6159, reward total was -20.0. running mean: -18.34150135516278, timestamp: 2022-08-19 10:23:30.127359\n",
      "resetting env. episode 6160, reward total was -16.0. running mean: -18.318086341611153, timestamp: 2022-08-19 10:23:34.522409\n",
      "resetting env. episode 6161, reward total was -15.0. running mean: -18.28490547819504, timestamp: 2022-08-19 10:23:40.706481\n",
      "resetting env. episode 6162, reward total was -20.0. running mean: -18.302056423413088, timestamp: 2022-08-19 10:23:44.967530\n",
      "resetting env. episode 6163, reward total was -16.0. running mean: -18.279035859178958, timestamp: 2022-08-19 10:23:50.303590\n",
      "resetting env. episode 6164, reward total was -19.0. running mean: -18.28624550058717, timestamp: 2022-08-19 10:23:54.826641\n",
      "resetting env. episode 6165, reward total was -21.0. running mean: -18.3133830455813, timestamp: 2022-08-19 10:24:00.150702\n",
      "resetting env. episode 6166, reward total was -16.0. running mean: -18.29024921512549, timestamp: 2022-08-19 10:24:05.711766\n",
      "resetting env. episode 6167, reward total was -16.0. running mean: -18.267346722974235, timestamp: 2022-08-19 10:24:10.847825\n",
      "resetting env. episode 6168, reward total was -18.0. running mean: -18.26467325574449, timestamp: 2022-08-19 10:24:16.515888\n",
      "resetting env. episode 6169, reward total was -21.0. running mean: -18.292026523187047, timestamp: 2022-08-19 10:24:21.708946\n",
      "resetting env. episode 6170, reward total was -18.0. running mean: -18.289106257955176, timestamp: 2022-08-19 10:24:27.271009\n",
      "resetting env. episode 6171, reward total was -19.0. running mean: -18.296215195375623, timestamp: 2022-08-19 10:24:32.996076\n",
      "resetting env. episode 6172, reward total was -19.0. running mean: -18.30325304342187, timestamp: 2022-08-19 10:24:38.605136\n",
      "resetting env. episode 6173, reward total was -18.0. running mean: -18.30022051298765, timestamp: 2022-08-19 10:24:44.635208\n",
      "resetting env. episode 6174, reward total was -16.0. running mean: -18.277218307857773, timestamp: 2022-08-19 10:24:50.942278\n",
      "resetting env. episode 6175, reward total was -15.0. running mean: -18.244446124779195, timestamp: 2022-08-19 10:24:57.074343\n",
      "resetting env. episode 6176, reward total was -18.0. running mean: -18.242001663531404, timestamp: 2022-08-19 10:25:01.662397\n",
      "resetting env. episode 6177, reward total was -17.0. running mean: -18.22958164689609, timestamp: 2022-08-19 10:25:05.972449\n",
      "resetting env. episode 6178, reward total was -19.0. running mean: -18.23728583042713, timestamp: 2022-08-19 10:25:10.422500\n",
      "resetting env. episode 6179, reward total was -18.0. running mean: -18.234912972122856, timestamp: 2022-08-19 10:25:15.336553\n",
      "resetting env. episode 6180, reward total was -21.0. running mean: -18.26256384240163, timestamp: 2022-08-19 10:25:21.246619\n",
      "resetting env. episode 6181, reward total was -18.0. running mean: -18.25993820397761, timestamp: 2022-08-19 10:25:26.894681\n",
      "resetting env. episode 6182, reward total was -19.0. running mean: -18.267338821937837, timestamp: 2022-08-19 10:25:31.164727\n",
      "resetting env. episode 6183, reward total was -19.0. running mean: -18.27466543371846, timestamp: 2022-08-19 10:25:35.650780\n",
      "resetting env. episode 6184, reward total was -18.0. running mean: -18.271918779381277, timestamp: 2022-08-19 10:25:40.555837\n",
      "resetting env. episode 6185, reward total was -19.0. running mean: -18.279199591587467, timestamp: 2022-08-19 10:25:44.709885\n",
      "resetting env. episode 6186, reward total was -17.0. running mean: -18.266407595671595, timestamp: 2022-08-19 10:25:48.826930\n",
      "resetting env. episode 6187, reward total was -21.0. running mean: -18.29374351971488, timestamp: 2022-08-19 10:25:53.612981\n",
      "resetting env. episode 6188, reward total was -18.0. running mean: -18.29080608451773, timestamp: 2022-08-19 10:25:58.062034\n",
      "resetting env. episode 6189, reward total was -19.0. running mean: -18.297898023672552, timestamp: 2022-08-19 10:26:03.677094\n",
      "resetting env. episode 6190, reward total was -19.0. running mean: -18.304919043435827, timestamp: 2022-08-19 10:26:08.492150\n",
      "resetting env. episode 6191, reward total was -19.0. running mean: -18.311869853001472, timestamp: 2022-08-19 10:26:12.937201\n",
      "resetting env. episode 6192, reward total was -17.0. running mean: -18.298751154471457, timestamp: 2022-08-19 10:26:17.977781\n",
      "resetting env. episode 6193, reward total was -16.0. running mean: -18.275763642926744, timestamp: 2022-08-19 10:26:22.773835\n",
      "resetting env. episode 6194, reward total was -15.0. running mean: -18.243006006497474, timestamp: 2022-08-19 10:26:27.642895\n",
      "resetting env. episode 6195, reward total was -21.0. running mean: -18.2705759464325, timestamp: 2022-08-19 10:26:32.255949\n",
      "resetting env. episode 6196, reward total was -19.0. running mean: -18.277870186968176, timestamp: 2022-08-19 10:26:37.696007\n",
      "resetting env. episode 6197, reward total was -17.0. running mean: -18.265091485098495, timestamp: 2022-08-19 10:26:43.440076\n",
      "resetting env. episode 6198, reward total was -17.0. running mean: -18.25244057024751, timestamp: 2022-08-19 10:26:48.154131\n",
      "resetting env. episode 6199, reward total was -19.0. running mean: -18.259916164545036, timestamp: 2022-08-19 10:26:52.214176\n",
      "resetting env. episode 6200, reward total was -20.0. running mean: -18.277317002899586, timestamp: 2022-08-19 10:26:56.252223\n",
      "resetting env. episode 6201, reward total was -17.0. running mean: -18.264543832870594, timestamp: 2022-08-19 10:27:01.240281\n",
      "resetting env. episode 6202, reward total was -13.0. running mean: -18.211898394541887, timestamp: 2022-08-19 10:27:07.414354\n",
      "resetting env. episode 6203, reward total was -12.0. running mean: -18.14977941059647, timestamp: 2022-08-19 10:27:13.151422\n",
      "resetting env. episode 6204, reward total was -19.0. running mean: -18.158281616490505, timestamp: 2022-08-19 10:27:18.170480\n",
      "resetting env. episode 6205, reward total was -20.0. running mean: -18.1766988003256, timestamp: 2022-08-19 10:27:22.245531\n",
      "resetting env. episode 6206, reward total was -15.0. running mean: -18.14493181232234, timestamp: 2022-08-19 10:27:26.647577\n",
      "resetting env. episode 6207, reward total was -15.0. running mean: -18.113482494199115, timestamp: 2022-08-19 10:27:31.099631\n",
      "resetting env. episode 6208, reward total was -19.0. running mean: -18.122347669257124, timestamp: 2022-08-19 10:27:35.370680\n",
      "resetting env. episode 6209, reward total was -16.0. running mean: -18.10112419256455, timestamp: 2022-08-19 10:27:40.669747\n",
      "resetting env. episode 6210, reward total was -17.0. running mean: -18.090112950638908, timestamp: 2022-08-19 10:27:46.633815\n",
      "resetting env. episode 6211, reward total was -20.0. running mean: -18.10921182113252, timestamp: 2022-08-19 10:27:52.039878\n",
      "resetting env. episode 6212, reward total was -17.0. running mean: -18.098119702921196, timestamp: 2022-08-19 10:27:58.119950\n",
      "resetting env. episode 6213, reward total was -19.0. running mean: -18.107138505891985, timestamp: 2022-08-19 10:28:03.241013\n",
      "resetting env. episode 6214, reward total was -14.0. running mean: -18.066067120833065, timestamp: 2022-08-19 10:28:08.883077\n",
      "resetting env. episode 6215, reward total was -21.0. running mean: -18.095406449624736, timestamp: 2022-08-19 10:28:12.891126\n",
      "resetting env. episode 6216, reward total was -18.0. running mean: -18.094452385128488, timestamp: 2022-08-19 10:28:16.991174\n",
      "resetting env. episode 6217, reward total was -21.0. running mean: -18.123507861277204, timestamp: 2022-08-19 10:28:23.796255\n",
      "resetting env. episode 6218, reward total was -21.0. running mean: -18.152272782664433, timestamp: 2022-08-19 10:28:29.124316\n",
      "resetting env. episode 6219, reward total was -18.0. running mean: -18.150750054837786, timestamp: 2022-08-19 10:28:34.595386\n",
      "resetting env. episode 6220, reward total was -17.0. running mean: -18.13924255428941, timestamp: 2022-08-19 10:28:39.007434\n",
      "resetting env. episode 6221, reward total was -17.0. running mean: -18.127850128746516, timestamp: 2022-08-19 10:28:43.176484\n",
      "resetting env. episode 6222, reward total was -18.0. running mean: -18.12657162745905, timestamp: 2022-08-19 10:28:49.018553\n",
      "resetting env. episode 6223, reward total was -15.0. running mean: -18.095305911184457, timestamp: 2022-08-19 10:28:54.778628\n",
      "resetting env. episode 6224, reward total was -19.0. running mean: -18.104352852072616, timestamp: 2022-08-19 10:28:59.725682\n",
      "resetting env. episode 6225, reward total was -17.0. running mean: -18.093309323551892, timestamp: 2022-08-19 10:29:05.142747\n",
      "resetting env. episode 6226, reward total was -18.0. running mean: -18.092376230316372, timestamp: 2022-08-19 10:29:10.355810\n",
      "resetting env. episode 6227, reward total was -19.0. running mean: -18.10145246801321, timestamp: 2022-08-19 10:29:16.613885\n",
      "resetting env. episode 6228, reward total was -18.0. running mean: -18.100437943333077, timestamp: 2022-08-19 10:29:22.043951\n",
      "resetting env. episode 6229, reward total was -21.0. running mean: -18.129433563899745, timestamp: 2022-08-19 10:29:26.876012\n",
      "resetting env. episode 6230, reward total was -17.0. running mean: -18.11813922826075, timestamp: 2022-08-19 10:29:32.309073\n",
      "resetting env. episode 6231, reward total was -19.0. running mean: -18.126957835978143, timestamp: 2022-08-19 10:29:35.866116\n",
      "resetting env. episode 6232, reward total was -18.0. running mean: -18.12568825761836, timestamp: 2022-08-19 10:29:41.052177\n",
      "resetting env. episode 6233, reward total was -18.0. running mean: -18.124431375042178, timestamp: 2022-08-19 10:29:45.901236\n",
      "resetting env. episode 6234, reward total was -16.0. running mean: -18.103187061291756, timestamp: 2022-08-19 10:29:50.871295\n",
      "resetting env. episode 6235, reward total was -19.0. running mean: -18.112155190678838, timestamp: 2022-08-19 10:29:55.729354\n",
      "resetting env. episode 6236, reward total was -16.0. running mean: -18.09103363877205, timestamp: 2022-08-19 10:30:02.295436\n",
      "resetting env. episode 6237, reward total was -20.0. running mean: -18.110123302384327, timestamp: 2022-08-19 10:30:06.404484\n",
      "resetting env. episode 6238, reward total was -19.0. running mean: -18.119022069360486, timestamp: 2022-08-19 10:30:11.679545\n",
      "resetting env. episode 6239, reward total was -19.0. running mean: -18.127831848666883, timestamp: 2022-08-19 10:30:17.113612\n",
      "resetting env. episode 6240, reward total was -18.0. running mean: -18.126553530180214, timestamp: 2022-08-19 10:30:22.367674\n",
      "resetting env. episode 6241, reward total was -17.0. running mean: -18.115287994878415, timestamp: 2022-08-19 10:30:26.554725\n",
      "resetting env. episode 6242, reward total was -20.0. running mean: -18.13413511492963, timestamp: 2022-08-19 10:30:31.178783\n",
      "resetting env. episode 6243, reward total was -19.0. running mean: -18.142793763780336, timestamp: 2022-08-19 10:30:35.872838\n",
      "resetting env. episode 6244, reward total was -13.0. running mean: -18.091365826142532, timestamp: 2022-08-19 10:30:42.395917\n",
      "resetting env. episode 6245, reward total was -19.0. running mean: -18.10045216788111, timestamp: 2022-08-19 10:30:47.256975\n",
      "resetting env. episode 6246, reward total was -18.0. running mean: -18.099447646202297, timestamp: 2022-08-19 10:30:53.019045\n",
      "resetting env. episode 6247, reward total was -18.0. running mean: -18.098453169740274, timestamp: 2022-08-19 10:30:59.581127\n",
      "resetting env. episode 6248, reward total was -18.0. running mean: -18.097468638042873, timestamp: 2022-08-19 10:31:05.845200\n",
      "resetting env. episode 6249, reward total was -17.0. running mean: -18.086493951662447, timestamp: 2022-08-19 10:31:10.537263\n",
      "resetting env. episode 6250, reward total was -17.0. running mean: -18.075629012145825, timestamp: 2022-08-19 10:31:15.853321\n",
      "resetting env. episode 6251, reward total was -19.0. running mean: -18.084872722024368, timestamp: 2022-08-19 10:31:22.061397\n",
      "resetting env. episode 6252, reward total was -18.0. running mean: -18.084023994804124, timestamp: 2022-08-19 10:31:27.295478\n",
      "resetting env. episode 6253, reward total was -17.0. running mean: -18.073183754856085, timestamp: 2022-08-19 10:31:32.010532\n",
      "resetting env. episode 6254, reward total was -16.0. running mean: -18.052451917307526, timestamp: 2022-08-19 10:31:37.983605\n",
      "resetting env. episode 6255, reward total was -21.0. running mean: -18.08192739813445, timestamp: 2022-08-19 10:31:42.979664\n",
      "resetting env. episode 6256, reward total was -19.0. running mean: -18.091108124153106, timestamp: 2022-08-19 10:31:47.544719\n",
      "resetting env. episode 6257, reward total was -20.0. running mean: -18.110197042911572, timestamp: 2022-08-19 10:31:52.631781\n",
      "resetting env. episode 6258, reward total was -21.0. running mean: -18.13909507248246, timestamp: 2022-08-19 10:31:57.190837\n",
      "resetting env. episode 6259, reward total was -21.0. running mean: -18.167704121757634, timestamp: 2022-08-19 10:32:02.072896\n",
      "resetting env. episode 6260, reward total was -19.0. running mean: -18.17602708054006, timestamp: 2022-08-19 10:32:06.518949\n",
      "resetting env. episode 6261, reward total was -18.0. running mean: -18.174266809734657, timestamp: 2022-08-19 10:32:10.743000\n",
      "resetting env. episode 6262, reward total was -15.0. running mean: -18.14252414163731, timestamp: 2022-08-19 10:32:15.621061\n",
      "resetting env. episode 6263, reward total was -16.0. running mean: -18.121098900220936, timestamp: 2022-08-19 10:32:20.193117\n",
      "resetting env. episode 6264, reward total was -18.0. running mean: -18.119887911218726, timestamp: 2022-08-19 10:32:24.647169\n",
      "resetting env. episode 6265, reward total was -19.0. running mean: -18.12868903210654, timestamp: 2022-08-19 10:32:29.674230\n",
      "resetting env. episode 6266, reward total was -16.0. running mean: -18.107402141785474, timestamp: 2022-08-19 10:32:35.255297\n",
      "resetting env. episode 6267, reward total was -21.0. running mean: -18.13632812036762, timestamp: 2022-08-19 10:32:40.281361\n",
      "resetting env. episode 6268, reward total was -19.0. running mean: -18.144964839163944, timestamp: 2022-08-19 10:32:45.284417\n",
      "resetting env. episode 6269, reward total was -21.0. running mean: -18.173515190772306, timestamp: 2022-08-19 10:32:49.239464\n",
      "resetting env. episode 6270, reward total was -17.0. running mean: -18.161780038864585, timestamp: 2022-08-19 10:32:54.448528\n",
      "resetting env. episode 6271, reward total was -20.0. running mean: -18.180162238475937, timestamp: 2022-08-19 10:32:59.212585\n",
      "resetting env. episode 6272, reward total was -17.0. running mean: -18.168360616091178, timestamp: 2022-08-19 10:33:04.644650\n",
      "resetting env. episode 6273, reward total was -18.0. running mean: -18.166677009930265, timestamp: 2022-08-19 10:33:08.836699\n",
      "resetting env. episode 6274, reward total was -19.0. running mean: -18.175010239830964, timestamp: 2022-08-19 10:33:14.056766\n",
      "resetting env. episode 6275, reward total was -19.0. running mean: -18.183260137432654, timestamp: 2022-08-19 10:33:19.421828\n",
      "resetting env. episode 6276, reward total was -20.0. running mean: -18.201427536058326, timestamp: 2022-08-19 10:33:23.858884\n",
      "resetting env. episode 6277, reward total was -17.0. running mean: -18.189413260697744, timestamp: 2022-08-19 10:33:29.001946\n",
      "resetting env. episode 6278, reward total was -19.0. running mean: -18.197519128090768, timestamp: 2022-08-19 10:33:33.936001\n",
      "resetting env. episode 6279, reward total was -18.0. running mean: -18.19554393680986, timestamp: 2022-08-19 10:33:38.632058\n",
      "resetting env. episode 6280, reward total was -16.0. running mean: -18.17358849744176, timestamp: 2022-08-19 10:33:44.044121\n",
      "resetting env. episode 6281, reward total was -19.0. running mean: -18.181852612467342, timestamp: 2022-08-19 10:33:48.956185\n",
      "resetting env. episode 6282, reward total was -17.0. running mean: -18.17003408634267, timestamp: 2022-08-19 10:33:52.948232\n",
      "resetting env. episode 6283, reward total was -19.0. running mean: -18.178333745479247, timestamp: 2022-08-19 10:33:57.810288\n",
      "resetting env. episode 6284, reward total was -14.0. running mean: -18.136550408024455, timestamp: 2022-08-19 10:34:04.143365\n",
      "resetting env. episode 6285, reward total was -16.0. running mean: -18.11518490394421, timestamp: 2022-08-19 10:34:09.645431\n",
      "resetting env. episode 6286, reward total was -19.0. running mean: -18.12403305490477, timestamp: 2022-08-19 10:34:14.352486\n",
      "resetting env. episode 6287, reward total was -21.0. running mean: -18.152792724355724, timestamp: 2022-08-19 10:34:19.972556\n",
      "resetting env. episode 6288, reward total was -16.0. running mean: -18.131264797112166, timestamp: 2022-08-19 10:34:24.898615\n",
      "resetting env. episode 6289, reward total was -19.0. running mean: -18.139952149141045, timestamp: 2022-08-19 10:34:29.591672\n",
      "resetting env. episode 6290, reward total was -20.0. running mean: -18.158552627649634, timestamp: 2022-08-19 10:34:35.305737\n",
      "resetting env. episode 6291, reward total was -13.0. running mean: -18.106967101373137, timestamp: 2022-08-19 10:34:40.677804\n",
      "resetting env. episode 6292, reward total was -16.0. running mean: -18.085897430359406, timestamp: 2022-08-19 10:34:45.829863\n",
      "resetting env. episode 6293, reward total was -21.0. running mean: -18.115038456055814, timestamp: 2022-08-19 10:34:50.957924\n",
      "resetting env. episode 6294, reward total was -19.0. running mean: -18.123888071495255, timestamp: 2022-08-19 10:34:56.276992\n",
      "resetting env. episode 6295, reward total was -17.0. running mean: -18.112649190780303, timestamp: 2022-08-19 10:35:03.004069\n",
      "resetting env. episode 6296, reward total was -17.0. running mean: -18.1015226988725, timestamp: 2022-08-19 10:35:08.019126\n",
      "resetting env. episode 6297, reward total was -16.0. running mean: -18.080507471883774, timestamp: 2022-08-19 10:35:13.411192\n",
      "resetting env. episode 6298, reward total was -21.0. running mean: -18.109702397164938, timestamp: 2022-08-19 10:35:18.028248\n",
      "resetting env. episode 6299, reward total was -15.0. running mean: -18.078605373193287, timestamp: 2022-08-19 10:35:22.905308\n",
      "resetting env. episode 6300, reward total was -17.0. running mean: -18.067819319461357, timestamp: 2022-08-19 10:35:28.314368\n",
      "resetting env. episode 6301, reward total was -19.0. running mean: -18.077141126266746, timestamp: 2022-08-19 10:35:32.849421\n",
      "resetting env. episode 6302, reward total was -17.0. running mean: -18.06636971500408, timestamp: 2022-08-19 10:35:37.933483\n",
      "resetting env. episode 6303, reward total was -20.0. running mean: -18.085706017854037, timestamp: 2022-08-19 10:35:42.953545\n",
      "resetting env. episode 6304, reward total was -16.0. running mean: -18.064848957675498, timestamp: 2022-08-19 10:35:48.587608\n",
      "resetting env. episode 6305, reward total was -19.0. running mean: -18.074200468098745, timestamp: 2022-08-19 10:35:52.276652\n",
      "resetting env. episode 6306, reward total was -15.0. running mean: -18.043458463417757, timestamp: 2022-08-19 10:35:57.935721\n",
      "resetting env. episode 6307, reward total was -19.0. running mean: -18.05302387878358, timestamp: 2022-08-19 10:36:03.414786\n",
      "resetting env. episode 6308, reward total was -17.0. running mean: -18.042493639995747, timestamp: 2022-08-19 10:36:08.735850\n",
      "resetting env. episode 6309, reward total was -17.0. running mean: -18.03206870359579, timestamp: 2022-08-19 10:36:13.517911\n",
      "resetting env. episode 6310, reward total was -21.0. running mean: -18.061748016559832, timestamp: 2022-08-19 10:36:19.093972\n",
      "resetting env. episode 6311, reward total was -19.0. running mean: -18.071130536394236, timestamp: 2022-08-19 10:36:24.479034\n",
      "resetting env. episode 6312, reward total was -21.0. running mean: -18.100419231030294, timestamp: 2022-08-19 10:36:29.471099\n",
      "resetting env. episode 6313, reward total was -21.0. running mean: -18.12941503871999, timestamp: 2022-08-19 10:36:33.658145\n",
      "resetting env. episode 6314, reward total was -19.0. running mean: -18.138120888332793, timestamp: 2022-08-19 10:36:38.318199\n",
      "resetting env. episode 6315, reward total was -20.0. running mean: -18.156739679449466, timestamp: 2022-08-19 10:36:44.031268\n",
      "resetting env. episode 6316, reward total was -20.0. running mean: -18.17517228265497, timestamp: 2022-08-19 10:36:47.973313\n",
      "resetting env. episode 6317, reward total was -21.0. running mean: -18.20342055982842, timestamp: 2022-08-19 10:36:52.484367\n",
      "resetting env. episode 6318, reward total was -19.0. running mean: -18.211386354230136, timestamp: 2022-08-19 10:36:56.990419\n",
      "resetting env. episode 6319, reward total was -16.0. running mean: -18.189272490687834, timestamp: 2022-08-19 10:37:02.050477\n",
      "resetting env. episode 6320, reward total was -18.0. running mean: -18.187379765780957, timestamp: 2022-08-19 10:37:07.764544\n",
      "resetting env. episode 6321, reward total was -20.0. running mean: -18.205505968123145, timestamp: 2022-08-19 10:37:11.469588\n",
      "resetting env. episode 6322, reward total was -19.0. running mean: -18.213450908441914, timestamp: 2022-08-19 10:37:16.883654\n",
      "resetting env. episode 6323, reward total was -14.0. running mean: -18.171316399357494, timestamp: 2022-08-19 10:37:22.980729\n",
      "resetting env. episode 6324, reward total was -19.0. running mean: -18.17960323536392, timestamp: 2022-08-19 10:37:27.283773\n",
      "resetting env. episode 6325, reward total was -21.0. running mean: -18.207807203010283, timestamp: 2022-08-19 10:37:31.331822\n",
      "resetting env. episode 6326, reward total was -18.0. running mean: -18.20572913098018, timestamp: 2022-08-19 10:37:35.971875\n",
      "resetting env. episode 6327, reward total was -21.0. running mean: -18.23367183967038, timestamp: 2022-08-19 10:37:40.211930\n",
      "resetting env. episode 6328, reward total was -19.0. running mean: -18.241335121273675, timestamp: 2022-08-19 10:37:44.475979\n",
      "resetting env. episode 6329, reward total was -15.0. running mean: -18.208921770060936, timestamp: 2022-08-19 10:37:49.917038\n",
      "resetting env. episode 6330, reward total was -18.0. running mean: -18.206832552360325, timestamp: 2022-08-19 10:37:55.858109\n",
      "resetting env. episode 6331, reward total was -17.0. running mean: -18.194764226836725, timestamp: 2022-08-19 10:38:01.685176\n",
      "resetting env. episode 6332, reward total was -15.0. running mean: -18.162816584568358, timestamp: 2022-08-19 10:38:06.815236\n",
      "resetting env. episode 6333, reward total was -19.0. running mean: -18.171188418722675, timestamp: 2022-08-19 10:38:12.060297\n",
      "resetting env. episode 6334, reward total was -9.0. running mean: -18.07947653453545, timestamp: 2022-08-19 10:38:18.955379\n",
      "resetting env. episode 6335, reward total was -19.0. running mean: -18.088681769190096, timestamp: 2022-08-19 10:38:23.401431\n",
      "resetting env. episode 6336, reward total was -19.0. running mean: -18.097794951498194, timestamp: 2022-08-19 10:38:28.076482\n",
      "resetting env. episode 6337, reward total was -19.0. running mean: -18.106817001983213, timestamp: 2022-08-19 10:38:32.989543\n",
      "resetting env. episode 6338, reward total was -18.0. running mean: -18.105748831963382, timestamp: 2022-08-19 10:38:37.441596\n",
      "resetting env. episode 6339, reward total was -19.0. running mean: -18.11469134364375, timestamp: 2022-08-19 10:38:41.457638\n",
      "resetting env. episode 6340, reward total was -19.0. running mean: -18.12354443020731, timestamp: 2022-08-19 10:38:45.397684\n",
      "resetting env. episode 6341, reward total was -19.0. running mean: -18.13230898590524, timestamp: 2022-08-19 10:38:49.598733\n",
      "resetting env. episode 6342, reward total was -17.0. running mean: -18.12098589604619, timestamp: 2022-08-19 10:38:55.465802\n",
      "resetting env. episode 6343, reward total was -17.0. running mean: -18.10977603708573, timestamp: 2022-08-19 10:39:01.512872\n",
      "resetting env. episode 6344, reward total was -20.0. running mean: -18.128678276714872, timestamp: 2022-08-19 10:39:06.849933\n",
      "resetting env. episode 6345, reward total was -20.0. running mean: -18.147391493947723, timestamp: 2022-08-19 10:39:10.861979\n",
      "resetting env. episode 6346, reward total was -19.0. running mean: -18.155917579008246, timestamp: 2022-08-19 10:39:15.093031\n",
      "resetting env. episode 6347, reward total was -21.0. running mean: -18.184358403218166, timestamp: 2022-08-19 10:39:19.704086\n",
      "resetting env. episode 6348, reward total was -19.0. running mean: -18.192514819185984, timestamp: 2022-08-19 10:39:25.108145\n",
      "resetting env. episode 6349, reward total was -21.0. running mean: -18.220589670994126, timestamp: 2022-08-19 10:39:29.826202\n",
      "resetting env. episode 6350, reward total was -18.0. running mean: -18.218383774284185, timestamp: 2022-08-19 10:39:35.392261\n",
      "resetting env. episode 6351, reward total was -18.0. running mean: -18.216199936541344, timestamp: 2022-08-19 10:39:41.070331\n",
      "resetting env. episode 6352, reward total was -19.0. running mean: -18.224037937175932, timestamp: 2022-08-19 10:39:45.926388\n",
      "resetting env. episode 6353, reward total was -19.0. running mean: -18.231797557804175, timestamp: 2022-08-19 10:39:51.913457\n",
      "resetting env. episode 6354, reward total was -18.0. running mean: -18.229479582226134, timestamp: 2022-08-19 10:39:57.510518\n",
      "resetting env. episode 6355, reward total was -17.0. running mean: -18.217184786403873, timestamp: 2022-08-19 10:40:04.103596\n",
      "resetting env. episode 6356, reward total was -18.0. running mean: -18.215012938539832, timestamp: 2022-08-19 10:40:08.758645\n",
      "resetting env. episode 6357, reward total was -20.0. running mean: -18.232862809154433, timestamp: 2022-08-19 10:40:13.555705\n",
      "resetting env. episode 6358, reward total was -18.0. running mean: -18.23053418106289, timestamp: 2022-08-19 10:40:18.439756\n",
      "resetting env. episode 6359, reward total was -17.0. running mean: -18.218228839252262, timestamp: 2022-08-19 10:40:22.429801\n",
      "resetting env. episode 6360, reward total was -19.0. running mean: -18.226046550859742, timestamp: 2022-08-19 10:40:27.473860\n",
      "resetting env. episode 6361, reward total was -15.0. running mean: -18.193786085351142, timestamp: 2022-08-19 10:40:32.084911\n",
      "resetting env. episode 6362, reward total was -20.0. running mean: -18.21184822449763, timestamp: 2022-08-19 10:40:37.231972\n",
      "resetting env. episode 6363, reward total was -15.0. running mean: -18.17972974225265, timestamp: 2022-08-19 10:40:44.544585\n",
      "resetting env. episode 6364, reward total was -19.0. running mean: -18.187932444830125, timestamp: 2022-08-19 10:40:49.603642\n",
      "resetting env. episode 6365, reward total was -18.0. running mean: -18.186053120381825, timestamp: 2022-08-19 10:40:54.269698\n",
      "resetting env. episode 6366, reward total was -21.0. running mean: -18.21419258917801, timestamp: 2022-08-19 10:40:59.522755\n",
      "resetting env. episode 6367, reward total was -20.0. running mean: -18.232050663286227, timestamp: 2022-08-19 10:41:04.140807\n",
      "resetting env. episode 6368, reward total was -16.0. running mean: -18.209730156653364, timestamp: 2022-08-19 10:41:09.787874\n",
      "resetting env. episode 6369, reward total was -17.0. running mean: -18.197632855086834, timestamp: 2022-08-19 10:41:16.064942\n",
      "resetting env. episode 6370, reward total was -16.0. running mean: -18.175656526535967, timestamp: 2022-08-19 10:41:23.080022\n",
      "resetting env. episode 6371, reward total was -17.0. running mean: -18.16389996127061, timestamp: 2022-08-19 10:41:28.268082\n",
      "resetting env. episode 6372, reward total was -19.0. running mean: -18.172260961657905, timestamp: 2022-08-19 10:41:32.343127\n",
      "resetting env. episode 6373, reward total was -19.0. running mean: -18.180538352041328, timestamp: 2022-08-19 10:41:38.476198\n",
      "resetting env. episode 6374, reward total was -18.0. running mean: -18.178732968520915, timestamp: 2022-08-19 10:41:43.424252\n",
      "resetting env. episode 6375, reward total was -18.0. running mean: -18.176945638835704, timestamp: 2022-08-19 10:41:48.444313\n",
      "resetting env. episode 6376, reward total was -17.0. running mean: -18.16517618244735, timestamp: 2022-08-19 10:41:53.064361\n",
      "resetting env. episode 6377, reward total was -19.0. running mean: -18.17352442062288, timestamp: 2022-08-19 10:41:59.006431\n",
      "resetting env. episode 6378, reward total was -19.0. running mean: -18.18178917641665, timestamp: 2022-08-19 10:42:04.050490\n",
      "resetting env. episode 6379, reward total was -19.0. running mean: -18.189971284652486, timestamp: 2022-08-19 10:42:08.853544\n",
      "resetting env. episode 6380, reward total was -17.0. running mean: -18.178071571805962, timestamp: 2022-08-19 10:42:13.305590\n",
      "resetting env. episode 6381, reward total was -18.0. running mean: -18.176290856087903, timestamp: 2022-08-19 10:42:17.784642\n",
      "resetting env. episode 6382, reward total was -17.0. running mean: -18.164527947527024, timestamp: 2022-08-19 10:42:23.703708\n",
      "resetting env. episode 6383, reward total was -19.0. running mean: -18.172882668051756, timestamp: 2022-08-19 10:42:27.920286\n",
      "resetting env. episode 6384, reward total was -16.0. running mean: -18.151153841371237, timestamp: 2022-08-19 10:42:32.874336\n",
      "resetting env. episode 6385, reward total was -17.0. running mean: -18.139642302957526, timestamp: 2022-08-19 10:42:38.833404\n",
      "resetting env. episode 6386, reward total was -21.0. running mean: -18.16824587992795, timestamp: 2022-08-19 10:42:45.045472\n",
      "resetting env. episode 6387, reward total was -14.0. running mean: -18.126563421128672, timestamp: 2022-08-19 10:42:51.439546\n",
      "resetting env. episode 6388, reward total was -17.0. running mean: -18.115297786917388, timestamp: 2022-08-19 10:42:57.945622\n",
      "resetting env. episode 6389, reward total was -18.0. running mean: -18.114144809048213, timestamp: 2022-08-19 10:43:03.475682\n",
      "resetting env. episode 6390, reward total was -17.0. running mean: -18.103003360957732, timestamp: 2022-08-19 10:43:10.305758\n",
      "resetting env. episode 6391, reward total was -18.0. running mean: -18.101973327348155, timestamp: 2022-08-19 10:43:14.666812\n",
      "resetting env. episode 6392, reward total was -21.0. running mean: -18.130953594074676, timestamp: 2022-08-19 10:43:19.156862\n",
      "resetting env. episode 6393, reward total was -17.0. running mean: -18.11964405813393, timestamp: 2022-08-19 10:43:25.395931\n",
      "resetting env. episode 6394, reward total was -13.0. running mean: -18.06844761755259, timestamp: 2022-08-19 10:43:31.990006\n",
      "resetting env. episode 6395, reward total was -21.0. running mean: -18.097763141377065, timestamp: 2022-08-19 10:43:35.846055\n",
      "resetting env. episode 6396, reward total was -16.0. running mean: -18.076785509963294, timestamp: 2022-08-19 10:43:41.655120\n",
      "resetting env. episode 6397, reward total was -20.0. running mean: -18.09601765486366, timestamp: 2022-08-19 10:43:46.579176\n",
      "resetting env. episode 6398, reward total was -17.0. running mean: -18.085057478315026, timestamp: 2022-08-19 10:43:51.239232\n",
      "resetting env. episode 6399, reward total was -17.0. running mean: -18.074206903531877, timestamp: 2022-08-19 10:43:56.506292\n",
      "resetting env. episode 6400, reward total was -18.0. running mean: -18.07346483449656, timestamp: 2022-08-19 10:44:02.338359\n",
      "resetting env. episode 6401, reward total was -21.0. running mean: -18.102730186151593, timestamp: 2022-08-19 10:44:07.828423\n",
      "resetting env. episode 6402, reward total was -19.0. running mean: -18.11170288429008, timestamp: 2022-08-19 10:44:12.886483\n",
      "resetting env. episode 6403, reward total was -14.0. running mean: -18.070585855447177, timestamp: 2022-08-19 10:44:19.647563\n",
      "resetting env. episode 6404, reward total was -18.0. running mean: -18.069879996892706, timestamp: 2022-08-19 10:44:25.353629\n",
      "resetting env. episode 6405, reward total was -21.0. running mean: -18.09918119692378, timestamp: 2022-08-19 10:44:30.906695\n",
      "resetting env. episode 6406, reward total was -18.0. running mean: -18.09818938495454, timestamp: 2022-08-19 10:44:35.827750\n",
      "resetting env. episode 6407, reward total was -17.0. running mean: -18.087207491104998, timestamp: 2022-08-19 10:44:42.036825\n",
      "resetting env. episode 6408, reward total was -18.0. running mean: -18.086335416193947, timestamp: 2022-08-19 10:44:46.863880\n",
      "resetting env. episode 6409, reward total was -19.0. running mean: -18.09547206203201, timestamp: 2022-08-19 10:44:51.403934\n",
      "resetting env. episode 6410, reward total was -21.0. running mean: -18.12451734141169, timestamp: 2022-08-19 10:44:56.880999\n",
      "resetting env. episode 6411, reward total was -21.0. running mean: -18.153272167997574, timestamp: 2022-08-19 10:45:01.567057\n",
      "resetting env. episode 6412, reward total was -15.0. running mean: -18.121739446317598, timestamp: 2022-08-19 10:45:06.453111\n",
      "resetting env. episode 6413, reward total was -19.0. running mean: -18.130522051854424, timestamp: 2022-08-19 10:45:11.108171\n",
      "resetting env. episode 6414, reward total was -16.0. running mean: -18.10921683133588, timestamp: 2022-08-19 10:45:15.919224\n",
      "resetting env. episode 6415, reward total was -17.0. running mean: -18.09812466302252, timestamp: 2022-08-19 10:45:21.475290\n",
      "resetting env. episode 6416, reward total was -15.0. running mean: -18.067143416392295, timestamp: 2022-08-19 10:45:27.408362\n",
      "resetting env. episode 6417, reward total was -17.0. running mean: -18.056471982228373, timestamp: 2022-08-19 10:45:32.544426\n",
      "resetting env. episode 6418, reward total was -18.0. running mean: -18.05590726240609, timestamp: 2022-08-19 10:45:37.925489\n",
      "resetting env. episode 6419, reward total was -15.0. running mean: -18.02534818978203, timestamp: 2022-08-19 10:45:45.011575\n",
      "resetting env. episode 6420, reward total was -19.0. running mean: -18.03509470788421, timestamp: 2022-08-19 10:45:49.895628\n",
      "resetting env. episode 6421, reward total was -16.0. running mean: -18.014743760805366, timestamp: 2022-08-19 10:45:54.505683\n",
      "resetting env. episode 6422, reward total was -16.0. running mean: -17.994596323197314, timestamp: 2022-08-19 10:46:00.049750\n",
      "resetting env. episode 6423, reward total was -15.0. running mean: -17.96465035996534, timestamp: 2022-08-19 10:46:05.544816\n",
      "resetting env. episode 6424, reward total was -17.0. running mean: -17.95500385636569, timestamp: 2022-08-19 10:46:10.394875\n",
      "resetting env. episode 6425, reward total was -19.0. running mean: -17.965453817802032, timestamp: 2022-08-19 10:46:15.534936\n",
      "resetting env. episode 6426, reward total was -14.0. running mean: -17.925799279624012, timestamp: 2022-08-19 10:46:21.278008\n",
      "resetting env. episode 6427, reward total was -21.0. running mean: -17.956541286827772, timestamp: 2022-08-19 10:46:25.487055\n",
      "resetting env. episode 6428, reward total was -18.0. running mean: -17.956975873959493, timestamp: 2022-08-19 10:46:32.376141\n",
      "resetting env. episode 6429, reward total was -21.0. running mean: -17.987406115219898, timestamp: 2022-08-19 10:46:38.512212\n",
      "resetting env. episode 6430, reward total was -15.0. running mean: -17.9575320540677, timestamp: 2022-08-19 10:46:43.809277\n",
      "resetting env. episode 6431, reward total was -19.0. running mean: -17.96795673352702, timestamp: 2022-08-19 10:46:47.481320\n",
      "resetting env. episode 6432, reward total was -21.0. running mean: -17.99827716619175, timestamp: 2022-08-19 10:46:52.688384\n",
      "resetting env. episode 6433, reward total was -19.0. running mean: -18.008294394529834, timestamp: 2022-08-19 10:46:57.912447\n",
      "resetting env. episode 6434, reward total was -18.0. running mean: -18.008211450584536, timestamp: 2022-08-19 10:47:03.922517\n",
      "resetting env. episode 6435, reward total was -19.0. running mean: -18.01812933607869, timestamp: 2022-08-19 10:47:09.587585\n",
      "resetting env. episode 6436, reward total was -16.0. running mean: -17.997948042717905, timestamp: 2022-08-19 10:47:14.803649\n",
      "resetting env. episode 6437, reward total was -16.0. running mean: -17.977968562290727, timestamp: 2022-08-19 10:47:20.365714\n",
      "resetting env. episode 6438, reward total was -21.0. running mean: -18.00818887666782, timestamp: 2022-08-19 10:47:25.268298\n",
      "resetting env. episode 6439, reward total was -11.0. running mean: -17.93810698790114, timestamp: 2022-08-19 10:47:31.516372\n",
      "resetting env. episode 6440, reward total was -16.0. running mean: -17.91872591802213, timestamp: 2022-08-19 10:47:36.429430\n",
      "resetting env. episode 6441, reward total was -13.0. running mean: -17.869538658841908, timestamp: 2022-08-19 10:47:43.243513\n",
      "resetting env. episode 6442, reward total was -20.0. running mean: -17.890843272253488, timestamp: 2022-08-19 10:47:47.167562\n",
      "resetting env. episode 6443, reward total was -18.0. running mean: -17.89193483953095, timestamp: 2022-08-19 10:47:52.947633\n",
      "resetting env. episode 6444, reward total was -17.0. running mean: -17.88301549113564, timestamp: 2022-08-19 10:47:58.072698\n",
      "resetting env. episode 6445, reward total was -18.0. running mean: -17.884185336224284, timestamp: 2022-08-19 10:48:03.080752\n",
      "resetting env. episode 6446, reward total was -19.0. running mean: -17.895343482862042, timestamp: 2022-08-19 10:48:08.807822\n",
      "resetting env. episode 6447, reward total was -19.0. running mean: -17.906390048033423, timestamp: 2022-08-19 10:48:14.488423\n",
      "resetting env. episode 6448, reward total was -16.0. running mean: -17.88732614755309, timestamp: 2022-08-19 10:48:20.778498\n",
      "resetting env. episode 6449, reward total was -15.0. running mean: -17.858452886077558, timestamp: 2022-08-19 10:48:25.851561\n",
      "resetting env. episode 6450, reward total was -19.0. running mean: -17.869868357216784, timestamp: 2022-08-19 10:48:31.103624\n",
      "resetting env. episode 6451, reward total was -20.0. running mean: -17.891169673644615, timestamp: 2022-08-19 10:48:35.560678\n",
      "resetting env. episode 6452, reward total was -16.0. running mean: -17.87225797690817, timestamp: 2022-08-19 10:48:41.397749\n",
      "resetting env. episode 6453, reward total was -18.0. running mean: -17.873535397139086, timestamp: 2022-08-19 10:48:46.834816\n",
      "resetting env. episode 6454, reward total was -20.0. running mean: -17.894800043167695, timestamp: 2022-08-19 10:48:52.222880\n",
      "resetting env. episode 6455, reward total was -18.0. running mean: -17.895852042736017, timestamp: 2022-08-19 10:48:58.013955\n",
      "resetting env. episode 6456, reward total was -20.0. running mean: -17.916893522308655, timestamp: 2022-08-19 10:49:01.634998\n",
      "resetting env. episode 6457, reward total was -15.0. running mean: -17.887724587085568, timestamp: 2022-08-19 10:49:07.619068\n",
      "resetting env. episode 6458, reward total was -19.0. running mean: -17.898847341214715, timestamp: 2022-08-19 10:49:13.805142\n",
      "resetting env. episode 6459, reward total was -17.0. running mean: -17.88985886780257, timestamp: 2022-08-19 10:49:19.829212\n",
      "resetting env. episode 6460, reward total was -15.0. running mean: -17.86096027912454, timestamp: 2022-08-19 10:49:25.522292\n",
      "resetting env. episode 6461, reward total was -19.0. running mean: -17.872350676333298, timestamp: 2022-08-19 10:49:31.209349\n",
      "resetting env. episode 6462, reward total was -15.0. running mean: -17.843627169569963, timestamp: 2022-08-19 10:49:37.268421\n",
      "resetting env. episode 6463, reward total was -16.0. running mean: -17.825190897874265, timestamp: 2022-08-19 10:49:44.043505\n",
      "resetting env. episode 6464, reward total was -17.0. running mean: -17.816938988895522, timestamp: 2022-08-19 10:49:49.770574\n",
      "resetting env. episode 6465, reward total was -18.0. running mean: -17.818769599006565, timestamp: 2022-08-19 10:49:54.988635\n",
      "resetting env. episode 6466, reward total was -20.0. running mean: -17.8405819030165, timestamp: 2022-08-19 10:49:59.679692\n",
      "resetting env. episode 6467, reward total was -15.0. running mean: -17.812176083986333, timestamp: 2022-08-19 10:50:06.115774\n",
      "resetting env. episode 6468, reward total was -19.0. running mean: -17.82405432314647, timestamp: 2022-08-19 10:50:10.459821\n",
      "resetting env. episode 6469, reward total was -19.0. running mean: -17.835813779915007, timestamp: 2022-08-19 10:50:17.071900\n",
      "resetting env. episode 6470, reward total was -17.0. running mean: -17.827455642115858, timestamp: 2022-08-19 10:50:22.158961\n",
      "resetting env. episode 6471, reward total was -17.0. running mean: -17.8191810856947, timestamp: 2022-08-19 10:50:27.023023\n",
      "resetting env. episode 6472, reward total was -18.0. running mean: -17.820989274837753, timestamp: 2022-08-19 10:50:32.211082\n",
      "resetting env. episode 6473, reward total was -19.0. running mean: -17.832779382089377, timestamp: 2022-08-19 10:50:37.392146\n",
      "resetting env. episode 6474, reward total was -15.0. running mean: -17.80445158826848, timestamp: 2022-08-19 10:50:42.505205\n",
      "resetting env. episode 6475, reward total was -17.0. running mean: -17.796407072385797, timestamp: 2022-08-19 10:50:47.747272\n",
      "resetting env. episode 6476, reward total was -17.0. running mean: -17.78844300166194, timestamp: 2022-08-19 10:50:53.207334\n",
      "resetting env. episode 6477, reward total was -17.0. running mean: -17.780558571645322, timestamp: 2022-08-19 10:50:59.100404\n",
      "resetting env. episode 6478, reward total was -16.0. running mean: -17.76275298592887, timestamp: 2022-08-19 10:51:04.355466\n",
      "resetting env. episode 6479, reward total was -12.0. running mean: -17.70512545606958, timestamp: 2022-08-19 10:51:10.715545\n",
      "resetting env. episode 6480, reward total was -19.0. running mean: -17.718074201508887, timestamp: 2022-08-19 10:51:15.365599\n",
      "resetting env. episode 6481, reward total was -14.0. running mean: -17.6808934594938, timestamp: 2022-08-19 10:51:19.912657\n",
      "resetting env. episode 6482, reward total was -19.0. running mean: -17.694084524898862, timestamp: 2022-08-19 10:51:24.695711\n",
      "resetting env. episode 6483, reward total was -19.0. running mean: -17.707143679649874, timestamp: 2022-08-19 10:51:27.868753\n",
      "resetting env. episode 6484, reward total was -18.0. running mean: -17.710072242853375, timestamp: 2022-08-19 10:51:31.827798\n",
      "resetting env. episode 6485, reward total was -18.0. running mean: -17.71297152042484, timestamp: 2022-08-19 10:51:36.867856\n",
      "resetting env. episode 6486, reward total was -21.0. running mean: -17.745841805220593, timestamp: 2022-08-19 10:51:42.811929\n",
      "resetting env. episode 6487, reward total was -18.0. running mean: -17.748383387168385, timestamp: 2022-08-19 10:51:47.309981\n",
      "resetting env. episode 6488, reward total was -16.0. running mean: -17.7308995532967, timestamp: 2022-08-19 10:51:52.772048\n",
      "resetting env. episode 6489, reward total was -21.0. running mean: -17.763590557763735, timestamp: 2022-08-19 10:51:56.852098\n",
      "resetting env. episode 6490, reward total was -19.0. running mean: -17.775954652186098, timestamp: 2022-08-19 10:52:03.066168\n",
      "resetting env. episode 6491, reward total was -20.0. running mean: -17.798195105664234, timestamp: 2022-08-19 10:52:07.146219\n",
      "resetting env. episode 6492, reward total was -21.0. running mean: -17.83021315460759, timestamp: 2022-08-19 10:52:12.596283\n",
      "resetting env. episode 6493, reward total was -21.0. running mean: -17.861911023061516, timestamp: 2022-08-19 10:52:17.418340\n",
      "resetting env. episode 6494, reward total was -19.0. running mean: -17.8732919128309, timestamp: 2022-08-19 10:52:22.265398\n",
      "resetting env. episode 6495, reward total was -18.0. running mean: -17.874558993702593, timestamp: 2022-08-19 10:52:27.920468\n",
      "resetting env. episode 6496, reward total was -19.0. running mean: -17.885813403765567, timestamp: 2022-08-19 10:52:32.168516\n",
      "resetting env. episode 6497, reward total was -19.0. running mean: -17.89695526972791, timestamp: 2022-08-19 10:52:37.225574\n",
      "resetting env. episode 6498, reward total was -19.0. running mean: -17.907985717030634, timestamp: 2022-08-19 10:52:42.661640\n",
      "resetting env. episode 6499, reward total was -13.0. running mean: -17.858905859860325, timestamp: 2022-08-19 10:52:47.253700\n",
      "resetting env. episode 6500, reward total was -18.0. running mean: -17.86031680126172, timestamp: 2022-08-19 10:52:53.266768\n",
      "resetting env. episode 6501, reward total was -18.0. running mean: -17.861713633249103, timestamp: 2022-08-19 10:52:58.497828\n",
      "resetting env. episode 6502, reward total was -15.0. running mean: -17.83309649691661, timestamp: 2022-08-19 10:53:03.988893\n",
      "resetting env. episode 6503, reward total was -19.0. running mean: -17.844765531947445, timestamp: 2022-08-19 10:53:09.369957\n",
      "resetting env. episode 6504, reward total was -15.0. running mean: -17.81631787662797, timestamp: 2022-08-19 10:53:15.722033\n",
      "resetting env. episode 6505, reward total was -17.0. running mean: -17.808154697861692, timestamp: 2022-08-19 10:53:22.004108\n",
      "resetting env. episode 6506, reward total was -19.0. running mean: -17.820073150883076, timestamp: 2022-08-19 10:53:26.759162\n",
      "resetting env. episode 6507, reward total was -18.0. running mean: -17.821872419374245, timestamp: 2022-08-19 10:53:32.486231\n",
      "resetting env. episode 6508, reward total was -16.0. running mean: -17.8036536951805, timestamp: 2022-08-19 10:53:37.118283\n",
      "resetting env. episode 6509, reward total was -18.0. running mean: -17.805617158228696, timestamp: 2022-08-19 10:53:42.732352\n",
      "resetting env. episode 6510, reward total was -21.0. running mean: -17.83756098664641, timestamp: 2022-08-19 10:53:48.689419\n",
      "resetting env. episode 6511, reward total was -18.0. running mean: -17.839185376779945, timestamp: 2022-08-19 10:53:55.741504\n",
      "resetting env. episode 6512, reward total was -21.0. running mean: -17.870793523012146, timestamp: 2022-08-19 10:54:00.463559\n",
      "resetting env. episode 6513, reward total was -21.0. running mean: -17.902085587782025, timestamp: 2022-08-19 10:54:05.842622\n",
      "resetting env. episode 6514, reward total was -19.0. running mean: -17.913064731904207, timestamp: 2022-08-19 10:54:10.455680\n",
      "resetting env. episode 6515, reward total was -19.0. running mean: -17.923934084585166, timestamp: 2022-08-19 10:54:16.173747\n",
      "resetting env. episode 6516, reward total was -20.0. running mean: -17.944694743739316, timestamp: 2022-08-19 10:54:22.053813\n",
      "resetting env. episode 6517, reward total was -19.0. running mean: -17.955247796301922, timestamp: 2022-08-19 10:54:27.922883\n",
      "resetting env. episode 6518, reward total was -19.0. running mean: -17.965695318338906, timestamp: 2022-08-19 10:54:33.719950\n",
      "resetting env. episode 6519, reward total was -16.0. running mean: -17.946038365155516, timestamp: 2022-08-19 10:54:39.844020\n",
      "resetting env. episode 6520, reward total was -17.0. running mean: -17.936577981503962, timestamp: 2022-08-19 10:54:45.244084\n",
      "resetting env. episode 6521, reward total was -18.0. running mean: -17.937212201688922, timestamp: 2022-08-19 10:54:49.727139\n",
      "resetting env. episode 6522, reward total was -19.0. running mean: -17.947840079672034, timestamp: 2022-08-19 10:54:54.320192\n",
      "resetting env. episode 6523, reward total was -18.0. running mean: -17.94836167887531, timestamp: 2022-08-19 10:54:58.761247\n",
      "resetting env. episode 6524, reward total was -20.0. running mean: -17.968878062086556, timestamp: 2022-08-19 10:55:03.439299\n",
      "resetting env. episode 6525, reward total was -17.0. running mean: -17.959189281465694, timestamp: 2022-08-19 10:55:09.464369\n",
      "resetting env. episode 6526, reward total was -19.0. running mean: -17.96959738865104, timestamp: 2022-08-19 10:55:13.754418\n",
      "resetting env. episode 6527, reward total was -15.0. running mean: -17.939901414764527, timestamp: 2022-08-19 10:55:19.351483\n",
      "resetting env. episode 6528, reward total was -18.0. running mean: -17.940502400616882, timestamp: 2022-08-19 10:55:24.297542\n",
      "resetting env. episode 6529, reward total was -18.0. running mean: -17.941097376610713, timestamp: 2022-08-19 10:55:29.585606\n",
      "resetting env. episode 6530, reward total was -14.0. running mean: -17.901686402844607, timestamp: 2022-08-19 10:55:34.721661\n",
      "resetting env. episode 6531, reward total was -19.0. running mean: -17.91266953881616, timestamp: 2022-08-19 10:55:39.184717\n",
      "resetting env. episode 6532, reward total was -20.0. running mean: -17.933542843427997, timestamp: 2022-08-19 10:55:44.443774\n",
      "resetting env. episode 6533, reward total was -19.0. running mean: -17.944207414993716, timestamp: 2022-08-19 10:55:49.342834\n",
      "resetting env. episode 6534, reward total was -14.0. running mean: -17.90476534084378, timestamp: 2022-08-19 10:55:54.954897\n",
      "resetting env. episode 6535, reward total was -17.0. running mean: -17.895717687435344, timestamp: 2022-08-19 10:56:00.958971\n",
      "resetting env. episode 6536, reward total was -20.0. running mean: -17.91676051056099, timestamp: 2022-08-19 10:56:05.304016\n",
      "resetting env. episode 6537, reward total was -14.0. running mean: -17.87759290545538, timestamp: 2022-08-19 10:56:10.654080\n",
      "resetting env. episode 6538, reward total was -13.0. running mean: -17.828816976400827, timestamp: 2022-08-19 10:56:16.141146\n",
      "resetting env. episode 6539, reward total was -20.0. running mean: -17.850528806636817, timestamp: 2022-08-19 10:56:20.662196\n",
      "resetting env. episode 6540, reward total was -18.0. running mean: -17.852023518570448, timestamp: 2022-08-19 10:56:25.764254\n",
      "resetting env. episode 6541, reward total was -21.0. running mean: -17.883503283384744, timestamp: 2022-08-19 10:56:30.455307\n",
      "resetting env. episode 6542, reward total was -21.0. running mean: -17.914668250550896, timestamp: 2022-08-19 10:56:34.108350\n",
      "resetting env. episode 6543, reward total was -18.0. running mean: -17.91552156804539, timestamp: 2022-08-19 10:56:38.936404\n",
      "resetting env. episode 6544, reward total was -19.0. running mean: -17.926366352364937, timestamp: 2022-08-19 10:56:43.099452\n",
      "resetting env. episode 6545, reward total was -16.0. running mean: -17.907102688841288, timestamp: 2022-08-19 10:56:49.498527\n",
      "resetting env. episode 6546, reward total was -19.0. running mean: -17.918031661952877, timestamp: 2022-08-19 10:56:54.397583\n",
      "resetting env. episode 6547, reward total was -18.0. running mean: -17.918851345333348, timestamp: 2022-08-19 10:56:59.269642\n",
      "resetting env. episode 6548, reward total was -20.0. running mean: -17.939662831880014, timestamp: 2022-08-19 10:57:03.417691\n",
      "resetting env. episode 6549, reward total was -15.0. running mean: -17.91026620356121, timestamp: 2022-08-19 10:57:08.729750\n",
      "resetting env. episode 6550, reward total was -19.0. running mean: -17.9211635415256, timestamp: 2022-08-19 10:57:12.939796\n",
      "resetting env. episode 6551, reward total was -18.0. running mean: -17.921951906110344, timestamp: 2022-08-19 10:57:19.771875\n",
      "resetting env. episode 6552, reward total was -20.0. running mean: -17.94273238704924, timestamp: 2022-08-19 10:57:24.640934\n",
      "resetting env. episode 6553, reward total was -15.0. running mean: -17.913305063178747, timestamp: 2022-08-19 10:57:29.937992\n",
      "resetting env. episode 6554, reward total was -17.0. running mean: -17.90417201254696, timestamp: 2022-08-19 10:57:35.612056\n",
      "resetting env. episode 6555, reward total was -15.0. running mean: -17.875130292421492, timestamp: 2022-08-19 10:57:41.324122\n",
      "resetting env. episode 6556, reward total was -16.0. running mean: -17.856378989497276, timestamp: 2022-08-19 10:57:46.105178\n",
      "resetting env. episode 6557, reward total was -20.0. running mean: -17.877815199602303, timestamp: 2022-08-19 10:57:51.136233\n",
      "resetting env. episode 6558, reward total was -21.0. running mean: -17.90903704760628, timestamp: 2022-08-19 10:57:56.225294\n",
      "resetting env. episode 6559, reward total was -16.0. running mean: -17.889946677130215, timestamp: 2022-08-19 10:58:01.476353\n",
      "resetting env. episode 6560, reward total was -18.0. running mean: -17.891047210358913, timestamp: 2022-08-19 10:58:05.828400\n",
      "resetting env. episode 6561, reward total was -18.0. running mean: -17.892136738255324, timestamp: 2022-08-19 10:58:10.311454\n",
      "resetting env. episode 6562, reward total was -18.0. running mean: -17.89321537087277, timestamp: 2022-08-19 10:58:14.798503\n",
      "resetting env. episode 6563, reward total was -21.0. running mean: -17.924283217164042, timestamp: 2022-08-19 10:58:19.226556\n",
      "resetting env. episode 6564, reward total was -20.0. running mean: -17.9450403849924, timestamp: 2022-08-19 10:58:23.647601\n",
      "resetting env. episode 6565, reward total was -13.0. running mean: -17.895589981142475, timestamp: 2022-08-19 10:58:29.891674\n",
      "resetting env. episode 6566, reward total was -18.0. running mean: -17.89663408133105, timestamp: 2022-08-19 10:58:35.599739\n",
      "resetting env. episode 6567, reward total was -18.0. running mean: -17.89766774051774, timestamp: 2022-08-19 10:58:40.962803\n",
      "resetting env. episode 6568, reward total was -15.0. running mean: -17.86869106311256, timestamp: 2022-08-19 10:58:47.440871\n",
      "resetting env. episode 6569, reward total was -17.0. running mean: -17.860004152481437, timestamp: 2022-08-19 10:58:53.610944\n",
      "resetting env. episode 6570, reward total was -13.0. running mean: -17.811404110956623, timestamp: 2022-08-19 10:59:02.007585\n",
      "resetting env. episode 6571, reward total was -17.0. running mean: -17.80329006984706, timestamp: 2022-08-19 10:59:07.173643\n",
      "resetting env. episode 6572, reward total was -19.0. running mean: -17.815257169148587, timestamp: 2022-08-19 10:59:12.138700\n",
      "resetting env. episode 6573, reward total was -17.0. running mean: -17.8071045974571, timestamp: 2022-08-19 10:59:16.897754\n",
      "resetting env. episode 6574, reward total was -17.0. running mean: -17.79903355148253, timestamp: 2022-08-19 10:59:21.325808\n",
      "resetting env. episode 6575, reward total was -20.0. running mean: -17.821043215967705, timestamp: 2022-08-19 10:59:25.593851\n",
      "resetting env. episode 6576, reward total was -18.0. running mean: -17.82283278380803, timestamp: 2022-08-19 10:59:31.778921\n",
      "resetting env. episode 6577, reward total was -17.0. running mean: -17.81460445596995, timestamp: 2022-08-19 10:59:36.847980\n",
      "resetting env. episode 6578, reward total was -17.0. running mean: -17.80645841141025, timestamp: 2022-08-19 10:59:42.249036\n",
      "resetting env. episode 6579, reward total was -20.0. running mean: -17.828393827296146, timestamp: 2022-08-19 10:59:46.777092\n",
      "resetting env. episode 6580, reward total was -18.0. running mean: -17.830109889023184, timestamp: 2022-08-19 10:59:51.536141\n",
      "resetting env. episode 6581, reward total was -18.0. running mean: -17.831808790132953, timestamp: 2022-08-19 10:59:56.710200\n",
      "resetting env. episode 6582, reward total was -19.0. running mean: -17.843490702231627, timestamp: 2022-08-19 11:00:01.749261\n",
      "resetting env. episode 6583, reward total was -17.0. running mean: -17.83505579520931, timestamp: 2022-08-19 11:00:07.992329\n",
      "resetting env. episode 6584, reward total was -17.0. running mean: -17.82670523725722, timestamp: 2022-08-19 11:00:13.068388\n",
      "resetting env. episode 6585, reward total was -19.0. running mean: -17.838438184884648, timestamp: 2022-08-19 11:00:16.815432\n",
      "resetting env. episode 6586, reward total was -17.0. running mean: -17.830053803035803, timestamp: 2022-08-19 11:00:21.013802\n",
      "resetting env. episode 6587, reward total was -20.0. running mean: -17.851753265005442, timestamp: 2022-08-19 11:00:25.137847\n",
      "resetting env. episode 6588, reward total was -18.0. running mean: -17.853235732355387, timestamp: 2022-08-19 11:00:29.943903\n",
      "resetting env. episode 6589, reward total was -16.0. running mean: -17.834703375031832, timestamp: 2022-08-19 11:00:33.921948\n",
      "resetting env. episode 6590, reward total was -19.0. running mean: -17.846356341281517, timestamp: 2022-08-19 11:00:38.802001\n",
      "resetting env. episode 6591, reward total was -17.0. running mean: -17.837892777868703, timestamp: 2022-08-19 11:00:43.919059\n",
      "resetting env. episode 6592, reward total was -19.0. running mean: -17.849513850090016, timestamp: 2022-08-19 11:00:49.547129\n",
      "resetting env. episode 6593, reward total was -15.0. running mean: -17.821018711589115, timestamp: 2022-08-19 11:00:54.891191\n",
      "resetting env. episode 6594, reward total was -21.0. running mean: -17.852808524473225, timestamp: 2022-08-19 11:00:59.422238\n",
      "resetting env. episode 6595, reward total was -21.0. running mean: -17.884280439228494, timestamp: 2022-08-19 11:01:03.935291\n",
      "resetting env. episode 6596, reward total was -15.0. running mean: -17.855437634836207, timestamp: 2022-08-19 11:01:09.735362\n",
      "resetting env. episode 6597, reward total was -18.0. running mean: -17.856883258487844, timestamp: 2022-08-19 11:01:14.671416\n",
      "resetting env. episode 6598, reward total was -18.0. running mean: -17.858314425902964, timestamp: 2022-08-19 11:01:20.604485\n",
      "resetting env. episode 6599, reward total was -19.0. running mean: -17.869731281643936, timestamp: 2022-08-19 11:01:25.877545\n",
      "resetting env. episode 6600, reward total was -15.0. running mean: -17.841033968827496, timestamp: 2022-08-19 11:01:32.646157\n",
      "resetting env. episode 6601, reward total was -16.0. running mean: -17.822623629139223, timestamp: 2022-08-19 11:01:37.509212\n",
      "resetting env. episode 6602, reward total was -16.0. running mean: -17.80439739284783, timestamp: 2022-08-19 11:01:43.569286\n",
      "resetting env. episode 6603, reward total was -18.0. running mean: -17.80635341891935, timestamp: 2022-08-19 11:01:48.748346\n",
      "resetting env. episode 6604, reward total was -18.0. running mean: -17.808289884730158, timestamp: 2022-08-19 11:01:53.704403\n",
      "resetting env. episode 6605, reward total was -19.0. running mean: -17.82020698588286, timestamp: 2022-08-19 11:01:58.241457\n",
      "resetting env. episode 6606, reward total was -18.0. running mean: -17.822004916024028, timestamp: 2022-08-19 11:02:02.849508\n",
      "resetting env. episode 6607, reward total was -18.0. running mean: -17.823784866863786, timestamp: 2022-08-19 11:02:08.801581\n",
      "resetting env. episode 6608, reward total was -19.0. running mean: -17.83554701819515, timestamp: 2022-08-19 11:02:13.888639\n",
      "resetting env. episode 6609, reward total was -21.0. running mean: -17.8671915480132, timestamp: 2022-08-19 11:02:19.037701\n",
      "resetting env. episode 6610, reward total was -19.0. running mean: -17.87851963253307, timestamp: 2022-08-19 11:02:24.930769\n",
      "resetting env. episode 6611, reward total was -17.0. running mean: -17.86973443620774, timestamp: 2022-08-19 11:02:28.963819\n",
      "resetting env. episode 6612, reward total was -19.0. running mean: -17.881037091845663, timestamp: 2022-08-19 11:02:33.907875\n",
      "resetting env. episode 6613, reward total was -19.0. running mean: -17.89222672092721, timestamp: 2022-08-19 11:02:39.044938\n",
      "resetting env. episode 6614, reward total was -16.0. running mean: -17.873304453717935, timestamp: 2022-08-19 11:02:44.779004\n",
      "resetting env. episode 6615, reward total was -18.0. running mean: -17.874571409180756, timestamp: 2022-08-19 11:02:50.261068\n",
      "resetting env. episode 6616, reward total was -17.0. running mean: -17.86582569508895, timestamp: 2022-08-19 11:02:54.940126\n",
      "resetting env. episode 6617, reward total was -17.0. running mean: -17.857167438138063, timestamp: 2022-08-19 11:03:00.770192\n",
      "resetting env. episode 6618, reward total was -17.0. running mean: -17.848595763756684, timestamp: 2022-08-19 11:03:06.445262\n",
      "resetting env. episode 6619, reward total was -21.0. running mean: -17.88010980611912, timestamp: 2022-08-19 11:03:11.991328\n",
      "resetting env. episode 6620, reward total was -17.0. running mean: -17.871308708057928, timestamp: 2022-08-19 11:03:18.824407\n",
      "resetting env. episode 6621, reward total was -19.0. running mean: -17.882595620977348, timestamp: 2022-08-19 11:03:23.247459\n",
      "resetting env. episode 6622, reward total was -20.0. running mean: -17.903769664767573, timestamp: 2022-08-19 11:03:28.814527\n",
      "resetting env. episode 6623, reward total was -18.0. running mean: -17.904731968119897, timestamp: 2022-08-19 11:03:33.080577\n",
      "resetting env. episode 6624, reward total was -19.0. running mean: -17.9156846484387, timestamp: 2022-08-19 11:03:37.521634\n",
      "resetting env. episode 6625, reward total was -18.0. running mean: -17.916527801954313, timestamp: 2022-08-19 11:03:42.881692\n",
      "resetting env. episode 6626, reward total was -21.0. running mean: -17.94736252393477, timestamp: 2022-08-19 11:03:48.388761\n",
      "resetting env. episode 6627, reward total was -21.0. running mean: -17.977888898695426, timestamp: 2022-08-19 11:03:52.138804\n",
      "resetting env. episode 6628, reward total was -19.0. running mean: -17.98811000970847, timestamp: 2022-08-19 11:03:56.907860\n",
      "resetting env. episode 6629, reward total was -19.0. running mean: -17.998228909611388, timestamp: 2022-08-19 11:04:02.402927\n",
      "resetting env. episode 6630, reward total was -19.0. running mean: -18.008246620515276, timestamp: 2022-08-19 11:04:06.589975\n",
      "resetting env. episode 6631, reward total was -19.0. running mean: -18.018164154310124, timestamp: 2022-08-19 11:04:11.253033\n",
      "resetting env. episode 6632, reward total was -18.0. running mean: -18.017982512767023, timestamp: 2022-08-19 11:04:16.067087\n",
      "resetting env. episode 6633, reward total was -17.0. running mean: -18.007802687639355, timestamp: 2022-08-19 11:04:22.208161\n",
      "resetting env. episode 6634, reward total was -19.0. running mean: -18.017724660762962, timestamp: 2022-08-19 11:04:27.319231\n",
      "resetting env. episode 6635, reward total was -17.0. running mean: -18.007547414155333, timestamp: 2022-08-19 11:04:32.824287\n",
      "resetting env. episode 6636, reward total was -17.0. running mean: -17.99747194001378, timestamp: 2022-08-19 11:04:39.848370\n",
      "resetting env. episode 6637, reward total was -19.0. running mean: -18.007497220613644, timestamp: 2022-08-19 11:04:43.826421\n",
      "resetting env. episode 6638, reward total was -19.0. running mean: -18.01742224840751, timestamp: 2022-08-19 11:04:47.464464\n",
      "resetting env. episode 6639, reward total was -17.0. running mean: -18.007248025923435, timestamp: 2022-08-19 11:04:52.643522\n",
      "resetting env. episode 6640, reward total was -14.0. running mean: -17.9671755456642, timestamp: 2022-08-19 11:04:57.988587\n",
      "resetting env. episode 6641, reward total was -17.0. running mean: -17.95750379020756, timestamp: 2022-08-19 11:05:02.835644\n",
      "resetting env. episode 6642, reward total was -21.0. running mean: -17.987928752305486, timestamp: 2022-08-19 11:05:07.309697\n",
      "resetting env. episode 6643, reward total was -17.0. running mean: -17.978049464782433, timestamp: 2022-08-19 11:05:13.379771\n",
      "resetting env. episode 6644, reward total was -18.0. running mean: -17.978268970134607, timestamp: 2022-08-19 11:05:18.423832\n",
      "resetting env. episode 6645, reward total was -21.0. running mean: -18.00848628043326, timestamp: 2022-08-19 11:05:23.808896\n",
      "resetting env. episode 6646, reward total was -17.0. running mean: -17.99840141762893, timestamp: 2022-08-19 11:05:30.080969\n",
      "resetting env. episode 6647, reward total was -20.0. running mean: -18.01841740345264, timestamp: 2022-08-19 11:05:34.830027\n",
      "resetting env. episode 6648, reward total was -14.0. running mean: -17.978233229418116, timestamp: 2022-08-19 11:05:40.380090\n",
      "resetting env. episode 6649, reward total was -19.0. running mean: -17.988450897123936, timestamp: 2022-08-19 11:05:45.790156\n",
      "resetting env. episode 6650, reward total was -21.0. running mean: -18.0185663881527, timestamp: 2022-08-19 11:05:51.006217\n",
      "resetting env. episode 6651, reward total was -19.0. running mean: -18.028380724271173, timestamp: 2022-08-19 11:05:56.647286\n",
      "resetting env. episode 6652, reward total was -20.0. running mean: -18.04809691702846, timestamp: 2022-08-19 11:06:01.099350\n",
      "resetting env. episode 6653, reward total was -21.0. running mean: -18.077615947858174, timestamp: 2022-08-19 11:06:06.566402\n",
      "resetting env. episode 6654, reward total was -16.0. running mean: -18.05683978837959, timestamp: 2022-08-19 11:06:13.451485\n",
      "resetting env. episode 6655, reward total was -16.0. running mean: -18.036271390495795, timestamp: 2022-08-19 11:06:19.380556\n",
      "resetting env. episode 6656, reward total was -19.0. running mean: -18.045908676590837, timestamp: 2022-08-19 11:06:24.459615\n",
      "resetting env. episode 6657, reward total was -18.0. running mean: -18.04544958982493, timestamp: 2022-08-19 11:06:30.089685\n",
      "resetting env. episode 6658, reward total was -17.0. running mean: -18.034995093926682, timestamp: 2022-08-19 11:06:35.571748\n",
      "resetting env. episode 6659, reward total was -16.0. running mean: -18.014645142987415, timestamp: 2022-08-19 11:06:41.453818\n",
      "resetting env. episode 6660, reward total was -16.0. running mean: -17.994498691557542, timestamp: 2022-08-19 11:06:47.956896\n",
      "resetting env. episode 6661, reward total was -14.0. running mean: -17.954553704641967, timestamp: 2022-08-19 11:06:53.920967\n",
      "resetting env. episode 6662, reward total was -16.0. running mean: -17.935008167595548, timestamp: 2022-08-19 11:06:59.859042\n",
      "resetting env. episode 6663, reward total was -16.0. running mean: -17.915658085919592, timestamp: 2022-08-19 11:07:05.209100\n",
      "resetting env. episode 6664, reward total was -15.0. running mean: -17.886501505060394, timestamp: 2022-08-19 11:07:10.384690\n",
      "resetting env. episode 6665, reward total was -18.0. running mean: -17.88763649000979, timestamp: 2022-08-19 11:07:15.548752\n",
      "resetting env. episode 6666, reward total was -20.0. running mean: -17.90876012510969, timestamp: 2022-08-19 11:07:20.428810\n",
      "resetting env. episode 6667, reward total was -20.0. running mean: -17.929672523858592, timestamp: 2022-08-19 11:07:24.846862\n",
      "resetting env. episode 6668, reward total was -18.0. running mean: -17.930375798620005, timestamp: 2022-08-19 11:07:30.134928\n",
      "resetting env. episode 6669, reward total was -16.0. running mean: -17.911072040633805, timestamp: 2022-08-19 11:07:36.663003\n",
      "resetting env. episode 6670, reward total was -17.0. running mean: -17.901961320227468, timestamp: 2022-08-19 11:07:42.007067\n",
      "resetting env. episode 6671, reward total was -19.0. running mean: -17.912941707025194, timestamp: 2022-08-19 11:07:46.988655\n",
      "resetting env. episode 6672, reward total was -18.0. running mean: -17.91381228995494, timestamp: 2022-08-19 11:07:51.585705\n",
      "resetting env. episode 6673, reward total was -16.0. running mean: -17.894674167055392, timestamp: 2022-08-19 11:07:58.177786\n",
      "resetting env. episode 6674, reward total was -18.0. running mean: -17.895727425384838, timestamp: 2022-08-19 11:08:03.852853\n",
      "resetting env. episode 6675, reward total was -20.0. running mean: -17.91677015113099, timestamp: 2022-08-19 11:08:08.532906\n",
      "resetting env. episode 6676, reward total was -20.0. running mean: -17.93760244961968, timestamp: 2022-08-19 11:08:14.245975\n",
      "resetting env. episode 6677, reward total was -20.0. running mean: -17.95822642512348, timestamp: 2022-08-19 11:08:19.289034\n",
      "resetting env. episode 6678, reward total was -21.0. running mean: -17.988644160872248, timestamp: 2022-08-19 11:08:23.596087\n",
      "resetting env. episode 6679, reward total was -17.0. running mean: -17.978757719263527, timestamp: 2022-08-19 11:08:28.035136\n",
      "resetting env. episode 6680, reward total was -17.0. running mean: -17.968970142070894, timestamp: 2022-08-19 11:08:34.935222\n",
      "resetting env. episode 6681, reward total was -20.0. running mean: -17.989280440650184, timestamp: 2022-08-19 11:08:39.495272\n",
      "resetting env. episode 6682, reward total was -19.0. running mean: -17.999387636243682, timestamp: 2022-08-19 11:08:43.263317\n",
      "resetting env. episode 6683, reward total was -19.0. running mean: -18.009393759881245, timestamp: 2022-08-19 11:08:48.295375\n",
      "resetting env. episode 6684, reward total was -18.0. running mean: -18.009299822282433, timestamp: 2022-08-19 11:08:54.237448\n",
      "resetting env. episode 6685, reward total was -18.0. running mean: -18.009206824059607, timestamp: 2022-08-19 11:08:58.733499\n",
      "resetting env. episode 6686, reward total was -19.0. running mean: -18.01911475581901, timestamp: 2022-08-19 11:09:04.059565\n",
      "resetting env. episode 6687, reward total was -18.0. running mean: -18.01892360826082, timestamp: 2022-08-19 11:09:10.212636\n",
      "resetting env. episode 6688, reward total was -19.0. running mean: -18.028734372178214, timestamp: 2022-08-19 11:09:15.016692\n",
      "resetting env. episode 6689, reward total was -19.0. running mean: -18.03844702845643, timestamp: 2022-08-19 11:09:19.865750\n",
      "resetting env. episode 6690, reward total was -17.0. running mean: -18.028062558171868, timestamp: 2022-08-19 11:09:25.542816\n",
      "resetting env. episode 6691, reward total was -19.0. running mean: -18.03778193259015, timestamp: 2022-08-19 11:09:29.716868\n",
      "resetting env. episode 6692, reward total was -17.0. running mean: -18.02740411326425, timestamp: 2022-08-19 11:09:35.393933\n",
      "resetting env. episode 6693, reward total was -17.0. running mean: -18.01713007213161, timestamp: 2022-08-19 11:09:41.326002\n",
      "resetting env. episode 6694, reward total was -17.0. running mean: -18.006958771410297, timestamp: 2022-08-19 11:09:46.722066\n",
      "resetting env. episode 6695, reward total was -17.0. running mean: -17.996889183696194, timestamp: 2022-08-19 11:09:51.417121\n",
      "resetting env. episode 6696, reward total was -18.0. running mean: -17.996920291859233, timestamp: 2022-08-19 11:09:56.470180\n",
      "resetting env. episode 6697, reward total was -21.0. running mean: -18.026951088940642, timestamp: 2022-08-19 11:10:00.714230\n",
      "resetting env. episode 6698, reward total was -17.0. running mean: -18.016681578051237, timestamp: 2022-08-19 11:10:06.918302\n",
      "resetting env. episode 6699, reward total was -11.0. running mean: -17.946514762270724, timestamp: 2022-08-19 11:10:13.946384\n",
      "resetting env. episode 6700, reward total was -21.0. running mean: -17.977049614648017, timestamp: 2022-08-19 11:10:18.927442\n",
      "resetting env. episode 6701, reward total was -17.0. running mean: -17.967279118501537, timestamp: 2022-08-19 11:10:24.170502\n",
      "resetting env. episode 6702, reward total was -20.0. running mean: -17.98760632731652, timestamp: 2022-08-19 11:10:28.387552\n",
      "resetting env. episode 6703, reward total was -17.0. running mean: -17.977730264043355, timestamp: 2022-08-19 11:10:33.689615\n",
      "resetting env. episode 6704, reward total was -15.0. running mean: -17.94795296140292, timestamp: 2022-08-19 11:10:39.461682\n",
      "resetting env. episode 6705, reward total was -14.0. running mean: -17.90847343178889, timestamp: 2022-08-19 11:10:46.049759\n",
      "resetting env. episode 6706, reward total was -19.0. running mean: -17.919388697471003, timestamp: 2022-08-19 11:10:51.497823\n",
      "resetting env. episode 6707, reward total was -21.0. running mean: -17.950194810496296, timestamp: 2022-08-19 11:10:56.629880\n",
      "resetting env. episode 6708, reward total was -17.0. running mean: -17.940692862391334, timestamp: 2022-08-19 11:11:01.865946\n",
      "resetting env. episode 6709, reward total was -17.0. running mean: -17.931285933767423, timestamp: 2022-08-19 11:11:07.330015\n",
      "resetting env. episode 6710, reward total was -19.0. running mean: -17.94197307442975, timestamp: 2022-08-19 11:11:11.559055\n",
      "resetting env. episode 6711, reward total was -18.0. running mean: -17.942553343685454, timestamp: 2022-08-19 11:11:16.933120\n",
      "resetting env. episode 6712, reward total was -13.0. running mean: -17.893127810248597, timestamp: 2022-08-19 11:11:23.282192\n",
      "resetting env. episode 6713, reward total was -14.0. running mean: -17.854196532146112, timestamp: 2022-08-19 11:11:29.331264\n",
      "resetting env. episode 6714, reward total was -17.0. running mean: -17.845654566824653, timestamp: 2022-08-19 11:11:35.811338\n",
      "resetting env. episode 6715, reward total was -18.0. running mean: -17.847198021156405, timestamp: 2022-08-19 11:11:41.120398\n",
      "resetting env. episode 6716, reward total was -19.0. running mean: -17.85872604094484, timestamp: 2022-08-19 11:11:45.672453\n",
      "resetting env. episode 6717, reward total was -17.0. running mean: -17.850138780535396, timestamp: 2022-08-19 11:11:52.022525\n",
      "resetting env. episode 6718, reward total was -20.0. running mean: -17.87163739273004, timestamp: 2022-08-19 11:11:56.485577\n",
      "resetting env. episode 6719, reward total was -17.0. running mean: -17.86292101880274, timestamp: 2022-08-19 11:12:02.181641\n",
      "resetting env. episode 6720, reward total was -17.0. running mean: -17.854291808614715, timestamp: 2022-08-19 11:12:09.150720\n",
      "resetting env. episode 6721, reward total was -18.0. running mean: -17.855748890528567, timestamp: 2022-08-19 11:12:14.143780\n",
      "resetting env. episode 6722, reward total was -16.0. running mean: -17.83719140162328, timestamp: 2022-08-19 11:12:19.912849\n",
      "resetting env. episode 6723, reward total was -14.0. running mean: -17.798819487607048, timestamp: 2022-08-19 11:12:26.693924\n",
      "resetting env. episode 6724, reward total was -13.0. running mean: -17.750831292730975, timestamp: 2022-08-19 11:12:33.728003\n",
      "resetting env. episode 6725, reward total was -18.0. running mean: -17.753322979803666, timestamp: 2022-08-19 11:12:39.402069\n",
      "resetting env. episode 6726, reward total was -21.0. running mean: -17.78578975000563, timestamp: 2022-08-19 11:12:44.207124\n",
      "resetting env. episode 6727, reward total was -19.0. running mean: -17.797931852505574, timestamp: 2022-08-19 11:12:48.886181\n",
      "resetting env. episode 6728, reward total was -18.0. running mean: -17.799952533980516, timestamp: 2022-08-19 11:12:53.995237\n",
      "resetting env. episode 6729, reward total was -19.0. running mean: -17.81195300864071, timestamp: 2022-08-19 11:12:58.328289\n",
      "resetting env. episode 6730, reward total was -18.0. running mean: -17.813833478554304, timestamp: 2022-08-19 11:13:04.783359\n",
      "resetting env. episode 6731, reward total was -19.0. running mean: -17.825695143768762, timestamp: 2022-08-19 11:13:08.997416\n",
      "resetting env. episode 6732, reward total was -18.0. running mean: -17.827438192331073, timestamp: 2022-08-19 11:13:15.146484\n",
      "resetting env. episode 6733, reward total was -18.0. running mean: -17.82916381040776, timestamp: 2022-08-19 11:13:22.151559\n",
      "resetting env. episode 6734, reward total was -21.0. running mean: -17.860872172303683, timestamp: 2022-08-19 11:13:26.730616\n",
      "resetting env. episode 6735, reward total was -19.0. running mean: -17.872263450580647, timestamp: 2022-08-19 11:13:31.738672\n",
      "resetting env. episode 6736, reward total was -17.0. running mean: -17.863540816074842, timestamp: 2022-08-19 11:13:37.584737\n",
      "resetting env. episode 6737, reward total was -19.0. running mean: -17.874905407914095, timestamp: 2022-08-19 11:13:44.759337\n",
      "resetting env. episode 6738, reward total was -19.0. running mean: -17.886156353834956, timestamp: 2022-08-19 11:13:50.694403\n",
      "resetting env. episode 6739, reward total was -21.0. running mean: -17.917294790296605, timestamp: 2022-08-19 11:13:56.185469\n",
      "resetting env. episode 6740, reward total was -19.0. running mean: -17.92812184239364, timestamp: 2022-08-19 11:14:00.890519\n",
      "resetting env. episode 6741, reward total was -21.0. running mean: -17.958840623969703, timestamp: 2022-08-19 11:14:06.442583\n",
      "resetting env. episode 6742, reward total was -19.0. running mean: -17.969252217730006, timestamp: 2022-08-19 11:14:11.040634\n",
      "resetting env. episode 6743, reward total was -20.0. running mean: -17.989559695552703, timestamp: 2022-08-19 11:14:17.277706\n",
      "resetting env. episode 6744, reward total was -15.0. running mean: -17.959664098597173, timestamp: 2022-08-19 11:14:23.183774\n",
      "resetting env. episode 6745, reward total was -21.0. running mean: -17.990067457611204, timestamp: 2022-08-19 11:14:28.479837\n",
      "resetting env. episode 6746, reward total was -20.0. running mean: -18.010166783035093, timestamp: 2022-08-19 11:14:33.496890\n",
      "resetting env. episode 6747, reward total was -19.0. running mean: -18.020065115204744, timestamp: 2022-08-19 11:14:38.870951\n",
      "resetting env. episode 6748, reward total was -17.0. running mean: -18.009864464052697, timestamp: 2022-08-19 11:14:45.740030\n",
      "resetting env. episode 6749, reward total was -18.0. running mean: -18.00976581941217, timestamp: 2022-08-19 11:14:51.118091\n",
      "resetting env. episode 6750, reward total was -18.0. running mean: -18.00966816121805, timestamp: 2022-08-19 11:14:56.817154\n",
      "resetting env. episode 6751, reward total was -17.0. running mean: -17.99957147960587, timestamp: 2022-08-19 11:15:01.898212\n",
      "resetting env. episode 6752, reward total was -21.0. running mean: -18.02957576480981, timestamp: 2022-08-19 11:15:06.103258\n",
      "resetting env. episode 6753, reward total was -15.0. running mean: -17.99928000716171, timestamp: 2022-08-19 11:15:12.878336\n",
      "resetting env. episode 6754, reward total was -21.0. running mean: -18.029287207090093, timestamp: 2022-08-19 11:15:19.256404\n",
      "resetting env. episode 6755, reward total was -14.0. running mean: -17.988994335019193, timestamp: 2022-08-19 11:15:26.376485\n",
      "resetting env. episode 6756, reward total was -21.0. running mean: -18.019104391669, timestamp: 2022-08-19 11:15:30.586535\n",
      "resetting env. episode 6757, reward total was -20.0. running mean: -18.03891334775231, timestamp: 2022-08-19 11:15:35.473590\n",
      "resetting env. episode 6758, reward total was -18.0. running mean: -18.038524214274787, timestamp: 2022-08-19 11:15:41.773662\n",
      "resetting env. episode 6759, reward total was -16.0. running mean: -18.01813897213204, timestamp: 2022-08-19 11:15:47.437726\n",
      "resetting env. episode 6760, reward total was -17.0. running mean: -18.00795758241072, timestamp: 2022-08-19 11:15:53.040784\n",
      "resetting env. episode 6761, reward total was -16.0. running mean: -17.987878006586616, timestamp: 2022-08-19 11:15:58.422844\n",
      "resetting env. episode 6762, reward total was -19.0. running mean: -17.99799922652075, timestamp: 2022-08-19 11:16:03.616903\n",
      "resetting env. episode 6763, reward total was -19.0. running mean: -18.008019234255546, timestamp: 2022-08-19 11:16:09.491971\n",
      "resetting env. episode 6764, reward total was -16.0. running mean: -17.98793904191299, timestamp: 2022-08-19 11:16:14.977029\n",
      "resetting env. episode 6765, reward total was -17.0. running mean: -17.97805965149386, timestamp: 2022-08-19 11:16:20.947098\n",
      "resetting env. episode 6766, reward total was -19.0. running mean: -17.988279054978925, timestamp: 2022-08-19 11:16:25.581151\n",
      "resetting env. episode 6767, reward total was -21.0. running mean: -18.018396264429136, timestamp: 2022-08-19 11:16:30.949207\n",
      "resetting env. episode 6768, reward total was -19.0. running mean: -18.028212301784844, timestamp: 2022-08-19 11:16:36.760278\n",
      "resetting env. episode 6769, reward total was -13.0. running mean: -17.977930178766993, timestamp: 2022-08-19 11:16:43.282343\n",
      "resetting env. episode 6770, reward total was -19.0. running mean: -17.988150876979326, timestamp: 2022-08-19 11:16:47.241386\n",
      "resetting env. episode 6771, reward total was -15.0. running mean: -17.958269368209532, timestamp: 2022-08-19 11:16:53.000452\n",
      "resetting env. episode 6772, reward total was -20.0. running mean: -17.978686674527435, timestamp: 2022-08-19 11:16:57.265499\n",
      "resetting env. episode 6773, reward total was -19.0. running mean: -17.98889980778216, timestamp: 2022-08-19 11:17:02.943563\n",
      "resetting env. episode 6774, reward total was -15.0. running mean: -17.95901080970434, timestamp: 2022-08-19 11:17:10.165644\n",
      "resetting env. episode 6775, reward total was -17.0. running mean: -17.949420701607295, timestamp: 2022-08-19 11:17:16.029710\n",
      "resetting env. episode 6776, reward total was -16.0. running mean: -17.92992649459122, timestamp: 2022-08-19 11:17:22.227778\n",
      "resetting env. episode 6777, reward total was -21.0. running mean: -17.96062722964531, timestamp: 2022-08-19 11:17:27.326839\n",
      "resetting env. episode 6778, reward total was -17.0. running mean: -17.95102095734886, timestamp: 2022-08-19 11:17:32.505896\n",
      "resetting env. episode 6779, reward total was -19.0. running mean: -17.96151074777537, timestamp: 2022-08-19 11:17:37.563959\n",
      "resetting env. episode 6780, reward total was -14.0. running mean: -17.921895640297617, timestamp: 2022-08-19 11:17:43.764025\n",
      "resetting env. episode 6781, reward total was -20.0. running mean: -17.94267668389464, timestamp: 2022-08-19 11:17:49.269087\n",
      "resetting env. episode 6782, reward total was -16.0. running mean: -17.923249917055692, timestamp: 2022-08-19 11:17:55.435162\n",
      "resetting env. episode 6783, reward total was -17.0. running mean: -17.914017417885137, timestamp: 2022-08-19 11:18:01.170223\n",
      "resetting env. episode 6784, reward total was -19.0. running mean: -17.924877243706288, timestamp: 2022-08-19 11:18:07.166295\n",
      "resetting env. episode 6785, reward total was -19.0. running mean: -17.935628471269226, timestamp: 2022-08-19 11:18:13.749368\n",
      "resetting env. episode 6786, reward total was -19.0. running mean: -17.946272186556534, timestamp: 2022-08-19 11:18:18.575423\n",
      "resetting env. episode 6787, reward total was -16.0. running mean: -17.92680946469097, timestamp: 2022-08-19 11:18:23.464479\n",
      "resetting env. episode 6788, reward total was -18.0. running mean: -17.927541370044057, timestamp: 2022-08-19 11:18:27.926535\n",
      "resetting env. episode 6789, reward total was -16.0. running mean: -17.908265956343616, timestamp: 2022-08-19 11:18:32.756587\n",
      "resetting env. episode 6790, reward total was -17.0. running mean: -17.89918329678018, timestamp: 2022-08-19 11:18:38.538654\n",
      "resetting env. episode 6791, reward total was -17.0. running mean: -17.89019146381238, timestamp: 2022-08-19 11:18:43.306712\n",
      "resetting env. episode 6792, reward total was -20.0. running mean: -17.911289549174253, timestamp: 2022-08-19 11:18:48.713773\n",
      "resetting env. episode 6793, reward total was -11.0. running mean: -17.84217665368251, timestamp: 2022-08-19 11:18:55.783856\n",
      "resetting env. episode 6794, reward total was -19.0. running mean: -17.853754887145687, timestamp: 2022-08-19 11:19:00.470907\n",
      "resetting env. episode 6795, reward total was -19.0. running mean: -17.86521733827423, timestamp: 2022-08-19 11:19:05.931973\n",
      "resetting env. episode 6796, reward total was -18.0. running mean: -17.866565164891487, timestamp: 2022-08-19 11:19:10.777029\n",
      "resetting env. episode 6797, reward total was -18.0. running mean: -17.86789951324257, timestamp: 2022-08-19 11:19:15.791088\n",
      "resetting env. episode 6798, reward total was -19.0. running mean: -17.879220518110145, timestamp: 2022-08-19 11:19:21.013147\n",
      "resetting env. episode 6799, reward total was -19.0. running mean: -17.890428312929046, timestamp: 2022-08-19 11:19:26.262209\n",
      "resetting env. episode 6800, reward total was -18.0. running mean: -17.891524029799754, timestamp: 2022-08-19 11:19:31.614272\n",
      "resetting env. episode 6801, reward total was -16.0. running mean: -17.872608789501758, timestamp: 2022-08-19 11:19:36.816335\n",
      "resetting env. episode 6802, reward total was -18.0. running mean: -17.87388270160674, timestamp: 2022-08-19 11:19:43.522413\n",
      "resetting env. episode 6803, reward total was -18.0. running mean: -17.87514387459067, timestamp: 2022-08-19 11:19:50.178489\n",
      "resetting env. episode 6804, reward total was -18.0. running mean: -17.876392435844764, timestamp: 2022-08-19 11:19:55.883557\n",
      "resetting env. episode 6805, reward total was -16.0. running mean: -17.857628511486315, timestamp: 2022-08-19 11:20:01.373625\n",
      "resetting env. episode 6806, reward total was -21.0. running mean: -17.88905222637145, timestamp: 2022-08-19 11:20:06.141680\n",
      "resetting env. episode 6807, reward total was -19.0. running mean: -17.900161704107738, timestamp: 2022-08-19 11:20:11.142737\n",
      "resetting env. episode 6808, reward total was -15.0. running mean: -17.87116008706666, timestamp: 2022-08-19 11:20:17.502816\n",
      "resetting env. episode 6809, reward total was -16.0. running mean: -17.852448486195993, timestamp: 2022-08-19 11:20:23.461887\n",
      "resetting env. episode 6810, reward total was -16.0. running mean: -17.833924001334033, timestamp: 2022-08-19 11:20:29.401952\n",
      "resetting env. episode 6811, reward total was -19.0. running mean: -17.845584761320694, timestamp: 2022-08-19 11:20:34.720019\n",
      "resetting env. episode 6812, reward total was -18.0. running mean: -17.847128913707486, timestamp: 2022-08-19 11:20:40.342081\n",
      "resetting env. episode 6813, reward total was -16.0. running mean: -17.82865762457041, timestamp: 2022-08-19 11:20:46.108150\n",
      "resetting env. episode 6814, reward total was -17.0. running mean: -17.82037104832471, timestamp: 2022-08-19 11:20:52.137221\n",
      "resetting env. episode 6815, reward total was -14.0. running mean: -17.78216733784146, timestamp: 2022-08-19 11:21:00.543320\n",
      "resetting env. episode 6816, reward total was -19.0. running mean: -17.794345664463048, timestamp: 2022-08-19 11:21:05.219374\n",
      "resetting env. episode 6817, reward total was -20.0. running mean: -17.816402207818417, timestamp: 2022-08-19 11:21:09.677428\n",
      "resetting env. episode 6818, reward total was -16.0. running mean: -17.79823818574023, timestamp: 2022-08-19 11:21:15.051494\n",
      "resetting env. episode 6819, reward total was -21.0. running mean: -17.83025580388283, timestamp: 2022-08-19 11:21:19.709547\n",
      "resetting env. episode 6820, reward total was -17.0. running mean: -17.821953245844004, timestamp: 2022-08-19 11:21:24.834606\n",
      "resetting env. episode 6821, reward total was -20.0. running mean: -17.843733713385564, timestamp: 2022-08-19 11:21:30.387674\n",
      "resetting env. episode 6822, reward total was -16.0. running mean: -17.825296376251707, timestamp: 2022-08-19 11:21:35.846738\n",
      "resetting env. episode 6823, reward total was -17.0. running mean: -17.81704341248919, timestamp: 2022-08-19 11:21:41.013798\n",
      "resetting env. episode 6824, reward total was -17.0. running mean: -17.808872978364302, timestamp: 2022-08-19 11:21:47.425877\n",
      "resetting env. episode 6825, reward total was -15.0. running mean: -17.78078424858066, timestamp: 2022-08-19 11:21:54.342960\n",
      "resetting env. episode 6826, reward total was -16.0. running mean: -17.762976406094854, timestamp: 2022-08-19 11:22:00.946038\n",
      "resetting env. episode 6827, reward total was -19.0. running mean: -17.775346642033906, timestamp: 2022-08-19 11:22:04.938083\n",
      "resetting env. episode 6828, reward total was -16.0. running mean: -17.757593175613568, timestamp: 2022-08-19 11:22:11.217159\n",
      "resetting env. episode 6829, reward total was -15.0. running mean: -17.730017243857432, timestamp: 2022-08-19 11:22:17.056228\n",
      "resetting env. episode 6830, reward total was -18.0. running mean: -17.732717071418858, timestamp: 2022-08-19 11:22:22.159853\n",
      "resetting env. episode 6831, reward total was -17.0. running mean: -17.72538990070467, timestamp: 2022-08-19 11:22:28.134926\n",
      "resetting env. episode 6832, reward total was -15.0. running mean: -17.698136001697623, timestamp: 2022-08-19 11:22:33.425988\n",
      "resetting env. episode 6833, reward total was -13.0. running mean: -17.651154641680645, timestamp: 2022-08-19 11:22:40.047067\n",
      "resetting env. episode 6834, reward total was -16.0. running mean: -17.634643095263836, timestamp: 2022-08-19 11:22:45.677133\n",
      "resetting env. episode 6835, reward total was -20.0. running mean: -17.658296664311198, timestamp: 2022-08-19 11:22:50.414192\n",
      "resetting env. episode 6836, reward total was -16.0. running mean: -17.641713697668084, timestamp: 2022-08-19 11:22:55.608250\n",
      "resetting env. episode 6837, reward total was -18.0. running mean: -17.645296560691403, timestamp: 2022-08-19 11:23:01.183318\n",
      "resetting env. episode 6838, reward total was -17.0. running mean: -17.63884359508449, timestamp: 2022-08-19 11:23:06.584383\n",
      "resetting env. episode 6839, reward total was -15.0. running mean: -17.612455159133646, timestamp: 2022-08-19 11:23:12.414457\n",
      "resetting env. episode 6840, reward total was -15.0. running mean: -17.58633060754231, timestamp: 2022-08-19 11:23:19.702538\n",
      "resetting env. episode 6841, reward total was -19.0. running mean: -17.600467301466885, timestamp: 2022-08-19 11:23:24.509595\n",
      "resetting env. episode 6842, reward total was -16.0. running mean: -17.584462628452215, timestamp: 2022-08-19 11:23:29.276657\n",
      "resetting env. episode 6843, reward total was -18.0. running mean: -17.588618002167692, timestamp: 2022-08-19 11:23:34.428715\n",
      "resetting env. episode 6844, reward total was -19.0. running mean: -17.602731822146016, timestamp: 2022-08-19 11:23:41.078796\n",
      "resetting env. episode 6845, reward total was -15.0. running mean: -17.576704503924553, timestamp: 2022-08-19 11:23:46.285859\n",
      "resetting env. episode 6846, reward total was -20.0. running mean: -17.600937458885305, timestamp: 2022-08-19 11:23:51.355915\n",
      "resetting env. episode 6847, reward total was -13.0. running mean: -17.55492808429645, timestamp: 2022-08-19 11:23:57.695995\n",
      "resetting env. episode 6848, reward total was -14.0. running mean: -17.519378803453485, timestamp: 2022-08-19 11:24:03.902063\n",
      "resetting env. episode 6849, reward total was -17.0. running mean: -17.514185015418953, timestamp: 2022-08-19 11:24:10.262137\n",
      "resetting env. episode 6850, reward total was -16.0. running mean: -17.499043165264762, timestamp: 2022-08-19 11:24:15.408884\n",
      "resetting env. episode 6851, reward total was -19.0. running mean: -17.514052733612115, timestamp: 2022-08-19 11:24:20.397946\n",
      "resetting env. episode 6852, reward total was -19.0. running mean: -17.528912206275994, timestamp: 2022-08-19 11:24:25.963013\n",
      "resetting env. episode 6853, reward total was -17.0. running mean: -17.523623084213234, timestamp: 2022-08-19 11:24:31.985081\n",
      "resetting env. episode 6854, reward total was -19.0. running mean: -17.538386853371104, timestamp: 2022-08-19 11:24:36.901143\n",
      "resetting env. episode 6855, reward total was -20.0. running mean: -17.563002984837393, timestamp: 2022-08-19 11:24:43.214212\n",
      "resetting env. episode 6856, reward total was -19.0. running mean: -17.57737295498902, timestamp: 2022-08-19 11:24:48.014273\n",
      "resetting env. episode 6857, reward total was -18.0. running mean: -17.581599225439128, timestamp: 2022-08-19 11:24:53.726341\n",
      "resetting env. episode 6858, reward total was -16.0. running mean: -17.565783233184735, timestamp: 2022-08-19 11:24:59.655407\n",
      "resetting env. episode 6859, reward total was -15.0. running mean: -17.540125400852887, timestamp: 2022-08-19 11:25:06.646489\n",
      "resetting env. episode 6860, reward total was -19.0. running mean: -17.554724146844357, timestamp: 2022-08-19 11:25:12.873563\n",
      "resetting env. episode 6861, reward total was -18.0. running mean: -17.559176905375914, timestamp: 2022-08-19 11:25:17.544618\n",
      "resetting env. episode 6862, reward total was -15.0. running mean: -17.533585136322152, timestamp: 2022-08-19 11:25:24.791704\n",
      "resetting env. episode 6863, reward total was -20.0. running mean: -17.55824928495893, timestamp: 2022-08-19 11:25:29.452758\n",
      "resetting env. episode 6864, reward total was -17.0. running mean: -17.552666792109342, timestamp: 2022-08-19 11:25:34.823822\n",
      "resetting env. episode 6865, reward total was -18.0. running mean: -17.557140124188248, timestamp: 2022-08-19 11:25:40.433891\n",
      "resetting env. episode 6866, reward total was -18.0. running mean: -17.561568722946365, timestamp: 2022-08-19 11:25:45.117945\n",
      "resetting env. episode 6867, reward total was -13.0. running mean: -17.5159530357169, timestamp: 2022-08-19 11:25:51.371017\n",
      "resetting env. episode 6868, reward total was -17.0. running mean: -17.510793505359732, timestamp: 2022-08-19 11:25:57.273088\n",
      "resetting env. episode 6869, reward total was -18.0. running mean: -17.515685570306136, timestamp: 2022-08-19 11:26:02.517149\n",
      "resetting env. episode 6870, reward total was -18.0. running mean: -17.520528714603074, timestamp: 2022-08-19 11:26:08.680220\n",
      "resetting env. episode 6871, reward total was -16.0. running mean: -17.505323427457043, timestamp: 2022-08-19 11:26:13.167273\n",
      "resetting env. episode 6872, reward total was -18.0. running mean: -17.51027019318247, timestamp: 2022-08-19 11:26:18.300335\n",
      "resetting env. episode 6873, reward total was -21.0. running mean: -17.54516749125065, timestamp: 2022-08-19 11:26:23.395391\n",
      "resetting env. episode 6874, reward total was -17.0. running mean: -17.539715816338145, timestamp: 2022-08-19 11:26:28.599456\n",
      "resetting env. episode 6875, reward total was -18.0. running mean: -17.544318658174763, timestamp: 2022-08-19 11:26:33.703514\n",
      "resetting env. episode 6876, reward total was -16.0. running mean: -17.528875471593015, timestamp: 2022-08-19 11:26:38.661576\n",
      "resetting env. episode 6877, reward total was -19.0. running mean: -17.543586716877087, timestamp: 2022-08-19 11:26:43.291629\n",
      "resetting env. episode 6878, reward total was -18.0. running mean: -17.548150849708314, timestamp: 2022-08-19 11:26:48.516687\n",
      "resetting env. episode 6879, reward total was -21.0. running mean: -17.582669341211233, timestamp: 2022-08-19 11:26:53.594746\n",
      "resetting env. episode 6880, reward total was -17.0. running mean: -17.576842647799122, timestamp: 2022-08-19 11:26:59.521815\n",
      "resetting env. episode 6881, reward total was -16.0. running mean: -17.56107422132113, timestamp: 2022-08-19 11:27:05.294883\n",
      "resetting env. episode 6882, reward total was -17.0. running mean: -17.55546347910792, timestamp: 2022-08-19 11:27:11.696958\n",
      "resetting env. episode 6883, reward total was -17.0. running mean: -17.549908844316843, timestamp: 2022-08-19 11:27:17.264024\n",
      "resetting env. episode 6884, reward total was -19.0. running mean: -17.564409755873676, timestamp: 2022-08-19 11:27:23.029091\n",
      "resetting env. episode 6885, reward total was -17.0. running mean: -17.55876565831494, timestamp: 2022-08-19 11:27:30.119172\n",
      "resetting env. episode 6886, reward total was -14.0. running mean: -17.52317800173179, timestamp: 2022-08-19 11:27:35.723239\n",
      "resetting env. episode 6887, reward total was -17.0. running mean: -17.517946221714475, timestamp: 2022-08-19 11:27:42.326315\n",
      "resetting env. episode 6888, reward total was -16.0. running mean: -17.50276675949733, timestamp: 2022-08-19 11:27:48.116383\n",
      "resetting env. episode 6889, reward total was -19.0. running mean: -17.517739091902357, timestamp: 2022-08-19 11:27:52.834437\n",
      "resetting env. episode 6890, reward total was -18.0. running mean: -17.52256170098333, timestamp: 2022-08-19 11:27:58.165499\n",
      "resetting env. episode 6891, reward total was -17.0. running mean: -17.5173360839735, timestamp: 2022-08-19 11:28:03.376562\n",
      "resetting env. episode 6892, reward total was -18.0. running mean: -17.522162723133764, timestamp: 2022-08-19 11:28:07.704614\n",
      "resetting env. episode 6893, reward total was -16.0. running mean: -17.506941095902427, timestamp: 2022-08-19 11:28:14.925694\n",
      "resetting env. episode 6894, reward total was -20.0. running mean: -17.5318716849434, timestamp: 2022-08-19 11:28:19.532749\n",
      "resetting env. episode 6895, reward total was -16.0. running mean: -17.516552968093965, timestamp: 2022-08-19 11:28:25.813820\n",
      "resetting env. episode 6896, reward total was -20.0. running mean: -17.541387438413025, timestamp: 2022-08-19 11:28:30.814881\n",
      "resetting env. episode 6897, reward total was -19.0. running mean: -17.555973564028896, timestamp: 2022-08-19 11:28:36.923948\n",
      "resetting env. episode 6898, reward total was -17.0. running mean: -17.55041382838861, timestamp: 2022-08-19 11:28:43.034022\n",
      "resetting env. episode 6899, reward total was -19.0. running mean: -17.564909690104724, timestamp: 2022-08-19 11:28:49.016088\n",
      "resetting env. episode 6900, reward total was -19.0. running mean: -17.579260593203678, timestamp: 2022-08-19 11:28:54.956155\n",
      "resetting env. episode 6901, reward total was -17.0. running mean: -17.57346798727164, timestamp: 2022-08-19 11:29:00.144215\n",
      "resetting env. episode 6902, reward total was -21.0. running mean: -17.607733307398927, timestamp: 2022-08-19 11:29:05.917287\n",
      "resetting env. episode 6903, reward total was -14.0. running mean: -17.571655974324937, timestamp: 2022-08-19 11:29:12.736365\n",
      "resetting env. episode 6904, reward total was -16.0. running mean: -17.555939414581687, timestamp: 2022-08-19 11:29:18.091423\n",
      "resetting env. episode 6905, reward total was -16.0. running mean: -17.54038002043587, timestamp: 2022-08-19 11:29:24.291493\n",
      "resetting env. episode 6906, reward total was -17.0. running mean: -17.534976220231513, timestamp: 2022-08-19 11:29:28.860550\n",
      "resetting env. episode 6907, reward total was -19.0. running mean: -17.5496264580292, timestamp: 2022-08-19 11:29:34.301610\n",
      "resetting env. episode 6908, reward total was -20.0. running mean: -17.574130193448905, timestamp: 2022-08-19 11:29:38.904664\n",
      "resetting env. episode 6909, reward total was -16.0. running mean: -17.558388891514415, timestamp: 2022-08-19 11:29:43.208711\n",
      "resetting env. episode 6910, reward total was -17.0. running mean: -17.55280500259927, timestamp: 2022-08-19 11:29:49.234779\n",
      "resetting env. episode 6911, reward total was -17.0. running mean: -17.54727695257328, timestamp: 2022-08-19 11:29:55.162848\n",
      "resetting env. episode 6912, reward total was -17.0. running mean: -17.54180418304755, timestamp: 2022-08-19 11:30:00.278912\n",
      "resetting env. episode 6913, reward total was -15.0. running mean: -17.516386141217072, timestamp: 2022-08-19 11:30:05.241961\n",
      "resetting env. episode 6914, reward total was -18.0. running mean: -17.521222279804903, timestamp: 2022-08-19 11:30:10.583022\n",
      "resetting env. episode 6915, reward total was -20.0. running mean: -17.546010057006853, timestamp: 2022-08-19 11:30:15.308596\n",
      "resetting env. episode 6916, reward total was -20.0. running mean: -17.570549956436786, timestamp: 2022-08-19 11:30:20.289652\n",
      "resetting env. episode 6917, reward total was -17.0. running mean: -17.564844456872418, timestamp: 2022-08-19 11:30:25.220712\n",
      "resetting env. episode 6918, reward total was -19.0. running mean: -17.579196012303694, timestamp: 2022-08-19 11:30:30.223765\n",
      "resetting env. episode 6919, reward total was -12.0. running mean: -17.52340405218066, timestamp: 2022-08-19 11:30:36.858844\n",
      "resetting env. episode 6920, reward total was -17.0. running mean: -17.518170011658853, timestamp: 2022-08-19 11:30:42.186902\n",
      "resetting env. episode 6921, reward total was -18.0. running mean: -17.522988311542264, timestamp: 2022-08-19 11:30:48.153972\n",
      "resetting env. episode 6922, reward total was -20.0. running mean: -17.54775842842684, timestamp: 2022-08-19 11:30:52.689020\n",
      "resetting env. episode 6923, reward total was -15.0. running mean: -17.522280844142568, timestamp: 2022-08-19 11:30:58.266085\n",
      "resetting env. episode 6924, reward total was -19.0. running mean: -17.537058035701143, timestamp: 2022-08-19 11:31:03.296665\n",
      "resetting env. episode 6925, reward total was -15.0. running mean: -17.51168745534413, timestamp: 2022-08-19 11:31:10.661746\n",
      "resetting env. episode 6926, reward total was -20.0. running mean: -17.536570580790688, timestamp: 2022-08-19 11:31:15.323801\n",
      "resetting env. episode 6927, reward total was -15.0. running mean: -17.51120487498278, timestamp: 2022-08-19 11:31:21.425875\n",
      "resetting env. episode 6928, reward total was -16.0. running mean: -17.496092826232953, timestamp: 2022-08-19 11:31:28.149943\n",
      "resetting env. episode 6929, reward total was -21.0. running mean: -17.531131897970624, timestamp: 2022-08-19 11:31:32.775001\n",
      "resetting env. episode 6930, reward total was -15.0. running mean: -17.505820578990917, timestamp: 2022-08-19 11:31:39.009065\n",
      "resetting env. episode 6931, reward total was -13.0. running mean: -17.460762373201007, timestamp: 2022-08-19 11:31:44.944132\n",
      "resetting env. episode 6932, reward total was -18.0. running mean: -17.466154749468995, timestamp: 2022-08-19 11:31:49.032181\n",
      "resetting env. episode 6933, reward total was -13.0. running mean: -17.421493201974304, timestamp: 2022-08-19 11:31:55.778256\n",
      "resetting env. episode 6934, reward total was -19.0. running mean: -17.43727826995456, timestamp: 2022-08-19 11:32:01.211318\n",
      "resetting env. episode 6935, reward total was -16.0. running mean: -17.422905487255015, timestamp: 2022-08-19 11:32:06.876380\n",
      "resetting env. episode 6936, reward total was -21.0. running mean: -17.458676432382465, timestamp: 2022-08-19 11:32:12.959452\n",
      "resetting env. episode 6937, reward total was -19.0. running mean: -17.474089668058642, timestamp: 2022-08-19 11:32:16.663491\n",
      "resetting env. episode 6938, reward total was -20.0. running mean: -17.499348771378056, timestamp: 2022-08-19 11:32:22.051555\n",
      "resetting env. episode 6939, reward total was -18.0. running mean: -17.504355283664275, timestamp: 2022-08-19 11:32:26.976604\n",
      "resetting env. episode 6940, reward total was -17.0. running mean: -17.499311730827632, timestamp: 2022-08-19 11:32:33.386677\n",
      "resetting env. episode 6941, reward total was -17.0. running mean: -17.494318613519358, timestamp: 2022-08-19 11:32:38.927741\n",
      "resetting env. episode 6942, reward total was -15.0. running mean: -17.46937542738416, timestamp: 2022-08-19 11:32:45.245810\n",
      "resetting env. episode 6943, reward total was -17.0. running mean: -17.46468167311032, timestamp: 2022-08-19 11:32:51.147876\n",
      "resetting env. episode 6944, reward total was -15.0. running mean: -17.440034856379214, timestamp: 2022-08-19 11:32:57.481946\n",
      "resetting env. episode 6945, reward total was -19.0. running mean: -17.45563450781542, timestamp: 2022-08-19 11:33:02.854007\n",
      "resetting env. episode 6946, reward total was -16.0. running mean: -17.441078162737266, timestamp: 2022-08-19 11:33:08.945077\n",
      "resetting env. episode 6947, reward total was -19.0. running mean: -17.456667381109895, timestamp: 2022-08-19 11:33:13.753129\n",
      "resetting env. episode 6948, reward total was -15.0. running mean: -17.432100707298794, timestamp: 2022-08-19 11:33:18.997188\n",
      "resetting env. episode 6949, reward total was -15.0. running mean: -17.407779700225806, timestamp: 2022-08-19 11:33:24.884252\n",
      "resetting env. episode 6950, reward total was -19.0. running mean: -17.42370190322355, timestamp: 2022-08-19 11:33:29.716305\n",
      "resetting env. episode 6951, reward total was -12.0. running mean: -17.369464884191313, timestamp: 2022-08-19 11:33:35.769379\n",
      "resetting env. episode 6952, reward total was -13.0. running mean: -17.3257702353494, timestamp: 2022-08-19 11:33:43.141455\n",
      "resetting env. episode 6953, reward total was -21.0. running mean: -17.362512532995904, timestamp: 2022-08-19 11:33:48.492515\n",
      "resetting env. episode 6954, reward total was -19.0. running mean: -17.378887407665946, timestamp: 2022-08-19 11:33:53.961580\n",
      "resetting env. episode 6955, reward total was -17.0. running mean: -17.375098533589288, timestamp: 2022-08-19 11:33:59.678640\n",
      "resetting env. episode 6956, reward total was -14.0. running mean: -17.341347548253395, timestamp: 2022-08-19 11:34:05.680708\n",
      "resetting env. episode 6957, reward total was -20.0. running mean: -17.36793407277086, timestamp: 2022-08-19 11:34:11.324770\n",
      "resetting env. episode 6958, reward total was -18.0. running mean: -17.374254732043152, timestamp: 2022-08-19 11:34:17.033833\n",
      "resetting env. episode 6959, reward total was -17.0. running mean: -17.37051218472272, timestamp: 2022-08-19 11:34:22.302893\n",
      "resetting env. episode 6960, reward total was -18.0. running mean: -17.376807062875493, timestamp: 2022-08-19 11:34:27.547954\n",
      "resetting env. episode 6961, reward total was -19.0. running mean: -17.39303899224674, timestamp: 2022-08-19 11:34:34.289028\n",
      "resetting env. episode 6962, reward total was -17.0. running mean: -17.389108602324274, timestamp: 2022-08-19 11:34:38.758078\n",
      "resetting env. episode 6963, reward total was -18.0. running mean: -17.39521751630103, timestamp: 2022-08-19 11:34:44.447142\n",
      "resetting env. episode 6964, reward total was -17.0. running mean: -17.391265341138023, timestamp: 2022-08-19 11:34:49.856205\n",
      "resetting env. episode 6965, reward total was -17.0. running mean: -17.387352687726644, timestamp: 2022-08-19 11:34:55.928273\n",
      "resetting env. episode 6966, reward total was -17.0. running mean: -17.38347916084938, timestamp: 2022-08-19 11:35:02.305346\n",
      "resetting env. episode 6967, reward total was -19.0. running mean: -17.399644369240885, timestamp: 2022-08-19 11:35:08.140415\n",
      "resetting env. episode 6968, reward total was -20.0. running mean: -17.425647925548475, timestamp: 2022-08-19 11:35:13.409475\n",
      "resetting env. episode 6969, reward total was -18.0. running mean: -17.431391446292988, timestamp: 2022-08-19 11:35:19.060536\n",
      "resetting env. episode 6970, reward total was -18.0. running mean: -17.437077531830056, timestamp: 2022-08-19 11:35:24.442598\n",
      "resetting env. episode 6971, reward total was -19.0. running mean: -17.452706756511756, timestamp: 2022-08-19 11:35:30.727670\n",
      "resetting env. episode 6972, reward total was -19.0. running mean: -17.468179688946638, timestamp: 2022-08-19 11:35:36.666740\n",
      "resetting env. episode 6973, reward total was -19.0. running mean: -17.483497892057173, timestamp: 2022-08-19 11:35:42.679809\n",
      "resetting env. episode 6974, reward total was -18.0. running mean: -17.4886629131366, timestamp: 2022-08-19 11:35:48.460877\n",
      "resetting env. episode 6975, reward total was -19.0. running mean: -17.503776284005237, timestamp: 2022-08-19 11:35:54.014939\n",
      "resetting env. episode 6976, reward total was -11.0. running mean: -17.438738521165185, timestamp: 2022-08-19 11:36:00.572015\n",
      "resetting env. episode 6977, reward total was -17.0. running mean: -17.434351135953534, timestamp: 2022-08-19 11:36:05.707078\n",
      "resetting env. episode 6978, reward total was -16.0. running mean: -17.420007624594, timestamp: 2022-08-19 11:36:12.802159\n",
      "resetting env. episode 6979, reward total was -17.0. running mean: -17.41580754834806, timestamp: 2022-08-19 11:36:18.554225\n",
      "resetting env. episode 6980, reward total was -20.0. running mean: -17.44164947286458, timestamp: 2022-08-19 11:36:23.175277\n",
      "resetting env. episode 6981, reward total was -13.0. running mean: -17.397232978135932, timestamp: 2022-08-19 11:36:29.460351\n",
      "resetting env. episode 6982, reward total was -17.0. running mean: -17.393260648354573, timestamp: 2022-08-19 11:36:34.629411\n",
      "resetting env. episode 6983, reward total was -17.0. running mean: -17.38932804187103, timestamp: 2022-08-19 11:36:40.091474\n",
      "resetting env. episode 6984, reward total was -15.0. running mean: -17.365434761452317, timestamp: 2022-08-19 11:36:45.966542\n",
      "resetting env. episode 6985, reward total was -17.0. running mean: -17.361780413837796, timestamp: 2022-08-19 11:36:51.518610\n",
      "resetting env. episode 6986, reward total was -19.0. running mean: -17.37816260969942, timestamp: 2022-08-19 11:36:57.088676\n",
      "resetting env. episode 6987, reward total was -20.0. running mean: -17.404380983602426, timestamp: 2022-08-19 11:37:01.366724\n",
      "resetting env. episode 6988, reward total was -20.0. running mean: -17.4303371737664, timestamp: 2022-08-19 11:37:06.551782\n",
      "resetting env. episode 6989, reward total was -19.0. running mean: -17.446033802028737, timestamp: 2022-08-19 11:37:11.308841\n",
      "resetting env. episode 6990, reward total was -17.0. running mean: -17.44157346400845, timestamp: 2022-08-19 11:37:16.820903\n",
      "resetting env. episode 6991, reward total was -19.0. running mean: -17.457157729368365, timestamp: 2022-08-19 11:37:21.093954\n",
      "resetting env. episode 6992, reward total was -17.0. running mean: -17.452586152074684, timestamp: 2022-08-19 11:37:26.710020\n",
      "resetting env. episode 6993, reward total was -21.0. running mean: -17.48806029055394, timestamp: 2022-08-19 11:37:31.629076\n",
      "resetting env. episode 6994, reward total was -15.0. running mean: -17.4631796876484, timestamp: 2022-08-19 11:37:38.337156\n",
      "resetting env. episode 6995, reward total was -17.0. running mean: -17.458547890771918, timestamp: 2022-08-19 11:37:43.656220\n",
      "resetting env. episode 6996, reward total was -20.0. running mean: -17.483962411864198, timestamp: 2022-08-19 11:37:49.513288\n",
      "resetting env. episode 6997, reward total was -21.0. running mean: -17.519122787745555, timestamp: 2022-08-19 11:37:54.580348\n",
      "resetting env. episode 6998, reward total was -19.0. running mean: -17.5339315598681, timestamp: 2022-08-19 11:37:59.863410\n",
      "resetting env. episode 6999, reward total was -20.0. running mean: -17.55859224426942, timestamp: 2022-08-19 11:38:04.463466\n",
      "resetting env. episode 7000, reward total was -19.0. running mean: -17.57300632182673, timestamp: 2022-08-19 11:38:10.236532\n",
      "resetting env. episode 7001, reward total was -18.0. running mean: -17.57727625860846, timestamp: 2022-08-19 11:38:15.881597\n",
      "resetting env. episode 7002, reward total was -17.0. running mean: -17.571503496022377, timestamp: 2022-08-19 11:38:20.313651\n",
      "resetting env. episode 7003, reward total was -19.0. running mean: -17.585788461062155, timestamp: 2022-08-19 11:38:26.054717\n",
      "resetting env. episode 7004, reward total was -16.0. running mean: -17.569930576451533, timestamp: 2022-08-19 11:38:31.809787\n",
      "resetting env. episode 7005, reward total was -15.0. running mean: -17.544231270687018, timestamp: 2022-08-19 11:38:38.044863\n",
      "resetting env. episode 7006, reward total was -19.0. running mean: -17.55878895798015, timestamp: 2022-08-19 11:38:43.320923\n",
      "resetting env. episode 7007, reward total was -10.0. running mean: -17.483201068400348, timestamp: 2022-08-19 11:38:49.297995\n",
      "resetting env. episode 7008, reward total was -15.0. running mean: -17.458369057716343, timestamp: 2022-08-19 11:38:54.671055\n",
      "resetting env. episode 7009, reward total was -20.0. running mean: -17.48378536713918, timestamp: 2022-08-19 11:39:00.234122\n",
      "resetting env. episode 7010, reward total was -19.0. running mean: -17.49894751346779, timestamp: 2022-08-19 11:39:05.176180\n",
      "resetting env. episode 7011, reward total was -19.0. running mean: -17.513958038333115, timestamp: 2022-08-19 11:39:10.108237\n",
      "resetting env. episode 7012, reward total was -15.0. running mean: -17.488818457949783, timestamp: 2022-08-19 11:39:15.019298\n",
      "resetting env. episode 7013, reward total was -15.0. running mean: -17.463930273370284, timestamp: 2022-08-19 11:39:20.760364\n",
      "resetting env. episode 7014, reward total was -16.0. running mean: -17.449290970636582, timestamp: 2022-08-19 11:39:26.096435\n",
      "resetting env. episode 7015, reward total was -17.0. running mean: -17.444798060930218, timestamp: 2022-08-19 11:39:31.921496\n",
      "resetting env. episode 7016, reward total was -18.0. running mean: -17.450350080320916, timestamp: 2022-08-19 11:39:37.514560\n",
      "resetting env. episode 7017, reward total was -19.0. running mean: -17.46584657951771, timestamp: 2022-08-19 11:39:42.777145\n",
      "resetting env. episode 7018, reward total was -19.0. running mean: -17.481188113722535, timestamp: 2022-08-19 11:39:48.133207\n",
      "resetting env. episode 7019, reward total was -17.0. running mean: -17.47637623258531, timestamp: 2022-08-19 11:39:53.577275\n",
      "resetting env. episode 7020, reward total was -16.0. running mean: -17.461612470259457, timestamp: 2022-08-19 11:39:58.231326\n",
      "resetting env. episode 7021, reward total was -19.0. running mean: -17.476996345556863, timestamp: 2022-08-19 11:40:04.012396\n",
      "resetting env. episode 7022, reward total was -19.0. running mean: -17.492226382101297, timestamp: 2022-08-19 11:40:08.718449\n",
      "resetting env. episode 7023, reward total was -17.0. running mean: -17.487304118280285, timestamp: 2022-08-19 11:40:15.810536\n",
      "resetting env. episode 7024, reward total was -18.0. running mean: -17.492431077097482, timestamp: 2022-08-19 11:40:21.047597\n",
      "resetting env. episode 7025, reward total was -21.0. running mean: -17.527506766326507, timestamp: 2022-08-19 11:40:26.579663\n",
      "resetting env. episode 7026, reward total was -14.0. running mean: -17.492231698663243, timestamp: 2022-08-19 11:40:32.780737\n",
      "resetting env. episode 7027, reward total was -16.0. running mean: -17.477309381676612, timestamp: 2022-08-19 11:40:37.188786\n",
      "resetting env. episode 7028, reward total was -19.0. running mean: -17.492536287859846, timestamp: 2022-08-19 11:40:42.683853\n",
      "resetting env. episode 7029, reward total was -14.0. running mean: -17.457610924981246, timestamp: 2022-08-19 11:40:48.709922\n",
      "resetting env. episode 7030, reward total was -19.0. running mean: -17.473034815731435, timestamp: 2022-08-19 11:40:53.799982\n",
      "resetting env. episode 7031, reward total was -11.0. running mean: -17.40830446757412, timestamp: 2022-08-19 11:41:00.845066\n",
      "resetting env. episode 7032, reward total was -18.0. running mean: -17.41422142289838, timestamp: 2022-08-19 11:41:06.118131\n",
      "resetting env. episode 7033, reward total was -15.0. running mean: -17.390079208669395, timestamp: 2022-08-19 11:41:11.944196\n",
      "resetting env. episode 7034, reward total was -14.0. running mean: -17.3561784165827, timestamp: 2022-08-19 11:41:17.638268\n",
      "resetting env. episode 7035, reward total was -11.0. running mean: -17.292616632416873, timestamp: 2022-08-19 11:41:23.820338\n",
      "resetting env. episode 7036, reward total was -17.0. running mean: -17.289690466092708, timestamp: 2022-08-19 11:41:29.448404\n",
      "resetting env. episode 7037, reward total was -17.0. running mean: -17.286793561431782, timestamp: 2022-08-19 11:41:33.966454\n",
      "resetting env. episode 7038, reward total was -17.0. running mean: -17.283925625817467, timestamp: 2022-08-19 11:41:38.596512\n",
      "resetting env. episode 7039, reward total was -21.0. running mean: -17.321086369559293, timestamp: 2022-08-19 11:41:43.735570\n",
      "resetting env. episode 7040, reward total was -15.0. running mean: -17.297875505863697, timestamp: 2022-08-19 11:41:49.760639\n",
      "resetting env. episode 7041, reward total was -16.0. running mean: -17.28489675080506, timestamp: 2022-08-19 11:41:55.344709\n",
      "resetting env. episode 7042, reward total was -19.0. running mean: -17.30204778329701, timestamp: 2022-08-19 11:42:00.136762\n",
      "resetting env. episode 7043, reward total was -16.0. running mean: -17.28902730546404, timestamp: 2022-08-19 11:42:05.895833\n",
      "resetting env. episode 7044, reward total was -21.0. running mean: -17.3261370324094, timestamp: 2022-08-19 11:42:10.727889\n",
      "resetting env. episode 7045, reward total was -19.0. running mean: -17.342875662085305, timestamp: 2022-08-19 11:42:15.700944\n",
      "resetting env. episode 7046, reward total was -17.0. running mean: -17.339446905464452, timestamp: 2022-08-19 11:42:21.873018\n",
      "resetting env. episode 7047, reward total was -18.0. running mean: -17.346052436409806, timestamp: 2022-08-19 11:42:27.460083\n",
      "resetting env. episode 7048, reward total was -18.0. running mean: -17.352591912045707, timestamp: 2022-08-19 11:42:33.615154\n",
      "resetting env. episode 7049, reward total was -19.0. running mean: -17.36906599292525, timestamp: 2022-08-19 11:42:39.229219\n",
      "resetting env. episode 7050, reward total was -17.0. running mean: -17.365375332996, timestamp: 2022-08-19 11:42:45.106287\n",
      "resetting env. episode 7051, reward total was -19.0. running mean: -17.38172157966604, timestamp: 2022-08-19 11:42:50.967359\n",
      "resetting env. episode 7052, reward total was -17.0. running mean: -17.37790436386938, timestamp: 2022-08-19 11:42:55.874416\n",
      "resetting env. episode 7053, reward total was -18.0. running mean: -17.384125320230687, timestamp: 2022-08-19 11:43:01.958486\n",
      "resetting env. episode 7054, reward total was -16.0. running mean: -17.37028406702838, timestamp: 2022-08-19 11:43:09.046569\n",
      "resetting env. episode 7055, reward total was -21.0. running mean: -17.406581226358096, timestamp: 2022-08-19 11:43:14.132631\n",
      "resetting env. episode 7056, reward total was -15.0. running mean: -17.382515414094513, timestamp: 2022-08-19 11:43:19.911694\n",
      "resetting env. episode 7057, reward total was -13.0. running mean: -17.338690259953566, timestamp: 2022-08-19 11:43:28.431793\n",
      "resetting env. episode 7058, reward total was -16.0. running mean: -17.32530335735403, timestamp: 2022-08-19 11:43:33.919861\n",
      "resetting env. episode 7059, reward total was -17.0. running mean: -17.32205032378049, timestamp: 2022-08-19 11:43:39.305922\n",
      "resetting env. episode 7060, reward total was -16.0. running mean: -17.308829820542687, timestamp: 2022-08-19 11:43:45.707996\n",
      "resetting env. episode 7061, reward total was -19.0. running mean: -17.32574152233726, timestamp: 2022-08-19 11:43:51.302063\n",
      "resetting env. episode 7062, reward total was -19.0. running mean: -17.34248410711389, timestamp: 2022-08-19 11:43:56.783126\n",
      "resetting env. episode 7063, reward total was -19.0. running mean: -17.359059266042753, timestamp: 2022-08-19 11:44:02.915194\n",
      "resetting env. episode 7064, reward total was -19.0. running mean: -17.375468673382326, timestamp: 2022-08-19 11:44:08.528259\n",
      "resetting env. episode 7065, reward total was -20.0. running mean: -17.401713986648502, timestamp: 2022-08-19 11:44:13.789323\n",
      "resetting env. episode 7066, reward total was -18.0. running mean: -17.407696846782017, timestamp: 2022-08-19 11:44:18.952378\n",
      "resetting env. episode 7067, reward total was -16.0. running mean: -17.393619878314198, timestamp: 2022-08-19 11:44:25.436457\n",
      "resetting env. episode 7068, reward total was -16.0. running mean: -17.379683679531055, timestamp: 2022-08-19 11:44:32.085533\n",
      "resetting env. episode 7069, reward total was -18.0. running mean: -17.385886842735744, timestamp: 2022-08-19 11:44:37.108591\n",
      "resetting env. episode 7070, reward total was -14.0. running mean: -17.35202797430839, timestamp: 2022-08-19 11:44:43.103659\n",
      "resetting env. episode 7071, reward total was -19.0. running mean: -17.368507694565306, timestamp: 2022-08-19 11:44:48.459726\n",
      "resetting env. episode 7072, reward total was -19.0. running mean: -17.384822617619655, timestamp: 2022-08-19 11:44:53.774784\n",
      "resetting env. episode 7073, reward total was -18.0. running mean: -17.390974391443457, timestamp: 2022-08-19 11:44:57.915829\n",
      "resetting env. episode 7074, reward total was -14.0. running mean: -17.357064647529022, timestamp: 2022-08-19 11:45:03.909900\n",
      "resetting env. episode 7075, reward total was -21.0. running mean: -17.393494001053732, timestamp: 2022-08-19 11:45:11.377988\n",
      "resetting env. episode 7076, reward total was -12.0. running mean: -17.339559061043197, timestamp: 2022-08-19 11:45:18.299592\n",
      "resetting env. episode 7077, reward total was -19.0. running mean: -17.356163470432765, timestamp: 2022-08-19 11:45:23.871657\n",
      "resetting env. episode 7078, reward total was -20.0. running mean: -17.382601835728437, timestamp: 2022-08-19 11:45:29.893251\n",
      "resetting env. episode 7079, reward total was -15.0. running mean: -17.35877581737115, timestamp: 2022-08-19 11:45:36.694856\n",
      "resetting env. episode 7080, reward total was -19.0. running mean: -17.37518805919744, timestamp: 2022-08-19 11:45:43.090455\n",
      "resetting env. episode 7081, reward total was -16.0. running mean: -17.361436178605466, timestamp: 2022-08-19 11:45:49.851581\n",
      "resetting env. episode 7082, reward total was -16.0. running mean: -17.347821816819412, timestamp: 2022-08-19 11:45:56.081652\n",
      "resetting env. episode 7083, reward total was -15.0. running mean: -17.324343598651215, timestamp: 2022-08-19 11:46:01.987720\n",
      "resetting env. episode 7084, reward total was -17.0. running mean: -17.321100162664703, timestamp: 2022-08-19 11:46:08.655796\n",
      "resetting env. episode 7085, reward total was -15.0. running mean: -17.297889161038054, timestamp: 2022-08-19 11:46:15.906878\n",
      "resetting env. episode 7086, reward total was -19.0. running mean: -17.314910269427674, timestamp: 2022-08-19 11:46:21.191941\n",
      "resetting env. episode 7087, reward total was -21.0. running mean: -17.351761166733397, timestamp: 2022-08-19 11:46:25.938991\n",
      "resetting env. episode 7088, reward total was -19.0. running mean: -17.368243555066062, timestamp: 2022-08-19 11:46:30.312045\n",
      "resetting env. episode 7089, reward total was -17.0. running mean: -17.364561119515404, timestamp: 2022-08-19 11:46:35.963106\n",
      "resetting env. episode 7090, reward total was -17.0. running mean: -17.36091550832025, timestamp: 2022-08-19 11:46:41.873173\n",
      "resetting env. episode 7091, reward total was -15.0. running mean: -17.337306353237047, timestamp: 2022-08-19 11:46:48.482252\n",
      "resetting env. episode 7092, reward total was -20.0. running mean: -17.363933289704676, timestamp: 2022-08-19 11:46:54.634320\n",
      "resetting env. episode 7093, reward total was -18.0. running mean: -17.37029395680763, timestamp: 2022-08-19 11:47:00.753390\n",
      "resetting env. episode 7094, reward total was -18.0. running mean: -17.37659101723955, timestamp: 2022-08-19 11:47:06.134453\n",
      "resetting env. episode 7095, reward total was -18.0. running mean: -17.382825107067156, timestamp: 2022-08-19 11:47:11.642512\n",
      "resetting env. episode 7096, reward total was -18.0. running mean: -17.388996855996485, timestamp: 2022-08-19 11:47:17.120575\n",
      "resetting env. episode 7097, reward total was -17.0. running mean: -17.38510688743652, timestamp: 2022-08-19 11:47:23.035641\n",
      "resetting env. episode 7098, reward total was -12.0. running mean: -17.331255818562155, timestamp: 2022-08-19 11:47:29.382714\n",
      "resetting env. episode 7099, reward total was -15.0. running mean: -17.307943260376533, timestamp: 2022-08-19 11:47:35.454782\n",
      "resetting env. episode 7100, reward total was -16.0. running mean: -17.29486382777277, timestamp: 2022-08-19 11:47:42.510861\n",
      "resetting env. episode 7101, reward total was -21.0. running mean: -17.331915189495042, timestamp: 2022-08-19 11:47:47.479921\n",
      "resetting env. episode 7102, reward total was -20.0. running mean: -17.35859603760009, timestamp: 2022-08-19 11:47:52.112971\n",
      "resetting env. episode 7103, reward total was -17.0. running mean: -17.35501007722409, timestamp: 2022-08-19 11:47:56.849025\n",
      "resetting env. episode 7104, reward total was -18.0. running mean: -17.361459976451847, timestamp: 2022-08-19 11:48:01.713078\n",
      "resetting env. episode 7105, reward total was -13.0. running mean: -17.317845376687327, timestamp: 2022-08-19 11:48:08.307154\n",
      "resetting env. episode 7106, reward total was -15.0. running mean: -17.294666922920452, timestamp: 2022-08-19 11:48:14.859226\n",
      "resetting env. episode 7107, reward total was -16.0. running mean: -17.281720253691248, timestamp: 2022-08-19 11:48:20.769298\n",
      "resetting env. episode 7108, reward total was -17.0. running mean: -17.278903051154337, timestamp: 2022-08-19 11:48:27.855373\n",
      "resetting env. episode 7109, reward total was -12.0. running mean: -17.226114020642793, timestamp: 2022-08-19 11:48:34.430446\n",
      "resetting env. episode 7110, reward total was -20.0. running mean: -17.253852880436366, timestamp: 2022-08-19 11:48:40.247510\n",
      "resetting env. episode 7111, reward total was -19.0. running mean: -17.271314351632004, timestamp: 2022-08-19 11:48:45.376567\n",
      "resetting env. episode 7112, reward total was -20.0. running mean: -17.298601208115684, timestamp: 2022-08-19 11:48:51.220636\n",
      "resetting env. episode 7113, reward total was -15.0. running mean: -17.275615196034526, timestamp: 2022-08-19 11:48:57.419703\n",
      "resetting env. episode 7114, reward total was -19.0. running mean: -17.29285904407418, timestamp: 2022-08-19 11:49:03.096766\n",
      "resetting env. episode 7115, reward total was -17.0. running mean: -17.289930453633442, timestamp: 2022-08-19 11:49:09.219844\n",
      "resetting env. episode 7116, reward total was -19.0. running mean: -17.30703114909711, timestamp: 2022-08-19 11:49:14.795897\n",
      "resetting env. episode 7117, reward total was -13.0. running mean: -17.263960837606138, timestamp: 2022-08-19 11:49:21.556976\n",
      "resetting env. episode 7118, reward total was -19.0. running mean: -17.281321229230077, timestamp: 2022-08-19 11:49:26.078021\n",
      "resetting env. episode 7119, reward total was -16.0. running mean: -17.268508016937776, timestamp: 2022-08-19 11:49:30.830078\n",
      "resetting env. episode 7120, reward total was -15.0. running mean: -17.2458229367684, timestamp: 2022-08-19 11:49:37.142146\n",
      "resetting env. episode 7121, reward total was -20.0. running mean: -17.273364707400713, timestamp: 2022-08-19 11:49:42.514205\n",
      "resetting env. episode 7122, reward total was -15.0. running mean: -17.250631060326704, timestamp: 2022-08-19 11:49:47.695266\n",
      "resetting env. episode 7123, reward total was -16.0. running mean: -17.238124749723436, timestamp: 2022-08-19 11:49:54.372336\n",
      "resetting env. episode 7124, reward total was -20.0. running mean: -17.2657435022262, timestamp: 2022-08-19 11:49:59.418392\n",
      "resetting env. episode 7125, reward total was -17.0. running mean: -17.26308606720394, timestamp: 2022-08-19 11:50:05.118987\n",
      "resetting env. episode 7126, reward total was -15.0. running mean: -17.240455206531898, timestamp: 2022-08-19 11:50:10.987050\n",
      "resetting env. episode 7127, reward total was -19.0. running mean: -17.25805065446658, timestamp: 2022-08-19 11:50:17.084639\n",
      "resetting env. episode 7128, reward total was -20.0. running mean: -17.285470147921913, timestamp: 2022-08-19 11:50:22.918703\n",
      "resetting env. episode 7129, reward total was -14.0. running mean: -17.252615446442693, timestamp: 2022-08-19 11:50:29.813780\n",
      "resetting env. episode 7130, reward total was -18.0. running mean: -17.260089291978264, timestamp: 2022-08-19 11:50:35.129837\n",
      "resetting env. episode 7131, reward total was -15.0. running mean: -17.23748839905848, timestamp: 2022-08-19 11:50:41.432909\n",
      "resetting env. episode 7132, reward total was -18.0. running mean: -17.245113515067896, timestamp: 2022-08-19 11:50:47.462976\n",
      "resetting env. episode 7133, reward total was -16.0. running mean: -17.232662379917215, timestamp: 2022-08-19 11:50:52.124024\n",
      "resetting env. episode 7134, reward total was -19.0. running mean: -17.250335756118044, timestamp: 2022-08-19 11:50:57.074079\n",
      "resetting env. episode 7135, reward total was -21.0. running mean: -17.287832398556866, timestamp: 2022-08-19 11:51:01.826131\n",
      "resetting env. episode 7136, reward total was -15.0. running mean: -17.264954074571296, timestamp: 2022-08-19 11:51:08.587207\n",
      "resetting env. episode 7137, reward total was -17.0. running mean: -17.262304533825585, timestamp: 2022-08-19 11:51:14.206267\n",
      "resetting env. episode 7138, reward total was -17.0. running mean: -17.25968148848733, timestamp: 2022-08-19 11:51:19.811331\n",
      "resetting env. episode 7139, reward total was -19.0. running mean: -17.27708467360246, timestamp: 2022-08-19 11:51:25.492395\n",
      "resetting env. episode 7140, reward total was -18.0. running mean: -17.284313826866434, timestamp: 2022-08-19 11:51:30.452452\n",
      "resetting env. episode 7141, reward total was -21.0. running mean: -17.32147068859777, timestamp: 2022-08-19 11:51:35.459507\n",
      "resetting env. episode 7142, reward total was -21.0. running mean: -17.358255981711793, timestamp: 2022-08-19 11:51:40.197563\n",
      "resetting env. episode 7143, reward total was -17.0. running mean: -17.354673421894677, timestamp: 2022-08-19 11:51:45.874625\n",
      "resetting env. episode 7144, reward total was -19.0. running mean: -17.371126687675734, timestamp: 2022-08-19 11:51:51.511689\n",
      "resetting env. episode 7145, reward total was -19.0. running mean: -17.387415420798977, timestamp: 2022-08-19 11:51:56.383744\n",
      "resetting env. episode 7146, reward total was -19.0. running mean: -17.403541266590988, timestamp: 2022-08-19 11:52:01.116800\n",
      "resetting env. episode 7147, reward total was -17.0. running mean: -17.39950585392508, timestamp: 2022-08-19 11:52:06.209858\n",
      "resetting env. episode 7148, reward total was -13.0. running mean: -17.35551079538583, timestamp: 2022-08-19 11:52:12.745929\n",
      "resetting env. episode 7149, reward total was -18.0. running mean: -17.36195568743197, timestamp: 2022-08-19 11:52:19.144004\n",
      "resetting env. episode 7150, reward total was -15.0. running mean: -17.338336130557646, timestamp: 2022-08-19 11:52:25.218073\n",
      "resetting env. episode 7151, reward total was -16.0. running mean: -17.32495276925207, timestamp: 2022-08-19 11:52:31.015138\n",
      "resetting env. episode 7152, reward total was -18.0. running mean: -17.331703241559552, timestamp: 2022-08-19 11:52:36.713203\n",
      "resetting env. episode 7153, reward total was -16.0. running mean: -17.318386209143956, timestamp: 2022-08-19 11:52:42.381268\n",
      "resetting env. episode 7154, reward total was -17.0. running mean: -17.31520234705252, timestamp: 2022-08-19 11:52:47.467327\n",
      "resetting env. episode 7155, reward total was -18.0. running mean: -17.322050323581994, timestamp: 2022-08-19 11:52:51.684375\n",
      "resetting env. episode 7156, reward total was -21.0. running mean: -17.358829820346173, timestamp: 2022-08-19 11:52:56.686432\n",
      "resetting env. episode 7157, reward total was -18.0. running mean: -17.36524152214271, timestamp: 2022-08-19 11:53:01.829493\n",
      "resetting env. episode 7158, reward total was -17.0. running mean: -17.361589106921286, timestamp: 2022-08-19 11:53:08.185564\n",
      "resetting env. episode 7159, reward total was -16.0. running mean: -17.347973215852072, timestamp: 2022-08-19 11:53:16.259656\n",
      "resetting env. episode 7160, reward total was -17.0. running mean: -17.34449348369355, timestamp: 2022-08-19 11:53:22.105252\n",
      "resetting env. episode 7161, reward total was -21.0. running mean: -17.381048548856615, timestamp: 2022-08-19 11:53:28.414455\n",
      "resetting env. episode 7162, reward total was -18.0. running mean: -17.38723806336805, timestamp: 2022-08-19 11:53:34.758222\n",
      "resetting env. episode 7163, reward total was -19.0. running mean: -17.403365682734368, timestamp: 2022-08-19 11:53:42.586437\n",
      "resetting env. episode 7164, reward total was -21.0. running mean: -17.439332025907024, timestamp: 2022-08-19 11:53:47.602165\n",
      "resetting env. episode 7165, reward total was -16.0. running mean: -17.424938705647953, timestamp: 2022-08-19 11:53:53.265330\n",
      "resetting env. episode 7166, reward total was -15.0. running mean: -17.40068931859147, timestamp: 2022-08-19 11:53:58.943398\n",
      "resetting env. episode 7167, reward total was -18.0. running mean: -17.406682425405556, timestamp: 2022-08-19 11:54:03.437448\n",
      "resetting env. episode 7168, reward total was -18.0. running mean: -17.4126156011515, timestamp: 2022-08-19 11:54:08.240507\n",
      "resetting env. episode 7169, reward total was -17.0. running mean: -17.40848944513999, timestamp: 2022-08-19 11:54:13.503569\n",
      "resetting env. episode 7170, reward total was -17.0. running mean: -17.40440455068859, timestamp: 2022-08-19 11:54:19.383633\n",
      "resetting env. episode 7171, reward total was -17.0. running mean: -17.400360505181705, timestamp: 2022-08-19 11:54:24.224692\n",
      "resetting env. episode 7172, reward total was -20.0. running mean: -17.42635690012989, timestamp: 2022-08-19 11:54:30.002760\n",
      "resetting env. episode 7173, reward total was -19.0. running mean: -17.442093331128593, timestamp: 2022-08-19 11:54:33.921803\n",
      "resetting env. episode 7174, reward total was -17.0. running mean: -17.43767239781731, timestamp: 2022-08-19 11:54:39.893874\n",
      "resetting env. episode 7175, reward total was -17.0. running mean: -17.433295673839137, timestamp: 2022-08-19 11:54:45.856945\n",
      "resetting env. episode 7176, reward total was -18.0. running mean: -17.438962717100743, timestamp: 2022-08-19 11:54:51.375013\n",
      "resetting env. episode 7177, reward total was -14.0. running mean: -17.404573089929738, timestamp: 2022-08-19 11:54:57.278131\n",
      "resetting env. episode 7178, reward total was -19.0. running mean: -17.42052735903044, timestamp: 2022-08-19 11:55:02.315189\n",
      "resetting env. episode 7179, reward total was -16.0. running mean: -17.406322085440138, timestamp: 2022-08-19 11:55:07.867253\n",
      "resetting env. episode 7180, reward total was -18.0. running mean: -17.412258864585738, timestamp: 2022-08-19 11:55:14.279329\n",
      "resetting env. episode 7181, reward total was -16.0. running mean: -17.39813627593988, timestamp: 2022-08-19 11:55:20.169398\n",
      "resetting env. episode 7182, reward total was -17.0. running mean: -17.394154913180483, timestamp: 2022-08-19 11:55:27.660487\n",
      "resetting env. episode 7183, reward total was -17.0. running mean: -17.39021336404868, timestamp: 2022-08-19 11:55:32.408545\n",
      "resetting env. episode 7184, reward total was -18.0. running mean: -17.396311230408195, timestamp: 2022-08-19 11:55:38.151613\n",
      "resetting env. episode 7185, reward total was -12.0. running mean: -17.342348118104113, timestamp: 2022-08-19 11:55:45.226693\n",
      "resetting env. episode 7186, reward total was -20.0. running mean: -17.368924636923072, timestamp: 2022-08-19 11:55:49.401746\n",
      "resetting env. episode 7187, reward total was -19.0. running mean: -17.38523539055384, timestamp: 2022-08-19 11:55:53.482792\n",
      "resetting env. episode 7188, reward total was -14.0. running mean: -17.351383036648304, timestamp: 2022-08-19 11:55:58.762854\n",
      "resetting env. episode 7189, reward total was -15.0. running mean: -17.327869206281818, timestamp: 2022-08-19 11:56:04.930926\n",
      "resetting env. episode 7190, reward total was -20.0. running mean: -17.354590514218998, timestamp: 2022-08-19 11:56:09.490979\n",
      "resetting env. episode 7191, reward total was -17.0. running mean: -17.35104460907681, timestamp: 2022-08-19 11:56:15.410053\n",
      "resetting env. episode 7192, reward total was -10.0. running mean: -17.27753416298604, timestamp: 2022-08-19 11:56:22.436133\n",
      "resetting env. episode 7193, reward total was -15.0. running mean: -17.254758821356177, timestamp: 2022-08-19 11:56:28.251201\n",
      "resetting env. episode 7194, reward total was -17.0. running mean: -17.252211233142617, timestamp: 2022-08-19 11:56:34.873280\n",
      "resetting env. episode 7195, reward total was -15.0. running mean: -17.22968912081119, timestamp: 2022-08-19 11:56:41.961364\n",
      "resetting env. episode 7196, reward total was -16.0. running mean: -17.217392229603078, timestamp: 2022-08-19 11:56:48.316439\n",
      "resetting env. episode 7197, reward total was -19.0. running mean: -17.235218307307047, timestamp: 2022-08-19 11:56:54.186510\n",
      "resetting env. episode 7198, reward total was -20.0. running mean: -17.262866124233977, timestamp: 2022-08-19 11:56:59.504572\n",
      "resetting env. episode 7199, reward total was -19.0. running mean: -17.28023746299164, timestamp: 2022-08-19 11:57:04.522155\n",
      "resetting env. episode 7200, reward total was -21.0. running mean: -17.317435088361723, timestamp: 2022-08-19 11:57:10.599226\n",
      "resetting env. episode 7201, reward total was -17.0. running mean: -17.314260737478108, timestamp: 2022-08-19 11:57:16.867831\n",
      "resetting env. episode 7202, reward total was -19.0. running mean: -17.331118130103327, timestamp: 2022-08-19 11:57:21.941892\n",
      "resetting env. episode 7203, reward total was -21.0. running mean: -17.367806948802293, timestamp: 2022-08-19 11:57:26.528951\n",
      "resetting env. episode 7204, reward total was -21.0. running mean: -17.40412887931427, timestamp: 2022-08-19 11:57:32.051011\n",
      "resetting env. episode 7205, reward total was -18.0. running mean: -17.41008759052113, timestamp: 2022-08-19 11:57:40.431110\n",
      "resetting env. episode 7206, reward total was -14.0. running mean: -17.37598671461592, timestamp: 2022-08-19 11:57:47.631195\n",
      "resetting env. episode 7207, reward total was -14.0. running mean: -17.34222684746976, timestamp: 2022-08-19 11:57:55.180807\n",
      "resetting env. episode 7208, reward total was -17.0. running mean: -17.338804578995063, timestamp: 2022-08-19 11:58:01.184877\n",
      "resetting env. episode 7209, reward total was -19.0. running mean: -17.355416533205112, timestamp: 2022-08-19 11:58:06.545942\n",
      "resetting env. episode 7210, reward total was -18.0. running mean: -17.361862367873062, timestamp: 2022-08-19 11:58:12.489010\n",
      "resetting env. episode 7211, reward total was -18.0. running mean: -17.36824374419433, timestamp: 2022-08-19 11:58:17.165068\n",
      "resetting env. episode 7212, reward total was -18.0. running mean: -17.374561306752387, timestamp: 2022-08-19 11:58:21.403117\n",
      "resetting env. episode 7213, reward total was -19.0. running mean: -17.390815693684864, timestamp: 2022-08-19 11:58:26.720181\n",
      "resetting env. episode 7214, reward total was -19.0. running mean: -17.406907536748015, timestamp: 2022-08-19 11:58:31.729238\n",
      "resetting env. episode 7215, reward total was -19.0. running mean: -17.422838461380536, timestamp: 2022-08-19 11:58:37.740312\n",
      "resetting env. episode 7216, reward total was -17.0. running mean: -17.418610076766733, timestamp: 2022-08-19 11:58:43.115374\n",
      "resetting env. episode 7217, reward total was -17.0. running mean: -17.414423975999068, timestamp: 2022-08-19 11:58:47.146420\n",
      "resetting env. episode 7218, reward total was -16.0. running mean: -17.400279736239078, timestamp: 2022-08-19 11:58:53.547495\n",
      "resetting env. episode 7219, reward total was -16.0. running mean: -17.386276938876687, timestamp: 2022-08-19 11:59:00.545099\n",
      "resetting env. episode 7220, reward total was -18.0. running mean: -17.39241416948792, timestamp: 2022-08-19 11:59:06.760171\n",
      "resetting env. episode 7221, reward total was -19.0. running mean: -17.408490027793043, timestamp: 2022-08-19 11:59:12.174236\n",
      "resetting env. episode 7222, reward total was -21.0. running mean: -17.444405127515115, timestamp: 2022-08-19 11:59:17.900302\n",
      "resetting env. episode 7223, reward total was -21.0. running mean: -17.479961076239963, timestamp: 2022-08-19 11:59:22.963366\n",
      "resetting env. episode 7224, reward total was -21.0. running mean: -17.515161465477565, timestamp: 2022-08-19 11:59:27.890419\n",
      "resetting env. episode 7225, reward total was -17.0. running mean: -17.51000985082279, timestamp: 2022-08-19 11:59:32.906481\n",
      "resetting env. episode 7226, reward total was -19.0. running mean: -17.524909752314564, timestamp: 2022-08-19 11:59:37.397534\n",
      "resetting env. episode 7227, reward total was -18.0. running mean: -17.529660654791417, timestamp: 2022-08-19 11:59:43.059601\n",
      "resetting env. episode 7228, reward total was -15.0. running mean: -17.504364048243502, timestamp: 2022-08-19 11:59:48.376660\n",
      "resetting env. episode 7229, reward total was -12.0. running mean: -17.449320407761068, timestamp: 2022-08-19 11:59:55.650744\n",
      "resetting env. episode 7230, reward total was -20.0. running mean: -17.474827203683457, timestamp: 2022-08-19 12:00:02.117819\n",
      "resetting env. episode 7231, reward total was -17.0. running mean: -17.470078931646626, timestamp: 2022-08-19 12:00:07.552884\n",
      "resetting env. episode 7232, reward total was -19.0. running mean: -17.48537814233016, timestamp: 2022-08-19 12:00:14.032962\n",
      "resetting env. episode 7233, reward total was -21.0. running mean: -17.520524360906858, timestamp: 2022-08-19 12:00:20.810038\n",
      "resetting env. episode 7234, reward total was -20.0. running mean: -17.54531911729779, timestamp: 2022-08-19 12:00:25.212093\n",
      "resetting env. episode 7235, reward total was -16.0. running mean: -17.529865926124813, timestamp: 2022-08-19 12:00:30.144148\n",
      "resetting env. episode 7236, reward total was -17.0. running mean: -17.524567266863567, timestamp: 2022-08-19 12:00:35.818214\n",
      "resetting env. episode 7237, reward total was -17.0. running mean: -17.51932159419493, timestamp: 2022-08-19 12:00:41.792283\n",
      "resetting env. episode 7238, reward total was -13.0. running mean: -17.47412837825298, timestamp: 2022-08-19 12:00:48.572362\n",
      "resetting env. episode 7239, reward total was -15.0. running mean: -17.44938709447045, timestamp: 2022-08-19 12:00:55.113440\n",
      "resetting env. episode 7240, reward total was -19.0. running mean: -17.464893223525745, timestamp: 2022-08-19 12:01:01.075506\n",
      "resetting env. episode 7241, reward total was -17.0. running mean: -17.46024429129049, timestamp: 2022-08-19 12:01:08.067589\n",
      "resetting env. episode 7242, reward total was -19.0. running mean: -17.475641848377585, timestamp: 2022-08-19 12:01:13.209651\n",
      "resetting env. episode 7243, reward total was -17.0. running mean: -17.47088542989381, timestamp: 2022-08-19 12:01:18.380711\n",
      "resetting env. episode 7244, reward total was -18.0. running mean: -17.47617657559487, timestamp: 2022-08-19 12:01:24.628781\n",
      "resetting env. episode 7245, reward total was -16.0. running mean: -17.46141480983892, timestamp: 2022-08-19 12:01:29.659839\n",
      "resetting env. episode 7246, reward total was -17.0. running mean: -17.456800661740534, timestamp: 2022-08-19 12:01:35.533910\n",
      "resetting env. episode 7247, reward total was -18.0. running mean: -17.462232655123128, timestamp: 2022-08-19 12:01:41.472976\n",
      "resetting env. episode 7248, reward total was -19.0. running mean: -17.4776103285719, timestamp: 2022-08-19 12:01:46.975040\n",
      "resetting env. episode 7249, reward total was -16.0. running mean: -17.46283422528618, timestamp: 2022-08-19 12:01:53.562117\n",
      "resetting env. episode 7250, reward total was -15.0. running mean: -17.438205883033316, timestamp: 2022-08-19 12:01:59.737190\n",
      "resetting env. episode 7251, reward total was -17.0. running mean: -17.433823824202985, timestamp: 2022-08-19 12:02:05.931263\n",
      "resetting env. episode 7252, reward total was -17.0. running mean: -17.429485585960958, timestamp: 2022-08-19 12:02:11.110320\n",
      "resetting env. episode 7253, reward total was -13.0. running mean: -17.385190730101346, timestamp: 2022-08-19 12:02:17.116390\n",
      "resetting env. episode 7254, reward total was -16.0. running mean: -17.371338822800332, timestamp: 2022-08-19 12:02:23.000460\n",
      "resetting env. episode 7255, reward total was -19.0. running mean: -17.387625434572332, timestamp: 2022-08-19 12:02:27.179507\n",
      "resetting env. episode 7256, reward total was -17.0. running mean: -17.38374918022661, timestamp: 2022-08-19 12:02:33.183574\n",
      "resetting env. episode 7257, reward total was -15.0. running mean: -17.35991168842434, timestamp: 2022-08-19 12:02:39.086642\n",
      "resetting env. episode 7258, reward total was -18.0. running mean: -17.366312571540096, timestamp: 2022-08-19 12:02:45.232711\n",
      "resetting env. episode 7259, reward total was -17.0. running mean: -17.362649445824697, timestamp: 2022-08-19 12:02:50.567777\n",
      "resetting env. episode 7260, reward total was -19.0. running mean: -17.37902295136645, timestamp: 2022-08-19 12:02:56.965370\n",
      "resetting env. episode 7261, reward total was -14.0. running mean: -17.34523272185279, timestamp: 2022-08-19 12:03:04.531459\n",
      "resetting env. episode 7262, reward total was -15.0. running mean: -17.32178039463426, timestamp: 2022-08-19 12:03:11.698540\n",
      "resetting env. episode 7263, reward total was -17.0. running mean: -17.318562590687918, timestamp: 2022-08-19 12:03:16.650599\n",
      "resetting env. episode 7264, reward total was -14.0. running mean: -17.28537696478104, timestamp: 2022-08-19 12:03:21.585652\n",
      "resetting env. episode 7265, reward total was -17.0. running mean: -17.28252319513323, timestamp: 2022-08-19 12:03:27.428721\n",
      "resetting env. episode 7266, reward total was -15.0. running mean: -17.259697963181896, timestamp: 2022-08-19 12:03:33.888794\n",
      "resetting env. episode 7267, reward total was -18.0. running mean: -17.267100983550076, timestamp: 2022-08-19 12:03:39.515862\n",
      "resetting env. episode 7268, reward total was -14.0. running mean: -17.234429973714576, timestamp: 2022-08-19 12:03:45.655929\n",
      "resetting env. episode 7269, reward total was -16.0. running mean: -17.222085673977432, timestamp: 2022-08-19 12:03:52.257004\n",
      "resetting env. episode 7270, reward total was -18.0. running mean: -17.229864817237658, timestamp: 2022-08-19 12:03:58.994079\n",
      "resetting env. episode 7271, reward total was -17.0. running mean: -17.227566169065284, timestamp: 2022-08-19 12:04:05.612157\n",
      "resetting env. episode 7272, reward total was -14.0. running mean: -17.195290507374633, timestamp: 2022-08-19 12:04:12.493235\n",
      "resetting env. episode 7273, reward total was -15.0. running mean: -17.173337602300887, timestamp: 2022-08-19 12:04:18.679304\n",
      "resetting env. episode 7274, reward total was -19.0. running mean: -17.191604226277878, timestamp: 2022-08-19 12:04:23.150357\n",
      "resetting env. episode 7275, reward total was -17.0. running mean: -17.1896881840151, timestamp: 2022-08-19 12:04:29.819433\n",
      "resetting env. episode 7276, reward total was -17.0. running mean: -17.18779130217495, timestamp: 2022-08-19 12:04:35.429497\n",
      "resetting env. episode 7277, reward total was -19.0. running mean: -17.205913389153203, timestamp: 2022-08-19 12:04:41.065561\n",
      "resetting env. episode 7278, reward total was -15.0. running mean: -17.183854255261668, timestamp: 2022-08-19 12:04:47.288631\n",
      "resetting env. episode 7279, reward total was -20.0. running mean: -17.21201571270905, timestamp: 2022-08-19 12:04:52.526218\n",
      "resetting env. episode 7280, reward total was -19.0. running mean: -17.22989555558196, timestamp: 2022-08-19 12:04:57.831275\n",
      "resetting env. episode 7281, reward total was -19.0. running mean: -17.247596600026142, timestamp: 2022-08-19 12:05:04.525352\n",
      "resetting env. episode 7282, reward total was -19.0. running mean: -17.26512063402588, timestamp: 2022-08-19 12:05:10.736422\n",
      "resetting env. episode 7283, reward total was -17.0. running mean: -17.262469427685623, timestamp: 2022-08-19 12:05:15.476474\n",
      "resetting env. episode 7284, reward total was -13.0. running mean: -17.219844733408767, timestamp: 2022-08-19 12:05:22.489555\n",
      "resetting env. episode 7285, reward total was -17.0. running mean: -17.217646286074682, timestamp: 2022-08-19 12:05:29.485633\n",
      "resetting env. episode 7286, reward total was -21.0. running mean: -17.255469823213936, timestamp: 2022-08-19 12:05:35.546703\n",
      "resetting env. episode 7287, reward total was -19.0. running mean: -17.272915124981797, timestamp: 2022-08-19 12:05:41.371768\n",
      "resetting env. episode 7288, reward total was -19.0. running mean: -17.29018597373198, timestamp: 2022-08-19 12:05:47.641837\n",
      "resetting env. episode 7289, reward total was -18.0. running mean: -17.29728411399466, timestamp: 2022-08-19 12:05:52.910896\n",
      "resetting env. episode 7290, reward total was -21.0. running mean: -17.334311272854713, timestamp: 2022-08-19 12:05:58.133955\n",
      "resetting env. episode 7291, reward total was -19.0. running mean: -17.35096816012617, timestamp: 2022-08-19 12:06:03.218010\n",
      "resetting env. episode 7292, reward total was -16.0. running mean: -17.337458478524905, timestamp: 2022-08-19 12:06:10.990100\n",
      "resetting env. episode 7293, reward total was -18.0. running mean: -17.344083893739654, timestamp: 2022-08-19 12:06:18.726186\n",
      "resetting env. episode 7294, reward total was -16.0. running mean: -17.33064305480226, timestamp: 2022-08-19 12:06:24.170246\n",
      "resetting env. episode 7295, reward total was -14.0. running mean: -17.297336624254235, timestamp: 2022-08-19 12:06:30.593318\n",
      "resetting env. episode 7296, reward total was -21.0. running mean: -17.334363258011695, timestamp: 2022-08-19 12:06:35.862378\n",
      "resetting env. episode 7297, reward total was -15.0. running mean: -17.311019625431577, timestamp: 2022-08-19 12:06:41.878448\n",
      "resetting env. episode 7298, reward total was -16.0. running mean: -17.29790942917726, timestamp: 2022-08-19 12:06:49.089527\n",
      "resetting env. episode 7299, reward total was -18.0. running mean: -17.304930334885487, timestamp: 2022-08-19 12:06:54.765592\n",
      "resetting env. episode 7300, reward total was -13.0. running mean: -17.261881031536632, timestamp: 2022-08-19 12:07:01.400662\n",
      "resetting env. episode 7301, reward total was -19.0. running mean: -17.279262221221266, timestamp: 2022-08-19 12:07:07.206733\n",
      "resetting env. episode 7302, reward total was -21.0. running mean: -17.316469599009054, timestamp: 2022-08-19 12:07:13.094791\n",
      "resetting env. episode 7303, reward total was -15.0. running mean: -17.29330490301896, timestamp: 2022-08-19 12:07:19.733865\n",
      "resetting env. episode 7304, reward total was -15.0. running mean: -17.27037185398877, timestamp: 2022-08-19 12:07:26.945945\n",
      "resetting env. episode 7305, reward total was -17.0. running mean: -17.267668135448883, timestamp: 2022-08-19 12:07:31.472997\n",
      "resetting env. episode 7306, reward total was -17.0. running mean: -17.264991454094396, timestamp: 2022-08-19 12:07:37.991069\n",
      "resetting env. episode 7307, reward total was -18.0. running mean: -17.27234153955345, timestamp: 2022-08-19 12:07:44.955667\n",
      "resetting env. episode 7308, reward total was -20.0. running mean: -17.299618124157917, timestamp: 2022-08-19 12:07:49.958722\n",
      "resetting env. episode 7309, reward total was -18.0. running mean: -17.306621942916337, timestamp: 2022-08-19 12:07:55.184786\n",
      "resetting env. episode 7310, reward total was -15.0. running mean: -17.283555723487172, timestamp: 2022-08-19 12:08:01.910855\n",
      "resetting env. episode 7311, reward total was -20.0. running mean: -17.3107201662523, timestamp: 2022-08-19 12:08:07.815921\n",
      "resetting env. episode 7312, reward total was -16.0. running mean: -17.297612964589774, timestamp: 2022-08-19 12:08:15.058002\n",
      "resetting env. episode 7313, reward total was -13.0. running mean: -17.254636834943874, timestamp: 2022-08-19 12:08:22.833089\n",
      "resetting env. episode 7314, reward total was -19.0. running mean: -17.272090466594435, timestamp: 2022-08-19 12:08:28.626024\n",
      "resetting env. episode 7315, reward total was -14.0. running mean: -17.23936956192849, timestamp: 2022-08-19 12:08:33.568083\n",
      "resetting env. episode 7316, reward total was -19.0. running mean: -17.256975866309208, timestamp: 2022-08-19 12:08:39.759153\n",
      "resetting env. episode 7317, reward total was -16.0. running mean: -17.244406107646117, timestamp: 2022-08-19 12:08:45.319211\n",
      "resetting env. episode 7318, reward total was -17.0. running mean: -17.241962046569657, timestamp: 2022-08-19 12:08:51.686287\n",
      "resetting env. episode 7319, reward total was -16.0. running mean: -17.22954242610396, timestamp: 2022-08-19 12:08:58.850367\n",
      "resetting env. episode 7320, reward total was -17.0. running mean: -17.227247001842922, timestamp: 2022-08-19 12:09:04.948435\n",
      "resetting env. episode 7321, reward total was -17.0. running mean: -17.224974531824493, timestamp: 2022-08-19 12:09:10.827502\n",
      "resetting env. episode 7322, reward total was -19.0. running mean: -17.24272478650625, timestamp: 2022-08-19 12:09:18.178583\n",
      "resetting env. episode 7323, reward total was -17.0. running mean: -17.24029753864119, timestamp: 2022-08-19 12:09:23.227643\n",
      "resetting env. episode 7324, reward total was -17.0. running mean: -17.23789456325478, timestamp: 2022-08-19 12:09:29.532717\n",
      "resetting env. episode 7325, reward total was -18.0. running mean: -17.24551561762223, timestamp: 2022-08-19 12:09:35.329780\n",
      "resetting env. episode 7326, reward total was -17.0. running mean: -17.24306046144601, timestamp: 2022-08-19 12:09:40.755368\n",
      "resetting env. episode 7327, reward total was -17.0. running mean: -17.24062985683155, timestamp: 2022-08-19 12:09:46.913439\n",
      "resetting env. episode 7328, reward total was -21.0. running mean: -17.278223558263235, timestamp: 2022-08-19 12:09:52.696505\n",
      "resetting env. episode 7329, reward total was -18.0. running mean: -17.2854413226806, timestamp: 2022-08-19 12:09:58.496575\n",
      "resetting env. episode 7330, reward total was -13.0. running mean: -17.242586909453795, timestamp: 2022-08-19 12:10:05.602653\n",
      "resetting env. episode 7331, reward total was -20.0. running mean: -17.270161040359255, timestamp: 2022-08-19 12:10:10.892714\n",
      "resetting env. episode 7332, reward total was -19.0. running mean: -17.287459429955664, timestamp: 2022-08-19 12:10:15.310771\n",
      "resetting env. episode 7333, reward total was -19.0. running mean: -17.304584835656108, timestamp: 2022-08-19 12:10:21.410838\n",
      "resetting env. episode 7334, reward total was -14.0. running mean: -17.271538987299547, timestamp: 2022-08-19 12:10:29.884935\n",
      "resetting env. episode 7335, reward total was -19.0. running mean: -17.288823597426553, timestamp: 2022-08-19 12:10:35.835533\n",
      "resetting env. episode 7336, reward total was -19.0. running mean: -17.30593536145229, timestamp: 2022-08-19 12:10:41.610597\n",
      "resetting env. episode 7337, reward total was -19.0. running mean: -17.322876007837767, timestamp: 2022-08-19 12:10:48.174199\n",
      "resetting env. episode 7338, reward total was -18.0. running mean: -17.32964724775939, timestamp: 2022-08-19 12:10:54.163270\n",
      "resetting env. episode 7339, reward total was -17.0. running mean: -17.326350775281796, timestamp: 2022-08-19 12:10:59.115328\n",
      "resetting env. episode 7340, reward total was -17.0. running mean: -17.32308726752898, timestamp: 2022-08-19 12:11:04.151384\n",
      "resetting env. episode 7341, reward total was -19.0. running mean: -17.33985639485369, timestamp: 2022-08-19 12:11:10.174457\n",
      "resetting env. episode 7342, reward total was -18.0. running mean: -17.346457830905152, timestamp: 2022-08-19 12:11:16.106526\n",
      "resetting env. episode 7343, reward total was -16.0. running mean: -17.3329932525961, timestamp: 2022-08-19 12:11:22.202597\n",
      "resetting env. episode 7344, reward total was -19.0. running mean: -17.349663320070142, timestamp: 2022-08-19 12:11:28.446680\n",
      "resetting env. episode 7345, reward total was -17.0. running mean: -17.34616668686944, timestamp: 2022-08-19 12:11:33.887742\n",
      "resetting env. episode 7346, reward total was -18.0. running mean: -17.352705020000748, timestamp: 2022-08-19 12:11:38.804797\n",
      "resetting env. episode 7347, reward total was -19.0. running mean: -17.36917796980074, timestamp: 2022-08-19 12:11:44.506863\n",
      "resetting env. episode 7348, reward total was -17.0. running mean: -17.365486190102736, timestamp: 2022-08-19 12:11:51.193947\n",
      "resetting env. episode 7349, reward total was -17.0. running mean: -17.36183132820171, timestamp: 2022-08-19 12:11:57.135014\n",
      "resetting env. episode 7350, reward total was -20.0. running mean: -17.388213014919693, timestamp: 2022-08-19 12:12:03.128080\n",
      "resetting env. episode 7351, reward total was -19.0. running mean: -17.404330884770495, timestamp: 2022-08-19 12:12:09.257153\n",
      "resetting env. episode 7352, reward total was -11.0. running mean: -17.34028757592279, timestamp: 2022-08-19 12:12:16.221234\n",
      "resetting env. episode 7353, reward total was -16.0. running mean: -17.326884700163564, timestamp: 2022-08-19 12:12:23.192315\n",
      "resetting env. episode 7354, reward total was -15.0. running mean: -17.303615853161926, timestamp: 2022-08-19 12:12:30.058397\n",
      "resetting env. episode 7355, reward total was -17.0. running mean: -17.300579694630308, timestamp: 2022-08-19 12:12:36.558473\n",
      "resetting env. episode 7356, reward total was -18.0. running mean: -17.307573897684005, timestamp: 2022-08-19 12:12:43.533552\n",
      "resetting env. episode 7357, reward total was -17.0. running mean: -17.304498158707165, timestamp: 2022-08-19 12:12:49.821628\n",
      "resetting env. episode 7358, reward total was -18.0. running mean: -17.311453177120093, timestamp: 2022-08-19 12:12:56.309704\n",
      "resetting env. episode 7359, reward total was -17.0. running mean: -17.308338645348893, timestamp: 2022-08-19 12:13:02.633779\n",
      "resetting env. episode 7360, reward total was -16.0. running mean: -17.295255258895406, timestamp: 2022-08-19 12:13:09.070853\n",
      "resetting env. episode 7361, reward total was -14.0. running mean: -17.262302706306453, timestamp: 2022-08-19 12:13:14.683916\n",
      "resetting env. episode 7362, reward total was -21.0. running mean: -17.29967967924339, timestamp: 2022-08-19 12:13:20.467986\n",
      "resetting env. episode 7363, reward total was -16.0. running mean: -17.286682882450958, timestamp: 2022-08-19 12:13:25.807051\n",
      "resetting env. episode 7364, reward total was -14.0. running mean: -17.253816053626448, timestamp: 2022-08-19 12:13:32.186123\n",
      "resetting env. episode 7365, reward total was -19.0. running mean: -17.271277893090183, timestamp: 2022-08-19 12:13:37.733188\n",
      "resetting env. episode 7366, reward total was -21.0. running mean: -17.308565114159283, timestamp: 2022-08-19 12:13:44.203264\n",
      "resetting env. episode 7367, reward total was -19.0. running mean: -17.32547946301769, timestamp: 2022-08-19 12:13:50.626337\n",
      "resetting env. episode 7368, reward total was -17.0. running mean: -17.322224668387513, timestamp: 2022-08-19 12:13:58.610433\n",
      "resetting env. episode 7369, reward total was -17.0. running mean: -17.31900242170364, timestamp: 2022-08-19 12:14:05.302510\n",
      "resetting env. episode 7370, reward total was -17.0. running mean: -17.315812397486606, timestamp: 2022-08-19 12:14:13.050601\n",
      "resetting env. episode 7371, reward total was -16.0. running mean: -17.30265427351174, timestamp: 2022-08-19 12:14:20.052683\n",
      "resetting env. episode 7372, reward total was -16.0. running mean: -17.289627730776623, timestamp: 2022-08-19 12:14:27.196765\n",
      "resetting env. episode 7373, reward total was -21.0. running mean: -17.326731453468856, timestamp: 2022-08-19 12:14:31.746819\n",
      "resetting env. episode 7374, reward total was -16.0. running mean: -17.31346413893417, timestamp: 2022-08-19 12:14:38.518902\n",
      "resetting env. episode 7375, reward total was -16.0. running mean: -17.300329497544826, timestamp: 2022-08-19 12:14:45.688983\n",
      "resetting env. episode 7376, reward total was -17.0. running mean: -17.29732620256938, timestamp: 2022-08-19 12:14:51.903059\n",
      "resetting env. episode 7377, reward total was -17.0. running mean: -17.29435294054369, timestamp: 2022-08-19 12:14:58.095128\n",
      "resetting env. episode 7378, reward total was -17.0. running mean: -17.291409411138254, timestamp: 2022-08-19 12:15:03.967198\n",
      "resetting env. episode 7379, reward total was -14.0. running mean: -17.25849531702687, timestamp: 2022-08-19 12:15:10.464277\n",
      "resetting env. episode 7380, reward total was -19.0. running mean: -17.275910363856603, timestamp: 2022-08-19 12:15:16.211340\n",
      "resetting env. episode 7381, reward total was -13.0. running mean: -17.233151260218037, timestamp: 2022-08-19 12:15:23.850431\n",
      "resetting env. episode 7382, reward total was -16.0. running mean: -17.220819747615856, timestamp: 2022-08-19 12:15:31.517522\n",
      "resetting env. episode 7383, reward total was -19.0. running mean: -17.238611550139698, timestamp: 2022-08-19 12:15:38.040121\n",
      "resetting env. episode 7384, reward total was -13.0. running mean: -17.1962254346383, timestamp: 2022-08-19 12:15:46.411218\n",
      "resetting env. episode 7385, reward total was -15.0. running mean: -17.174263180291916, timestamp: 2022-08-19 12:15:53.417299\n",
      "resetting env. episode 7386, reward total was -13.0. running mean: -17.132520548488998, timestamp: 2022-08-19 12:16:00.079375\n",
      "resetting env. episode 7387, reward total was -18.0. running mean: -17.141195343004107, timestamp: 2022-08-19 12:16:05.649442\n",
      "resetting env. episode 7388, reward total was -19.0. running mean: -17.159783389574066, timestamp: 2022-08-19 12:16:12.628521\n",
      "resetting env. episode 7389, reward total was -18.0. running mean: -17.168185555678324, timestamp: 2022-08-19 12:16:18.500591\n",
      "resetting env. episode 7390, reward total was -17.0. running mean: -17.16650370012154, timestamp: 2022-08-19 12:16:25.807674\n",
      "resetting env. episode 7391, reward total was -18.0. running mean: -17.174838663120326, timestamp: 2022-08-19 12:16:31.563745\n",
      "resetting env. episode 7392, reward total was -20.0. running mean: -17.20309027648912, timestamp: 2022-08-19 12:16:37.286815\n",
      "resetting env. episode 7393, reward total was -13.0. running mean: -17.16105937372423, timestamp: 2022-08-19 12:16:44.669896\n",
      "resetting env. episode 7394, reward total was -18.0. running mean: -17.169448779986986, timestamp: 2022-08-19 12:16:50.443963\n",
      "resetting env. episode 7395, reward total was -20.0. running mean: -17.197754292187117, timestamp: 2022-08-19 12:16:56.606036\n",
      "resetting env. episode 7396, reward total was -18.0. running mean: -17.205776749265244, timestamp: 2022-08-19 12:17:02.053098\n",
      "resetting env. episode 7397, reward total was -17.0. running mean: -17.203718981772592, timestamp: 2022-08-19 12:17:08.786174\n",
      "resetting env. episode 7398, reward total was -17.0. running mean: -17.20168179195487, timestamp: 2022-08-19 12:17:15.017248\n",
      "resetting env. episode 7399, reward total was -11.0. running mean: -17.13966497403532, timestamp: 2022-08-19 12:17:22.637338\n",
      "resetting env. episode 7400, reward total was -13.0. running mean: -17.098268324294967, timestamp: 2022-08-19 12:17:31.237437\n",
      "resetting env. episode 7401, reward total was -21.0. running mean: -17.137285641052017, timestamp: 2022-08-19 12:17:37.646514\n",
      "resetting env. episode 7402, reward total was -19.0. running mean: -17.155912784641497, timestamp: 2022-08-19 12:17:43.261576\n",
      "resetting env. episode 7403, reward total was -14.0. running mean: -17.124353656795083, timestamp: 2022-08-19 12:17:51.075667\n",
      "resetting env. episode 7404, reward total was -14.0. running mean: -17.093110120227134, timestamp: 2022-08-19 12:17:57.851748\n",
      "resetting env. episode 7405, reward total was -15.0. running mean: -17.072179019024862, timestamp: 2022-08-19 12:18:04.029816\n",
      "resetting env. episode 7406, reward total was -19.0. running mean: -17.091457228834614, timestamp: 2022-08-19 12:18:09.496879\n",
      "resetting env. episode 7407, reward total was -16.0. running mean: -17.080542656546267, timestamp: 2022-08-19 12:18:15.621951\n",
      "resetting env. episode 7408, reward total was -20.0. running mean: -17.109737229980805, timestamp: 2022-08-19 12:18:21.092015\n",
      "resetting env. episode 7409, reward total was -21.0. running mean: -17.148639857680998, timestamp: 2022-08-19 12:18:26.797079\n",
      "resetting env. episode 7410, reward total was -16.0. running mean: -17.137153459104187, timestamp: 2022-08-19 12:18:33.727158\n",
      "resetting env. episode 7411, reward total was -20.0. running mean: -17.165781924513144, timestamp: 2022-08-19 12:18:39.110221\n",
      "resetting env. episode 7412, reward total was -17.0. running mean: -17.164124105268016, timestamp: 2022-08-19 12:18:45.330291\n",
      "resetting env. episode 7413, reward total was -17.0. running mean: -17.162482864215338, timestamp: 2022-08-19 12:18:52.860380\n",
      "resetting env. episode 7414, reward total was -19.0. running mean: -17.180858035573188, timestamp: 2022-08-19 12:18:58.755448\n",
      "resetting env. episode 7415, reward total was -15.0. running mean: -17.159049455217453, timestamp: 2022-08-19 12:19:05.722530\n",
      "resetting env. episode 7416, reward total was -18.0. running mean: -17.16745896066528, timestamp: 2022-08-19 12:19:11.602595\n",
      "resetting env. episode 7417, reward total was -19.0. running mean: -17.185784371058627, timestamp: 2022-08-19 12:19:17.492662\n",
      "resetting env. episode 7418, reward total was -16.0. running mean: -17.17392652734804, timestamp: 2022-08-19 12:19:25.953761\n",
      "resetting env. episode 7419, reward total was -18.0. running mean: -17.18218726207456, timestamp: 2022-08-19 12:19:32.368835\n",
      "resetting env. episode 7420, reward total was -20.0. running mean: -17.210365389453813, timestamp: 2022-08-19 12:19:37.404890\n",
      "resetting env. episode 7421, reward total was -13.0. running mean: -17.168261735559273, timestamp: 2022-08-19 12:19:42.849954\n",
      "resetting env. episode 7422, reward total was -17.0. running mean: -17.166579118203682, timestamp: 2022-08-19 12:19:49.166026\n",
      "resetting env. episode 7423, reward total was -17.0. running mean: -17.164913327021647, timestamp: 2022-08-19 12:19:54.227082\n",
      "resetting env. episode 7424, reward total was -19.0. running mean: -17.18326419375143, timestamp: 2022-08-19 12:19:58.548134\n",
      "resetting env. episode 7425, reward total was -17.0. running mean: -17.18143155181392, timestamp: 2022-08-19 12:20:04.566199\n",
      "resetting env. episode 7426, reward total was -18.0. running mean: -17.189617236295778, timestamp: 2022-08-19 12:20:10.068262\n",
      "resetting env. episode 7427, reward total was -15.0. running mean: -17.16772106393282, timestamp: 2022-08-19 12:20:17.695351\n",
      "resetting env. episode 7428, reward total was -19.0. running mean: -17.186043853293494, timestamp: 2022-08-19 12:20:22.990411\n",
      "resetting env. episode 7429, reward total was -17.0. running mean: -17.18418341476056, timestamp: 2022-08-19 12:20:28.970479\n",
      "resetting env. episode 7430, reward total was -16.0. running mean: -17.172341580612954, timestamp: 2022-08-19 12:20:35.656554\n",
      "resetting env. episode 7431, reward total was -16.0. running mean: -17.160618164806824, timestamp: 2022-08-19 12:20:42.715635\n",
      "resetting env. episode 7432, reward total was -17.0. running mean: -17.159011983158756, timestamp: 2022-08-19 12:20:49.525713\n",
      "resetting env. episode 7433, reward total was -21.0. running mean: -17.19742186332717, timestamp: 2022-08-19 12:20:55.235778\n",
      "resetting env. episode 7434, reward total was -14.0. running mean: -17.1654476446939, timestamp: 2022-08-19 12:21:01.569368\n",
      "resetting env. episode 7435, reward total was -17.0. running mean: -17.16379316824696, timestamp: 2022-08-19 12:21:09.266459\n",
      "resetting env. episode 7436, reward total was -20.0. running mean: -17.192155236564492, timestamp: 2022-08-19 12:21:14.311513\n",
      "resetting env. episode 7437, reward total was -19.0. running mean: -17.210233684198847, timestamp: 2022-08-19 12:21:19.396572\n",
      "resetting env. episode 7438, reward total was -17.0. running mean: -17.20813134735686, timestamp: 2022-08-19 12:21:24.653632\n",
      "resetting env. episode 7439, reward total was -16.0. running mean: -17.196050033883292, timestamp: 2022-08-19 12:21:29.893689\n",
      "resetting env. episode 7440, reward total was -17.0. running mean: -17.19408953354446, timestamp: 2022-08-19 12:21:35.161749\n",
      "resetting env. episode 7441, reward total was -20.0. running mean: -17.222148638209013, timestamp: 2022-08-19 12:21:41.113814\n",
      "resetting env. episode 7442, reward total was -15.0. running mean: -17.199927151826923, timestamp: 2022-08-19 12:21:47.249885\n",
      "resetting env. episode 7443, reward total was -16.0. running mean: -17.187927880308653, timestamp: 2022-08-19 12:21:53.050950\n",
      "resetting env. episode 7444, reward total was -19.0. running mean: -17.206048601505568, timestamp: 2022-08-19 12:21:58.547015\n",
      "resetting env. episode 7445, reward total was -19.0. running mean: -17.223988115490513, timestamp: 2022-08-19 12:22:04.439079\n",
      "resetting env. episode 7446, reward total was -21.0. running mean: -17.26174823433561, timestamp: 2022-08-19 12:22:09.714138\n",
      "resetting env. episode 7447, reward total was -19.0. running mean: -17.279130751992255, timestamp: 2022-08-19 12:22:16.007208\n",
      "resetting env. episode 7448, reward total was -10.0. running mean: -17.206339444472334, timestamp: 2022-08-19 12:22:22.686282\n",
      "resetting env. episode 7449, reward total was -19.0. running mean: -17.224276050027612, timestamp: 2022-08-19 12:22:29.014354\n",
      "resetting env. episode 7450, reward total was -15.0. running mean: -17.202033289527336, timestamp: 2022-08-19 12:22:37.237444\n",
      "resetting env. episode 7451, reward total was -18.0. running mean: -17.210012956632063, timestamp: 2022-08-19 12:22:42.714505\n",
      "resetting env. episode 7452, reward total was -16.0. running mean: -17.197912827065743, timestamp: 2022-08-19 12:22:48.538573\n",
      "resetting env. episode 7453, reward total was -21.0. running mean: -17.235933698795087, timestamp: 2022-08-19 12:22:54.513162\n",
      "resetting env. episode 7454, reward total was -16.0. running mean: -17.223574361807135, timestamp: 2022-08-19 12:23:01.619242\n",
      "resetting env. episode 7455, reward total was -18.0. running mean: -17.231338618189064, timestamp: 2022-08-19 12:23:07.379306\n",
      "resetting env. episode 7456, reward total was -14.0. running mean: -17.199025232007173, timestamp: 2022-08-19 12:23:13.345372\n",
      "resetting env. episode 7457, reward total was -19.0. running mean: -17.217034979687103, timestamp: 2022-08-19 12:23:18.053954\n",
      "resetting env. episode 7458, reward total was -20.0. running mean: -17.24486462989023, timestamp: 2022-08-19 12:23:23.965017\n",
      "resetting env. episode 7459, reward total was -19.0. running mean: -17.26241598359133, timestamp: 2022-08-19 12:23:28.577068\n",
      "resetting env. episode 7460, reward total was -16.0. running mean: -17.249791823755416, timestamp: 2022-08-19 12:23:34.636133\n",
      "resetting env. episode 7461, reward total was -14.0. running mean: -17.217293905517863, timestamp: 2022-08-19 12:23:40.774202\n",
      "resetting env. episode 7462, reward total was -18.0. running mean: -17.225120966462683, timestamp: 2022-08-19 12:23:45.773256\n",
      "resetting env. episode 7463, reward total was -13.0. running mean: -17.182869756798056, timestamp: 2022-08-19 12:23:53.354343\n",
      "resetting env. episode 7464, reward total was -17.0. running mean: -17.181041059230076, timestamp: 2022-08-19 12:23:59.057405\n",
      "resetting env. episode 7465, reward total was -16.0. running mean: -17.169230648637775, timestamp: 2022-08-19 12:24:04.985472\n",
      "resetting env. episode 7466, reward total was -18.0. running mean: -17.177538342151397, timestamp: 2022-08-19 12:24:11.897548\n",
      "resetting env. episode 7467, reward total was -17.0. running mean: -17.175762958729884, timestamp: 2022-08-19 12:24:18.581624\n",
      "resetting env. episode 7468, reward total was -17.0. running mean: -17.174005329142588, timestamp: 2022-08-19 12:24:24.717693\n",
      "resetting env. episode 7469, reward total was -17.0. running mean: -17.172265275851164, timestamp: 2022-08-19 12:24:30.583754\n",
      "resetting env. episode 7470, reward total was -19.0. running mean: -17.190542623092654, timestamp: 2022-08-19 12:24:36.431818\n",
      "resetting env. episode 7471, reward total was -19.0. running mean: -17.20863719686173, timestamp: 2022-08-19 12:24:42.986891\n",
      "resetting env. episode 7472, reward total was -19.0. running mean: -17.226550824893113, timestamp: 2022-08-19 12:24:47.668945\n",
      "resetting env. episode 7473, reward total was -15.0. running mean: -17.20428531664418, timestamp: 2022-08-19 12:24:53.213003\n",
      "resetting env. episode 7474, reward total was -15.0. running mean: -17.18224246347774, timestamp: 2022-08-19 12:25:02.442105\n",
      "resetting env. episode 7475, reward total was -17.0. running mean: -17.180420038842964, timestamp: 2022-08-19 12:25:09.637185\n",
      "resetting env. episode 7476, reward total was -19.0. running mean: -17.198615838454536, timestamp: 2022-08-19 12:25:13.988231\n",
      "resetting env. episode 7477, reward total was -14.0. running mean: -17.166629680069992, timestamp: 2022-08-19 12:25:19.630294\n",
      "resetting env. episode 7478, reward total was -13.0. running mean: -17.12496338326929, timestamp: 2022-08-19 12:25:25.985365\n",
      "resetting env. episode 7479, reward total was -19.0. running mean: -17.143713749436596, timestamp: 2022-08-19 12:25:31.151423\n",
      "resetting env. episode 7480, reward total was -15.0. running mean: -17.12227661194223, timestamp: 2022-08-19 12:25:36.911487\n",
      "resetting env. episode 7481, reward total was -20.0. running mean: -17.151053845822805, timestamp: 2022-08-19 12:25:42.700554\n",
      "resetting env. episode 7482, reward total was -19.0. running mean: -17.169543307364577, timestamp: 2022-08-19 12:25:48.728620\n",
      "resetting env. episode 7483, reward total was -13.0. running mean: -17.127847874290932, timestamp: 2022-08-19 12:25:56.111701\n",
      "resetting env. episode 7484, reward total was -19.0. running mean: -17.146569395548024, timestamp: 2022-08-19 12:26:02.411772\n",
      "resetting env. episode 7485, reward total was -15.0. running mean: -17.125103701592543, timestamp: 2022-08-19 12:26:09.091848\n",
      "resetting env. episode 7486, reward total was -19.0. running mean: -17.14385266457662, timestamp: 2022-08-19 12:26:13.507899\n",
      "resetting env. episode 7487, reward total was -16.0. running mean: -17.132414137930855, timestamp: 2022-08-19 12:26:19.839971\n",
      "resetting env. episode 7488, reward total was -19.0. running mean: -17.151089996551548, timestamp: 2022-08-19 12:26:26.018039\n",
      "resetting env. episode 7489, reward total was -20.0. running mean: -17.179579096586032, timestamp: 2022-08-19 12:26:30.663091\n",
      "resetting env. episode 7490, reward total was -16.0. running mean: -17.167783305620173, timestamp: 2022-08-19 12:26:36.086153\n",
      "resetting env. episode 7491, reward total was -16.0. running mean: -17.156105472563972, timestamp: 2022-08-19 12:26:43.052232\n",
      "resetting env. episode 7492, reward total was -18.0. running mean: -17.164544417838332, timestamp: 2022-08-19 12:26:48.822304\n",
      "resetting env. episode 7493, reward total was -19.0. running mean: -17.18289897365995, timestamp: 2022-08-19 12:26:53.463351\n",
      "resetting env. episode 7494, reward total was -20.0. running mean: -17.21106998392335, timestamp: 2022-08-19 12:26:58.624413\n",
      "resetting env. episode 7495, reward total was -17.0. running mean: -17.208959284084116, timestamp: 2022-08-19 12:27:05.699492\n",
      "resetting env. episode 7496, reward total was -15.0. running mean: -17.186869691243274, timestamp: 2022-08-19 12:27:11.721562\n",
      "resetting env. episode 7497, reward total was -20.0. running mean: -17.21500099433084, timestamp: 2022-08-19 12:27:18.243635\n",
      "resetting env. episode 7498, reward total was -15.0. running mean: -17.19285098438753, timestamp: 2022-08-19 12:27:25.311719\n",
      "resetting env. episode 7499, reward total was -21.0. running mean: -17.230922474543654, timestamp: 2022-08-19 12:27:32.200796\n",
      "resetting env. episode 7500, reward total was -19.0. running mean: -17.24861324979822, timestamp: 2022-08-19 12:27:37.684860\n",
      "resetting env. episode 7501, reward total was -19.0. running mean: -17.266127117300236, timestamp: 2022-08-19 12:27:43.638927\n",
      "resetting env. episode 7502, reward total was -19.0. running mean: -17.283465846127235, timestamp: 2022-08-19 12:27:49.205993\n",
      "resetting env. episode 7503, reward total was -16.0. running mean: -17.270631187665963, timestamp: 2022-08-19 12:27:55.100062\n",
      "resetting env. episode 7504, reward total was -18.0. running mean: -17.277924875789303, timestamp: 2022-08-19 12:28:00.968134\n",
      "resetting env. episode 7505, reward total was -16.0. running mean: -17.26514562703141, timestamp: 2022-08-19 12:28:06.910198\n",
      "resetting env. episode 7506, reward total was -16.0. running mean: -17.252494170761093, timestamp: 2022-08-19 12:28:11.663252\n",
      "resetting env. episode 7507, reward total was -19.0. running mean: -17.269969229053483, timestamp: 2022-08-19 12:28:18.069328\n",
      "resetting env. episode 7508, reward total was -17.0. running mean: -17.26726953676295, timestamp: 2022-08-19 12:28:24.009399\n",
      "resetting env. episode 7509, reward total was -19.0. running mean: -17.28459684139532, timestamp: 2022-08-19 12:28:29.600000\n",
      "resetting env. episode 7510, reward total was -18.0. running mean: -17.291750872981368, timestamp: 2022-08-19 12:28:35.309062\n",
      "resetting env. episode 7511, reward total was -16.0. running mean: -17.278833364251554, timestamp: 2022-08-19 12:28:42.113667\n",
      "resetting env. episode 7512, reward total was -17.0. running mean: -17.27604503060904, timestamp: 2022-08-19 12:28:48.863749\n",
      "resetting env. episode 7513, reward total was -17.0. running mean: -17.273284580302953, timestamp: 2022-08-19 12:28:55.756827\n",
      "resetting env. episode 7514, reward total was -19.0. running mean: -17.290551734499925, timestamp: 2022-08-19 12:29:01.781897\n",
      "resetting env. episode 7515, reward total was -18.0. running mean: -17.297646217154924, timestamp: 2022-08-19 12:29:06.170948\n",
      "resetting env. episode 7516, reward total was -18.0. running mean: -17.304669754983372, timestamp: 2022-08-19 12:29:12.201022\n",
      "resetting env. episode 7517, reward total was -15.0. running mean: -17.28162305743354, timestamp: 2022-08-19 12:29:18.662096\n",
      "resetting env. episode 7518, reward total was -18.0. running mean: -17.288806826859204, timestamp: 2022-08-19 12:29:24.129161\n",
      "resetting env. episode 7519, reward total was -15.0. running mean: -17.26591875859061, timestamp: 2022-08-19 12:29:29.955232\n",
      "resetting env. episode 7520, reward total was -14.0. running mean: -17.233259571004705, timestamp: 2022-08-19 12:29:37.771319\n",
      "resetting env. episode 7521, reward total was -18.0. running mean: -17.24092697529466, timestamp: 2022-08-19 12:29:43.680387\n",
      "resetting env. episode 7522, reward total was -17.0. running mean: -17.238517705541714, timestamp: 2022-08-19 12:29:50.247990\n",
      "resetting env. episode 7523, reward total was -12.0. running mean: -17.186132528486297, timestamp: 2022-08-19 12:29:56.111060\n",
      "resetting env. episode 7524, reward total was -15.0. running mean: -17.164271203201434, timestamp: 2022-08-19 12:30:03.568148\n",
      "resetting env. episode 7525, reward total was -17.0. running mean: -17.16262849116942, timestamp: 2022-08-19 12:30:09.671220\n",
      "resetting env. episode 7526, reward total was -15.0. running mean: -17.141002206257724, timestamp: 2022-08-19 12:30:16.764300\n",
      "resetting env. episode 7527, reward total was -18.0. running mean: -17.149592184195146, timestamp: 2022-08-19 12:30:22.539368\n",
      "resetting env. episode 7528, reward total was -19.0. running mean: -17.168096262353195, timestamp: 2022-08-19 12:30:28.345436\n",
      "resetting env. episode 7529, reward total was -17.0. running mean: -17.166415299729664, timestamp: 2022-08-19 12:30:34.042503\n",
      "resetting env. episode 7530, reward total was -15.0. running mean: -17.144751146732364, timestamp: 2022-08-19 12:30:40.584581\n",
      "resetting env. episode 7531, reward total was -16.0. running mean: -17.13330363526504, timestamp: 2022-08-19 12:30:47.021654\n",
      "resetting env. episode 7532, reward total was -16.0. running mean: -17.12197059891239, timestamp: 2022-08-19 12:30:55.891688\n",
      "resetting env. episode 7533, reward total was -18.0. running mean: -17.130750892923267, timestamp: 2022-08-19 12:31:02.341764\n",
      "resetting env. episode 7534, reward total was -17.0. running mean: -17.129443383994037, timestamp: 2022-08-19 12:31:08.435834\n",
      "resetting env. episode 7535, reward total was -18.0. running mean: -17.138148950154097, timestamp: 2022-08-19 12:31:14.183902\n",
      "resetting env. episode 7536, reward total was -21.0. running mean: -17.176767460652556, timestamp: 2022-08-19 12:31:19.361960\n",
      "resetting env. episode 7537, reward total was -12.0. running mean: -17.124999786046033, timestamp: 2022-08-19 12:31:27.122055\n",
      "resetting env. episode 7538, reward total was -15.0. running mean: -17.10374978818557, timestamp: 2022-08-19 12:31:34.509139\n",
      "resetting env. episode 7539, reward total was -15.0. running mean: -17.082712290303714, timestamp: 2022-08-19 12:31:39.866208\n",
      "resetting env. episode 7540, reward total was -15.0. running mean: -17.061885167400675, timestamp: 2022-08-19 12:31:45.751271\n",
      "resetting env. episode 7541, reward total was -18.0. running mean: -17.071266315726668, timestamp: 2022-08-19 12:31:51.646337\n",
      "resetting env. episode 7542, reward total was -17.0. running mean: -17.0705536525694, timestamp: 2022-08-19 12:31:58.261415\n",
      "resetting env. episode 7543, reward total was -16.0. running mean: -17.059848116043707, timestamp: 2022-08-19 12:32:05.608500\n",
      "resetting env. episode 7544, reward total was -19.0. running mean: -17.079249634883272, timestamp: 2022-08-19 12:32:10.248552\n",
      "resetting env. episode 7545, reward total was -15.0. running mean: -17.058457138534436, timestamp: 2022-08-19 12:32:16.535627\n",
      "resetting env. episode 7546, reward total was -21.0. running mean: -17.097872567149093, timestamp: 2022-08-19 12:32:22.865704\n",
      "resetting env. episode 7547, reward total was -14.0. running mean: -17.0668938414776, timestamp: 2022-08-19 12:32:29.296785\n",
      "resetting env. episode 7548, reward total was -15.0. running mean: -17.04622490306282, timestamp: 2022-08-19 12:32:35.404853\n",
      "resetting env. episode 7549, reward total was -13.0. running mean: -17.005762654032193, timestamp: 2022-08-19 12:32:42.462932\n",
      "resetting env. episode 7550, reward total was -19.0. running mean: -17.02570502749187, timestamp: 2022-08-19 12:32:48.880005\n",
      "resetting env. episode 7551, reward total was -20.0. running mean: -17.05544797721695, timestamp: 2022-08-19 12:32:54.158067\n",
      "resetting env. episode 7552, reward total was -16.0. running mean: -17.04489349744478, timestamp: 2022-08-19 12:33:01.142675\n",
      "resetting env. episode 7553, reward total was -19.0. running mean: -17.06444456247033, timestamp: 2022-08-19 12:33:06.910742\n",
      "resetting env. episode 7554, reward total was -18.0. running mean: -17.07380011684563, timestamp: 2022-08-19 12:33:12.773809\n",
      "resetting env. episode 7555, reward total was -15.0. running mean: -17.05306211567717, timestamp: 2022-08-19 12:33:19.463889\n",
      "resetting env. episode 7556, reward total was -17.0. running mean: -17.0525314945204, timestamp: 2022-08-19 12:33:24.318946\n",
      "resetting env. episode 7557, reward total was -16.0. running mean: -17.042006179575196, timestamp: 2022-08-19 12:33:31.039024\n",
      "resetting env. episode 7558, reward total was -19.0. running mean: -17.061586117779445, timestamp: 2022-08-19 12:33:37.058094\n",
      "resetting env. episode 7559, reward total was -19.0. running mean: -17.080970256601653, timestamp: 2022-08-19 12:33:42.351158\n",
      "resetting env. episode 7560, reward total was -21.0. running mean: -17.120160554035635, timestamp: 2022-08-19 12:33:47.327213\n",
      "resetting env. episode 7561, reward total was -17.0. running mean: -17.11895894849528, timestamp: 2022-08-19 12:33:53.639287\n",
      "resetting env. episode 7562, reward total was -14.0. running mean: -17.087769359010327, timestamp: 2022-08-19 12:34:04.108410\n",
      "resetting env. episode 7563, reward total was -18.0. running mean: -17.096891665420223, timestamp: 2022-08-19 12:34:10.173007\n",
      "resetting env. episode 7564, reward total was -18.0. running mean: -17.10592274876602, timestamp: 2022-08-19 12:34:16.343080\n",
      "resetting env. episode 7565, reward total was -17.0. running mean: -17.10486352127836, timestamp: 2022-08-19 12:34:22.096146\n",
      "resetting env. episode 7566, reward total was -18.0. running mean: -17.113814886065576, timestamp: 2022-08-19 12:34:29.817233\n",
      "resetting env. episode 7567, reward total was -17.0. running mean: -17.11267673720492, timestamp: 2022-08-19 12:34:36.447311\n",
      "resetting env. episode 7568, reward total was -15.0. running mean: -17.091549969832872, timestamp: 2022-08-19 12:34:43.175389\n",
      "resetting env. episode 7569, reward total was -18.0. running mean: -17.100634470134544, timestamp: 2022-08-19 12:34:48.489450\n",
      "resetting env. episode 7570, reward total was -18.0. running mean: -17.109628125433197, timestamp: 2022-08-19 12:34:53.360507\n",
      "resetting env. episode 7571, reward total was -9.0. running mean: -17.028531844178865, timestamp: 2022-08-19 12:35:01.097596\n",
      "resetting env. episode 7572, reward total was -17.0. running mean: -17.028246525737078, timestamp: 2022-08-19 12:35:06.966664\n",
      "resetting env. episode 7573, reward total was -17.0. running mean: -17.027964060479707, timestamp: 2022-08-19 12:35:13.821749\n",
      "resetting env. episode 7574, reward total was -15.0. running mean: -17.00768441987491, timestamp: 2022-08-19 12:35:20.674823\n",
      "resetting env. episode 7575, reward total was -19.0. running mean: -17.02760757567616, timestamp: 2022-08-19 12:35:26.422892\n",
      "resetting env. episode 7576, reward total was -11.0. running mean: -16.9673314999194, timestamp: 2022-08-19 12:35:32.717968\n",
      "resetting env. episode 7577, reward total was -17.0. running mean: -16.967658184920207, timestamp: 2022-08-19 12:35:38.146026\n",
      "resetting env. episode 7578, reward total was -15.0. running mean: -16.947981603071003, timestamp: 2022-08-19 12:35:47.238130\n",
      "resetting env. episode 7579, reward total was -14.0. running mean: -16.918501787040295, timestamp: 2022-08-19 12:35:53.344200\n",
      "resetting env. episode 7580, reward total was -18.0. running mean: -16.92931676916989, timestamp: 2022-08-19 12:36:00.799284\n",
      "resetting env. episode 7581, reward total was -18.0. running mean: -16.94002360147819, timestamp: 2022-08-19 12:36:06.198347\n",
      "resetting env. episode 7582, reward total was -13.0. running mean: -16.90062336546341, timestamp: 2022-08-19 12:36:13.472431\n",
      "resetting env. episode 7583, reward total was -18.0. running mean: -16.911617131808775, timestamp: 2022-08-19 12:36:19.808503\n",
      "resetting env. episode 7584, reward total was -13.0. running mean: -16.872500960490687, timestamp: 2022-08-19 12:36:28.878609\n",
      "resetting env. episode 7585, reward total was -14.0. running mean: -16.84377595088578, timestamp: 2022-08-19 12:36:34.486675\n",
      "resetting env. episode 7586, reward total was -17.0. running mean: -16.845338191376925, timestamp: 2022-08-19 12:36:40.436741\n",
      "resetting env. episode 7587, reward total was -18.0. running mean: -16.856884809463157, timestamp: 2022-08-19 12:36:46.813815\n",
      "resetting env. episode 7588, reward total was -10.0. running mean: -16.788315961368525, timestamp: 2022-08-19 12:36:55.336916\n",
      "resetting env. episode 7589, reward total was -17.0. running mean: -16.790432801754843, timestamp: 2022-08-19 12:37:00.935979\n",
      "resetting env. episode 7590, reward total was -19.0. running mean: -16.812528473737295, timestamp: 2022-08-19 12:37:05.863554\n",
      "resetting env. episode 7591, reward total was -16.0. running mean: -16.80440318899992, timestamp: 2022-08-19 12:37:10.903613\n",
      "resetting env. episode 7592, reward total was -16.0. running mean: -16.796359157109922, timestamp: 2022-08-19 12:37:17.172684\n",
      "resetting env. episode 7593, reward total was -16.0. running mean: -16.788395565538824, timestamp: 2022-08-19 12:37:24.298765\n",
      "resetting env. episode 7594, reward total was -17.0. running mean: -16.79051160988344, timestamp: 2022-08-19 12:37:30.678881\n",
      "resetting env. episode 7595, reward total was -14.0. running mean: -16.762606493784606, timestamp: 2022-08-19 12:37:39.138979\n",
      "resetting env. episode 7596, reward total was -13.0. running mean: -16.72498042884676, timestamp: 2022-08-19 12:37:46.047058\n",
      "resetting env. episode 7597, reward total was -16.0. running mean: -16.717730624558293, timestamp: 2022-08-19 12:37:51.413119\n",
      "resetting env. episode 7598, reward total was -19.0. running mean: -16.74055331831271, timestamp: 2022-08-19 12:37:57.852192\n",
      "resetting env. episode 7599, reward total was -19.0. running mean: -16.763147785129583, timestamp: 2022-08-19 12:38:03.118255\n",
      "resetting env. episode 7600, reward total was -18.0. running mean: -16.775516307278288, timestamp: 2022-08-19 12:38:08.534311\n",
      "resetting env. episode 7601, reward total was -14.0. running mean: -16.747761144205505, timestamp: 2022-08-19 12:38:14.802386\n",
      "resetting env. episode 7602, reward total was -13.0. running mean: -16.710283532763448, timestamp: 2022-08-19 12:38:21.571460\n",
      "resetting env. episode 7603, reward total was -16.0. running mean: -16.703180697435812, timestamp: 2022-08-19 12:38:27.874532\n",
      "resetting env. episode 7604, reward total was -17.0. running mean: -16.706148890461456, timestamp: 2022-08-19 12:38:33.059591\n",
      "resetting env. episode 7605, reward total was -16.0. running mean: -16.69908740155684, timestamp: 2022-08-19 12:38:39.760670\n",
      "resetting env. episode 7606, reward total was -21.0. running mean: -16.742096527541275, timestamp: 2022-08-19 12:38:45.083728\n",
      "resetting env. episode 7607, reward total was -17.0. running mean: -16.744675562265865, timestamp: 2022-08-19 12:38:50.610787\n",
      "resetting env. episode 7608, reward total was -15.0. running mean: -16.727228806643204, timestamp: 2022-08-19 12:38:55.910847\n",
      "resetting env. episode 7609, reward total was -17.0. running mean: -16.729956518576774, timestamp: 2022-08-19 12:39:01.407909\n",
      "resetting env. episode 7610, reward total was -17.0. running mean: -16.732656953391007, timestamp: 2022-08-19 12:39:07.666980\n",
      "resetting env. episode 7611, reward total was -15.0. running mean: -16.715330383857097, timestamp: 2022-08-19 12:39:14.826063\n",
      "resetting env. episode 7612, reward total was -10.0. running mean: -16.648177080018527, timestamp: 2022-08-19 12:39:24.075167\n",
      "resetting env. episode 7613, reward total was -16.0. running mean: -16.641695309218342, timestamp: 2022-08-19 12:39:30.477239\n",
      "resetting env. episode 7614, reward total was -17.0. running mean: -16.64527835612616, timestamp: 2022-08-19 12:39:36.767308\n",
      "resetting env. episode 7615, reward total was -16.0. running mean: -16.638825572564897, timestamp: 2022-08-19 12:39:41.990368\n",
      "resetting env. episode 7616, reward total was -18.0. running mean: -16.652437316839247, timestamp: 2022-08-19 12:39:49.014445\n",
      "resetting env. episode 7617, reward total was -17.0. running mean: -16.655912943670856, timestamp: 2022-08-19 12:39:55.049513\n",
      "resetting env. episode 7618, reward total was -19.0. running mean: -16.679353814234148, timestamp: 2022-08-19 12:40:00.903576\n",
      "resetting env. episode 7619, reward total was -17.0. running mean: -16.682560276091806, timestamp: 2022-08-19 12:40:08.514663\n",
      "resetting env. episode 7620, reward total was -16.0. running mean: -16.675734673330886, timestamp: 2022-08-19 12:40:14.663731\n",
      "resetting env. episode 7621, reward total was -19.0. running mean: -16.69897732659758, timestamp: 2022-08-19 12:40:20.123793\n",
      "resetting env. episode 7622, reward total was -15.0. running mean: -16.681987553331602, timestamp: 2022-08-19 12:40:27.646877\n",
      "resetting env. episode 7623, reward total was -15.0. running mean: -16.665167677798284, timestamp: 2022-08-19 12:40:35.287963\n",
      "resetting env. episode 7624, reward total was -20.0. running mean: -16.698516001020298, timestamp: 2022-08-19 12:40:41.068555\n",
      "resetting env. episode 7625, reward total was -18.0. running mean: -16.711530841010095, timestamp: 2022-08-19 12:40:46.850622\n",
      "resetting env. episode 7626, reward total was -20.0. running mean: -16.744415532599994, timestamp: 2022-08-19 12:40:53.388691\n",
      "resetting env. episode 7627, reward total was -18.0. running mean: -16.756971377273995, timestamp: 2022-08-19 12:40:58.086743\n",
      "resetting env. episode 7628, reward total was -18.0. running mean: -16.769401663501256, timestamp: 2022-08-19 12:41:04.173813\n",
      "resetting env. episode 7629, reward total was -18.0. running mean: -16.78170764686624, timestamp: 2022-08-19 12:41:10.000876\n",
      "resetting env. episode 7630, reward total was -17.0. running mean: -16.78389057039758, timestamp: 2022-08-19 12:41:15.932942\n",
      "resetting env. episode 7631, reward total was -19.0. running mean: -16.806051664693605, timestamp: 2022-08-19 12:41:21.649006\n",
      "resetting env. episode 7632, reward total was -17.0. running mean: -16.80799114804667, timestamp: 2022-08-19 12:41:27.719074\n",
      "resetting env. episode 7633, reward total was -14.0. running mean: -16.779911236566203, timestamp: 2022-08-19 12:41:33.600141\n",
      "resetting env. episode 7634, reward total was -16.0. running mean: -16.77211212420054, timestamp: 2022-08-19 12:41:41.220220\n",
      "resetting env. episode 7635, reward total was -18.0. running mean: -16.784391002958532, timestamp: 2022-08-19 12:41:47.450811\n",
      "resetting env. episode 7636, reward total was -14.0. running mean: -16.756547092928948, timestamp: 2022-08-19 12:41:55.489901\n",
      "resetting env. episode 7637, reward total was -14.0. running mean: -16.728981621999658, timestamp: 2022-08-19 12:42:01.844970\n",
      "resetting env. episode 7638, reward total was -15.0. running mean: -16.711691805779658, timestamp: 2022-08-19 12:42:07.601033\n",
      "resetting env. episode 7639, reward total was -18.0. running mean: -16.72457488772186, timestamp: 2022-08-19 12:42:14.629109\n",
      "resetting env. episode 7640, reward total was -16.0. running mean: -16.717329138844644, timestamp: 2022-08-19 12:42:21.264183\n",
      "resetting env. episode 7641, reward total was -17.0. running mean: -16.720155847456198, timestamp: 2022-08-19 12:42:28.146266\n",
      "resetting env. episode 7642, reward total was -12.0. running mean: -16.672954288981636, timestamp: 2022-08-19 12:42:35.074339\n",
      "resetting env. episode 7643, reward total was -15.0. running mean: -16.65622474609182, timestamp: 2022-08-19 12:42:40.959404\n",
      "resetting env. episode 7644, reward total was -11.0. running mean: -16.5996624986309, timestamp: 2022-08-19 12:42:49.990505\n",
      "resetting env. episode 7645, reward total was -19.0. running mean: -16.62366587364459, timestamp: 2022-08-19 12:42:55.447569\n",
      "resetting env. episode 7646, reward total was -18.0. running mean: -16.637429214908146, timestamp: 2022-08-19 12:43:02.507646\n",
      "resetting env. episode 7647, reward total was -15.0. running mean: -16.62105492275906, timestamp: 2022-08-19 12:43:09.454724\n",
      "resetting env. episode 7648, reward total was -13.0. running mean: -16.58484437353147, timestamp: 2022-08-19 12:43:15.625796\n",
      "resetting env. episode 7649, reward total was -17.0. running mean: -16.58899592979616, timestamp: 2022-08-19 12:43:22.204870\n",
      "resetting env. episode 7650, reward total was -15.0. running mean: -16.573105970498197, timestamp: 2022-08-19 12:43:29.462951\n",
      "resetting env. episode 7651, reward total was -19.0. running mean: -16.597374910793217, timestamp: 2022-08-19 12:43:33.960001\n",
      "resetting env. episode 7652, reward total was -17.0. running mean: -16.601401161685285, timestamp: 2022-08-19 12:43:40.152076\n",
      "resetting env. episode 7653, reward total was -15.0. running mean: -16.58538715006843, timestamp: 2022-08-19 12:43:46.739149\n",
      "resetting env. episode 7654, reward total was -19.0. running mean: -16.60953327856775, timestamp: 2022-08-19 12:43:53.229223\n",
      "resetting env. episode 7655, reward total was -18.0. running mean: -16.623437945782072, timestamp: 2022-08-19 12:43:58.676289\n",
      "resetting env. episode 7656, reward total was -15.0. running mean: -16.60720356632425, timestamp: 2022-08-19 12:44:05.760367\n",
      "resetting env. episode 7657, reward total was -19.0. running mean: -16.631131530661012, timestamp: 2022-08-19 12:44:10.439423\n",
      "resetting env. episode 7658, reward total was -21.0. running mean: -16.6748202153544, timestamp: 2022-08-19 12:44:15.859008\n",
      "resetting env. episode 7659, reward total was -18.0. running mean: -16.688072013200856, timestamp: 2022-08-19 12:44:21.742080\n",
      "resetting env. episode 7660, reward total was -16.0. running mean: -16.681191293068846, timestamp: 2022-08-19 12:44:28.431154\n",
      "resetting env. episode 7661, reward total was -18.0. running mean: -16.694379380138155, timestamp: 2022-08-19 12:44:34.635224\n",
      "resetting env. episode 7662, reward total was -18.0. running mean: -16.707435586336775, timestamp: 2022-08-19 12:44:40.386291\n",
      "resetting env. episode 7663, reward total was -19.0. running mean: -16.73036123047341, timestamp: 2022-08-19 12:44:46.155359\n",
      "resetting env. episode 7664, reward total was -19.0. running mean: -16.753057618168675, timestamp: 2022-08-19 12:44:52.759436\n",
      "resetting env. episode 7665, reward total was -18.0. running mean: -16.76552704198699, timestamp: 2022-08-19 12:44:59.258509\n",
      "resetting env. episode 7666, reward total was -21.0. running mean: -16.807871771567118, timestamp: 2022-08-19 12:45:04.833575\n",
      "resetting env. episode 7667, reward total was -11.0. running mean: -16.749793053851445, timestamp: 2022-08-19 12:45:12.101660\n",
      "resetting env. episode 7668, reward total was -17.0. running mean: -16.752295123312933, timestamp: 2022-08-19 12:45:18.605741\n",
      "resetting env. episode 7669, reward total was -18.0. running mean: -16.764772172079805, timestamp: 2022-08-19 12:45:24.420808\n",
      "resetting env. episode 7670, reward total was -18.0. running mean: -16.777124450359008, timestamp: 2022-08-19 12:45:29.422866\n",
      "resetting env. episode 7671, reward total was -16.0. running mean: -16.769353205855417, timestamp: 2022-08-19 12:45:36.207945\n",
      "resetting env. episode 7672, reward total was -21.0. running mean: -16.811659673796864, timestamp: 2022-08-19 12:45:40.811999\n",
      "resetting env. episode 7673, reward total was -18.0. running mean: -16.823543077058893, timestamp: 2022-08-19 12:45:47.322072\n",
      "resetting env. episode 7674, reward total was -19.0. running mean: -16.845307646288305, timestamp: 2022-08-19 12:45:52.692136\n",
      "resetting env. episode 7675, reward total was -19.0. running mean: -16.866854569825424, timestamp: 2022-08-19 12:45:58.519206\n",
      "resetting env. episode 7676, reward total was -16.0. running mean: -16.85818602412717, timestamp: 2022-08-19 12:46:03.576263\n",
      "resetting env. episode 7677, reward total was -17.0. running mean: -16.8596041638859, timestamp: 2022-08-19 12:46:09.852336\n",
      "resetting env. episode 7678, reward total was -16.0. running mean: -16.85100812224704, timestamp: 2022-08-19 12:46:16.911418\n",
      "resetting env. episode 7679, reward total was -16.0. running mean: -16.84249804102457, timestamp: 2022-08-19 12:46:23.734498\n",
      "resetting env. episode 7680, reward total was -18.0. running mean: -16.854073060614322, timestamp: 2022-08-19 12:46:29.510565\n",
      "resetting env. episode 7681, reward total was -18.0. running mean: -16.86553233000818, timestamp: 2022-08-19 12:46:34.948629\n",
      "resetting env. episode 7682, reward total was -17.0. running mean: -16.866877006708098, timestamp: 2022-08-19 12:46:42.567720\n",
      "resetting env. episode 7683, reward total was -14.0. running mean: -16.838208236641016, timestamp: 2022-08-19 12:46:48.412787\n",
      "resetting env. episode 7684, reward total was -14.0. running mean: -16.809826154274607, timestamp: 2022-08-19 12:46:55.148866\n",
      "resetting env. episode 7685, reward total was -17.0. running mean: -16.811727892731863, timestamp: 2022-08-19 12:47:01.822945\n",
      "resetting env. episode 7686, reward total was -17.0. running mean: -16.813610613804546, timestamp: 2022-08-19 12:47:09.956041\n",
      "resetting env. episode 7687, reward total was -18.0. running mean: -16.8254745076665, timestamp: 2022-08-19 12:47:15.828110\n",
      "resetting env. episode 7688, reward total was -17.0. running mean: -16.827219762589834, timestamp: 2022-08-19 12:47:21.842187\n",
      "resetting env. episode 7689, reward total was -15.0. running mean: -16.808947564963933, timestamp: 2022-08-19 12:47:28.279258\n",
      "resetting env. episode 7690, reward total was -21.0. running mean: -16.850858089314293, timestamp: 2022-08-19 12:47:33.923323\n",
      "resetting env. episode 7691, reward total was -19.0. running mean: -16.872349508421152, timestamp: 2022-08-19 12:47:39.067387\n",
      "resetting env. episode 7692, reward total was -19.0. running mean: -16.89362601333694, timestamp: 2022-08-19 12:47:45.693462\n",
      "resetting env. episode 7693, reward total was -19.0. running mean: -16.91468975320357, timestamp: 2022-08-19 12:47:52.242542\n",
      "resetting env. episode 7694, reward total was -21.0. running mean: -16.955542855671535, timestamp: 2022-08-19 12:47:58.511615\n",
      "resetting env. episode 7695, reward total was -17.0. running mean: -16.95598742711482, timestamp: 2022-08-19 12:48:04.510684\n",
      "resetting env. episode 7696, reward total was -17.0. running mean: -16.956427552843675, timestamp: 2022-08-19 12:48:11.450767\n",
      "resetting env. episode 7697, reward total was -12.0. running mean: -16.90686327731524, timestamp: 2022-08-19 12:48:19.732865\n",
      "resetting env. episode 7698, reward total was -10.0. running mean: -16.837794644542086, timestamp: 2022-08-19 12:48:27.874961\n",
      "resetting env. episode 7699, reward total was -14.0. running mean: -16.809416698096665, timestamp: 2022-08-19 12:48:34.501039\n",
      "resetting env. episode 7700, reward total was -19.0. running mean: -16.8313225311157, timestamp: 2022-08-19 12:48:39.829101\n",
      "resetting env. episode 7701, reward total was -15.0. running mean: -16.813009305804542, timestamp: 2022-08-19 12:48:45.793177\n",
      "resetting env. episode 7702, reward total was -16.0. running mean: -16.804879212746496, timestamp: 2022-08-19 12:48:51.797243\n",
      "resetting env. episode 7703, reward total was -16.0. running mean: -16.79683042061903, timestamp: 2022-08-19 12:49:00.020342\n",
      "resetting env. episode 7704, reward total was -16.0. running mean: -16.78886211641284, timestamp: 2022-08-19 12:49:05.335406\n",
      "resetting env. episode 7705, reward total was -17.0. running mean: -16.790973495248714, timestamp: 2022-08-19 12:49:10.161463\n",
      "resetting env. episode 7706, reward total was -15.0. running mean: -16.773063760296225, timestamp: 2022-08-19 12:49:16.721538\n",
      "resetting env. episode 7707, reward total was -15.0. running mean: -16.755333122693262, timestamp: 2022-08-19 12:49:24.325627\n",
      "resetting env. episode 7708, reward total was -16.0. running mean: -16.74777979146633, timestamp: 2022-08-19 12:49:30.528699\n",
      "resetting env. episode 7709, reward total was -20.0. running mean: -16.780301993551664, timestamp: 2022-08-19 12:49:36.384768\n",
      "resetting env. episode 7710, reward total was -16.0. running mean: -16.77249897361615, timestamp: 2022-08-19 12:49:41.965832\n",
      "resetting env. episode 7711, reward total was -18.0. running mean: -16.784773983879987, timestamp: 2022-08-19 12:49:48.423909\n",
      "resetting env. episode 7712, reward total was -15.0. running mean: -16.766926244041187, timestamp: 2022-08-19 12:49:55.107992\n",
      "resetting env. episode 7713, reward total was -16.0. running mean: -16.759256981600775, timestamp: 2022-08-19 12:50:01.878067\n",
      "resetting env. episode 7714, reward total was -15.0. running mean: -16.741664411784765, timestamp: 2022-08-19 12:50:10.026162\n",
      "resetting env. episode 7715, reward total was -19.0. running mean: -16.76424776766692, timestamp: 2022-08-19 12:50:17.497251\n",
      "resetting env. episode 7716, reward total was -18.0. running mean: -16.77660528999025, timestamp: 2022-08-19 12:50:24.489331\n",
      "resetting env. episode 7717, reward total was -14.0. running mean: -16.748839237090348, timestamp: 2022-08-19 12:50:30.250399\n",
      "resetting env. episode 7718, reward total was -18.0. running mean: -16.761350844719445, timestamp: 2022-08-19 12:50:37.686486\n",
      "resetting env. episode 7719, reward total was -17.0. running mean: -16.763737336272253, timestamp: 2022-08-19 12:50:42.893549\n",
      "resetting env. episode 7720, reward total was -16.0. running mean: -16.75609996290953, timestamp: 2022-08-19 12:50:49.080620\n",
      "resetting env. episode 7721, reward total was -15.0. running mean: -16.738538963280433, timestamp: 2022-08-19 12:50:55.645701\n",
      "resetting env. episode 7722, reward total was -15.0. running mean: -16.721153573647626, timestamp: 2022-08-19 12:51:03.934793\n",
      "resetting env. episode 7723, reward total was -16.0. running mean: -16.71394203791115, timestamp: 2022-08-19 12:51:10.739872\n",
      "resetting env. episode 7724, reward total was -14.0. running mean: -16.686802617532038, timestamp: 2022-08-19 12:51:18.618965\n",
      "resetting env. episode 7725, reward total was -17.0. running mean: -16.68993459135672, timestamp: 2022-08-19 12:51:24.561034\n",
      "resetting env. episode 7726, reward total was -17.0. running mean: -16.693035245443156, timestamp: 2022-08-19 12:51:33.033934\n",
      "resetting env. episode 7727, reward total was -18.0. running mean: -16.706104892988723, timestamp: 2022-08-19 12:51:38.967002\n",
      "resetting env. episode 7728, reward total was -18.0. running mean: -16.719043844058834, timestamp: 2022-08-19 12:51:45.531080\n",
      "resetting env. episode 7729, reward total was -16.0. running mean: -16.711853405618246, timestamp: 2022-08-19 12:51:51.081144\n",
      "resetting env. episode 7730, reward total was -15.0. running mean: -16.694734871562062, timestamp: 2022-08-19 12:51:58.151225\n",
      "resetting env. episode 7731, reward total was -15.0. running mean: -16.67778752284644, timestamp: 2022-08-19 12:52:04.590302\n",
      "resetting env. episode 7732, reward total was -21.0. running mean: -16.721009647617976, timestamp: 2022-08-19 12:52:10.977376\n",
      "resetting env. episode 7733, reward total was -12.0. running mean: -16.673799551141798, timestamp: 2022-08-19 12:52:19.417475\n",
      "resetting env. episode 7734, reward total was -19.0. running mean: -16.69706155563038, timestamp: 2022-08-19 12:52:26.108551\n",
      "resetting env. episode 7735, reward total was -17.0. running mean: -16.700090940074077, timestamp: 2022-08-19 12:52:32.053619\n",
      "resetting env. episode 7736, reward total was -19.0. running mean: -16.723090030673337, timestamp: 2022-08-19 12:52:39.424708\n",
      "resetting env. episode 7737, reward total was -17.0. running mean: -16.725859130366604, timestamp: 2022-08-19 12:52:46.795793\n",
      "resetting env. episode 7738, reward total was -17.0. running mean: -16.72860053906294, timestamp: 2022-08-19 12:52:56.057900\n",
      "resetting env. episode 7739, reward total was -17.0. running mean: -16.73131453367231, timestamp: 2022-08-19 12:53:03.886989\n",
      "resetting env. episode 7740, reward total was -18.0. running mean: -16.744001388335587, timestamp: 2022-08-19 12:53:11.297075\n",
      "resetting env. episode 7741, reward total was -17.0. running mean: -16.74656137445223, timestamp: 2022-08-19 12:53:17.731152\n",
      "resetting env. episode 7742, reward total was -16.0. running mean: -16.73909576070771, timestamp: 2022-08-19 12:53:25.572241\n",
      "resetting env. episode 7743, reward total was -19.0. running mean: -16.761704803100635, timestamp: 2022-08-19 12:53:31.690315\n",
      "resetting env. episode 7744, reward total was -8.0. running mean: -16.67408775506963, timestamp: 2022-08-19 12:53:40.634934\n",
      "resetting env. episode 7745, reward total was -17.0. running mean: -16.677346877518932, timestamp: 2022-08-19 12:53:46.882598\n",
      "resetting env. episode 7746, reward total was -17.0. running mean: -16.680573408743744, timestamp: 2022-08-19 12:53:53.761676\n",
      "resetting env. episode 7747, reward total was -17.0. running mean: -16.68376767465631, timestamp: 2022-08-19 12:54:00.210751\n",
      "resetting env. episode 7748, reward total was -18.0. running mean: -16.696929997909745, timestamp: 2022-08-19 12:54:04.818808\n",
      "resetting env. episode 7749, reward total was -15.0. running mean: -16.679960697930646, timestamp: 2022-08-19 12:54:11.736884\n",
      "resetting env. episode 7750, reward total was -19.0. running mean: -16.70316109095134, timestamp: 2022-08-19 12:54:16.871941\n",
      "resetting env. episode 7751, reward total was -15.0. running mean: -16.686129480041824, timestamp: 2022-08-19 12:54:23.552019\n",
      "resetting env. episode 7752, reward total was -18.0. running mean: -16.699268185241404, timestamp: 2022-08-19 12:54:30.853105\n",
      "resetting env. episode 7753, reward total was -14.0. running mean: -16.672275503388992, timestamp: 2022-08-19 12:54:37.640182\n",
      "resetting env. episode 7754, reward total was -14.0. running mean: -16.6455527483551, timestamp: 2022-08-19 12:54:45.281267\n",
      "resetting env. episode 7755, reward total was -17.0. running mean: -16.64909722087155, timestamp: 2022-08-19 12:54:50.850330\n",
      "resetting env. episode 7756, reward total was -17.0. running mean: -16.652606248662835, timestamp: 2022-08-19 12:54:57.155404\n",
      "resetting env. episode 7757, reward total was -12.0. running mean: -16.606080186176207, timestamp: 2022-08-19 12:55:04.496490\n",
      "resetting env. episode 7758, reward total was -17.0. running mean: -16.610019384314448, timestamp: 2022-08-19 12:55:11.383567\n",
      "resetting env. episode 7759, reward total was -20.0. running mean: -16.6439191904713, timestamp: 2022-08-19 12:55:17.114577\n",
      "resetting env. episode 7760, reward total was -17.0. running mean: -16.647479998566588, timestamp: 2022-08-19 12:55:23.154647\n",
      "resetting env. episode 7761, reward total was -12.0. running mean: -16.601005198580925, timestamp: 2022-08-19 12:55:31.103740\n",
      "resetting env. episode 7762, reward total was -15.0. running mean: -16.584995146595116, timestamp: 2022-08-19 12:55:37.593809\n",
      "resetting env. episode 7763, reward total was -18.0. running mean: -16.599145195129164, timestamp: 2022-08-19 12:55:44.549415\n",
      "resetting env. episode 7764, reward total was -17.0. running mean: -16.603153743177874, timestamp: 2022-08-19 12:55:51.960499\n",
      "resetting env. episode 7765, reward total was -17.0. running mean: -16.607122205746098, timestamp: 2022-08-19 12:55:59.006581\n",
      "resetting env. episode 7766, reward total was -15.0. running mean: -16.591050983688636, timestamp: 2022-08-19 12:56:05.240649\n",
      "resetting env. episode 7767, reward total was -19.0. running mean: -16.61514047385175, timestamp: 2022-08-19 12:56:12.244730\n",
      "resetting env. episode 7768, reward total was -18.0. running mean: -16.62898906911323, timestamp: 2022-08-19 12:56:18.564804\n",
      "resetting env. episode 7769, reward total was -17.0. running mean: -16.6326991784221, timestamp: 2022-08-19 12:56:26.915895\n",
      "resetting env. episode 7770, reward total was -18.0. running mean: -16.64637218663788, timestamp: 2022-08-19 12:56:33.464486\n",
      "resetting env. episode 7771, reward total was -17.0. running mean: -16.649908464771503, timestamp: 2022-08-19 12:56:39.505559\n",
      "resetting env. episode 7772, reward total was -20.0. running mean: -16.683409380123788, timestamp: 2022-08-19 12:56:45.760627\n",
      "resetting env. episode 7773, reward total was -20.0. running mean: -16.71657528632255, timestamp: 2022-08-19 12:56:51.296689\n",
      "resetting env. episode 7774, reward total was -11.0. running mean: -16.65940953345932, timestamp: 2022-08-19 12:56:59.099779\n",
      "resetting env. episode 7775, reward total was -20.0. running mean: -16.69281543812473, timestamp: 2022-08-19 12:57:04.877366\n",
      "resetting env. episode 7776, reward total was -18.0. running mean: -16.705887283743483, timestamp: 2022-08-19 12:57:10.583428\n",
      "resetting env. episode 7777, reward total was -15.0. running mean: -16.688828410906048, timestamp: 2022-08-19 12:57:18.293514\n",
      "resetting env. episode 7778, reward total was -21.0. running mean: -16.73194012679699, timestamp: 2022-08-19 12:57:24.419583\n",
      "resetting env. episode 7779, reward total was -17.0. running mean: -16.73462072552902, timestamp: 2022-08-19 12:57:30.521653\n",
      "resetting env. episode 7780, reward total was -11.0. running mean: -16.67727451827373, timestamp: 2022-08-19 12:57:38.207739\n",
      "resetting env. episode 7781, reward total was -13.0. running mean: -16.640501773090993, timestamp: 2022-08-19 12:57:45.736822\n",
      "resetting env. episode 7782, reward total was -16.0. running mean: -16.634096755360083, timestamp: 2022-08-19 12:57:51.088886\n",
      "resetting env. episode 7783, reward total was -17.0. running mean: -16.637755787806483, timestamp: 2022-08-19 12:57:56.760946\n",
      "resetting env. episode 7784, reward total was -19.0. running mean: -16.66137822992842, timestamp: 2022-08-19 12:58:02.181007\n",
      "resetting env. episode 7785, reward total was -13.0. running mean: -16.624764447629136, timestamp: 2022-08-19 12:58:08.966082\n",
      "resetting env. episode 7786, reward total was -16.0. running mean: -16.618516803152843, timestamp: 2022-08-19 12:58:15.268151\n",
      "resetting env. episode 7787, reward total was -17.0. running mean: -16.622331635121316, timestamp: 2022-08-19 12:58:21.276219\n",
      "resetting env. episode 7788, reward total was -14.0. running mean: -16.596108318770103, timestamp: 2022-08-19 12:58:27.428289\n",
      "resetting env. episode 7789, reward total was -16.0. running mean: -16.590147235582403, timestamp: 2022-08-19 12:58:34.209527\n",
      "resetting env. episode 7790, reward total was -17.0. running mean: -16.59424576322658, timestamp: 2022-08-19 12:58:40.419597\n",
      "resetting env. episode 7791, reward total was -17.0. running mean: -16.598303305594317, timestamp: 2022-08-19 12:58:46.725667\n",
      "resetting env. episode 7792, reward total was -17.0. running mean: -16.602320272538375, timestamp: 2022-08-19 12:58:53.156740\n",
      "resetting env. episode 7793, reward total was -17.0. running mean: -16.606297069812992, timestamp: 2022-08-19 12:59:00.149816\n",
      "resetting env. episode 7794, reward total was -20.0. running mean: -16.64023409911486, timestamp: 2022-08-19 12:59:05.657875\n",
      "resetting env. episode 7795, reward total was -17.0. running mean: -16.643831758123714, timestamp: 2022-08-19 12:59:10.863932\n",
      "resetting env. episode 7796, reward total was -18.0. running mean: -16.657393440542474, timestamp: 2022-08-19 12:59:18.201015\n",
      "resetting env. episode 7797, reward total was -15.0. running mean: -16.64081950613705, timestamp: 2022-08-19 12:59:24.886092\n",
      "resetting env. episode 7798, reward total was -18.0. running mean: -16.654411311075677, timestamp: 2022-08-19 12:59:30.811154\n",
      "resetting env. episode 7799, reward total was -17.0. running mean: -16.657867197964922, timestamp: 2022-08-19 12:59:36.585221\n",
      "resetting env. episode 7800, reward total was -13.0. running mean: -16.62128852598527, timestamp: 2022-08-19 12:59:44.772310\n",
      "resetting env. episode 7801, reward total was -17.0. running mean: -16.62507564072542, timestamp: 2022-08-19 12:59:51.805391\n",
      "resetting env. episode 7802, reward total was -16.0. running mean: -16.618824884318165, timestamp: 2022-08-19 12:59:58.707468\n",
      "resetting env. episode 7803, reward total was -20.0. running mean: -16.652636635474984, timestamp: 2022-08-19 13:00:03.474522\n",
      "resetting env. episode 7804, reward total was -18.0. running mean: -16.666110269120235, timestamp: 2022-08-19 13:00:10.500603\n",
      "resetting env. episode 7805, reward total was -13.0. running mean: -16.629449166429033, timestamp: 2022-08-19 13:00:17.310682\n",
      "resetting env. episode 7806, reward total was -19.0. running mean: -16.653154674764743, timestamp: 2022-08-19 13:00:23.675283\n",
      "resetting env. episode 7807, reward total was -17.0. running mean: -16.656623128017095, timestamp: 2022-08-19 13:00:30.237357\n",
      "resetting env. episode 7808, reward total was -16.0. running mean: -16.650056896736924, timestamp: 2022-08-19 13:00:35.468414\n",
      "resetting env. episode 7809, reward total was -14.0. running mean: -16.623556327769556, timestamp: 2022-08-19 13:00:42.592497\n",
      "resetting env. episode 7810, reward total was -15.0. running mean: -16.60732076449186, timestamp: 2022-08-19 13:00:49.291575\n",
      "resetting env. episode 7811, reward total was -17.0. running mean: -16.611247556846944, timestamp: 2022-08-19 13:00:55.161643\n",
      "resetting env. episode 7812, reward total was -12.0. running mean: -16.565135081278477, timestamp: 2022-08-19 13:01:03.799742\n",
      "resetting env. episode 7813, reward total was -17.0. running mean: -16.569483730465695, timestamp: 2022-08-19 13:01:11.031825\n",
      "resetting env. episode 7814, reward total was -17.0. running mean: -16.57378889316104, timestamp: 2022-08-19 13:01:17.220896\n",
      "resetting env. episode 7815, reward total was -16.0. running mean: -16.56805100422943, timestamp: 2022-08-19 13:01:22.122953\n",
      "resetting env. episode 7816, reward total was -18.0. running mean: -16.58237049418714, timestamp: 2022-08-19 13:01:27.995021\n",
      "resetting env. episode 7817, reward total was -17.0. running mean: -16.58654678924527, timestamp: 2022-08-19 13:01:35.220636\n",
      "resetting env. episode 7818, reward total was -19.0. running mean: -16.610681321352818, timestamp: 2022-08-19 13:01:42.252717\n",
      "resetting env. episode 7819, reward total was -18.0. running mean: -16.62457450813929, timestamp: 2022-08-19 13:01:48.574791\n",
      "resetting env. episode 7820, reward total was -11.0. running mean: -16.568328763057895, timestamp: 2022-08-19 13:01:54.697864\n",
      "resetting env. episode 7821, reward total was -14.0. running mean: -16.542645475427317, timestamp: 2022-08-19 13:02:02.596955\n",
      "resetting env. episode 7822, reward total was -15.0. running mean: -16.527219020673044, timestamp: 2022-08-19 13:02:09.102036\n",
      "resetting env. episode 7823, reward total was -16.0. running mean: -16.521946830466312, timestamp: 2022-08-19 13:02:15.435107\n",
      "resetting env. episode 7824, reward total was -14.0. running mean: -16.49672736216165, timestamp: 2022-08-19 13:02:21.892181\n",
      "resetting env. episode 7825, reward total was -19.0. running mean: -16.521760088540034, timestamp: 2022-08-19 13:02:27.068239\n",
      "resetting env. episode 7826, reward total was -16.0. running mean: -16.516542487654633, timestamp: 2022-08-19 13:02:32.782314\n",
      "resetting env. episode 7827, reward total was -16.0. running mean: -16.511377062778084, timestamp: 2022-08-19 13:02:38.876378\n",
      "resetting env. episode 7828, reward total was -18.0. running mean: -16.526263292150304, timestamp: 2022-08-19 13:02:45.985462\n",
      "resetting env. episode 7829, reward total was -15.0. running mean: -16.5110006592288, timestamp: 2022-08-19 13:02:52.788543\n",
      "resetting env. episode 7830, reward total was -13.0. running mean: -16.475890652636508, timestamp: 2022-08-19 13:03:00.675634\n",
      "resetting env. episode 7831, reward total was -19.0. running mean: -16.501131746110143, timestamp: 2022-08-19 13:03:07.337712\n",
      "resetting env. episode 7832, reward total was -20.0. running mean: -16.536120428649042, timestamp: 2022-08-19 13:03:13.287780\n",
      "resetting env. episode 7833, reward total was -12.0. running mean: -16.490759224362552, timestamp: 2022-08-19 13:03:20.241860\n",
      "resetting env. episode 7834, reward total was -16.0. running mean: -16.485851632118926, timestamp: 2022-08-19 13:03:27.415947\n",
      "resetting env. episode 7835, reward total was -18.0. running mean: -16.500993115797737, timestamp: 2022-08-19 13:03:35.286040\n",
      "resetting env. episode 7836, reward total was -12.0. running mean: -16.45598318463976, timestamp: 2022-08-19 13:03:41.242111\n",
      "resetting env. episode 7837, reward total was -9.0. running mean: -16.381423352793362, timestamp: 2022-08-19 13:03:49.385207\n",
      "resetting env. episode 7838, reward total was -17.0. running mean: -16.38760911926543, timestamp: 2022-08-19 13:03:54.926270\n",
      "resetting env. episode 7839, reward total was -17.0. running mean: -16.393733028072777, timestamp: 2022-08-19 13:04:01.875353\n",
      "resetting env. episode 7840, reward total was -10.0. running mean: -16.32979569779205, timestamp: 2022-08-19 13:04:09.816445\n",
      "resetting env. episode 7841, reward total was -18.0. running mean: -16.34649774081413, timestamp: 2022-08-19 13:04:15.736517\n",
      "resetting env. episode 7842, reward total was -17.0. running mean: -16.353032763405988, timestamp: 2022-08-19 13:04:23.140607\n",
      "resetting env. episode 7843, reward total was -15.0. running mean: -16.339502435771927, timestamp: 2022-08-19 13:04:29.543682\n",
      "resetting env. episode 7844, reward total was -16.0. running mean: -16.336107411414208, timestamp: 2022-08-19 13:04:37.100768\n",
      "resetting env. episode 7845, reward total was -18.0. running mean: -16.352746337300065, timestamp: 2022-08-19 13:04:43.555844\n",
      "resetting env. episode 7846, reward total was -14.0. running mean: -16.329218873927065, timestamp: 2022-08-19 13:04:50.843931\n",
      "resetting env. episode 7847, reward total was -17.0. running mean: -16.335926685187797, timestamp: 2022-08-19 13:04:56.864003\n",
      "resetting env. episode 7848, reward total was -15.0. running mean: -16.322567418335918, timestamp: 2022-08-19 13:05:04.135085\n",
      "resetting env. episode 7849, reward total was -18.0. running mean: -16.33934174415256, timestamp: 2022-08-19 13:05:11.509174\n",
      "resetting env. episode 7850, reward total was -17.0. running mean: -16.345948326711035, timestamp: 2022-08-19 13:05:17.544001\n",
      "resetting env. episode 7851, reward total was -11.0. running mean: -16.292488843443923, timestamp: 2022-08-19 13:05:23.842074\n",
      "resetting env. episode 7852, reward total was -15.0. running mean: -16.279563955009483, timestamp: 2022-08-19 13:05:30.704686\n",
      "resetting env. episode 7853, reward total was -16.0. running mean: -16.27676831545939, timestamp: 2022-08-19 13:05:39.223785\n",
      "resetting env. episode 7854, reward total was -17.0. running mean: -16.284000632304796, timestamp: 2022-08-19 13:05:45.392860\n",
      "resetting env. episode 7855, reward total was -16.0. running mean: -16.281160625981748, timestamp: 2022-08-19 13:05:52.634947\n",
      "resetting env. episode 7856, reward total was -18.0. running mean: -16.29834901972193, timestamp: 2022-08-19 13:05:58.055530\n",
      "resetting env. episode 7857, reward total was -17.0. running mean: -16.30536552952471, timestamp: 2022-08-19 13:06:04.562610\n",
      "resetting env. episode 7858, reward total was -17.0. running mean: -16.312311874229465, timestamp: 2022-08-19 13:06:12.010694\n",
      "resetting env. episode 7859, reward total was -16.0. running mean: -16.30918875548717, timestamp: 2022-08-19 13:06:18.143766\n",
      "resetting env. episode 7860, reward total was -15.0. running mean: -16.2960968679323, timestamp: 2022-08-19 13:06:24.337839\n",
      "resetting env. episode 7861, reward total was -17.0. running mean: -16.30313589925298, timestamp: 2022-08-19 13:06:30.651914\n",
      "resetting env. episode 7862, reward total was -18.0. running mean: -16.32010454026045, timestamp: 2022-08-19 13:06:36.336984\n",
      "resetting env. episode 7863, reward total was -18.0. running mean: -16.336903494857843, timestamp: 2022-08-19 13:06:41.993049\n",
      "resetting env. episode 7864, reward total was -17.0. running mean: -16.343534459909264, timestamp: 2022-08-19 13:06:51.057156\n",
      "resetting env. episode 7865, reward total was -16.0. running mean: -16.34009911531017, timestamp: 2022-08-19 13:06:57.342752\n",
      "resetting env. episode 7866, reward total was -21.0. running mean: -16.38669812415707, timestamp: 2022-08-19 13:07:03.204820\n",
      "resetting env. episode 7867, reward total was -16.0. running mean: -16.3828311429155, timestamp: 2022-08-19 13:07:10.023900\n",
      "resetting env. episode 7868, reward total was -13.0. running mean: -16.34900283148634, timestamp: 2022-08-19 13:07:17.135985\n",
      "resetting env. episode 7869, reward total was -14.0. running mean: -16.325512803171478, timestamp: 2022-08-19 13:07:23.602061\n",
      "resetting env. episode 7870, reward total was -16.0. running mean: -16.322257675139763, timestamp: 2022-08-19 13:07:31.158676\n",
      "resetting env. episode 7871, reward total was -18.0. running mean: -16.339035098388365, timestamp: 2022-08-19 13:07:37.212749\n",
      "resetting env. episode 7872, reward total was -11.0. running mean: -16.28564474740448, timestamp: 2022-08-19 13:07:44.472212\n",
      "resetting env. episode 7873, reward total was -13.0. running mean: -16.252788299930433, timestamp: 2022-08-19 13:07:50.671284\n",
      "resetting env. episode 7874, reward total was -19.0. running mean: -16.28026041693113, timestamp: 2022-08-19 13:07:56.098348\n",
      "resetting env. episode 7875, reward total was -19.0. running mean: -16.30745781276182, timestamp: 2022-08-19 13:08:01.505414\n",
      "resetting env. episode 7876, reward total was -19.0. running mean: -16.334383234634206, timestamp: 2022-08-19 13:08:07.109476\n",
      "resetting env. episode 7877, reward total was -16.0. running mean: -16.331039402287864, timestamp: 2022-08-19 13:08:14.042558\n",
      "resetting env. episode 7878, reward total was -18.0. running mean: -16.347729008264984, timestamp: 2022-08-19 13:08:19.786626\n",
      "resetting env. episode 7879, reward total was -19.0. running mean: -16.374251718182336, timestamp: 2022-08-19 13:08:24.713682\n",
      "resetting env. episode 7880, reward total was -14.0. running mean: -16.350509201000513, timestamp: 2022-08-19 13:08:30.672282\n",
      "resetting env. episode 7881, reward total was -15.0. running mean: -16.337004108990506, timestamp: 2022-08-19 13:08:37.043358\n",
      "resetting env. episode 7882, reward total was -15.0. running mean: -16.3236340679006, timestamp: 2022-08-19 13:08:44.973452\n",
      "resetting env. episode 7883, reward total was -13.0. running mean: -16.290397727221592, timestamp: 2022-08-19 13:08:51.253527\n",
      "resetting env. episode 7884, reward total was -19.0. running mean: -16.317493749949378, timestamp: 2022-08-19 13:08:57.117592\n",
      "resetting env. episode 7885, reward total was -16.0. running mean: -16.314318812449883, timestamp: 2022-08-19 13:09:03.560206\n",
      "resetting env. episode 7886, reward total was -17.0. running mean: -16.321175624325384, timestamp: 2022-08-19 13:09:10.074281\n",
      "resetting env. episode 7887, reward total was -15.0. running mean: -16.30796386808213, timestamp: 2022-08-19 13:09:17.752370\n",
      "resetting env. episode 7888, reward total was -14.0. running mean: -16.28488422940131, timestamp: 2022-08-19 13:09:24.079443\n",
      "resetting env. episode 7889, reward total was -20.0. running mean: -16.322035387107295, timestamp: 2022-08-19 13:09:28.778497\n",
      "resetting env. episode 7890, reward total was -17.0. running mean: -16.328815033236225, timestamp: 2022-08-19 13:09:34.431563\n",
      "resetting env. episode 7891, reward total was -11.0. running mean: -16.27552688290386, timestamp: 2022-08-19 13:09:43.229666\n",
      "resetting env. episode 7892, reward total was -15.0. running mean: -16.262771614074822, timestamp: 2022-08-19 13:09:50.873753\n",
      "resetting env. episode 7893, reward total was -21.0. running mean: -16.310143897934076, timestamp: 2022-08-19 13:09:57.070824\n",
      "resetting env. episode 7894, reward total was -16.0. running mean: -16.307042458954736, timestamp: 2022-08-19 13:10:03.518902\n",
      "resetting env. episode 7895, reward total was -15.0. running mean: -16.293972034365186, timestamp: 2022-08-19 13:10:10.305979\n",
      "resetting env. episode 7896, reward total was -14.0. running mean: -16.271032314021536, timestamp: 2022-08-19 13:10:16.196047\n",
      "resetting env. episode 7897, reward total was -17.0. running mean: -16.278321990881324, timestamp: 2022-08-19 13:10:22.825125\n",
      "resetting env. episode 7898, reward total was -17.0. running mean: -16.28553877097251, timestamp: 2022-08-19 13:10:29.080197\n",
      "resetting env. episode 7899, reward total was -9.0. running mean: -16.212683383262785, timestamp: 2022-08-19 13:10:37.101290\n",
      "resetting env. episode 7900, reward total was -16.0. running mean: -16.21055654943016, timestamp: 2022-08-19 13:10:44.089371\n",
      "resetting env. episode 7901, reward total was -17.0. running mean: -16.21845098393586, timestamp: 2022-08-19 13:10:51.889460\n",
      "resetting env. episode 7902, reward total was -16.0. running mean: -16.2162664740965, timestamp: 2022-08-19 13:10:58.520534\n",
      "resetting env. episode 7903, reward total was -14.0. running mean: -16.194103809355536, timestamp: 2022-08-19 13:11:06.168624\n",
      "resetting env. episode 7904, reward total was -17.0. running mean: -16.202162771261982, timestamp: 2022-08-19 13:11:12.438695\n",
      "resetting env. episode 7905, reward total was -12.0. running mean: -16.160141143549364, timestamp: 2022-08-19 13:11:19.151772\n",
      "resetting env. episode 7906, reward total was -12.0. running mean: -16.11853973211387, timestamp: 2022-08-19 13:11:27.399868\n",
      "resetting env. episode 7907, reward total was -15.0. running mean: -16.10735433479273, timestamp: 2022-08-19 13:11:33.055935\n",
      "resetting env. episode 7908, reward total was -20.0. running mean: -16.146280791444806, timestamp: 2022-08-19 13:11:38.753001\n",
      "resetting env. episode 7909, reward total was -14.0. running mean: -16.124817983530356, timestamp: 2022-08-19 13:11:45.568078\n",
      "resetting env. episode 7910, reward total was -15.0. running mean: -16.11356980369505, timestamp: 2022-08-19 13:11:52.998164\n",
      "resetting env. episode 7911, reward total was -19.0. running mean: -16.1424341056581, timestamp: 2022-08-19 13:11:59.164287\n",
      "resetting env. episode 7912, reward total was -14.0. running mean: -16.12100976460152, timestamp: 2022-08-19 13:12:07.179377\n",
      "resetting env. episode 7913, reward total was -17.0. running mean: -16.129799666955506, timestamp: 2022-08-19 13:12:14.449461\n",
      "resetting env. episode 7914, reward total was -15.0. running mean: -16.11850167028595, timestamp: 2022-08-19 13:12:21.719078\n",
      "resetting env. episode 7915, reward total was -19.0. running mean: -16.147316653583093, timestamp: 2022-08-19 13:12:29.204692\n",
      "resetting env. episode 7916, reward total was -16.0. running mean: -16.145843487047262, timestamp: 2022-08-19 13:12:35.693771\n",
      "resetting env. episode 7917, reward total was -16.0. running mean: -16.144385052176787, timestamp: 2022-08-19 13:12:41.737834\n",
      "resetting env. episode 7918, reward total was -19.0. running mean: -16.172941201655018, timestamp: 2022-08-19 13:12:49.043923\n",
      "resetting env. episode 7919, reward total was -16.0. running mean: -16.171211789638466, timestamp: 2022-08-19 13:12:55.167993\n",
      "resetting env. episode 7920, reward total was -15.0. running mean: -16.15949967174208, timestamp: 2022-08-19 13:13:01.501060\n",
      "resetting env. episode 7921, reward total was -11.0. running mean: -16.10790467502466, timestamp: 2022-08-19 13:13:08.757142\n",
      "resetting env. episode 7922, reward total was -15.0. running mean: -16.096825628274413, timestamp: 2022-08-19 13:13:15.240215\n",
      "resetting env. episode 7923, reward total was -20.0. running mean: -16.13585737199167, timestamp: 2022-08-19 13:13:20.432277\n",
      "resetting env. episode 7924, reward total was -17.0. running mean: -16.14449879827175, timestamp: 2022-08-19 13:13:28.273361\n",
      "resetting env. episode 7925, reward total was -20.0. running mean: -16.183053810289035, timestamp: 2022-08-19 13:13:34.173430\n",
      "resetting env. episode 7926, reward total was -10.0. running mean: -16.121223272186146, timestamp: 2022-08-19 13:13:41.994040\n",
      "resetting env. episode 7927, reward total was -21.0. running mean: -16.170011039464285, timestamp: 2022-08-19 13:13:48.422114\n",
      "resetting env. episode 7928, reward total was -21.0. running mean: -16.21831092906964, timestamp: 2022-08-19 13:13:54.943186\n",
      "resetting env. episode 7929, reward total was -15.0. running mean: -16.206127819778942, timestamp: 2022-08-19 13:14:01.959789\n",
      "resetting env. episode 7930, reward total was -21.0. running mean: -16.254066541581153, timestamp: 2022-08-19 13:14:09.697877\n",
      "resetting env. episode 7931, reward total was -15.0. running mean: -16.24152587616534, timestamp: 2022-08-19 13:14:16.510952\n",
      "resetting env. episode 7932, reward total was -15.0. running mean: -16.229110617403684, timestamp: 2022-08-19 13:14:21.661014\n",
      "resetting env. episode 7933, reward total was -17.0. running mean: -16.236819511229648, timestamp: 2022-08-19 13:14:28.654090\n",
      "resetting env. episode 7934, reward total was -18.0. running mean: -16.25445131611735, timestamp: 2022-08-19 13:14:34.765156\n",
      "resetting env. episode 7935, reward total was -16.0. running mean: -16.251906802956178, timestamp: 2022-08-19 13:14:42.542245\n",
      "resetting env. episode 7936, reward total was -14.0. running mean: -16.22938773492662, timestamp: 2022-08-19 13:14:49.564844\n",
      "resetting env. episode 7937, reward total was -17.0. running mean: -16.237093857577353, timestamp: 2022-08-19 13:14:56.840926\n",
      "resetting env. episode 7938, reward total was -15.0. running mean: -16.22472291900158, timestamp: 2022-08-19 13:15:02.609991\n",
      "resetting env. episode 7939, reward total was -15.0. running mean: -16.212475689811562, timestamp: 2022-08-19 13:15:09.178063\n",
      "resetting env. episode 7940, reward total was -20.0. running mean: -16.250350932913445, timestamp: 2022-08-19 13:15:15.029128\n",
      "resetting env. episode 7941, reward total was -17.0. running mean: -16.257847423584312, timestamp: 2022-08-19 13:15:22.850215\n",
      "resetting env. episode 7942, reward total was -18.0. running mean: -16.27526894934847, timestamp: 2022-08-19 13:15:28.483278\n",
      "resetting env. episode 7943, reward total was -11.0. running mean: -16.222516259854984, timestamp: 2022-08-19 13:15:36.494368\n",
      "resetting env. episode 7944, reward total was -9.0. running mean: -16.150291097256435, timestamp: 2022-08-19 13:15:44.499455\n",
      "resetting env. episode 7945, reward total was -19.0. running mean: -16.17878818628387, timestamp: 2022-08-19 13:15:51.406530\n",
      "resetting env. episode 7946, reward total was -11.0. running mean: -16.12700030442103, timestamp: 2022-08-19 13:16:00.182631\n",
      "resetting env. episode 7947, reward total was -15.0. running mean: -16.11573030137682, timestamp: 2022-08-19 13:16:07.334709\n",
      "resetting env. episode 7948, reward total was -16.0. running mean: -16.11457299836305, timestamp: 2022-08-19 13:16:15.375798\n",
      "resetting env. episode 7949, reward total was -17.0. running mean: -16.123427268379423, timestamp: 2022-08-19 13:16:22.157872\n",
      "resetting env. episode 7950, reward total was -20.0. running mean: -16.16219299569563, timestamp: 2022-08-19 13:16:27.626934\n",
      "resetting env. episode 7951, reward total was -17.0. running mean: -16.170571065738674, timestamp: 2022-08-19 13:16:33.499001\n",
      "resetting env. episode 7952, reward total was -18.0. running mean: -16.188865355081287, timestamp: 2022-08-19 13:16:40.581080\n",
      "resetting env. episode 7953, reward total was -17.0. running mean: -16.196976701530474, timestamp: 2022-08-19 13:16:45.374133\n",
      "resetting env. episode 7954, reward total was -17.0. running mean: -16.205006934515172, timestamp: 2022-08-19 13:16:51.224204\n",
      "resetting env. episode 7955, reward total was -17.0. running mean: -16.21295686517002, timestamp: 2022-08-19 13:16:57.623275\n",
      "resetting env. episode 7956, reward total was -14.0. running mean: -16.19082729651832, timestamp: 2022-08-19 13:17:04.407351\n",
      "resetting env. episode 7957, reward total was -21.0. running mean: -16.238919023553137, timestamp: 2022-08-19 13:17:10.975959\n",
      "resetting env. episode 7958, reward total was -21.0. running mean: -16.286529833317605, timestamp: 2022-08-19 13:17:16.787021\n",
      "resetting env. episode 7959, reward total was -12.0. running mean: -16.24366453498443, timestamp: 2022-08-19 13:17:24.625111\n",
      "resetting env. episode 7960, reward total was -18.0. running mean: -16.261227889634583, timestamp: 2022-08-19 13:17:31.589191\n",
      "resetting env. episode 7961, reward total was -14.0. running mean: -16.238615610738236, timestamp: 2022-08-19 13:17:38.730272\n",
      "resetting env. episode 7962, reward total was -17.0. running mean: -16.246229454630857, timestamp: 2022-08-19 13:17:44.932345\n",
      "resetting env. episode 7963, reward total was -16.0. running mean: -16.24376716008455, timestamp: 2022-08-19 13:17:51.600420\n",
      "resetting env. episode 7964, reward total was -13.0. running mean: -16.211329488483702, timestamp: 2022-08-19 13:17:58.923506\n",
      "resetting env. episode 7965, reward total was -14.0. running mean: -16.189216193598867, timestamp: 2022-08-19 13:18:05.831583\n",
      "resetting env. episode 7966, reward total was -16.0. running mean: -16.18732403166288, timestamp: 2022-08-19 13:18:13.403670\n",
      "resetting env. episode 7967, reward total was -19.0. running mean: -16.21545079134625, timestamp: 2022-08-19 13:18:19.360740\n",
      "resetting env. episode 7968, reward total was -18.0. running mean: -16.233296283432786, timestamp: 2022-08-19 13:18:25.690816\n",
      "resetting env. episode 7969, reward total was -16.0. running mean: -16.23096332059846, timestamp: 2022-08-19 13:18:32.272414\n",
      "resetting env. episode 7970, reward total was -17.0. running mean: -16.238653687392475, timestamp: 2022-08-19 13:18:38.111483\n",
      "resetting env. episode 7971, reward total was -18.0. running mean: -16.25626715051855, timestamp: 2022-08-19 13:18:44.809558\n",
      "resetting env. episode 7972, reward total was -19.0. running mean: -16.283704479013366, timestamp: 2022-08-19 13:18:50.678628\n",
      "resetting env. episode 7973, reward total was -19.0. running mean: -16.310867434223233, timestamp: 2022-08-19 13:18:57.522708\n",
      "resetting env. episode 7974, reward total was -18.0. running mean: -16.327758759881, timestamp: 2022-08-19 13:19:03.864781\n",
      "resetting env. episode 7975, reward total was -19.0. running mean: -16.354481172282192, timestamp: 2022-08-19 13:19:11.850874\n",
      "resetting env. episode 7976, reward total was -19.0. running mean: -16.38093636055937, timestamp: 2022-08-19 13:19:18.865957\n",
      "resetting env. episode 7977, reward total was -20.0. running mean: -16.417126996953776, timestamp: 2022-08-19 13:19:24.698024\n",
      "resetting env. episode 7978, reward total was -19.0. running mean: -16.442955726984238, timestamp: 2022-08-19 13:19:31.236100\n",
      "resetting env. episode 7979, reward total was -17.0. running mean: -16.4485261697144, timestamp: 2022-08-19 13:19:38.101182\n",
      "resetting env. episode 7980, reward total was -13.0. running mean: -16.414040908017252, timestamp: 2022-08-19 13:19:44.539258\n",
      "resetting env. episode 7981, reward total was -15.0. running mean: -16.39990049893708, timestamp: 2022-08-19 13:19:51.531858\n",
      "resetting env. episode 7982, reward total was -11.0. running mean: -16.345901493947707, timestamp: 2022-08-19 13:19:59.113948\n",
      "resetting env. episode 7983, reward total was -19.0. running mean: -16.37244247900823, timestamp: 2022-08-19 13:20:05.724025\n",
      "resetting env. episode 7984, reward total was -19.0. running mean: -16.39871805421815, timestamp: 2022-08-19 13:20:10.695088\n",
      "resetting env. episode 7985, reward total was -15.0. running mean: -16.384730873675966, timestamp: 2022-08-19 13:20:17.682167\n",
      "resetting env. episode 7986, reward total was -21.0. running mean: -16.430883564939208, timestamp: 2022-08-19 13:20:23.102228\n",
      "resetting env. episode 7987, reward total was -15.0. running mean: -16.416574729289813, timestamp: 2022-08-19 13:20:30.826322\n",
      "resetting env. episode 7988, reward total was -20.0. running mean: -16.452408981996914, timestamp: 2022-08-19 13:20:36.585910\n",
      "resetting env. episode 7989, reward total was -14.0. running mean: -16.427884892176944, timestamp: 2022-08-19 13:20:44.895533\n",
      "resetting env. episode 7990, reward total was -14.0. running mean: -16.403606043255177, timestamp: 2022-08-19 13:20:52.426336\n",
      "resetting env. episode 7991, reward total was -17.0. running mean: -16.409569982822628, timestamp: 2022-08-19 13:20:59.574421\n",
      "resetting env. episode 7992, reward total was -20.0. running mean: -16.4454742829944, timestamp: 2022-08-19 13:21:04.466477\n",
      "resetting env. episode 7993, reward total was -15.0. running mean: -16.431019540164456, timestamp: 2022-08-19 13:21:10.112551\n",
      "resetting env. episode 7994, reward total was -15.0. running mean: -16.41670934476281, timestamp: 2022-08-19 13:21:17.203628\n",
      "resetting env. episode 7995, reward total was -17.0. running mean: -16.422542251315186, timestamp: 2022-08-19 13:21:23.681708\n",
      "resetting env. episode 7996, reward total was -18.0. running mean: -16.438316828802034, timestamp: 2022-08-19 13:21:28.478762\n",
      "resetting env. episode 7997, reward total was -16.0. running mean: -16.433933660514015, timestamp: 2022-08-19 13:21:33.764823\n",
      "resetting env. episode 7998, reward total was -19.0. running mean: -16.459594323908874, timestamp: 2022-08-19 13:21:41.143912\n",
      "resetting env. episode 7999, reward total was -15.0. running mean: -16.444998380669784, timestamp: 2022-08-19 13:21:46.835982\n",
      "resetting env. episode 8000, reward total was -21.0. running mean: -16.490548396863087, timestamp: 2022-08-19 13:21:52.233041\n",
      "resetting env. episode 8001, reward total was -18.0. running mean: -16.505642912894455, timestamp: 2022-08-19 13:21:58.975123\n",
      "resetting env. episode 8002, reward total was -17.0. running mean: -16.51058648376551, timestamp: 2022-08-19 13:22:06.237208\n",
      "resetting env. episode 8003, reward total was -16.0. running mean: -16.505480618927855, timestamp: 2022-08-19 13:22:12.505281\n",
      "resetting env. episode 8004, reward total was -14.0. running mean: -16.480425812738577, timestamp: 2022-08-19 13:22:19.163359\n",
      "resetting env. episode 8005, reward total was -18.0. running mean: -16.49562155461119, timestamp: 2022-08-19 13:22:25.252431\n",
      "resetting env. episode 8006, reward total was -21.0. running mean: -16.54066533906508, timestamp: 2022-08-19 13:22:30.169490\n",
      "resetting env. episode 8007, reward total was -14.0. running mean: -16.51525868567443, timestamp: 2022-08-19 13:22:37.383575\n",
      "resetting env. episode 8008, reward total was -15.0. running mean: -16.50010609881768, timestamp: 2022-08-19 13:22:43.887653\n",
      "resetting env. episode 8009, reward total was -15.0. running mean: -16.485105037829502, timestamp: 2022-08-19 13:22:49.754720\n",
      "resetting env. episode 8010, reward total was -12.0. running mean: -16.440253987451207, timestamp: 2022-08-19 13:22:57.452810\n",
      "resetting env. episode 8011, reward total was -15.0. running mean: -16.425851447576694, timestamp: 2022-08-19 13:23:05.514908\n",
      "resetting env. episode 8012, reward total was -15.0. running mean: -16.411592933100927, timestamp: 2022-08-19 13:23:11.463978\n",
      "resetting env. episode 8013, reward total was -13.0. running mean: -16.377477003769915, timestamp: 2022-08-19 13:23:18.039056\n",
      "resetting env. episode 8014, reward total was -15.0. running mean: -16.363702233732216, timestamp: 2022-08-19 13:23:24.374130\n",
      "resetting env. episode 8015, reward total was -19.0. running mean: -16.390065211394894, timestamp: 2022-08-19 13:23:31.354213\n",
      "resetting env. episode 8016, reward total was -15.0. running mean: -16.376164559280944, timestamp: 2022-08-19 13:23:37.875286\n",
      "resetting env. episode 8017, reward total was -12.0. running mean: -16.332402913688135, timestamp: 2022-08-19 13:23:46.427390\n",
      "resetting env. episode 8018, reward total was -20.0. running mean: -16.369078884551254, timestamp: 2022-08-19 13:23:51.876456\n",
      "resetting env. episode 8019, reward total was -16.0. running mean: -16.36538809570574, timestamp: 2022-08-19 13:23:59.998552\n",
      "resetting env. episode 8020, reward total was -14.0. running mean: -16.341734214748683, timestamp: 2022-08-19 13:24:08.582653\n",
      "resetting env. episode 8021, reward total was -17.0. running mean: -16.3483168726012, timestamp: 2022-08-19 13:24:14.814724\n",
      "resetting env. episode 8022, reward total was -17.0. running mean: -16.354833703875187, timestamp: 2022-08-19 13:24:20.458792\n",
      "resetting env. episode 8023, reward total was -17.0. running mean: -16.361285366836437, timestamp: 2022-08-19 13:24:27.568406\n",
      "resetting env. episode 8024, reward total was -14.0. running mean: -16.337672513168073, timestamp: 2022-08-19 13:24:34.617489\n",
      "resetting env. episode 8025, reward total was -15.0. running mean: -16.32429578803639, timestamp: 2022-08-19 13:24:42.249577\n",
      "resetting env. episode 8026, reward total was -12.0. running mean: -16.281052830156028, timestamp: 2022-08-19 13:24:49.451664\n",
      "resetting env. episode 8027, reward total was -16.0. running mean: -16.27824230185447, timestamp: 2022-08-19 13:24:56.452269\n",
      "resetting env. episode 8028, reward total was -17.0. running mean: -16.285459878835926, timestamp: 2022-08-19 13:25:04.639366\n",
      "resetting env. episode 8029, reward total was -15.0. running mean: -16.272605280047564, timestamp: 2022-08-19 13:25:13.600471\n",
      "resetting env. episode 8030, reward total was -16.0. running mean: -16.26987922724709, timestamp: 2022-08-19 13:25:20.348549\n",
      "resetting env. episode 8031, reward total was -21.0. running mean: -16.317180434974617, timestamp: 2022-08-19 13:25:27.046630\n",
      "resetting env. episode 8032, reward total was -14.0. running mean: -16.29400863062487, timestamp: 2022-08-19 13:25:34.822718\n",
      "resetting env. episode 8033, reward total was -9.0. running mean: -16.22106854431862, timestamp: 2022-08-19 13:25:43.280816\n",
      "resetting env. episode 8034, reward total was -19.0. running mean: -16.248857858875436, timestamp: 2022-08-19 13:25:48.738878\n",
      "resetting env. episode 8035, reward total was -18.0. running mean: -16.266369280286682, timestamp: 2022-08-19 13:25:54.959951\n",
      "resetting env. episode 8036, reward total was -16.0. running mean: -16.263705587483816, timestamp: 2022-08-19 13:26:01.159024\n",
      "resetting env. episode 8037, reward total was -17.0. running mean: -16.27106853160898, timestamp: 2022-08-19 13:26:07.577101\n",
      "resetting env. episode 8038, reward total was -21.0. running mean: -16.31835784629289, timestamp: 2022-08-19 13:26:13.725174\n",
      "resetting env. episode 8039, reward total was -12.0. running mean: -16.275174267829964, timestamp: 2022-08-19 13:26:21.761267\n",
      "resetting env. episode 8040, reward total was -17.0. running mean: -16.282422525151667, timestamp: 2022-08-19 13:26:27.857335\n",
      "resetting env. episode 8041, reward total was -14.0. running mean: -16.25959829990015, timestamp: 2022-08-19 13:26:36.205438\n",
      "resetting env. episode 8042, reward total was -15.0. running mean: -16.24700231690115, timestamp: 2022-08-19 13:26:42.749515\n",
      "resetting env. episode 8043, reward total was -17.0. running mean: -16.25453229373214, timestamp: 2022-08-19 13:26:49.604588\n",
      "resetting env. episode 8044, reward total was -17.0. running mean: -16.26198697079482, timestamp: 2022-08-19 13:26:54.744648\n",
      "resetting env. episode 8045, reward total was -18.0. running mean: -16.27936710108687, timestamp: 2022-08-19 13:27:01.753256\n",
      "resetting env. episode 8046, reward total was -18.0. running mean: -16.296573430076, timestamp: 2022-08-19 13:27:10.314355\n",
      "resetting env. episode 8047, reward total was -17.0. running mean: -16.30360769577524, timestamp: 2022-08-19 13:27:18.904454\n",
      "resetting env. episode 8048, reward total was -17.0. running mean: -16.31057161881749, timestamp: 2022-08-19 13:27:25.289528\n",
      "resetting env. episode 8049, reward total was -9.0. running mean: -16.237465902629317, timestamp: 2022-08-19 13:27:31.453599\n",
      "resetting env. episode 8050, reward total was -18.0. running mean: -16.255091243603022, timestamp: 2022-08-19 13:27:37.506668\n",
      "resetting env. episode 8051, reward total was -15.0. running mean: -16.24254033116699, timestamp: 2022-08-19 13:27:44.812756\n",
      "resetting env. episode 8052, reward total was -11.0. running mean: -16.19011492785532, timestamp: 2022-08-19 13:27:51.255832\n",
      "resetting env. episode 8053, reward total was -17.0. running mean: -16.19821377857677, timestamp: 2022-08-19 13:27:59.166918\n",
      "resetting env. episode 8054, reward total was -12.0. running mean: -16.156231640791002, timestamp: 2022-08-19 13:28:07.332017\n",
      "resetting env. episode 8055, reward total was -13.0. running mean: -16.124669324383092, timestamp: 2022-08-19 13:28:14.725099\n",
      "resetting env. episode 8056, reward total was -15.0. running mean: -16.11342263113926, timestamp: 2022-08-19 13:28:21.827179\n",
      "resetting env. episode 8057, reward total was -18.0. running mean: -16.132288404827868, timestamp: 2022-08-19 13:28:28.426260\n",
      "resetting env. episode 8058, reward total was -17.0. running mean: -16.14096552077959, timestamp: 2022-08-19 13:28:35.748343\n",
      "resetting env. episode 8059, reward total was -20.0. running mean: -16.179555865571796, timestamp: 2022-08-19 13:28:40.275396\n",
      "resetting env. episode 8060, reward total was -14.0. running mean: -16.157760306916078, timestamp: 2022-08-19 13:28:46.556465\n",
      "resetting env. episode 8061, reward total was -15.0. running mean: -16.146182703846918, timestamp: 2022-08-19 13:28:53.127541\n",
      "resetting env. episode 8062, reward total was -17.0. running mean: -16.15472087680845, timestamp: 2022-08-19 13:29:00.368625\n",
      "resetting env. episode 8063, reward total was -15.0. running mean: -16.143173668040365, timestamp: 2022-08-19 13:29:07.066847\n",
      "resetting env. episode 8064, reward total was -10.0. running mean: -16.08174193135996, timestamp: 2022-08-19 13:29:17.388959\n",
      "resetting env. episode 8065, reward total was -17.0. running mean: -16.09092451204636, timestamp: 2022-08-19 13:29:24.023033\n",
      "resetting env. episode 8066, reward total was -15.0. running mean: -16.080015266925894, timestamp: 2022-08-19 13:29:29.396098\n",
      "resetting env. episode 8067, reward total was -12.0. running mean: -16.039215114256635, timestamp: 2022-08-19 13:29:36.469176\n",
      "resetting env. episode 8068, reward total was -14.0. running mean: -16.01882296311407, timestamp: 2022-08-19 13:29:43.297257\n",
      "resetting env. episode 8069, reward total was -18.0. running mean: -16.03863473348293, timestamp: 2022-08-19 13:29:49.436324\n",
      "resetting env. episode 8070, reward total was -19.0. running mean: -16.0682483861481, timestamp: 2022-08-19 13:29:55.796397\n",
      "resetting env. episode 8071, reward total was -14.0. running mean: -16.047565902286618, timestamp: 2022-08-19 13:30:01.637463\n",
      "resetting env. episode 8072, reward total was -19.0. running mean: -16.07709024326375, timestamp: 2022-08-19 13:30:06.671525\n",
      "resetting env. episode 8073, reward total was -18.0. running mean: -16.096319340831112, timestamp: 2022-08-19 13:30:13.884089\n",
      "resetting env. episode 8074, reward total was -15.0. running mean: -16.0853561474228, timestamp: 2022-08-19 13:30:20.312163\n",
      "resetting env. episode 8075, reward total was -20.0. running mean: -16.124502585948573, timestamp: 2022-08-19 13:30:25.453224\n",
      "resetting env. episode 8076, reward total was -14.0. running mean: -16.103257560089087, timestamp: 2022-08-19 13:30:33.828316\n",
      "resetting env. episode 8077, reward total was -19.0. running mean: -16.132224984488197, timestamp: 2022-08-19 13:30:40.156387\n",
      "resetting env. episode 8078, reward total was -14.0. running mean: -16.110902734643314, timestamp: 2022-08-19 13:30:49.836495\n",
      "resetting env. episode 8079, reward total was -10.0. running mean: -16.04979370729688, timestamp: 2022-08-19 13:30:58.525595\n",
      "resetting env. episode 8080, reward total was -17.0. running mean: -16.059295770223912, timestamp: 2022-08-19 13:31:05.936679\n",
      "resetting env. episode 8081, reward total was -21.0. running mean: -16.108702812521674, timestamp: 2022-08-19 13:31:10.521733\n",
      "resetting env. episode 8082, reward total was -15.0. running mean: -16.097615784396456, timestamp: 2022-08-19 13:31:17.971819\n",
      "resetting env. episode 8083, reward total was -16.0. running mean: -16.09663962655249, timestamp: 2022-08-19 13:31:26.452911\n",
      "resetting env. episode 8084, reward total was -12.0. running mean: -16.055673230286967, timestamp: 2022-08-19 13:31:34.367999\n",
      "resetting env. episode 8085, reward total was -14.0. running mean: -16.035116497984095, timestamp: 2022-08-19 13:31:42.073086\n",
      "resetting env. episode 8086, reward total was -18.0. running mean: -16.054765333004255, timestamp: 2022-08-19 13:31:48.496157\n",
      "resetting env. episode 8087, reward total was -17.0. running mean: -16.064217679674215, timestamp: 2022-08-19 13:31:56.535251\n",
      "resetting env. episode 8088, reward total was -13.0. running mean: -16.033575502877472, timestamp: 2022-08-19 13:32:03.170323\n",
      "resetting env. episode 8089, reward total was -21.0. running mean: -16.083239747848697, timestamp: 2022-08-19 13:32:09.395260\n",
      "resetting env. episode 8090, reward total was -18.0. running mean: -16.10240735037021, timestamp: 2022-08-19 13:32:15.223845\n",
      "resetting env. episode 8091, reward total was -18.0. running mean: -16.12138327686651, timestamp: 2022-08-19 13:32:21.087912\n",
      "resetting env. episode 8092, reward total was -13.0. running mean: -16.090169444097846, timestamp: 2022-08-19 13:32:28.432560\n",
      "resetting env. episode 8093, reward total was -14.0. running mean: -16.069267749656866, timestamp: 2022-08-19 13:32:35.561646\n",
      "resetting env. episode 8094, reward total was -18.0. running mean: -16.0885750721603, timestamp: 2022-08-19 13:32:41.635708\n",
      "resetting env. episode 8095, reward total was -13.0. running mean: -16.057689321438698, timestamp: 2022-08-19 13:32:48.860644\n",
      "resetting env. episode 8096, reward total was -14.0. running mean: -16.03711242822431, timestamp: 2022-08-19 13:32:56.459725\n",
      "resetting env. episode 8097, reward total was -15.0. running mean: -16.026741303942067, timestamp: 2022-08-19 13:33:04.427346\n",
      "resetting env. episode 8098, reward total was -13.0. running mean: -15.996473890902648, timestamp: 2022-08-19 13:33:10.667415\n",
      "resetting env. episode 8099, reward total was -14.0. running mean: -15.976509151993621, timestamp: 2022-08-19 13:33:18.427501\n",
      "resetting env. episode 8100, reward total was -19.0. running mean: -16.006744060473686, timestamp: 2022-08-19 13:33:23.305080\n",
      "resetting env. episode 8101, reward total was -16.0. running mean: -16.006676619868948, timestamp: 2022-08-19 13:33:30.533162\n",
      "resetting env. episode 8102, reward total was -15.0. running mean: -15.99660985367026, timestamp: 2022-08-19 13:33:36.317225\n",
      "resetting env. episode 8103, reward total was -14.0. running mean: -15.976643755133557, timestamp: 2022-08-19 13:33:44.523319\n",
      "resetting env. episode 8104, reward total was -16.0. running mean: -15.976877317582222, timestamp: 2022-08-19 13:33:51.506399\n",
      "resetting env. episode 8105, reward total was -12.0. running mean: -15.9371085444064, timestamp: 2022-08-19 13:33:59.065485\n",
      "resetting env. episode 8106, reward total was -13.0. running mean: -15.907737458962336, timestamp: 2022-08-19 13:34:07.668582\n",
      "resetting env. episode 8107, reward total was -19.0. running mean: -15.938660084372712, timestamp: 2022-08-19 13:34:14.023179\n",
      "resetting env. episode 8108, reward total was -15.0. running mean: -15.929273483528984, timestamp: 2022-08-19 13:34:19.958250\n",
      "resetting env. episode 8109, reward total was -17.0. running mean: -15.939980748693694, timestamp: 2022-08-19 13:34:26.417322\n",
      "resetting env. episode 8110, reward total was -10.0. running mean: -15.880580941206757, timestamp: 2022-08-19 13:34:38.159983\n",
      "resetting env. episode 8111, reward total was -17.0. running mean: -15.89177513179469, timestamp: 2022-08-19 13:34:44.829064\n",
      "resetting env. episode 8112, reward total was -17.0. running mean: -15.902857380476743, timestamp: 2022-08-19 13:34:51.754143\n",
      "resetting env. episode 8113, reward total was -16.0. running mean: -15.903828806671974, timestamp: 2022-08-19 13:34:58.222214\n",
      "resetting env. episode 8114, reward total was -11.0. running mean: -15.854790518605254, timestamp: 2022-08-19 13:35:06.860314\n",
      "resetting env. episode 8115, reward total was -16.0. running mean: -15.856242613419202, timestamp: 2022-08-19 13:35:15.588413\n",
      "resetting env. episode 8116, reward total was -20.0. running mean: -15.897680187285008, timestamp: 2022-08-19 13:35:21.571485\n",
      "resetting env. episode 8117, reward total was -14.0. running mean: -15.878703385412159, timestamp: 2022-08-19 13:35:28.030564\n",
      "resetting env. episode 8118, reward total was -17.0. running mean: -15.889916351558037, timestamp: 2022-08-19 13:35:36.170326\n",
      "resetting env. episode 8119, reward total was -16.0. running mean: -15.891017188042458, timestamp: 2022-08-19 13:35:42.719396\n",
      "resetting env. episode 8120, reward total was -18.0. running mean: -15.912107016162032, timestamp: 2022-08-19 13:35:48.572462\n",
      "resetting env. episode 8121, reward total was -15.0. running mean: -15.902985946000411, timestamp: 2022-08-19 13:35:55.140544\n",
      "resetting env. episode 8122, reward total was -10.0. running mean: -15.843956086540407, timestamp: 2022-08-19 13:36:03.310122\n",
      "resetting env. episode 8123, reward total was -16.0. running mean: -15.845516525675004, timestamp: 2022-08-19 13:36:09.477193\n",
      "resetting env. episode 8124, reward total was -15.0. running mean: -15.837061360418254, timestamp: 2022-08-19 13:36:16.462280\n",
      "resetting env. episode 8125, reward total was -9.0. running mean: -15.768690746814071, timestamp: 2022-08-19 13:36:24.399370\n",
      "resetting env. episode 8126, reward total was -12.0. running mean: -15.731003839345929, timestamp: 2022-08-19 13:36:34.136537\n",
      "resetting env. episode 8127, reward total was -19.0. running mean: -15.763693800952469, timestamp: 2022-08-19 13:36:41.029617\n",
      "resetting env. episode 8128, reward total was -15.0. running mean: -15.756056862942945, timestamp: 2022-08-19 13:36:47.701696\n",
      "resetting env. episode 8129, reward total was -19.0. running mean: -15.788496294313514, timestamp: 2022-08-19 13:36:54.062771\n",
      "resetting env. episode 8130, reward total was -18.0. running mean: -15.810611331370378, timestamp: 2022-08-19 13:37:00.078841\n",
      "resetting env. episode 8131, reward total was -12.0. running mean: -15.772505218056674, timestamp: 2022-08-19 13:37:07.575931\n",
      "resetting env. episode 8132, reward total was -17.0. running mean: -15.784780165876107, timestamp: 2022-08-19 13:37:14.614013\n",
      "resetting env. episode 8133, reward total was -13.0. running mean: -15.756932364217347, timestamp: 2022-08-19 13:37:23.654122\n",
      "resetting env. episode 8134, reward total was -20.0. running mean: -15.799363040575173, timestamp: 2022-08-19 13:37:28.855184\n",
      "resetting env. episode 8135, reward total was -17.0. running mean: -15.811369410169421, timestamp: 2022-08-19 13:37:36.188269\n",
      "resetting env. episode 8136, reward total was -15.0. running mean: -15.803255716067728, timestamp: 2022-08-19 13:37:42.745067\n",
      "resetting env. episode 8137, reward total was -16.0. running mean: -15.80522315890705, timestamp: 2022-08-19 13:37:48.982140\n",
      "resetting env. episode 8138, reward total was -17.0. running mean: -15.81717092731798, timestamp: 2022-08-19 13:37:55.500215\n",
      "resetting env. episode 8139, reward total was -15.0. running mean: -15.8089992180448, timestamp: 2022-08-19 13:38:04.708325\n",
      "resetting env. episode 8140, reward total was -19.0. running mean: -15.840909225864351, timestamp: 2022-08-19 13:38:10.906396\n",
      "resetting env. episode 8141, reward total was -15.0. running mean: -15.832500133605707, timestamp: 2022-08-19 13:38:18.797374\n",
      "resetting env. episode 8142, reward total was -11.0. running mean: -15.784175132269649, timestamp: 2022-08-19 13:38:26.276462\n",
      "resetting env. episode 8143, reward total was -13.0. running mean: -15.756333380946954, timestamp: 2022-08-19 13:38:35.196569\n",
      "resetting env. episode 8144, reward total was -14.0. running mean: -15.738770047137484, timestamp: 2022-08-19 13:38:41.374420\n",
      "resetting env. episode 8145, reward total was -11.0. running mean: -15.691382346666108, timestamp: 2022-08-19 13:38:48.535507\n",
      "resetting env. episode 8146, reward total was -18.0. running mean: -15.714468523199447, timestamp: 2022-08-19 13:38:54.775582\n",
      "resetting env. episode 8147, reward total was -18.0. running mean: -15.737323837967452, timestamp: 2022-08-19 13:39:02.010666\n",
      "resetting env. episode 8148, reward total was -17.0. running mean: -15.749950599587777, timestamp: 2022-08-19 13:39:07.755737\n",
      "resetting env. episode 8149, reward total was -19.0. running mean: -15.782451093591899, timestamp: 2022-08-19 13:39:14.342815\n",
      "resetting env. episode 8150, reward total was -17.0. running mean: -15.79462658265598, timestamp: 2022-08-19 13:39:22.018904\n",
      "resetting env. episode 8151, reward total was -14.0. running mean: -15.77668031682942, timestamp: 2022-08-19 13:39:29.628997\n",
      "resetting env. episode 8152, reward total was -21.0. running mean: -15.828913513661126, timestamp: 2022-08-19 13:39:35.669067\n",
      "resetting env. episode 8153, reward total was -15.0. running mean: -15.820624378524515, timestamp: 2022-08-19 13:39:43.439160\n",
      "resetting env. episode 8154, reward total was -15.0. running mean: -15.81241813473927, timestamp: 2022-08-19 13:39:49.371231\n",
      "resetting env. episode 8155, reward total was -17.0. running mean: -15.824293953391876, timestamp: 2022-08-19 13:39:55.094299\n",
      "resetting env. episode 8156, reward total was -19.0. running mean: -15.856051013857957, timestamp: 2022-08-19 13:40:00.169358\n",
      "resetting env. episode 8157, reward total was -15.0. running mean: -15.847490503719378, timestamp: 2022-08-19 13:40:06.465437\n",
      "resetting env. episode 8158, reward total was -19.0. running mean: -15.879015598682184, timestamp: 2022-08-19 13:40:12.421508\n",
      "resetting env. episode 8159, reward total was -15.0. running mean: -15.870225442695363, timestamp: 2022-08-19 13:40:18.110572\n",
      "resetting env. episode 8160, reward total was -13.0. running mean: -15.84152318826841, timestamp: 2022-08-19 13:40:25.562658\n",
      "resetting env. episode 8161, reward total was -18.0. running mean: -15.863107956385726, timestamp: 2022-08-19 13:40:33.122748\n",
      "resetting env. episode 8162, reward total was -14.0. running mean: -15.844476876821869, timestamp: 2022-08-19 13:40:39.730828\n",
      "resetting env. episode 8163, reward total was -17.0. running mean: -15.85603210805365, timestamp: 2022-08-19 13:40:46.353908\n",
      "resetting env. episode 8164, reward total was -19.0. running mean: -15.887471786973114, timestamp: 2022-08-19 13:40:52.174612\n",
      "resetting env. episode 8165, reward total was -11.0. running mean: -15.838597069103383, timestamp: 2022-08-19 13:41:00.995713\n",
      "resetting env. episode 8166, reward total was -19.0. running mean: -15.870211098412348, timestamp: 2022-08-19 13:41:06.488777\n",
      "resetting env. episode 8167, reward total was -18.0. running mean: -15.891508987428224, timestamp: 2022-08-19 13:41:12.266847\n",
      "resetting env. episode 8168, reward total was -14.0. running mean: -15.872593897553942, timestamp: 2022-08-19 13:41:19.901936\n",
      "resetting env. episode 8169, reward total was -17.0. running mean: -15.883867958578403, timestamp: 2022-08-19 13:41:25.772012\n",
      "resetting env. episode 8170, reward total was -11.0. running mean: -15.835029278992618, timestamp: 2022-08-19 13:41:32.749088\n",
      "resetting env. episode 8171, reward total was -14.0. running mean: -15.816678986202692, timestamp: 2022-08-19 13:41:40.894184\n",
      "resetting env. episode 8172, reward total was -18.0. running mean: -15.838512196340664, timestamp: 2022-08-19 13:41:47.002255\n",
      "resetting env. episode 8173, reward total was -18.0. running mean: -15.860127074377257, timestamp: 2022-08-19 13:41:53.717334\n",
      "resetting env. episode 8174, reward total was -19.0. running mean: -15.891525803633483, timestamp: 2022-08-19 13:41:59.268933\n",
      "resetting env. episode 8175, reward total was -15.0. running mean: -15.882610545597148, timestamp: 2022-08-19 13:42:05.987011\n",
      "resetting env. episode 8176, reward total was -19.0. running mean: -15.913784440141175, timestamp: 2022-08-19 13:42:11.817080\n",
      "resetting env. episode 8177, reward total was -12.0. running mean: -15.874646595739762, timestamp: 2022-08-19 13:42:19.507695\n",
      "resetting env. episode 8178, reward total was -17.0. running mean: -15.885900129782364, timestamp: 2022-08-19 13:42:27.046784\n",
      "resetting env. episode 8179, reward total was -19.0. running mean: -15.91704112848454, timestamp: 2022-08-19 13:42:34.235868\n",
      "resetting env. episode 8180, reward total was -16.0. running mean: -15.917870717199694, timestamp: 2022-08-19 13:42:40.936949\n",
      "resetting env. episode 8181, reward total was -13.0. running mean: -15.888692010027698, timestamp: 2022-08-19 13:42:48.478039\n",
      "resetting env. episode 8182, reward total was -18.0. running mean: -15.90980508992742, timestamp: 2022-08-19 13:42:54.080102\n",
      "resetting env. episode 8183, reward total was -20.0. running mean: -15.950707039028146, timestamp: 2022-08-19 13:43:00.593710\n",
      "resetting env. episode 8184, reward total was -16.0. running mean: -15.951199968637864, timestamp: 2022-08-19 13:43:08.707803\n",
      "resetting env. episode 8185, reward total was -14.0. running mean: -15.931687968951486, timestamp: 2022-08-19 13:43:16.761900\n",
      "resetting env. episode 8186, reward total was -15.0. running mean: -15.922371089261972, timestamp: 2022-08-19 13:43:22.884969\n",
      "resetting env. episode 8187, reward total was -18.0. running mean: -15.943147378369352, timestamp: 2022-08-19 13:43:28.528037\n",
      "resetting env. episode 8188, reward total was -16.0. running mean: -15.943715904585659, timestamp: 2022-08-19 13:43:35.816124\n",
      "resetting env. episode 8189, reward total was -18.0. running mean: -15.964278745539803, timestamp: 2022-08-19 13:43:43.698214\n",
      "resetting env. episode 8190, reward total was -19.0. running mean: -15.994635958084404, timestamp: 2022-08-19 13:43:51.208301\n",
      "resetting env. episode 8191, reward total was -12.0. running mean: -15.954689598503558, timestamp: 2022-08-19 13:43:59.251394\n",
      "resetting env. episode 8192, reward total was -18.0. running mean: -15.975142702518522, timestamp: 2022-08-19 13:44:06.178477\n",
      "resetting env. episode 8193, reward total was -17.0. running mean: -15.985391275493336, timestamp: 2022-08-19 13:44:11.896548\n",
      "resetting env. episode 8194, reward total was -13.0. running mean: -15.955537362738404, timestamp: 2022-08-19 13:44:18.997626\n",
      "resetting env. episode 8195, reward total was -10.0. running mean: -15.89598198911102, timestamp: 2022-08-19 13:44:26.094708\n",
      "resetting env. episode 8196, reward total was -14.0. running mean: -15.87702216921991, timestamp: 2022-08-19 13:44:34.097805\n",
      "resetting env. episode 8197, reward total was -20.0. running mean: -15.91825194752771, timestamp: 2022-08-19 13:44:40.242876\n",
      "resetting env. episode 8198, reward total was -15.0. running mean: -15.909069428052433, timestamp: 2022-08-19 13:44:45.527937\n",
      "resetting env. episode 8199, reward total was -17.0. running mean: -15.91997873377191, timestamp: 2022-08-19 13:44:51.860065\n",
      "resetting env. episode 8200, reward total was -17.0. running mean: -15.93077894643419, timestamp: 2022-08-19 13:44:58.266137\n",
      "resetting env. episode 8201, reward total was -17.0. running mean: -15.941471156969847, timestamp: 2022-08-19 13:45:06.856243\n",
      "resetting env. episode 8202, reward total was -15.0. running mean: -15.932056445400148, timestamp: 2022-08-19 13:45:13.359312\n",
      "resetting env. episode 8203, reward total was -18.0. running mean: -15.952735880946147, timestamp: 2022-08-19 13:45:20.939403\n",
      "resetting env. episode 8204, reward total was -17.0. running mean: -15.963208522136686, timestamp: 2022-08-19 13:45:26.916472\n",
      "resetting env. episode 8205, reward total was -12.0. running mean: -15.923576436915319, timestamp: 2022-08-19 13:45:33.063542\n",
      "resetting env. episode 8206, reward total was -16.0. running mean: -15.924340672546165, timestamp: 2022-08-19 13:45:41.660642\n",
      "resetting env. episode 8207, reward total was -15.0. running mean: -15.915097265820703, timestamp: 2022-08-19 13:45:47.634709\n",
      "resetting env. episode 8208, reward total was -12.0. running mean: -15.875946293162496, timestamp: 2022-08-19 13:45:55.875330\n",
      "resetting env. episode 8209, reward total was -17.0. running mean: -15.88718683023087, timestamp: 2022-08-19 13:46:03.728421\n",
      "resetting env. episode 8210, reward total was -15.0. running mean: -15.878314961928561, timestamp: 2022-08-19 13:46:11.359506\n",
      "resetting env. episode 8211, reward total was -17.0. running mean: -15.889531812309276, timestamp: 2022-08-19 13:46:18.258587\n",
      "resetting env. episode 8212, reward total was -16.0. running mean: -15.890636494186182, timestamp: 2022-08-19 13:46:26.498683\n",
      "resetting env. episode 8213, reward total was -14.0. running mean: -15.871730129244321, timestamp: 2022-08-19 13:46:33.388760\n",
      "resetting env. episode 8214, reward total was -13.0. running mean: -15.84301282795188, timestamp: 2022-08-19 13:46:42.081860\n",
      "resetting env. episode 8215, reward total was -8.0. running mean: -15.76458269967236, timestamp: 2022-08-19 13:46:49.730948\n",
      "resetting env. episode 8216, reward total was -17.0. running mean: -15.776936872675636, timestamp: 2022-08-19 13:46:55.339018\n",
      "resetting env. episode 8217, reward total was -18.0. running mean: -15.79916750394888, timestamp: 2022-08-19 13:47:00.762075\n",
      "resetting env. episode 8218, reward total was -15.0. running mean: -15.791175828909392, timestamp: 2022-08-19 13:47:08.746167\n",
      "resetting env. episode 8219, reward total was -16.0. running mean: -15.793264070620298, timestamp: 2022-08-19 13:47:16.787259\n",
      "resetting env. episode 8220, reward total was -21.0. running mean: -15.845331429914095, timestamp: 2022-08-19 13:47:22.770327\n",
      "resetting env. episode 8221, reward total was -15.0. running mean: -15.836878115614955, timestamp: 2022-08-19 13:47:31.290427\n",
      "resetting env. episode 8222, reward total was -17.0. running mean: -15.848509334458805, timestamp: 2022-08-19 13:47:40.223523\n",
      "resetting env. episode 8223, reward total was -15.0. running mean: -15.840024241114218, timestamp: 2022-08-19 13:47:49.475633\n",
      "resetting env. episode 8224, reward total was -15.0. running mean: -15.831623998703076, timestamp: 2022-08-19 13:47:56.745714\n",
      "resetting env. episode 8225, reward total was -19.0. running mean: -15.863307758716045, timestamp: 2022-08-19 13:48:03.095787\n",
      "resetting env. episode 8226, reward total was -11.0. running mean: -15.814674681128885, timestamp: 2022-08-19 13:48:10.239868\n",
      "resetting env. episode 8227, reward total was -17.0. running mean: -15.826527934317596, timestamp: 2022-08-19 13:48:17.612477\n",
      "resetting env. episode 8228, reward total was -17.0. running mean: -15.83826265497442, timestamp: 2022-08-19 13:48:24.312554\n",
      "resetting env. episode 8229, reward total was -14.0. running mean: -15.819880028424675, timestamp: 2022-08-19 13:48:32.003162\n",
      "resetting env. episode 8230, reward total was -12.0. running mean: -15.781681228140428, timestamp: 2022-08-19 13:48:39.173239\n",
      "resetting env. episode 8231, reward total was -15.0. running mean: -15.773864415859023, timestamp: 2022-08-19 13:48:46.218319\n",
      "resetting env. episode 8232, reward total was -17.0. running mean: -15.786125771700434, timestamp: 2022-08-19 13:48:51.134375\n",
      "resetting env. episode 8233, reward total was -13.0. running mean: -15.75826451398343, timestamp: 2022-08-19 13:48:57.967454\n",
      "resetting env. episode 8234, reward total was -14.0. running mean: -15.740681868843597, timestamp: 2022-08-19 13:49:04.698529\n",
      "resetting env. episode 8235, reward total was -14.0. running mean: -15.723275050155161, timestamp: 2022-08-19 13:49:10.467595\n",
      "resetting env. episode 8236, reward total was -17.0. running mean: -15.73604229965361, timestamp: 2022-08-19 13:49:17.490673\n",
      "resetting env. episode 8237, reward total was -18.0. running mean: -15.758681876657073, timestamp: 2022-08-19 13:49:23.796747\n",
      "resetting env. episode 8238, reward total was -13.0. running mean: -15.731095057890503, timestamp: 2022-08-19 13:49:31.405831\n",
      "resetting env. episode 8239, reward total was -15.0. running mean: -15.723784107311598, timestamp: 2022-08-19 13:49:38.769912\n",
      "resetting env. episode 8240, reward total was -15.0. running mean: -15.716546266238483, timestamp: 2022-08-19 13:49:47.520010\n",
      "resetting env. episode 8241, reward total was -19.0. running mean: -15.749380803576097, timestamp: 2022-08-19 13:49:54.350089\n",
      "resetting env. episode 8242, reward total was -17.0. running mean: -15.761886995540335, timestamp: 2022-08-19 13:50:02.353704\n",
      "resetting env. episode 8243, reward total was -20.0. running mean: -15.804268125584931, timestamp: 2022-08-19 13:50:09.457781\n",
      "resetting env. episode 8244, reward total was -14.0. running mean: -15.786225444329082, timestamp: 2022-08-19 13:50:16.203387\n",
      "resetting env. episode 8245, reward total was -21.0. running mean: -15.838363189885792, timestamp: 2022-08-19 13:50:22.109449\n",
      "resetting env. episode 8246, reward total was -14.0. running mean: -15.819979557986935, timestamp: 2022-08-19 13:50:29.003527\n",
      "resetting env. episode 8247, reward total was -17.0. running mean: -15.831779762407065, timestamp: 2022-08-19 13:50:36.297607\n",
      "resetting env. episode 8248, reward total was -15.0. running mean: -15.823461964782995, timestamp: 2022-08-19 13:50:43.911216\n",
      "resetting env. episode 8249, reward total was -15.0. running mean: -15.815227345135165, timestamp: 2022-08-19 13:50:51.344303\n",
      "resetting env. episode 8250, reward total was -16.0. running mean: -15.817075071683814, timestamp: 2022-08-19 13:50:56.956364\n",
      "resetting env. episode 8251, reward total was -9.0. running mean: -15.748904320966975, timestamp: 2022-08-19 13:51:05.804465\n",
      "resetting env. episode 8252, reward total was -16.0. running mean: -15.751415277757305, timestamp: 2022-08-19 13:51:14.021557\n",
      "resetting env. episode 8253, reward total was -16.0. running mean: -15.753901124979732, timestamp: 2022-08-19 13:51:20.276628\n",
      "resetting env. episode 8254, reward total was -13.0. running mean: -15.726362113729936, timestamp: 2022-08-19 13:51:27.923717\n",
      "resetting env. episode 8255, reward total was -19.0. running mean: -15.759098492592635, timestamp: 2022-08-19 13:51:35.777806\n",
      "resetting env. episode 8256, reward total was -11.0. running mean: -15.711507507666708, timestamp: 2022-08-19 13:51:43.799899\n",
      "resetting env. episode 8257, reward total was -10.0. running mean: -15.65439243259004, timestamp: 2022-08-19 13:51:51.748518\n",
      "resetting env. episode 8258, reward total was -15.0. running mean: -15.64784850826414, timestamp: 2022-08-19 13:51:58.936602\n",
      "resetting env. episode 8259, reward total was -17.0. running mean: -15.661370023181497, timestamp: 2022-08-19 13:52:06.599692\n",
      "resetting env. episode 8260, reward total was -17.0. running mean: -15.674756322949682, timestamp: 2022-08-19 13:52:12.449757\n",
      "resetting env. episode 8261, reward total was -17.0. running mean: -15.688008759720185, timestamp: 2022-08-19 13:52:19.428838\n",
      "resetting env. episode 8262, reward total was -16.0. running mean: -15.691128672122984, timestamp: 2022-08-19 13:52:24.978903\n",
      "resetting env. episode 8263, reward total was -17.0. running mean: -15.704217385401753, timestamp: 2022-08-19 13:52:32.248988\n",
      "resetting env. episode 8264, reward total was -20.0. running mean: -15.747175211547734, timestamp: 2022-08-19 13:52:37.958056\n",
      "resetting env. episode 8265, reward total was -18.0. running mean: -15.769703459432257, timestamp: 2022-08-19 13:52:43.915124\n",
      "resetting env. episode 8266, reward total was -17.0. running mean: -15.782006424837935, timestamp: 2022-08-19 13:52:49.300189\n",
      "resetting env. episode 8267, reward total was -14.0. running mean: -15.764186360589555, timestamp: 2022-08-19 13:52:55.305260\n",
      "resetting env. episode 8268, reward total was -17.0. running mean: -15.776544496983659, timestamp: 2022-08-19 13:53:01.762336\n",
      "resetting env. episode 8269, reward total was -21.0. running mean: -15.828779052013823, timestamp: 2022-08-19 13:53:07.449400\n",
      "resetting env. episode 8270, reward total was -19.0. running mean: -15.860491261493685, timestamp: 2022-08-19 13:53:13.321469\n",
      "resetting env. episode 8271, reward total was -16.0. running mean: -15.861886348878748, timestamp: 2022-08-19 13:53:20.296080\n",
      "resetting env. episode 8272, reward total was -14.0. running mean: -15.843267485389962, timestamp: 2022-08-19 13:53:26.097145\n",
      "resetting env. episode 8273, reward total was -15.0. running mean: -15.834834810536062, timestamp: 2022-08-19 13:53:32.442222\n",
      "resetting env. episode 8274, reward total was -14.0. running mean: -15.816486462430701, timestamp: 2022-08-19 13:53:39.516305\n",
      "resetting env. episode 8275, reward total was -19.0. running mean: -15.848321597806393, timestamp: 2022-08-19 13:53:46.651388\n",
      "resetting env. episode 8276, reward total was -18.0. running mean: -15.869838381828329, timestamp: 2022-08-19 13:53:54.368481\n",
      "resetting env. episode 8277, reward total was -21.0. running mean: -15.921139998010046, timestamp: 2022-08-19 13:54:01.040560\n",
      "resetting env. episode 8278, reward total was -17.0. running mean: -15.931928598029945, timestamp: 2022-08-19 13:54:08.459167\n",
      "resetting env. episode 8279, reward total was -17.0. running mean: -15.942609312049646, timestamp: 2022-08-19 13:54:14.648238\n",
      "resetting env. episode 8280, reward total was -15.0. running mean: -15.93318321892915, timestamp: 2022-08-19 13:54:21.354318\n",
      "resetting env. episode 8281, reward total was -15.0. running mean: -15.923851386739859, timestamp: 2022-08-19 13:54:29.838419\n",
      "resetting env. episode 8282, reward total was -21.0. running mean: -15.974612872872461, timestamp: 2022-08-19 13:54:36.842502\n",
      "resetting env. episode 8283, reward total was -16.0. running mean: -15.974866744143736, timestamp: 2022-08-19 13:54:43.674585\n",
      "resetting env. episode 8284, reward total was -17.0. running mean: -15.985118076702298, timestamp: 2022-08-19 13:54:51.164677\n",
      "resetting env. episode 8285, reward total was -17.0. running mean: -15.995266895935275, timestamp: 2022-08-19 13:54:57.462751\n",
      "resetting env. episode 8286, reward total was -17.0. running mean: -16.005314226975923, timestamp: 2022-08-19 13:55:04.192833\n",
      "resetting env. episode 8287, reward total was -15.0. running mean: -15.995261084706163, timestamp: 2022-08-19 13:55:11.075912\n",
      "resetting env. episode 8288, reward total was -18.0. running mean: -16.0153084738591, timestamp: 2022-08-19 13:55:17.313992\n",
      "resetting env. episode 8289, reward total was -10.0. running mean: -15.95515538912051, timestamp: 2022-08-19 13:55:27.319104\n",
      "resetting env. episode 8290, reward total was -17.0. running mean: -15.965603835229304, timestamp: 2022-08-19 13:55:33.996182\n",
      "resetting env. episode 8291, reward total was -17.0. running mean: -15.97594779687701, timestamp: 2022-08-19 13:55:40.854264\n",
      "resetting env. episode 8292, reward total was -17.0. running mean: -15.98618831890824, timestamp: 2022-08-19 13:55:47.428343\n",
      "resetting env. episode 8293, reward total was -17.0. running mean: -15.996326435719158, timestamp: 2022-08-19 13:55:53.496422\n",
      "resetting env. episode 8294, reward total was -17.0. running mean: -16.00636317136197, timestamp: 2022-08-19 13:56:01.253507\n",
      "resetting env. episode 8295, reward total was -15.0. running mean: -15.99629953964835, timestamp: 2022-08-19 13:56:06.892574\n",
      "resetting env. episode 8296, reward total was -15.0. running mean: -15.986336544251866, timestamp: 2022-08-19 13:56:15.216674\n",
      "resetting env. episode 8297, reward total was -15.0. running mean: -15.976473178809348, timestamp: 2022-08-19 13:56:20.607740\n",
      "resetting env. episode 8298, reward total was -18.0. running mean: -15.996708447021254, timestamp: 2022-08-19 13:56:26.617809\n",
      "resetting env. episode 8299, reward total was -18.0. running mean: -16.01674136255104, timestamp: 2022-08-19 13:56:33.010886\n",
      "resetting env. episode 8300, reward total was -17.0. running mean: -16.02657394892553, timestamp: 2022-08-19 13:56:40.241971\n",
      "resetting env. episode 8301, reward total was -20.0. running mean: -16.066308209436276, timestamp: 2022-08-19 13:56:46.136046\n",
      "resetting env. episode 8302, reward total was -15.0. running mean: -16.05564512734191, timestamp: 2022-08-19 13:56:52.853123\n",
      "resetting env. episode 8303, reward total was -16.0. running mean: -16.05508867606849, timestamp: 2022-08-19 13:57:00.480216\n",
      "resetting env. episode 8304, reward total was -18.0. running mean: -16.074537789307804, timestamp: 2022-08-19 13:57:06.768287\n",
      "resetting env. episode 8305, reward total was -19.0. running mean: -16.103792411414727, timestamp: 2022-08-19 13:57:13.808371\n",
      "resetting env. episode 8306, reward total was -15.0. running mean: -16.092754487300578, timestamp: 2022-08-19 13:57:21.584464\n",
      "resetting env. episode 8307, reward total was -12.0. running mean: -16.05182694242757, timestamp: 2022-08-19 13:57:29.978099\n",
      "resetting env. episode 8308, reward total was -11.0. running mean: -16.001308673003294, timestamp: 2022-08-19 13:57:38.660721\n",
      "resetting env. episode 8309, reward total was -12.0. running mean: -15.96129558627326, timestamp: 2022-08-19 13:57:46.662818\n",
      "resetting env. episode 8310, reward total was -20.0. running mean: -16.001682630410528, timestamp: 2022-08-19 13:57:52.997524\n",
      "resetting env. episode 8311, reward total was -14.0. running mean: -15.981665804106424, timestamp: 2022-08-19 13:58:00.749614\n",
      "resetting env. episode 8312, reward total was -17.0. running mean: -15.99184914606536, timestamp: 2022-08-19 13:58:06.918690\n",
      "resetting env. episode 8313, reward total was -18.0. running mean: -16.011930654604708, timestamp: 2022-08-19 13:58:13.637768\n",
      "resetting env. episode 8314, reward total was -9.0. running mean: -15.94181134805866, timestamp: 2022-08-19 13:58:22.286874\n",
      "resetting env. episode 8315, reward total was -13.0. running mean: -15.912393234578074, timestamp: 2022-08-19 13:58:31.519983\n",
      "resetting env. episode 8316, reward total was -19.0. running mean: -15.943269302232293, timestamp: 2022-08-19 13:58:38.547067\n",
      "resetting env. episode 8317, reward total was -17.0. running mean: -15.95383660920997, timestamp: 2022-08-19 13:58:45.127144\n",
      "resetting env. episode 8318, reward total was -12.0. running mean: -15.91429824311787, timestamp: 2022-08-19 13:58:51.735225\n",
      "resetting env. episode 8319, reward total was -13.0. running mean: -15.885155260686691, timestamp: 2022-08-19 13:58:58.898307\n",
      "resetting env. episode 8320, reward total was -14.0. running mean: -15.866303708079824, timestamp: 2022-08-19 13:59:06.648400\n",
      "resetting env. episode 8321, reward total was -17.0. running mean: -15.877640670999027, timestamp: 2022-08-19 13:59:13.410483\n",
      "resetting env. episode 8322, reward total was -15.0. running mean: -15.868864264289037, timestamp: 2022-08-19 13:59:20.679566\n",
      "resetting env. episode 8323, reward total was -18.0. running mean: -15.890175621646147, timestamp: 2022-08-19 13:59:26.563634\n",
      "resetting env. episode 8324, reward total was -15.0. running mean: -15.881273865429685, timestamp: 2022-08-19 13:59:34.072725\n",
      "resetting env. episode 8325, reward total was -19.0. running mean: -15.912461126775389, timestamp: 2022-08-19 13:59:40.647807\n",
      "resetting env. episode 8326, reward total was -14.0. running mean: -15.893336515507634, timestamp: 2022-08-19 13:59:49.014902\n",
      "resetting env. episode 8327, reward total was -11.0. running mean: -15.844403150352557, timestamp: 2022-08-19 13:59:56.375987\n",
      "resetting env. episode 8328, reward total was -20.0. running mean: -15.88595911884903, timestamp: 2022-08-19 14:00:01.589046\n",
      "resetting env. episode 8329, reward total was -15.0. running mean: -15.87709952766054, timestamp: 2022-08-19 14:00:08.071124\n",
      "resetting env. episode 8330, reward total was -17.0. running mean: -15.888328532383936, timestamp: 2022-08-19 14:00:14.022194\n",
      "resetting env. episode 8331, reward total was -15.0. running mean: -15.879445247060097, timestamp: 2022-08-19 14:00:20.516271\n",
      "resetting env. episode 8332, reward total was -19.0. running mean: -15.910650794589495, timestamp: 2022-08-19 14:00:26.473341\n",
      "resetting env. episode 8333, reward total was -18.0. running mean: -15.9315442866436, timestamp: 2022-08-19 14:00:32.553415\n",
      "resetting env. episode 8334, reward total was -14.0. running mean: -15.912228843777164, timestamp: 2022-08-19 14:00:41.235515\n",
      "resetting env. episode 8335, reward total was -18.0. running mean: -15.933106555339393, timestamp: 2022-08-19 14:00:49.767613\n",
      "resetting env. episode 8336, reward total was -15.0. running mean: -15.923775489786, timestamp: 2022-08-19 14:00:57.419707\n",
      "resetting env. episode 8337, reward total was -14.0. running mean: -15.90453773488814, timestamp: 2022-08-19 14:01:06.217808\n",
      "resetting env. episode 8338, reward total was -16.0. running mean: -15.905492357539257, timestamp: 2022-08-19 14:01:13.597894\n",
      "resetting env. episode 8339, reward total was -14.0. running mean: -15.886437433963865, timestamp: 2022-08-19 14:01:20.697978\n",
      "resetting env. episode 8340, reward total was -17.0. running mean: -15.897573059624225, timestamp: 2022-08-19 14:01:28.328066\n",
      "resetting env. episode 8341, reward total was -15.0. running mean: -15.888597329027982, timestamp: 2022-08-19 14:01:35.734153\n",
      "resetting env. episode 8342, reward total was -15.0. running mean: -15.879711355737703, timestamp: 2022-08-19 14:01:42.527231\n",
      "resetting env. episode 8343, reward total was -11.0. running mean: -15.830914242180326, timestamp: 2022-08-19 14:01:49.928317\n",
      "resetting env. episode 8344, reward total was -16.0. running mean: -15.832605099758522, timestamp: 2022-08-19 14:01:56.508396\n",
      "resetting env. episode 8345, reward total was -15.0. running mean: -15.824279048760937, timestamp: 2022-08-19 14:02:04.074011\n",
      "resetting env. episode 8346, reward total was -10.0. running mean: -15.766036258273328, timestamp: 2022-08-19 14:02:14.683137\n",
      "resetting env. episode 8347, reward total was -13.0. running mean: -15.738375895690595, timestamp: 2022-08-19 14:02:23.272238\n",
      "resetting env. episode 8348, reward total was -15.0. running mean: -15.73099213673369, timestamp: 2022-08-19 14:02:31.546333\n",
      "resetting env. episode 8349, reward total was -13.0. running mean: -15.703682215366353, timestamp: 2022-08-19 14:02:39.485952\n",
      "resetting env. episode 8350, reward total was -9.0. running mean: -15.636645393212689, timestamp: 2022-08-19 14:02:48.445054\n",
      "resetting env. episode 8351, reward total was -19.0. running mean: -15.67027893928056, timestamp: 2022-08-19 14:02:54.760128\n",
      "resetting env. episode 8352, reward total was -16.0. running mean: -15.673576149887754, timestamp: 2022-08-19 14:03:01.879212\n",
      "resetting env. episode 8353, reward total was -17.0. running mean: -15.686840388388877, timestamp: 2022-08-19 14:03:09.761305\n",
      "resetting env. episode 8354, reward total was -17.0. running mean: -15.699971984504987, timestamp: 2022-08-19 14:03:16.503380\n",
      "resetting env. episode 8355, reward total was -15.0. running mean: -15.692972264659938, timestamp: 2022-08-19 14:03:22.883454\n",
      "resetting env. episode 8356, reward total was -14.0. running mean: -15.676042542013338, timestamp: 2022-08-19 14:03:29.855538\n",
      "resetting env. episode 8357, reward total was -16.0. running mean: -15.679282116593205, timestamp: 2022-08-19 14:03:36.866616\n",
      "resetting env. episode 8358, reward total was -14.0. running mean: -15.662489295427273, timestamp: 2022-08-19 14:03:43.812229\n",
      "resetting env. episode 8359, reward total was -21.0. running mean: -15.715864402473, timestamp: 2022-08-19 14:03:49.653298\n",
      "resetting env. episode 8360, reward total was -13.0. running mean: -15.688705758448272, timestamp: 2022-08-19 14:03:57.857390\n",
      "resetting env. episode 8361, reward total was -19.0. running mean: -15.721818700863789, timestamp: 2022-08-19 14:04:03.852984\n",
      "resetting env. episode 8362, reward total was -14.0. running mean: -15.704600513855151, timestamp: 2022-08-19 14:04:11.602074\n",
      "resetting env. episode 8363, reward total was -9.0. running mean: -15.6375545087166, timestamp: 2022-08-19 14:04:20.300174\n",
      "resetting env. episode 8364, reward total was -18.0. running mean: -15.661178963629434, timestamp: 2022-08-19 14:04:26.121761\n",
      "resetting env. episode 8365, reward total was -15.0. running mean: -15.65456717399314, timestamp: 2022-08-19 14:04:34.184854\n",
      "resetting env. episode 8366, reward total was -17.0. running mean: -15.66802150225321, timestamp: 2022-08-19 14:04:41.126931\n",
      "resetting env. episode 8367, reward total was -13.0. running mean: -15.641341287230677, timestamp: 2022-08-19 14:04:48.579018\n",
      "resetting env. episode 8368, reward total was -15.0. running mean: -15.63492787435837, timestamp: 2022-08-19 14:04:55.995103\n",
      "resetting env. episode 8369, reward total was -17.0. running mean: -15.648578595614786, timestamp: 2022-08-19 14:05:02.225171\n",
      "resetting env. episode 8370, reward total was -15.0. running mean: -15.642092809658639, timestamp: 2022-08-19 14:05:09.169251\n",
      "resetting env. episode 8371, reward total was -13.0. running mean: -15.615671881562053, timestamp: 2022-08-19 14:05:17.701879\n",
      "resetting env. episode 8372, reward total was -18.0. running mean: -15.63951516274643, timestamp: 2022-08-19 14:05:24.855480\n",
      "resetting env. episode 8373, reward total was -16.0. running mean: -15.643120011118967, timestamp: 2022-08-19 14:05:32.692571\n",
      "resetting env. episode 8374, reward total was -18.0. running mean: -15.666688811007777, timestamp: 2022-08-19 14:05:38.256638\n",
      "resetting env. episode 8375, reward total was -16.0. running mean: -15.6700219228977, timestamp: 2022-08-19 14:05:46.238727\n",
      "resetting env. episode 8376, reward total was -19.0. running mean: -15.703321703668722, timestamp: 2022-08-19 14:05:52.629329\n",
      "resetting env. episode 8377, reward total was -17.0. running mean: -15.716288486632035, timestamp: 2022-08-19 14:05:59.617411\n",
      "resetting env. episode 8378, reward total was -17.0. running mean: -15.729125601765714, timestamp: 2022-08-19 14:06:06.904490\n",
      "resetting env. episode 8379, reward total was -17.0. running mean: -15.741834345748057, timestamp: 2022-08-19 14:06:13.926569\n",
      "resetting env. episode 8380, reward total was -15.0. running mean: -15.734416002290576, timestamp: 2022-08-19 14:06:22.409188\n",
      "resetting env. episode 8381, reward total was -13.0. running mean: -15.707071842267672, timestamp: 2022-08-19 14:06:30.516278\n",
      "resetting env. episode 8382, reward total was -15.0. running mean: -15.700001123844995, timestamp: 2022-08-19 14:06:37.302357\n",
      "resetting env. episode 8383, reward total was -13.0. running mean: -15.673001112606546, timestamp: 2022-08-19 14:06:45.888457\n",
      "resetting env. episode 8384, reward total was -20.0. running mean: -15.71627110148048, timestamp: 2022-08-19 14:06:52.143524\n",
      "resetting env. episode 8385, reward total was -16.0. running mean: -15.719108390465674, timestamp: 2022-08-19 14:06:59.010654\n",
      "resetting env. episode 8386, reward total was -20.0. running mean: -15.761917306561017, timestamp: 2022-08-19 14:07:05.641730\n",
      "resetting env. episode 8387, reward total was -18.0. running mean: -15.784298133495406, timestamp: 2022-08-19 14:07:11.396791\n",
      "resetting env. episode 8388, reward total was -14.0. running mean: -15.766455152160454, timestamp: 2022-08-19 14:07:19.482882\n",
      "resetting env. episode 8389, reward total was -15.0. running mean: -15.75879060063885, timestamp: 2022-08-19 14:07:26.664964\n",
      "resetting env. episode 8390, reward total was -9.0. running mean: -15.69120269463246, timestamp: 2022-08-19 14:07:36.255594\n",
      "resetting env. episode 8391, reward total was -11.0. running mean: -15.644290667686136, timestamp: 2022-08-19 14:07:45.133695\n",
      "resetting env. episode 8392, reward total was -18.0. running mean: -15.667847761009273, timestamp: 2022-08-19 14:07:53.270792\n",
      "resetting env. episode 8393, reward total was -19.0. running mean: -15.70116928339918, timestamp: 2022-08-19 14:07:59.114373\n",
      "resetting env. episode 8394, reward total was -15.0. running mean: -15.694157590565188, timestamp: 2022-08-19 14:08:07.433469\n",
      "resetting env. episode 8395, reward total was -17.0. running mean: -15.707216014659537, timestamp: 2022-08-19 14:08:13.815542\n",
      "resetting env. episode 8396, reward total was -15.0. running mean: -15.700143854512941, timestamp: 2022-08-19 14:08:21.075625\n",
      "resetting env. episode 8397, reward total was -18.0. running mean: -15.72314241596781, timestamp: 2022-08-19 14:08:28.244708\n",
      "resetting env. episode 8398, reward total was -14.0. running mean: -15.705910991808134, timestamp: 2022-08-19 14:08:35.618796\n",
      "resetting env. episode 8399, reward total was -19.0. running mean: -15.738851881890051, timestamp: 2022-08-19 14:08:43.303884\n",
      "resetting env. episode 8400, reward total was -12.0. running mean: -15.70146336307115, timestamp: 2022-08-19 14:08:53.021994\n",
      "resetting env. episode 8401, reward total was -19.0. running mean: -15.73444872944044, timestamp: 2022-08-19 14:08:58.640060\n",
      "resetting env. episode 8402, reward total was -15.0. running mean: -15.727104242146035, timestamp: 2022-08-19 14:09:06.629152\n",
      "resetting env. episode 8403, reward total was -18.0. running mean: -15.749833199724575, timestamp: 2022-08-19 14:09:12.234221\n",
      "resetting env. episode 8404, reward total was -18.0. running mean: -15.772334867727329, timestamp: 2022-08-19 14:09:18.944297\n",
      "resetting env. episode 8405, reward total was -17.0. running mean: -15.784611519050056, timestamp: 2022-08-19 14:09:25.874376\n",
      "resetting env. episode 8406, reward total was -14.0. running mean: -15.766765403859557, timestamp: 2022-08-19 14:09:33.771470\n",
      "resetting env. episode 8407, reward total was -15.0. running mean: -15.759097749820961, timestamp: 2022-08-19 14:09:40.994556\n",
      "resetting env. episode 8408, reward total was -15.0. running mean: -15.751506772322752, timestamp: 2022-08-19 14:09:47.807638\n",
      "resetting env. episode 8409, reward total was -13.0. running mean: -15.723991704599525, timestamp: 2022-08-19 14:09:55.252723\n",
      "resetting env. episode 8410, reward total was -14.0. running mean: -15.70675178755353, timestamp: 2022-08-19 14:10:02.896812\n",
      "resetting env. episode 8411, reward total was -17.0. running mean: -15.719684269677995, timestamp: 2022-08-19 14:10:09.966899\n",
      "resetting env. episode 8412, reward total was -11.0. running mean: -15.672487426981213, timestamp: 2022-08-19 14:10:19.344008\n",
      "resetting env. episode 8413, reward total was -16.0. running mean: -15.6757625527114, timestamp: 2022-08-19 14:10:25.355079\n",
      "resetting env. episode 8414, reward total was -17.0. running mean: -15.689004927184287, timestamp: 2022-08-19 14:10:32.362683\n",
      "resetting env. episode 8415, reward total was -19.0. running mean: -15.722114877912444, timestamp: 2022-08-19 14:10:39.510765\n",
      "resetting env. episode 8416, reward total was -14.0. running mean: -15.704893729133321, timestamp: 2022-08-19 14:10:47.875862\n",
      "resetting env. episode 8417, reward total was -19.0. running mean: -15.737844791841987, timestamp: 2022-08-19 14:10:54.129940\n",
      "resetting env. episode 8418, reward total was -19.0. running mean: -15.770466343923566, timestamp: 2022-08-19 14:11:00.133008\n",
      "resetting env. episode 8419, reward total was -20.0. running mean: -15.81276168048433, timestamp: 2022-08-19 14:11:06.092083\n",
      "resetting env. episode 8420, reward total was -18.0. running mean: -15.834634063679486, timestamp: 2022-08-19 14:11:11.949148\n",
      "resetting env. episode 8421, reward total was -16.0. running mean: -15.836287723042691, timestamp: 2022-08-19 14:11:18.873232\n",
      "resetting env. episode 8422, reward total was -18.0. running mean: -15.857924845812263, timestamp: 2022-08-19 14:11:25.967321\n",
      "resetting env. episode 8423, reward total was -13.0. running mean: -15.829345597354141, timestamp: 2022-08-19 14:11:32.235389\n",
      "resetting env. episode 8424, reward total was -18.0. running mean: -15.851052141380599, timestamp: 2022-08-19 14:11:38.091463\n",
      "resetting env. episode 8425, reward total was -17.0. running mean: -15.862541619966793, timestamp: 2022-08-19 14:11:47.160569\n",
      "resetting env. episode 8426, reward total was -19.0. running mean: -15.893916203767125, timestamp: 2022-08-19 14:11:52.914639\n",
      "resetting env. episode 8427, reward total was -15.0. running mean: -15.884977041729455, timestamp: 2022-08-19 14:12:01.288737\n",
      "resetting env. episode 8428, reward total was -12.0. running mean: -15.84612727131216, timestamp: 2022-08-19 14:12:08.301821\n",
      "resetting env. episode 8429, reward total was -15.0. running mean: -15.837665998599038, timestamp: 2022-08-19 14:12:17.225927\n",
      "resetting env. episode 8430, reward total was -18.0. running mean: -15.859289338613047, timestamp: 2022-08-19 14:12:23.276998\n",
      "resetting env. episode 8431, reward total was -13.0. running mean: -15.830696445226918, timestamp: 2022-08-19 14:12:29.787077\n",
      "resetting env. episode 8432, reward total was -16.0. running mean: -15.83238948077465, timestamp: 2022-08-19 14:12:36.050151\n",
      "resetting env. episode 8433, reward total was -17.0. running mean: -15.844065585966902, timestamp: 2022-08-19 14:12:42.734232\n",
      "resetting env. episode 8434, reward total was -16.0. running mean: -15.845624930107233, timestamp: 2022-08-19 14:12:50.157323\n",
      "resetting env. episode 8435, reward total was -16.0. running mean: -15.84716868080616, timestamp: 2022-08-19 14:12:57.828416\n",
      "resetting env. episode 8436, reward total was -15.0. running mean: -15.838696993998099, timestamp: 2022-08-19 14:13:05.408503\n",
      "resetting env. episode 8437, reward total was -14.0. running mean: -15.820310024058118, timestamp: 2022-08-19 14:13:13.508601\n",
      "resetting env. episode 8438, reward total was -20.0. running mean: -15.862106923817537, timestamp: 2022-08-19 14:13:21.151693\n",
      "resetting env. episode 8439, reward total was -13.0. running mean: -15.833485854579362, timestamp: 2022-08-19 14:13:28.053780\n",
      "resetting env. episode 8440, reward total was -17.0. running mean: -15.845150996033567, timestamp: 2022-08-19 14:13:35.373865\n",
      "resetting env. episode 8441, reward total was -15.0. running mean: -15.83669948607323, timestamp: 2022-08-19 14:13:43.576490\n",
      "resetting env. episode 8442, reward total was -14.0. running mean: -15.8183324912125, timestamp: 2022-08-19 14:13:51.714590\n",
      "resetting env. episode 8443, reward total was -13.0. running mean: -15.790149166300376, timestamp: 2022-08-19 14:13:59.961687\n",
      "resetting env. episode 8444, reward total was -16.0. running mean: -15.792247674637371, timestamp: 2022-08-19 14:14:07.064777\n",
      "resetting env. episode 8445, reward total was -19.0. running mean: -15.824325197890998, timestamp: 2022-08-19 14:14:14.260863\n",
      "resetting env. episode 8446, reward total was -6.0. running mean: -15.726081945912089, timestamp: 2022-08-19 14:14:22.994966\n",
      "resetting env. episode 8447, reward total was -19.0. running mean: -15.758821126452967, timestamp: 2022-08-19 14:14:29.157043\n",
      "resetting env. episode 8448, reward total was -19.0. running mean: -15.791232915188436, timestamp: 2022-08-19 14:14:35.399113\n",
      "resetting env. episode 8449, reward total was -16.0. running mean: -15.793320586036552, timestamp: 2022-08-19 14:14:42.149192\n",
      "resetting env. episode 8450, reward total was -18.0. running mean: -15.815387380176187, timestamp: 2022-08-19 14:14:49.364278\n",
      "resetting env. episode 8451, reward total was -15.0. running mean: -15.807233506374425, timestamp: 2022-08-19 14:14:57.170372\n",
      "resetting env. episode 8452, reward total was -14.0. running mean: -15.789161171310681, timestamp: 2022-08-19 14:15:04.332456\n",
      "resetting env. episode 8453, reward total was -15.0. running mean: -15.781269559597575, timestamp: 2022-08-19 14:15:11.277539\n",
      "resetting env. episode 8454, reward total was -19.0. running mean: -15.8134568640016, timestamp: 2022-08-19 14:15:17.267611\n",
      "resetting env. episode 8455, reward total was -18.0. running mean: -15.835322295361584, timestamp: 2022-08-19 14:15:23.851690\n",
      "resetting env. episode 8456, reward total was -15.0. running mean: -15.826969072407968, timestamp: 2022-08-19 14:15:31.551307\n",
      "resetting env. episode 8457, reward total was -15.0. running mean: -15.818699381683889, timestamp: 2022-08-19 14:15:39.009392\n",
      "resetting env. episode 8458, reward total was -18.0. running mean: -15.840512387867049, timestamp: 2022-08-19 14:15:45.695471\n",
      "resetting env. episode 8459, reward total was -13.0. running mean: -15.812107263988379, timestamp: 2022-08-19 14:15:53.817568\n",
      "resetting env. episode 8460, reward total was -11.0. running mean: -15.763986191348494, timestamp: 2022-08-19 14:16:01.726661\n",
      "resetting env. episode 8461, reward total was -14.0. running mean: -15.74634632943501, timestamp: 2022-08-19 14:16:10.578767\n",
      "resetting env. episode 8462, reward total was -18.0. running mean: -15.76888286614066, timestamp: 2022-08-19 14:16:17.008846\n",
      "resetting env. episode 8463, reward total was -12.0. running mean: -15.731194037479252, timestamp: 2022-08-19 14:16:24.802937\n",
      "resetting env. episode 8464, reward total was -19.0. running mean: -15.763882097104458, timestamp: 2022-08-19 14:16:32.252028\n",
      "resetting env. episode 8465, reward total was -20.0. running mean: -15.806243276133413, timestamp: 2022-08-19 14:16:37.237084\n",
      "resetting env. episode 8466, reward total was -12.0. running mean: -15.768180843372079, timestamp: 2022-08-19 14:16:43.762162\n",
      "resetting env. episode 8467, reward total was -14.0. running mean: -15.75049903493836, timestamp: 2022-08-19 14:16:50.879249\n",
      "resetting env. episode 8468, reward total was -21.0. running mean: -15.802994044588976, timestamp: 2022-08-19 14:16:56.803322\n",
      "resetting env. episode 8469, reward total was -15.0. running mean: -15.794964104143087, timestamp: 2022-08-19 14:17:03.733927\n",
      "resetting env. episode 8470, reward total was -15.0. running mean: -15.787014463101656, timestamp: 2022-08-19 14:17:10.824009\n",
      "resetting env. episode 8471, reward total was -14.0. running mean: -15.769144318470639, timestamp: 2022-08-19 14:17:17.792090\n",
      "resetting env. episode 8472, reward total was -19.0. running mean: -15.801452875285932, timestamp: 2022-08-19 14:17:23.964164\n",
      "resetting env. episode 8473, reward total was -17.0. running mean: -15.813438346533072, timestamp: 2022-08-19 14:17:29.580231\n",
      "resetting env. episode 8474, reward total was -15.0. running mean: -15.805303963067741, timestamp: 2022-08-19 14:17:36.310311\n",
      "resetting env. episode 8475, reward total was -19.0. running mean: -15.837250923437063, timestamp: 2022-08-19 14:17:43.077391\n",
      "resetting env. episode 8476, reward total was -14.0. running mean: -15.818878414202693, timestamp: 2022-08-19 14:17:49.861471\n",
      "resetting env. episode 8477, reward total was -17.0. running mean: -15.830689630060666, timestamp: 2022-08-19 14:17:55.547539\n",
      "resetting env. episode 8478, reward total was -17.0. running mean: -15.84238273376006, timestamp: 2022-08-19 14:18:02.239140\n",
      "resetting env. episode 8479, reward total was -17.0. running mean: -15.85395890642246, timestamp: 2022-08-19 14:18:10.086768\n",
      "resetting env. episode 8480, reward total was -16.0. running mean: -15.855419317358235, timestamp: 2022-08-19 14:18:17.130846\n",
      "resetting env. episode 8481, reward total was -14.0. running mean: -15.836865124184653, timestamp: 2022-08-19 14:18:23.789924\n",
      "resetting env. episode 8482, reward total was -11.0. running mean: -15.788496472942805, timestamp: 2022-08-19 14:18:32.773030\n",
      "resetting env. episode 8483, reward total was -15.0. running mean: -15.780611508213378, timestamp: 2022-08-19 14:18:41.141129\n",
      "resetting env. episode 8484, reward total was -17.0. running mean: -15.792805393131244, timestamp: 2022-08-19 14:18:47.953207\n",
      "resetting env. episode 8485, reward total was -12.0. running mean: -15.75487733919993, timestamp: 2022-08-19 14:18:57.262318\n",
      "resetting env. episode 8486, reward total was -17.0. running mean: -15.767328565807931, timestamp: 2022-08-19 14:19:03.911396\n",
      "resetting env. episode 8487, reward total was -18.0. running mean: -15.789655280149852, timestamp: 2022-08-19 14:19:12.240491\n",
      "resetting env. episode 8488, reward total was -13.0. running mean: -15.761758727348354, timestamp: 2022-08-19 14:19:20.738591\n",
      "resetting env. episode 8489, reward total was -13.0. running mean: -15.734141140074872, timestamp: 2022-08-19 14:19:28.785690\n",
      "resetting env. episode 8490, reward total was -18.0. running mean: -15.756799728674123, timestamp: 2022-08-19 14:19:34.554277\n",
      "resetting env. episode 8491, reward total was -16.0. running mean: -15.759231731387382, timestamp: 2022-08-19 14:19:41.633361\n",
      "resetting env. episode 8492, reward total was -15.0. running mean: -15.751639414073509, timestamp: 2022-08-19 14:19:50.092984\n",
      "resetting env. episode 8493, reward total was -21.0. running mean: -15.804123019932774, timestamp: 2022-08-19 14:19:55.960099\n",
      "resetting env. episode 8494, reward total was -17.0. running mean: -15.816081789733447, timestamp: 2022-08-19 14:20:03.199183\n",
      "resetting env. episode 8495, reward total was -17.0. running mean: -15.827920971836113, timestamp: 2022-08-19 14:20:10.730274\n",
      "resetting env. episode 8496, reward total was -13.0. running mean: -15.799641762117751, timestamp: 2022-08-19 14:20:19.314372\n",
      "resetting env. episode 8497, reward total was -15.0. running mean: -15.791645344496574, timestamp: 2022-08-19 14:20:27.259461\n",
      "resetting env. episode 8498, reward total was -13.0. running mean: -15.76372889105161, timestamp: 2022-08-19 14:20:34.996552\n",
      "resetting env. episode 8499, reward total was -17.0. running mean: -15.776091602141094, timestamp: 2022-08-19 14:20:40.824620\n",
      "resetting env. episode 8500, reward total was -17.0. running mean: -15.788330686119682, timestamp: 2022-08-19 14:20:46.966689\n",
      "resetting env. episode 8501, reward total was -18.0. running mean: -15.810447379258484, timestamp: 2022-08-19 14:20:51.950751\n",
      "resetting env. episode 8502, reward total was -17.0. running mean: -15.822342905465899, timestamp: 2022-08-19 14:20:57.200812\n",
      "resetting env. episode 8503, reward total was -15.0. running mean: -15.81411947641124, timestamp: 2022-08-19 14:21:05.437904\n",
      "resetting env. episode 8504, reward total was -16.0. running mean: -15.815978281647126, timestamp: 2022-08-19 14:21:13.231994\n",
      "resetting env. episode 8505, reward total was -21.0. running mean: -15.867818498830657, timestamp: 2022-08-19 14:21:21.336091\n",
      "resetting env. episode 8506, reward total was -15.0. running mean: -15.85914031384235, timestamp: 2022-08-19 14:21:29.952189\n",
      "resetting env. episode 8507, reward total was -19.0. running mean: -15.890548910703926, timestamp: 2022-08-19 14:21:35.379251\n",
      "resetting env. episode 8508, reward total was -17.0. running mean: -15.901643421596885, timestamp: 2022-08-19 14:21:41.006319\n",
      "resetting env. episode 8509, reward total was -12.0. running mean: -15.862626987380915, timestamp: 2022-08-19 14:21:49.796416\n",
      "resetting env. episode 8510, reward total was -7.0. running mean: -15.774000717507107, timestamp: 2022-08-19 14:21:59.741529\n",
      "resetting env. episode 8511, reward total was -11.0. running mean: -15.726260710332035, timestamp: 2022-08-19 14:22:09.736645\n",
      "resetting env. episode 8512, reward total was -17.0. running mean: -15.738998103228715, timestamp: 2022-08-19 14:22:18.324742\n",
      "resetting env. episode 8513, reward total was -19.0. running mean: -15.771608122196428, timestamp: 2022-08-19 14:22:23.946811\n",
      "resetting env. episode 8514, reward total was -11.0. running mean: -15.723892040974462, timestamp: 2022-08-19 14:22:32.065902\n",
      "resetting env. episode 8515, reward total was -20.0. running mean: -15.766653120564717, timestamp: 2022-08-19 14:22:38.221971\n",
      "resetting env. episode 8516, reward total was -15.0. running mean: -15.75898658935907, timestamp: 2022-08-19 14:22:45.163053\n",
      "resetting env. episode 8517, reward total was -19.0. running mean: -15.791396723465478, timestamp: 2022-08-19 14:22:52.005128\n",
      "resetting env. episode 8518, reward total was -12.0. running mean: -15.753482756230822, timestamp: 2022-08-19 14:23:01.633775\n",
      "resetting env. episode 8519, reward total was -19.0. running mean: -15.785947928668513, timestamp: 2022-08-19 14:23:08.209849\n",
      "resetting env. episode 8520, reward total was -18.0. running mean: -15.808088449381827, timestamp: 2022-08-19 14:23:15.464932\n",
      "resetting env. episode 8521, reward total was -13.0. running mean: -15.78000756488801, timestamp: 2022-08-19 14:23:24.367034\n",
      "resetting env. episode 8522, reward total was -20.0. running mean: -15.822207489239128, timestamp: 2022-08-19 14:23:30.914111\n",
      "resetting env. episode 8523, reward total was -15.0. running mean: -15.813985414346737, timestamp: 2022-08-19 14:23:37.812187\n",
      "resetting env. episode 8524, reward total was -18.0. running mean: -15.83584556020327, timestamp: 2022-08-19 14:23:43.971255\n",
      "resetting env. episode 8525, reward total was -13.0. running mean: -15.807487104601238, timestamp: 2022-08-19 14:23:51.524344\n",
      "resetting env. episode 8526, reward total was -20.0. running mean: -15.849412233555224, timestamp: 2022-08-19 14:23:56.656399\n",
      "resetting env. episode 8527, reward total was -16.0. running mean: -15.850918111219672, timestamp: 2022-08-19 14:24:02.810468\n",
      "resetting env. episode 8528, reward total was -19.0. running mean: -15.882408930107474, timestamp: 2022-08-19 14:24:08.968542\n",
      "resetting env. episode 8529, reward total was -13.0. running mean: -15.8535848408064, timestamp: 2022-08-19 14:24:16.545625\n",
      "resetting env. episode 8530, reward total was -19.0. running mean: -15.885048992398335, timestamp: 2022-08-19 14:24:23.456701\n",
      "resetting env. episode 8531, reward total was -13.0. running mean: -15.856198502474353, timestamp: 2022-08-19 14:24:32.149801\n",
      "resetting env. episode 8532, reward total was -16.0. running mean: -15.85763651744961, timestamp: 2022-08-19 14:24:38.666877\n",
      "resetting env. episode 8533, reward total was -11.0. running mean: -15.809060152275112, timestamp: 2022-08-19 14:24:46.040961\n",
      "resetting env. episode 8534, reward total was -10.0. running mean: -15.75096955075236, timestamp: 2022-08-19 14:24:53.789052\n",
      "resetting env. episode 8535, reward total was -16.0. running mean: -15.753459855244836, timestamp: 2022-08-19 14:24:59.873118\n",
      "resetting env. episode 8536, reward total was -19.0. running mean: -15.785925256692387, timestamp: 2022-08-19 14:25:05.209179\n",
      "resetting env. episode 8537, reward total was -15.0. running mean: -15.778066004125463, timestamp: 2022-08-19 14:25:12.897268\n",
      "resetting env. episode 8538, reward total was -15.0. running mean: -15.77028534408421, timestamp: 2022-08-19 14:25:21.043887\n",
      "resetting env. episode 8539, reward total was -20.0. running mean: -15.812582490643367, timestamp: 2022-08-19 14:25:26.474952\n",
      "resetting env. episode 8540, reward total was -16.0. running mean: -15.814456665736934, timestamp: 2022-08-19 14:25:32.858023\n",
      "resetting env. episode 8541, reward total was -21.0. running mean: -15.866312099079565, timestamp: 2022-08-19 14:25:38.771614\n",
      "resetting env. episode 8542, reward total was -12.0. running mean: -15.827648978088769, timestamp: 2022-08-19 14:25:47.666903\n",
      "resetting env. episode 8543, reward total was -14.0. running mean: -15.809372488307881, timestamp: 2022-08-19 14:25:56.479007\n",
      "resetting env. episode 8544, reward total was -13.0. running mean: -15.781278763424803, timestamp: 2022-08-19 14:26:02.612078\n",
      "resetting env. episode 8545, reward total was -17.0. running mean: -15.793465975790555, timestamp: 2022-08-19 14:26:09.074151\n",
      "resetting env. episode 8546, reward total was -16.0. running mean: -15.79553131603265, timestamp: 2022-08-19 14:26:15.938755\n",
      "resetting env. episode 8547, reward total was -15.0. running mean: -15.787576002872322, timestamp: 2022-08-19 14:26:24.497913\n",
      "resetting env. episode 8548, reward total was -13.0. running mean: -15.7597002428436, timestamp: 2022-08-19 14:26:32.205000\n",
      "resetting env. episode 8549, reward total was -11.0. running mean: -15.712103240415162, timestamp: 2022-08-19 14:26:39.748089\n",
      "resetting env. episode 8550, reward total was -17.0. running mean: -15.72498220801101, timestamp: 2022-08-19 14:26:47.470178\n",
      "resetting env. episode 8551, reward total was -19.0. running mean: -15.757732385930899, timestamp: 2022-08-19 14:26:54.172261\n",
      "resetting env. episode 8552, reward total was -14.0. running mean: -15.74015506207159, timestamp: 2022-08-19 14:27:01.204340\n",
      "resetting env. episode 8553, reward total was -18.0. running mean: -15.762753511450875, timestamp: 2022-08-19 14:27:06.263400\n",
      "resetting env. episode 8554, reward total was -15.0. running mean: -15.755125976336366, timestamp: 2022-08-19 14:27:11.832466\n",
      "resetting env. episode 8555, reward total was -17.0. running mean: -15.767574716573002, timestamp: 2022-08-19 14:27:19.000550\n",
      "resetting env. episode 8556, reward total was -18.0. running mean: -15.789898969407272, timestamp: 2022-08-19 14:27:25.966636\n",
      "resetting env. episode 8557, reward total was -17.0. running mean: -15.801999979713198, timestamp: 2022-08-19 14:27:32.340711\n",
      "resetting env. episode 8558, reward total was -11.0. running mean: -15.753979979916066, timestamp: 2022-08-19 14:27:40.943811\n",
      "resetting env. episode 8559, reward total was -21.0. running mean: -15.806440180116907, timestamp: 2022-08-19 14:27:47.988894\n",
      "resetting env. episode 8560, reward total was -15.0. running mean: -15.798375778315737, timestamp: 2022-08-19 14:27:56.778997\n",
      "resetting env. episode 8561, reward total was -18.0. running mean: -15.82039202053258, timestamp: 2022-08-19 14:28:04.086084\n",
      "resetting env. episode 8562, reward total was -19.0. running mean: -15.852188100327254, timestamp: 2022-08-19 14:28:10.159158\n",
      "resetting env. episode 8563, reward total was -15.0. running mean: -15.843666219323982, timestamp: 2022-08-19 14:28:17.208240\n",
      "resetting env. episode 8564, reward total was -14.0. running mean: -15.825229557130742, timestamp: 2022-08-19 14:28:23.658320\n",
      "resetting env. episode 8565, reward total was -18.0. running mean: -15.846977261559434, timestamp: 2022-08-19 14:28:32.225420\n",
      "resetting env. episode 8566, reward total was -18.0. running mean: -15.86850748894384, timestamp: 2022-08-19 14:28:38.430492\n",
      "resetting env. episode 8567, reward total was -16.0. running mean: -15.8698224140544, timestamp: 2022-08-19 14:28:44.077560\n",
      "resetting env. episode 8568, reward total was -12.0. running mean: -15.831124189913856, timestamp: 2022-08-19 14:28:51.242646\n",
      "resetting env. episode 8569, reward total was -15.0. running mean: -15.822812948014718, timestamp: 2022-08-19 14:28:58.596735\n",
      "resetting env. episode 8570, reward total was -10.0. running mean: -15.764584818534571, timestamp: 2022-08-19 14:29:07.359837\n",
      "resetting env. episode 8571, reward total was -13.0. running mean: -15.736938970349225, timestamp: 2022-08-19 14:29:15.621936\n",
      "resetting env. episode 8572, reward total was -15.0. running mean: -15.729569580645734, timestamp: 2022-08-19 14:29:22.162013\n",
      "resetting env. episode 8573, reward total was -15.0. running mean: -15.722273884839277, timestamp: 2022-08-19 14:29:28.683092\n",
      "resetting env. episode 8574, reward total was -17.0. running mean: -15.735051145990884, timestamp: 2022-08-19 14:29:35.219169\n",
      "resetting env. episode 8575, reward total was -20.0. running mean: -15.777700634530975, timestamp: 2022-08-19 14:29:40.854239\n",
      "resetting env. episode 8576, reward total was -14.0. running mean: -15.759923628185666, timestamp: 2022-08-19 14:29:48.525330\n",
      "resetting env. episode 8577, reward total was -16.0. running mean: -15.762324391903809, timestamp: 2022-08-19 14:29:55.186409\n",
      "resetting env. episode 8578, reward total was -19.0. running mean: -15.79470114798477, timestamp: 2022-08-19 14:30:01.810486\n",
      "resetting env. episode 8579, reward total was -20.0. running mean: -15.83675413650492, timestamp: 2022-08-19 14:30:07.977559\n",
      "resetting env. episode 8580, reward total was -14.0. running mean: -15.818386595139872, timestamp: 2022-08-19 14:30:16.639662\n",
      "resetting env. episode 8581, reward total was -11.0. running mean: -15.770202729188473, timestamp: 2022-08-19 14:30:25.358768\n",
      "resetting env. episode 8582, reward total was -15.0. running mean: -15.762500701896588, timestamp: 2022-08-19 14:30:32.910854\n",
      "resetting env. episode 8583, reward total was -12.0. running mean: -15.724875694877621, timestamp: 2022-08-19 14:30:41.128954\n",
      "resetting env. episode 8584, reward total was -17.0. running mean: -15.737626937928844, timestamp: 2022-08-19 14:30:47.100028\n",
      "resetting env. episode 8585, reward total was -15.0. running mean: -15.730250668549557, timestamp: 2022-08-19 14:30:54.506112\n",
      "resetting env. episode 8586, reward total was -20.0. running mean: -15.772948161864061, timestamp: 2022-08-19 14:31:00.719714\n",
      "resetting env. episode 8587, reward total was -17.0. running mean: -15.785218680245421, timestamp: 2022-08-19 14:31:07.074792\n",
      "resetting env. episode 8588, reward total was -16.0. running mean: -15.787366493442967, timestamp: 2022-08-19 14:31:14.676882\n",
      "resetting env. episode 8589, reward total was -15.0. running mean: -15.779492828508538, timestamp: 2022-08-19 14:31:22.376974\n",
      "resetting env. episode 8590, reward total was -13.0. running mean: -15.751697900223453, timestamp: 2022-08-19 14:31:29.937061\n",
      "resetting env. episode 8591, reward total was -12.0. running mean: -15.714180921221217, timestamp: 2022-08-19 14:31:43.775748\n",
      "resetting env. episode 8592, reward total was -16.0. running mean: -15.717039112009004, timestamp: 2022-08-19 14:31:52.802854\n",
      "resetting env. episode 8593, reward total was -18.0. running mean: -15.739868720888914, timestamp: 2022-08-19 14:32:01.509960\n",
      "resetting env. episode 8594, reward total was -15.0. running mean: -15.732470033680025, timestamp: 2022-08-19 14:32:10.455067\n",
      "resetting env. episode 8595, reward total was -15.0. running mean: -15.725145333343225, timestamp: 2022-08-19 14:32:19.963697\n",
      "resetting env. episode 8596, reward total was -15.0. running mean: -15.717893880009793, timestamp: 2022-08-19 14:32:30.563870\n",
      "resetting env. episode 8597, reward total was -15.0. running mean: -15.710714941209696, timestamp: 2022-08-19 14:32:42.390009\n",
      "resetting env. episode 8598, reward total was -19.0. running mean: -15.743607791797599, timestamp: 2022-08-19 14:32:50.253103\n",
      "resetting env. episode 8599, reward total was -17.0. running mean: -15.756171713879622, timestamp: 2022-08-19 14:32:59.717217\n",
      "resetting env. episode 8600, reward total was -12.0. running mean: -15.718609996740826, timestamp: 2022-08-19 14:33:10.624343\n",
      "resetting env. episode 8601, reward total was -18.0. running mean: -15.741423896773417, timestamp: 2022-08-19 14:33:18.421438\n",
      "resetting env. episode 8602, reward total was -13.0. running mean: -15.714009657805684, timestamp: 2022-08-19 14:33:31.331589\n",
      "resetting env. episode 8603, reward total was -14.0. running mean: -15.696869561227627, timestamp: 2022-08-19 14:33:41.063227\n",
      "resetting env. episode 8604, reward total was -15.0. running mean: -15.689900865615352, timestamp: 2022-08-19 14:33:51.224348\n",
      "resetting env. episode 8605, reward total was -13.0. running mean: -15.663001856959198, timestamp: 2022-08-19 14:33:59.987972\n",
      "resetting env. episode 8606, reward total was -18.0. running mean: -15.686371838389606, timestamp: 2022-08-19 14:34:10.195092\n",
      "resetting env. episode 8607, reward total was -17.0. running mean: -15.69950812000571, timestamp: 2022-08-19 14:34:20.150212\n",
      "resetting env. episode 8608, reward total was -18.0. running mean: -15.722513038805653, timestamp: 2022-08-19 14:34:29.155843\n",
      "resetting env. episode 8609, reward total was -13.0. running mean: -15.695287908417598, timestamp: 2022-08-19 14:34:39.182963\n",
      "resetting env. episode 8610, reward total was -17.0. running mean: -15.708335029333421, timestamp: 2022-08-19 14:34:48.967077\n",
      "resetting env. episode 8611, reward total was -15.0. running mean: -15.701251679040087, timestamp: 2022-08-19 14:35:00.813225\n",
      "resetting env. episode 8612, reward total was -17.0. running mean: -15.714239162249687, timestamp: 2022-08-19 14:35:09.453318\n",
      "resetting env. episode 8613, reward total was -13.0. running mean: -15.68709677062719, timestamp: 2022-08-19 14:35:17.912421\n",
      "resetting env. episode 8614, reward total was -18.0. running mean: -15.710225802920919, timestamp: 2022-08-19 14:35:25.037503\n",
      "resetting env. episode 8615, reward total was -15.0. running mean: -15.70312354489171, timestamp: 2022-08-19 14:35:32.902120\n",
      "resetting env. episode 8616, reward total was -19.0. running mean: -15.736092309442792, timestamp: 2022-08-19 14:35:40.026201\n",
      "resetting env. episode 8617, reward total was -12.0. running mean: -15.698731386348364, timestamp: 2022-08-19 14:35:48.067294\n",
      "resetting env. episode 8618, reward total was -21.0. running mean: -15.75174407248488, timestamp: 2022-08-19 14:35:55.880388\n",
      "resetting env. episode 8619, reward total was -14.0. running mean: -15.734226631760032, timestamp: 2022-08-19 14:36:04.834491\n",
      "resetting env. episode 8620, reward total was -14.0. running mean: -15.716884365442432, timestamp: 2022-08-19 14:36:13.891597\n",
      "resetting env. episode 8621, reward total was -17.0. running mean: -15.729715521788007, timestamp: 2022-08-19 14:36:21.490685\n",
      "resetting env. episode 8622, reward total was -19.0. running mean: -15.762418366570126, timestamp: 2022-08-19 14:36:27.793761\n",
      "resetting env. episode 8623, reward total was -15.0. running mean: -15.754794182904424, timestamp: 2022-08-19 14:36:37.065868\n",
      "resetting env. episode 8624, reward total was -15.0. running mean: -15.74724624107538, timestamp: 2022-08-19 14:36:45.297963\n",
      "resetting env. episode 8625, reward total was -16.0. running mean: -15.749773778664627, timestamp: 2022-08-19 14:36:52.552574\n",
      "resetting env. episode 8626, reward total was -15.0. running mean: -15.74227604087798, timestamp: 2022-08-19 14:37:01.325196\n",
      "resetting env. episode 8627, reward total was -17.0. running mean: -15.7548532804692, timestamp: 2022-08-19 14:37:08.971287\n",
      "resetting env. episode 8628, reward total was -17.0. running mean: -15.76730474766451, timestamp: 2022-08-19 14:37:17.154381\n",
      "resetting env. episode 8629, reward total was -3.0. running mean: -15.639631700187863, timestamp: 2022-08-19 14:37:27.482501\n",
      "resetting env. episode 8630, reward total was -19.0. running mean: -15.673235383185984, timestamp: 2022-08-19 14:37:34.887110\n",
      "resetting env. episode 8631, reward total was -19.0. running mean: -15.706503029354124, timestamp: 2022-08-19 14:37:41.824187\n",
      "resetting env. episode 8632, reward total was -15.0. running mean: -15.699437999060583, timestamp: 2022-08-19 14:37:49.622280\n",
      "resetting env. episode 8633, reward total was -15.0. running mean: -15.692443619069978, timestamp: 2022-08-19 14:37:57.369368\n",
      "resetting env. episode 8634, reward total was -9.0. running mean: -15.625519182879279, timestamp: 2022-08-19 14:38:08.250023\n",
      "resetting env. episode 8635, reward total was -12.0. running mean: -15.589263991050485, timestamp: 2022-08-19 14:38:18.104132\n",
      "resetting env. episode 8636, reward total was -17.0. running mean: -15.60337135113998, timestamp: 2022-08-19 14:38:25.539749\n",
      "resetting env. episode 8637, reward total was -15.0. running mean: -15.59733763762858, timestamp: 2022-08-19 14:38:33.623367\n",
      "resetting env. episode 8638, reward total was -17.0. running mean: -15.611364261252294, timestamp: 2022-08-19 14:38:42.029467\n",
      "resetting env. episode 8639, reward total was -14.0. running mean: -15.595250618639772, timestamp: 2022-08-19 14:38:53.345119\n",
      "resetting env. episode 8640, reward total was -17.0. running mean: -15.609298112453374, timestamp: 2022-08-19 14:39:00.520728\n",
      "resetting env. episode 8641, reward total was -18.0. running mean: -15.63320513132884, timestamp: 2022-08-19 14:39:07.632812\n",
      "resetting env. episode 8642, reward total was -17.0. running mean: -15.64687308001555, timestamp: 2022-08-19 14:39:17.852931\n",
      "resetting env. episode 8643, reward total was -10.0. running mean: -15.590404349215396, timestamp: 2022-08-19 14:39:27.386036\n",
      "resetting env. episode 8644, reward total was -15.0. running mean: -15.584500305723243, timestamp: 2022-08-19 14:39:35.438129\n",
      "resetting env. episode 8645, reward total was -19.0. running mean: -15.61865530266601, timestamp: 2022-08-19 14:39:42.307207\n",
      "resetting env. episode 8646, reward total was -17.0. running mean: -15.632468749639349, timestamp: 2022-08-19 14:39:49.426290\n",
      "resetting env. episode 8647, reward total was -18.0. running mean: -15.656144062142955, timestamp: 2022-08-19 14:39:55.520356\n",
      "resetting env. episode 8648, reward total was -17.0. running mean: -15.669582621521526, timestamp: 2022-08-19 14:40:03.667451\n",
      "resetting env. episode 8649, reward total was -11.0. running mean: -15.622886795306309, timestamp: 2022-08-19 14:40:13.810567\n",
      "resetting env. episode 8650, reward total was -12.0. running mean: -15.586657927353246, timestamp: 2022-08-19 14:40:21.820657\n",
      "resetting env. episode 8651, reward total was -15.0. running mean: -15.580791348079714, timestamp: 2022-08-19 14:40:28.543733\n",
      "resetting env. episode 8652, reward total was -19.0. running mean: -15.614983434598916, timestamp: 2022-08-19 14:40:35.986817\n",
      "resetting env. episode 8653, reward total was -10.0. running mean: -15.558833600252926, timestamp: 2022-08-19 14:40:47.115943\n",
      "resetting env. episode 8654, reward total was -17.0. running mean: -15.573245264250398, timestamp: 2022-08-19 14:40:55.865090\n",
      "resetting env. episode 8655, reward total was -16.0. running mean: -15.577512811607894, timestamp: 2022-08-19 14:41:03.042175\n",
      "resetting env. episode 8656, reward total was -11.0. running mean: -15.531737683491814, timestamp: 2022-08-19 14:41:12.857281\n",
      "resetting env. episode 8657, reward total was -17.0. running mean: -15.546420306656895, timestamp: 2022-08-19 14:41:21.007897\n",
      "resetting env. episode 8658, reward total was -19.0. running mean: -15.580956103590326, timestamp: 2022-08-19 14:41:29.698517\n",
      "resetting env. episode 8659, reward total was -19.0. running mean: -15.615146542554422, timestamp: 2022-08-19 14:41:36.861598\n",
      "resetting env. episode 8660, reward total was -17.0. running mean: -15.628995077128877, timestamp: 2022-08-19 14:41:44.594683\n",
      "resetting env. episode 8661, reward total was -19.0. running mean: -15.662705126357588, timestamp: 2022-08-19 14:41:52.714776\n",
      "resetting env. episode 8662, reward total was -14.0. running mean: -15.646078075094012, timestamp: 2022-08-19 14:42:01.493877\n",
      "resetting env. episode 8663, reward total was -14.0. running mean: -15.629617294343072, timestamp: 2022-08-19 14:42:11.926046\n",
      "resetting env. episode 8664, reward total was -13.0. running mean: -15.603321121399642, timestamp: 2022-08-19 14:42:22.153161\n",
      "resetting env. episode 8665, reward total was -10.0. running mean: -15.547287910185645, timestamp: 2022-08-19 14:42:31.977275\n",
      "resetting env. episode 8666, reward total was -17.0. running mean: -15.561815031083789, timestamp: 2022-08-19 14:42:41.694385\n",
      "resetting env. episode 8667, reward total was -13.0. running mean: -15.536196880772952, timestamp: 2022-08-19 14:42:50.648014\n",
      "resetting env. episode 8668, reward total was -17.0. running mean: -15.550834911965222, timestamp: 2022-08-19 14:42:58.520635\n",
      "resetting env. episode 8669, reward total was -14.0. running mean: -15.53532656284557, timestamp: 2022-08-19 14:43:07.078732\n",
      "resetting env. episode 8670, reward total was -15.0. running mean: -15.529973297217115, timestamp: 2022-08-19 14:43:19.413396\n",
      "resetting env. episode 8671, reward total was -12.0. running mean: -15.494673564244943, timestamp: 2022-08-19 14:43:28.624504\n",
      "resetting env. episode 8672, reward total was -19.0. running mean: -15.529726828602493, timestamp: 2022-08-19 14:43:35.039106\n",
      "resetting env. episode 8673, reward total was -9.0. running mean: -15.464429560316468, timestamp: 2022-08-19 14:43:44.800269\n",
      "resetting env. episode 8674, reward total was -16.0. running mean: -15.469785264713304, timestamp: 2022-08-19 14:43:53.115367\n",
      "resetting env. episode 8675, reward total was -15.0. running mean: -15.46508741206617, timestamp: 2022-08-19 14:44:00.028447\n",
      "resetting env. episode 8676, reward total was -14.0. running mean: -15.450436537945508, timestamp: 2022-08-19 14:44:08.185542\n",
      "resetting env. episode 8677, reward total was -11.0. running mean: -15.405932172566052, timestamp: 2022-08-19 14:44:16.286640\n",
      "resetting env. episode 8678, reward total was -16.0. running mean: -15.41187285084039, timestamp: 2022-08-19 14:44:23.566723\n",
      "resetting env. episode 8679, reward total was -19.0. running mean: -15.447754122331986, timestamp: 2022-08-19 14:44:31.126814\n",
      "resetting env. episode 8680, reward total was -16.0. running mean: -15.453276581108666, timestamp: 2022-08-19 14:44:40.394924\n",
      "resetting env. episode 8681, reward total was -17.0. running mean: -15.468743815297579, timestamp: 2022-08-19 14:44:46.652997\n",
      "resetting env. episode 8682, reward total was -14.0. running mean: -15.454056377144603, timestamp: 2022-08-19 14:44:54.864095\n",
      "resetting env. episode 8683, reward total was -14.0. running mean: -15.439515813373157, timestamp: 2022-08-19 14:45:05.650221\n",
      "resetting env. episode 8684, reward total was -17.0. running mean: -15.455120655239426, timestamp: 2022-08-19 14:45:11.337290\n",
      "resetting env. episode 8685, reward total was -18.0. running mean: -15.480569448687032, timestamp: 2022-08-19 14:45:18.352905\n",
      "resetting env. episode 8686, reward total was -13.0. running mean: -15.455763754200161, timestamp: 2022-08-19 14:45:27.135012\n",
      "resetting env. episode 8687, reward total was -14.0. running mean: -15.44120611665816, timestamp: 2022-08-19 14:45:36.857127\n",
      "resetting env. episode 8688, reward total was -16.0. running mean: -15.446794055491578, timestamp: 2022-08-19 14:45:45.959761\n",
      "resetting env. episode 8689, reward total was -20.0. running mean: -15.492326114936661, timestamp: 2022-08-19 14:45:52.837841\n",
      "resetting env. episode 8690, reward total was -15.0. running mean: -15.487402853787295, timestamp: 2022-08-19 14:46:00.536933\n",
      "resetting env. episode 8691, reward total was -15.0. running mean: -15.482528825249421, timestamp: 2022-08-19 14:46:07.808019\n",
      "resetting env. episode 8692, reward total was -17.0. running mean: -15.497703536996926, timestamp: 2022-08-19 14:46:16.171121\n",
      "resetting env. episode 8693, reward total was -19.0. running mean: -15.532726501626957, timestamp: 2022-08-19 14:46:23.229721\n",
      "resetting env. episode 8694, reward total was -14.0. running mean: -15.517399236610688, timestamp: 2022-08-19 14:46:32.030828\n",
      "resetting env. episode 8695, reward total was -17.0. running mean: -15.53222524424458, timestamp: 2022-08-19 14:46:39.207914\n",
      "resetting env. episode 8696, reward total was -16.0. running mean: -15.536902991802135, timestamp: 2022-08-19 14:46:47.983020\n",
      "resetting env. episode 8697, reward total was -15.0. running mean: -15.531533961884113, timestamp: 2022-08-19 14:46:57.017129\n",
      "resetting env. episode 8698, reward total was -14.0. running mean: -15.516218622265272, timestamp: 2022-08-19 14:47:05.493225\n",
      "resetting env. episode 8699, reward total was -17.0. running mean: -15.53105643604262, timestamp: 2022-08-19 14:47:13.293322\n",
      "resetting env. episode 8700, reward total was -17.0. running mean: -15.545745871682193, timestamp: 2022-08-19 14:47:20.668406\n",
      "resetting env. episode 8701, reward total was -16.0. running mean: -15.55028841296537, timestamp: 2022-08-19 14:47:28.010497\n",
      "resetting env. episode 8702, reward total was -17.0. running mean: -15.564785528835717, timestamp: 2022-08-19 14:47:35.137106\n",
      "resetting env. episode 8703, reward total was -18.0. running mean: -15.58913767354736, timestamp: 2022-08-19 14:47:44.356264\n",
      "resetting env. episode 8704, reward total was -19.0. running mean: -15.623246296811885, timestamp: 2022-08-19 14:47:55.657397\n",
      "resetting env. episode 8705, reward total was -9.0. running mean: -15.557013833843767, timestamp: 2022-08-19 14:48:06.920531\n",
      "resetting env. episode 8706, reward total was -15.0. running mean: -15.551443695505329, timestamp: 2022-08-19 14:48:15.199629\n",
      "resetting env. episode 8707, reward total was -15.0. running mean: -15.545929258550276, timestamp: 2022-08-19 14:48:24.470742\n",
      "resetting env. episode 8708, reward total was -16.0. running mean: -15.550469965964773, timestamp: 2022-08-19 14:48:31.185343\n",
      "resetting env. episode 8709, reward total was -19.0. running mean: -15.584965266305124, timestamp: 2022-08-19 14:48:38.372946\n",
      "resetting env. episode 8710, reward total was -15.0. running mean: -15.579115613642074, timestamp: 2022-08-19 14:48:48.768070\n",
      "resetting env. episode 8711, reward total was -17.0. running mean: -15.593324457505654, timestamp: 2022-08-19 14:48:58.311184\n",
      "resetting env. episode 8712, reward total was -12.0. running mean: -15.557391212930597, timestamp: 2022-08-19 14:49:07.532295\n",
      "resetting env. episode 8713, reward total was -12.0. running mean: -15.52181730080129, timestamp: 2022-08-19 14:49:17.433415\n",
      "resetting env. episode 8714, reward total was -17.0. running mean: -15.536599127793277, timestamp: 2022-08-19 14:49:25.174507\n",
      "resetting env. episode 8715, reward total was -19.0. running mean: -15.571233136515344, timestamp: 2022-08-19 14:49:33.320604\n",
      "resetting env. episode 8716, reward total was -15.0. running mean: -15.565520805150191, timestamp: 2022-08-19 14:49:42.489710\n",
      "resetting env. episode 8717, reward total was -13.0. running mean: -15.53986559709869, timestamp: 2022-08-19 14:49:51.666822\n",
      "resetting env. episode 8718, reward total was -11.0. running mean: -15.494466941127701, timestamp: 2022-08-19 14:50:00.157921\n",
      "resetting env. episode 8719, reward total was -17.0. running mean: -15.509522271716424, timestamp: 2022-08-19 14:50:07.986014\n",
      "resetting env. episode 8720, reward total was -13.0. running mean: -15.48442704899926, timestamp: 2022-08-19 14:50:17.466126\n",
      "resetting env. episode 8721, reward total was -17.0. running mean: -15.499582778509268, timestamp: 2022-08-19 14:50:25.622222\n",
      "resetting env. episode 8722, reward total was -18.0. running mean: -15.524586950724174, timestamp: 2022-08-19 14:50:31.907826\n",
      "resetting env. episode 8723, reward total was -11.0. running mean: -15.479341081216932, timestamp: 2022-08-19 14:50:40.678932\n",
      "resetting env. episode 8724, reward total was -15.0. running mean: -15.474547670404762, timestamp: 2022-08-19 14:50:48.727022\n",
      "resetting env. episode 8725, reward total was -13.0. running mean: -15.449802193700716, timestamp: 2022-08-19 14:50:58.558139\n",
      "resetting env. episode 8726, reward total was -15.0. running mean: -15.44530417176371, timestamp: 2022-08-19 14:51:07.315242\n",
      "resetting env. episode 8727, reward total was -14.0. running mean: -15.430851130046072, timestamp: 2022-08-19 14:51:15.078339\n",
      "resetting env. episode 8728, reward total was -15.0. running mean: -15.426542618745613, timestamp: 2022-08-19 14:51:22.030417\n",
      "resetting env. episode 8729, reward total was -12.0. running mean: -15.392277192558156, timestamp: 2022-08-19 14:51:32.235540\n",
      "resetting env. episode 8730, reward total was -15.0. running mean: -15.388354420632576, timestamp: 2022-08-19 14:51:40.260631\n",
      "resetting env. episode 8731, reward total was -19.0. running mean: -15.424470876426248, timestamp: 2022-08-19 14:51:46.593707\n",
      "resetting env. episode 8732, reward total was -18.0. running mean: -15.450226167661986, timestamp: 2022-08-19 14:51:54.663804\n",
      "resetting env. episode 8733, reward total was -19.0. running mean: -15.485723905985365, timestamp: 2022-08-19 14:52:01.253880\n",
      "resetting env. episode 8734, reward total was -14.0. running mean: -15.470866666925511, timestamp: 2022-08-19 14:52:09.102972\n",
      "resetting env. episode 8735, reward total was -18.0. running mean: -15.496158000256255, timestamp: 2022-08-19 14:52:17.765079\n",
      "resetting env. episode 8736, reward total was -3.0. running mean: -15.37119642025369, timestamp: 2022-08-19 14:52:28.782202\n",
      "resetting env. episode 8737, reward total was -16.0. running mean: -15.377484456051153, timestamp: 2022-08-19 14:52:36.245292\n",
      "resetting env. episode 8738, reward total was -20.0. running mean: -15.42370961149064, timestamp: 2022-08-19 14:52:43.803377\n",
      "resetting env. episode 8739, reward total was -13.0. running mean: -15.399472515375734, timestamp: 2022-08-19 14:52:53.329490\n",
      "resetting env. episode 8740, reward total was -16.0. running mean: -15.405477790221976, timestamp: 2022-08-19 14:53:01.076581\n",
      "resetting env. episode 8741, reward total was -15.0. running mean: -15.401423012319757, timestamp: 2022-08-19 14:53:09.225679\n",
      "resetting env. episode 8742, reward total was -15.0. running mean: -15.39740878219656, timestamp: 2022-08-19 14:53:17.120772\n",
      "resetting env. episode 8743, reward total was -14.0. running mean: -15.383434694374595, timestamp: 2022-08-19 14:53:26.749411\n",
      "resetting env. episode 8744, reward total was -13.0. running mean: -15.359600347430849, timestamp: 2022-08-19 14:53:34.616502\n",
      "resetting env. episode 8745, reward total was -15.0. running mean: -15.35600434395654, timestamp: 2022-08-19 14:53:42.148594\n",
      "resetting env. episode 8746, reward total was -20.0. running mean: -15.402444300516974, timestamp: 2022-08-19 14:53:51.287697\n",
      "resetting env. episode 8747, reward total was -16.0. running mean: -15.408419857511804, timestamp: 2022-08-19 14:53:58.260776\n",
      "resetting env. episode 8748, reward total was -14.0. running mean: -15.394335658936686, timestamp: 2022-08-19 14:54:07.855888\n",
      "resetting env. episode 8749, reward total was -16.0. running mean: -15.400392302347319, timestamp: 2022-08-19 14:54:15.884981\n",
      "resetting env. episode 8750, reward total was -19.0. running mean: -15.436388379323844, timestamp: 2022-08-19 14:54:23.031066\n",
      "resetting env. episode 8751, reward total was -18.0. running mean: -15.462024495530606, timestamp: 2022-08-19 14:54:32.696177\n",
      "resetting env. episode 8752, reward total was -17.0. running mean: -15.477404250575301, timestamp: 2022-08-19 14:54:39.770257\n",
      "resetting env. episode 8753, reward total was -13.0. running mean: -15.452630208069548, timestamp: 2022-08-19 14:54:47.985353\n",
      "resetting env. episode 8754, reward total was -11.0. running mean: -15.408103905988852, timestamp: 2022-08-19 14:54:59.823493\n",
      "resetting env. episode 8755, reward total was -14.0. running mean: -15.394022866928964, timestamp: 2022-08-19 14:55:08.785594\n",
      "resetting env. episode 8756, reward total was -15.0. running mean: -15.390082638259674, timestamp: 2022-08-19 14:55:15.676674\n",
      "resetting env. episode 8757, reward total was -16.0. running mean: -15.396181811877078, timestamp: 2022-08-19 14:55:23.462763\n",
      "resetting env. episode 8758, reward total was -17.0. running mean: -15.412219993758306, timestamp: 2022-08-19 14:55:31.599859\n",
      "resetting env. episode 8759, reward total was -18.0. running mean: -15.438097793820722, timestamp: 2022-08-19 14:55:39.181945\n",
      "resetting env. episode 8760, reward total was -17.0. running mean: -15.453716815882515, timestamp: 2022-08-19 14:55:47.273037\n",
      "resetting env. episode 8761, reward total was -11.0. running mean: -15.40917964772369, timestamp: 2022-08-19 14:55:56.423146\n",
      "resetting env. episode 8762, reward total was -17.0. running mean: -15.425087851246452, timestamp: 2022-08-19 14:56:04.004753\n",
      "resetting env. episode 8763, reward total was -13.0. running mean: -15.40083697273399, timestamp: 2022-08-19 14:56:12.905858\n",
      "resetting env. episode 8764, reward total was -14.0. running mean: -15.38682860300665, timestamp: 2022-08-19 14:56:20.121941\n",
      "resetting env. episode 8765, reward total was -11.0. running mean: -15.342960316976583, timestamp: 2022-08-19 14:56:30.427055\n",
      "resetting env. episode 8766, reward total was -15.0. running mean: -15.339530713806818, timestamp: 2022-08-19 14:56:38.335147\n",
      "resetting env. episode 8767, reward total was -15.0. running mean: -15.33613540666875, timestamp: 2022-08-19 14:56:46.282239\n",
      "resetting env. episode 8768, reward total was -18.0. running mean: -15.362774052602063, timestamp: 2022-08-19 14:56:55.268864\n",
      "resetting env. episode 8769, reward total was -15.0. running mean: -15.359146312076042, timestamp: 2022-08-19 14:57:04.100964\n",
      "resetting env. episode 8770, reward total was -8.0. running mean: -15.285554848955282, timestamp: 2022-08-19 14:57:13.801132\n",
      "resetting env. episode 8771, reward total was -13.0. running mean: -15.26269930046573, timestamp: 2022-08-19 14:57:21.811218\n",
      "resetting env. episode 8772, reward total was -19.0. running mean: -15.300072307461072, timestamp: 2022-08-19 14:57:29.526308\n",
      "resetting env. episode 8773, reward total was -12.0. running mean: -15.26707158438646, timestamp: 2022-08-19 14:57:37.260396\n",
      "resetting env. episode 8774, reward total was -17.0. running mean: -15.284400868542596, timestamp: 2022-08-19 14:57:44.795001\n",
      "resetting env. episode 8775, reward total was -16.0. running mean: -15.29155685985717, timestamp: 2022-08-19 14:57:52.684092\n",
      "resetting env. episode 8776, reward total was -17.0. running mean: -15.3086412912586, timestamp: 2022-08-19 14:58:01.123187\n",
      "resetting env. episode 8777, reward total was -19.0. running mean: -15.345554878346013, timestamp: 2022-08-19 14:58:09.234277\n",
      "resetting env. episode 8778, reward total was -21.0. running mean: -15.402099329562553, timestamp: 2022-08-19 14:58:16.108355\n",
      "resetting env. episode 8779, reward total was -14.0. running mean: -15.388078336266927, timestamp: 2022-08-19 14:58:26.183468\n",
      "resetting env. episode 8780, reward total was -15.0. running mean: -15.384197552904258, timestamp: 2022-08-19 14:58:34.296562\n",
      "resetting env. episode 8781, reward total was -17.0. running mean: -15.400355577375215, timestamp: 2022-08-19 14:58:43.280664\n",
      "resetting env. episode 8782, reward total was -17.0. running mean: -15.416352021601464, timestamp: 2022-08-19 14:58:49.796734\n",
      "resetting env. episode 8783, reward total was -16.0. running mean: -15.422188501385449, timestamp: 2022-08-19 14:58:57.206821\n",
      "resetting env. episode 8784, reward total was -19.0. running mean: -15.457966616371595, timestamp: 2022-08-19 14:59:03.803898\n",
      "resetting env. episode 8785, reward total was -13.0. running mean: -15.433386950207879, timestamp: 2022-08-19 14:59:11.225982\n",
      "resetting env. episode 8786, reward total was -17.0. running mean: -15.4490530807058, timestamp: 2022-08-19 14:59:19.124595\n",
      "resetting env. episode 8787, reward total was -13.0. running mean: -15.424562549898743, timestamp: 2022-08-19 14:59:28.851707\n",
      "resetting env. episode 8788, reward total was -13.0. running mean: -15.400316924399757, timestamp: 2022-08-19 14:59:39.473827\n",
      "resetting env. episode 8789, reward total was -19.0. running mean: -15.436313755155759, timestamp: 2022-08-19 14:59:45.168418\n",
      "resetting env. episode 8790, reward total was -14.0. running mean: -15.421950617604201, timestamp: 2022-08-19 14:59:52.552026\n",
      "resetting env. episode 8791, reward total was -10.0. running mean: -15.367731111428158, timestamp: 2022-08-19 15:00:03.082674\n",
      "resetting env. episode 8792, reward total was -16.0. running mean: -15.374053800313877, timestamp: 2022-08-19 15:00:11.813775\n",
      "resetting env. episode 8793, reward total was -15.0. running mean: -15.37031326231074, timestamp: 2022-08-19 15:00:19.197857\n",
      "resetting env. episode 8794, reward total was -17.0. running mean: -15.386610129687632, timestamp: 2022-08-19 15:00:26.239940\n",
      "resetting env. episode 8795, reward total was -17.0. running mean: -15.402744028390757, timestamp: 2022-08-19 15:00:34.115032\n",
      "resetting env. episode 8796, reward total was -16.0. running mean: -15.408716588106849, timestamp: 2022-08-19 15:00:42.953663\n",
      "resetting env. episode 8797, reward total was -19.0. running mean: -15.444629422225779, timestamp: 2022-08-19 15:00:49.362741\n",
      "resetting env. episode 8798, reward total was -13.0. running mean: -15.420183128003522, timestamp: 2022-08-19 15:00:58.027361\n",
      "resetting env. episode 8799, reward total was -17.0. running mean: -15.435981296723487, timestamp: 2022-08-19 15:01:05.334446\n",
      "resetting env. episode 8800, reward total was -11.0. running mean: -15.391621483756252, timestamp: 2022-08-19 15:01:14.770085\n",
      "resetting env. episode 8801, reward total was -13.0. running mean: -15.367705268918689, timestamp: 2022-08-19 15:01:24.581205\n",
      "resetting env. episode 8802, reward total was -14.0. running mean: -15.354028216229503, timestamp: 2022-08-19 15:01:32.072295\n",
      "resetting env. episode 8803, reward total was -11.0. running mean: -15.310487934067208, timestamp: 2022-08-19 15:01:41.028398\n",
      "resetting env. episode 8804, reward total was -17.0. running mean: -15.327383054726536, timestamp: 2022-08-19 15:01:47.550475\n",
      "resetting env. episode 8805, reward total was -19.0. running mean: -15.36410922417927, timestamp: 2022-08-19 15:01:54.424556\n",
      "resetting env. episode 8806, reward total was -15.0. running mean: -15.360468131937477, timestamp: 2022-08-19 15:02:03.431663\n",
      "resetting env. episode 8807, reward total was -19.0. running mean: -15.3968634506181, timestamp: 2022-08-19 15:02:10.997750\n",
      "resetting env. episode 8808, reward total was -19.0. running mean: -15.432894816111919, timestamp: 2022-08-19 15:02:18.213837\n",
      "resetting env. episode 8809, reward total was -17.0. running mean: -15.4485658679508, timestamp: 2022-08-19 15:02:25.403922\n",
      "resetting env. episode 8810, reward total was -18.0. running mean: -15.47408020927129, timestamp: 2022-08-19 15:02:33.070534\n",
      "resetting env. episode 8811, reward total was -13.0. running mean: -15.449339407178579, timestamp: 2022-08-19 15:02:41.460632\n",
      "resetting env. episode 8812, reward total was -17.0. running mean: -15.464846013106794, timestamp: 2022-08-19 15:02:49.224724\n",
      "resetting env. episode 8813, reward total was -15.0. running mean: -15.460197552975727, timestamp: 2022-08-19 15:02:57.815828\n",
      "resetting env. episode 8814, reward total was -19.0. running mean: -15.495595577445968, timestamp: 2022-08-19 15:03:04.598908\n",
      "resetting env. episode 8815, reward total was -11.0. running mean: -15.450639621671508, timestamp: 2022-08-19 15:03:12.980009\n",
      "resetting env. episode 8816, reward total was -17.0. running mean: -15.466133225454792, timestamp: 2022-08-19 15:03:21.573108\n",
      "resetting env. episode 8817, reward total was -19.0. running mean: -15.501471893200243, timestamp: 2022-08-19 15:03:28.020187\n",
      "resetting env. episode 8818, reward total was -16.0. running mean: -15.50645717426824, timestamp: 2022-08-19 15:03:36.237332\n",
      "resetting env. episode 8819, reward total was -19.0. running mean: -15.541392602525557, timestamp: 2022-08-19 15:03:42.473411\n",
      "resetting env. episode 8820, reward total was -19.0. running mean: -15.5759786765003, timestamp: 2022-08-19 15:03:48.830483\n",
      "resetting env. episode 8821, reward total was -17.0. running mean: -15.590218889735297, timestamp: 2022-08-19 15:03:55.960568\n",
      "resetting env. episode 8822, reward total was -15.0. running mean: -15.584316700837944, timestamp: 2022-08-19 15:04:03.528660\n",
      "resetting env. episode 8823, reward total was -19.0. running mean: -15.618473533829563, timestamp: 2022-08-19 15:04:11.805756\n",
      "resetting env. episode 8824, reward total was -13.0. running mean: -15.592288798491268, timestamp: 2022-08-19 15:04:21.256870\n",
      "resetting env. episode 8825, reward total was -19.0. running mean: -15.626365910506355, timestamp: 2022-08-19 15:04:29.084494\n",
      "resetting env. episode 8826, reward total was -18.0. running mean: -15.650102251401291, timestamp: 2022-08-19 15:04:35.352567\n",
      "resetting env. episode 8827, reward total was -19.0. running mean: -15.683601228887278, timestamp: 2022-08-19 15:04:42.413648\n",
      "resetting env. episode 8828, reward total was -16.0. running mean: -15.686765216598406, timestamp: 2022-08-19 15:04:49.626739\n",
      "resetting env. episode 8829, reward total was -16.0. running mean: -15.689897564432423, timestamp: 2022-08-19 15:04:58.261838\n",
      "resetting env. episode 8830, reward total was -15.0. running mean: -15.682998588788099, timestamp: 2022-08-19 15:05:06.133459\n",
      "resetting env. episode 8831, reward total was -17.0. running mean: -15.696168602900217, timestamp: 2022-08-19 15:05:12.914539\n",
      "resetting env. episode 8832, reward total was -13.0. running mean: -15.669206916871216, timestamp: 2022-08-19 15:05:22.587654\n",
      "resetting env. episode 8833, reward total was -17.0. running mean: -15.682514847702503, timestamp: 2022-08-19 15:05:32.216289\n",
      "resetting env. episode 8834, reward total was -12.0. running mean: -15.645689699225477, timestamp: 2022-08-19 15:05:43.708427\n",
      "resetting env. episode 8835, reward total was -17.0. running mean: -15.659232802233221, timestamp: 2022-08-19 15:05:51.273514\n",
      "resetting env. episode 8836, reward total was -16.0. running mean: -15.662640474210889, timestamp: 2022-08-19 15:05:58.434127\n",
      "resetting env. episode 8837, reward total was -19.0. running mean: -15.696014069468779, timestamp: 2022-08-19 15:06:04.421198\n",
      "resetting env. episode 8838, reward total was -14.0. running mean: -15.679053928774092, timestamp: 2022-08-19 15:06:10.972277\n",
      "resetting env. episode 8839, reward total was -16.0. running mean: -15.682263389486351, timestamp: 2022-08-19 15:06:19.343373\n",
      "resetting env. episode 8840, reward total was -13.0. running mean: -15.655440755591489, timestamp: 2022-08-19 15:06:29.518495\n",
      "resetting env. episode 8841, reward total was -19.0. running mean: -15.688886348035574, timestamp: 2022-08-19 15:06:36.102572\n",
      "resetting env. episode 8842, reward total was -19.0. running mean: -15.721997484555217, timestamp: 2022-08-19 15:06:43.575663\n",
      "resetting env. episode 8843, reward total was -15.0. running mean: -15.714777509709664, timestamp: 2022-08-19 15:06:52.532764\n",
      "resetting env. episode 8844, reward total was -18.0. running mean: -15.737629734612568, timestamp: 2022-08-19 15:06:59.886858\n",
      "resetting env. episode 8845, reward total was -7.0. running mean: -15.650253437266443, timestamp: 2022-08-19 15:07:10.585983\n",
      "resetting env. episode 8846, reward total was -17.0. running mean: -15.663750902893778, timestamp: 2022-08-19 15:07:18.038067\n",
      "resetting env. episode 8847, reward total was -13.0. running mean: -15.63711339386484, timestamp: 2022-08-19 15:07:26.167161\n",
      "resetting env. episode 8848, reward total was -17.0. running mean: -15.650742259926192, timestamp: 2022-08-19 15:07:34.600264\n",
      "resetting env. episode 8849, reward total was -14.0. running mean: -15.63423483732693, timestamp: 2022-08-19 15:07:44.559381\n",
      "resetting env. episode 8850, reward total was -9.0. running mean: -15.56789248895366, timestamp: 2022-08-19 15:07:54.718499\n",
      "resetting env. episode 8851, reward total was -10.0. running mean: -15.512213564064123, timestamp: 2022-08-19 15:08:05.775633\n",
      "resetting env. episode 8852, reward total was -19.0. running mean: -15.547091428423482, timestamp: 2022-08-19 15:08:13.056715\n",
      "resetting env. episode 8853, reward total was -14.0. running mean: -15.531620514139247, timestamp: 2022-08-19 15:08:21.808820\n",
      "resetting env. episode 8854, reward total was -8.0. running mean: -15.456304308997854, timestamp: 2022-08-19 15:08:33.909960\n",
      "resetting env. episode 8855, reward total was -15.0. running mean: -15.451741265907875, timestamp: 2022-08-19 15:08:41.422049\n",
      "resetting env. episode 8856, reward total was -13.0. running mean: -15.427223853248798, timestamp: 2022-08-19 15:08:49.488144\n",
      "resetting env. episode 8857, reward total was -17.0. running mean: -15.442951614716309, timestamp: 2022-08-19 15:08:56.228222\n",
      "resetting env. episode 8858, reward total was -19.0. running mean: -15.478522098569146, timestamp: 2022-08-19 15:09:04.054314\n",
      "resetting env. episode 8859, reward total was -17.0. running mean: -15.493736877583453, timestamp: 2022-08-19 15:09:12.982419\n",
      "resetting env. episode 8860, reward total was -16.0. running mean: -15.498799508807618, timestamp: 2022-08-19 15:09:21.839520\n",
      "resetting env. episode 8861, reward total was -14.0. running mean: -15.483811513719543, timestamp: 2022-08-19 15:09:30.412623\n",
      "resetting env. episode 8862, reward total was -16.0. running mean: -15.488973398582347, timestamp: 2022-08-19 15:09:38.226242\n",
      "resetting env. episode 8863, reward total was -18.0. running mean: -15.514083664596523, timestamp: 2022-08-19 15:09:45.228320\n",
      "resetting env. episode 8864, reward total was -14.0. running mean: -15.498942827950557, timestamp: 2022-08-19 15:09:56.118449\n",
      "resetting env. episode 8865, reward total was -19.0. running mean: -15.53395339967105, timestamp: 2022-08-19 15:10:04.921549\n",
      "resetting env. episode 8866, reward total was -19.0. running mean: -15.568613865674338, timestamp: 2022-08-19 15:10:11.617630\n",
      "resetting env. episode 8867, reward total was -19.0. running mean: -15.602927727017594, timestamp: 2022-08-19 15:10:19.627718\n",
      "resetting env. episode 8868, reward total was -15.0. running mean: -15.596898449747417, timestamp: 2022-08-19 15:10:29.013829\n",
      "resetting env. episode 8869, reward total was -14.0. running mean: -15.580929465249945, timestamp: 2022-08-19 15:10:35.847914\n",
      "resetting env. episode 8870, reward total was -15.0. running mean: -15.575120170597446, timestamp: 2022-08-19 15:10:44.818015\n",
      "resetting env. episode 8871, reward total was -18.0. running mean: -15.59936896889147, timestamp: 2022-08-19 15:10:51.578091\n",
      "resetting env. episode 8872, reward total was -12.0. running mean: -15.563375279202555, timestamp: 2022-08-19 15:11:00.194715\n",
      "resetting env. episode 8873, reward total was -13.0. running mean: -15.53774152641053, timestamp: 2022-08-19 15:11:08.573808\n",
      "resetting env. episode 8874, reward total was -8.0. running mean: -15.462364111146425, timestamp: 2022-08-19 15:11:20.034941\n",
      "resetting env. episode 8875, reward total was -15.0. running mean: -15.45774047003496, timestamp: 2022-08-19 15:11:27.543028\n",
      "resetting env. episode 8876, reward total was -9.0. running mean: -15.39316306533461, timestamp: 2022-08-19 15:11:38.799683\n",
      "resetting env. episode 8877, reward total was -13.0. running mean: -15.369231434681264, timestamp: 2022-08-19 15:11:47.338782\n",
      "resetting env. episode 8878, reward total was -19.0. running mean: -15.405539120334451, timestamp: 2022-08-19 15:11:54.137861\n",
      "resetting env. episode 8879, reward total was -19.0. running mean: -15.441483729131106, timestamp: 2022-08-19 15:12:00.934941\n",
      "resetting env. episode 8880, reward total was -11.0. running mean: -15.397068891839794, timestamp: 2022-08-19 15:12:10.158042\n",
      "resetting env. episode 8881, reward total was -12.0. running mean: -15.363098202921394, timestamp: 2022-08-19 15:12:18.812146\n",
      "resetting env. episode 8882, reward total was -17.0. running mean: -15.379467220892181, timestamp: 2022-08-19 15:12:25.854223\n",
      "resetting env. episode 8883, reward total was -17.0. running mean: -15.395672548683258, timestamp: 2022-08-19 15:12:32.815303\n",
      "resetting env. episode 8884, reward total was -13.0. running mean: -15.371715823196427, timestamp: 2022-08-19 15:12:41.714925\n",
      "resetting env. episode 8885, reward total was -12.0. running mean: -15.337998664964461, timestamp: 2022-08-19 15:12:49.206015\n",
      "resetting env. episode 8886, reward total was -20.0. running mean: -15.384618678314816, timestamp: 2022-08-19 15:12:56.239091\n",
      "resetting env. episode 8887, reward total was -15.0. running mean: -15.380772491531667, timestamp: 2022-08-19 15:13:05.092195\n",
      "resetting env. episode 8888, reward total was -19.0. running mean: -15.41696476661635, timestamp: 2022-08-19 15:13:13.272286\n",
      "resetting env. episode 8889, reward total was -15.0. running mean: -15.412795118950186, timestamp: 2022-08-19 15:13:21.801913\n",
      "resetting env. episode 8890, reward total was -16.0. running mean: -15.418667167760685, timestamp: 2022-08-19 15:13:29.721001\n",
      "resetting env. episode 8891, reward total was -16.0. running mean: -15.424480496083078, timestamp: 2022-08-19 15:13:38.853106\n",
      "resetting env. episode 8892, reward total was -14.0. running mean: -15.410235691122248, timestamp: 2022-08-19 15:13:47.459727\n",
      "resetting env. episode 8893, reward total was -13.0. running mean: -15.386133334211026, timestamp: 2022-08-19 15:13:55.889820\n",
      "resetting env. episode 8894, reward total was -12.0. running mean: -15.352272000868915, timestamp: 2022-08-19 15:14:04.683922\n",
      "resetting env. episode 8895, reward total was -13.0. running mean: -15.328749280860226, timestamp: 2022-08-19 15:14:12.941015\n",
      "resetting env. episode 8896, reward total was -13.0. running mean: -15.305461788051625, timestamp: 2022-08-19 15:14:21.962637\n",
      "resetting env. episode 8897, reward total was -18.0. running mean: -15.332407170171109, timestamp: 2022-08-19 15:14:30.628739\n",
      "resetting env. episode 8898, reward total was -13.0. running mean: -15.309083098469399, timestamp: 2022-08-19 15:14:39.004881\n",
      "resetting env. episode 8899, reward total was -14.0. running mean: -15.295992267484705, timestamp: 2022-08-19 15:14:48.831041\n",
      "resetting env. episode 8900, reward total was -17.0. running mean: -15.313032344809857, timestamp: 2022-08-19 15:14:55.609116\n",
      "resetting env. episode 8901, reward total was -12.0. running mean: -15.279902021361757, timestamp: 2022-08-19 15:15:05.262230\n",
      "resetting env. episode 8902, reward total was -9.0. running mean: -15.21710300114814, timestamp: 2022-08-19 15:15:15.983348\n",
      "resetting env. episode 8903, reward total was -14.0. running mean: -15.204931971136658, timestamp: 2022-08-19 15:15:25.292452\n",
      "resetting env. episode 8904, reward total was -18.0. running mean: -15.23288265142529, timestamp: 2022-08-19 15:15:33.468543\n",
      "resetting env. episode 8905, reward total was -14.0. running mean: -15.220553824911038, timestamp: 2022-08-19 15:15:44.111182\n",
      "resetting env. episode 8906, reward total was -19.0. running mean: -15.258348286661928, timestamp: 2022-08-19 15:15:52.222273\n",
      "resetting env. episode 8907, reward total was -20.0. running mean: -15.305764803795308, timestamp: 2022-08-19 15:15:58.559346\n",
      "resetting env. episode 8908, reward total was -15.0. running mean: -15.302707155757355, timestamp: 2022-08-19 15:16:08.831461\n",
      "resetting env. episode 8909, reward total was -9.0. running mean: -15.239680084199781, timestamp: 2022-08-19 15:16:19.392582\n",
      "resetting env. episode 8910, reward total was -19.0. running mean: -15.277283283357782, timestamp: 2022-08-19 15:16:28.309683\n",
      "resetting env. episode 8911, reward total was -19.0. running mean: -15.314510450524203, timestamp: 2022-08-19 15:16:35.655768\n",
      "resetting env. episode 8912, reward total was -11.0. running mean: -15.27136534601896, timestamp: 2022-08-19 15:16:44.299864\n",
      "resetting env. episode 8913, reward total was -11.0. running mean: -15.22865169255877, timestamp: 2022-08-19 15:16:53.708973\n",
      "resetting env. episode 8914, reward total was -17.0. running mean: -15.246365175633182, timestamp: 2022-08-19 15:17:01.132059\n",
      "resetting env. episode 8915, reward total was -16.0. running mean: -15.25390152387685, timestamp: 2022-08-19 15:17:10.018161\n",
      "resetting env. episode 8916, reward total was -17.0. running mean: -15.27136250863808, timestamp: 2022-08-19 15:17:16.795242\n",
      "resetting env. episode 8917, reward total was -11.0. running mean: -15.228648883551699, timestamp: 2022-08-19 15:17:26.448351\n",
      "resetting env. episode 8918, reward total was -19.0. running mean: -15.26636239471618, timestamp: 2022-08-19 15:17:32.588423\n",
      "resetting env. episode 8919, reward total was -16.0. running mean: -15.273698770769018, timestamp: 2022-08-19 15:17:41.525528\n",
      "resetting env. episode 8920, reward total was -13.0. running mean: -15.250961783061328, timestamp: 2022-08-19 15:17:50.700633\n",
      "resetting env. episode 8921, reward total was -17.0. running mean: -15.268452165230714, timestamp: 2022-08-19 15:18:00.264745\n",
      "resetting env. episode 8922, reward total was -15.0. running mean: -15.265767643578407, timestamp: 2022-08-19 15:18:08.720846\n",
      "resetting env. episode 8923, reward total was -16.0. running mean: -15.273109967142624, timestamp: 2022-08-19 15:18:17.714950\n",
      "resetting env. episode 8924, reward total was -14.0. running mean: -15.260378867471198, timestamp: 2022-08-19 15:18:26.139047\n",
      "resetting env. episode 8925, reward total was -17.0. running mean: -15.277775078796486, timestamp: 2022-08-19 15:18:33.788665\n",
      "resetting env. episode 8926, reward total was -15.0. running mean: -15.27499732800852, timestamp: 2022-08-19 15:18:43.097773\n",
      "resetting env. episode 8927, reward total was -10.0. running mean: -15.222247354728434, timestamp: 2022-08-19 15:18:54.466908\n",
      "resetting env. episode 8928, reward total was -12.0. running mean: -15.190024881181149, timestamp: 2022-08-19 15:19:05.955563\n",
      "resetting env. episode 8929, reward total was -12.0. running mean: -15.158124632369336, timestamp: 2022-08-19 15:19:15.566679\n",
      "resetting env. episode 8930, reward total was -15.0. running mean: -15.156543386045643, timestamp: 2022-08-19 15:19:23.505770\n",
      "resetting env. episode 8931, reward total was -17.0. running mean: -15.174977952185186, timestamp: 2022-08-19 15:19:30.536853\n",
      "resetting env. episode 8932, reward total was -15.0. running mean: -15.173228172663334, timestamp: 2022-08-19 15:19:39.359956\n",
      "resetting env. episode 8933, reward total was -17.0. running mean: -15.1914958909367, timestamp: 2022-08-19 15:19:48.131062\n",
      "resetting env. episode 8934, reward total was -17.0. running mean: -15.209580932027333, timestamp: 2022-08-19 15:19:57.090692\n",
      "resetting env. episode 8935, reward total was -14.0. running mean: -15.197485122707059, timestamp: 2022-08-19 15:20:07.460814\n",
      "resetting env. episode 8936, reward total was -10.0. running mean: -15.145510271479989, timestamp: 2022-08-19 15:20:18.170940\n",
      "resetting env. episode 8937, reward total was -15.0. running mean: -15.144055168765188, timestamp: 2022-08-19 15:20:27.016050\n",
      "resetting env. episode 8938, reward total was -14.0. running mean: -15.132614617077538, timestamp: 2022-08-19 15:20:33.888133\n",
      "resetting env. episode 8939, reward total was -13.0. running mean: -15.111288470906763, timestamp: 2022-08-19 15:20:43.354770\n",
      "resetting env. episode 8940, reward total was -15.0. running mean: -15.110175586197695, timestamp: 2022-08-19 15:20:51.052861\n",
      "resetting env. episode 8941, reward total was -18.0. running mean: -15.139073830335718, timestamp: 2022-08-19 15:20:59.130536\n",
      "resetting env. episode 8942, reward total was -17.0. running mean: -15.15768309203236, timestamp: 2022-08-19 15:21:06.490153\n",
      "resetting env. episode 8943, reward total was -18.0. running mean: -15.186106261112037, timestamp: 2022-08-19 15:21:13.259230\n",
      "resetting env. episode 8944, reward total was -15.0. running mean: -15.184245198500918, timestamp: 2022-08-19 15:21:22.512341\n",
      "resetting env. episode 8945, reward total was -13.0. running mean: -15.162402746515909, timestamp: 2022-08-19 15:21:33.452994\n",
      "resetting env. episode 8946, reward total was -15.0. running mean: -15.16077871905075, timestamp: 2022-08-19 15:21:41.285088\n",
      "resetting env. episode 8947, reward total was -16.0. running mean: -15.169170931860243, timestamp: 2022-08-19 15:21:49.127178\n",
      "resetting env. episode 8948, reward total was -17.0. running mean: -15.18747922254164, timestamp: 2022-08-19 15:21:56.334265\n",
      "resetting env. episode 8949, reward total was -16.0. running mean: -15.195604430316223, timestamp: 2022-08-19 15:22:06.538429\n",
      "resetting env. episode 8950, reward total was -17.0. running mean: -15.21364838601306, timestamp: 2022-08-19 15:22:14.730045\n",
      "resetting env. episode 8951, reward total was -11.0. running mean: -15.171511902152929, timestamp: 2022-08-19 15:22:24.440691\n",
      "resetting env. episode 8952, reward total was -13.0. running mean: -15.1497967831314, timestamp: 2022-08-19 15:22:33.802803\n",
      "resetting env. episode 8953, reward total was -11.0. running mean: -15.108298815300085, timestamp: 2022-08-19 15:22:45.878942\n",
      "resetting env. episode 8954, reward total was -13.0. running mean: -15.087215827147084, timestamp: 2022-08-19 15:22:54.540048\n",
      "resetting env. episode 8955, reward total was -14.0. running mean: -15.076343668875614, timestamp: 2022-08-19 15:23:02.890146\n",
      "resetting env. episode 8956, reward total was -13.0. running mean: -15.055580232186859, timestamp: 2022-08-19 15:23:10.424235\n",
      "resetting env. episode 8957, reward total was -17.0. running mean: -15.07502442986499, timestamp: 2022-08-19 15:23:19.105338\n",
      "resetting env. episode 8958, reward total was -16.0. running mean: -15.084274185566342, timestamp: 2022-08-19 15:23:26.868428\n",
      "resetting env. episode 8959, reward total was -10.0. running mean: -15.033431443710677, timestamp: 2022-08-19 15:23:35.821533\n",
      "resetting env. episode 8960, reward total was -19.0. running mean: -15.07309712927357, timestamp: 2022-08-19 15:23:44.001629\n",
      "resetting env. episode 8961, reward total was -17.0. running mean: -15.092366157980834, timestamp: 2022-08-19 15:23:53.402740\n",
      "resetting env. episode 8962, reward total was -19.0. running mean: -15.131442496401025, timestamp: 2022-08-19 15:24:00.894828\n",
      "resetting env. episode 8963, reward total was -21.0. running mean: -15.190128071437016, timestamp: 2022-08-19 15:24:07.851909\n",
      "resetting env. episode 8964, reward total was -14.0. running mean: -15.178226790722647, timestamp: 2022-08-19 15:24:16.518016\n",
      "resetting env. episode 8965, reward total was -15.0. running mean: -15.176444522815421, timestamp: 2022-08-19 15:24:23.821100\n",
      "resetting env. episode 8966, reward total was -14.0. running mean: -15.164680077587267, timestamp: 2022-08-19 15:24:32.918207\n",
      "resetting env. episode 8967, reward total was -12.0. running mean: -15.133033276811393, timestamp: 2022-08-19 15:24:43.917339\n",
      "resetting env. episode 8968, reward total was -18.0. running mean: -15.16170294404328, timestamp: 2022-08-19 15:24:53.900465\n",
      "resetting env. episode 8969, reward total was -13.0. running mean: -15.140085914602848, timestamp: 2022-08-19 15:25:04.089573\n",
      "resetting env. episode 8970, reward total was -11.0. running mean: -15.09868505545682, timestamp: 2022-08-19 15:25:13.396682\n",
      "resetting env. episode 8971, reward total was -21.0. running mean: -15.157698204902252, timestamp: 2022-08-19 15:25:20.092762\n",
      "resetting env. episode 8972, reward total was -16.0. running mean: -15.16612122285323, timestamp: 2022-08-19 15:25:27.727853\n",
      "resetting env. episode 8973, reward total was -17.0. running mean: -15.184460010624697, timestamp: 2022-08-19 15:25:36.586482\n",
      "resetting env. episode 8974, reward total was -17.0. running mean: -15.20261541051845, timestamp: 2022-08-19 15:25:43.555560\n",
      "resetting env. episode 8975, reward total was -17.0. running mean: -15.220589256413264, timestamp: 2022-08-19 15:25:52.054667\n",
      "resetting env. episode 8976, reward total was -18.0. running mean: -15.24838336384913, timestamp: 2022-08-19 15:25:59.600750\n",
      "resetting env. episode 8977, reward total was -12.0. running mean: -15.215899530210638, timestamp: 2022-08-19 15:26:08.819388\n",
      "resetting env. episode 8978, reward total was -15.0. running mean: -15.213740534908533, timestamp: 2022-08-19 15:26:19.661518\n",
      "resetting env. episode 8979, reward total was -10.0. running mean: -15.161603129559447, timestamp: 2022-08-19 15:26:31.395650\n",
      "resetting env. episode 8980, reward total was -13.0. running mean: -15.139987098263854, timestamp: 2022-08-19 15:26:42.354314\n",
      "resetting env. episode 8981, reward total was -15.0. running mean: -15.138587227281215, timestamp: 2022-08-19 15:26:50.181406\n",
      "resetting env. episode 8982, reward total was -16.0. running mean: -15.147201355008404, timestamp: 2022-08-19 15:26:57.874495\n",
      "resetting env. episode 8983, reward total was -14.0. running mean: -15.13572934145832, timestamp: 2022-08-19 15:27:08.775622\n",
      "resetting env. episode 8984, reward total was -14.0. running mean: -15.124372048043737, timestamp: 2022-08-19 15:27:17.432723\n",
      "resetting env. episode 8985, reward total was -12.0. running mean: -15.0931283275633, timestamp: 2022-08-19 15:27:26.322827\n",
      "resetting env. episode 8986, reward total was -13.0. running mean: -15.072197044287666, timestamp: 2022-08-19 15:27:34.431921\n",
      "resetting env. episode 8987, reward total was -17.0. running mean: -15.091475073844789, timestamp: 2022-08-19 15:27:43.069017\n",
      "resetting env. episode 8988, reward total was -12.0. running mean: -15.06056032310634, timestamp: 2022-08-19 15:27:52.506131\n",
      "resetting env. episode 8989, reward total was -13.0. running mean: -15.039954719875277, timestamp: 2022-08-19 15:28:01.597753\n",
      "resetting env. episode 8990, reward total was -20.0. running mean: -15.089555172676524, timestamp: 2022-08-19 15:28:08.523835\n",
      "resetting env. episode 8991, reward total was -16.0. running mean: -15.098659620949759, timestamp: 2022-08-19 15:28:16.762978\n",
      "resetting env. episode 8992, reward total was -8.0. running mean: -15.027673024740261, timestamp: 2022-08-19 15:28:28.948117\n",
      "resetting env. episode 8993, reward total was -18.0. running mean: -15.05739629449286, timestamp: 2022-08-19 15:28:39.753244\n",
      "resetting env. episode 8994, reward total was -17.0. running mean: -15.07682233154793, timestamp: 2022-08-19 15:28:49.059348\n",
      "resetting env. episode 8995, reward total was -15.0. running mean: -15.076054108232452, timestamp: 2022-08-19 15:28:56.818438\n",
      "resetting env. episode 8996, reward total was -17.0. running mean: -15.095293567150128, timestamp: 2022-08-19 15:29:02.793031\n",
      "resetting env. episode 8997, reward total was -11.0. running mean: -15.054340631478626, timestamp: 2022-08-19 15:29:11.096129\n",
      "resetting env. episode 8998, reward total was -13.0. running mean: -15.03379722516384, timestamp: 2022-08-19 15:29:19.042739\n",
      "resetting env. episode 8999, reward total was -5.0. running mean: -14.933459252912202, timestamp: 2022-08-19 15:29:31.322881\n",
      "resetting env. episode 9000, reward total was -15.0. running mean: -14.93412466038308, timestamp: 2022-08-19 15:29:40.402983\n",
      "resetting env. episode 9001, reward total was -20.0. running mean: -14.98478341377925, timestamp: 2022-08-19 15:29:46.933057\n",
      "resetting env. episode 9002, reward total was -13.0. running mean: -14.964935579641457, timestamp: 2022-08-19 15:29:56.463168\n",
      "resetting env. episode 9003, reward total was -14.0. running mean: -14.955286223845043, timestamp: 2022-08-19 15:30:03.938252\n",
      "resetting env. episode 9004, reward total was -13.0. running mean: -14.935733361606593, timestamp: 2022-08-19 15:30:14.616372\n",
      "resetting env. episode 9005, reward total was -17.0. running mean: -14.956376027990526, timestamp: 2022-08-19 15:30:21.474451\n",
      "resetting env. episode 9006, reward total was -15.0. running mean: -14.956812267710621, timestamp: 2022-08-19 15:30:31.147564\n",
      "resetting env. episode 9007, reward total was -16.0. running mean: -14.967244145033515, timestamp: 2022-08-19 15:30:38.980652\n",
      "resetting env. episode 9008, reward total was -15.0. running mean: -14.96757170358318, timestamp: 2022-08-19 15:30:46.953264\n",
      "resetting env. episode 9009, reward total was -17.0. running mean: -14.987895986547349, timestamp: 2022-08-19 15:30:56.305369\n",
      "resetting env. episode 9010, reward total was -13.0. running mean: -14.968017026681876, timestamp: 2022-08-19 15:31:06.788486\n",
      "resetting env. episode 9011, reward total was -14.0. running mean: -14.958336856415057, timestamp: 2022-08-19 15:31:14.066099\n",
      "resetting env. episode 9012, reward total was -16.0. running mean: -14.968753487850906, timestamp: 2022-08-19 15:31:23.043198\n",
      "resetting env. episode 9013, reward total was -14.0. running mean: -14.959065952972397, timestamp: 2022-08-19 15:31:30.913287\n",
      "resetting env. episode 9014, reward total was -14.0. running mean: -14.949475293442672, timestamp: 2022-08-19 15:31:38.757378\n",
      "resetting env. episode 9015, reward total was -12.0. running mean: -14.919980540508245, timestamp: 2022-08-19 15:31:47.649476\n",
      "resetting env. episode 9016, reward total was -17.0. running mean: -14.940780735103163, timestamp: 2022-08-19 15:31:56.383576\n",
      "resetting env. episode 9017, reward total was -17.0. running mean: -14.96137292775213, timestamp: 2022-08-19 15:32:03.445657\n",
      "resetting env. episode 9018, reward total was -19.0. running mean: -15.001759198474609, timestamp: 2022-08-19 15:32:13.445769\n",
      "resetting env. episode 9019, reward total was -19.0. running mean: -15.041741606489863, timestamp: 2022-08-19 15:32:20.101367\n",
      "resetting env. episode 9020, reward total was -18.0. running mean: -15.071324190424964, timestamp: 2022-08-19 15:32:28.107454\n",
      "resetting env. episode 9021, reward total was -12.0. running mean: -15.040610948520714, timestamp: 2022-08-19 15:32:38.261091\n",
      "resetting env. episode 9022, reward total was -17.0. running mean: -15.060204839035507, timestamp: 2022-08-19 15:32:47.046712\n",
      "resetting env. episode 9023, reward total was -18.0. running mean: -15.08960279064515, timestamp: 2022-08-19 15:32:52.248769\n",
      "resetting env. episode 9024, reward total was -15.0. running mean: -15.088706762738699, timestamp: 2022-08-19 15:33:00.304378\n",
      "resetting env. episode 9025, reward total was -12.0. running mean: -15.057819695111311, timestamp: 2022-08-19 15:33:11.351505\n",
      "resetting env. episode 9026, reward total was -17.0. running mean: -15.077241498160198, timestamp: 2022-08-19 15:33:20.616611\n",
      "resetting env. episode 9027, reward total was -16.0. running mean: -15.086469083178596, timestamp: 2022-08-19 15:33:29.658711\n",
      "resetting env. episode 9028, reward total was -18.0. running mean: -15.115604392346809, timestamp: 2022-08-19 15:33:37.513326\n",
      "resetting env. episode 9029, reward total was -14.0. running mean: -15.104448348423341, timestamp: 2022-08-19 15:33:46.029474\n",
      "resetting env. episode 9030, reward total was -15.0. running mean: -15.103403864939109, timestamp: 2022-08-19 15:33:54.874577\n",
      "resetting env. episode 9031, reward total was -9.0. running mean: -15.042369826289718, timestamp: 2022-08-19 15:34:05.327695\n",
      "resetting env. episode 9032, reward total was -17.0. running mean: -15.06194612802682, timestamp: 2022-08-19 15:34:12.720781\n",
      "resetting env. episode 9033, reward total was -14.0. running mean: -15.051326666746553, timestamp: 2022-08-19 15:34:21.918886\n",
      "resetting env. episode 9034, reward total was -17.0. running mean: -15.070813400079087, timestamp: 2022-08-19 15:34:28.797969\n",
      "resetting env. episode 9035, reward total was -17.0. running mean: -15.090105266078297, timestamp: 2022-08-19 15:34:38.323076\n",
      "resetting env. episode 9036, reward total was -8.0. running mean: -15.019204213417513, timestamp: 2022-08-19 15:34:50.156215\n",
      "resetting env. episode 9037, reward total was -19.0. running mean: -15.059012171283337, timestamp: 2022-08-19 15:35:00.475336\n",
      "resetting env. episode 9038, reward total was -19.0. running mean: -15.098422049570503, timestamp: 2022-08-19 15:35:12.467047\n",
      "resetting env. episode 9039, reward total was -19.0. running mean: -15.137437829074798, timestamp: 2022-08-19 15:35:20.716146\n",
      "resetting env. episode 9040, reward total was -17.0. running mean: -15.15606345078405, timestamp: 2022-08-19 15:35:28.535233\n",
      "resetting env. episode 9041, reward total was -15.0. running mean: -15.15450281627621, timestamp: 2022-08-19 15:35:36.741330\n",
      "resetting env. episode 9042, reward total was -11.0. running mean: -15.112957788113448, timestamp: 2022-08-19 15:35:46.489974\n",
      "resetting env. episode 9043, reward total was -17.0. running mean: -15.131828210232314, timestamp: 2022-08-19 15:35:55.066074\n",
      "resetting env. episode 9044, reward total was -17.0. running mean: -15.15050992812999, timestamp: 2022-08-19 15:36:03.379171\n",
      "resetting env. episode 9045, reward total was -15.0. running mean: -15.14900482884869, timestamp: 2022-08-19 15:36:11.494268\n",
      "resetting env. episode 9046, reward total was -9.0. running mean: -15.087514780560204, timestamp: 2022-08-19 15:36:24.760423\n",
      "resetting env. episode 9047, reward total was -16.0. running mean: -15.096639632754602, timestamp: 2022-08-19 15:36:31.237498\n",
      "resetting env. episode 9048, reward total was -15.0. running mean: -15.095673236427057, timestamp: 2022-08-19 15:36:41.722623\n",
      "resetting env. episode 9049, reward total was -15.0. running mean: -15.094716504062786, timestamp: 2022-08-19 15:36:50.188723\n",
      "resetting env. episode 9050, reward total was -12.0. running mean: -15.063769339022157, timestamp: 2022-08-19 15:36:58.296819\n",
      "resetting env. episode 9051, reward total was -13.0. running mean: -15.043131645631936, timestamp: 2022-08-19 15:37:07.583457\n",
      "resetting env. episode 9052, reward total was -19.0. running mean: -15.082700329175616, timestamp: 2022-08-19 15:37:15.474551\n",
      "resetting env. episode 9053, reward total was -19.0. running mean: -15.12187332588386, timestamp: 2022-08-19 15:37:23.408165\n",
      "resetting env. episode 9054, reward total was -19.0. running mean: -15.16065459262502, timestamp: 2022-08-19 15:37:31.609264\n",
      "resetting env. episode 9055, reward total was -19.0. running mean: -15.199048046698769, timestamp: 2022-08-19 15:37:38.678872\n",
      "resetting env. episode 9056, reward total was -14.0. running mean: -15.18705756623178, timestamp: 2022-08-19 15:37:47.796982\n",
      "resetting env. episode 9057, reward total was -14.0. running mean: -15.175186990569463, timestamp: 2022-08-19 15:37:58.499106\n",
      "resetting env. episode 9058, reward total was -7.0. running mean: -15.093435120663768, timestamp: 2022-08-19 15:38:09.851245\n",
      "resetting env. episode 9059, reward total was -19.0. running mean: -15.13250076945713, timestamp: 2022-08-19 15:38:16.738324\n",
      "resetting env. episode 9060, reward total was -11.0. running mean: -15.091175761762557, timestamp: 2022-08-19 15:38:26.236437\n",
      "resetting env. episode 9061, reward total was -15.0. running mean: -15.090264004144931, timestamp: 2022-08-19 15:38:34.745540\n",
      "resetting env. episode 9062, reward total was -7.0. running mean: -15.009361364103482, timestamp: 2022-08-19 15:38:45.073662\n",
      "resetting env. episode 9063, reward total was -13.0. running mean: -14.989267750462448, timestamp: 2022-08-19 15:38:54.553300\n",
      "resetting env. episode 9064, reward total was -19.0. running mean: -15.029375072957823, timestamp: 2022-08-19 15:39:01.313905\n",
      "resetting env. episode 9065, reward total was -19.0. running mean: -15.069081322228245, timestamp: 2022-08-19 15:39:08.782991\n",
      "resetting env. episode 9066, reward total was -13.0. running mean: -15.048390509005962, timestamp: 2022-08-19 15:39:17.148090\n",
      "resetting env. episode 9067, reward total was -9.0. running mean: -14.987906603915903, timestamp: 2022-08-19 15:39:28.290223\n",
      "resetting env. episode 9068, reward total was -7.0. running mean: -14.908027537876745, timestamp: 2022-08-19 15:39:41.520381\n",
      "resetting env. episode 9069, reward total was -11.0. running mean: -14.868947262497976, timestamp: 2022-08-19 15:39:50.342487\n",
      "resetting env. episode 9070, reward total was -17.0. running mean: -14.890257789872996, timestamp: 2022-08-19 15:39:58.660583\n",
      "resetting env. episode 9071, reward total was -17.0. running mean: -14.911355211974266, timestamp: 2022-08-19 15:40:07.621212\n",
      "resetting env. episode 9072, reward total was -16.0. running mean: -14.922241659854523, timestamp: 2022-08-19 15:40:15.895314\n",
      "resetting env. episode 9073, reward total was -15.0. running mean: -14.923019243255977, timestamp: 2022-08-19 15:40:24.308411\n",
      "resetting env. episode 9074, reward total was -17.0. running mean: -14.943789050823417, timestamp: 2022-08-19 15:40:31.253490\n",
      "resetting env. episode 9075, reward total was -8.0. running mean: -14.874351160315182, timestamp: 2022-08-19 15:40:40.754605\n",
      "resetting env. episode 9076, reward total was -8.0. running mean: -14.80560764871203, timestamp: 2022-08-19 15:40:49.606708\n",
      "resetting env. episode 9077, reward total was -16.0. running mean: -14.81755157222491, timestamp: 2022-08-19 15:40:57.657803\n",
      "resetting env. episode 9078, reward total was -18.0. running mean: -14.84937605650266, timestamp: 2022-08-19 15:41:05.598896\n",
      "resetting env. episode 9079, reward total was -20.0. running mean: -14.900882295937633, timestamp: 2022-08-19 15:41:11.886973\n",
      "resetting env. episode 9080, reward total was -15.0. running mean: -14.901873472978256, timestamp: 2022-08-19 15:41:19.834064\n",
      "resetting env. episode 9081, reward total was -13.0. running mean: -14.882854738248474, timestamp: 2022-08-19 15:41:29.580707\n",
      "resetting env. episode 9082, reward total was -18.0. running mean: -14.91402619086599, timestamp: 2022-08-19 15:41:36.456841\n",
      "resetting env. episode 9083, reward total was -14.0. running mean: -14.90488592895733, timestamp: 2022-08-19 15:41:46.912962\n",
      "resetting env. episode 9084, reward total was -11.0. running mean: -14.865837069667757, timestamp: 2022-08-19 15:41:57.231661\n",
      "resetting env. episode 9085, reward total was -12.0. running mean: -14.837178698971078, timestamp: 2022-08-19 15:42:07.694785\n",
      "resetting env. episode 9086, reward total was -10.0. running mean: -14.788806911981366, timestamp: 2022-08-19 15:42:20.111933\n",
      "resetting env. episode 9087, reward total was -16.0. running mean: -14.800918842861552, timestamp: 2022-08-19 15:42:28.537029\n",
      "resetting env. episode 9088, reward total was -15.0. running mean: -14.802909654432938, timestamp: 2022-08-19 15:42:37.303134\n",
      "resetting env. episode 9089, reward total was -15.0. running mean: -14.804880557888609, timestamp: 2022-08-19 15:42:44.574740\n",
      "resetting env. episode 9090, reward total was -8.0. running mean: -14.736831752309723, timestamp: 2022-08-19 15:42:56.141874\n",
      "resetting env. episode 9091, reward total was -15.0. running mean: -14.739463434786625, timestamp: 2022-08-19 15:43:02.686948\n",
      "resetting env. episode 9092, reward total was -12.0. running mean: -14.712068800438757, timestamp: 2022-08-19 15:43:12.733067\n",
      "resetting env. episode 9093, reward total was -10.0. running mean: -14.66494811243437, timestamp: 2022-08-19 15:43:24.306202\n",
      "resetting env. episode 9094, reward total was -14.0. running mean: -14.658298631310027, timestamp: 2022-08-19 15:43:30.691278\n",
      "resetting env. episode 9095, reward total was -16.0. running mean: -14.671715644996926, timestamp: 2022-08-19 15:43:40.034385\n",
      "resetting env. episode 9096, reward total was -17.0. running mean: -14.694998488546956, timestamp: 2022-08-19 15:43:48.175481\n",
      "resetting env. episode 9097, reward total was -21.0. running mean: -14.758048503661486, timestamp: 2022-08-19 15:43:55.421567\n",
      "resetting env. episode 9098, reward total was -18.0. running mean: -14.790468018624871, timestamp: 2022-08-19 15:44:05.913690\n",
      "resetting env. episode 9099, reward total was -17.0. running mean: -14.812563338438622, timestamp: 2022-08-19 15:44:11.741757\n",
      "resetting env. episode 9100, reward total was -16.0. running mean: -14.824437705054235, timestamp: 2022-08-19 15:44:19.195844\n",
      "resetting env. episode 9101, reward total was -15.0. running mean: -14.826193328003693, timestamp: 2022-08-19 15:44:28.765954\n",
      "resetting env. episode 9102, reward total was -14.0. running mean: -14.817931394723656, timestamp: 2022-08-19 15:44:39.511084\n",
      "resetting env. episode 9103, reward total was -11.0. running mean: -14.779752080776419, timestamp: 2022-08-19 15:44:50.319209\n",
      "resetting env. episode 9104, reward total was -15.0. running mean: -14.781954559968655, timestamp: 2022-08-19 15:45:00.213323\n",
      "resetting env. episode 9105, reward total was -12.0. running mean: -14.754135014368968, timestamp: 2022-08-19 15:45:10.607443\n",
      "resetting env. episode 9106, reward total was -16.0. running mean: -14.766593664225278, timestamp: 2022-08-19 15:45:17.324518\n",
      "resetting env. episode 9107, reward total was -16.0. running mean: -14.778927727583024, timestamp: 2022-08-19 15:45:25.604615\n",
      "resetting env. episode 9108, reward total was -14.0. running mean: -14.771138450307195, timestamp: 2022-08-19 15:45:33.426707\n",
      "resetting env. episode 9109, reward total was -17.0. running mean: -14.793427065804122, timestamp: 2022-08-19 15:45:42.605815\n",
      "resetting env. episode 9110, reward total was -17.0. running mean: -14.815492795146081, timestamp: 2022-08-19 15:45:49.470891\n",
      "resetting env. episode 9111, reward total was -18.0. running mean: -14.84733786719462, timestamp: 2022-08-19 15:45:58.221992\n",
      "resetting env. episode 9112, reward total was -18.0. running mean: -14.878864488522673, timestamp: 2022-08-19 15:46:05.232074\n",
      "resetting env. episode 9113, reward total was -16.0. running mean: -14.890075843637446, timestamp: 2022-08-19 15:46:13.982173\n",
      "resetting env. episode 9114, reward total was -11.0. running mean: -14.85117508520107, timestamp: 2022-08-19 15:46:22.192271\n",
      "resetting env. episode 9115, reward total was -17.0. running mean: -14.87266333434906, timestamp: 2022-08-19 15:46:30.462365\n",
      "resetting env. episode 9116, reward total was -16.0. running mean: -14.883936701005569, timestamp: 2022-08-19 15:46:39.366466\n",
      "resetting env. episode 9117, reward total was -9.0. running mean: -14.825097333995513, timestamp: 2022-08-19 15:46:50.694596\n",
      "resetting env. episode 9118, reward total was -16.0. running mean: -14.836846360655558, timestamp: 2022-08-19 15:46:58.501688\n",
      "resetting env. episode 9119, reward total was -19.0. running mean: -14.878477897049002, timestamp: 2022-08-19 15:47:05.760772\n",
      "resetting env. episode 9120, reward total was -10.0. running mean: -14.829693118078511, timestamp: 2022-08-19 15:47:15.289877\n",
      "resetting env. episode 9121, reward total was -17.0. running mean: -14.851396186897725, timestamp: 2022-08-19 15:47:23.332972\n",
      "resetting env. episode 9122, reward total was -17.0. running mean: -14.872882225028748, timestamp: 2022-08-19 15:47:31.074058\n",
      "resetting env. episode 9123, reward total was -17.0. running mean: -14.89415340277846, timestamp: 2022-08-19 15:47:38.587143\n",
      "resetting env. episode 9124, reward total was -10.0. running mean: -14.845211868750676, timestamp: 2022-08-19 15:47:48.220254\n",
      "resetting env. episode 9125, reward total was -14.0. running mean: -14.83675975006317, timestamp: 2022-08-19 15:47:57.953366\n",
      "resetting env. episode 9126, reward total was -17.0. running mean: -14.858392152562537, timestamp: 2022-08-19 15:48:06.830467\n",
      "resetting env. episode 9127, reward total was -15.0. running mean: -14.859808231036912, timestamp: 2022-08-19 15:48:16.839581\n",
      "resetting env. episode 9128, reward total was -11.0. running mean: -14.821210148726541, timestamp: 2022-08-19 15:48:25.027674\n",
      "resetting env. episode 9129, reward total was -13.0. running mean: -14.802998047239276, timestamp: 2022-08-19 15:48:34.357776\n",
      "resetting env. episode 9130, reward total was -16.0. running mean: -14.814968066766884, timestamp: 2022-08-19 15:48:43.254880\n",
      "resetting env. episode 9131, reward total was -11.0. running mean: -14.776818386099215, timestamp: 2022-08-19 15:48:51.854975\n",
      "resetting env. episode 9132, reward total was -11.0. running mean: -14.739050202238223, timestamp: 2022-08-19 15:49:01.957091\n",
      "resetting env. episode 9133, reward total was -14.0. running mean: -14.731659700215841, timestamp: 2022-08-19 15:49:08.801169\n",
      "resetting env. episode 9134, reward total was -13.0. running mean: -14.714343103213684, timestamp: 2022-08-19 15:49:16.312255\n",
      "resetting env. episode 9135, reward total was -6.0. running mean: -14.627199672181547, timestamp: 2022-08-19 15:49:29.395399\n",
      "resetting env. episode 9136, reward total was -15.0. running mean: -14.630927675459732, timestamp: 2022-08-19 15:49:37.568491\n",
      "resetting env. episode 9137, reward total was -13.0. running mean: -14.614618398705137, timestamp: 2022-08-19 15:49:45.928587\n",
      "resetting env. episode 9138, reward total was -19.0. running mean: -14.658472214718085, timestamp: 2022-08-19 15:49:53.654672\n",
      "resetting env. episode 9139, reward total was -15.0. running mean: -14.661887492570905, timestamp: 2022-08-19 15:50:01.893763\n",
      "resetting env. episode 9140, reward total was -19.0. running mean: -14.705268617645196, timestamp: 2022-08-19 15:50:10.106860\n",
      "resetting env. episode 9141, reward total was -10.0. running mean: -14.658215931468742, timestamp: 2022-08-19 15:50:20.953983\n",
      "resetting env. episode 9142, reward total was -17.0. running mean: -14.681633772154054, timestamp: 2022-08-19 15:50:29.168073\n",
      "resetting env. episode 9143, reward total was -18.0. running mean: -14.714817434432513, timestamp: 2022-08-19 15:50:37.478172\n",
      "resetting env. episode 9144, reward total was -17.0. running mean: -14.737669260088188, timestamp: 2022-08-19 15:50:45.462261\n",
      "resetting env. episode 9145, reward total was -13.0. running mean: -14.720292567487306, timestamp: 2022-08-19 15:50:55.022369\n",
      "resetting env. episode 9146, reward total was -17.0. running mean: -14.743089641812432, timestamp: 2022-08-19 15:51:01.438444\n",
      "resetting env. episode 9147, reward total was -15.0. running mean: -14.745658745394309, timestamp: 2022-08-19 15:51:09.635537\n",
      "resetting env. episode 9148, reward total was -9.0. running mean: -14.688202157940365, timestamp: 2022-08-19 15:51:20.424661\n",
      "resetting env. episode 9149, reward total was -17.0. running mean: -14.71132013636096, timestamp: 2022-08-19 15:51:28.672761\n",
      "resetting env. episode 9150, reward total was -15.0. running mean: -14.714206934997351, timestamp: 2022-08-19 15:51:35.888844\n",
      "resetting env. episode 9151, reward total was -15.0. running mean: -14.717064865647378, timestamp: 2022-08-19 15:51:45.373952\n",
      "resetting env. episode 9152, reward total was -13.0. running mean: -14.699894216990906, timestamp: 2022-08-19 15:51:53.453048\n",
      "resetting env. episode 9153, reward total was -13.0. running mean: -14.682895274820996, timestamp: 2022-08-19 15:52:04.457177\n",
      "resetting env. episode 9154, reward total was -17.0. running mean: -14.706066322072786, timestamp: 2022-08-19 15:52:12.615270\n",
      "resetting env. episode 9155, reward total was -14.0. running mean: -14.699005658852059, timestamp: 2022-08-19 15:52:21.209370\n",
      "resetting env. episode 9156, reward total was -20.0. running mean: -14.752015602263537, timestamp: 2022-08-19 15:52:28.659460\n",
      "resetting env. episode 9157, reward total was -13.0. running mean: -14.734495446240903, timestamp: 2022-08-19 15:52:38.022566\n",
      "resetting env. episode 9158, reward total was -10.0. running mean: -14.687150491778493, timestamp: 2022-08-19 15:52:47.531682\n",
      "resetting env. episode 9159, reward total was -21.0. running mean: -14.750278986860708, timestamp: 2022-08-19 15:52:53.947754\n",
      "resetting env. episode 9160, reward total was -17.0. running mean: -14.772776196992101, timestamp: 2022-08-19 15:53:01.445846\n",
      "resetting env. episode 9161, reward total was -15.0. running mean: -14.77504843502218, timestamp: 2022-08-19 15:53:09.640943\n",
      "resetting env. episode 9162, reward total was -16.0. running mean: -14.787297950671958, timestamp: 2022-08-19 15:53:20.574069\n",
      "resetting env. episode 9163, reward total was -16.0. running mean: -14.799424971165239, timestamp: 2022-08-19 15:53:30.493759\n",
      "resetting env. episode 9164, reward total was -19.0. running mean: -14.841430721453586, timestamp: 2022-08-19 15:53:37.219836\n",
      "resetting env. episode 9165, reward total was -11.0. running mean: -14.80301641423905, timestamp: 2022-08-19 15:53:46.155943\n",
      "resetting env. episode 9166, reward total was -19.0. running mean: -14.844986250096659, timestamp: 2022-08-19 15:53:52.679020\n",
      "resetting env. episode 9167, reward total was -13.0. running mean: -14.826536387595693, timestamp: 2022-08-19 15:54:02.462137\n",
      "resetting env. episode 9168, reward total was -19.0. running mean: -14.868271023719736, timestamp: 2022-08-19 15:54:08.879216\n",
      "resetting env. episode 9169, reward total was -9.0. running mean: -14.809588313482537, timestamp: 2022-08-19 15:54:17.926319\n",
      "resetting env. episode 9170, reward total was -9.0. running mean: -14.751492430347712, timestamp: 2022-08-19 15:54:26.319418\n",
      "resetting env. episode 9171, reward total was -11.0. running mean: -14.713977506044234, timestamp: 2022-08-19 15:54:36.050532\n",
      "resetting env. episode 9172, reward total was -17.0. running mean: -14.736837730983792, timestamp: 2022-08-19 15:54:44.943640\n",
      "resetting env. episode 9173, reward total was -13.0. running mean: -14.719469353673954, timestamp: 2022-08-19 15:54:53.074737\n",
      "resetting env. episode 9174, reward total was -18.0. running mean: -14.752274660137214, timestamp: 2022-08-19 15:55:01.202832\n",
      "resetting env. episode 9175, reward total was -11.0. running mean: -14.71475191353584, timestamp: 2022-08-19 15:55:11.753957\n",
      "resetting env. episode 9176, reward total was -15.0. running mean: -14.717604394400482, timestamp: 2022-08-19 15:55:20.130058\n",
      "resetting env. episode 9177, reward total was -13.0. running mean: -14.700428350456477, timestamp: 2022-08-19 15:55:28.085157\n",
      "resetting env. episode 9178, reward total was -19.0. running mean: -14.743424066951912, timestamp: 2022-08-19 15:55:35.062238\n",
      "resetting env. episode 9179, reward total was -17.0. running mean: -14.765989826282393, timestamp: 2022-08-19 15:55:43.347335\n",
      "resetting env. episode 9180, reward total was -15.0. running mean: -14.76832992801957, timestamp: 2022-08-19 15:55:52.235438\n",
      "resetting env. episode 9181, reward total was -18.0. running mean: -14.800646628739374, timestamp: 2022-08-19 15:56:00.505068\n",
      "resetting env. episode 9182, reward total was -15.0. running mean: -14.802640162451981, timestamp: 2022-08-19 15:56:08.471687\n",
      "resetting env. episode 9183, reward total was -16.0. running mean: -14.814613760827461, timestamp: 2022-08-19 15:56:15.704774\n",
      "resetting env. episode 9184, reward total was -16.0. running mean: -14.826467623219186, timestamp: 2022-08-19 15:56:23.049858\n",
      "resetting env. episode 9185, reward total was -13.0. running mean: -14.808202946986995, timestamp: 2022-08-19 15:56:32.340973\n",
      "resetting env. episode 9186, reward total was -15.0. running mean: -14.810120917517125, timestamp: 2022-08-19 15:56:41.607080\n",
      "resetting env. episode 9187, reward total was -17.0. running mean: -14.832019708341953, timestamp: 2022-08-19 15:56:49.928182\n",
      "resetting env. episode 9188, reward total was -11.0. running mean: -14.793699511258533, timestamp: 2022-08-19 15:57:00.118301\n",
      "resetting env. episode 9189, reward total was -15.0. running mean: -14.795762516145947, timestamp: 2022-08-19 15:57:08.172396\n",
      "resetting env. episode 9190, reward total was -15.0. running mean: -14.797804890984487, timestamp: 2022-08-19 15:57:17.488508\n",
      "resetting env. episode 9191, reward total was -13.0. running mean: -14.779826842074643, timestamp: 2022-08-19 15:57:25.612605\n",
      "resetting env. episode 9192, reward total was -18.0. running mean: -14.812028573653896, timestamp: 2022-08-19 15:57:32.881689\n",
      "resetting env. episode 9193, reward total was -19.0. running mean: -14.853908287917356, timestamp: 2022-08-19 15:57:40.819784\n",
      "resetting env. episode 9194, reward total was -12.0. running mean: -14.825369205038182, timestamp: 2022-08-19 15:57:48.636878\n",
      "resetting env. episode 9195, reward total was -11.0. running mean: -14.7871155129878, timestamp: 2022-08-19 15:57:57.771988\n",
      "resetting env. episode 9196, reward total was -16.0. running mean: -14.799244357857923, timestamp: 2022-08-19 15:58:04.766065\n",
      "resetting env. episode 9197, reward total was -13.0. running mean: -14.781251914279345, timestamp: 2022-08-19 15:58:12.969166\n",
      "resetting env. episode 9198, reward total was -19.0. running mean: -14.823439395136552, timestamp: 2022-08-19 15:58:19.039234\n",
      "resetting env. episode 9199, reward total was -12.0. running mean: -14.795205001185185, timestamp: 2022-08-19 15:58:27.820341\n",
      "resetting env. episode 9200, reward total was -20.0. running mean: -14.847252951173331, timestamp: 2022-08-19 15:58:36.289438\n",
      "resetting env. episode 9201, reward total was -19.0. running mean: -14.888780421661597, timestamp: 2022-08-19 15:58:43.577527\n",
      "resetting env. episode 9202, reward total was -11.0. running mean: -14.849892617444981, timestamp: 2022-08-19 15:58:51.748623\n",
      "resetting env. episode 9203, reward total was -14.0. running mean: -14.841393691270532, timestamp: 2022-08-19 15:59:01.075730\n",
      "resetting env. episode 9204, reward total was -13.0. running mean: -14.822979754357828, timestamp: 2022-08-19 15:59:09.530833\n",
      "resetting env. episode 9205, reward total was -12.0. running mean: -14.794749956814249, timestamp: 2022-08-19 15:59:18.521936\n",
      "resetting env. episode 9206, reward total was -11.0. running mean: -14.756802457246106, timestamp: 2022-08-19 15:59:27.445043\n",
      "resetting env. episode 9207, reward total was -15.0. running mean: -14.759234432673646, timestamp: 2022-08-19 15:59:33.670116\n",
      "resetting env. episode 9208, reward total was -18.0. running mean: -14.791642088346908, timestamp: 2022-08-19 15:59:40.437194\n",
      "resetting env. episode 9209, reward total was -13.0. running mean: -14.77372566746344, timestamp: 2022-08-19 15:59:48.557297\n",
      "resetting env. episode 9210, reward total was -15.0. running mean: -14.775988410788806, timestamp: 2022-08-19 15:59:55.766376\n",
      "resetting env. episode 9211, reward total was -14.0. running mean: -14.768228526680918, timestamp: 2022-08-19 16:00:06.075497\n",
      "resetting env. episode 9212, reward total was -12.0. running mean: -14.740546241414108, timestamp: 2022-08-19 16:00:14.317596\n",
      "resetting env. episode 9213, reward total was -17.0. running mean: -14.763140778999967, timestamp: 2022-08-19 16:00:22.044685\n",
      "resetting env. episode 9214, reward total was -12.0. running mean: -14.735509371209966, timestamp: 2022-08-19 16:00:30.906787\n",
      "resetting env. episode 9215, reward total was -13.0. running mean: -14.718154277497867, timestamp: 2022-08-19 16:00:39.841893\n",
      "resetting env. episode 9216, reward total was -11.0. running mean: -14.680972734722888, timestamp: 2022-08-19 16:00:48.477993\n",
      "resetting env. episode 9217, reward total was -15.0. running mean: -14.684163007375659, timestamp: 2022-08-19 16:00:58.127106\n",
      "resetting env. episode 9218, reward total was -13.0. running mean: -14.667321377301903, timestamp: 2022-08-19 16:01:05.739762\n",
      "resetting env. episode 9219, reward total was -16.0. running mean: -14.680648163528884, timestamp: 2022-08-19 16:01:13.888856\n",
      "resetting env. episode 9220, reward total was -19.0. running mean: -14.723841681893594, timestamp: 2022-08-19 16:01:22.062953\n",
      "resetting env. episode 9221, reward total was -13.0. running mean: -14.706603265074659, timestamp: 2022-08-19 16:01:30.172047\n",
      "resetting env. episode 9222, reward total was -15.0. running mean: -14.709537232423912, timestamp: 2022-08-19 16:01:38.159139\n",
      "resetting env. episode 9223, reward total was -14.0. running mean: -14.702441860099674, timestamp: 2022-08-19 16:01:45.697226\n",
      "resetting env. episode 9224, reward total was -17.0. running mean: -14.725417441498676, timestamp: 2022-08-19 16:01:55.040337\n",
      "resetting env. episode 9225, reward total was -19.0. running mean: -14.768163267083688, timestamp: 2022-08-19 16:02:02.533421\n",
      "resetting env. episode 9226, reward total was -13.0. running mean: -14.750481634412852, timestamp: 2022-08-19 16:02:12.985543\n",
      "resetting env. episode 9227, reward total was -15.0. running mean: -14.752976818068724, timestamp: 2022-08-19 16:02:21.119688\n",
      "resetting env. episode 9228, reward total was -13.0. running mean: -14.735447049888037, timestamp: 2022-08-19 16:02:29.819789\n",
      "resetting env. episode 9229, reward total was -17.0. running mean: -14.758092579389157, timestamp: 2022-08-19 16:02:37.393876\n",
      "resetting env. episode 9230, reward total was -17.0. running mean: -14.780511653595266, timestamp: 2022-08-19 16:02:45.629972\n",
      "resetting env. episode 9231, reward total was -17.0. running mean: -14.802706537059313, timestamp: 2022-08-19 16:02:52.218572\n",
      "resetting env. episode 9232, reward total was -19.0. running mean: -14.84467947168872, timestamp: 2022-08-19 16:02:59.652655\n",
      "resetting env. episode 9233, reward total was -14.0. running mean: -14.836232676971832, timestamp: 2022-08-19 16:03:08.026754\n",
      "resetting env. episode 9234, reward total was -19.0. running mean: -14.877870350202114, timestamp: 2022-08-19 16:03:15.801844\n",
      "resetting env. episode 9235, reward total was -12.0. running mean: -14.849091646700092, timestamp: 2022-08-19 16:03:23.308931\n",
      "resetting env. episode 9236, reward total was -16.0. running mean: -14.860600730233092, timestamp: 2022-08-19 16:03:30.795017\n",
      "resetting env. episode 9237, reward total was -12.0. running mean: -14.83199472293076, timestamp: 2022-08-19 16:03:41.265133\n",
      "resetting env. episode 9238, reward total was -17.0. running mean: -14.853674775701453, timestamp: 2022-08-19 16:03:49.994234\n",
      "resetting env. episode 9239, reward total was -11.0. running mean: -14.815138027944437, timestamp: 2022-08-19 16:03:59.729346\n",
      "resetting env. episode 9240, reward total was -15.0. running mean: -14.816986647664994, timestamp: 2022-08-19 16:04:07.006956\n",
      "resetting env. episode 9241, reward total was -15.0. running mean: -14.818816781188344, timestamp: 2022-08-19 16:04:13.999035\n",
      "resetting env. episode 9242, reward total was -17.0. running mean: -14.840628613376461, timestamp: 2022-08-19 16:04:21.440119\n",
      "resetting env. episode 9243, reward total was -16.0. running mean: -14.852222327242696, timestamp: 2022-08-19 16:04:30.236220\n",
      "resetting env. episode 9244, reward total was -16.0. running mean: -14.863700103970269, timestamp: 2022-08-19 16:04:38.519315\n",
      "resetting env. episode 9245, reward total was -14.0. running mean: -14.855063102930567, timestamp: 2022-08-19 16:04:45.975399\n",
      "resetting env. episode 9246, reward total was -4.0. running mean: -14.74651247190126, timestamp: 2022-08-19 16:04:57.429531\n",
      "resetting env. episode 9247, reward total was -15.0. running mean: -14.749047347182248, timestamp: 2022-08-19 16:05:05.588623\n",
      "resetting env. episode 9248, reward total was -16.0. running mean: -14.761556873710425, timestamp: 2022-08-19 16:05:14.721250\n",
      "resetting env. episode 9249, reward total was -12.0. running mean: -14.733941304973321, timestamp: 2022-08-19 16:05:23.491351\n",
      "resetting env. episode 9250, reward total was -19.0. running mean: -14.776601891923587, timestamp: 2022-08-19 16:05:31.018961\n",
      "resetting env. episode 9251, reward total was -14.0. running mean: -14.76883587300435, timestamp: 2022-08-19 16:05:39.614059\n",
      "resetting env. episode 9252, reward total was -13.0. running mean: -14.751147514274308, timestamp: 2022-08-19 16:05:49.239168\n",
      "resetting env. episode 9253, reward total was -13.0. running mean: -14.733636039131566, timestamp: 2022-08-19 16:05:59.680286\n",
      "resetting env. episode 9254, reward total was -8.0. running mean: -14.66629967874025, timestamp: 2022-08-19 16:06:12.171954\n",
      "resetting env. episode 9255, reward total was -9.0. running mean: -14.609636681952848, timestamp: 2022-08-19 16:06:20.874054\n",
      "resetting env. episode 9256, reward total was -16.0. running mean: -14.623540315133319, timestamp: 2022-08-19 16:06:28.783142\n",
      "resetting env. episode 9257, reward total was -12.0. running mean: -14.597304911981984, timestamp: 2022-08-19 16:06:38.859257\n",
      "resetting env. episode 9258, reward total was -9.0. running mean: -14.541331862862164, timestamp: 2022-08-19 16:06:48.611366\n",
      "resetting env. episode 9259, reward total was -13.0. running mean: -14.525918544233543, timestamp: 2022-08-19 16:07:00.090502\n",
      "resetting env. episode 9260, reward total was -13.0. running mean: -14.510659358791207, timestamp: 2022-08-19 16:07:08.505592\n",
      "resetting env. episode 9261, reward total was -12.0. running mean: -14.485552765203295, timestamp: 2022-08-19 16:07:19.144235\n",
      "resetting env. episode 9262, reward total was -12.0. running mean: -14.46069723755126, timestamp: 2022-08-19 16:07:26.741325\n",
      "resetting env. episode 9263, reward total was -13.0. running mean: -14.446090265175748, timestamp: 2022-08-19 16:07:35.308945\n",
      "resetting env. episode 9264, reward total was -15.0. running mean: -14.45162936252399, timestamp: 2022-08-19 16:07:44.206047\n",
      "resetting env. episode 9265, reward total was -18.0. running mean: -14.487113068898749, timestamp: 2022-08-19 16:07:50.585651\n",
      "resetting env. episode 9266, reward total was -15.0. running mean: -14.492241938209762, timestamp: 2022-08-19 16:07:57.712733\n",
      "resetting env. episode 9267, reward total was -13.0. running mean: -14.477319518827665, timestamp: 2022-08-19 16:08:07.618847\n",
      "resetting env. episode 9268, reward total was -16.0. running mean: -14.492546323639388, timestamp: 2022-08-19 16:08:14.325928\n",
      "resetting env. episode 9269, reward total was -13.0. running mean: -14.477620860402995, timestamp: 2022-08-19 16:08:24.062559\n",
      "resetting env. episode 9270, reward total was -14.0. running mean: -14.472844651798965, timestamp: 2022-08-19 16:08:32.599658\n",
      "resetting env. episode 9271, reward total was -16.0. running mean: -14.488116205280976, timestamp: 2022-08-19 16:08:40.541754\n",
      "resetting env. episode 9272, reward total was -11.0. running mean: -14.453235043228165, timestamp: 2022-08-19 16:08:51.163875\n",
      "resetting env. episode 9273, reward total was -17.0. running mean: -14.478702692795883, timestamp: 2022-08-19 16:08:57.808952\n",
      "resetting env. episode 9274, reward total was -16.0. running mean: -14.493915665867924, timestamp: 2022-08-19 16:09:07.131063\n",
      "resetting env. episode 9275, reward total was -15.0. running mean: -14.498976509209244, timestamp: 2022-08-19 16:09:17.682184\n",
      "resetting env. episode 9276, reward total was -13.0. running mean: -14.483986744117153, timestamp: 2022-08-19 16:09:27.080296\n",
      "resetting env. episode 9277, reward total was -13.0. running mean: -14.469146876675982, timestamp: 2022-08-19 16:09:37.520416\n",
      "resetting env. episode 9278, reward total was -11.0. running mean: -14.43445540790922, timestamp: 2022-08-19 16:09:48.194544\n",
      "resetting env. episode 9279, reward total was -21.0. running mean: -14.50011085383013, timestamp: 2022-08-19 16:09:55.311625\n",
      "resetting env. episode 9280, reward total was -10.0. running mean: -14.455109745291828, timestamp: 2022-08-19 16:10:07.664296\n",
      "resetting env. episode 9281, reward total was -7.0. running mean: -14.38055864783891, timestamp: 2022-08-19 16:10:21.013974\n",
      "resetting env. episode 9282, reward total was -15.0. running mean: -14.38675306136052, timestamp: 2022-08-19 16:10:29.510074\n",
      "resetting env. episode 9283, reward total was -19.0. running mean: -14.432885530746915, timestamp: 2022-08-19 16:10:36.350154\n",
      "resetting env. episode 9284, reward total was -11.0. running mean: -14.398556675439446, timestamp: 2022-08-19 16:10:45.310259\n",
      "resetting env. episode 9285, reward total was -14.0. running mean: -14.394571108685051, timestamp: 2022-08-19 16:10:54.759376\n",
      "resetting env. episode 9286, reward total was -13.0. running mean: -14.380625397598202, timestamp: 2022-08-19 16:11:03.687479\n",
      "resetting env. episode 9287, reward total was -14.0. running mean: -14.37681914362222, timestamp: 2022-08-19 16:11:13.207592\n",
      "resetting env. episode 9288, reward total was -11.0. running mean: -14.343050952185996, timestamp: 2022-08-19 16:11:23.888722\n",
      "resetting env. episode 9289, reward total was -12.0. running mean: -14.319620442664135, timestamp: 2022-08-19 16:11:33.646835\n",
      "resetting env. episode 9290, reward total was -14.0. running mean: -14.316424238237495, timestamp: 2022-08-19 16:11:41.731927\n",
      "resetting env. episode 9291, reward total was -17.0. running mean: -14.34325999585512, timestamp: 2022-08-19 16:11:50.903037\n",
      "resetting env. episode 9292, reward total was -13.0. running mean: -14.32982739589657, timestamp: 2022-08-19 16:12:03.294187\n",
      "resetting env. episode 9293, reward total was -16.0. running mean: -14.346529121937605, timestamp: 2022-08-19 16:12:12.801298\n",
      "resetting env. episode 9294, reward total was -16.0. running mean: -14.363063830718229, timestamp: 2022-08-19 16:12:23.573428\n",
      "resetting env. episode 9295, reward total was -16.0. running mean: -14.379433192411046, timestamp: 2022-08-19 16:12:31.967526\n",
      "resetting env. episode 9296, reward total was -18.0. running mean: -14.415638860486935, timestamp: 2022-08-19 16:12:38.885614\n",
      "resetting env. episode 9297, reward total was -15.0. running mean: -14.421482471882065, timestamp: 2022-08-19 16:12:46.435699\n",
      "resetting env. episode 9298, reward total was -12.0. running mean: -14.397267647163243, timestamp: 2022-08-19 16:12:55.543806\n",
      "resetting env. episode 9299, reward total was -10.0. running mean: -14.35329497069161, timestamp: 2022-08-19 16:13:05.778928\n",
      "resetting env. episode 9300, reward total was -13.0. running mean: -14.339762020984695, timestamp: 2022-08-19 16:13:14.886036\n",
      "resetting env. episode 9301, reward total was -17.0. running mean: -14.366364400774849, timestamp: 2022-08-19 16:13:23.498668\n",
      "resetting env. episode 9302, reward total was -12.0. running mean: -14.3427007567671, timestamp: 2022-08-19 16:13:31.399762\n",
      "resetting env. episode 9303, reward total was -11.0. running mean: -14.309273749199427, timestamp: 2022-08-19 16:13:41.986947\n",
      "resetting env. episode 9304, reward total was -14.0. running mean: -14.306181011707434, timestamp: 2022-08-19 16:13:51.104051\n",
      "resetting env. episode 9305, reward total was -19.0. running mean: -14.353119201590358, timestamp: 2022-08-19 16:14:00.004158\n",
      "resetting env. episode 9306, reward total was -18.0. running mean: -14.389588009574455, timestamp: 2022-08-19 16:14:08.467255\n",
      "resetting env. episode 9307, reward total was -11.0. running mean: -14.35569212947871, timestamp: 2022-08-19 16:14:18.625901\n",
      "resetting env. episode 9308, reward total was -20.0. running mean: -14.412135208183923, timestamp: 2022-08-19 16:14:27.096999\n",
      "resetting env. episode 9309, reward total was -11.0. running mean: -14.378013856102083, timestamp: 2022-08-19 16:14:35.463097\n",
      "resetting env. episode 9310, reward total was -19.0. running mean: -14.42423371754106, timestamp: 2022-08-19 16:14:43.317715\n",
      "resetting env. episode 9311, reward total was -15.0. running mean: -14.42999138036565, timestamp: 2022-08-19 16:14:52.489827\n",
      "resetting env. episode 9312, reward total was -7.0. running mean: -14.355691466561993, timestamp: 2022-08-19 16:15:02.580943\n",
      "resetting env. episode 9313, reward total was -15.0. running mean: -14.362134551896373, timestamp: 2022-08-19 16:15:12.558062\n",
      "resetting env. episode 9314, reward total was -18.0. running mean: -14.398513206377409, timestamp: 2022-08-19 16:15:19.812675\n",
      "resetting env. episode 9315, reward total was -11.0. running mean: -14.364528074313634, timestamp: 2022-08-19 16:15:30.562800\n",
      "resetting env. episode 9316, reward total was -13.0. running mean: -14.350882793570499, timestamp: 2022-08-19 16:15:42.060938\n",
      "resetting env. episode 9317, reward total was -18.0. running mean: -14.387373965634794, timestamp: 2022-08-19 16:15:53.969079\n",
      "resetting env. episode 9318, reward total was -16.0. running mean: -14.403500225978446, timestamp: 2022-08-19 16:16:02.629182\n",
      "resetting env. episode 9319, reward total was -19.0. running mean: -14.449465223718661, timestamp: 2022-08-19 16:16:11.298286\n",
      "resetting env. episode 9320, reward total was -15.0. running mean: -14.454970571481475, timestamp: 2022-08-19 16:16:19.065372\n",
      "resetting env. episode 9321, reward total was -7.0. running mean: -14.380420865766661, timestamp: 2022-08-19 16:16:31.075515\n",
      "resetting env. episode 9322, reward total was -12.0. running mean: -14.356616657108994, timestamp: 2022-08-19 16:16:39.601613\n",
      "resetting env. episode 9323, reward total was -15.0. running mean: -14.363050490537905, timestamp: 2022-08-19 16:16:48.107713\n",
      "resetting env. episode 9324, reward total was -13.0. running mean: -14.349419985632526, timestamp: 2022-08-19 16:16:58.064832\n",
      "resetting env. episode 9325, reward total was -19.0. running mean: -14.3959257857762, timestamp: 2022-08-19 16:17:05.979922\n",
      "resetting env. episode 9326, reward total was -14.0. running mean: -14.391966527918438, timestamp: 2022-08-19 16:17:13.573010\n",
      "resetting env. episode 9327, reward total was -18.0. running mean: -14.428046862639253, timestamp: 2022-08-19 16:17:21.887111\n",
      "resetting env. episode 9328, reward total was -15.0. running mean: -14.43376639401286, timestamp: 2022-08-19 16:17:30.035206\n",
      "resetting env. episode 9329, reward total was -16.0. running mean: -14.449428730072732, timestamp: 2022-08-19 16:17:39.543315\n",
      "resetting env. episode 9330, reward total was -17.0. running mean: -14.474934442772005, timestamp: 2022-08-19 16:17:47.866943\n",
      "resetting env. episode 9331, reward total was -8.0. running mean: -14.410185098344284, timestamp: 2022-08-19 16:17:57.926060\n",
      "resetting env. episode 9332, reward total was -19.0. running mean: -14.45608324736084, timestamp: 2022-08-19 16:18:04.293139\n",
      "resetting env. episode 9333, reward total was -17.0. running mean: -14.481522414887232, timestamp: 2022-08-19 16:18:12.627761\n",
      "resetting env. episode 9334, reward total was -18.0. running mean: -14.516707190738359, timestamp: 2022-08-19 16:18:21.560864\n",
      "resetting env. episode 9335, reward total was -17.0. running mean: -14.541540118830975, timestamp: 2022-08-19 16:18:29.176952\n",
      "resetting env. episode 9336, reward total was -15.0. running mean: -14.546124717642666, timestamp: 2022-08-19 16:18:37.584049\n",
      "resetting env. episode 9337, reward total was -15.0. running mean: -14.55066347046624, timestamp: 2022-08-19 16:18:46.923157\n",
      "resetting env. episode 9338, reward total was -12.0. running mean: -14.525156835761576, timestamp: 2022-08-19 16:18:57.582282\n",
      "resetting env. episode 9339, reward total was -16.0. running mean: -14.539905267403961, timestamp: 2022-08-19 16:19:08.048399\n",
      "resetting env. episode 9340, reward total was -7.0. running mean: -14.464506214729921, timestamp: 2022-08-19 16:19:18.998053\n",
      "resetting env. episode 9341, reward total was -16.0. running mean: -14.479861152582622, timestamp: 2022-08-19 16:19:26.689140\n",
      "resetting env. episode 9342, reward total was -16.0. running mean: -14.495062541056795, timestamp: 2022-08-19 16:19:35.627246\n",
      "resetting env. episode 9343, reward total was -15.0. running mean: -14.500111915646228, timestamp: 2022-08-19 16:19:42.963334\n",
      "resetting env. episode 9344, reward total was -16.0. running mean: -14.515110796489765, timestamp: 2022-08-19 16:19:50.962428\n",
      "resetting env. episode 9345, reward total was -11.0. running mean: -14.479959688524866, timestamp: 2022-08-19 16:20:01.111538\n",
      "resetting env. episode 9346, reward total was -10.0. running mean: -14.435160091639617, timestamp: 2022-08-19 16:20:11.319656\n",
      "resetting env. episode 9347, reward total was -12.0. running mean: -14.41080849072322, timestamp: 2022-08-19 16:20:22.749790\n",
      "resetting env. episode 9348, reward total was -16.0. running mean: -14.426700405815987, timestamp: 2022-08-19 16:20:30.409876\n",
      "resetting env. episode 9349, reward total was -9.0. running mean: -14.372433401757828, timestamp: 2022-08-19 16:20:41.005997\n",
      "resetting env. episode 9350, reward total was -18.0. running mean: -14.408709067740249, timestamp: 2022-08-19 16:20:48.798089\n",
      "resetting env. episode 9351, reward total was -12.0. running mean: -14.384621977062846, timestamp: 2022-08-19 16:20:57.116181\n",
      "resetting env. episode 9352, reward total was -14.0. running mean: -14.380775757292218, timestamp: 2022-08-19 16:21:06.139285\n",
      "resetting env. episode 9353, reward total was -11.0. running mean: -14.346967999719295, timestamp: 2022-08-19 16:21:15.013389\n",
      "resetting env. episode 9354, reward total was -14.0. running mean: -14.343498319722103, timestamp: 2022-08-19 16:21:23.025481\n",
      "resetting env. episode 9355, reward total was -14.0. running mean: -14.340063336524883, timestamp: 2022-08-19 16:21:32.437590\n",
      "resetting env. episode 9356, reward total was -14.0. running mean: -14.336662703159634, timestamp: 2022-08-19 16:21:41.157686\n",
      "resetting env. episode 9357, reward total was -13.0. running mean: -14.323296076128038, timestamp: 2022-08-19 16:21:50.575312\n",
      "resetting env. episode 9358, reward total was -15.0. running mean: -14.330063115366759, timestamp: 2022-08-19 16:21:58.144398\n",
      "resetting env. episode 9359, reward total was -11.0. running mean: -14.29676248421309, timestamp: 2022-08-19 16:22:07.232501\n",
      "resetting env. episode 9360, reward total was -19.0. running mean: -14.34379485937096, timestamp: 2022-08-19 16:22:15.783599\n",
      "resetting env. episode 9361, reward total was -10.0. running mean: -14.30035691077725, timestamp: 2022-08-19 16:22:24.508698\n",
      "resetting env. episode 9362, reward total was -15.0. running mean: -14.307353341669478, timestamp: 2022-08-19 16:22:33.670802\n",
      "resetting env. episode 9363, reward total was -3.0. running mean: -14.194279808252782, timestamp: 2022-08-19 16:22:45.751464\n",
      "resetting env. episode 9364, reward total was -13.0. running mean: -14.182337010170254, timestamp: 2022-08-19 16:22:55.354575\n",
      "resetting env. episode 9365, reward total was -18.0. running mean: -14.220513640068551, timestamp: 2022-08-19 16:23:01.851644\n",
      "resetting env. episode 9366, reward total was -17.0. running mean: -14.248308503667866, timestamp: 2022-08-19 16:23:11.343755\n",
      "resetting env. episode 9367, reward total was -15.0. running mean: -14.255825418631188, timestamp: 2022-08-19 16:23:20.949387\n",
      "resetting env. episode 9368, reward total was -14.0. running mean: -14.253267164444877, timestamp: 2022-08-19 16:23:29.572481\n",
      "resetting env. episode 9369, reward total was -18.0. running mean: -14.290734492800427, timestamp: 2022-08-19 16:23:37.582573\n",
      "resetting env. episode 9370, reward total was -11.0. running mean: -14.257827147872423, timestamp: 2022-08-19 16:23:48.809702\n",
      "resetting env. episode 9371, reward total was -6.0. running mean: -14.175248876393699, timestamp: 2022-08-19 16:24:00.865836\n",
      "resetting env. episode 9372, reward total was -12.0. running mean: -14.153496387629762, timestamp: 2022-08-19 16:24:11.777961\n",
      "resetting env. episode 9373, reward total was -16.0. running mean: -14.171961423753464, timestamp: 2022-08-19 16:24:19.716051\n",
      "resetting env. episode 9374, reward total was -18.0. running mean: -14.210241809515928, timestamp: 2022-08-19 16:24:27.666142\n",
      "resetting env. episode 9375, reward total was -17.0. running mean: -14.238139391420768, timestamp: 2022-08-19 16:24:35.568754\n",
      "resetting env. episode 9376, reward total was -9.0. running mean: -14.18575799750656, timestamp: 2022-08-19 16:24:44.414385\n",
      "resetting env. episode 9377, reward total was -13.0. running mean: -14.173900417531495, timestamp: 2022-08-19 16:24:53.210484\n",
      "resetting env. episode 9378, reward total was -18.0. running mean: -14.21216141335618, timestamp: 2022-08-19 16:24:59.816559\n",
      "resetting env. episode 9379, reward total was -12.0. running mean: -14.190039799222617, timestamp: 2022-08-19 16:25:08.071698\n",
      "resetting env. episode 9380, reward total was -16.0. running mean: -14.208139401230392, timestamp: 2022-08-19 16:25:17.169801\n",
      "resetting env. episode 9381, reward total was -17.0. running mean: -14.236058007218087, timestamp: 2022-08-19 16:25:26.355908\n",
      "resetting env. episode 9382, reward total was -11.0. running mean: -14.203697427145906, timestamp: 2022-08-19 16:25:36.511025\n",
      "resetting env. episode 9383, reward total was -16.0. running mean: -14.221660452874447, timestamp: 2022-08-19 16:25:43.573108\n",
      "resetting env. episode 9384, reward total was -15.0. running mean: -14.229443848345703, timestamp: 2022-08-19 16:25:53.743226\n",
      "resetting env. episode 9385, reward total was -16.0. running mean: -14.247149409862246, timestamp: 2022-08-19 16:26:00.422303\n",
      "resetting env. episode 9386, reward total was -18.0. running mean: -14.284677915763623, timestamp: 2022-08-19 16:26:08.983406\n",
      "resetting env. episode 9387, reward total was -11.0. running mean: -14.251831136605986, timestamp: 2022-08-19 16:26:19.535528\n",
      "resetting env. episode 9388, reward total was -14.0. running mean: -14.249312825239926, timestamp: 2022-08-19 16:26:28.117154\n",
      "resetting env. episode 9389, reward total was -13.0. running mean: -14.236819696987528, timestamp: 2022-08-19 16:26:38.010271\n",
      "resetting env. episode 9390, reward total was -19.0. running mean: -14.284451500017651, timestamp: 2022-08-19 16:26:47.257377\n",
      "resetting env. episode 9391, reward total was -19.0. running mean: -14.331606985017475, timestamp: 2022-08-19 16:26:54.350514\n",
      "resetting env. episode 9392, reward total was -17.0. running mean: -14.3582909151673, timestamp: 2022-08-19 16:27:02.409607\n",
      "resetting env. episode 9393, reward total was -15.0. running mean: -14.364708006015627, timestamp: 2022-08-19 16:27:08.953725\n",
      "resetting env. episode 9394, reward total was -20.0. running mean: -14.42106092595547, timestamp: 2022-08-19 16:27:16.248812\n",
      "resetting env. episode 9395, reward total was -14.0. running mean: -14.416850316695916, timestamp: 2022-08-19 16:27:24.671911\n",
      "resetting env. episode 9396, reward total was -12.0. running mean: -14.392681813528956, timestamp: 2022-08-19 16:27:34.894031\n",
      "resetting env. episode 9397, reward total was -17.0. running mean: -14.418754995393666, timestamp: 2022-08-19 16:27:42.173120\n",
      "resetting env. episode 9398, reward total was -13.0. running mean: -14.40456744543973, timestamp: 2022-08-19 16:27:52.361237\n",
      "resetting env. episode 9399, reward total was -8.0. running mean: -14.340521770985331, timestamp: 2022-08-19 16:28:04.666381\n",
      "resetting env. episode 9400, reward total was -17.0. running mean: -14.367116553275478, timestamp: 2022-08-19 16:28:14.424497\n",
      "resetting env. episode 9401, reward total was -17.0. running mean: -14.393445387742723, timestamp: 2022-08-19 16:28:22.388591\n",
      "resetting env. episode 9402, reward total was -13.0. running mean: -14.379510933865296, timestamp: 2022-08-19 16:28:31.167695\n",
      "resetting env. episode 9403, reward total was -20.0. running mean: -14.435715824526643, timestamp: 2022-08-19 16:28:38.423782\n",
      "resetting env. episode 9404, reward total was -14.0. running mean: -14.431358666281376, timestamp: 2022-08-19 16:28:48.971908\n",
      "resetting env. episode 9405, reward total was -15.0. running mean: -14.437045079618562, timestamp: 2022-08-19 16:28:56.735000\n",
      "resetting env. episode 9406, reward total was -18.0. running mean: -14.472674628822375, timestamp: 2022-08-19 16:29:03.950086\n",
      "resetting env. episode 9407, reward total was -13.0. running mean: -14.457947882534151, timestamp: 2022-08-19 16:29:13.606199\n",
      "resetting env. episode 9408, reward total was -18.0. running mean: -14.493368403708809, timestamp: 2022-08-19 16:29:21.664295\n",
      "resetting env. episode 9409, reward total was -18.0. running mean: -14.52843471967172, timestamp: 2022-08-19 16:29:26.518351\n",
      "resetting env. episode 9410, reward total was -14.0. running mean: -14.523150372475003, timestamp: 2022-08-19 16:29:34.936454\n",
      "resetting env. episode 9411, reward total was -11.0. running mean: -14.487918868750253, timestamp: 2022-08-19 16:29:45.822581\n",
      "resetting env. episode 9412, reward total was -16.0. running mean: -14.50303968006275, timestamp: 2022-08-19 16:29:54.648686\n",
      "resetting env. episode 9413, reward total was -11.0. running mean: -14.468009283262122, timestamp: 2022-08-19 16:30:03.921797\n",
      "resetting env. episode 9414, reward total was -14.0. running mean: -14.463329190429501, timestamp: 2022-08-19 16:30:13.024903\n",
      "resetting env. episode 9415, reward total was -14.0. running mean: -14.458695898525207, timestamp: 2022-08-19 16:30:21.157001\n",
      "resetting env. episode 9416, reward total was -14.0. running mean: -14.454108939539955, timestamp: 2022-08-19 16:30:30.572113\n",
      "resetting env. episode 9417, reward total was -17.0. running mean: -14.479567850144555, timestamp: 2022-08-19 16:30:38.303205\n",
      "resetting env. episode 9418, reward total was -11.0. running mean: -14.444772171643109, timestamp: 2022-08-19 16:30:47.921319\n",
      "resetting env. episode 9419, reward total was -14.0. running mean: -14.440324449926678, timestamp: 2022-08-19 16:30:56.867426\n",
      "resetting env. episode 9420, reward total was -6.0. running mean: -14.35592120542741, timestamp: 2022-08-19 16:31:09.210573\n",
      "resetting env. episode 9421, reward total was -15.0. running mean: -14.362361993373137, timestamp: 2022-08-19 16:31:19.258690\n",
      "resetting env. episode 9422, reward total was -15.0. running mean: -14.368738373439406, timestamp: 2022-08-19 16:31:27.798792\n",
      "resetting env. episode 9423, reward total was -13.0. running mean: -14.355050989705013, timestamp: 2022-08-19 16:31:37.079424\n",
      "resetting env. episode 9424, reward total was -16.0. running mean: -14.371500479807963, timestamp: 2022-08-19 16:31:45.411523\n",
      "resetting env. episode 9425, reward total was -12.0. running mean: -14.347785475009882, timestamp: 2022-08-19 16:31:53.934623\n",
      "resetting env. episode 9426, reward total was -14.0. running mean: -14.344307620259784, timestamp: 2022-08-19 16:32:02.300723\n",
      "resetting env. episode 9427, reward total was -13.0. running mean: -14.330864544057187, timestamp: 2022-08-19 16:32:11.297828\n",
      "resetting env. episode 9428, reward total was -10.0. running mean: -14.287555898616615, timestamp: 2022-08-19 16:32:20.846467\n",
      "resetting env. episode 9429, reward total was -17.0. running mean: -14.31468033963045, timestamp: 2022-08-19 16:32:31.272591\n",
      "resetting env. episode 9430, reward total was -18.0. running mean: -14.351533536234145, timestamp: 2022-08-19 16:32:39.887688\n",
      "resetting env. episode 9431, reward total was -16.0. running mean: -14.368018200871804, timestamp: 2022-08-19 16:32:48.782797\n",
      "resetting env. episode 9432, reward total was -13.0. running mean: -14.354338018863086, timestamp: 2022-08-19 16:32:59.304920\n",
      "resetting env. episode 9433, reward total was -17.0. running mean: -14.380794638674455, timestamp: 2022-08-19 16:33:07.675016\n",
      "resetting env. episode 9434, reward total was -19.0. running mean: -14.426986692287711, timestamp: 2022-08-19 16:33:15.087108\n",
      "resetting env. episode 9435, reward total was -16.0. running mean: -14.442716825364833, timestamp: 2022-08-19 16:33:24.278217\n",
      "resetting env. episode 9436, reward total was -14.0. running mean: -14.438289657111186, timestamp: 2022-08-19 16:33:33.224320\n",
      "resetting env. episode 9437, reward total was -18.0. running mean: -14.473906760540073, timestamp: 2022-08-19 16:33:41.539417\n",
      "resetting env. episode 9438, reward total was -16.0. running mean: -14.489167692934672, timestamp: 2022-08-19 16:33:49.424509\n",
      "resetting env. episode 9439, reward total was -12.0. running mean: -14.464276016005323, timestamp: 2022-08-19 16:33:58.694618\n",
      "resetting env. episode 9440, reward total was -15.0. running mean: -14.46963325584527, timestamp: 2022-08-19 16:34:08.387729\n",
      "resetting env. episode 9441, reward total was -20.0. running mean: -14.524936923286816, timestamp: 2022-08-19 16:34:15.471816\n",
      "resetting env. episode 9442, reward total was -13.0. running mean: -14.509687554053949, timestamp: 2022-08-19 16:34:24.338918\n",
      "resetting env. episode 9443, reward total was -15.0. running mean: -14.51459067851341, timestamp: 2022-08-19 16:34:33.489024\n",
      "resetting env. episode 9444, reward total was -18.0. running mean: -14.549444771728275, timestamp: 2022-08-19 16:34:42.479131\n",
      "resetting env. episode 9445, reward total was -15.0. running mean: -14.553950324010993, timestamp: 2022-08-19 16:34:52.469245\n",
      "resetting env. episode 9446, reward total was -8.0. running mean: -14.488410820770882, timestamp: 2022-08-19 16:35:03.023893\n",
      "resetting env. episode 9447, reward total was -12.0. running mean: -14.463526712563173, timestamp: 2022-08-19 16:35:13.626019\n",
      "resetting env. episode 9448, reward total was -17.0. running mean: -14.488891445437542, timestamp: 2022-08-19 16:35:23.225129\n",
      "resetting env. episode 9449, reward total was -15.0. running mean: -14.494002530983167, timestamp: 2022-08-19 16:35:31.439222\n",
      "resetting env. episode 9450, reward total was -17.0. running mean: -14.519062505673334, timestamp: 2022-08-19 16:35:40.309326\n",
      "resetting env. episode 9451, reward total was -16.0. running mean: -14.533871880616601, timestamp: 2022-08-19 16:35:48.987426\n",
      "resetting env. episode 9452, reward total was -17.0. running mean: -14.558533161810436, timestamp: 2022-08-19 16:35:57.260522\n",
      "resetting env. episode 9453, reward total was -11.0. running mean: -14.522947830192331, timestamp: 2022-08-19 16:36:07.091637\n",
      "resetting env. episode 9454, reward total was -13.0. running mean: -14.507718351890409, timestamp: 2022-08-19 16:36:16.114264\n",
      "resetting env. episode 9455, reward total was -18.0. running mean: -14.542641168371505, timestamp: 2022-08-19 16:36:23.443350\n",
      "resetting env. episode 9456, reward total was -14.0. running mean: -14.53721475668779, timestamp: 2022-08-19 16:36:32.442453\n",
      "resetting env. episode 9457, reward total was -16.0. running mean: -14.551842609120913, timestamp: 2022-08-19 16:36:42.303569\n",
      "resetting env. episode 9458, reward total was -15.0. running mean: -14.556324183029703, timestamp: 2022-08-19 16:36:51.078668\n",
      "resetting env. episode 9459, reward total was -13.0. running mean: -14.540760941199407, timestamp: 2022-08-19 16:37:00.099304\n",
      "resetting env. episode 9460, reward total was -17.0. running mean: -14.565353331787414, timestamp: 2022-08-19 16:37:08.923403\n",
      "resetting env. episode 9461, reward total was -15.0. running mean: -14.56969979846954, timestamp: 2022-08-19 16:37:17.762506\n",
      "resetting env. episode 9462, reward total was -11.0. running mean: -14.534002800484844, timestamp: 2022-08-19 16:37:27.804620\n",
      "resetting env. episode 9463, reward total was -14.0. running mean: -14.528662772479995, timestamp: 2022-08-19 16:37:37.148729\n",
      "resetting env. episode 9464, reward total was -12.0. running mean: -14.503376144755194, timestamp: 2022-08-19 16:37:45.351345\n",
      "resetting env. episode 9465, reward total was -11.0. running mean: -14.468342383307641, timestamp: 2022-08-19 16:37:55.519461\n",
      "resetting env. episode 9466, reward total was -11.0. running mean: -14.433658959474565, timestamp: 2022-08-19 16:38:05.243573\n",
      "resetting env. episode 9467, reward total was -10.0. running mean: -14.38932236987982, timestamp: 2022-08-19 16:38:15.859695\n",
      "resetting env. episode 9468, reward total was -15.0. running mean: -14.395429146181021, timestamp: 2022-08-19 16:38:22.675776\n",
      "resetting env. episode 9469, reward total was -15.0. running mean: -14.401474854719211, timestamp: 2022-08-19 16:38:31.895877\n",
      "resetting env. episode 9470, reward total was -15.0. running mean: -14.407460106172019, timestamp: 2022-08-19 16:38:40.794979\n",
      "resetting env. episode 9471, reward total was -18.0. running mean: -14.443385505110298, timestamp: 2022-08-19 16:38:48.699070\n",
      "resetting env. episode 9472, reward total was -13.0. running mean: -14.428951650059195, timestamp: 2022-08-19 16:38:59.537195\n",
      "resetting env. episode 9473, reward total was -11.0. running mean: -14.394662133558603, timestamp: 2022-08-19 16:39:09.003352\n",
      "resetting env. episode 9474, reward total was -13.0. running mean: -14.380715512223018, timestamp: 2022-08-19 16:39:16.823443\n",
      "resetting env. episode 9475, reward total was -15.0. running mean: -14.386908357100788, timestamp: 2022-08-19 16:39:23.642523\n",
      "resetting env. episode 9476, reward total was -17.0. running mean: -14.41303927352978, timestamp: 2022-08-19 16:39:31.942615\n",
      "resetting env. episode 9477, reward total was -18.0. running mean: -14.448908880794482, timestamp: 2022-08-19 16:39:39.511703\n",
      "resetting env. episode 9478, reward total was -18.0. running mean: -14.484419791986538, timestamp: 2022-08-19 16:39:46.926784\n",
      "resetting env. episode 9479, reward total was -16.0. running mean: -14.499575594066672, timestamp: 2022-08-19 16:39:54.163869\n",
      "resetting env. episode 9480, reward total was -17.0. running mean: -14.524579838126005, timestamp: 2022-08-19 16:40:03.229969\n",
      "resetting env. episode 9481, reward total was -13.0. running mean: -14.509334039744745, timestamp: 2022-08-19 16:40:13.930135\n",
      "resetting env. episode 9482, reward total was -17.0. running mean: -14.534240699347297, timestamp: 2022-08-19 16:40:23.915247\n",
      "resetting env. episode 9483, reward total was -9.0. running mean: -14.478898292353824, timestamp: 2022-08-19 16:40:35.361378\n",
      "resetting env. episode 9484, reward total was -16.0. running mean: -14.494109309430286, timestamp: 2022-08-19 16:40:44.644007\n",
      "resetting env. episode 9485, reward total was -14.0. running mean: -14.489168216335983, timestamp: 2022-08-19 16:40:54.039115\n",
      "resetting env. episode 9486, reward total was -19.0. running mean: -14.534276534172623, timestamp: 2022-08-19 16:41:00.909192\n",
      "resetting env. episode 9487, reward total was -13.0. running mean: -14.518933768830896, timestamp: 2022-08-19 16:41:08.179276\n",
      "resetting env. episode 9488, reward total was -12.0. running mean: -14.493744431142586, timestamp: 2022-08-19 16:41:16.640370\n",
      "resetting env. episode 9489, reward total was -11.0. running mean: -14.45880698683116, timestamp: 2022-08-19 16:41:27.389491\n",
      "resetting env. episode 9490, reward total was -11.0. running mean: -14.424218916962849, timestamp: 2022-08-19 16:41:37.531607\n",
      "resetting env. episode 9491, reward total was -18.0. running mean: -14.459976727793219, timestamp: 2022-08-19 16:41:44.044216\n",
      "resetting env. episode 9492, reward total was -17.0. running mean: -14.485376960515286, timestamp: 2022-08-19 16:41:53.242318\n",
      "resetting env. episode 9493, reward total was -16.0. running mean: -14.500523190910133, timestamp: 2022-08-19 16:42:01.239411\n",
      "resetting env. episode 9494, reward total was -16.0. running mean: -14.515517959001032, timestamp: 2022-08-19 16:42:08.404492\n",
      "resetting env. episode 9495, reward total was -9.0. running mean: -14.460362779411021, timestamp: 2022-08-19 16:42:19.766625\n",
      "resetting env. episode 9496, reward total was -15.0. running mean: -14.465759151616911, timestamp: 2022-08-19 16:42:27.786719\n",
      "resetting env. episode 9497, reward total was -10.0. running mean: -14.421101560100741, timestamp: 2022-08-19 16:42:37.026824\n",
      "resetting env. episode 9498, reward total was -12.0. running mean: -14.396890544499733, timestamp: 2022-08-19 16:42:44.868914\n",
      "resetting env. episode 9499, reward total was -19.0. running mean: -14.442921639054735, timestamp: 2022-08-19 16:42:52.947008\n",
      "resetting env. episode 9500, reward total was -18.0. running mean: -14.478492422664187, timestamp: 2022-08-19 16:43:01.799110\n",
      "resetting env. episode 9501, reward total was -16.0. running mean: -14.493707498437546, timestamp: 2022-08-19 16:43:13.649249\n",
      "resetting env. episode 9502, reward total was -13.0. running mean: -14.478770423453172, timestamp: 2022-08-19 16:43:22.393351\n",
      "resetting env. episode 9503, reward total was -11.0. running mean: -14.44398271921864, timestamp: 2022-08-19 16:43:32.752474\n",
      "resetting env. episode 9504, reward total was -10.0. running mean: -14.399542892026453, timestamp: 2022-08-19 16:43:42.252586\n",
      "resetting env. episode 9505, reward total was -11.0. running mean: -14.365547463106187, timestamp: 2022-08-19 16:43:52.344703\n",
      "resetting env. episode 9506, reward total was -13.0. running mean: -14.351891988475126, timestamp: 2022-08-19 16:44:01.932339\n",
      "resetting env. episode 9507, reward total was -13.0. running mean: -14.338373068590375, timestamp: 2022-08-19 16:44:12.485462\n",
      "resetting env. episode 9508, reward total was -18.0. running mean: -14.37498933790447, timestamp: 2022-08-19 16:44:22.480580\n",
      "resetting env. episode 9509, reward total was -19.0. running mean: -14.421239444525424, timestamp: 2022-08-19 16:44:31.340689\n",
      "resetting env. episode 9510, reward total was -6.0. running mean: -14.33702705008017, timestamp: 2022-08-19 16:44:43.797831\n",
      "resetting env. episode 9511, reward total was -14.0. running mean: -14.33365677957937, timestamp: 2022-08-19 16:44:51.603926\n",
      "resetting env. episode 9512, reward total was -13.0. running mean: -14.320320211783576, timestamp: 2022-08-19 16:45:01.963047\n",
      "resetting env. episode 9513, reward total was -17.0. running mean: -14.347117009665741, timestamp: 2022-08-19 16:45:08.441121\n",
      "resetting env. episode 9514, reward total was -16.0. running mean: -14.363645839569084, timestamp: 2022-08-19 16:45:16.167215\n",
      "resetting env. episode 9515, reward total was -9.0. running mean: -14.310009381173394, timestamp: 2022-08-19 16:45:27.132343\n",
      "resetting env. episode 9516, reward total was -15.0. running mean: -14.31690928736166, timestamp: 2022-08-19 16:45:36.234971\n",
      "resetting env. episode 9517, reward total was -15.0. running mean: -14.323740194488044, timestamp: 2022-08-19 16:45:43.918062\n",
      "resetting env. episode 9518, reward total was -15.0. running mean: -14.330502792543165, timestamp: 2022-08-19 16:45:52.349160\n",
      "resetting env. episode 9519, reward total was -7.0. running mean: -14.257197764617732, timestamp: 2022-08-19 16:46:04.194301\n",
      "resetting env. episode 9520, reward total was -15.0. running mean: -14.264625786971555, timestamp: 2022-08-19 16:46:11.937394\n",
      "resetting env. episode 9521, reward total was -13.0. running mean: -14.25197952910184, timestamp: 2022-08-19 16:46:23.612532\n",
      "resetting env. episode 9522, reward total was -12.0. running mean: -14.22945973381082, timestamp: 2022-08-19 16:46:33.028644\n",
      "resetting env. episode 9523, reward total was -15.0. running mean: -14.237165136472713, timestamp: 2022-08-19 16:46:41.935749\n",
      "resetting env. episode 9524, reward total was -12.0. running mean: -14.214793485107986, timestamp: 2022-08-19 16:46:52.519876\n",
      "resetting env. episode 9525, reward total was -20.0. running mean: -14.272645550256906, timestamp: 2022-08-19 16:46:59.932963\n",
      "resetting env. episode 9526, reward total was -15.0. running mean: -14.279919094754337, timestamp: 2022-08-19 16:47:08.913073\n",
      "resetting env. episode 9527, reward total was -15.0. running mean: -14.287119903806794, timestamp: 2022-08-19 16:47:18.382183\n",
      "resetting env. episode 9528, reward total was -19.0. running mean: -14.334248704768726, timestamp: 2022-08-19 16:47:26.581281\n",
      "resetting env. episode 9529, reward total was -15.0. running mean: -14.340906217721038, timestamp: 2022-08-19 16:47:34.777377\n",
      "resetting env. episode 9530, reward total was -17.0. running mean: -14.367497155543827, timestamp: 2022-08-19 16:47:42.851525\n",
      "resetting env. episode 9531, reward total was -16.0. running mean: -14.38382218398839, timestamp: 2022-08-19 16:47:51.846632\n",
      "resetting env. episode 9532, reward total was -13.0. running mean: -14.369983962148506, timestamp: 2022-08-19 16:48:00.580735\n",
      "resetting env. episode 9533, reward total was -15.0. running mean: -14.376284122527021, timestamp: 2022-08-19 16:48:11.079863\n",
      "resetting env. episode 9534, reward total was -18.0. running mean: -14.412521281301752, timestamp: 2022-08-19 16:48:19.191958\n",
      "resetting env. episode 9535, reward total was -19.0. running mean: -14.458396068488733, timestamp: 2022-08-19 16:48:29.241078\n",
      "resetting env. episode 9536, reward total was -18.0. running mean: -14.493812107803846, timestamp: 2022-08-19 16:48:39.139195\n",
      "resetting env. episode 9537, reward total was -15.0. running mean: -14.498873986725808, timestamp: 2022-08-19 16:48:47.368340\n",
      "resetting env. episode 9538, reward total was -15.0. running mean: -14.50388524685855, timestamp: 2022-08-19 16:48:56.003441\n",
      "resetting env. episode 9539, reward total was -17.0. running mean: -14.528846394389964, timestamp: 2022-08-19 16:49:03.413528\n",
      "resetting env. episode 9540, reward total was -18.0. running mean: -14.563557930446065, timestamp: 2022-08-19 16:49:11.587624\n",
      "resetting env. episode 9541, reward total was -13.0. running mean: -14.547922351141604, timestamp: 2022-08-19 16:49:22.107751\n",
      "resetting env. episode 9542, reward total was -14.0. running mean: -14.54244312763019, timestamp: 2022-08-19 16:49:30.637851\n",
      "resetting env. episode 9543, reward total was -15.0. running mean: -14.547018696353888, timestamp: 2022-08-19 16:49:39.394953\n",
      "resetting env. episode 9544, reward total was -14.0. running mean: -14.54154850939035, timestamp: 2022-08-19 16:49:47.559052\n",
      "resetting env. episode 9545, reward total was -17.0. running mean: -14.566133024296445, timestamp: 2022-08-19 16:49:56.100152\n",
      "resetting env. episode 9546, reward total was -11.0. running mean: -14.53047169405348, timestamp: 2022-08-19 16:50:07.615286\n",
      "resetting env. episode 9547, reward total was -11.0. running mean: -14.495166977112945, timestamp: 2022-08-19 16:50:15.534382\n",
      "resetting env. episode 9548, reward total was -14.0. running mean: -14.490215307341815, timestamp: 2022-08-19 16:50:24.340483\n",
      "resetting env. episode 9549, reward total was -17.0. running mean: -14.515313154268396, timestamp: 2022-08-19 16:50:32.438578\n",
      "resetting env. episode 9550, reward total was -17.0. running mean: -14.540160022725711, timestamp: 2022-08-19 16:50:39.598663\n",
      "resetting env. episode 9551, reward total was -13.0. running mean: -14.524758422498454, timestamp: 2022-08-19 16:50:49.933784\n",
      "resetting env. episode 9552, reward total was -17.0. running mean: -14.54951083827347, timestamp: 2022-08-19 16:50:58.279408\n",
      "resetting env. episode 9553, reward total was -13.0. running mean: -14.534015729890736, timestamp: 2022-08-19 16:51:08.227056\n",
      "resetting env. episode 9554, reward total was -10.0. running mean: -14.488675572591829, timestamp: 2022-08-19 16:51:18.661172\n",
      "resetting env. episode 9555, reward total was -13.0. running mean: -14.47378881686591, timestamp: 2022-08-19 16:51:28.038282\n",
      "resetting env. episode 9556, reward total was -11.0. running mean: -14.43905092869725, timestamp: 2022-08-19 16:51:36.586381\n",
      "resetting env. episode 9557, reward total was -15.0. running mean: -14.444660419410278, timestamp: 2022-08-19 16:51:46.449500\n",
      "resetting env. episode 9558, reward total was -18.0. running mean: -14.480213815216175, timestamp: 2022-08-19 16:51:55.329604\n",
      "resetting env. episode 9559, reward total was -14.0. running mean: -14.475411677064013, timestamp: 2022-08-19 16:52:02.442684\n",
      "resetting env. episode 9560, reward total was -11.0. running mean: -14.440657560293372, timestamp: 2022-08-19 16:52:11.242787\n",
      "resetting env. episode 9561, reward total was -12.0. running mean: -14.416250984690437, timestamp: 2022-08-19 16:52:21.996913\n",
      "resetting env. episode 9562, reward total was -13.0. running mean: -14.402088474843534, timestamp: 2022-08-19 16:52:31.728029\n",
      "resetting env. episode 9563, reward total was -17.0. running mean: -14.428067590095099, timestamp: 2022-08-19 16:52:39.345116\n",
      "resetting env. episode 9564, reward total was -12.0. running mean: -14.403786914194146, timestamp: 2022-08-19 16:52:47.941217\n",
      "resetting env. episode 9565, reward total was -13.0. running mean: -14.389749045052206, timestamp: 2022-08-19 16:52:59.074346\n",
      "resetting env. episode 9566, reward total was -14.0. running mean: -14.385851554601684, timestamp: 2022-08-19 16:53:08.411456\n",
      "resetting env. episode 9567, reward total was -14.0. running mean: -14.381993039055669, timestamp: 2022-08-19 16:53:19.696584\n",
      "resetting env. episode 9568, reward total was -13.0. running mean: -14.368173108665113, timestamp: 2022-08-19 16:53:27.196673\n",
      "resetting env. episode 9569, reward total was -11.0. running mean: -14.33449137757846, timestamp: 2022-08-19 16:53:38.192806\n",
      "resetting env. episode 9570, reward total was -17.0. running mean: -14.361146463802676, timestamp: 2022-08-19 16:53:46.552896\n",
      "resetting env. episode 9571, reward total was -18.0. running mean: -14.397534999164648, timestamp: 2022-08-19 16:53:54.018981\n",
      "resetting env. episode 9572, reward total was -19.0. running mean: -14.443559649173, timestamp: 2022-08-19 16:54:02.876086\n",
      "resetting env. episode 9573, reward total was -11.0. running mean: -14.40912405268127, timestamp: 2022-08-19 16:54:11.916190\n",
      "resetting env. episode 9574, reward total was -11.0. running mean: -14.375032812154457, timestamp: 2022-08-19 16:54:23.091844\n",
      "resetting env. episode 9575, reward total was -16.0. running mean: -14.391282484032912, timestamp: 2022-08-19 16:54:33.602487\n",
      "resetting env. episode 9576, reward total was -15.0. running mean: -14.397369659192583, timestamp: 2022-08-19 16:54:42.893113\n",
      "resetting env. episode 9577, reward total was -12.0. running mean: -14.373395962600656, timestamp: 2022-08-19 16:54:52.507223\n",
      "resetting env. episode 9578, reward total was -15.0. running mean: -14.37966200297465, timestamp: 2022-08-19 16:55:00.724317\n",
      "resetting env. episode 9579, reward total was -13.0. running mean: -14.365865382944904, timestamp: 2022-08-19 16:55:11.312441\n",
      "resetting env. episode 9580, reward total was -19.0. running mean: -14.412206729115454, timestamp: 2022-08-19 16:55:18.814525\n",
      "resetting env. episode 9581, reward total was -11.0. running mean: -14.378084661824298, timestamp: 2022-08-19 16:55:29.668650\n",
      "resetting env. episode 9582, reward total was -14.0. running mean: -14.374303815206055, timestamp: 2022-08-19 16:55:37.838742\n",
      "resetting env. episode 9583, reward total was -14.0. running mean: -14.370560777053996, timestamp: 2022-08-19 16:55:45.847838\n",
      "resetting env. episode 9584, reward total was -17.0. running mean: -14.396855169283455, timestamp: 2022-08-19 16:55:54.842939\n",
      "resetting env. episode 9585, reward total was -7.0. running mean: -14.32288661759062, timestamp: 2022-08-19 16:56:05.316060\n",
      "resetting env. episode 9586, reward total was -13.0. running mean: -14.309657751414715, timestamp: 2022-08-19 16:56:14.570164\n",
      "resetting env. episode 9587, reward total was -13.0. running mean: -14.29656117390057, timestamp: 2022-08-19 16:56:23.799271\n",
      "resetting env. episode 9588, reward total was -18.0. running mean: -14.333595562161562, timestamp: 2022-08-19 16:56:31.799362\n",
      "resetting env. episode 9589, reward total was -19.0. running mean: -14.380259606539946, timestamp: 2022-08-19 16:56:39.518448\n",
      "resetting env. episode 9590, reward total was -12.0. running mean: -14.356457010474546, timestamp: 2022-08-19 16:56:49.721564\n",
      "resetting env. episode 9591, reward total was -17.0. running mean: -14.382892440369801, timestamp: 2022-08-19 16:56:57.334651\n",
      "resetting env. episode 9592, reward total was -17.0. running mean: -14.409063515966103, timestamp: 2022-08-19 16:57:07.526768\n",
      "resetting env. episode 9593, reward total was -11.0. running mean: -14.37497288080644, timestamp: 2022-08-19 16:57:19.179900\n",
      "resetting env. episode 9594, reward total was -17.0. running mean: -14.401223151998376, timestamp: 2022-08-19 16:57:27.844999\n",
      "resetting env. episode 9595, reward total was -13.0. running mean: -14.387210920478394, timestamp: 2022-08-19 16:57:36.666096\n",
      "resetting env. episode 9596, reward total was -7.0. running mean: -14.31333881127361, timestamp: 2022-08-19 16:57:49.524290\n",
      "resetting env. episode 9597, reward total was -17.0. running mean: -14.340205423160874, timestamp: 2022-08-19 16:57:58.295391\n",
      "resetting env. episode 9598, reward total was -11.0. running mean: -14.306803368929264, timestamp: 2022-08-19 16:58:07.999499\n",
      "resetting env. episode 9599, reward total was -16.0. running mean: -14.323735335239972, timestamp: 2022-08-19 16:58:16.638600\n",
      "resetting env. episode 9600, reward total was -15.0. running mean: -14.330497981887572, timestamp: 2022-08-19 16:58:25.533698\n",
      "resetting env. episode 9601, reward total was -14.0. running mean: -14.327193002068697, timestamp: 2022-08-19 16:58:34.817802\n",
      "resetting env. episode 9602, reward total was -18.0. running mean: -14.36392107204801, timestamp: 2022-08-19 16:58:43.860909\n",
      "resetting env. episode 9603, reward total was -7.0. running mean: -14.29028186132753, timestamp: 2022-08-19 16:58:55.313039\n",
      "resetting env. episode 9604, reward total was -17.0. running mean: -14.317379042714254, timestamp: 2022-08-19 16:59:03.630133\n",
      "resetting env. episode 9605, reward total was -15.0. running mean: -14.324205252287111, timestamp: 2022-08-19 16:59:12.563240\n",
      "resetting env. episode 9606, reward total was -13.0. running mean: -14.310963199764242, timestamp: 2022-08-19 16:59:22.114349\n",
      "resetting env. episode 9607, reward total was -13.0. running mean: -14.2978535677666, timestamp: 2022-08-19 16:59:34.155489\n",
      "resetting env. episode 9608, reward total was -13.0. running mean: -14.284875032088934, timestamp: 2022-08-19 16:59:43.964600\n",
      "resetting env. episode 9609, reward total was -16.0. running mean: -14.302026281768045, timestamp: 2022-08-19 16:59:52.843704\n",
      "resetting env. episode 9610, reward total was -12.0. running mean: -14.279006018950364, timestamp: 2022-08-19 17:00:01.732807\n",
      "resetting env. episode 9611, reward total was -15.0. running mean: -14.286215958760861, timestamp: 2022-08-19 17:00:09.845906\n",
      "resetting env. episode 9612, reward total was -18.0. running mean: -14.323353799173253, timestamp: 2022-08-19 17:00:17.507994\n",
      "resetting env. episode 9613, reward total was -8.0. running mean: -14.26012026118152, timestamp: 2022-08-19 17:00:28.302644\n",
      "resetting env. episode 9614, reward total was -14.0. running mean: -14.257519058569704, timestamp: 2022-08-19 17:00:39.275293\n",
      "resetting env. episode 9615, reward total was -19.0. running mean: -14.304943867984006, timestamp: 2022-08-19 17:00:46.889382\n",
      "resetting env. episode 9616, reward total was -11.0. running mean: -14.271894429304165, timestamp: 2022-08-19 17:00:57.263504\n",
      "resetting env. episode 9617, reward total was -10.0. running mean: -14.229175485011123, timestamp: 2022-08-19 17:01:06.201613\n",
      "resetting env. episode 9618, reward total was -20.0. running mean: -14.28688373016101, timestamp: 2022-08-19 17:01:12.214681\n",
      "resetting env. episode 9619, reward total was -16.0. running mean: -14.304014892859401, timestamp: 2022-08-19 17:01:19.802769\n",
      "resetting env. episode 9620, reward total was -15.0. running mean: -14.310974743930807, timestamp: 2022-08-19 17:01:28.092869\n",
      "resetting env. episode 9621, reward total was -11.0. running mean: -14.277864996491498, timestamp: 2022-08-19 17:01:37.852982\n",
      "resetting env. episode 9622, reward total was -12.0. running mean: -14.255086346526582, timestamp: 2022-08-19 17:01:47.351096\n",
      "resetting env. episode 9623, reward total was -21.0. running mean: -14.322535483061317, timestamp: 2022-08-19 17:01:53.293163\n",
      "resetting env. episode 9624, reward total was -17.0. running mean: -14.349310128230703, timestamp: 2022-08-19 17:02:03.125283\n",
      "resetting env. episode 9625, reward total was -18.0. running mean: -14.385817026948397, timestamp: 2022-08-19 17:02:11.721385\n",
      "resetting env. episode 9626, reward total was -11.0. running mean: -14.351958856678912, timestamp: 2022-08-19 17:02:20.231483\n",
      "resetting env. episode 9627, reward total was -9.0. running mean: -14.298439268112123, timestamp: 2022-08-19 17:02:31.136614\n",
      "resetting env. episode 9628, reward total was -17.0. running mean: -14.325454875431001, timestamp: 2022-08-19 17:02:38.673700\n",
      "resetting env. episode 9629, reward total was -15.0. running mean: -14.332200326676691, timestamp: 2022-08-19 17:02:47.988813\n",
      "resetting env. episode 9630, reward total was -17.0. running mean: -14.358878323409924, timestamp: 2022-08-19 17:02:57.061917\n",
      "resetting env. episode 9631, reward total was -15.0. running mean: -14.365289540175825, timestamp: 2022-08-19 17:03:06.458030\n",
      "resetting env. episode 9632, reward total was -13.0. running mean: -14.351636644774068, timestamp: 2022-08-19 17:03:13.751117\n",
      "resetting env. episode 9633, reward total was -13.0. running mean: -14.338120278326327, timestamp: 2022-08-19 17:03:22.543221\n",
      "resetting env. episode 9634, reward total was -16.0. running mean: -14.354739075543064, timestamp: 2022-08-19 17:03:31.385328\n",
      "resetting env. episode 9635, reward total was -16.0. running mean: -14.371191684787632, timestamp: 2022-08-19 17:03:41.805450\n",
      "resetting env. episode 9636, reward total was -16.0. running mean: -14.387479767939755, timestamp: 2022-08-19 17:03:51.274562\n",
      "resetting env. episode 9637, reward total was -9.0. running mean: -14.333604970260357, timestamp: 2022-08-19 17:04:03.410707\n",
      "resetting env. episode 9638, reward total was -10.0. running mean: -14.290268920557752, timestamp: 2022-08-19 17:04:15.225847\n",
      "resetting env. episode 9639, reward total was -13.0. running mean: -14.277366231352175, timestamp: 2022-08-19 17:04:26.654983\n",
      "resetting env. episode 9640, reward total was -17.0. running mean: -14.304592569038654, timestamp: 2022-08-19 17:04:34.157074\n",
      "resetting env. episode 9641, reward total was -14.0. running mean: -14.301546643348267, timestamp: 2022-08-19 17:04:43.356187\n",
      "resetting env. episode 9642, reward total was -13.0. running mean: -14.288531176914786, timestamp: 2022-08-19 17:04:53.289301\n",
      "resetting env. episode 9643, reward total was -15.0. running mean: -14.295645865145637, timestamp: 2022-08-19 17:05:03.002416\n",
      "resetting env. episode 9644, reward total was -10.0. running mean: -14.25268940649418, timestamp: 2022-08-19 17:05:13.568541\n",
      "resetting env. episode 9645, reward total was -9.0. running mean: -14.20016251242924, timestamp: 2022-08-19 17:05:25.079680\n",
      "resetting env. episode 9646, reward total was -15.0. running mean: -14.208160887304947, timestamp: 2022-08-19 17:05:32.430295\n",
      "resetting env. episode 9647, reward total was -15.0. running mean: -14.216079278431899, timestamp: 2022-08-19 17:05:41.296401\n",
      "resetting env. episode 9648, reward total was -13.0. running mean: -14.20391848564758, timestamp: 2022-08-19 17:05:51.608521\n",
      "resetting env. episode 9649, reward total was -15.0. running mean: -14.211879300791106, timestamp: 2022-08-19 17:06:02.582178\n",
      "resetting env. episode 9650, reward total was -9.0. running mean: -14.159760507783194, timestamp: 2022-08-19 17:06:13.851308\n",
      "resetting env. episode 9651, reward total was -11.0. running mean: -14.12816290270536, timestamp: 2022-08-19 17:06:23.099941\n",
      "resetting env. episode 9652, reward total was -15.0. running mean: -14.136881273678307, timestamp: 2022-08-19 17:06:31.522038\n",
      "resetting env. episode 9653, reward total was -19.0. running mean: -14.185512460941524, timestamp: 2022-08-19 17:06:38.814126\n",
      "resetting env. episode 9654, reward total was -13.0. running mean: -14.17365733633211, timestamp: 2022-08-19 17:06:47.428226\n",
      "resetting env. episode 9655, reward total was -13.0. running mean: -14.161920762968789, timestamp: 2022-08-19 17:06:57.535345\n",
      "resetting env. episode 9656, reward total was -13.0. running mean: -14.150301555339102, timestamp: 2022-08-19 17:07:07.491462\n",
      "resetting env. episode 9657, reward total was -11.0. running mean: -14.11879853978571, timestamp: 2022-08-19 17:07:17.530581\n",
      "resetting env. episode 9658, reward total was -19.0. running mean: -14.167610554387851, timestamp: 2022-08-19 17:07:24.154659\n",
      "resetting env. episode 9659, reward total was -13.0. running mean: -14.155934448843974, timestamp: 2022-08-19 17:07:34.246779\n",
      "resetting env. episode 9660, reward total was -18.0. running mean: -14.194375104355533, timestamp: 2022-08-19 17:07:41.282860\n",
      "resetting env. episode 9661, reward total was -12.0. running mean: -14.172431353311977, timestamp: 2022-08-19 17:07:50.736973\n",
      "resetting env. episode 9662, reward total was -10.0. running mean: -14.130707039778857, timestamp: 2022-08-19 17:08:02.223107\n",
      "resetting env. episode 9663, reward total was -9.0. running mean: -14.079399969381068, timestamp: 2022-08-19 17:08:11.827746\n",
      "resetting env. episode 9664, reward total was -15.0. running mean: -14.088605969687258, timestamp: 2022-08-19 17:08:24.910900\n",
      "resetting env. episode 9665, reward total was -16.0. running mean: -14.107719909990385, timestamp: 2022-08-19 17:08:35.436023\n",
      "resetting env. episode 9666, reward total was -12.0. running mean: -14.08664271089048, timestamp: 2022-08-19 17:08:44.703128\n",
      "resetting env. episode 9667, reward total was -18.0. running mean: -14.125776283781574, timestamp: 2022-08-19 17:08:53.033230\n",
      "resetting env. episode 9668, reward total was -18.0. running mean: -14.164518520943759, timestamp: 2022-08-19 17:09:01.190323\n",
      "resetting env. episode 9669, reward total was -10.0. running mean: -14.12287333573432, timestamp: 2022-08-19 17:09:11.235443\n",
      "resetting env. episode 9670, reward total was -11.0. running mean: -14.091644602376977, timestamp: 2022-08-19 17:09:21.788562\n",
      "resetting env. episode 9671, reward total was -12.0. running mean: -14.070728156353207, timestamp: 2022-08-19 17:09:32.746691\n",
      "resetting env. episode 9672, reward total was -17.0. running mean: -14.100020874789674, timestamp: 2022-08-19 17:09:40.594309\n",
      "resetting env. episode 9673, reward total was -13.0. running mean: -14.089020666041778, timestamp: 2022-08-19 17:09:50.180419\n",
      "resetting env. episode 9674, reward total was -14.0. running mean: -14.088130459381361, timestamp: 2022-08-19 17:10:00.891545\n",
      "resetting env. episode 9675, reward total was -15.0. running mean: -14.097249154787548, timestamp: 2022-08-19 17:10:11.414665\n",
      "resetting env. episode 9676, reward total was -13.0. running mean: -14.086276663239673, timestamp: 2022-08-19 17:10:21.979789\n",
      "resetting env. episode 9677, reward total was -21.0. running mean: -14.155413896607277, timestamp: 2022-08-19 17:10:28.830868\n",
      "resetting env. episode 9678, reward total was -15.0. running mean: -14.163859757641204, timestamp: 2022-08-19 17:10:36.399960\n",
      "resetting env. episode 9679, reward total was -19.0. running mean: -14.212221160064791, timestamp: 2022-08-19 17:10:45.562063\n",
      "resetting env. episode 9680, reward total was -13.0. running mean: -14.200098948464143, timestamp: 2022-08-19 17:10:54.750217\n",
      "resetting env. episode 9681, reward total was -13.0. running mean: -14.188097958979503, timestamp: 2022-08-19 17:11:05.597342\n",
      "resetting env. episode 9682, reward total was -17.0. running mean: -14.216216979389708, timestamp: 2022-08-19 17:11:12.740425\n",
      "resetting env. episode 9683, reward total was -15.0. running mean: -14.224054809595811, timestamp: 2022-08-19 17:11:20.578053\n",
      "resetting env. episode 9684, reward total was -9.0. running mean: -14.171814261499852, timestamp: 2022-08-19 17:11:30.383702\n",
      "resetting env. episode 9685, reward total was -10.0. running mean: -14.130096118884854, timestamp: 2022-08-19 17:11:39.560806\n",
      "resetting env. episode 9686, reward total was -13.0. running mean: -14.118795157696006, timestamp: 2022-08-19 17:11:50.102926\n",
      "resetting env. episode 9687, reward total was -15.0. running mean: -14.127607206119047, timestamp: 2022-08-19 17:11:58.018016\n",
      "resetting env. episode 9688, reward total was -14.0. running mean: -14.126331134057857, timestamp: 2022-08-19 17:12:08.375137\n",
      "resetting env. episode 9689, reward total was -14.0. running mean: -14.125067822717279, timestamp: 2022-08-19 17:12:15.600742\n",
      "resetting env. episode 9690, reward total was -15.0. running mean: -14.133817144490106, timestamp: 2022-08-19 17:12:23.866836\n",
      "resetting env. episode 9691, reward total was -11.0. running mean: -14.102478973045203, timestamp: 2022-08-19 17:12:34.801964\n",
      "resetting env. episode 9692, reward total was -10.0. running mean: -14.061454183314751, timestamp: 2022-08-19 17:12:44.296071\n",
      "resetting env. episode 9693, reward total was -14.0. running mean: -14.060839641481603, timestamp: 2022-08-19 17:12:53.912181\n",
      "resetting env. episode 9694, reward total was -14.0. running mean: -14.060231245066788, timestamp: 2022-08-19 17:13:02.793284\n",
      "resetting env. episode 9695, reward total was -11.0. running mean: -14.02962893261612, timestamp: 2022-08-19 17:13:14.843421\n",
      "resetting env. episode 9696, reward total was -16.0. running mean: -14.04933264328996, timestamp: 2022-08-19 17:13:24.056524\n",
      "resetting env. episode 9697, reward total was -18.0. running mean: -14.08883931685706, timestamp: 2022-08-19 17:13:33.154630\n",
      "resetting env. episode 9698, reward total was -16.0. running mean: -14.10795092368849, timestamp: 2022-08-19 17:13:42.956743\n",
      "resetting env. episode 9699, reward total was -6.0. running mean: -14.026871414451605, timestamp: 2022-08-19 17:13:55.325882\n",
      "resetting env. episode 9700, reward total was -17.0. running mean: -14.056602700307089, timestamp: 2022-08-19 17:14:03.248973\n",
      "resetting env. episode 9701, reward total was -12.0. running mean: -14.036036673304016, timestamp: 2022-08-19 17:14:13.431657\n",
      "resetting env. episode 9702, reward total was -18.0. running mean: -14.075676306570976, timestamp: 2022-08-19 17:14:21.305746\n",
      "resetting env. episode 9703, reward total was -7.0. running mean: -14.004919543505267, timestamp: 2022-08-19 17:14:31.635868\n",
      "resetting env. episode 9704, reward total was -16.0. running mean: -14.024870348070214, timestamp: 2022-08-19 17:14:41.476977\n",
      "resetting env. episode 9705, reward total was -5.0. running mean: -13.934621644589512, timestamp: 2022-08-19 17:14:54.935128\n",
      "resetting env. episode 9706, reward total was -9.0. running mean: -13.885275428143617, timestamp: 2022-08-19 17:15:05.479247\n",
      "resetting env. episode 9707, reward total was -14.0. running mean: -13.886422673862182, timestamp: 2022-08-19 17:15:16.382368\n",
      "resetting env. episode 9708, reward total was -13.0. running mean: -13.87755844712356, timestamp: 2022-08-19 17:15:26.807489\n",
      "resetting env. episode 9709, reward total was -12.0. running mean: -13.858782862652324, timestamp: 2022-08-19 17:15:36.505598\n",
      "resetting env. episode 9710, reward total was -16.0. running mean: -13.880195034025801, timestamp: 2022-08-19 17:15:45.535700\n",
      "resetting env. episode 9711, reward total was -14.0. running mean: -13.881393083685543, timestamp: 2022-08-19 17:15:54.013801\n",
      "resetting env. episode 9712, reward total was -9.0. running mean: -13.832579152848687, timestamp: 2022-08-19 17:16:04.275915\n",
      "resetting env. episode 9713, reward total was -17.0. running mean: -13.8642533613202, timestamp: 2022-08-19 17:16:13.809027\n",
      "resetting env. episode 9714, reward total was -15.0. running mean: -13.875610827706998, timestamp: 2022-08-19 17:16:21.729116\n",
      "resetting env. episode 9715, reward total was -9.0. running mean: -13.826854719429928, timestamp: 2022-08-19 17:16:31.578230\n",
      "resetting env. episode 9716, reward total was -15.0. running mean: -13.83858617223563, timestamp: 2022-08-19 17:16:41.281343\n",
      "resetting env. episode 9717, reward total was -17.0. running mean: -13.870200310513273, timestamp: 2022-08-19 17:16:48.679433\n",
      "resetting env. episode 9718, reward total was -14.0. running mean: -13.87149830740814, timestamp: 2022-08-19 17:16:58.021061\n",
      "resetting env. episode 9719, reward total was -11.0. running mean: -13.842783324334059, timestamp: 2022-08-19 17:17:06.834164\n",
      "resetting env. episode 9720, reward total was -17.0. running mean: -13.874355491090718, timestamp: 2022-08-19 17:17:16.276273\n",
      "resetting env. episode 9721, reward total was -10.0. running mean: -13.83561193617981, timestamp: 2022-08-19 17:17:27.518927\n",
      "resetting env. episode 9722, reward total was -13.0. running mean: -13.827255816818012, timestamp: 2022-08-19 17:17:36.155076\n",
      "resetting env. episode 9723, reward total was -13.0. running mean: -13.818983258649832, timestamp: 2022-08-19 17:17:45.753188\n",
      "resetting env. episode 9724, reward total was -19.0. running mean: -13.870793426063333, timestamp: 2022-08-19 17:17:53.263278\n",
      "resetting env. episode 9725, reward total was -8.0. running mean: -13.8120854918027, timestamp: 2022-08-19 17:18:04.618409\n",
      "resetting env. episode 9726, reward total was -12.0. running mean: -13.793964636884672, timestamp: 2022-08-19 17:18:14.882054\n",
      "resetting env. episode 9727, reward total was -14.0. running mean: -13.796024990515825, timestamp: 2022-08-19 17:18:23.858159\n",
      "resetting env. episode 9728, reward total was -9.0. running mean: -13.748064740610667, timestamp: 2022-08-19 17:18:34.373284\n",
      "resetting env. episode 9729, reward total was -18.0. running mean: -13.79058409320456, timestamp: 2022-08-19 17:18:41.450365\n",
      "resetting env. episode 9730, reward total was -15.0. running mean: -13.802678252272514, timestamp: 2022-08-19 17:18:50.391470\n",
      "resetting env. episode 9731, reward total was -9.0. running mean: -13.754651469749788, timestamp: 2022-08-19 17:19:02.757138\n",
      "resetting env. episode 9732, reward total was -15.0. running mean: -13.767104955052291, timestamp: 2022-08-19 17:19:12.018248\n",
      "resetting env. episode 9733, reward total was -14.0. running mean: -13.769433905501769, timestamp: 2022-08-19 17:19:23.745386\n",
      "resetting env. episode 9734, reward total was -16.0. running mean: -13.79173956644675, timestamp: 2022-08-19 17:19:33.248022\n",
      "resetting env. episode 9735, reward total was -7.0. running mean: -13.723822170782283, timestamp: 2022-08-19 17:19:44.695681\n",
      "resetting env. episode 9736, reward total was -18.0. running mean: -13.766583949074459, timestamp: 2022-08-19 17:19:53.092782\n",
      "resetting env. episode 9737, reward total was -15.0. running mean: -13.778918109583714, timestamp: 2022-08-19 17:20:02.012888\n",
      "resetting env. episode 9738, reward total was -16.0. running mean: -13.801128928487877, timestamp: 2022-08-19 17:20:12.477548\n",
      "resetting env. episode 9739, reward total was -17.0. running mean: -13.833117639202998, timestamp: 2022-08-19 17:20:21.338651\n",
      "resetting env. episode 9740, reward total was -15.0. running mean: -13.844786462810967, timestamp: 2022-08-19 17:20:29.734748\n",
      "resetting env. episode 9741, reward total was -13.0. running mean: -13.836338598182857, timestamp: 2022-08-19 17:20:38.807857\n",
      "resetting env. episode 9742, reward total was -15.0. running mean: -13.84797521220103, timestamp: 2022-08-19 17:20:49.884988\n",
      "resetting env. episode 9743, reward total was -15.0. running mean: -13.85949546007902, timestamp: 2022-08-19 17:20:58.891096\n",
      "resetting env. episode 9744, reward total was -15.0. running mean: -13.870900505478229, timestamp: 2022-08-19 17:21:11.071765\n",
      "resetting env. episode 9745, reward total was -18.0. running mean: -13.912191500423447, timestamp: 2022-08-19 17:21:20.921880\n",
      "resetting env. episode 9746, reward total was -19.0. running mean: -13.96306958541921, timestamp: 2022-08-19 17:21:30.488993\n",
      "resetting env. episode 9747, reward total was -8.0. running mean: -13.903438889565018, timestamp: 2022-08-19 17:21:42.128132\n",
      "resetting env. episode 9748, reward total was -17.0. running mean: -13.934404500669368, timestamp: 2022-08-19 17:21:53.224264\n",
      "resetting env. episode 9749, reward total was -14.0. running mean: -13.935060455662676, timestamp: 2022-08-19 17:22:02.166890\n",
      "resetting env. episode 9750, reward total was -14.0. running mean: -13.935709851106049, timestamp: 2022-08-19 17:22:11.855003\n",
      "resetting env. episode 9751, reward total was -16.0. running mean: -13.956352752594988, timestamp: 2022-08-19 17:22:21.716120\n",
      "resetting env. episode 9752, reward total was -12.0. running mean: -13.936789225069036, timestamp: 2022-08-19 17:22:33.044252\n",
      "resetting env. episode 9753, reward total was -12.0. running mean: -13.917421332818344, timestamp: 2022-08-19 17:22:42.497370\n",
      "resetting env. episode 9754, reward total was -15.0. running mean: -13.92824711949016, timestamp: 2022-08-19 17:22:50.217458\n",
      "resetting env. episode 9755, reward total was -11.0. running mean: -13.898964648295259, timestamp: 2022-08-19 17:23:00.340576\n",
      "resetting env. episode 9756, reward total was -14.0. running mean: -13.899975001812306, timestamp: 2022-08-19 17:23:08.448672\n",
      "resetting env. episode 9757, reward total was -19.0. running mean: -13.950975251794183, timestamp: 2022-08-19 17:23:16.273763\n",
      "resetting env. episode 9758, reward total was -19.0. running mean: -14.001465499276241, timestamp: 2022-08-19 17:23:23.741854\n",
      "resetting env. episode 9759, reward total was -12.0. running mean: -13.981450844283478, timestamp: 2022-08-19 17:23:34.121976\n",
      "resetting env. episode 9760, reward total was -16.0. running mean: -14.001636335840642, timestamp: 2022-08-19 17:23:41.571063\n",
      "resetting env. episode 9761, reward total was -17.0. running mean: -14.031619972482236, timestamp: 2022-08-19 17:23:49.022156\n",
      "resetting env. episode 9762, reward total was -16.0. running mean: -14.051303772757414, timestamp: 2022-08-19 17:23:57.636780\n",
      "resetting env. episode 9763, reward total was -15.0. running mean: -14.06079073502984, timestamp: 2022-08-19 17:24:07.632888\n",
      "resetting env. episode 9764, reward total was -15.0. running mean: -14.070182827679542, timestamp: 2022-08-19 17:24:16.660995\n",
      "resetting env. episode 9765, reward total was -19.0. running mean: -14.119480999402747, timestamp: 2022-08-19 17:24:25.591102\n",
      "resetting env. episode 9766, reward total was -14.0. running mean: -14.11828618940872, timestamp: 2022-08-19 17:24:35.441212\n",
      "resetting env. episode 9767, reward total was -11.0. running mean: -14.087103327514631, timestamp: 2022-08-19 17:24:45.430331\n",
      "resetting env. episode 9768, reward total was -11.0. running mean: -14.056232294239484, timestamp: 2022-08-19 17:24:56.515985\n",
      "resetting env. episode 9769, reward total was -11.0. running mean: -14.025669971297088, timestamp: 2022-08-19 17:25:08.387123\n",
      "resetting env. episode 9770, reward total was -16.0. running mean: -14.045413271584117, timestamp: 2022-08-19 17:25:15.720206\n",
      "resetting env. episode 9771, reward total was -15.0. running mean: -14.054959138868275, timestamp: 2022-08-19 17:25:23.486300\n",
      "resetting env. episode 9772, reward total was -13.0. running mean: -14.044409547479594, timestamp: 2022-08-19 17:25:31.220387\n",
      "resetting env. episode 9773, reward total was -13.0. running mean: -14.033965452004798, timestamp: 2022-08-19 17:25:41.418509\n",
      "resetting env. episode 9774, reward total was -16.0. running mean: -14.05362579748475, timestamp: 2022-08-19 17:25:50.897617\n",
      "resetting env. episode 9775, reward total was -14.0. running mean: -14.053089539509903, timestamp: 2022-08-19 17:26:01.533746\n",
      "resetting env. episode 9776, reward total was -15.0. running mean: -14.062558644114805, timestamp: 2022-08-19 17:26:12.670402\n",
      "resetting env. episode 9777, reward total was -16.0. running mean: -14.081933057673657, timestamp: 2022-08-19 17:26:23.281522\n",
      "resetting env. episode 9778, reward total was -11.0. running mean: -14.05111372709692, timestamp: 2022-08-19 17:26:33.575642\n",
      "resetting env. episode 9779, reward total was -14.0. running mean: -14.050602589825951, timestamp: 2022-08-19 17:26:42.382746\n",
      "resetting env. episode 9780, reward total was -15.0. running mean: -14.060096563927692, timestamp: 2022-08-19 17:26:53.571876\n",
      "resetting env. episode 9781, reward total was -17.0. running mean: -14.089495598288414, timestamp: 2022-08-19 17:27:02.556980\n",
      "resetting env. episode 9782, reward total was -12.0. running mean: -14.068600642305528, timestamp: 2022-08-19 17:27:13.056100\n",
      "resetting env. episode 9783, reward total was -12.0. running mean: -14.047914635882472, timestamp: 2022-08-19 17:27:22.265737\n",
      "resetting env. episode 9784, reward total was -11.0. running mean: -14.017435489523647, timestamp: 2022-08-19 17:27:34.745885\n",
      "resetting env. episode 9785, reward total was -18.0. running mean: -14.05726113462841, timestamp: 2022-08-19 17:27:41.013952\n",
      "resetting env. episode 9786, reward total was -13.0. running mean: -14.046688523282127, timestamp: 2022-08-19 17:27:51.326071\n",
      "resetting env. episode 9787, reward total was -13.0. running mean: -14.036221638049305, timestamp: 2022-08-19 17:28:00.172218\n",
      "resetting env. episode 9788, reward total was -16.0. running mean: -14.055859421668812, timestamp: 2022-08-19 17:28:11.848877\n",
      "resetting env. episode 9789, reward total was -16.0. running mean: -14.075300827452123, timestamp: 2022-08-19 17:28:21.739988\n",
      "resetting env. episode 9790, reward total was -15.0. running mean: -14.084547819177603, timestamp: 2022-08-19 17:28:30.775615\n",
      "resetting env. episode 9791, reward total was -11.0. running mean: -14.053702340985826, timestamp: 2022-08-19 17:28:40.041725\n",
      "resetting env. episode 9792, reward total was -19.0. running mean: -14.103165317575966, timestamp: 2022-08-19 17:28:47.905812\n",
      "resetting env. episode 9793, reward total was -13.0. running mean: -14.092133664400206, timestamp: 2022-08-19 17:28:58.641462\n",
      "resetting env. episode 9794, reward total was -9.0. running mean: -14.041212327756204, timestamp: 2022-08-19 17:29:10.490601\n",
      "resetting env. episode 9795, reward total was -16.0. running mean: -14.060800204478642, timestamp: 2022-08-19 17:29:19.318698\n",
      "resetting env. episode 9796, reward total was -15.0. running mean: -14.070192202433857, timestamp: 2022-08-19 17:29:31.501837\n",
      "resetting env. episode 9797, reward total was -13.0. running mean: -14.059490280409518, timestamp: 2022-08-19 17:29:41.215948\n",
      "resetting env. episode 9798, reward total was -14.0. running mean: -14.058895377605424, timestamp: 2022-08-19 17:29:51.245060\n",
      "resetting env. episode 9799, reward total was -11.0. running mean: -14.028306423829369, timestamp: 2022-08-19 17:30:03.808206\n",
      "resetting env. episode 9800, reward total was -15.0. running mean: -14.038023359591076, timestamp: 2022-08-19 17:30:13.848318\n",
      "resetting env. episode 9801, reward total was -9.0. running mean: -13.987643125995165, timestamp: 2022-08-19 17:30:24.378440\n",
      "resetting env. episode 9802, reward total was -17.0. running mean: -14.017766694735213, timestamp: 2022-08-19 17:30:32.719534\n",
      "resetting env. episode 9803, reward total was -17.0. running mean: -14.047589027787861, timestamp: 2022-08-19 17:30:42.450646\n",
      "resetting env. episode 9804, reward total was -18.0. running mean: -14.087113137509983, timestamp: 2022-08-19 17:30:50.917740\n",
      "resetting env. episode 9805, reward total was -13.0. running mean: -14.076242006134883, timestamp: 2022-08-19 17:30:59.683369\n",
      "resetting env. episode 9806, reward total was -12.0. running mean: -14.055479586073533, timestamp: 2022-08-19 17:31:10.209017\n",
      "resetting env. episode 9807, reward total was -14.0. running mean: -14.054924790212798, timestamp: 2022-08-19 17:31:19.927658\n",
      "resetting env. episode 9808, reward total was -12.0. running mean: -14.03437554231067, timestamp: 2022-08-19 17:31:29.265760\n",
      "resetting env. episode 9809, reward total was -16.0. running mean: -14.054031786887563, timestamp: 2022-08-19 17:31:38.477864\n",
      "resetting env. episode 9810, reward total was -15.0. running mean: -14.063491469018688, timestamp: 2022-08-19 17:31:46.805958\n",
      "resetting env. episode 9811, reward total was -14.0. running mean: -14.062856554328501, timestamp: 2022-08-19 17:31:57.193077\n",
      "resetting env. episode 9812, reward total was -18.0. running mean: -14.102227988785216, timestamp: 2022-08-19 17:32:06.195758\n",
      "resetting env. episode 9813, reward total was -18.0. running mean: -14.141205708897363, timestamp: 2022-08-19 17:32:13.164833\n",
      "resetting env. episode 9814, reward total was -14.0. running mean: -14.13979365180839, timestamp: 2022-08-19 17:32:23.371948\n",
      "resetting env. episode 9815, reward total was -11.0. running mean: -14.108395715290305, timestamp: 2022-08-19 17:32:33.503063\n",
      "resetting env. episode 9816, reward total was -13.0. running mean: -14.097311758137403, timestamp: 2022-08-19 17:32:44.000705\n",
      "resetting env. episode 9817, reward total was -13.0. running mean: -14.08633864055603, timestamp: 2022-08-19 17:32:53.645812\n",
      "resetting env. episode 9818, reward total was -13.0. running mean: -14.075475254150469, timestamp: 2022-08-19 17:33:00.696416\n",
      "resetting env. episode 9819, reward total was -15.0. running mean: -14.084720501608965, timestamp: 2022-08-19 17:33:09.021512\n",
      "resetting env. episode 9820, reward total was -11.0. running mean: -14.053873296592874, timestamp: 2022-08-19 17:33:21.547653\n",
      "resetting env. episode 9821, reward total was -16.0. running mean: -14.073334563626945, timestamp: 2022-08-19 17:33:29.828272\n",
      "resetting env. episode 9822, reward total was -18.0. running mean: -14.112601217990676, timestamp: 2022-08-19 17:33:38.338373\n",
      "resetting env. episode 9823, reward total was -14.0. running mean: -14.11147520581077, timestamp: 2022-08-19 17:33:48.281486\n",
      "resetting env. episode 9824, reward total was -13.0. running mean: -14.100360453752662, timestamp: 2022-08-19 17:33:58.028598\n",
      "resetting env. episode 9825, reward total was -10.0. running mean: -14.059356849215135, timestamp: 2022-08-19 17:34:08.695721\n",
      "resetting env. episode 9826, reward total was -7.0. running mean: -13.988763280722983, timestamp: 2022-08-19 17:34:19.151843\n",
      "resetting env. episode 9827, reward total was -17.0. running mean: -14.018875647915753, timestamp: 2022-08-19 17:34:26.990459\n",
      "resetting env. episode 9828, reward total was -13.0. running mean: -14.008686891436597, timestamp: 2022-08-19 17:34:37.925587\n",
      "resetting env. episode 9829, reward total was -11.0. running mean: -13.97860002252223, timestamp: 2022-08-19 17:34:48.445709\n",
      "resetting env. episode 9830, reward total was -19.0. running mean: -14.028814022297007, timestamp: 2022-08-19 17:34:57.015334\n",
      "resetting env. episode 9831, reward total was -15.0. running mean: -14.038525882074037, timestamp: 2022-08-19 17:35:04.795424\n",
      "resetting env. episode 9832, reward total was -16.0. running mean: -14.058140623253296, timestamp: 2022-08-19 17:35:12.807515\n",
      "resetting env. episode 9833, reward total was -13.0. running mean: -14.047559217020764, timestamp: 2022-08-19 17:35:22.129667\n",
      "resetting env. episode 9834, reward total was -14.0. running mean: -14.047083624850556, timestamp: 2022-08-19 17:35:31.677783\n",
      "resetting env. episode 9835, reward total was -13.0. running mean: -14.036612788602051, timestamp: 2022-08-19 17:35:38.958863\n",
      "resetting env. episode 9836, reward total was -17.0. running mean: -14.06624666071603, timestamp: 2022-08-19 17:35:47.064958\n",
      "resetting env. episode 9837, reward total was -15.0. running mean: -14.07558419410887, timestamp: 2022-08-19 17:35:56.239068\n",
      "resetting env. episode 9838, reward total was -16.0. running mean: -14.09482835216778, timestamp: 2022-08-19 17:36:06.729709\n",
      "resetting env. episode 9839, reward total was -10.0. running mean: -14.053880068646103, timestamp: 2022-08-19 17:36:17.642840\n",
      "resetting env. episode 9840, reward total was -11.0. running mean: -14.023341267959642, timestamp: 2022-08-19 17:36:27.884959\n",
      "resetting env. episode 9841, reward total was -15.0. running mean: -14.033107855280045, timestamp: 2022-08-19 17:36:37.915078\n",
      "resetting env. episode 9842, reward total was -17.0. running mean: -14.062776776727244, timestamp: 2022-08-19 17:36:46.442178\n",
      "resetting env. episode 9843, reward total was -16.0. running mean: -14.082149008959972, timestamp: 2022-08-19 17:36:53.799795\n",
      "resetting env. episode 9844, reward total was -15.0. running mean: -14.091327518870372, timestamp: 2022-08-19 17:37:03.626912\n",
      "resetting env. episode 9845, reward total was -13.0. running mean: -14.08041424368167, timestamp: 2022-08-19 17:37:13.896031\n",
      "resetting env. episode 9846, reward total was -17.0. running mean: -14.109610101244852, timestamp: 2022-08-19 17:37:23.401142\n",
      "resetting env. episode 9847, reward total was -18.0. running mean: -14.148514000232403, timestamp: 2022-08-19 17:37:31.555239\n",
      "resetting env. episode 9848, reward total was -10.0. running mean: -14.107028860230079, timestamp: 2022-08-19 17:37:42.823899\n",
      "resetting env. episode 9849, reward total was -15.0. running mean: -14.115958571627779, timestamp: 2022-08-19 17:37:55.038564\n",
      "resetting env. episode 9850, reward total was -12.0. running mean: -14.0947989859115, timestamp: 2022-08-19 17:38:06.147696\n",
      "resetting env. episode 9851, reward total was -15.0. running mean: -14.103850996052387, timestamp: 2022-08-19 17:38:14.568795\n",
      "resetting env. episode 9852, reward total was -13.0. running mean: -14.092812486091864, timestamp: 2022-08-19 17:38:25.589926\n",
      "resetting env. episode 9853, reward total was -17.0. running mean: -14.121884361230945, timestamp: 2022-08-19 17:38:35.200039\n",
      "resetting env. episode 9854, reward total was -11.0. running mean: -14.090665517618636, timestamp: 2022-08-19 17:38:43.107132\n",
      "resetting env. episode 9855, reward total was -9.0. running mean: -14.039758862442449, timestamp: 2022-08-19 17:38:55.066273\n",
      "resetting env. episode 9856, reward total was -11.0. running mean: -14.009361273818024, timestamp: 2022-08-19 17:39:05.364400\n",
      "resetting env. episode 9857, reward total was -14.0. running mean: -14.009267661079845, timestamp: 2022-08-19 17:39:14.317502\n",
      "resetting env. episode 9858, reward total was -8.0. running mean: -13.949174984469046, timestamp: 2022-08-19 17:39:26.096640\n",
      "resetting env. episode 9859, reward total was -14.0. running mean: -13.949683234624356, timestamp: 2022-08-19 17:39:35.842757\n",
      "resetting env. episode 9860, reward total was -17.0. running mean: -13.980186402278113, timestamp: 2022-08-19 17:39:45.772395\n",
      "resetting env. episode 9861, reward total was -17.0. running mean: -14.010384538255332, timestamp: 2022-08-19 17:39:53.811491\n",
      "resetting env. episode 9862, reward total was -17.0. running mean: -14.040280692872779, timestamp: 2022-08-19 17:40:01.867585\n",
      "resetting env. episode 9863, reward total was -15.0. running mean: -14.049877885944051, timestamp: 2022-08-19 17:40:10.816693\n",
      "resetting env. episode 9864, reward total was -15.0. running mean: -14.059379107084611, timestamp: 2022-08-19 17:40:19.695795\n",
      "resetting env. episode 9865, reward total was -15.0. running mean: -14.068785316013765, timestamp: 2022-08-19 17:40:29.382910\n",
      "resetting env. episode 9866, reward total was -13.0. running mean: -14.058097462853627, timestamp: 2022-08-19 17:40:39.046021\n",
      "resetting env. episode 9867, reward total was -13.0. running mean: -14.047516488225092, timestamp: 2022-08-19 17:40:49.448145\n",
      "resetting env. episode 9868, reward total was -15.0. running mean: -14.057041323342842, timestamp: 2022-08-19 17:40:59.692314\n",
      "resetting env. episode 9869, reward total was -14.0. running mean: -14.056470910109415, timestamp: 2022-08-19 17:41:09.603432\n",
      "resetting env. episode 9870, reward total was -12.0. running mean: -14.03590620100832, timestamp: 2022-08-19 17:41:21.602569\n",
      "resetting env. episode 9871, reward total was -14.0. running mean: -14.035547138998238, timestamp: 2022-08-19 17:41:32.803224\n",
      "resetting env. episode 9872, reward total was -12.0. running mean: -14.015191667608255, timestamp: 2022-08-19 17:41:43.880395\n",
      "resetting env. episode 9873, reward total was -19.0. running mean: -14.065039750932172, timestamp: 2022-08-19 17:41:51.565485\n",
      "resetting env. episode 9874, reward total was -14.0. running mean: -14.06438935342285, timestamp: 2022-08-19 17:42:01.316599\n",
      "resetting env. episode 9875, reward total was -14.0. running mean: -14.063745459888622, timestamp: 2022-08-19 17:42:11.976725\n",
      "resetting env. episode 9876, reward total was -16.0. running mean: -14.083108005289736, timestamp: 2022-08-19 17:42:19.889337\n",
      "resetting env. episode 9877, reward total was -16.0. running mean: -14.102276925236838, timestamp: 2022-08-19 17:42:28.419438\n",
      "resetting env. episode 9878, reward total was -14.0. running mean: -14.10125415598447, timestamp: 2022-08-19 17:42:38.388085\n",
      "resetting env. episode 9879, reward total was -17.0. running mean: -14.130241614424627, timestamp: 2022-08-19 17:42:46.138173\n",
      "resetting env. episode 9880, reward total was -4.0. running mean: -14.02893919828038, timestamp: 2022-08-19 17:42:57.181298\n",
      "resetting env. episode 9881, reward total was -16.0. running mean: -14.048649806297576, timestamp: 2022-08-19 17:43:06.881413\n",
      "resetting env. episode 9882, reward total was -19.0. running mean: -14.098163308234598, timestamp: 2022-08-19 17:43:16.916099\n",
      "resetting env. episode 9883, reward total was -19.0. running mean: -14.147181675152252, timestamp: 2022-08-19 17:43:24.341184\n",
      "resetting env. episode 9884, reward total was -16.0. running mean: -14.16570985840073, timestamp: 2022-08-19 17:43:34.291302\n",
      "resetting env. episode 9885, reward total was -16.0. running mean: -14.184052759816723, timestamp: 2022-08-19 17:43:43.692409\n",
      "resetting env. episode 9886, reward total was -9.0. running mean: -14.132212232218555, timestamp: 2022-08-19 17:43:54.794541\n",
      "resetting env. episode 9887, reward total was -16.0. running mean: -14.15089010989637, timestamp: 2022-08-19 17:44:04.146648\n",
      "resetting env. episode 9888, reward total was -15.0. running mean: -14.159381208797406, timestamp: 2022-08-19 17:44:14.658292\n",
      "resetting env. episode 9889, reward total was -15.0. running mean: -14.167787396709432, timestamp: 2022-08-19 17:44:24.484931\n",
      "resetting env. episode 9890, reward total was -12.0. running mean: -14.146109522742337, timestamp: 2022-08-19 17:44:34.373044\n",
      "resetting env. episode 9891, reward total was -17.0. running mean: -14.174648427514914, timestamp: 2022-08-19 17:44:43.139146\n",
      "resetting env. episode 9892, reward total was -20.0. running mean: -14.232901943239764, timestamp: 2022-08-19 17:44:50.986241\n",
      "resetting env. episode 9893, reward total was -8.0. running mean: -14.170572923807367, timestamp: 2022-08-19 17:45:01.816360\n",
      "resetting env. episode 9894, reward total was -19.0. running mean: -14.218867194569292, timestamp: 2022-08-19 17:45:11.099465\n",
      "resetting env. episode 9895, reward total was -9.0. running mean: -14.166678522623599, timestamp: 2022-08-19 17:45:23.062603\n",
      "resetting env. episode 9896, reward total was -14.0. running mean: -14.165011737397363, timestamp: 2022-08-19 17:45:32.614714\n",
      "resetting env. episode 9897, reward total was -17.0. running mean: -14.193361620023389, timestamp: 2022-08-19 17:45:42.154822\n",
      "resetting env. episode 9898, reward total was -13.0. running mean: -14.181428003823155, timestamp: 2022-08-19 17:45:52.809468\n",
      "resetting env. episode 9899, reward total was -18.0. running mean: -14.219613723784924, timestamp: 2022-08-19 17:46:00.655085\n",
      "resetting env. episode 9900, reward total was -16.0. running mean: -14.237417586547075, timestamp: 2022-08-19 17:46:10.623723\n",
      "resetting env. episode 9901, reward total was -19.0. running mean: -14.285043410681602, timestamp: 2022-08-19 17:46:19.630830\n",
      "resetting env. episode 9902, reward total was -8.0. running mean: -14.222192976574787, timestamp: 2022-08-19 17:46:30.865954\n",
      "resetting env. episode 9903, reward total was -17.0. running mean: -14.249971046809039, timestamp: 2022-08-19 17:46:38.268040\n",
      "resetting env. episode 9904, reward total was -18.0. running mean: -14.287471336340948, timestamp: 2022-08-19 17:46:43.685616\n",
      "resetting env. episode 9905, reward total was -12.0. running mean: -14.264596622977537, timestamp: 2022-08-19 17:46:52.540715\n",
      "resetting env. episode 9906, reward total was -17.0. running mean: -14.291950656747762, timestamp: 2022-08-19 17:46:59.885323\n",
      "resetting env. episode 9907, reward total was -17.0. running mean: -14.319031150180285, timestamp: 2022-08-19 17:47:07.442934\n",
      "resetting env. episode 9908, reward total was -15.0. running mean: -14.325840838678483, timestamp: 2022-08-19 17:47:17.004039\n",
      "resetting env. episode 9909, reward total was -17.0. running mean: -14.352582430291697, timestamp: 2022-08-19 17:47:27.202155\n",
      "resetting env. episode 9910, reward total was -14.0. running mean: -14.34905660598878, timestamp: 2022-08-19 17:47:39.312290\n",
      "resetting env. episode 9911, reward total was -15.0. running mean: -14.355566039928892, timestamp: 2022-08-19 17:47:48.785401\n",
      "resetting env. episode 9912, reward total was -14.0. running mean: -14.352010379529604, timestamp: 2022-08-19 17:47:58.211030\n",
      "resetting env. episode 9913, reward total was -14.0. running mean: -14.348490275734308, timestamp: 2022-08-19 17:48:06.889128\n",
      "resetting env. episode 9914, reward total was -14.0. running mean: -14.345005372976965, timestamp: 2022-08-19 17:48:15.794227\n",
      "resetting env. episode 9915, reward total was -12.0. running mean: -14.321555319247194, timestamp: 2022-08-19 17:48:27.198359\n",
      "resetting env. episode 9916, reward total was -6.0. running mean: -14.238339766054722, timestamp: 2022-08-19 17:48:40.966036\n",
      "resetting env. episode 9917, reward total was -13.0. running mean: -14.225956368394176, timestamp: 2022-08-19 17:48:53.463180\n",
      "resetting env. episode 9918, reward total was -17.0. running mean: -14.253696804710234, timestamp: 2022-08-19 17:49:01.971271\n",
      "resetting env. episode 9919, reward total was -15.0. running mean: -14.261159836663133, timestamp: 2022-08-19 17:49:11.624380\n",
      "resetting env. episode 9920, reward total was -17.0. running mean: -14.288548238296501, timestamp: 2022-08-19 17:49:20.041518\n",
      "resetting env. episode 9921, reward total was -15.0. running mean: -14.295662755913536, timestamp: 2022-08-19 17:49:31.778652\n",
      "resetting env. episode 9922, reward total was -18.0. running mean: -14.3327061283544, timestamp: 2022-08-19 17:49:38.529726\n",
      "resetting env. episode 9923, reward total was -19.0. running mean: -14.379379067070856, timestamp: 2022-08-19 17:49:45.657810\n",
      "resetting env. episode 9924, reward total was -16.0. running mean: -14.395585276400148, timestamp: 2022-08-19 17:49:56.249930\n",
      "resetting env. episode 9925, reward total was -21.0. running mean: -14.461629423636147, timestamp: 2022-08-19 17:50:04.629549\n",
      "resetting env. episode 9926, reward total was -13.0. running mean: -14.447013129399785, timestamp: 2022-08-19 17:50:15.323670\n",
      "resetting env. episode 9927, reward total was -13.0. running mean: -14.432542998105788, timestamp: 2022-08-19 17:50:23.545287\n",
      "resetting env. episode 9928, reward total was -9.0. running mean: -14.37821756812473, timestamp: 2022-08-19 17:50:34.656939\n",
      "resetting env. episode 9929, reward total was -8.0. running mean: -14.314435392443484, timestamp: 2022-08-19 17:50:46.207076\n",
      "resetting env. episode 9930, reward total was -10.0. running mean: -14.271291038519049, timestamp: 2022-08-19 17:50:56.061187\n",
      "resetting env. episode 9931, reward total was -12.0. running mean: -14.248578128133857, timestamp: 2022-08-19 17:51:06.864310\n",
      "resetting env. episode 9932, reward total was -9.0. running mean: -14.196092346852518, timestamp: 2022-08-19 17:51:17.231429\n",
      "resetting env. episode 9933, reward total was -15.0. running mean: -14.204131423383993, timestamp: 2022-08-19 17:51:27.069546\n",
      "resetting env. episode 9934, reward total was -14.0. running mean: -14.202090109150154, timestamp: 2022-08-19 17:51:36.876659\n",
      "resetting env. episode 9935, reward total was -15.0. running mean: -14.210069208058652, timestamp: 2022-08-19 17:51:46.438815\n",
      "resetting env. episode 9936, reward total was -14.0. running mean: -14.207968515978067, timestamp: 2022-08-19 17:51:55.667921\n",
      "resetting env. episode 9937, reward total was -12.0. running mean: -14.185888830818286, timestamp: 2022-08-19 17:52:04.855028\n",
      "resetting env. episode 9938, reward total was -17.0. running mean: -14.214029942510102, timestamp: 2022-08-19 17:52:15.428674\n",
      "resetting env. episode 9939, reward total was -20.0. running mean: -14.271889643085, timestamp: 2022-08-19 17:52:24.842785\n",
      "resetting env. episode 9940, reward total was -9.0. running mean: -14.21917074665415, timestamp: 2022-08-19 17:52:34.794899\n",
      "resetting env. episode 9941, reward total was -19.0. running mean: -14.266979039187609, timestamp: 2022-08-19 17:52:41.900506\n",
      "resetting env. episode 9942, reward total was -14.0. running mean: -14.264309248795733, timestamp: 2022-08-19 17:52:50.503605\n",
      "resetting env. episode 9943, reward total was -18.0. running mean: -14.301666156307775, timestamp: 2022-08-19 17:52:59.508713\n",
      "resetting env. episode 9944, reward total was -15.0. running mean: -14.308649494744698, timestamp: 2022-08-19 17:53:07.041800\n",
      "resetting env. episode 9945, reward total was -14.0. running mean: -14.305562999797251, timestamp: 2022-08-19 17:53:16.476909\n",
      "resetting env. episode 9946, reward total was -12.0. running mean: -14.282507369799278, timestamp: 2022-08-19 17:53:25.789540\n",
      "resetting env. episode 9947, reward total was -16.0. running mean: -14.299682296101285, timestamp: 2022-08-19 17:53:33.357628\n",
      "resetting env. episode 9948, reward total was -14.0. running mean: -14.296685473140272, timestamp: 2022-08-19 17:53:42.694741\n",
      "resetting env. episode 9949, reward total was -12.0. running mean: -14.273718618408868, timestamp: 2022-08-19 17:53:52.480852\n",
      "resetting env. episode 9950, reward total was -16.0. running mean: -14.290981432224779, timestamp: 2022-08-19 17:54:00.357945\n",
      "resetting env. episode 9951, reward total was -20.0. running mean: -14.34807161790253, timestamp: 2022-08-19 17:54:07.516028\n",
      "resetting env. episode 9952, reward total was -13.0. running mean: -14.334590901723505, timestamp: 2022-08-19 17:54:17.430147\n",
      "resetting env. episode 9953, reward total was -15.0. running mean: -14.34124499270627, timestamp: 2022-08-19 17:54:27.873268\n",
      "resetting env. episode 9954, reward total was -17.0. running mean: -14.367832542779208, timestamp: 2022-08-19 17:54:36.324366\n",
      "resetting env. episode 9955, reward total was -15.0. running mean: -14.374154217351416, timestamp: 2022-08-19 17:54:44.258458\n",
      "resetting env. episode 9956, reward total was -9.0. running mean: -14.320412675177902, timestamp: 2022-08-19 17:54:54.979585\n",
      "resetting env. episode 9957, reward total was -14.0. running mean: -14.317208548426123, timestamp: 2022-08-19 17:55:02.739676\n",
      "resetting env. episode 9958, reward total was -14.0. running mean: -14.314036462941862, timestamp: 2022-08-19 17:55:11.716304\n",
      "resetting env. episode 9959, reward total was -16.0. running mean: -14.330896098312444, timestamp: 2022-08-19 17:55:21.752421\n",
      "resetting env. episode 9960, reward total was -13.0. running mean: -14.317587137329319, timestamp: 2022-08-19 17:55:31.448533\n",
      "resetting env. episode 9961, reward total was -13.0. running mean: -14.304411265956027, timestamp: 2022-08-19 17:55:41.690652\n",
      "resetting env. episode 9962, reward total was -10.0. running mean: -14.261367153296467, timestamp: 2022-08-19 17:55:52.410308\n",
      "resetting env. episode 9963, reward total was -14.0. running mean: -14.258753481763502, timestamp: 2022-08-19 17:56:01.330414\n",
      "resetting env. episode 9964, reward total was -16.0. running mean: -14.276165946945868, timestamp: 2022-08-19 17:56:10.865525\n",
      "resetting env. episode 9965, reward total was -20.0. running mean: -14.333404287476409, timestamp: 2022-08-19 17:56:18.481610\n",
      "resetting env. episode 9966, reward total was -15.0. running mean: -14.340070244601645, timestamp: 2022-08-19 17:56:27.886722\n",
      "resetting env. episode 9967, reward total was -9.0. running mean: -14.286669542155629, timestamp: 2022-08-19 17:56:39.887862\n",
      "resetting env. episode 9968, reward total was -10.0. running mean: -14.243802846734072, timestamp: 2022-08-19 17:56:48.739017\n",
      "resetting env. episode 9969, reward total was -18.0. running mean: -14.28136481826673, timestamp: 2022-08-19 17:56:57.120116\n",
      "resetting env. episode 9970, reward total was -16.0. running mean: -14.298551170084064, timestamp: 2022-08-19 17:57:06.771223\n",
      "resetting env. episode 9971, reward total was -13.0. running mean: -14.285565658383224, timestamp: 2022-08-19 17:57:15.263324\n",
      "resetting env. episode 9972, reward total was -17.0. running mean: -14.312710001799392, timestamp: 2022-08-19 17:57:24.265432\n",
      "resetting env. episode 9973, reward total was -16.0. running mean: -14.329582901781398, timestamp: 2022-08-19 17:57:32.983058\n",
      "resetting env. episode 9974, reward total was -15.0. running mean: -14.336287072763584, timestamp: 2022-08-19 17:57:40.678148\n",
      "resetting env. episode 9975, reward total was -12.0. running mean: -14.312924202035948, timestamp: 2022-08-19 17:57:50.554265\n",
      "resetting env. episode 9976, reward total was -8.0. running mean: -14.249794960015588, timestamp: 2022-08-19 17:58:00.076895\n",
      "resetting env. episode 9977, reward total was -11.0. running mean: -14.217297010415432, timestamp: 2022-08-19 17:58:09.266011\n",
      "resetting env. episode 9978, reward total was -15.0. running mean: -14.225124040311279, timestamp: 2022-08-19 17:58:16.833096\n",
      "resetting env. episode 9979, reward total was -16.0. running mean: -14.242872799908167, timestamp: 2022-08-19 17:58:27.602218\n",
      "resetting env. episode 9980, reward total was -10.0. running mean: -14.200444071909084, timestamp: 2022-08-19 17:58:37.959385\n",
      "resetting env. episode 9981, reward total was -15.0. running mean: -14.208439631189993, timestamp: 2022-08-19 17:58:45.992476\n",
      "resetting env. episode 9982, reward total was -16.0. running mean: -14.226355234878094, timestamp: 2022-08-19 17:58:55.139586\n",
      "resetting env. episode 9983, reward total was -11.0. running mean: -14.194091682529312, timestamp: 2022-08-19 17:59:05.838707\n",
      "resetting env. episode 9984, reward total was -19.0. running mean: -14.242150765704018, timestamp: 2022-08-19 17:59:13.775801\n",
      "resetting env. episode 9985, reward total was -19.0. running mean: -14.289729258046977, timestamp: 2022-08-19 17:59:20.507882\n",
      "resetting env. episode 9986, reward total was -17.0. running mean: -14.316831965466507, timestamp: 2022-08-19 17:59:28.738972\n",
      "resetting env. episode 9987, reward total was -13.0. running mean: -14.303663645811843, timestamp: 2022-08-19 17:59:37.944081\n",
      "resetting env. episode 9988, reward total was -15.0. running mean: -14.310627009353725, timestamp: 2022-08-19 17:59:47.802196\n",
      "resetting env. episode 9989, reward total was -14.0. running mean: -14.307520739260188, timestamp: 2022-08-19 17:59:57.562308\n",
      "resetting env. episode 9990, reward total was -16.0. running mean: -14.324445531867585, timestamp: 2022-08-19 18:00:06.162409\n",
      "resetting env. episode 9991, reward total was -12.0. running mean: -14.301201076548908, timestamp: 2022-08-19 18:00:15.749043\n",
      "resetting env. episode 9992, reward total was -9.0. running mean: -14.24818906578342, timestamp: 2022-08-19 18:00:27.487180\n",
      "resetting env. episode 9993, reward total was -14.0. running mean: -14.245707175125586, timestamp: 2022-08-19 18:00:37.000810\n",
      "resetting env. episode 9994, reward total was -10.0. running mean: -14.20325010337433, timestamp: 2022-08-19 18:00:50.300966\n",
      "resetting env. episode 9995, reward total was -11.0. running mean: -14.171217602340587, timestamp: 2022-08-19 18:01:00.695084\n",
      "resetting env. episode 9996, reward total was -12.0. running mean: -14.14950542631718, timestamp: 2022-08-19 18:01:09.894713\n",
      "resetting env. episode 9997, reward total was -13.0. running mean: -14.138010372054008, timestamp: 2022-08-19 18:01:22.147851\n",
      "resetting env. episode 9998, reward total was -11.0. running mean: -14.106630268333468, timestamp: 2022-08-19 18:01:35.061004\n",
      "resetting env. episode 9999, reward total was -13.0. running mean: -14.095563965650134, timestamp: 2022-08-19 18:01:47.791668\n",
      "resetting env. episode 10000, reward total was -19.0. running mean: -14.144608325993632, timestamp: 2022-08-19 18:01:55.326756\n",
      "CPU times: total: 18h 26min 10s\n",
      "Wall time: 13h 36min 6s\n"
     ]
    }
   ],
   "source": [
    "file_name = 'hist1_last_.csv'\n",
    "%time hist1,hist_2 = train_model(env, model, total_episodes=10000)\n",
    "np.savetxt(file_name, hist1, delimiter =\",\", fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "plt.ion()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "def plot_graph2(data):\n",
    "    for line in data:\n",
    "        xs.append(float(line[0]))\n",
    "        ys.append(float(line[1]))\n",
    "        ax1.clear()\n",
    "        \n",
    "    ax1.plot(xs, ys)\n",
    "    plt.pause(1)\n",
    "    plt.show()\n",
    "\n",
    "plot_graph2(hist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHYCDYwhlVLV",
    "outputId": "44023870-3ed0-46f5-84e7-df559e94ffc0"
   },
   "outputs": [],
   "source": [
    "#%time hist2 = train_model(env, model, total_episodes=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "8fheN9DRlWXQ",
    "outputId": "23490ad9-3ac8-4899-824b-44400caa8afd"
   },
   "outputs": [],
   "source": [
    "#play_game(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AxOcQhIsKow",
    "outputId": "68d93a54-196d-4d91-a6f6-731aa0de23c4"
   },
   "outputs": [],
   "source": [
    "#%time hist3 = train_model(env, model, total_episodes=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "w2NblmwDsL3y",
    "outputId": "f3dc32bf-ab84-418d-b830-407510690d12"
   },
   "outputs": [],
   "source": [
    "#play_game(env, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "H=200 le-4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea2d5fd90987848081bf8639bc2a6955965d1ac41956e8a19667342fc3d5a5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
